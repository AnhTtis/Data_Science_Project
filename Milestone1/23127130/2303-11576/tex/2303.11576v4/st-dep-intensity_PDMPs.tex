% str 16, poprawiony wz√≥r na g_T
% str 17, linia 11 : poprawione ograniczenie odwzorowan

\documentclass[12pt]{article}
\usepackage{authblk}
\usepackage[cp1250]{inputenc}
\usepackage[reqno]{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{graphics}
\usepackage{enumitem}
\usepackage{fancyhdr}



\usepackage{bbm}
\usepackage[margin=1in]{geometry}
\numberwithin{equation}{section}


\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\theoremstyle{definition}
\newtheorem{remark}{Remark}[section]
\newtheorem{definition}{Definition}[section]

\newcommand{\n}{\mathbb{N}}
\newcommand {\<}{\left\langle}  
\renewcommand {\>}{\right\rangle}  
\newcommand {\norma}[1]{\left\|#1\right\|}
\newcommand{\ew}{\mathbb{E}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\wlim}{w^*\mbox{-}\lim}
\newcommand{\wcl}{w^*\mbox{-}\operatorname{cl}}
\newcommand{\olambda}{\bar{\lambda}}
\newcommand{\ulambda}{\underline{\lambda}}
\newcommand{\hlambda}{\hat{\lambda}}
\newcommand{\tG}{\widetilde{G}}
\newcommand{\tW}{\widetilde{W}}
\newcommand{\dpsi}{D_{\psi}}

\title{On the Existence and Uniqueness of Stationary Distributions for Some Class of Piecewise Deterministic Markov Processes With State-Dependent Jump Intensity}

%\pagestyle{fancy}
%\makeatletter
%\let\runauthor\@author
%\let\runtitle\@title
%\makeatother
\lhead{Dawid Czapla}
\rhead{On stationary distributions for some PDMPs}


\author{Dawid Czapla\footnote{\emph{E-mail address:} \texttt{dawid.czapla@us.edu.pl}}}
\affil{Institute of Mathematics, University of Silesia in Katowice, Bankowa 14, Katowice 40-007, Poland}
\renewcommand\Affilfont{\itshape}
%\linespread{1,02} 
\date{}
\begin{document}
\maketitle
\vspace{-1cm}
\begin{abstract}
In this paper, we are concerned with a class of piecewise deterministic Markov processes that involve a deterministic motion punctuated by random jumps, occurring in a Poisson-like fashion with some state-dependent rate, between which, at any time, the trajectory is driven by one of the given semiflows, randomly drawn right after the jump. We prove that there is a one-to-one correspondence between stationary distributions of such processes and those of the discrete-time Markov chains given by their post-jump locations. Using this result, we further establish a criterion guaranteeing the existence and uniqueness of the stationary distribution for some particular model, which, among others, constitutes a framework for analyzing gene expression in prokaryotes.

%
%in a particular case, where the post-jump locations result from the action of an iterated function system with place-dependent probabilities.
\end{abstract}
{\small
\noindent
\textbf {MSC 2010:} Primary: 60J25, 60J05; Secondary: 60J35, 37A30 \\
\textbf{Keywords:} Piecewise deterministic Markov process; Switching semiflows; State-dependent jump intensity; Invariant measure; Iterated function system; One-to-one correspondence. \\
}

\section{Introduction}
Let $Y$ be a Polish metric space, and suppose that we are given a finite collection $\{S_i:\, i\in I\}$ of continuous semiflows acting from $\mathbb{R}_+ \times Y$ to~$Y$, where $\mathbb{R}_+:=[0,\infty)$. The object of our study will be a~piecewise deterministic Markov process (PDMP) $\Psi:=\{(Y(t),\xi(t))\}_{t\geq 0}$ evolving on the space $X:=Y\times I$ in such a way that
\begin{equation}
\label{def:pdmp}
Y(t)=S_{\xi_n}(t-\tau_n,Y_n),\quad \xi(t)=\xi_n\quad\text{whenever}\quad t\in [\tau_n,\tau_{n+1})\;\;\text{for}\;\;n\in\n_0.
\end{equation}
Here, $\Phi:=\{(Y_n,\xi_n)\}_{n\in\n_0}$ stands for a given Markov chain describing the post-jump locations of the process $\Psi$, and $\{\tau_n\}_{n\in\n_0}$ is an a.s. increasing to infinity sequence of non-negative random variables, representing the jump times of $\Psi$, such that $\Delta \tau_{n+1}:=\tau_{n+1}-\tau_{n}$, $n\in\n_0$, are independent and satisfy
$$\pr(\Delta\tau_{n+1}\leq t\,|\,\Phi_n=(y,i))=1-\exp\left(-\int_0^t \lambda(S_i(h,y))dh\right)\quad\text{for all}\quad t\in\mathbb{R}_+,\; (y,i)\in X,$$ 
with a given bounded continuous function $\lambda:Y\to (0,\infty)$, for which $\inf_{y\in Y}\lambda(y)>0$. The~transition law of $\Phi$, further denoted by $P$, will be defined using an arbitrary stochastic kernel $J$ on $Y$ and a~state-dependent stochastic matrix $\{\pi_{ij}:\,i,j\in I\}$, consisting of continuous functions from~$Y$ to~$[0,1]$, so that the probability of entering any Borel set $B\subset Y$ by~$Y_{n+1}$ given~$Y(\tau_{n+1}-)=y$ is equal $J(y,B)$, while the probability of transition from $\xi_n=i$ to $\xi_{n+1}=j$ given $Y_{n+1}=y$ is specified by $\pi_{ij}(y)$.

The main goal of this paper is to prove that there is a one-to-one correspondence between the families of stationary distributions of the process $\Psi$ and the chain $\Phi$, provided that the kernel $J$ enjoys a strengthened form of the Feller property. This result \hbox{(i.e., Theorem~\ref{thm:main})} generalizes \hbox{\cite[Theorem 5.1]{b:czapla_exp_erg}}, which has been established under the assumptions that the inter-jump times, $\Delta\tau_n$, are exponentially distributed with a constant rate~$\lambda$, and the probabilities $\pi_{ij}$ are constant. 

The above-mentioned result in \cite{b:czapla_exp_erg} is an extension of \hbox{\cite[Theorem 4.4]{b:czapla_erg}}, whose proof, in turn, was inspired by \hbox{\cite[Proposition 2.4]{b:benaim1}}. The latter refers to a model that is somewhat similar to the one presented here but which involves the post-jump locations resulting only from semiflows switching, i.e., $Y_{n}=Y(\tau_n-)$, and, like the models in~\cite{b:czapla_erg, b:czapla_exp_erg}, is limited by a constant jump intensity. On the other hand, e.g., in \cite{b:costa1} (cf. also~\cite{b:azais, b:costa2}), the authors investigate a PDMP with a single semiflow that employs a general mechanism of jumps occurring with a state-dependent intensity. Among others, they provide \hbox{\cite[Theorem 4.2]{b:costa1}} which, at first sight, resembles the main result of the present paper. However, the correspondence of stationary distributions established in this theorem refers to a Markov chain which does not represent a sampling of the PDMP at its actual jump times. Instead, it describes random times depending on a combination of $\{\tau_n\}_{n\in\n_0}$  with a specific sequence of independent and exponentially distributed (with parameter $1$) random variables.

While proving the main result, we primarily follow the line of reasoning in the proofs of \hbox{\cite[Lemma 5.1]{b:czapla_exp_erg}} and \hbox{\cite[Theorem 4.4]{b:czapla_erg}}. The difficulty with that approach is essentially twofold. Firstly, the key argument in the above-mentioned lemma is that \hbox{$\eta(t):=\max\{n\in\n_0:\, \tau_n\leq t\}$} defines a Poisson process, which is not the case when $\lambda$ is non-constant. This can, however, be handled by estimating the probability of $\{\eta(t)=n\}$ using the bounds of $\lambda$, as in Lemma~\ref{lem:tech2}. Secondly, similar to \cite{b:czapla_erg}, the major step in our proof involves expressing the transition law~$P$ of the chain~$\Phi$ as the composition of two specific stochastic kernels $G$ and~$W$, so that $P=GW$. If $\lambda$ is constant, the operator on bounded continuous functions $f:X\to\mathbb{R}$ induced by~$G/\lambda$ proves to coincide with the resolvent of the semigroup $\{Q_t\}_{t\in\mathbb{R}_+}$ defined by 
$$Q_t f (y,i):=f(S_i(t,y),i)\quad\text{for}\quad (y,i)\in X.$$ 
Consequently, according to \cite[Theorem 1.7]{b:dynkin_1965}, $G/\lambda$ is then invertible and its inverse is the \hbox{operator} $\lambda\operatorname{id}-A_Q$ (defined on the domain of $A_Q$), where $A_Q$ is the weak generator of~$\{Q_t\}_{t\in\mathbb{R}_+}$. This fact plays a crucial role in the proof given in \cite{b:czapla_erg}, but it cannot be applied directly when $\lambda$ is non-constant. Nevertheless, we overcome this problem by showing from scratch that, in the case of a state-dependent jump intensity, the inverse of the operator induced by $G$ is the map $f\mapsto f-(A_Q f)/\hlambda$, with $\hlambda(y,i):=\lambda(y)$ for \hbox{$(y,i)\in X$} \hbox{(see Lemma \ref{lem:main1})}. This enables us to adapt the idea behind the reasoning in \cite{b:czapla_erg} to our framework by replacing the kernels $G$ and $W$ with their certain (non-stochastic) modifications while still preserving the composition that yields~$P$.

We finalize the paper with applying our main result to a special case of the PDMP under consideration, where $J$ is the transition law of the Markov chain arising from a random iterated functions system, that is,
\begin{equation}
\label{e:ifs}
J(y,B)=\int_{\Theta}\mathbbm{1}_B(w_{\theta}(y))\,p_{\theta}(y)\,\vartheta(d\theta)\quad\text{for all}\;\; y\in Y\;\text{and Borel sets}\;\; B\subset Y,
\end{equation}
where $\{w_{\theta}:\,\theta\in\Theta\}$ is an arbitrary family of continuous transformations from $Y$ to itself, indexed by the elements of some measure space $(\Theta,\vartheta)$, and  $\{p_{\theta}:\,\theta\in \Theta\}$ is an associated family of state-dependent densities with respect to $\vartheta$. More precisely, we provide a set of user-friendly conditions on $S_i$ and $w_{\theta}$ guaranteeing that such a PDMP has a unique stationary distribution with finite first moment (see Theorem \ref{thm:app}), which leads to a generalization of \hbox{\cite[Corollary 4.5]{b:czapla_erg}} (cf. also \hbox{\cite[Theorem 5.3.1]{b:horbacz}}). In an upcoming paper, we also plan to prove the exponential ergodicity of~$\Psi$ in the bounded Lipschitz distance, under similar assumptions (and thus generalize~\hbox{\cite[Proposition 7.2]{b:czapla_exp_erg}}). 

Eventually, it is worth to emphasize that considering the jumps occurring with a state-dependent intensity is often significant in applications. For example, the PDMP evolving on~$\mathbb{R}_+$ (driven by a single semiflow) with the kernel $J$ given by \eqref{e:ifs} and $w_{\theta}(y):=y+\theta$ proves to be useful in analysing the stochastic dynamics of gene expression in the presence of transcriptional bursting (see, e.g., \cite{b:tyran} or~\hbox{\cite[\S 5.1]{b:czapla_erg}}). In short, $\{Y(t)\}_{t\in\mathbb{R}_+}$ then describes the concentration of a protein encoded by some gene of a prokaryotic cell. The protein molecules undergo a degradation process, which is interrupted by production appearing in the so-called bursts at random times~$\tau_n$. From a biological point of view, it is known that the intensity of these bursts depends on the current number of molecules, and thus taking into account the non-constancy of $\lambda$ makes the model more accurate. 

The outline of the paper is as follows. In Section \ref{sec:prel}, we introduce notation and review several basic concepts related to transition kernels and Markov processes. Section \ref{sec:def} and \ref{sec:assumptions} contain the formal construction of the model and a list of assumptions employed throughout the~paper, respectively. The main result (Theorem \ref{thm:main}) and its application to the above-described particular PDMP (Theorem \ref{thm:app}) are presented in Section \ref{sec:main}. Finally, Section \ref{sec:proof}, divided into three parts, is devoted to proving the main result. In Section \ref{sec:technical}, we estimate the distribution of the Poisson-like process $\{\eta(t)\}_{t\in\mathbb{R}_+}$ and derive certain properties of the transition semigroup of $\Psi$. Section \ref{sec:generators} provides some auxiliary results on the weak generators of this semgroup and $\{Q_t\}_{t\in\mathbb{R}_+}$. The proof is completed in Section~\ref{sec:proof_fin}.

\section{Preliminaries} \label{sec:prel}
First of all, given a metric space $E$, we shall write $\mathcal{B}(E)$ for its Borel $\sigma$-field. By $B_b(E)$ we will denote the space of all bounded Borel measurable functions from $E$ to $\mathbb{R}$, endowed with the supremum norm 
$$\norma{f}_{\infty}:=\sup_{x\in E} |f(x)|\quad \text{for}\quad f\in B_b(E),$$
whilst by $C_b(E)$ we will mean the subspace of $B_b(E)$ consisting of all continuous functions. Further, let $\mathcal{M}_{sig}(E)$ be the family of all finite signed Borel measures on $E$ (that is, all  \hbox{$\sigma$-additive} real-valued set functions on $\mathcal{B}(E)$), and let $\mathcal{M}(E)$, $\mathcal{M}_1(E)$ stand for its subsets containing all non-negative measures and all probability measures, respectively. Additionally, for any given Borel measurable function $V:E\to [0,\infty)$, the symbol $\mathcal{M}_1^V(E)$ will denote the set of all $\mu\in\mathcal{M}_1(E)$ with finite first moment w.r.t. $V$, i.e., such that $\int_E V\,d\mu<\infty$. Moreover, for notational brevity, given $f\in B_b(E)$ and $\mu\in\mathcal{M}(E)$, we will sometimes write $\<f,\mu\>$ for the Lebesgue integral $\int_E f \,d\mu$.

Let us now recall several basic concepts from the theory of Markov processes, which we refer to throughout the paper.

A function $K: E\times\mathcal{B}(E)\to [0,\infty]$ is said to be a \emph{(transition) kernel} on $E$ whenever, for every $A\in\mathcal{B}(E)$, the map \hbox{$E\ni x \mapsto K(x,A)$} is Borel measurable, and, for every \hbox{$x\in E$},  $\mathcal{B}(E)\ni A \mapsto K(x,A)$ is a non-negative Borel measure. If, additionally, $\sup_{x\in E} K(x,E)<\infty$, then $K$ is said to be \emph{bounded}. In the case where $K(x,X)=1$ for every $x\in E$, $K$ is called a \emph{stochastic} kernel (or a \emph{Markov} kernel) and usually denoted by $P$ rather than $K$.

For any two kernels $K_1$ and $K_2$, we can consider their \emph{composition} $K_1K_2$ of the form
$$
K_1K_2(x,A):=\int_E K_2(y,A)K_1(x,dy)\quad\text{for}\quad x\in E,\; A\in\mathcal{B}(E).$$
The iterates of a kernel $K$ are defined as usual by
$$K^1:=K \quad\text{and}\quad K^{n+1}:=K K^n\quad\text{for every} \quad n\in\n.$$
Obviously, the composition of any two bounded kernels is again bounded.

Given a kernel $K$ on $E$, for any non-negative Borel measure $\mu$ on $E$ and any bounded below Borel measurable function $f:E\to\mathbb{R}$, we can consider the measure $\mu K$ and the function $Kf$ defined as
\begin{gather}
\label{e:mK} \mu K(A):=\int_E K(x,A)\mu(dx)\;\;\text{for}\;\;A\in\mathcal{B}(E),\\
\label{e:Kf} Kf(x):=\int_E f(y)\,K(x,dy)\;\;\text{for}\;\;x\in E,
\end{gather}
respectively. They are related to each other in such a way that $\<f, \mu K\>=\<Kf,\mu\>$. Obviously, if $K$ is bounded, then the operator $\mu \mapsto \mu K$ transforms $\mathcal{M}(E)$ into itself, whilst $f\mapsto Kf$ maps $B_b(E)$ into itself. In the case where $K$ is stochastic, the operator given by~\eqref{e:mK} also leaves the set $\mathcal{M}_1(X)$ invariant.

Let us stress here that the notation consistent with \eqref{e:mK} and \eqref{e:Kf} will be used for the suitable operators induced by all the kernels considered in paper, without further emphasis.

A kernel $K$ on $E$ is said to be \emph{Feller} if $Kf\in C_b(E)$ for every function $f\in C_b(E)$. Furthermore, a~non-negative Borel measure $\mu$ is called \emph{invariant} for a kernel~$K$ (or for the operator on measures induced by this kernel) whenever $\mu K=\mu$. These two concepts can also be used in reference to any family of transition kernels. The family of this kind is said to be Feller if all its members are Feller. A measure $\mu$ is called invariant for such a family if~$\mu$ is invariant for each of its members.

For a given $E$-valued time-homogeneous Markov chain $\Phi=\{\Phi_n\}_{n\in\n_0}$, defined on a probability space $(\Omega,\mathcal{F},\pr)$, a stochastic kernel $P$ on $E$ is called the \emph{transition law} of this chain~if
$$\pr(\Phi_{n+1}\in A\,|\,\Phi_n=x)=P(x,A)\quad\text{for all}\quad x\in E,\; A\in\mathcal{B}(E),\;n\in\n_0.$$
Letting $\mu_n$ denote the distribution of $\Phi_n$ for each $n\in\n_0$, we then have $\mu_{n+1}=\mu_n P$ for every \hbox{$n\in\n_0$}. The operator $(\cdot)P$ on $\mathcal{M}_1(E)$ is therefore referred as the \emph{transition operator} of~$\Phi$, and any invariant probability measure of $P$ is just a \emph{stationary distribution} of $\Phi$. Moreover, in fact, 
$\pr(\Phi_{n+k} \in A \,|\, \Phi_k=x)=P^n(x,A)$ for any $x\in E$, $A\in\mathcal{B}(E)$ and $k,n\in\n_0$, which implies that
$$\ew_x[f(\Phi_n)]=P^n f(x) \quad\text{for any}\quad x\in E,\; f\in B_b(E),\;n\in\n_0,$$
where $\ew_x$ stands for the expectation with respect to $\pr_x:=\pr(\cdot\,|\,\Phi_0=x)$.

On the other hand, it is well-known (see, e.g., \cite{b:revuz}) that for every stochastic kernel $P$ on~a separabe metric space $E$ there exists an $E$-valued Markov chain with transition law $P$. More precisely, putting $\Omega:=E^{\mathbb{N}_0}$, \hbox{$\mathcal{F}=\mathcal{B}(E^{\mathbb{N}_0})$} and, for each $n\in\n_0$, defining $\Phi_n:\Omega\to E$~as
\begin{equation}
\label{def:phi_n}
\Phi_n(\omega):=x_n\quad\text{for}\quad \omega=(x_0,x_1,\ldots)\in E,
\end{equation}
one can show that, for every $x\in E$, there exists a probability measure $\mathbb{P}_x$ on $\mathcal{F}$ such that, for any $n\in\n_0$, $A_0,\ldots,A_n\in\mathcal{B}(E)$ and $F:=\{\Phi_0\in A_0,\ldots,\Phi_n\in A_n\}$, we have
\begin{equation}
\label{e:canonical}
\mathbb{P}_x(F)=\mathbbm{1}_{A_0}(x)\int_{E}\int_E\ldots \int_{E}\mathbbm{1}_{A_1\times\ldots\times A_n}(x_1,\ldots,x_n)P(x_{n-1},dx_n)\ldots P(x_1,dx_2)P(x,dx_1).
\end{equation}
Then $\{\Phi_n\}_{n\in\n_0}$ specified by \eqref{def:phi_n} is a time-homogeneous Markov chain on $(\Omega,\mathcal{F},\pr_x)$ with initial state $x$ and transition law $P$. The Markov chain constructed in this way is called the \emph{canonical} one.

Finally, recall that a family $\{P_t\}_{t\in\mathbb{R}_+}$ of stochastic kernels on~$E$ (or the corresponding family of operators on $\mathcal{M}_1(X))$ is called a \emph{Markov transition semigroup} whenever $P_{s+t}=P_sP_t$ for all $s,t\geq 0$ and $P_0(x,\cdot)=\delta_x$ for every $x\in E$, where $\delta_x$ stands for the Dirac measure at~$x$. While using this term in the context of a time-homogeneous Markov process $\Psi=\{\Psi(t)\}_{t\geq 0}$, defined on some probability space $(\Omega,\mathcal{F},\pr)$, we will mean that
$$\pr(\Psi(s+t)\in A\,|\, \Psi(s)=x)=P_t(x,A) \quad\text{for all}\quad x\in E,\; A\in\mathcal{B}(E),\;s,t\geq 0.$$
Clearly, if $\mu_t$ denote the distribution of $\Psi(t)$ for every $t\geq 0$, then $\mu_{s+t}=\mu_s P_t$ for any $s,t\geq 0$, which, in particular, shows that any invariant probability measure of $\{P_t\}_{t\in\mathbb{R}_+}$ is, in fact, the stationary distribution of the process $\Psi$. Moreover, analogously as in the discrete case, we have
\begin{equation}
\label{e:efp}
\ew_x[f(\Psi(t))]=P_t f(x) \quad\text{for any}\quad x\in E,\; f\in B_b(E),\;t\geq 0,
\end{equation}
where $\ew_x$ stands for the expectation with respect to $\pr_x:=\pr(\cdot\,|\,\Psi(0)=x)$.
 
% (or, equivalently, in terms of Markov operators: $P_{s+t}=P_s\circ P_t$ for any $s,t\geq 0$ and $P_0=\operatorname{id}_{\mathcal{M}(E)}$)

\section{Definition of the model}\label{sec:def}
Let $(Y,\rho_Y)$ be a non-empty complete separable metric space, and let $I$ stand for an arbitrary non-empty finite set endowed with the discrete topology. Moreover, let us introduce
$$X:=Y\times I \quad \text{and} \quad \bar{X}:=X\times\mathbb{R}_+,$$ 
both equipped with the product topologies, upon assuming that $\mathbb{R}_+:=[0,\infty)$ is supplied with the Euclidean topology.

Consider a family $\{S_i:\,i\in I\}$ of jointly continuous semiflows acting from $\mathbb{R}_+\times Y$ to~$Y$. By calling $S_i$ a semiflow we mean, as usual, that
$$S_i(s,S_i(t,y))=S_i(s+t,y)\quad\text{and}\quad S_i(0,y)=y\quad\text{for any}\quad s,t\in\mathbb{R}_+,\;y\in Y.$$
Further, let $\{\pi_{ij}:\, i,j\in I\}$ be a collection of continuous maps from $Y$ to $[0,1]$ such that 
$$\sum_{j\in I} \pi_{ij}(y)=1\quad\text{for all}\quad i\in I,\; y\in Y.$$
Moreover, let $\lambda:Y\to (0,\infty)$ be a continuous function satisfying
\begin{equation}
\label{e:lambda_bounds}
\ulambda \leq \lambda(y) \leq \olambda \quad \text{for every}\quad y\in Y,
\end{equation}
with certain constants $\ulambda, \olambda>0$, and put
$$\Lambda(y,i,t):=\int_0^t \lambda(S_i(h,y))\,dh\quad \text{for}\quad y\in Y,\; i\in I,\; t\in\mathbb{R}_+.$$
Finally, suppose that we are given an arbitrary stochastic kernel $J: Y\times \mathcal{B}(Y)\to [0,1]$.

Let us now define a stochastic kernel $\bar{P}:\mathcal{B}(\bar{X})\times \bar{X}\to [0,1]$ by setting
\begin{equation}
\label{def:P_bar}
\bar{P}((y,i,s), \bar{A})= \int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)} \int_Y \sum_{j\in I} \pi_{ij}(u)\mathbbm{1}_{\bar{A}}(u,j,s+t)\,J(S_i(t,y),du)\,dt
\end{equation}
for any $y\in Y$, $i\in I$, $s\in\mathbb{R}_+$ and $\bar{A}\in\mathcal{B}(\bar{X})$. Furthermore, let $P:X\times\mathcal{B}(X)\to [0,1]$ be given by
\begin{equation}
\label{def:P}
P((y,i),A):=P((y,i,0),A\times\mathbb{R}_+)\quad\text{for}\quad y\in Y,\;i\in I,\; A\in\mathcal{B}(X).
\end{equation}

\begin{remark}\label{rem:feller}
Taking into account the continuity of the maps $X\ni (y,i) \mapsto S_i(t,y)$ for $t\geq 0$, $(y,i)\mapsto \pi_{ij}(y)$ for $j\in I$ and $(y,i)\mapsto \lambda(y)$, it is easy to see that $P$ is Feller whenever so is the kernel $J$.
\end{remark}

By $\bar{\Phi}:=\{(Y_n,\xi_n,\tau_n)\}_{n\in\n_0}$ we will denote a time-homogeneous Markov chain with state space $\bar{X}$ and transition law~$\bar{P}$, wherein $Y_n$, $\xi_n$, $\tau_n$ take values in $Y$, $I$, $\mathbb{R}_+$, respectively. For simplicity of analysis, we shall regard $\bar{\Phi}$ as the canonical Markov chain (starting from some point of $\bar{X}$), constructed on the coordinate space $\Omega:=\bar{X}^{\n_0}$, equipped with the $\sigma$-field $\mathcal{F}:=\mathcal{B}\left(\bar{X}^{\n_0}\right)$ and a suitable probability measure $\pr$ on $\mathcal{F}$. Obviously $\Phi:=\{(Y_n,\xi_n)\}_{n\in \n_0}$ is then a Markov chain with respect to its own natural filtration, governed by transition law~$P$, given by \eqref{def:P}. Moreover, for every~$n\in\n_0$, we have
\begin{gather}
\nonumber
\pr(Y_{n+1}\in B\,\,|\,\Phi_n;\;S_{\xi_n}( \Delta\tau_{n+1},Y_n)=y)=J(y,B)\quad\text{for}\quad y\in Y,\; B\in\mathcal{B}(Y),\\
\nonumber
\pr(\xi_{n+1}=j\,\,|\,Y_n;\;\xi_n=i, \,Y_{n+1}=y)=\pi_{ij}(y)\quad\text{for}\quad y\in Y,\;i,j\in I,
\end{gather}
where $\Delta \tau_{n+1}:=\tau_{n+1}-\tau_n$, and
\begin{equation}
\label{e:dist_tau}
\pr(\tau_{n+1}\leq t\,|\,\bar{\Phi}_n=(y,i,s))=\mathbbm{1}_{[s,\infty)}(t) \left(1-e^{-\Lambda(y,i,t-s)}\right)\quad \text{for}\quad t\in\mathbb{R}_+,\; (y,i,s)\in\bar{X}.
\end{equation}


In particular, \eqref{e:dist_tau} implies that the conditional distributions of $\Delta \tau_{n+1}$  given~$\bar{\Phi}_n$ are of the form
$$\pr(\Delta\tau_{n+1}\leq t\,|\,\bar{\Phi}_n=(y,i,s))=1-e^{-\Lambda(y,i,t)}\quad\text{for}\quad t\in\mathbb{R}_+,\; (y,i,s)\in\bar{X}.$$
This yields that $\Delta \tau_n>0$  almost surely (a.s.) for all $n\in\n$ (i.e., $\{\tau_n\}_{n\in\n_0}$ is a.s. strictly increasing), and,  together with the Markov property of $\bar{\Phi}$, shows that $\Delta\tau_1,\Delta \tau_2,\ldots$ are mutually independent. Further, it follows that, for any $n,r\in\n$,
\begin{align*}
\ew[(\Delta\tau_{n})^r]&=\ew\left[\ew[(\Delta\tau_{n})^r\,|\,\bar{\Phi}_{n-1}]\right]=\int_0^{\infty} t^r \ew\left[\lambda(S_{\xi_{n-1}}(t,\xi_{n-1}))e^{-\Lambda(t,Y_{n-1},\xi_{n-1})}\right]dt,
\end{align*}
whence, in view of \eqref{e:lambda_bounds}, we get
$$
\ulambda \olambda^{-(r+1)}r!\leq  \ew[(\Delta\tau_{n})^r]\leq\olambda \ulambda^{-(r+1)}r!.$$
Consequently, Kolmogorov's criterion guarantees that $(\Delta\tau_n-\ew\Delta\tau_n)_{n\in\n}$ obeys the strong law of large numbers. Hence, writing

$$\tau_n-\tau_0=n\left(\frac{\sum_{k=1}^n (\Delta\tau_k-\ew\Delta\tau_k)}{n}+\frac{\sum_{k=1}^n\ew\Delta\tau_k}{n}\right)\geq n\left(\frac{\sum_{k=1}^n (\Delta\tau_k-\ew\Delta\tau_k)}{n}+\ulambda \olambda^{-2}\right)$$
for $n\in\n$, we can conclude that 
\begin{equation}
\label{e:tau_inf}
\tau_n \uparrow \infty\;\;\;\pr\text{\;-\;a.s.}.
\end{equation}

The main focus of our study will be the PDMP $\Psi:=\{\Psi(t)\}_{t\in\mathbb{R}_+}$ of the form $$\Psi(t):=(Y(t),\xi(t))\quad\text{for}\quad t\in\mathbb{R}_+,$$ 
defined via interpolation of $\Phi$ according to formula \eqref{def:pdmp}. Obviously this definition is well-posed due to \eqref{e:tau_inf}, and the chain $\Phi$ describes the post-jump locations of the process~$\Psi$, that~is,
$$\Phi_n=(Y_n,\xi_n)=(Y(\tau_n),\xi(\tau_n))=\Psi(\tau_n) \quad\text{for every} \quad n\in\n_0.$$ 
In what follows, the Markov transition semigroup of $\Psi$ will be denoted by $\{P_t\}_{t\geq 0}$.

\section{Assumptions}\label{sec:assumptions}
Basically, the only assumption that we shall make in our main result (i.e., in Theorem \ref{thm:main}) is a~strengthened form of the Feller property of $J$, which reads as follows:
\begin{enumerate}[label=\textnormal{(F)}, leftmargin=*]
\item\label{cnd:f} For every function $g\in C_b(Y\times\mathbb{R}_+)$, the map $Y\times\mathbb{R}_+\ni(y,t)\mapsto J g(\cdot,t)(y)$ is jointly continuous.
\end{enumerate}

%regarding the correspondence between invariant measures of the operator $P$ and those of the semigroup $\{P_t\}_{t\in\mathbb{R}_+}$,


Nevertheless, when applying the main theorem to a particular case discussed in \hbox{Section}~\ref{sec:application}, we will also require, amog others, certain conditions referring to $S_i$, $\pi_{ij}$ and $\lambda$, similar to those employed in~\cite{b:czapla_kubieniec} (cf. also \cite{b:czapla_exp_erg}), namely:

\begin{enumerate}[label=\textnormal{(C\arabic*)}, leftmargin=*]
\item\label{cnd:a1}For some $y_*\in Y$, we have
\begin{equation}
\label{e:gv}
\beta(y_*):=\max_{i\in I}\int_0^{\infty} e^{-\ulambda t} \rho_Y(S_i(t,y_*),y_*)\,dt<\infty;
\end{equation}

\item\label{cnd:a2}There exist $L>0$ and $\alpha\in\mathbb{R}$ such that
$$\rho_Y(S_i(t,u), S_i(t,v))\leq Le^{\alpha t}\rho_Y(u,v)\;\;\;\mbox{for}\;\;\;u,v\in Y,\;i\in I,\;t\geq 0;$$ 

\item\label{cnd:a3}There exist a Lebesgue measurable function $\varphi:\mathbb{R}_+\to\mathbb{R}_+$ satisfying 
$$\int_0^{\infty}e^{-\underline{\lambda} t} \varphi(t)\,dt<\infty$$ and a function $\mathcal{L}:Y\to\mathbb{R}_+$, bounded on bounded sets, such that
$$\rho_Y(S_i(t,y),S_j(t,y))\leq \varphi(t)\mathcal{L}(y)\quad\text{for any}\quad t\geq 0,\;y\in Y,\;i,j\in I;$$

\item \label{cnd:a4} There exists $L_{\pi}>0$ such that

$$\sum_{j\in I}|\pi_{ij}(u)-\pi_{ij}(v)|\leq L_{\pi}\rho_Y(u,v) \quad \text{for any} \quad u,v \in Y,\; i\in I;$$

\item \label{cnd:a5} There exists $\delta_{\pi}>0$ such that
$$\sum_{j\in I}\min\{\pi_{ij}(u),  \pi_{kj}(v)  \}\geq \delta_{\pi} \quad \text{for any} \quad u,v \in Y,\; i,k\in I;$$

\item \label{cnd:a6} There exists $L_{\lambda}>0$ such that
$$|\lambda(u)-\lambda(v)|\leq L_{\lambda}\rho_Y(u,v)\quad\text{for any}\quad u,v\in Y;$$
\end{enumerate}


\begin{remark}
Note that, if \ref{cnd:a1} holds and \ref{cnd:a2} is satisfied with $\alpha<\ulambda$ , then \eqref{e:gv} is valid for every $y_*\in Y$.
\end{remark}

\begin{lemma}\label{lem:lapunov_P}
Suppose that \ref{cnd:a1} and \ref{cnd:a2} hold with $\alpha<\ulambda$. Further, let \hbox{$\widetilde{V}:=\rho_Y(\cdot,y_*)$} and assume that there exist constants $\tilde{a},\tilde{b}\geq 0$ such that
\begin{equation}
\label{e:lapunov_J}
J\widetilde{V}(y)\leq \tilde{a} \widetilde{V}(y)+\tilde{b}\quad\text{for all}\quad y\in Y.
\end{equation}
Then, letting 
\begin{equation}
\label{def:V}
V(x):=\rho_Y(y,y^*)\quad\text{for}\quad x=(y,i)\in X,
\end{equation}
$$a:=\frac{\olambda \tilde{a} L}{\ulambda-\alpha} \quad \text{and} \quad b:=\olambda\left(\tilde{a} \beta(y_*)+ \tilde{b}\ulambda^{-1}\right)$$
we have
\begin{equation}
\label{e:lapunov_V}
PV(x)\leq a V(x)+b\quad\text{for all}\quad x\in X.
\end{equation}
\end{lemma}
\begin{proof}
Let $x=(y,i)\in X$. Using \eqref{e:lapunov_J} and \ref{cnd:a2} we obtain
\begin{align*}
J\widetilde{V}(S_i(t,y))&\leq \tilde{a} \rho_Y(S_i(t,y),y_*)+\tilde{b}\\
& \leq \tilde{a} \left(\rho_Y(S_i(t,y),S_i(t,y_*))+\rho_Y(S_i(t,y_*),y_*) \right)+\tilde{b}\\
&\leq \tilde{a} Le^{\alpha t} \rho_Y(y,y_*)+\tilde{a}\rho_Y(S_i(t,y_*),y_*)+\tilde{b}\quad\text{for any}\quad t\in\mathbb{R}_+.
\end{align*}
Hence, by \ref{cnd:a2} we finally get
\begin{align*}
PV(x)&=\int_0^{\infty} \lambda(S_i(t,y))e^{-\Lambda(y,i,t)} J\widetilde{V}(S_i(t,y))\,dt\\
&\leq \olambda \int_0^{\infty} e^{-\ulambda t}\left(\tilde{a} Le^{\alpha t} \rho_Y(y,y_*)+\tilde{a}\rho_Y(S_i(t,y_*),y_*)+\tilde{b} \right)\,dt\\
&=\olambda\tilde{a}L\left(\int_0^{\infty} e^{-(\ulambda-\alpha)t}\,dt\right)V(x)+\olambda\left(\tilde{a}\int_0^{\infty} e^{-\ulambda t}\rho_Y(S_i(t,y_*),y_*)\,dt+ \tilde{b}\ulambda^{-1} \right)\\
&\leq \frac{\olambda \tilde{a} L}{\ulambda-\alpha} V(x)+\olambda\left(\tilde{a}\beta(y_*)+\tilde{b}\ulambda^{-1} \right).
\end{align*}


\end{proof}



\section{Main results}\label{sec:main}
In this part of the paper we formulate our main results. In Section \ref{sec:main1}, we establish a~\hbox{one-to-one} correspondence between invariant probability measures of the transition semigroup $\{P_t\}_{t\in\mathbb{R}_+}$ of the process $\Psi$, determined by \eqref{def:pdmp}, and those of the transition operator~$P$ of the chain $\Phi$, given by \eqref{def:P}. Further, in Section \ref{sec:application}, we apply this result to a particular case, where $J$ is the transition law of some random iterated function system.

\subsection{Correspondence between invariant measures of the continuous and discrete time models}\label{sec:main1}
Let us consider two stochastic kernels $G,W:X\times\mathcal{B}(X)\to [0,1]$ given by
\begin{gather}
\label{def:G}
G(x,A):=\int_0^{\infty} \lambda(S_i(t,y))e^{-\Lambda(y,i,t)}\mathbbm{1}_A(S_i(t,y),i)dt,\\
\label{def:W}
W(x,A):=\sum_{j\in I} \int_Y \pi_{ij}(u)\mathbbm{1}_A(u,j)\,J(y,du)
\end{gather}
for all $x=(y,i)\in X$ and $A\in\mathcal{B}(X)$, where $J$ stands for the kernel involved in \eqref{def:P_bar}. Further, put
\begin{equation}
\label{def:hlambda}
\hlambda(y,i):=\lambda(y)\quad \text{for any}\quad y\in Y,\;i\in I,
\end{equation}
and define two (generally non-stochastic) kernels $\tG,\tW:X\times\mathcal{B}(X)\to [0,\infty)$ of the form
$$\tG(x,A):=G\left(\mathbbm{1}_A/\hlambda\right)\hspace{-0.1cm}(x)\quad\text{and}\quad \tW(x,A):=\hlambda(x)\,W\mathbbm{1}_A(x) \quad\text{for all}\quad x\in X,\;A\in \mathcal{B}(X).$$

\begin{remark}\label{rem:gw}
It is easily seen that $GW=\tG\tW=P$, where $P$ is the kernel given by \eqref{def:P}.
\end{remark}



\begin{remark} According to \eqref{e:lambda_bounds}, for any $x\in X$ and $A\in\mathcal{B}(X)$, we have
$$\olambda^{-1}  \leq  \tG (x,A)\leq \ulambda^{-1}\quad \text{and}\quad  \ulambda \leq  \tW (x,A)\leq \olambda.$$
Consequently, the kernels $\tG$ and $\tW$ are bounded, and thus the sets $\mathcal{M}(X)$ and $B_b(X)$ are invariant under the operators induced by these kernels according to \eqref{e:mK} and \eqref{e:Kf}, respectively. Moreover, note that, if $\mu\in\mathcal{M}(X)$ is a non-trivial measure, then the measures $\mu \tG$ and $\mu \tW$ are non-trivial as well.
\end{remark}

\begin{remark}\label{rem:feller_gw} The kernels $G$ and $\widetilde{G}$ are Feller. Moreover, if the kernel $J$ is Feller then so are the kernels $W$ and~$\widetilde{W}$.
\end{remark}



%It is easily seen, that for every $f\in B_b(X)$, we have $(GW)f=(\tG\tW)f=Pf$, where $P$ is the operator induced by kernel \eqref{def:P}.

Having defined $\tG$ and $\tW$, we can state our main result:
\begin{theorem} \label{thm:main}
Suppose that the kernel $J$ satisfies condition~\ref{cnd:f}.
\begin{enumerate}[label=\textnormal{(\alph*)}, leftmargin=*]
\item\label{cnd:a}If $\mu_*^{\Phi}\in\mathcal{M}_1(X)$ is invariant for $P$, then 
\begin{equation}
\label{e:m_psi}
\mu_*^{\Psi}:=\frac{\mu_*^{\Phi}\tG}{\mu_*^{\Phi}\tG(X)}
\end{equation}
is an invariant probability measure of $\{P_t\}_{t\in\mathbb{R}_+}$, and 
\begin{equation}
\label{e:m_phi}
\mu_*^{\Phi}=\frac{ \mu_*^{\Psi} \tW}{\mu_*^{\Psi}\tW(X)}.
\end{equation}
\item\label{cnd:b} If $\mu_*^{\Psi}\in\mathcal{M}_1(X)$ is invariant for $\{P_t\}_{t\in\mathbb{R}_+}$, then $\mu_*^{\Phi}$ defined by \eqref{e:m_phi} is an invariant probability measure of $P$, and $\mu_*^{\Psi}$ can be then expressed as in \eqref{e:m_psi}.
\end{enumerate}
\end{theorem}
\begin{proof}
The proof of the theorem, together with all needed auxiliary results, is given in Section~\ref{sec:proof}.
\end{proof}

\begin{corollary}\label{cor:main}
Suppose that condition \ref{cnd:f} holds. Then $\{P_t\}_{t\in\mathbb{R}_+}$ admits a unique invariant probability measure if and only if so does $P$.
\end{corollary}

Let us finish this section with a simple observation on preserving the property of having finite first moments by the measures featured in Theorem \ref{thm:main}.

\begin{proposition}\label{prob:m1v}
Let $V$ be the function given by \eqref{def:V}. Then, the following holds:
\begin{itemize}
\item[(i)] If $\mu_*^{\Phi}\in\mathcal{M}_1^V(X)$, then  $\mu_*^{\Psi}$ defined by \eqref{e:m_psi} also belongs to $\mathcal{M}_1^V(X)$, provided that conditions \ref{cnd:a1} and \ref{cnd:a2} hold with some $\alpha<\ulambda$.
\item[(ii)] If $\mu_*^{\Psi}\in\mathcal{M}_1^V(X)$, then $\mu_*^{\Phi}$ defined by \eqref{e:m_phi} also belongs to  $\mathcal{M}_1^V(X)$, whenever \eqref{e:lapunov_J} is fulfilled with $\widetilde{V}=\rho_Y(\cdot,y_*)$ and certain $\tilde{a},\tilde{b}\geq 0$.
\end{itemize}
\end{proposition}
\begin{proof}
To see (i) it suffices to observe that, for every $(y,i)\in X$,
\begin{align*}
\tG V(y,i)&=\int_0^{\infty} e^{-\Lambda(y,i,t)} \rho_Y(S_i(t,y),y_*)\,dt \\
&\leq \int_0^{\infty} e^{-\ulambda t} \rho_Y(S_i(t,y),S_i(t,y_*))\,dt+\int_0^{\infty} e^{-\ulambda t} \rho_Y(S_i(t,y_*),y_*)\,dt\\
&\leq L\left(\int_0^{\infty}e^{-(\ulambda-\alpha)t}\,dt \right) \rho_Y(y,y_*) + \beta(y_*)=\frac{L}{\ulambda-\alpha} V(y,i)+\beta(y_*).
\end{align*}
Statement (ii) follows from the fact that, for any $(y,i)\in X$,
\begin{align*}
\tW V (y,i)& = \lambda(y,i)\sum_{j\in I} \int_Y \pi_{ij}(u) \widetilde{V}(u) J(y,du) =  \lambda(y,i) JV(y)\\
&\leq \olambda (\tilde{a} \widetilde{V}(y) +\tilde{b})=\olambda\tilde{a}V(y,i) +\olambda \tilde{b}.
\end{align*}

\end{proof}

\subsection{Application to a particular subclass of PDMPs}\label{sec:application}
As mentioned earlier, in this section we shall use Theorem \ref{thm:main} (and \cite[Theorem 4.1]{b:czapla_kubieniec}) to provide a set of conditions guaranteeing the existence and uniqueness of the stationary distribution for some particular PDMP, where $J$ is the transition law of a random iterated function system with an arbitrary family of transformations and state-dependent probabilities of selecting them.

Let $\Theta$ be a topological space, and suppose that $\vartheta$ is a non-negative Borel measure on~$\Theta$. Further, consider an arbitrary set \hbox{$\{w_{\theta}:\,\theta\in \Theta\}$} of continuous transformations from $Y$ to itself and an associated collection $\{p_{\theta}:\, \theta\in\Theta\}$ of continuous maps from $Y$ to $\mathbb{R}_+$ such that, for every $y\in Y$, $\theta\mapsto p_{\theta}(y)$ is a probability density function with respect to $\vartheta$. Moreover, assume that $(y,\theta)\mapsto w_{\theta}(y)$ and $(y,\theta)\mapsto p_{\theta}(y)$ are product measurable.  Given this framework, we are concerned with the kernel $J$ defined by \eqref{e:ifs}.

The transition law $P$, specified by \eqref{def:P}, can be then expressed exactly as in \cite{b:czapla_kubieniec}, i.e.,
\begin{align}
\begin{split}
\label{def:P_ifs}
P((y,i), A)&= \int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)} \int_{\Theta} p_{\theta}(S_i(t,y))\\
&\quad \times \sum_{j\in I}\ \pi_{ij}(w_{\theta}(S_i(t,y)))\mathbbm{1}_A(w_{\theta}(S_i(t,y)),j)\,\vartheta(d\theta)\,dt
\end{split}
\end{align}
for any $y\in Y$, $i\in I$ and $A\in\mathcal{B}(X)$. Moreover, note that, in this case, the first coordinate of $\Phi$ can be determined by the recursive formula:
$$Y_{n+1}=w_{\eta_{n+1}}(Y(\tau_{n+1}-))=w_{\eta_{n+1}}(S_{\xi_n}(\Delta\tau_{n+1},Y_n))\;\;\text{a.s.}\quad \text{for}\quad n\in\n_0,$$
where $\{\eta_n\}_{n\in\n}$ is a sequence of random variables with values in $\Theta$, such that
\begin{equation}
\label{e:p}
\pr(\eta_{n+1}\in D\,|\,S_{\xi_n}(\Delta\tau_{n+1},Y_n)=y)=\int_D p_{\theta}(y)\vartheta(d\theta)\;\;\text{for}\;\; D\in\mathcal{B}(\Theta),\;y\in Y,\;n\in\n_0.
\end{equation}

Let us now employ the following assumptions:

\begin{enumerate}[label=\textnormal{(W\arabic*)}, leftmargin=*]
\item\label{cnd:w1}For some $y_*\in Y$, we have
$$\gamma(y_*):=\sup_{y\in Y}\int_{\Theta} \rho_Y(w_{\theta}(y_*),y_*)p_{\theta}(y)\,\vartheta(d\theta)<\infty;$$
\item \label{cnd:w2} There exists $L_w>0$ such that 
$$\int_{\Theta} \rho_Y(w_{\theta}(u),w_{\theta}(v))\,p_{\theta}(u)\vartheta(d\theta)\leq L_w\rho_Y(u,v)\quad \text{for any}\quad u,v\in Y;$$

\item \label{cnd:w3} There exists $L_p>0$ such that 
$$\int_{\Theta} |p_{\theta}(u)-p_{\theta}(v)|\,\vartheta(d\theta)\leq L_p\rho_Y(u,v)\quad\text{for any}\quad u,v\in Y;$$

\item \label{cnd:w4} There exists $\delta_{p}>0$ such that 
$$\int_{\Theta(u,v)} \min\{p_{\theta}(u)\wedge p_{\theta}(v)\}\,\vartheta(d\theta)\geq \delta_p\quad\text{for any}\quad u,v\in Y,$$
where
$$
\Theta(u,v):=\{\theta\in \Theta:\,\rho_Y(w_{\theta}(u),w_{\theta}(v))\leq L_w\rho_Y(u,v)\}.
$$
\end{enumerate}

It is worth stressing here that conditions similar in form to \ref{cnd:w1}-\ref{cnd:w4} are commonly \hbox{utilized} when examining the existence of invariant measures and stability properties of random iterated function systems. See, e.g., \cite[Proposition 3.1]{b:kapica} or \hbox{\cite[Theorem 3.1]{b:szarek}}.

\begin{lemma}\label{lem:lapunov_J}
Suppose that conditions \ref{cnd:w1} and \ref{cnd:w2} hold. Then the operator $J(\cdot)$~on~$B_b(X)$ induced by \eqref{e:ifs} satisfies \eqref{e:lapunov_J} with $\widetilde{V}:=\rho_Y(\cdot,y_*)$, $\tilde{a}:=L_w$ and $\tilde{b}:=\gamma(y_*)$.
\end{lemma}
\begin{proof}
For every $y\in Y$ we have
\begin{align*}
J\widetilde{V}(y)&=\int_{\Theta} \rho_Y(w_{\theta}(y),y_*)p_{\theta}(y)\vartheta(d\theta)\\
&\leq \int_{\Theta} \rho_Y(w_{\theta}(y),w_{\theta}(y_*))p_{\theta}(y)\vartheta(d\theta)+ \int_{\Theta} \rho_Y(w_{\theta}(y_*),y_*)p_{\theta}(y)\vartheta(d\theta)\\
&\leq L_w\rho_Y(y,y_*)+\gamma(y_*)=L_w\widetilde{V}(y)+\gamma(y_*).
\end{align*}
\end{proof}

\begin{lemma}\label{lem:f}
If condition \ref{cnd:w3} holds, then $J$ defined by \eqref{e:ifs} enjoys property \ref{cnd:f}. 
\end{lemma}
\begin{proof}
Let $g\in C_b(Y\times\mathbb{R}_+)$ and fix \hbox{$(y_0,t_0)\in Y\times\mathbb{R}_+$}. Then, for any $y\in Y$ and $t\geq 0$, we can write
\begin{align*}
|Jg(\cdot,t_0)(y_0) - Jg(\cdot,t)(y)|&\leq\int_{\Theta}|g(w_{\theta}(y_0),t_0)p_{\theta}(y_0)-g(w_{\theta}(y),t)p_{\theta}(y)|\,\vartheta(d\theta)\\
&\leq\int_{\Theta}|g(w_{\theta}(y_0),t_0)-g(w_{\theta}(y),t)|p_{\theta}(y_0)\,\vartheta(d\theta)\\
&\quad+ \int_{\Theta} |g(w_{\theta}(y),t)|\cdot|p_{\theta}(y_0)-p_{\theta}(y)|\,\vartheta(d\theta).
\end{align*}
It now suffices to observe that both terms on the right-hand side of this estimation tend to~$0$ as $(t,y)\to (t_0,y_0)$. The convergence of the first term follows from the Lebesgue dominated convergence theorem, since $w_{\theta}$ and $g$ are continuous (and the latter is also bounded). The second one converges by condition \ref{cnd:w3} and boundedness of $g$, which allow estimating it from above by $\norma{g}_{\infty}L_p\rho_Y(y_0,y)$.
\end{proof}


\begin{theorem}\label{thm:app}
Let $J$ be of the form \eqref{e:ifs}. Further, suppose that conditions \ref{cnd:a1}-\ref{cnd:a6}, \hbox{\ref{cnd:w1}-\ref{cnd:w4}} hold, and that the~constants $\alpha, L$ and $L_w$ can be chosen so that
\begin{equation}
\label{e:balance}
LL_w\olambda+\alpha<\ulambda.
\end{equation}
Then the transition semigroup $\{P_t\}_{t\in\mathbb{R}_+}$ of the process $\Psi$ (determined by \eqref{def:pdmp}) has a unique invariant probability measure, which belongs to $\mathcal{M}_1^V(X)$ with $V$ given by \eqref{def:V}.

\begin{proof}
First of all, one can show that the transition operator $P$ of the chain $\Phi$ possesses a~unique invariant probability  measure $\mu_*^{\Phi}$, which is a member of $\mathcal{M}_1^V(X)$, by verifying conditions of \cite[Thoerem 2.1]{b:kapica}. This proceeds almost identically as in the proof of \hbox{\cite[Theorem 4.1]{b:czapla_kubieniec}}, except for Step~1. 

%This can be done almost identically as in the proof of \hbox{\cite[Theorem 4.1]{b:czapla_kubieniec}}, except for Step 1.

The goal of Step 1 in \cite{b:czapla_kubieniec} is to prove that $P$ enjoys \eqref{e:lapunov_V} with certain $a\in (0,1)$ and $b\geq 0$, which is accomplished there by using, among others, condition (A1). Here this condition is substituted with \ref{cnd:a1} and \ref{cnd:w1}, which do not imply (A1) in general. Nevertheless, we may apply Lemmas \ref{lem:lapunov_J} and \ref{lem:lapunov_P}, which together with inequality \eqref{e:balance}, yield that $P$ indeed satisfies \eqref{e:lapunov_V} with
$$a=\frac{\olambda L_w L}{\ulambda-\alpha}\in (0,1)\quad\text{and}\quad b=\olambda\left(\tilde{a} \beta(y_*)+ \gamma(y_*)\ulambda^{-1}\right)\geq 0.$$
Moreover, it should be emphasised, that although the proof of \hbox{\cite[Theorem 4.1]{b:czapla_kubieniec}} has been conducted upon assuming \ref{cnd:a3} with $\varphi(t)=t$, a simple analysis shows that it remains the same (with the obvious changes) if $\varphi:\mathbb{R}_+\to\mathbb{R}_+$ is an arbitrary Lebesgue measurable function satisfying $\int_0^{\infty}e^{-\underline{\lambda} t} \varphi(t)\,dt<\infty$.

Having established the existence and uniqueness of the $P$-invariant measure and keeping in mind that, according to Lemma \ref{lem:f}, the kernel $J$ enjoys property \ref{cnd:f}, we can conclude from Theorem~\ref{thm:main} (cf. also Corollary \ref{cor:main}) that  $\mu_*^{\Psi}$ given by \eqref{e:m_psi} is a unique invariant probability measure of the semigroup $\{P_t\}_{t\in\mathbb{R}_+}$. Finally, from Proposition \ref{prob:m1v}(i) it follows that $\mu_*^{\Psi}\in\mathcal{M}_1^V(X),$ which ends the proof.
\end{proof}
\end{theorem}


\section{Proof of Theorem \ref{thm:main}}\label{sec:proof}
The remainder of the paper is devoted to proving Theorem \ref{thm:main}. In the first part of this section, we establish certain properties of the Markov semigroup under consideration. They will be used in the second one to prove two lemmas on weak generators, which are crucial in the core of the proof, presented in the last part.

\subsection{Some technical results}\label{sec:technical}
Let us begin this section with defining
\begin{equation}
\label{def:eta}
\eta(t):=\max\{n\in\n_0:\, \tau_n\leq t\}\quad\text{for}\quad t\in\mathbb{R}_+.
\end{equation}
Obviously, $\{\eta(t)=n\}=\{\tau_n\leq t <\tau_{n+1}\}$ for any $t\in\mathbb{R}_+$ and $n\in\n_0$. 


Although \eqref{def:eta} is generally not a Poisson process, \eqref{e:lambda_bounds} suggests that the probability of~$\{\eta(t)=n\}$ can be estimated (from above) by a value close to the corresponding probability in such a process. This estimation is demonstrated in Lemma \ref{lem:tech2}, which relies on the following observation:

\begin{lemma}\label{lem:tech1}
For any $x\in X$, $t\in\mathbb{R}_+$ and $n\in\n_0$,
\begin{equation}
\label{as_ind}
\ew_{(x,0)}\left[e^{\ulambda \tau_n}\mathbbm{1}_{\{\tau_n\leq t\}} \right]\leq \frac{(\olambda t)^n}{n!}.
\end{equation}
\end{lemma}
\begin{proof}
The inequality is obvious for $n=0$. 

According to \eqref{e:dist_tau}, for every $n\in\n$ and each $(y,i,s)\in\bar{X}$, the conditional probability density function of $\tau_n$ given $\bar{\Phi}_{n-1}=(y,i,s)$ is of the form
$$f_{\tau_n|\bar{\Phi}_{n-1}}(t\,|\,(y,i,s))=\lambda(S_i(t-s,y)) e^{-\Lambda(y,i,t-s)}\mathbbm{1}_{[s,\infty)}(t)\quad\text{for}\quad t\in\mathbb{R}_+.$$

Let $x=(y,i)\in X$ and put $\bar{x}:=(x,0)\in\bar{X}$. We shall proceed by induction. Taking into account \eqref{e:lambda_bounds}, for $n=1$ we have

\begin{align}
\begin{split}
\label{base_step}
\ew_{\bar{x}}\left[e^{\ulambda \tau_1}\mathbbm{1}_{\{\tau_1\leq T\}} \right]&=\int_0^T e^{\ulambda t} f_{\tau_1|\bar{\Phi}_{0}}(t|\bar{x})\,dt\leq  \int_0^T e^{\ulambda t}\,\olambda e^{-\ulambda t}\,dt=\olambda T \quad\text{for any}\quad T\in\mathbb{R}_+.
\end{split}
\end{align}
Now, suppose inductively that \eqref{as_ind} holds for some arbitrarily fixed $n\in\n$ and all $t\in\mathbb{R}_+$. Then, for every $T\in\mathbb{R}_+$, we can write
\begin{align*}
\ew_{\bar{x}}\left[e^{\ulambda \tau_{n+1}}\mathbbm{1}_{\{\tau_{n+1}\leq T\}}\,|\,\bar{\Phi}_n \right]&=\int_0^T e^{\ulambda t} f_{\tau_{n+1}|\bar{\Phi}_{n}}(t|\bar{\Phi}_n)\,dt\leq \int_0^T e^{\ulambda t}\, \olambda e^{-\ulambda(t-\tau_n)}\mathbbm{1}_{[\tau_n,\infty)}(t)\,dt\\
&=\olambda\int_0^T e^{\ulambda\tau_n}\mathbbm{1}_{\{\tau_n\leq t\}}\,dt.
\end{align*}
Taking the expectation of both sides of this inequality and, further, using the inductive hypothesis gives

\begin{align*}
\ew_{\bar{x}}\left[e^{\ulambda \tau_{n+1}}\mathbbm{1}_{\{\tau_{n+1}\leq T\}}\right]
&\leq \olambda\int_0^T \ew_{\bar{x}}\left[e^{\ulambda\tau_n}\mathbbm{1}_{\{\tau_n\leq t\}}\right] dt 
\leq \olambda\int_0^T \frac{(\olambda t)^n}{n!}
\,dt \\
&= \frac{\olambda^{n+1}}{n!} \int_0^T t^n\,dt=\frac{(\olambda T)^{n+1}}{(n+1)!},
\end{align*}
which ends the proof.
\end{proof}


\begin{lemma}\label{lem:tech2}
For any $x\in X$, $t\in\mathbb{R}_+$ and $n\in\n_0$,
$$\pr_{(x,0)}(\eta(t)=n)\leq e^{-\ulambda t} \frac{(\olambda t)^n}{n!}.$$
\end{lemma}
\begin{proof}
Let $x\in X$, $\bar{x}:=(x,0)$, $t\in\mathbb{R}_+$, $n\in\n_0$, and observe that
$$\pr_{\bar{x}}(\eta(t)=n)=\pr_{\bar{x}}(\tau_n\leq t <\tau_{n+1})=\ew_{\bar{x}}\left[ \mathbbm{1}_{\{\tau_n\leq t\}}\pr_{\bar{x}}(\tau_{n+1}>t\,|\, \bar{\Phi}_n)\right].$$
From \eqref{e:dist_tau} and \eqref{e:lambda_bounds} it follows that
$$\pr_{\bar{x}}(\tau_{n+1}>t\,|\,\bar{\Phi}_n)= e^{-\Lambda(Y_n,\,\xi_n,\,t-\tau_n)}\leq e^{-\ulambda(t-\tau_n)} \quad \text{on}\quad \{\tau_n\leq t\}.$$
Having this in mind and applying Lemma \ref{lem:tech1} we therefore get
$$\pr_{\bar{x}}(\eta(t)=n)\leq \ew_{\bar{x}}\left[\mathbbm{1}_{\{\tau_n\leq t\}} e^{-\ulambda(t-\tau_n)}\right]=e^{-\ulambda t}\, \ew_{\bar{x}} \left[ \mathbbm{1}_{\{\tau_n\leq t\}} e^{\ulambda\tau_n}\right]\leq e^{-\ulambda t}\frac{(\olambda t)^n}{n!},$$
which is the desired claim.
\end{proof}

The following result gathers certain properties of ${\{P_t\}}_{t\in\mathbb{R}+}$ that will be needed in the proof of forthcoming Lemma \ref{lem:main2}. Simultaneously, it extends the scope of \cite[Lemma 5.1]{b:czapla_erg}, which was previously established only for constant $\lambda$ and $\pi_{ij}$.

\begin{lemma}\label{lem:Pt_prop}
The following statements hold for the transition semigroup $\{P_t\}_{t\in\mathbb{R}_+}$ of the process~$\Psi$, specified by \eqref{def:pdmp}:
\begin{enumerate}[label=(\roman*), leftmargin=*, widest=iii]
\item\label{lem:i} If $J$ is Feller, then $\{P_t\}_{t\in\mathbb{R}_+}$ is Feller too.
\item\label{lem:ii} For every $f\in B_b(X)$, there exist functions $u_f:X\times \mathbb{R}_+\to\mathbb{R}$ and $\psi_f:X\times \dpsi \to\mathbb{R}$, where $\dpsi:=\left\{(t,T)\in\mathbb{R}_+^2: t\leq T\right\}$, such that
\begin{equation}
\label{e:P_T_app}
P_T f(x)=e^{-\Lambda(y,i,T)} f(S_i(T,y),i)+\int_0^T \psi_f((y,i),t,T)\,dt+u_f((y,i),T)
\end{equation}
for any $x=(y,i)\in X$ and $T\in\mathbb{R}_+$, and that the following conditions hold:
\begin{equation}
\label{e:prop_uf}
u_f(\cdot,T)\in B_b(X) \quad\text{for all}\quad T\in\mathbb{R}_+,\quad\lim_{T\to 0} \norma{u_f(\cdot,T)}_{\infty}/{T}=0,
\end{equation}
\begin{equation}
\label{e:psi_prop1}
\psi_f(\cdot,t,T)\in B_b(X),\quad \norma{\psi_f(\cdot,t,T)}_{\infty}\leq\olambda\norma{f}_{\infty}\quad\text{for any}\quad (t,T)\in \dpsi,
\end{equation}
\begin{equation}
\label{e:psi_prop2}
\psi_f(x,0,0)=\hlambda(x) Wf(x)\quad\text{for every}\quad x\in X,
\end{equation}
with $\hlambda$ given by \eqref{def:hlambda} and, if the kernel $J$ enjoys property \ref{cnd:f}, then, for every $x\in X$, the map  \hbox{$\dpsi\ni (t,T)\mapsto \psi_f(x,t,T)$} is jointly continuous whenever $f\in C_b(X)$.

\item\label{lem:iii} $\{P_t\}_{t\in\mathbb{R}_+}$ is stochastically continuous, i.e. 
$$\lim_{T\to 0} P_T f(x)=f(x)\quad\text{for any}\quad x\in X,\; f\in C_b(X).$$
\end{enumerate}
\end{lemma}

\begin{proof}
Throughout the proof, we will write $\bar{x}:=(x,0)$ for any given $x\in X$. 

Let $f\in B_b(X)$ and $T\in\mathbb{R}_+$. Then, appealing to \eqref{e:efp} and \eqref{def:pdmp}, for every $x\in X$, we get
\begin{align}
\begin{split}
\label{e:pt_ew}
P_T f(x)&=\ew_{\bar{x}}f(Y(T),\xi(T))=\sum_{n=0}^{\infty} \ew_{\bar{x}}\left[f(S_{\xi_n}(T-\tau_n,Y_n),\xi_n)\mathbbm{1}_{\left\{\eta(T)=n\right\}} \right]\\
&=\sum_{n=0}^{\infty} \ew_{\bar{x}}\left[\mathbbm{1}_{[0,T]}(\tau_n)\,f(S_{\xi_n}(T-\tau_n,Y_n),\xi_n)\,\mathbbm{1}_{(T,\infty)}(\tau_{n+1}) \right],
\end{split}
\end{align}
with $\eta(\cdot)$ defined by \eqref{def:eta}. On the other hand, in view of \eqref{e:canonical}, it is clear that, for any~$x\in X$, $g,h\in B_b(\bar{X})$ and $n\in\n_0$,
\begin{align}
\begin{split}
\label{e:dod}
\ew_{\bar{x}}[g(\bar{\Phi}_n)h(\bar{\Phi}_{n+1})]&=\int_{\bar{X}}\int_{\bar{X}} g(w)h(z)\,\bar{P}(w,dz)\bar{P}^n(\bar{x},dw)\\
&=\int_{\bar{X}}g(w)\bar{P}h(w)\bar{P}^n(\bar{x},dw)=\bar{P}^n(g\bar{P}h)(\bar{x}).
\end{split}
\end{align}
Hence, we can write
\begin{align}
\begin{split}
\label{e:decomp}
P_T f(x)&=\sum_{n=0}^{\infty}\ew_{\bar{x}}[g_T(Y_n,\xi_n,\tau_n)h_T(Y_{n+1},\xi_{n+1},\tau_{n+1})]\\&=\sum_{n=0}^{\infty}\bar{P}^n(g_T\bar{P}h_T)(\bar{x})\quad\text{for every}\quad x\in X,
\end{split}
\end{align}
where $g_T,h_T\in B_b(\bar{X})$ are given by
\begin{equation}
\label{def:gh}
g_T(u,j,s):=\mathbbm{1}_{[0,T]}(s)f(S_j(T-s,u),j)\quad\text{and}\quad
h_T(u,j,s):=\mathbbm{1}_{(T,\infty)}(s)
\end{equation}
for any $u\in Y$, $j\in I$ and $s\in\mathbb{R}_+$.


\textbf{\ref{lem:i}}: Suppose that $J$ is Feller, $f\in C_b(X)$ and let $T\in\mathbb{R}_+$. The aim is to prove that $P_T f$ is continuous.

Let us first observe that, for any function $\varphi\in B_b(\bar{X})$ such that $X\ni x\mapsto\varphi(x,s)$ is continuous for every $s\geq 0$ (which is obviously the case for $g_T$ and $h_T$), the map \hbox{$X\ni x\mapsto \bar{P}\varphi(x,s)$} is continuous for each $s\geq 0$ as well. Indeed, let $s\in\mathbb{R}_+$, and note that, for any \hbox{$i,j\in I$} and \hbox{$t\in\mathbb{R}_+$}, the map $Y \ni y \mapsto J(\pi_{ij} \varphi(\cdot,j,t))(y)$ is continuous, since the kernel $J$ is Feller and~\hbox{$\pi_{ij},\, \varphi(\cdot,j,t)\in C_b(Y)$}. Consequently, taking into account the continuity of $\lambda$  and the semiflows, it follows that, for all $j\in I$ and $t\geq 0$, the maps 
$$X\ni (y,i) \mapsto \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)}J(\pi_{ij}\varphi(\cdot,j,s+t))(S_i(t,y))$$
are continuous. Moreover, all these maps are bounded by $\olambda\, e^{-\ulambda t}\norma{\varphi}_{\infty}$. Hence, using the  Lebesgue dominated convergence theorem, we can conclude that the function
$$X\ni (y,i)=x \mapsto \bar{P}\varphi(x,s)=\sum_{j\in I}\int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)}\, J(\pi_{ij} \varphi(\cdot,j,s+t))(S_i(t,y))\,dt$$
is continuous, as claimed.

In light of the observation above, all the maps $X\ni x\mapsto \bar{P}^n(g_T\bar{P}h_T)(\bar{x})$, $n\in \n_0$, are continuous. Furthermore, by Lemma \ref{lem:tech2} we know that
\begin{align}
\begin{split}
\label{e:com_bound}
|\bar{P}^n(g_T\bar{P}h_T)(\bar{x})|&=\left|\ew_{\bar{x}}[f(S_{\xi_n}(T-\tau_n,Y_n),\xi_n))\mathbbm{1}_{\{\eta(T)=n\}} ]\right|\\
&\leq \norma{f}_{\infty}\pr_{\bar{x}}(\eta(t)=n)\leq \norma{f}_{\infty}e^{-\ulambda T}\frac{(\olambda T)^n}{n!}
\end{split}
\end{align}
for all $x\in X$ and $n\in\n_0$. Hence, the continuity of $P_Tf$ can be now deduced by applying the discrete analogue of the Lebesgue dominated convergence theorem to \eqref{e:decomp}.
\vspace{0.2cm}

\textbf{\ref{lem:ii}}: Let us define
$$u_f(x,T):=\sum_{n=2}^{\infty}\bar{P}^n(g_T\bar{P}h_T)(\bar{x})\quad\text{for}\quad x\in X,\; T\in\mathbb{R}_+,\vspace{-0.5cm}$$
and
\begin{align*}
\psi_f(x,t,T)&:=\lambda(S_i(t,y))e^{-\Lambda(y,i,t)}\int_Y\sum_{j\in I}  \pi_{ij}(u) e^{-\Lambda(u,j,T-t)}\\
&\quad\times f(S_j(T-t,u),j) J(S_i(t,y),du)\quad\text{for}\quad x=(y,i)\in X,\; (t,T)\in \dpsi.
\end{align*}
Obviously, $u_f(\cdot, T)$ and $\psi_f(\cdot, t, T)$ are a Borel measurable for any $T\in\mathbb{R}_+$ and $0\leq t\leq T$. 

Now, fix $T\in\mathbb{R}_+$. Then, according to \eqref{e:decomp}, we have
\begin{equation}
\label{e:P_T_app1} 
P_T f(x)=g_T\bar{P}h_T(\bar{x})+\bar{P}(g_T\bar{P}h_T)(\bar{x})+u_f(x,T)\quad\text{for}\quad x\in X.
\end{equation}
Keeping in mind \eqref{def:P_bar} and \eqref{def:gh}, we see that for any $x=(y,i)\in X$ and $s\in\mathbb{R}_+$,
\begin{align}
\begin{split}
\label{e:gph}
g_T\bar{P}h_T(x,s)&=\mathbbm{1}_{[0,T]}(s)f(S_i(T-s,y),i)\int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)} \mathbbm{1}_{(T,\infty)}(s+t)\,dt
\\
&=\mathbbm{1}_{[0,T]}(s) e^{-\Lambda(y,\,i,\,T-s)} f(S_i(T-s,y),i),
\end{split}
\end{align}
which, in particular, gives
\begin{equation}
\label{e:P_T_app2}
g_T\bar{P}h_T(\bar{x})=g_T\bar{P}h_T(x,0)= e^{-\Lambda(y,i,T)} f(S_i(T,y),i) .
\end{equation}
Appealing to \eqref{e:gph}, we can also conclude that
\begin{align*}
\bar{P}&(g_T\bar{P}h_T)(\bar{x})=\int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)} \int_Y \sum_{j\in I} \pi_{ij}(u)(g_T\bar{P}h_T)(u,j,t)\,J(S_i(t,y),du)\,dt\\
&=\int_0^T\lambda(S_i(t,y)) e^{-\Lambda(y,i,t)} \int_Y \sum_{j\in I} \pi_{ij}(u) e^{-\Lambda(u,\,j,\,T-t)} f(S_j(T-t,u),j) \,J(S_i(t,y),du)\,dt\\
&=\int_0^T \psi_f((y,i),t,T)\,dt \quad\text{for all}\quad x=(y,i)\in X,
\end{align*}
which, together with \eqref{e:P_T_app1} and \eqref{e:P_T_app2} implies \eqref{e:P_T_app}.

Further, note that the conditions regarding $u_f$ specified in \eqref{e:prop_uf} can be deduced from~\eqref{e:com_bound}, since
\begin{align}
\begin{split}
\label{e:est_rest}
\frac{|u_f(x,T)|}{T}&\leq \norma{f}_{\infty}\frac{1}{T}e^{-\ulambda T}\sum_{n=2}^{\infty} \frac{(\olambda T)^n}{n!}=\norma{f}_{\infty}\frac{1}{T}e^{-\ulambda T}(e^{\olambda T}-1-\olambda T)\\
&=\norma{f}_{\infty} e^{-\ulambda T}\left(\frac{e^{\olambda T}-1}{T}-\olambda  \right) \quad \text{for all}\quad x\in X,\; T\in\mathbb{R}_+,
\end{split}
\end{align}
whilst the properties of the function $\psi_f$ stated in \eqref{e:psi_prop1} and \eqref{e:psi_prop2} follow directly from its definition and~\eqref{e:lambda_bounds}.

Now, suppose that $J$ satisfies condition $\ref{cnd:f}$, $f\in C_b(X)$, and let  $x=(y,i)\in X$. To prove that the map $\dpsi \ni (t,T)\mapsto \psi(x,t,T)$ is jointly continuous, define
$$g(u,t):=\sum_{j\in I} \pi_{ij}(u) e^{-\Lambda(u,j,t)} f(S_j(t,u),j) \quad\text{for}\quad u\in Y,\;t\in\mathbb{R}_+.$$
Then
$$\psi_f(x,t,T)=\lambda(S_i(t,y))e^{-\Lambda(y,i,t)} Jg(\cdot,T-t)(S_i(t,y))\quad\text{for}\quad (t,T)\in D_{\psi}.$$
Taking into account \eqref{e:lambda_bounds}, for every $j\in I$ and any $(u,t), (u_0,t_0)\in Y\times\mathbb{R}_+$, we have
$$|\Lambda(u,j,t)-\Lambda(u_0,j,t_0)|\leq \int_0^{t_0} |\lambda(S_j(h,u))-\lambda(S_j(h,u_0)) |\,dh +\olambda |t-t_0|.$$
Hence, in view of the continuity of $\lambda$ and $S_j(h,\cdot)$ for any $h\geq 0$, we can conclude (by applying the Lebesgue dominated convergence theorem) that $(u,t)\mapsto \Lambda(u,j,t)$ is jointly continuous  for each $j\in I$. This, together with the continuity of $f$, $S_j$ and $\pi_{ij}$, \hbox{$j\in J$}, shows that $g$ is jointly continuous as well, which, in turn, guarantees that $g\in C_b(Y\times\mathbb{R}_+)$, since $|g(u,t)|\leq \norma{f}_{\infty}$ for all $(u,t)\in Y\times\mathbb{R}_+$. Eventually, it now follows from condition \ref{cnd:f} and the continuity of $S_i(\cdot,y)$ that the map 
$D_{\psi}\ni(t,T)\mapsto Jg(\cdot, T-t)(S_i(t,y))$ is jointly continuous, and thus so is $D_{\psi}\ni (t,T)\mapsto \psi_f(x,t,T)$.

\vspace{0.2cm}
\textbf{\ref{lem:iii}}: Statement \ref{lem:iii} follows immediately from \ref{lem:ii}.
\end{proof}


\subsection{Certain properties of the weak generator of $\{P_t\}_{t\in\mathbb{R}_+}$} \label{sec:generators}

While proving Theorem \ref{thm:main} we will also require certain results concerning the weak infinitesimal generator of $\{P_t\}_{t\in\mathbb{R}_+}$, with a focus on its relationship with the weak generator of the~auxiliary semigroup ${\{Q_t\}}_{t\in\mathbb{R}+}$, mentioned in the introduction. In this study, we adapt the concept of weak generator from \cite{ b:dynkin_1965, b:dynkin_2000}.

Consider the Banach space $(\mathcal{M}_{sig}(X), \norma{\cdot}_{TV})$ with the total variation norm, defined by
$$\norma{\mu}_{TV}:=\sup\{|\<f,\mu\>|:\,f\in B_b(X),\;\norma{f}_{\infty}\leq 1\}\quad\text{for}\quad\mu\in\mathcal{M}_{sig}(X),$$
and let $\mathcal{M}_{sig}(X)^*$ denote its dual space. Further, for every $f\in B_b(X)$, define the bounded linear functional $\ell_f:\mathcal{M}_{sig}(X)\to\mathbb{R}$ by
$$\ell_f(\mu):=\<f,\mu\>\quad\text{for}\quad\mu\in\mathcal{M}_{sig}(X).$$
Then $f\mapsto \ell_f$ is an isometric embedding of $B_b(X)$ in $\mathcal{M}_{sig}(X)^*$, i.e. an injective linear map satisfying $\norma{\ell_f}=\norma{f}_{\infty}$ for all $f\in B_b(X)$, where $\norma{\cdot}$ denotes the operator norm. Therefore,~$B_b(X)$ can be regarded as a subspace of $\mathcal{M}_{sig}(X)^*$, and thus it can be endowed with the weak star ($w^*$-) topology inherited from the latter. Moreover, $B_b(X)$ is then \hbox{$w^*$-closed} in~$\mathcal{M}_{sig}(X)^*$. 

In view of the above, a sequence $\{f_n\}_{n\in\n}\subset B_b(X)$ is said to be $*$-weak convergent to~$f\in B_b(X)$, which is written as $\wlim_{n\to \infty} f_n=f$, whenever $(\ell_{f_n})_{n\in\n}$ converges $*$-weakly to $\ell_f$ in $\mathcal{M}_{sig}(X)^*$, i.e.,

\begin{equation} \label{wlimit} \wlim_{n\to \infty} f_n=f \;\;\;\mbox{iff}\;\;\;\lim_{n\to\infty}\<f_n,\mu\>=\<f,\mu\>\;\;\;\mbox{for all}\;\;\;\mu\in\mathcal{M}_{sig}(X).
\end{equation}
On the other hand, it is well-known that \eqref{wlimit} is equivalent to the pointwise convergence of $\{f_n\}_{n\in\n}$ to $f$ in conjunction with the boundedness of the sequence $(\norma{f_n}_{\infty})_{n\in\n}$.

Given a subspace $L$ of $B_b(X)\subset \mathcal{M}_{sig}(X)^*$ and a contraction semigroup $(H_t)_{t\in\mathbb{R}_+}$ of bounded linear operators from $L$ to itself (i.e., a semigroup satisfying $\norma{H_t f}_{\infty}\leq \norma{f}_{\infty}$ for all $t\geq 0$ and $f\in L$), by \emph{the~weak (infinitesimal) generator} of this semigroup we will mean (following \cite[Ch.1\,\S\,6]{b:dynkin_1965}) the operator $A_H:D(A_H)\to L_{0,H}$ given by
$$A_H f=\wlim_{t\to 0}\frac{H_t f -f}{t}\quad\text{for}\quad f\in D(A_H),$$
where
$$D(A_H):=\left\{f\in L:\, \wlim_{t\to 0}\frac{H_t f -f}{t}\;\;\text{exists and belongs to}\;\;L_{0,H}\right\},$$
while $L_{0,H}$ denotes the center of $(H_t)_{t\geq 0}$, i.e.
\begin{equation}\label{defL0} 
L_{0,H}:=\{f\in L:\,\wlim_{t\to 0} H_t f =f\}.
\end{equation}

\begin{remark}[see \text{\cite[p. 40]{b:dynkin_1965} or \cite[pp. 437-448]{b:dynkin_2000}}]\label{rem:inf}
Let $(H_t)_{t\geq 0}$ be a contraction semigroup of bounded linear operators on a subspace $L$ of $B_b(X)$, and let $A_H$ stand for the weak generator of this semigroup. Then
\begin{enumerate}[label=(\roman*), leftmargin=*, widest=ii]
\item\label{rem:i}$\wcl D(A_H) =\wcl L_{0,H},$ where $\wcl$ denotes the $*$-weak closure in $B_b(X)$.
\item\label{rem:ii} For every $f\in D(A_H)$ the derivative 
$$\mathbb{R}_+\ni t\mapsto \frac{d^+ H_t f}{dt}:=\wlim_{h\to 0^+} \frac{H_{t+h} f - H_t f}{h}$$
exists and is $*$-weak continuous from the right. Moreover, we have
{$$\frac{d_+ H_t f}{dt}=A_H H_t f =H_t A_H f\;\;\;\mbox{and}\;\;\;
H_t f-f=\int_0^t H_s A_Hf\,ds\quad\text{for all}\ \quad t\geq 0.$$}
\end{enumerate}
\end{remark}

Let us recall that, according to statement  \ref{lem:i} of Lemma \ref{lem:Pt_prop}, if $J$ is Feller (or, in particular, if it enjoys property \ref{cnd:f}), then so is the transition semigroup $\{P_t\}_{t\in\mathbb{R}_+}$ of the process~$\Psi$. Consequently, in this case, the family of operators on $C_b(X)$ corresponding to $\{P_t\}_{t\in\mathbb{R}_+}$ is a contraction semigroup of bounded linear operators and, thus, we can consider its weak generator. In what follows, this generator will be denoted by $A_P$. Apart from this, we also employ the weak generator $A_Q$ of the semigroup $\{Q_t\}_{t\in\mathbb{R}_+}$ defined by
\begin{equation}
\label{def:Qt}
Q_t f(x):=f(S_i(t,y),i)\quad\text{for}\quad x=(y,i)\in X,\;f\in C_b(X).
\end{equation}

Furthermore, it should be noted that $L_{0,P}=C_b(X)$ by statement \ref{lem:iii} of Lemma~\ref{lem:Pt_prop}, and also $L_{0,Q}=C_b(X)$, which holds trivially.

As mentioned in the introduction, if $\lambda$ is constant then, according to \cite[Theorem 1.7]{b:dynkin_1965}, $(G/\lambda\,|_{\,C_b(X)})^{-1}= \lambda \operatorname{id}-A_Q$, which is a key observation in \cite{b:czapla_erg}. Since this argument fails in our framework, we prove the following result:

\begin{lemma}\label{lem:main1}
Let $A_Q/\hlambda$ be the operator defined by
$$\left(A_Q/\hlambda\right)f=\frac{A_Q f}{\hlambda}\quad\text{for}\quad f\in D(A_Q),$$
with $\hlambda$ given by \eqref{def:hlambda}.
Then the operator $\operatorname{id}-A_Q/\hlambda: D(A_Q)\to C_b(X)$ is invertible, and its inverse is the operator on $C_b(X)$ induced by the kernel $G$, specified by~\eqref{def:G}.
\end{lemma}
\begin{proof}
Obviously, it suffices to show that
\begin{gather}
\label{e:inv1}
Gf\in D(A_Q)\quad\text{and}\quad Gf-\frac{A_Q G f}\hlambda=f\quad\text{for any}\quad f\in C_b(X),\\
\label{e:inv2}
Gf-G\left(\frac{A_Q f}{\hlambda}\right)=f\quad \text{for any}\quad f\in D(A_Q).
\end{gather}

Let $f\in C_b(X)$. Then, using the flow property, for any $x=(y,i)\in X$ and $T>0$, we obtain
\begin{align*}
Q_T G f(x)&= Gf(S_i(T,y),i)=\int_0^{\infty} \lambda(S_i(\bar{t}+T,y))e^{-\int_0^{\bar{t}} \lambda(S_i(\bar{h}+T,y))\,d\bar{h}}f(S_i(\bar{t}+T,y),i)\,d\bar{t}.
\end{align*}
Making the substitutions $t=\bar{t}+T$ and $h=\bar{h}+T$ therefore gives
\begin{align*}
Q_T G f(x)&=\int_T^{\infty} \lambda(S_i(t,y))e^{-\int_T^{t} \lambda(S_i(h,y))\,dh}f(S_i(t,y),i)\,dt.
\end{align*}
Further, since
$$\int_T^{t} \lambda(S_i(h,y))\,dh=L(y,i,t)-L(y,i,T)\quad\text{for}\quad t\geq T,$$
it follows that
\begin{align*}
Q_T G f(x)&=e^{L(y,i,T)}\int_T^{\infty} \lambda(S_i(t,y))e^{-L(y,i,t)}f(S_i(t,y),i)\,dt\\
&=e^{L(y,i,T)}\left(Gf(y,i)- \int_0^T \lambda(S_i(t,y))e^{-L(y,i,t)}f(S_i(t,y),i)\,dt \right).
\end{align*}
Hence, for all $x=(y,i)\in X$ and $T>0$, we have
\begin{align*}
\frac{Q_T(Gf)(x)-Gf(x)}{T}&=\frac{e^{L(y,i,T)}-1}{T}Gf(y,i)\\
&\quad-e^{L(y,i,T)}\frac{1}{T}\int_0^T \lambda(S_i(t,y))e^{-L(y,i,t)}f(S_i(t,y),i)\,dt.
\end{align*}
Now, using l'Hospital's rule and taking into account the continuity of the integrand on the right-hand side of this equality, we can conclude that
\begin{align*}
\lim_{T\to 0}\frac{Q_T(Gf)(x)-Gf(x)}{T}&=\lambda(y)Gf(y,i)-\lambda(y)f(y,i)\\\
&=\hlambda(x)(Gf(x)-f(x)) \quad\text{for every}\quad x=(y,i)\in X,
\end{align*}
and $\hlambda(Gf-f)\in C_b(X)$, since $G$ is Feller. Moreover, bearing in mind \eqref{e:lambda_bounds}, we see that
\begin{align*}
\norma{\frac{Q_T(Gf)-Gf}{T}}_{\infty}\leq \left(\frac{e^{\olambda T}-1}{T} + \olambda e^{\olambda T} \right)\norma{f}_{\infty}\leq \left(\olambda+1+\olambda e^{\olambda \delta}\right)\norma{f}
\end{align*}
for every $T\in(0,\delta)$ with sufficiently small $\delta>0$. We have therefore shown that
$$\wlim_{T\to 0} \frac{Q_T(Gf)-Gf}{T}=\hlambda(Gf-f)\in C_b(X)=L_{0,Q}.$$
This obviously means that $Gf\in D(A_Q)$ and $A_Q(Gf)=\hlambda(Gf-f)$,
which immediately implies \eqref{e:inv1}.

What is left is to prove \eqref{e:inv2}. To this end, let $f\in D(A_Q)$ and $x=(y,i)\in X$. Then
\begin{align*}
Gf(x)&=\int_0^{\infty} \lambda(S_i(t,y))e^{-\Lambda(y,i,t)}f(S_i(t,y),i)\,dt=-
\int_0^{\infty} \left(\frac{d^+}{dt}e^{-\Lambda(y,i,t)}\right)Q_tf(y,i)\,dt\\
&=-\left[e^{-\Lambda(y,i,t)} f(S_i(t,y),i)\right]_0^{\infty}
+\int_0^{\infty} e^{-\Lambda(y,i,t)} \left(\frac{d^+}{dt} Q_t f(y,i) \right)\,dt\\
&=f(y,i)+\int_0^{\infty} e^{-\Lambda(y,i,t)} \left(\frac{d^+}{dt} Q_t f(y,i) \right)\,dt.
\end{align*}
According to statement \ref{rem:ii} of Remark \ref{rem:inf}, we have
$$\frac{d^+}{dt} Q_t f(y,i)=Q_t A_Q f(y,i)= A_Qf(S_i(t,y),i)\quad\text{for all}\quad t\geq 0,$$
whence it finally follows that
\begin{align*}
Gf(x)&=f(y,i)+\int_0^{\infty} \lambda(S_i(t,y)) e^{-\Lambda(y,i,t)}\frac{A_Q f(S_i(t,y),i)}{\lambda(S_i(t,y))}\,dt=f(x)+G(A_Q/\hlambda)(x),
\end{align*}
which clearly yields \eqref{e:inv2}. The proof is now complete.
\end{proof}

Another fact that will play a significant role in the proof of Theorem \ref{thm:main} concerns the relationship between the weak generators $A_P$ and $A_Q$.

\begin{lemma}\label{lem:main2}
Suppose that $J$ enjoys property \ref{cnd:f}. Then $D(A_P)=D(A_Q)$ and, for every $f\in D(A_P)$, we have
\begin{equation}
\label{e:APQ}
A_P f=A_Q f +\hlambda Wf-\hlambda  f,
\end{equation}
where $\hlambda$ is given by \eqref{def:hlambda}.
\end{lemma}

\begin{proof}
Let $f\in C_b(X)$ and define
\begin{equation}
\label{def:delta}
\Delta_f(x,T):=\frac{1}{T}\int_0^T \psi_f(x,t,T)\,dt-\frac{1-e^{-\Lambda(x,T)}}{T}f(x)+\frac{u_f(x,T)}{T},
\end{equation}
for any $x\in X$ and $T>0$, where $\psi_f$ is the function specified in statement \ref{lem:ii} of Lemma~\ref{lem:Pt_prop}. Recall that, according to this lemma, the map $D_{\psi}\ni (t,T) \mapsto \psi_f(x,t,T)$ is then (jointly) continuous for every $x\in X$, as condition \ref{cnd:f} is assumed.

We will first show that
\begin{equation}
\label{e:wlim1}
\wlim_{T\to 0} \Delta_f(\cdot,T)=\hlambda Wf-\hlambda f\in C_b(X),
\end{equation}
where $W$ is the operator on $B_b(X)$ induced by kernel \eqref{def:W}. To do this, let $x\in X$. Since, for any $T>0$, the map $[0,T]\ni t\mapsto \psi_f(x,t,T)$ is continuous, the mean value theorem for integrals yields that, for every $T>0$, the first component on the right-hand side of \eqref{def:delta} equals to $\psi_f(x,t_x(T),T)$ for some $t_x(T)\in [0,T]$. Consequently, taking into account the continuity of $T\mapsto \psi_f(x,t_x(T),T)$ and \eqref{e:psi_prop2}, we see that
$$\lim_{T\to 0}\frac{1}{T}\int_0^T \psi_f(x,t,T)\,dt=\lim_{T\to 0}\psi_f(x,t_x(T),T) =\psi_f(x,0,0)=\hlambda(x)Wf(x).$$
This, together with the fact that
$$\norma{\frac{1}{T}\int_0^T \psi_f(\cdot,t,T)\,dt }_{\infty}\leq \olambda\norma{f}_{\infty}\quad\text{for all}\quad T>0,$$
resulting from \eqref{e:psi_prop1}, implies that $\wlim_{T\to 0}T^{-1}\int_0^T \psi_f(\cdot,t,T)\,dt=\hlambda Wf$. Further, from l'Hospital's rule it follows that
$$\lim_{T\to 0} \frac{1-e^{-\Lambda(x,T)}}{T}=\hlambda(x),$$
and \eqref{e:lambda_bounds} yields that
$$\norma{\frac{1-e^{-\Lambda(\cdot,T)}}{T}}_{\infty}\leq \frac{1-e^{-\olambda T}}{T}\leq \olambda+1\quad\text{for sufficiently small}\quad T>0,$$
whence $\wlim_{T\to 0} (1-e^{-\Lambda(\cdot,T)})/T=\hlambda$. Moreover, \eqref{e:prop_uf} implies that \hbox{$\wlim_{T\to 0} u_f(\cdot,T)/T=0$}. Finally, we see that $\hlambda Wf-\hlambda f\in C_b(X)$, as $W$ is Feller by property \ref{cnd:f} and $\hlambda\in C_b(X)$, which ends the proof of \eqref{e:wlim1}.

Now, referring to \eqref{e:P_T_app}, we can write
\begin{align*}
\frac{P_T f(x)-f(x)}{T}&=e^{-\Lambda(y,i,T)}\cdot \frac{f(S_i(t,y),i)-f(y,i)}{T}+\frac{1}{T}\int_0^T \psi_f((y,i),t,T)\,dt\\
&\quad-\frac{1-e^{-\Lambda(y,i,T)}}{T} f(y,i)+\frac{u_f((y,i),T)}{T}\quad \text{for}\quad x=(y,i)\in X,\;T>0,
\end{align*}
which, due to \eqref{def:Qt} and \eqref{def:delta}, gives
$$
\frac{P_T f- f}{T}=e^{-\Lambda(\cdot,T)}\cdot\frac{Q_T f -f}{T}+\Delta_f(\cdot,T)\quad\text{for}\quad T>0.
$$
In view of \eqref{e:wlim1} and the fact that $\wlim_{T\to 0} e^{-\Lambda(\cdot,T)}=1$, this observation shows that $f\in D(A_P)$ iff $f\in D(A_Q)$, and that \eqref{e:APQ} is satisfied, whenever $f\in D(A_P)=D(A_Q)$. The proof of the lemma is therefore complete.


\end{proof}
\subsection{Finalization of the proof}\label{sec:proof_fin}
Armed with the results of Section \ref{sec:generators}, we are now ready to prove Theorem \ref{thm:main}. Before we proceed, let us recall that $A_P$ and $A_Q$ stand for the weak infinitesimal generators of the semigroups $\{P_t\}_{t\in\mathbb{R}_+}$ and $\{Q_t\}_{t\in\mathbb{R}_+}$ on $C_b(X)$, respectively, where $\{Q_t\}_{t\in\mathbb{R}_+}$ is given by \eqref{def:Qt}.

\begin{proof}[Proof of Theorem \ref{thm:main}]
{\bf (a):}\; To prove statement \ref{cnd:a}, suppose that $\mu_*^{\Phi}\in\mathcal{M}_1(X)$ is invariant for $P$, and let $\mu_*^{\Psi}$ be given by \eqref{e:m_psi}. 

We will first show that
\begin{equation}
\label{e:main1}
\<A_P f,\, \mu_*^{\Phi}\tG\>=0\quad\text{for every}\quad f\in D(A_P).
\end{equation}
To this end, let $f\in D(A_P)$ and define $\nu_*:=\mu_*^{\Phi} G$. Taking into account that $GW=P$ (cf. Remark \ref{rem:gw}), we see that
$$\nu_*WG=(\mu_*^{\Phi} G)WG=(\mu_*^{\Phi} GW)G=(\mu_*^{\Phi} P)G=\mu_*^{\Phi} G=\nu_*,$$
which means that $\nu_*$ is an invariant probability measure of $WG$. Further, from Lemma~\ref{lem:main2} it follows that $f\in D(A_Q)$, and that
\begin{equation}
\label{e:main2}
\frac{A_P f}{\hlambda}=\frac{A_Q f}{\hlambda}+Wf-f.
\end{equation}
Using identity \eqref{e:inv2}, resulting from Lemma \ref{lem:main1}, and the $WG$-invariance of $\nu_*$, we further obtain
\begin{align*}
\<f-\frac{A_Q f}{\hlambda},\,\nu_* \>&= \<f-\frac{A_Q f}{\hlambda},\,\nu_* WG\>= \<G\left(f-\frac{A_Q f}{\hlambda}\right),\,\nu_*W \>\\
&=\<f,\,\nu_* W\>=\<Wf,\,\nu_*\>.
\end{align*}
In view of \eqref{e:main2}, this gives
$$\<\frac{A_P f}{\hlambda},\,\nu_*\>=\< \frac{A_Q f}{\hlambda}+Wf-f ,\, \nu_*\>=0,$$
which finally implies that
\begin{align*}
\<A_P f,\, \mu_*^{\Phi}\tG\>&=\<\tG(A_P f),\, \mu_*^{\Phi}\>=\<G\left(\frac{A_P f}{\hlambda}\right),\, \mu_*^{\Phi} \>=\<\frac{A_P f}{\hlambda},\, \mu_*^{\Phi} G \>\\
&=\<\frac{A_P f}{\hlambda},\, \nu_* \>=0,
\end{align*}
as claimed.

Now, according to Remark \ref{rem:inf}\ref{rem:ii}, for any $t\in\mathbb{R}_+$ and $f\in D(A_P)$, we have
$$P_t f - f = \int_0^t A_P P_s f\,ds,$$
which, together with \eqref{e:main1}, yields that
\begin{align*}
\<P_t f - f,\, \mu_*^{\Phi} \tG\>=\<\int_0^t A_P P_s f\,ds,\, \mu_*^{\Phi} \tG\>=\int_0^t \<A_P P_s f,\, \mu_*^{\Phi} \tG\> \,ds=0.
\end{align*}
Since  $C_b(X)\subset w^*-\operatorname{cl}D(A_P)$ due to Remark \ref{rem:inf}\ref{rem:i}, one can easily conclude that, in fact, the above equality holds for all $f\in C_b(X)$. We have therefore shown that
$$\<P_t f,\,\mu_*^{\Phi} \tG\>=\<f,\,\mu_*^{\Phi} \tG\>\quad\text{for all}\quad t\in\mathbb{R}_+,\; f\in C_b(X).$$
This obviously implies that, for any $t\in\mathbb{R}_+$ and $f\in C_b(X)$,
\begin{align*}
\<f, \mu_*^{\Psi} P_t\>=\<P_t f,\, \mu_*^{\Psi}\>= \frac{\<P_t f,\, \mu_*^{\Phi} \tG\>}{\mu_*^{\Phi}\tG(X)}=\frac{\<f,\, \mu_*^{\Phi} \tG\>}{\mu_*^{\Phi}\tG(X)}=\<f,\,\mu_*^{\Psi}\>,
\end{align*}
and thus proves that $\mu_*^{\Psi}$ is invariant for $\{P_t\}_{t\in\mathbb{R}_+}$.

Furthermore, since $\tG\tW=P$ (as emphasized in Remark \ref{rem:gw}) and $\mu_*^{\Phi}$ is invariant for $P$, we see that
\begin{align*}
\mu_*^{\Psi} \tW=\frac{\mu_*^{\Phi} \tG\tW}{\mu_*^{\Phi} \tG(X)}=\frac{\mu_*^{\Phi} P}{\mu_*^{\Phi} \tG(X)}=\frac{\mu_*^{\Phi}}{\mu_*^{\Phi} \tG(X)},
\end{align*}
whence, in particular,
$$\mu_*^{\Psi} \tW (X)=\frac{1}{\mu_*^{\Phi} \tG(X)}.$$
These two observations finally yield that
$$\frac{\mu_*^{\Psi} \tW}{\mu_*^{\Psi} \tW(X)}=\mu_*^{\Phi} \tG(X) \cdot \mu_*^{\Psi} \tW=\mu_*^{\Phi},$$
as claimed in \eqref{e:m_phi}.

{\bf (b):}\; We now proceed to the proof of claim \ref{cnd:b}. For this aim, suppose that $\mu_*^{\Psi}\in\mathcal{M}_1(X)$ is invariant for $\{P_t\}_{t\in\mathbb{R}_+}$, and let $\mu_*^{\Phi}$ be the measure defined by \eqref{e:m_phi}.

Let us begin with showing that
\begin{equation}
\label{e:main3}
\<\tW G f, \mu_*^{\Psi}\>=\<\hlambda f, \mu_*^{\Psi}\>\quad\text{for every} \quad f\in C_b(X).
\end{equation}
To do this, let $f\in C_b(X)$ and define $g:=Gf$. Obviously, lemmas \ref{lem:main1} and \ref{lem:main2} guarantee that $g\in D(A_Q)=D(A_P)$. Taking into account statement \ref{rem:ii} of Remark \ref{rem:inf} and the fact that $\mu_*^{\Psi}$ is invariant for $\{P_t\}_{t\in\mathbb{R}_+}$, we infer that
\begin{align*}
\<A_P g,\, \mu_*^{\Psi}\>&=\int_0^1 \<A_P g,\, \mu_*^{\Psi}\>\,ds=\int_0^1 \<P_s A_P g,\, \mu_*^{\Psi}\>\,ds=\<\int_0^1 P_s A_P g \,ds,\,\mu_*^{\Psi}\>\\
&=\<P_1 g - g,\, \mu_*^{\Psi}\>=\<g,\, \mu_*^{\Psi}P_1\>-\<g,\,\mu_*^{\Psi}\>=0.
\end{align*}
Hence, referring to Lemma \ref{lem:main2}, we get
$$\<A_Q g + \hlambda Wg -\hlambda g,\,\mu_*^{\Psi}\>=\<A_P g,\, \mu_*^{\Psi}\>=0,$$
which gives
$$\<\hlambda W g, \,\mu_*^{\Psi}\>=\< \hlambda g - A_Q g,\,\mu_*^{\Psi}\>
=\<\hlambda\left(g-\frac{A_Q g}{\hlambda}\right),\, \mu_*^{\Psi}\>.$$
Eventually, having in mind that $g=Gf$ and using \eqref{e:inv1}, following from Lemma~\ref{lem:main1}, we obtain
$$\<\tW Gf, \,\mu_*^{\Psi}\>=\<\hlambda WGf, \,\mu_*^{\Psi}\>= \<\hlambda\left(Gf-\frac{A_Q(Gf)}{\hlambda}\right),\, \mu_*^{\Psi}\>=\<\hlambda f,\,\mu_*^{\Psi}\>,$$
which is the desired claim.

If we now fix an arbitrary $f\in C_b(X)$ and apply \eqref{e:main3} with $f/\hlambda$ in the place of $f$,  then we obtain
$$\<f,\,\mu_*^{\Psi}\>=\<\tW G\left(\frac{f}{\hlambda}\right),\,\mu_*^{\Psi}\>=\<\tW \tG f,\,\mu_*^{\Psi}\>=\<f,\, \mu_*^{\Psi} \tW \tG\>,$$
which shows that $\mu_*^{\Psi}$ is invariant for $\tW \tG$. From this and the identity $\tG \tW=P$ it follows that
$$(\mu_*^{\Psi} \tW )P=(\mu_*^{\Psi} \tW)\tG \tW=(\mu_*^{\Psi} \tW\tG) \tW=\mu_*^{\Psi} \tW,$$
which further gives
$$\mu_*^{\Phi} P=\frac{\mu_*^{\Psi} \tW P}{\mu_*^{\Psi}\tW(X)}=\frac{\mu_*^{\Psi} \tW}{\mu_*^{\Psi}\tW(X)}=\mu_*^{\Phi},$$
and, in turn, shows that $\mu_*^{\Phi}$ is indeed invariant for $P$.

Finally, it remains to demonstrate that $\mu_*^{\Psi}$ can be represented according to \eqref{e:m_psi}. To see this, we again use the fact that $\mu_*^{\Psi}$ is invariant for $\tW \tG$, to obtain
$$\mu_*^{\Phi}\tG=\frac{\mu_*^{\Psi} \tW \tG}{\mu_*^{\Psi}\tW(X)}=\frac{\mu_*^{\Psi}}{\mu_*^{\Psi}\tW(X)},$$
which, in particular, implies that
$$\mu_*^{\Phi}\tG(X)=\frac{1}{\mu_*^{\Psi}\tW(X)}.$$
Consequently, it now follows that
$$\frac{\mu_*^{\Phi}\tG}{\mu_*^{\Phi}\tG(X)}=\mu_*^{\Psi}\tW(X)\cdot \mu_*^{\Phi} \tG=\mu_*^{\Psi}.$$
This completes the proof of the theorem.
\end{proof}

%\section*{Funding} This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.
%
%\section*{Declarations of interest} None.

\bibliographystyle{plain}
\bibliography{ReferencesDatabase}
\end{document}
