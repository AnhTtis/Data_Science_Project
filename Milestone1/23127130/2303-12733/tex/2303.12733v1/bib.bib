@article{zhang2023DatasetdrivenUnsupervisedObject,
  title = {Dataset-Driven Unsupervised Object Discovery for Region-Based Instance Image Retrieval},
  author = {Zhang, Zhongyan and Wang, Lei and Wang, Yang and Zhou, Luping and Zhang, Jianjia and Chen, Fang},
  year = {2023},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {45},
  number = {1},
  pages = {247--263},
  doi = {10.1109/TPAMI.2022.3141433},
  file = {/Users/jurie/Zotero/storage/R8CCMWUE/Zhang et al. - 2023 - Dataset-driven unsupervised object discovery for r.pdf}
}

@inproceedings{dubois2021LossyCompressionLossless,
  title = {Lossy {{Compression}} for {{Lossless Prediction}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Dubois, Yann and {Bloem-Reddy}, Benjamin and Ullrich, Karen and Maddison, Chris J},
  year = {2021},
  volume = {34},
  pages = {14014--14028},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Most data is automatically collected and only ever "seen" by algorithms. Yet, data compressors preserve perceptual fidelity rather than just the information needed by algorithms performing downstream tasks. In this paper, we characterize the bit-rate required to ensure high performance on all predictive tasks that are invariant under a set of transformations, such as data augmentations. Based on our theory, we design unsupervised objectives for training neural compressors. Using these objectives, we train a generic image compressor that achieves substantial rate savings (more than 1000x on ImageNet) compared to JPEG on 8 datasets, without decreasing downstream classification performance.},
  file = {/Users/jurie/Zotero/storage/ZRCRLQNR/Dubois et al_2021_Lossy Compression for Lossless Prediction.pdf}
}

@inproceedings{li2021CEDedupCosteffectiveConvolutional,
  title = {{{CE-Dedup}}: {{Cost-effective}} Convolutional Neural Nets Training Based on Image Deduplication},
  booktitle = {2021 {{IEEE}} Intl Conf on Parallel \& Distributed Processing with Applications, Big Data \& Cloud Computing, Sustainable Computing \& Communications, Social Computing \& Networking ({{ISPA}}/{{BDCloud}}/{{SocialCom}}/{{SustainCom}}), New York City, {{NY}}, {{USA}}, September 30 - Oct. 3, 2021},
  author = {Li, Xuan and Chang, Liqiong and Liu, Xue},
  year = {2021},
  pages = {11--18},
  publisher = {{IEEE}},
  doi = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00017}
}

@inproceedings{theis2017LossyImageCompression,
  title = {Lossy Image Compression with Compressive Autoencoders},
  booktitle = {5th International Conference on Learning Representations, {{ICLR}} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  author = {Theis, Lucas and Shi, Wenzhe and Cunningham, Andrew and Husz{\'a}r, Ferenc},
  year = {2017},
  publisher = {{OpenReview.net}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iclr/TheisSCH17.bib},
  timestamp = {Thu, 25 Jul 2019 14:25:47 +0200},
  file = {/Users/jurie/Zotero/storage/BL46D4AR/Theis et al. - 2017 - LOSSY IMAGE COMPRESSION WITH COMPRESSIVE AUTOENCOD.pdf}
}


@inproceedings{li2021QHashEfficientHashing,
  title = {{{QHash}}: {{An}} Efficient Hashing Algorithm for Low-Variance Image Deduplication},
  booktitle = {2021 {{IEEE}} 23rd Int Conf on High Performance Computing \& Communications; 7th Int Conf on Data Science \& Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud \& Big Data Systems \& Application ({{HPCC}}/{{DSS}}/{{SmartCity}}/{{DependSys}})},
  author = {Li, Xuan and Chang, Liqiong and Liu, Xue},
  year = {2021},
  pages = {9--15}
}

@inproceedings{matsubara2022SupervisedCompressionResourceConstrained,
  title = {Supervised {{Compression}} for {{Resource-Constrained Edge Computing Systems}}},
  booktitle = {2022 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Matsubara, Yoshitomo and Yang, Ruihan and Levorato, Marco and Mandt, Stephan},
  year = {2022},
  month = jan,
  pages = {923--933},
  publisher = {{IEEE}},
  address = {{Waikoloa, HI, USA}},
  doi = {10.1109/WACV51458.2022.00100},
  abstract = {There has been much interest in deploying deep learning algorithms on low-powered devices, including smartphones, drones, and medical sensors. However, full-scale deep neural networks are often too resource-intensive in terms of energy and storage. As a result, the bulk part of the machine learning operation is therefore often carried out on an edge server, where the data is compressed and transmitted. However, compressing data (such as images) leads to transmitting information irrelevant to the supervised task. Another popular approach is to split the deep network between the device and the server while compressing intermediate features. To date, however, such split computing strategies have barely outperformed the aforementioned naive data compression baselines due to their inefficient approaches to feature compression. This paper adopts ideas from knowledge distillation and neural image compression to compress intermediate feature representations more efficiently. Our supervised compression approach uses a teacher model and a student model with a stochastic bottleneck and learnable prior for entropy coding (Entropic Student). We compare our approach to various neural image and feature compression baselines in three vision tasks and found that it achieves better supervised rate-distortion performance while maintaining smaller end-to-end latency. We furthermore show that the learned feature representations can be tuned to serve multiple downstream tasks.},
  isbn = {978-1-66540-915-5},
  langid = {english},
  file = {/Users/jurie/Zotero/storage/7XGXVSXV/Matsubara et al. - 2022 - Supervised Compression for Resource-Constrained Ed.pdf}
}


@software{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}
@article{ge2013optimized,
  title={Optimized product quantization},
  author={Ge, Tiezheng and He, Kaiming and Ke, Qifa and Sun, Jian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={36},
  number={4},
  pages={744--755},
  year={2013},
  publisher={IEEE}
}

@article{malkov2018efficient,
  title={Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs},
  author={Malkov, Yu A and Yashunin, Dmitry A},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={4},
  pages={824--836},
  year={2018},
  publisher={IEEE}
}
@article{xu2022versatile,
	title        = {Versatile Diffusion: Text, Images and Variations All in One Diffusion Model},
	author       = {Xingqian Xu and Zhangyang Wang and Eric Zhang and Kai Wang and Humphrey Shi},
	year         = 2022,
	url          = {https://arxiv.org/abs/2211.08332},
	eprint       = {2211.08332},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}


@inproceedings{pizzi2022self,
  title={A self-supervised descriptor for image copy detection},
  author={Pizzi, Ed and Roy, Sreya Dutta and Ravindra, Sugosh Nagavara and Goyal, Priya and Douze, Matthijs},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14532--14542},
  year={2022}
}

@article{carlini2023extracting,
  title={Extracting training data from diffusion models},
  author={Carlini, Nicholas and Hayes, Jamie and Nasr, Milad and Jagielski, Matthew and Sehwag, Vikash and Tram{\`e}r, Florian and Balle, Borja and Ippolito, Daphne and Wallace, Eric},
  journal={arXiv preprint arXiv:2301.13188},
  year={2023}
}
@article{somepalli2022diffusion,
  title={Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models},
  author={Somepalli, Gowthami and Singla, Vasu and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2212.03860},
  year={2022}
}
@article{sauer2023stylegan,
  title={StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis},
  author={Sauer, Axel and Karras, Tero and Laine, Samuli and Geiger, Andreas and Aila, Timo},
  journal={arXiv preprint arXiv:2301.09515},
  year={2023}
}

@article{gordo2017end,
  title={End-to-end learning of deep visual representations for image retrieval},
  author={Gordo, Albert and Almazan, Jon and Revaud, Jerome and Larlus, Diane},
  journal={International Journal of Computer Vision},
  volume={124},
  number={2},
  pages={237--254},
  year={2017},
  publisher={Springer}
}
@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@InProceedings{Philbin07,
  author       = "James Philbin and Ondrej Chum and Michael Isard and Josef Sivic and Andrew Zisserman",
  title        = "Object Retrieval with Large Vocabularies and Fast Spatial Matching",
  booktitle    = "IEEE Conference on Computer Vision and Pattern Recognition",
  year         = "2007",
}

@article{johnson2019billion,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@article{jegou2010product,
  title={Product quantization for nearest neighbor search},
  author={Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={1},
  pages={117--128},
  year={2010},
  publisher={IEEE}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@inproceedings{dosovitskiy2021ImageWorth16x16,
  title = {An Image Is Worth 16x16 Words: {{Transformers}} for Image Recognition at Scale},
  booktitle = {9th International Conference on Learning Representations, {{ICLR}} 2021, Virtual Event, Austria, May 3-7, 2021},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  publisher = {{OpenReview.net}},
  keywords = {_Ã _lire},
  file = {/Users/jurie/Zotero/storage/ZAK653VT/Dosovitskiy et al_2020_An Image is Worth 16x16 Words.pdf;/Users/jurie/Zotero/storage/2WTC565X/2010.html}
}


@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@article{jafari2021survey,
  title={A survey on locality sensitive hashing algorithms and their applications},
  author={Jafari, Omid and Maurya, Preeti and Nagarkar, Parth and Islam, Khandker Mushfiqul and Crushev, Chidambaram},
  journal={arXiv preprint arXiv:2102.08942},
  year={2021}
}


@misc{kakaobrain2022coyo-700m,
  title         = {COYO-700M: Image-Text Pair Dataset},
  author        = {Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
  year          = {2022},
  howpublished  = {\url{https://github.com/kakaobrain/coyo-dataset}},
}
@misc{clipretrieval,
  title         = {Clip retrieval},
  author        = {Romain Beaumont},
  year          = {2022},
  howpublished  = {\url{https://github.com/rom1504/clip-retrieval}},
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{Esser2021TamingTF,
  title={Taming Transformers for High-Resolution Image Synthesis},
  author={Patrick Esser and Robin Rombach and Bj{\"o}rn Ommer},
  journal={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={12868-12878}
}
@article{karras2022elucidating,
  title={Elucidating the Design Space of Diffusion-Based Generative Models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={arXiv preprint arXiv:2206.00364},
  year={2022}
}


@article{Song2021DenoisingDI,
  title={Denoising Diffusion Implicit Models},
  author={Jiaming Song and Chenlin Meng and Stefano Ermon},
  journal={ArXiv},
  year={2021},
  volume={abs/2010.02502}
}

@inproceedings{babenko2016efficient,
  title={Efficient indexing of billion-scale datasets of deep descriptors},
  author={Babenko, Artem and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2055--2063},
  year={2016}
}

@article{Binkowski2018DemystifyingMG,
  title={Demystifying MMD GANs},
  author={Mikolaj Binkowski and Danica J. Sutherland and Michal Arbel and Arthur Gretton},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.01401}
}

@article{liu2022pseudo,
  title={Pseudo numerical methods for diffusion models on manifolds},
  author={Liu, Luping and Ren, Yi and Lin, Zhijie and Zhao, Zhou},
  journal={arXiv preprint arXiv:2202.09778},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{brock2018large,
  title={Large scale GAN training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@inproceedings{Lin2014MicrosoftCC,
  title={Microsoft COCO: Common Objects in Context},
  author={Tsung-Yi Lin and Michael Maire and Serge J. Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
  booktitle={ECCV},
  year={2014}
}

@techreport { pressmancrowson2022 ,
author = { John David Pressman and Katherine Crowson and Simulacra Captions Contributors } ,
year = 2022 ,
title = { Simulacra Aesthetic Captions } ,
institution = { Stability AI } ,
type = {} ,
number = { Version 1.0 } ,
note = {\ url { https://github.com/JD-P/simulacra-aesthetic-captions }}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}
@misc{stablediffusion2022,
  title = {\href{https://stability.ai/blog/stable-diffusion-public-release}{Stable Diffusion}},
}

@misc{openaipremitigate,
  title = {\href{https://openai.com/blog/dall-e-2-pre-training-mitigations/}{Pre-training Mitigations for DALLE2}},
}

@misc{dayma2021dallemini,
  title = {\href{https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mini-Explained--Vmlldzo4NjIxODA?galleryTag=intermediate/}{DALL-E Mini}},
  author={Boris Dayma et al},
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}
@misc{yu-2022-autofaiss,
  author     = {Paltz, Victor and
  				Yu, Bokai and 
  				Beaumont, Romain},
  title      = {Autofaiss},
  year       = {2022},
  publisher  = {GitHub},
  journal    = {GitHub repository},
  url        = {https://github.com/criteo/autofaiss}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu et al},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}

@article{kynkaanniemi2019improved,
  title={Improved precision and recall metric for assessing generative models},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{webster2019detecting,
  title={Detecting overfitting of deep generative networks via latent recovery},
  author={Webster, Ryan and Rabin, Julien and Simon, Loic and Jurie, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11273--11282},
  year={2019}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{simon2019revisiting,
  title={Revisiting precision and recall definition for generative model evaluation},
  author={Simon, Lo{\"\i}c and Webster, Ryan and Rabin, Julien},
  journal={arXiv preprint arXiv:1905.05441},
  year={2019}
}

@article{Johnson2021BillionScaleSS,
  title={Billion-Scale Similarity Search with GPUs},
  author={Jeff Johnson and Matthijs Douze and Herv{\'e} J{\'e}gou},
  journal={IEEE Transactions on Big Data},
  year={2021},
  volume={7},
  pages={535-547}
}

@inproceedings{xiaoyun_randomproj,
 author = {Li, Xiaoyun and Li, Ping},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Random Projections with Asymmetric Quantization},
 url = {https://proceedings.neurips.cc/paper/2019/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf},
 volume = {32},
 year = {2019}
}



@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8110--8119},
  year={2020}
}

@article{kynkaanniemi2022role,
  title={The Role of ImageNet Classes in Fr$\backslash$'echet Inception Distance},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Aittala, Miika and Aila, Timo and Lehtinen, Jaakko},
  journal={arXiv preprint arXiv:2203.06026},
  year={2022}
}

@article{sajjadi2018assessing,
  title={Assessing generative models via precision and recall},
  author={Sajjadi, Mehdi SM and Bachem, Olivier and Lucic, Mario and Bousquet, Olivier and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1806.00035},
  year={2018}
}


@article{borji2019pros,
  title={Pros and cons of gan evaluation measures},
  author={Borji, Ali},
  journal={Computer Vision and Image Understanding},
  volume={179},
  pages={41--65},
  year={2019},
  publisher={Elsevier}
}


@misc{midjourney,
  howpublished = {\url{https://www.midjourney.com/}},
}

@article{cherti2022reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  journal={arXiv preprint arXiv:2212.07143},
  year={2022}
}


@article{OpenCLIP,
title={OpenCLIP Repository},
author={Ilharco, Gabriel and        Wortsman, Mitchell and
     Wightman, Ross and 
      Gordon, Cade and
      Carlini, Nicholas and
      Taori, Rohan and
     Dave, Achal and
     Shankar, Vaishaal and
     Namkoong, Hongseok and
     Miller, John and
     Hajishirzi, Hannaneh and
     Farhadi, Ali and 
    Schmidt, Ludwig},
  year={2021},
  month={July}
}