\begin{table*}[tb]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Dimension Reduction & Index Info & Memory (GB) & ~\eqref{eq:eval r int k} & IN Zero-shot Top-1 \\
\hline
Raw ViT-H-14 & - &  708 & 100 &  67.1 \\
\hline
$\mathcal{L}_{\textsc{SNIP}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 29.2 &  40.3 \\
\hline
$\mathcal{L}_{\textsc{SNIP}}$, $d=128$ & IVFPQ, M=16 &  4.2 & 49.5 &  48.7 \\
\hline
$\mathcal{L}_{\textsc{SNIP}}$, $d=32$ & IVFPQ, M=4 &  2.2 & 36.4 &  39.2 \\
\hline
$\mathcal{L}_{\textsc{MSE}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 43.1 &  30.6 \\
\hline
$\mathcal{L}_{\textsc{MSE}}$, $d=128$ & IVFPQ, M=16 &  4.2 & 50.1 &  42.3 \\
\hline
$\mathcal{L}_{\textsc{CLIP}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 32.1 &  40.2 \\
\hline
$\mathcal{L}_{\textsc{CLIP}}$, $d=32$ & IVFPQ, M=4 &  2.2 & 28.1 &  39.4 \\
\hline
$\mathcal{L}_{\textsc{CLIP}}$, $d=32$ & IVFPQ, M=8 &  2.9 & 35.5 &  42.2 \\
\hline
$\mathcal{L}_{\textsc{CLIP}}$, $d=8$ & IVFPQ, M=4 &  2.2 & 19.2 &  0.0 \\
\hline
OPQ, $d=56$ & AutoFaiss &  2.2 & 0.1 &  2.7 \\
\hline
OPQ, $d=112$ & AutoFaiss &  2.9 & 1.6 &  8.7 \\
\hline
OPQ, $d=168$ & AutoFaiss &  5.6 & 44.1 &  43.4 \\
\hline
- & IVFPQ, M=4 &  2.4 & 14.6 & 40.4 \\
\hline
- & IVFPQ, M=16 &  5.5 & 44.7 &  46.3 \\
\hline
\end{tabular}
\vspace*{1mm}
\caption{Comparisons of the k-NN accuracy (with k=5) of different networks and losses on ViT-H-14 (OpenClip~\cite{OpenClip}) for queries outside of the database vectors, against an exhaustive search. The compressed CLIP features have a dimensionality of $d$, and the number of chunks for product quantization is denoted by $M$.}
\label{tab:vith14 full analysis}
%\medskip
\end{table*}

\if0
\begin{table*}[tb]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multirow{3}{*}{SOC}  &Dimension Reduction & Index Info & Memory (GB) & ~\ref{eq:eval r int k} & IN Zero-shot Top-1 \\
\hline
&Raw ViT-H-14 & - &  708 & 100 &  67.1 \\
\hline
&$\mathcal{L}_{\textsc{SNIP}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 29.2 &  40.3 \\
\hline
&$\mathcal{L}_{\textsc{SNIP}}$, $d=128$ & IVFPQ, M=16 &  4.2 & 49.5 &  48.7 \\
\hline
&$\mathcal{L}_{\textsc{SNIP}}$, $d=32$ & IVFPQ, M=4 &  2.2 & 36.4 &  39.2 \\
\hline
&$\mathcal{L}_{\textsc{MSE}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 43.1 &  30.6 \\
\hline
&$\mathcal{L}_{\textsc{MSE}}$, $d=128$ & IVFPQ, M=16 &  4.2 & 50.1 &  42.3 \\
\hline
&$\mathcal{L}_{\textsc{CLIP}}$, $d=128$ & IVFPQ, M=4 &  2.2 & 32.1 &  40.2 \\
\hline
&$\mathcal{L}_{\textsc{CLIP}}$, $d=32$ & IVFPQ, M=4 &  2.2 & 28.1 &  39.4 \\
\hline
&$\mathcal{L}_{\textsc{CLIP}}$, $d=32$ & IVFPQ, M=8 &  2.9 & 35.5 &  42.2 \\
\hline
&$\mathcal{L}_{\textsc{CLIP}}$, $d=8$ & IVFPQ, M=4 &  2.2 & 19.2 &  0.0 \\
\hline
&OPQ, $d=56$ & Autofaiss &  2.2 & 0.1 &  2.7 \\
\hline
&OPQ, $d=112$ & Autofaiss &  2.9 & 1.6 &  8.7 \\
\hline
&OPQ, $d=168$ & Autofaiss &  5.6 & 44.1 &  43.4 \\
\hline
&- & IVFPQ, M=4 &  2.4 & 14.6 & 40.4 \\
\hline
&- & IVFPQ, M=16 &  5.5 & 44.7 &  46.3 \\
\hline
\end{tabular}
\caption{NN5 accuracy versus ground truth across networks/losses on ViT-H-14 for queries within the training set.}
\label{tab:vith14 full analysis}
%\medskip
\end{table*}

\fi