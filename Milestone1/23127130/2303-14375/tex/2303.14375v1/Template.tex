% Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{multicol,multirow}
\usepackage{color}


% \paperwidth=\dimexpr \paperwidth+6cm\relax
% \oddsidemargin=\dimexpr \oddsidemargin+2.9cm\relax
% \evensidemargin = \dimexpr \evensidemargin +2.9cm\relax
% \marginparwidth=\dimexpr \marginparwidth+1.7cm\relax
% \usepackage{xspace}
% \RequirePackage{todonotes}
% \newcommand{\yjcomment}[1]{\todo[color=green!10,size=\small,fancyline,author=Yajing]{#1}\xspace}
% \newcommand{\zrcomment}[1]{\todo[color=blue!10,size=\small,fancyline,author=Zhangrui]{#1}\xspace}


% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Knowledge-augmented Frame Semantic Parsing with \\ Hybrid Prompt-tuning}
%
% Single address.
% ---------------
\name{Rui Zhang$^\dag$, Yajing Sun$^\dag$ \thanks{$^\dag$ Contributed equally to this work.}, Jingyuan Yang, Wei Peng$^*$ \thanks{$^*$ Corresponding author.}}
\address{Artificial Intelligence Application Research Center, Huawei Technologies}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Frame semantics-based approaches have been widely used in semantic parsing tasks and have become mainstream. It remains challenging to disambiguate frame representations evoked by target lexical units under different contexts. Pre-trained Language Models (PLMs) have been used in semantic parsing and significantly improve the accuracy of neural parsers. However, the PLMs-based approaches tend to favor collocated patterns presented in the training data, leading to inaccurate outcomes. The intuition here is to design a mechanism to optimally use knowledge captured in semantic frames in conjunction with PLMs to disambiguate frames. We propose a novel Knowledge-Augmented Frame Semantic Parsing Architecture (KAF-SPA) to enhance semantic representation by incorporating accurate frame knowledge into PLMs during frame semantic parsing. Specifically, a Memory-based Knowledge Extraction Module (MKEM) is devised to select accurate frame knowledge and construct the continuous templates in the high dimensional vector space.
Moreover, we design a Task-oriented Knowledge Probing Module (TKPM) using hybrid prompts (in terms of continuous and discrete prompts) to incorporate the selected knowledge into the PLMs and adapt PLMs to the tasks of frame and argument identification. Experimental results on two public FrameNet datasets demonstrate that our method significantly outperforms strong baselines  (by more than +3$\%$ in F1),  achieving state-of-art results on the current benchmark. Ablation studies verify the effectiveness of KAF-SPA. 
\end{abstract}
%
\begin{keywords}
Frame Definition, Knowledge Probing Module, Knowledge Extraction Module, Hybrid Prompts
\end{keywords}

\section{Introduction}
\label{sec:intro}
%第一段：frame semantic 包含哪些任务，由于深度学习技术的发展，模型效果取得了很大的进步。
% Frame semantic parsing (FSP) \cite{das2014frame} is a fundamental task that contributes to many NLP applications such as dialogue systems \cite{chen2013unsupervised,gupta2021controlling}, machine reading comprehension \cite{guo2020frame}, and question answering \cite{shen2007using}. Generally, the FSP task is processed in a pipelined manner and consists of two subtasks: frame identification and argument identification.
% As shown in Figure \ref{fig:fsp}, the goal of FSP is to extract the frame semantic structure of the target word for a given sentence, as well as its corresponding roles.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{imgs/intro-color3.pdf}
    \caption{An illustration of the knowledge-augmented frame semantic parsing for a target word ``book". The black boxes represent the predicted frame and related arguments, and the blue boxes underneath represent the frame definitions. Proper frame definitions are beneficial for frame semantic parsing for given inputs. } 
    \label{fig:intro}
\end{figure}

Frame semantics defines the conceptual structure based on FrameNet \cite{baker1998berkeley,das2014frame}, capturing the background knowledge necessary for an agent to understand a situation. 
It is fundamental for many NLP applications such as dialogue systems \cite{chen2013unsupervised}, machine reading comprehension \cite{guo2020frame}, and question answering \cite{shen2007using}. 
The frame semantic parsing task aims at identifying semantic structure evoked in text, consisting of semantic frames and their associated arguments. It remains challenging to disambiguate frame representations triggered by the targeted lexical units in various aspects of contexts.  


Recent advances in semantic parsing can be attributed to Pre-trained Language Models (PLMs), which significantly improved the accuracy of neural parsers \cite{kalyanpur2020open, petroni2019language, li2021prefix}. 
Researches treat Frame-Semantic Parsing task as a classification \cite{das2014frame, kshirsagar2015frame, swayamdipta2017frame, bastianelli2020encoding, marcheggiani2020graph} or a generation problem \cite{kalyanpur2020open}. Specifically, \cite{kalyanpur2020open} showed that a pure generative encoder-decoder architecture handily beats the previous state-of-the-art in a FrameNet 1.7 parsing task.
However, these methods treat frames and arguments as discrete labels represented using one-hot embeddings, neglecting the natural bondage among frame elements that give meanings to utterances. 
In fact, FrameNet \cite{baker1998berkeley}, as a lexical database of concepts with annotated meanings based on semantic frames, defines events, relations, entities, and the relevant participants. Researches that learned from an integrated semantic space encompassing frame definition, frame elements, and frame-frame relationships can achieve better frame semantic parsing results \cite{jiang2021exploiting,su2021knowledge,zheng2022double}. 

Despite some progress achieved along this line, the fundamental issue of frame representation disambiguation remains unsolved.  
%non-relevant knowledge also introduces noise, which decreases the performance of the models. 
\begin{figure*}
    \centering
    \includegraphics[width=0.91\textwidth]{imgs/model-3.pdf}
    \caption{The overall architecture of the proposed KAF-SPA. KAF-SPA consists of two modules: the Memory-based Knowledge Extraction Module (MKEM) and the Task-oriented Knowledge Probing Module (TKPM).} %The Knowledge-augmented is responsible for selecting knowledge based on the input utterance and the whole frame definitions. The task-relevant Hybrid prompt module concates the continuous prompt and discrete prompts to generated frame and frame elements.}
    \label{fig:overall}
\end{figure*}
As shown in Figure \ref{fig:intro}, the target word ``book" is linked to two ambiguous frames: \textbf{Text} and \textbf{Reserving}. A PLMs-based approach favors the incorrect frame ``Text" based on our observations. A potential reason is that frequent collocations of ``book'' and related contexts depicting a ``book'' (as a literature of recording information) from the training data may account for the ill-classified frame label (``Text").   The intuition here is to design a mechanism leveraging additional information captured in the semantic frames of FrameNet to alleviate the issue. For example, secondary knowledge supporting an accurate selection of each frame (fonts appeared in the frame definition box in Figure \ref{fig:intro}) can be used by PLMs to create a desirable result during frame semantic parsing.       

%Based on the explanations provided for each frame, which emphasizes the ``entity" for the frame ``Text" while the ``Reserving" frame highlights the action ``brings". It's easy to distinguish the correct frame ``Reserving" for input text, which is beneficial for frame semantic parsing when incorporating  ``Reserving"-related knowledge into the PLMs.



%Suppose lacking understanding of the frame label's semantic information, the PLMs model tends to select the wrong frame ``Text" and identifies the wrong arguments accordingly, which appears at a higher frequency in training data. However, FrameNet defines different frames' explanations for each frame. The definition emphasizes the ``entity" for the frame ``Text" while the ``Reserving" frame highlights the action ``brings". It's easy to distinguish the correct frame ``Reserving" for input text, which is beneficial for frame semantic parsing when incorporating  ``Reserving"-related knowledge into the PLMs.
%Therefore, it is vital to incorporate accurate frame knowledge to enhance the interaction between utterance and frame definition and avoid introducing noise.

%%Suppose incorporating two candidate frame knowledge into the model, the PLMs model tends to select the wrong frame ``Text" and identifies the wrong arguments accordingly, which appears at a higher frequency in training data. However, he definition emphasizes the ``entity" for the frame ``Text" while the ``Reserving" frame highlights the action ``brings". It's easy to distinguish the correct frame ``Reserving" for input text, which is beneficial for frame semantic parsing when incorporating  ``Reserving"-related knowledge into the PLMs.
This paper proposes Knowledge-Augmented Frame Semantic Parsing Architecture (KAF-SPA) to enhance semantic representation and disambiguate semantic frames. 
Specifically, we design a Memory-based Knowledge Extraction Module (MKEM) to select the most relevant frame definitions and inject the latent knowledge into the PLMs with a continuous learnable knowledge vector. Furthermore, the Task-oriented Knowledge Probing Module (TKPM) is used to incorporate the selected knowledge into the PLMs and adapt PLMs to different subtasks.  Concretely, the knowledge-aware continuous prompt exploits the selected label semantics (from MKEM) to learn the semantic representation of the sentence. Meanwhile, the task-aware discrete prompt is conducted to adapt the PLMs to different frame semantic parsing subtasks.
% It is worth noting that we are the first to propose hybrid-prompt learning for the adaption of PLMs.
It is worth noting that we are the first to design hybrid prompts to the adaptation of PLMs in frame semantic parsing.
Finally, We conduct experiments on the FrameNet1.5 and FrameNet1.7 datasets with frame identification and arguments identification tasks. Experiment results demonstrate that our model achieves state-of-art in most metrics. The ablation studies also verify the effectiveness of the method.

% Moreover, the Task-oriented Hybrid Prompt (HYP) is conducted to capture the characteristics of different frame semantic parsing tasks as well as exploit the connections between them.

%第二段：由于深度学习技术的发展，目前xxxx工作。。这些传统的方法将framelabel或者。。当成一个one-hot向量，忽略了。。包含丰富的语义信息，这些信息可以用来干嘛【参考framenet】的论文。因此当前的一些研究通过融入knowledge信息来增强frame的信息。比如xxx方法采用concate的方法利用frame的信息，xxxx结合。。。提升模型的效果。然而由于frame信息比较大并且比较冗余，研究表明不相关的知识信息会降低模型的效果，现有的一些知识注入的方法大多关注于三元组的信息，对于frame的信息。。。因此
%第三段：memory network的重要性【】以及prompting的重要性，最后提出我们的方法以及contribution
%prompting方法有什么好处对于引入frame知识

% Typical FSP studies learn frame semantic patterns from exemplar sentences \cite{kshirsagar2015frame,yang2017joint,kalyanpur2020open}, while recent researches have introduced the ontological frame knowledge \cite{jiang2021exploiting,su2021knowledge,zheng2022double}. In addition, most previous works treat frame identification and argument identification independently \cite{fitzgerald2015semantic,peng2018learning,marcheggiani2020graph}, which neglect the interaction between subtasks.
% % \sfcomment{no relations}
% Despite the success of recent efforts on FSP, one of its key challenges is that models learned from limited exemplar are fallible and lack scalability in a few-shot scenario (as discussed in Section \ref{sec:}). Thus, it is necessary to introduce expert knowledge into the FSP process. However, expert knowledge might be incomplete, and undifferentiated knowledge injection can also lead to knowledge noise \cite{liu2016leveraging,zhang2021drop}.



% To address these issues, we propose a hybrid prompt-tuning model with Framenet knowledge injection. Our model leverage both discrete and continuous prompts, where the discrete prompt acts as an anchor for specific subtask, while the continuous prompt dynamically suggests knowledge related to the current subtask. Our model is constructed based on pre-train language models (PLMs) to leverage commonsense knowledge from large-scale pre-train corpus. Moreover, we introduce several auxiliary tasks for multi-task learning to enhance the interaction between different subtasks.
% \section{Related Work}
% \label{sec:related_work}
% % 按照introduction的逻辑需要讲单纯的frame怎么做的；加知识的frame怎么做的；Prompt这块应该要简单写一下

% % 纯Frame
% %Early research on frame semantic parsing
% % }\cite{swayamdipta2017frame} \cite{kshirsagar2015frame}
% % Different neural network architectures for FSP are also explored, of which the most widely used is the graph convolutional network (GCN). 
% Early frame semantic parsing methods \cite{das2014frame,kshirsagar2015frame,swayamdipta2017frame} were mainly based on linear classifier, which relied heavily on manual feature engineering to construct parameter space. With the rise of deep learning technology, approaches based on neural networks \cite{yang2017joint} with automatic feature and join learning tasks become the mainstream of the research field. The most widely use neural network architecture is the graph convolutional network (GCN), where GCNs are used to learn the syntactic dependency structures \cite{bastianelli2020encoding,marcheggiani2020graph}. These methods make full use of syntactic information and greatly improve the manual feature-based approaches.
% %With the rise of PLM in recent years, parsing frame semantics using Transformer-based model  is becoming a new trend.
% % Knowledge

% However, most previous works are learned from exemplar sentences and ignore the Framenet knowledge. Recent studies have introduced frame definitions \cite{jiang2021exploiting} and frame-frame semantic relationships \cite{su2021knowledge,zheng2022double} into models and demonstrated that these knowledge can effectively improve the model performance, especially on the frame identification task.

% % Prompt
% In addition, the PLM-based prompting model \cite{kalyanpur2020open} also shows potential and achieve state-of-the-art on the argument identification task. The prompting-based model transforms different NLP tasks into a cloze \cite{petroni2019language} or generation task \cite{li2021prefix}, and use the language model to probabilistically fill the unfilled information \cite{liu2021pre}.
% Nevertheless, it is a new challenge to introduce external knowledge into such model. Although some efforts \cite{han2021ptr,chen2022knowprompt} on knowledge injection have been made, the selection of related knowledge remains an open problem.

\section{Task Definition}
% 给定一个带有目标片段t的句子，FSP通常视为pipeline任务：1）frame identification：根据句子上下文预测当前target所唤起的框架；2）argument identification：识别上下文中与该框架有关的片段并预测其角色（也称为框架元素FE）。

Frame semantic parsing consists of \textbf{frame identification} and \textbf{argument identification} task. 
Given a sentence $X = \{w_0, w_1, \cdots, w_{n}\}$ and a target word\footnote{Referred as a lexical unit when appeared in the Framenet.} $w_t$ in $X$ , the frame identification task aims at predicting the frame $Y_{f}$ evoked by $w_t$ according to the sentence context, while the argument identification task aims at finding the frame-related spans $Y_{s}$ from the context and assigning their semantic roles $Y_{r}$.
In this paper, we introduce frame definitions $k_f$ and role definitions $k_r$ in the FrameNet as knowledge source $K$. 
Frame and role definitions refer to the descriptions of the frame and its corresponding roles, as shown in Figure \ref{fig:intro}. 
Specifically, $k_f$ is used in the frame identification task while $k_r$ is served in the argument identification task.


% FrameNet describes human cognitive experiences using structural \textbf{frames}. 
% %It is based on the assumption that people understand the world by performing mental operations on what they already know \cite{baker1998berkeley}. 
% A frame is associated with a set of \textbf{semantic roles} (also known as the frame element), and lexical units are able to evoke frames. Each frame and its corresponding semantic roles also have textual \textbf{definitions} that describe the event scenario and how these roles interact.%, as shown in Figure \ref{fig:intro}.

% % Framenet describes human co

% Given a sentence $X = \{w_0, w_1, \cdots, w_{n}\}$, a target word\footnote{Refer to the lexical unit when appears in the Framenet.} $w_t$ in $X$, and the frame definitions $k_f$ and the semantic role definitions $k_r$ as knowledge base $K=k_f \cup k_r$, frame semantic parsing is usually performed as a pipeline of tasks: (1) \textbf{frame identification}: predicting the frame $Y_{f}$ evoked by $w_t$ according to the sentence context. (2) \textbf{argument identification}: finding the frame-related spans $Y_{s}$ from the context and assigning their semantic roles $Y_{r}$.
% % \yjcomment{input is not corresponding with the proposed model? where is knowledge}

\section{Methods}
% 我们的模型，如图2所示，结合了离散prompt和连续prompt以分别利用PLM和Framenet知识库中的知识。给定输入句子X和LU w_t，我们首先检索可能与该LU关联的Frame知识（记为K=k_1...）,并采用mem net自适应地选择最相关的知识来构造连续prompt P_C。随后，我们为每个子任务显式的构造了离散提示P_D以引导模型理解其生成目标。最后，我们使用特殊符号"[t]"标记句子中的lexical unit，将连续/离散提示与其拼接后传入到T5模型进行prompt-tuning。

% Figure \ref{fig:overall} illustrates the overall framework of our model.

Figure \ref{fig:overall} illustrates the overall architecture of the proposed method. The model comprises a Memory-based Knowledge Extraction Module (MKEM) and a Task-oriented Knowledge Probing Module (TKPM). 
MKEM is responsible for selecting relevant frame knowledge from $K$ and constructing the continuous learnable knowledge vector $P_C$. TKPM accounts for integrating the selected latent knowledge into a PLM and adapting it to frame and argument identification tasks. Details of our methods are described as follows.


% Given the input sentence $X$ and target word $w_t$, the KMM module first apply a memory network to select the most relevant knowledge from $K$ to construct a continuous prompt $P_C$. Then, the discrete prompts $P_D$ are also constructed for each subtask to guide the model better understand its generating objectives. Finally, the THP module combines both prompts to perform prompt-tuning on large-scale PLMs. 

% Our model is a unified generative framework for the frame semantic parsing problem.
% As illustrated in Figure \ref{fig:overall}, our model is based on the T5 \cite{raffel2020exploring} language model, and we combine hybrid prompts to leverage knowledge from both the PLMs and the Framenet ontology. 
% \yjcomment{too many "we","our"}

% \yjcomment{the model is composed of knowledge-augmented module and ...it need emphasis the use first}
% Given the input sentence $X$ and target word $w_t$, our model first retrieves the knowledge (denoted as $K=\{k_1, k_2, \cdots\}$) of frames that possibly associated with $w_t$, and apply a memory network to select the most relevant knowledge to construct a continuous prompt $P_C$. Then, discrete prompts $P_D$ are explicitly constructed for each subtask to guide the model better understand its generating objectives. Finally, we mark the lexical unit $w_t$ using special symbols "[t]" and "[/t]", then combine the $P_C$ and $P_D$ with the marked sentence $X$ as the input of the T5-based prompt-tuning model. Details of our method are described as follow.

% 混合prompting

\subsection{Memory-based Knowledge Extraction Module}
Since undifferentiated knowledge injection will lead to the knowledge noise problems \cite{liu2020k}, we introduce a simple yet effective end-to-end memory network \cite{sukhbaatar2015end} to extract the most related definition sentences from $K$ as a priori knowledge.

% Given knowledge spans $K=\{k_1, k_2, \cdots\}$ to be stored in memory and raw input $X$, KMM computes the representation of input and output memory by inner product with softmax
Given knowledge spans $K=\{k_1, k_2, \cdots\}$ to be stored in memory and raw input $X$, MKEM first computes the input memory weight $a_i$ by taking the inner product followed by a softmax, then forms the output memory representation as the continuous prompts $P_C$ using weighted sum, which is:
\begin{eqnarray}
    a_i &=& \text{Softmax}(\text{mean}(e(X))^\top (W_i \cdot \text{mean}(e(k_i)))) \\
    P_C &=& \sum_i a_i (W_o \cdot \text{mean}(e(k_i)))
\end{eqnarray}
where $W_i$ and $W_o$ are learnable parameters, $e(\cdot)$ indicates the shared embedding function, and the token-wise mean function $\text{mean}(\cdot)$ is applied to obtain the sentence vectors. 
% 无差别的知识注入会带来噪音。因此，我们采用end-2-end memory网络\cite{}从知识库K中选取
% In general, a target word may be associated with several frames, while introducing knowledge of all frames without distinction will lead to knowledge noise problems \cite{liu2020k}.
% Therefore, we introduce an end-to-end memory \cite{sukhbaatar2015end} to select the most related definition sentences from $K$ as a priori knowledge. 
% Given knowledge spans $K=\{k_1, k_2, \cdots\}$ to be stored in memory and raw input $X$, KMM first computes the input memory representation by taking the inner product followed by a softmax, following \cite{sukhbaatar2015end}:
% \begin{equation}
%     a_i = \text{Softmax}(\text{mean}(e(X))^\top (W_i \cdot \text{mean}(e(k_i))))
% \end{equation}
% where $W_i$ is learnable parameter, $e(\cdot)$ indicates the shared embedding representation function, and the mean function is applied on the token-wise vector to obtain the sentence representation. 
% Then, the output memory representation is formed using a weighted sum function as the continuous prompts $P_C$ for the hybrid-prompting module:
% \begin{equation}
%     P_C = \sum_i a_i (W_o \cdot \text{mean}(e(k_i)))
% \end{equation}
% where $W_o$ is trainable parameter.

Extracting knowledge from the entire $K$ is always time-consuming. In practice, only a relatively relevant subset $K' \in K$ is transferred into the MKEM. For the frame identification task, the definitions of frames associated with $w_t$ are retrieved as $K' \in k_f$. For target words that do not have a corresponding lexical unit in the FrameNet ontology, a simple cosine similarity function with GloVe embeddings is used to extract the most similar lexical units. For the argument identification task, we construct $K' \in k_r$ by fetching the definitions of semantic roles associated with a given frame.

% \subsection{Knowledge-based Continuous Prompts}
% % 我们首先从frame本体中检索与当前目标span有关的知识：对于出现在本体库中的目标词，我们将与其关联的每个候选Frame以及该Frame的定义进行拼接得到一则知识样本。在Framenet中，每一个目标span（通常也称为LU）往往可以对应多个候选框架。对于没有出现在Frame本体中的目标span，我们采用简单的GloVe向量余弦相似度来匹配与其最相近的LU，使用其知识传入模型。

% % 为什么这么做

% % We first retrieve knowledge related to the current lexical unit $w_t$ according to the Framenet ontology. 
% In general, lexical units can evoke multiple frames, . Therefore, we introduce a memory network to adaptively model frame knowledge.
% For the frame identification task, we retrieve the frames associated with the lexical unit $w_t$ as candidates, and concatenate the name and definition of each possible frame to obtain a knowledge span. For LUs that do not appear in the Framenet ontology, we use a simple cosine similarity algorithm with GloVe embeddings to match the most similar LUs for knowledge fetching. For the argument identification task, we construct the knowledge span directly using the names and definitions of the FEs associated with the given frame.
% % 这里，附录里面加个示例？

% % 给定原始输入X，和通过前述过程检索出的候选知识（记为K），模型采用一个单跳的memory网络\cite{}学习相关联的知识的提取。其中，输入memory表示
% Given the raw input $X$ and the retrieved candidate knowledge spans $K=\{k_1, k_2, \cdots\}$, our model uses a single-hop memory network \cite{sukhbaatar2015end} to extract the relevant knowledge. By taking the inner product followed by a softmax, we compute the match between $X$ and each knowledge span $k_i \in K$: 
% \begin{equation}
%     a_i = \text{Softmax}(\text{mean}(e(X))^\top (W_i \cdot \text{mean}(e(k_i))))
% \end{equation}
% where $W_i$ is learnable parameter, $e(\cdot)$ indicates the shared embedding representation function, and we apply the mean function on the token-wise vector to obtain the sentence representation. Then, we form the retrieved knowledge as continuous prompts $P_C$ using a weighted sum function:
% \begin{equation}
%     P_C = \sum_i a_i (W_o \cdot \text{mean}(e(k_i)))
% \end{equation}
% where $W_o$ is trainable parameter. We then fill the continuous prompting vector into the placeholder to import knowledge into the model along with the discrete prompt and raw input.

\subsection{Task-oriented Knowledge Probing Module}
The task-oriented knowledge probing module is proposed to leverage the common-sense knowledge from PLMs and inject the frame-related knowledge into the prompting model.

% Although pre-train language models have abundant common-sense knowledge, the pre-training objective of PLMs and our tasks are widely divergent.
% Although pre-train language models have abundant common-sense knowledge, it is necessary to introduce discrete prompt to eliminate the gap between the pre-training objective of PLMs and our tasks. Meanwhile, the frame-related knowledge should be effectively injected to the prompting model. Therefore, the hybrid prompt module is proposed to leverage knowledge from both PLMs and the KMM.

Specifically, TKPM prepends a prefix for the PLMs to obtain $[P_C;P_D;Y]$, where $P_D=[\text{head}_i; X]$ is the discrete prompt.
Figure \ref{fig:prompts} depicts the prefix template $\text{head}_i$ and its corresponding $Y$ for different tasks: (1) For the frame identification task, $\text{head}_i$ is set to ``\textit{generate [frame\_name]:}" with the frame label $Y_f$ of $X$ as the target output. (2) For the argument identification task, $\text{head}_i$ is set to ``\textit{generate [argument\_name] with [argument\_value] for} $\mathcal{F}$" where $\mathcal{F}$ is the given frame label. Its target output is formed as a sequence of span-role pairs: ``$y_s^1$ = $y_e^1$ $|$ $y_s^2$ = $y_e^2$ $|$ $\cdots$", where $y_s^i \in Y_s$ and $y_r^i \in Y_r$ are frame-related spans and semantic roles, respectively. Such a mechanism can effectively combine knowledge from different sources and allow the MKEM module to be trained while fine-tuning PLM parameters.

% Specifically, we use discrete prompts to identify different tasks. The prompt "generate [frame\_name]: $X$ $Y_f$" is applied for frame identification task with a token "[frame\_name]", as shown in Figure \ref{fig:prompts}. For the argument identification task, the prompt "generate [argument\_name] with [argument\_value] for $\mathcal{F}$: $X$ $[y_s^i=y_r^i]_n$" is added with specials tokens "[argument\_name]" and "[argument\_value]", where $n$ is the size of arguments, $y_s^i \in Y_s$ and $y_r^i \in Y_r$ are frame-related span and FE role, respectively.

% To ensure the consistency of position encoding, the hybrid prompt module first combines a placeholder with the discrete prompt (denoted as $P_D$) to perform encoding, and then fills the placeholder with the continuous prompt $P_C$ before prompt-tuning. Such mechanism can effectively combine the continuous and discrete prompts, and simultaneously trains the KMM module while fine-tuning the PLM parameters. 

%However, the pre-training objective of PLMs and our tasks are widely divergent.
%Our model uses the same architecture to handle both frame and argument identification tasks, while their original task forms are widely divergent (classification and sequence labeling). Hence, it is necessary to construct discrete prompts as the task anchors. 

%Although pre-train language models have abundant common-sense knowledge, the pre-training objective of PLMs and our tasks are widely divergent. 
%Therefore, it is necessary to introduce discrete prompts to eliminate the gap between them.
% Hence, introducing  is necessary. \yjcomment{Therefore, It's necessary to introduce....}
%In this paper, we utilize prefix prompts \cite{li2021prefix} instead of cloze prompts \cite{petroni2019language} as they mesh well with the generation model \cite{liu2021pre}. Specifically, the prompt for frame identification is constructed as: "generate [frame\_name]: $\langle X \rangle $ $ \langle Y \rangle$", \yjcomment{why is $\langle  \rangle$} while the prompt for argument identification set as : "generate [argument\_name] with [argument\_value] for $ \langle F \rangle$: $\langle X \rangle$ $ \langle Y \rangle$", where $\langle X \rangle$, $ \langle Y \rangle$ and $ \langle F \rangle$ indicate the raw input, the target output, and the Frame label (only available for argument identification). $ \langle Y \rangle$ can be the gold label of target frame (for frame identification) or a sequence of FE pairs (for argument identification), as shown in Figure \ref{fig:prompts}. \yjcomment{please refer the description of UniGDD framework}

% For the frame identification task, $ \langle Y \rangle$ is the gold label of target frame (e.g. "[Cause\_change]"), while for the argument identification task $ \langle Y \rangle$ is a sequence of FE pairs (e.g. "I = [Agent] $|$ the number of guests = [Entity]").

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{imgs/prompts-2.pdf}
    \caption{Discrete prompt templates are constructed for two tasks respectively.}
    \label{fig:prompts}
\end{figure}

% 模型训练
% 模型通过maximum likelihood目标进行训练。给定训练样本e=(X, P, Y)，目标损失定义为blabla。其中theta为模型参数，X为原始输入，P为任务对应的

\subsection{Model Training}
% The model is trained with the maximum likelihood objective. Given a training example $e=(X, P_D, K, Y)$, our model first compute the continuous prompt $P_C$ through the memory network to extract relevant knowledge from $K$. Then, the objective $\mathcal{L}_\theta$ is defined as:
After constructing the hybrid prompts $P_C$ and $P_D$, we perform prompt-tuning on a PLM in an end-to-end manner. The model is trained with the maximum likelihood objective, defined as:
\begin{equation}
    \mathcal{L}_\theta = - \sum_{i=1}^n \log P_\theta(Y_i | Y_{<i}, X, P_C, P_D)
\end{equation}
where $\theta$ is the model parameters, $X$ represents the raw input, and $Y$ is the target sequence. $P_C$ and $P_D$ indicate continuous and discrete prompts, respectively.

To take full advantage of the prior FrameNet knowledge, we follow \cite{kshirsagar2015frame,zheng2022double} to pre-train the model using exemplar instances. We construct pre-train data for both tasks based on the exemplars, which helps the model obtain a better initial representation for both the frame and role labels. Then, we jointly fine-tune the parameters using original training data.

\section{Experiment}
\label{sec:exp}

\subsection{Datasets and Experimental Settings}
Two benchmark datasets\footnote{https://framenet.icsi.berkeley.edu/fndrupal/about}: FrameNet1.5 and FrameNet1.7 are used for evaluation. FrameNet1.5 defines 1,019 frames and 9,634 frame elements. FrameNet1.7 is an extended version of FrameNet1.5, which contains more fine-grained frames and exemplars, with a total of 1,221 frames and 11,428 frame elements. We follow the same splits of datasets as depicted in open-SESAME \cite{swayamdipta2017frame}. Besides, we follow the way \cite{kshirsagar2015frame,zheng2022double} in pre-training the model: initially using the exemplar instances followed by fine-tuning the model parameters using original training data.

% We initialize our model with pre-trained T5-based model, and adopt the implementation from Hugging Face Transformers. For training, we apply the AdamW optimizer with an inital learning rate of $5\times10^{-4}$ and a learning rate decay scheduler. We pre-train the model using exemplars for 1 epoch, and perform prompt-tuning for 3 epochs using training data. The hidden size of the memory network is set to 768.

We validate the proposed method based on a T5-base model \cite{raffel2020exploring}. The learning rates for pre-training and prompt-tunning are set to $5\times10^{-4}$ and $2\times10^{-4}$, respectively. We pre-train the model using exemplars for one epoch, followed by prompt-tuning for three epochs using training data. 

%The hidden size of the memory network is set to 768.

% \zrcomment{need to present the model details.}
% \yjcomment{add baselines description}
The baselines fall into two categories: (1) those don't use frame knowledge \cite{das2014frame,kalyanpur2020open,swayamdipta2017frame,bastianelli2020encoding,marcheggiani2020graph,yang2017joint}; (2) those utilize frame knowledge \cite{jiang2021exploiting,su2021knowledge,zheng2022double}. \cite{zheng2022double} introduce the frame-frame knowledge and design a double-graph based frames to improve the performances.
% Since the answer space of the frame identification task is constrained, we apply a mapping function to map the original output to the underlying categories.

\subsection{Empirical Results}

\begin{table*}[ht]
\resizebox{\textwidth}{!}{%
%   \begin{center}
    
    \begin{tabular}{| l | c | c | c | c | c | c | c | c | c | c |}
        \hline
        \multirow{4}{*}{\textbf{Model}} & \multicolumn{5}{c |}{\textbf{FrameNet1.5}} & \multicolumn{5}{c |}{\textbf{FrameNet1.7}} \\
        \cline{2-11}
        & \multicolumn{2}{c |}{\textbf{Frame Id}} & \multicolumn{3}{c |}{\textbf{Arg Id}} & \multicolumn{2}{c |}{\textbf{Frame Id}} & \multicolumn{3}{c |}{\textbf{Arg Id}} \\
        \cline{2-11}
       & \multicolumn{2}{c |}{Accuracy} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} & \multicolumn{2}{c |}{Accuracy} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1}\\
       \cline{2-3} \cline{7-8}
       & All & Amb.& & & & All & Amb. & & & \\
      \hline
      SEMAFOR \cite{das2014frame} (2014) & 83.6 & 69.2 & 65.6 & 53.8 & 59.1 & - & - & - & - & - \\
      open-SESAME \cite{swayamdipta2017frame} (2017) & 86.9 &  -  & 69.4 & 60.5 & 64.6 & 86.6 &  -  & 60.6 & 58.9 & 59.8 \\
      Yang and Mitchell \cite{yang2017joint} (2017) & 88.2 & 75.7 & 70.2 & 60.2 & 65.5 & - & - & - & - & - \\
      Bastianelli et al.\cite{bastianelli2020encoding} (2020) & 90.1 & - & 74.6 & 74.4 & 74.5 & - & - & - & - & - \\
      Marchegginiani and Titov \cite{marcheggiani2020graph} (2020) & - & - & 69.8 & 68.8 & 69.3 & - & - & - & - & - \\
      Transformer (Full-Gen) \cite{kalyanpur2020open} (2020) & - & - & - & - & - & 87.0 &  -  & 71 & 73 & 72\\
      Transformer (Multi-task) \cite{kalyanpur2020open} (2020) & - & - & - & - & - & 87.5 &  -  & 77 & 77 & 77\\
      FIDO \cite{jiang2021exploiting} (2021) & 91.3 & 81.0 & - & - & - & 92.1 & 83.8 & - & - & - \\
      Su et al. \cite{su2021knowledge} (2021) & 92.1 & 82.3 & - & - & - & 92.4 & 84.4 & - & - & - \\
      KID \cite{zheng2022double} (2022) & 91.7 &  -  & 71.7 & \textbf{79.0} & 75.2 & 91.7 &  -  & 74.1 & 77.3 & 75.6 \\
      \hline
      KAF-SPA & \textbf{92.4} & \textbf{86.6} & \textbf{78.9} & 77.9 & \textbf{78.4} & \textbf{93.6} & \textbf{89.1} & \textbf{81.9} & \textbf{80.7} & \textbf{81.3}\\
      \hline
    \end{tabular}}
    \caption{ Experiments results on the FrameNet1.5 and FrameNet1.7 datasets. ``-'' indicates that the baselines do not report the result. ``All'' indicates a test on the whole test data. ``Amb.'' describes a test on ambiguous test data with two or more candidate frames for a target word. }
    \label{tab:table_fn15}
%   \end{center}

\end{table*}

\begin{table}[ht]
\centering
\resizebox{0.85\linewidth}{!}{%
\begin{tabular}{|l|clccc|}
\hline
\multicolumn{1}{|c|}{\multirow{4}{*}{\textbf{Model}}} & \multicolumn{5}{c|}{\textbf{FrameNet1.5}}                                                                                                                                                 \\ \cline{2-6} 
\multicolumn{1}{|c|}{}                       & \multicolumn{2}{c|}{\textbf{Frame Id}} & \multicolumn{3}{c|}{\textbf{Arg Id}}                                                                                            \\ \cline{2-6} 
\multicolumn{1}{|c|}{}                       & \multicolumn{2}{c|}{Accuracy}                           & \multicolumn{1}{c|}{\multirow{2}{*}{Precision}} & \multicolumn{1}{c|}{\multirow{2}{*}{Recall}} & \multirow{2}{*}{F1}   \\ \cline{2-3}
\multicolumn{1}{|c|}{}                       & \multicolumn{1}{c|}{All}   & \multicolumn{1}{c|}{Amb.}  & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c|}{}                        &                       \\ \hline
KAF-SPA                                         & \multicolumn{1}{c|}{92.4}  & \multicolumn{1}{c|}{86.6}  & \multicolumn{1}{c|}{78.9}                       & \multicolumn{1}{c|}{77.9}                    & 78.4                  \\
w/o MKEM                                         & \multicolumn{1}{c|}{90.6}  & \multicolumn{1}{c|}{83.4}      & \multicolumn{1}{c|}{77.4}                       & \multicolumn{1}{c|}{77.0}                    & 77.2                  \\
w/o TKPM                                         & \multicolumn{1}{c|}{92.4}      & \multicolumn{1}{c|}{86.0}      & \multicolumn{1}{c|}{77.5}                           & \multicolumn{1}{c|}{76.2}                        &           76.9            \\
w/o PT                                         & \multicolumn{1}{c|}{91.0}  & \multicolumn{1}{c|}{78.7}      & \multicolumn{1}{c|}{77.5}                       & \multicolumn{1}{c|}{75.5}                    & 76.5                  \\ \hline
\multirow{4}{*}{}                            & \multicolumn{5}{c|}{\textbf{FrameNet1.7}}                                                                                                                                                 \\ \cline{2-6} 
                                             & \multicolumn{2}{c|}{\textbf{Frame Id}} & \multicolumn{3}{c|}{\textbf{Arg Id}}                                                                                            \\ \cline{2-6} 
                                             & \multicolumn{2}{c|}{Accuracy}                           & \multicolumn{1}{l|}{\multirow{2}{*}{Precision}} & \multicolumn{1}{c|}{\multirow{2}{*}{Recall}} & \multirow{2}{*}{F1}   \\ \cline{2-3}
                                             & \multicolumn{1}{c|}{All}   & \multicolumn{1}{c|}{Amb.}  & \multicolumn{1}{l|}{}                           & \multicolumn{1}{c|}{}                        &                       \\ \hline
KAF-SPA                                         & \multicolumn{1}{c|}{93.6}  & \multicolumn{1}{c|}{89.1}  & \multicolumn{1}{c|}{81.9}                       & \multicolumn{1}{c|}{80.7}                    & 81.3                  \\
w/o MKEM                                         & \multicolumn{1}{c|}{90.9}  & \multicolumn{1}{c|}{86.1}      & \multicolumn{1}{c|}{80.6}                       & \multicolumn{1}{c|}{80.7}                    & 80.7                  \\
w/o TKPM                    & \multicolumn{1}{c|}{93.5}      & \multicolumn{1}{c|}{88.7}      & \multicolumn{1}{c|}{80.0}                           & \multicolumn{1}{c|}{76.9}                        & \multicolumn{1}{c|}{78.5} \\
w/o PT                                         & \multicolumn{1}{c|}{91.2}  & \multicolumn{1}{c|}{77.6}      & \multicolumn{1}{c|}{76.0}                       & \multicolumn{1}{c|}{74.3}                    & 75.1                  \\ \hline

\end{tabular}}%
\caption{The results of the ablation study on model components. ``w/o MKEM'' indicates the study removing the memory-based knowledge extraction module. ``w/o TKPM'' illustrates a test leaving discrete prompts out in the task-oriented knowledge probing module and training two tasks separately. ``w/o PT'' indicates a study refraining using the exemplar-based pre-train process.}
\label{tab:ablation}
\end{table}
%这部分的重点1.说明评价的维度2.准确率预测结果比较高，说明。。。3.召回率虽然低，但是保持了准确率和召回率的平衡，相比KID模型。。。分析高准确率和低召回的问题所在。41.5和1.7的区别在于？需要参考以前文章的说明。
% For the frame identification (Frame Id) task, we follow the \textbf{accuracy} to calculate the ratio for the correct predicted frame. 
% \zrcomment{For ..., we apply the \textbf{accuracy} to evaluate the ratio of correctly predicted frame on both total and ambiguous (Amb.) test set.}
For the frame identification (Frame Id) task, we apply the \textbf{accuracy} to calculate the ratio of the correctly predicted frame on both total and ambiguous (Amb.) test data.
For the argument identification (Arg Id) task, we use \textbf{Precision}, \textbf{Recall} and \textbf{F1} to evaluate the quality of extracted spans and the according frame element roles. 
Table \ref{tab:table_fn15} shows the performance of the proposed method compared to the results from different baselines. 
From Table \ref{tab:table_fn15}, FIDO, \cite{su2021knowledge} and KID models perform considerably better than other baselines without the knowledge. 
Incorporating knowledge contributes both to the frame and argument identification performance consistently.
Compared with the knowledge-augmented strong baselines, our method achieves state-of-art in the frame identification task. 
The main result table (Table \ref{tab:table_fn15}) also shows that our method outperforms the best baseline by a wide margin in identifying ambiguous frames (86.6 vs. 82.3 for FrameNet1.5 and 89.1 vs. 84.4 for FrameNet1.7). 
Besides, in the arguments identification task, the proposed method significantly outperforms the best baselines: 3$\%$ in F1 of FrameNet1.5 and over 5$\%$ in the FrameNet1.7 dataset. The results confirm the capability of KAF-SPA in selecting/incorporating accurate knowledge and probing task-relevant knowledge in PLMs to improve frame semantic parsing performance. Another observation is that our method shows an inferior recall performance in FrameNet1.5, potentially due to the imbalanced class distributions in Framenet1.5. KID has a high recall performance but a low precision score, indicating that the model lacks the capability to differentiate false positive outcomes. 

\subsection{Ablation Study}

% \begin{table*}[h!]
%   \begin{center}
    
%     \begin{tabular}{|l|c |c |c |c |c |c |c |c|}
%         \hline
        
%         \multirow{3}{*}{\textbf{Model}} & \multicolumn{4}{c |}{\textbf{FrameNet1.5}} & \multicolumn{4}{c |}{\textbf{FrameNet1.7}} \\
%         \cline{2-9}
%         & \textbf{Frame Id} & \multicolumn{3}{c |}{\textbf{Arg Id}} & \textbf{Frame Id} & \multicolumn{3}{c |}{\textbf{Arg Id}} \\
%         \cline{2-9}
%       & Accuracy & Precision & Recall & F1 & Accuracy & Precision & Recall & F1\\
%       \hline
%       Ours & 92.4 [86.6] & 78.9 & 77.9 & 78.4 & 93.6 [89.1] & 81.9 & 80.7 & 81.3\\
%       - CP & 90.6 & 77.4 & 77.0 & 77.2 & 90.9 & 80.6 & 80.7 & 80.7\\
%       - PT & 91.0 & 77.5 & 75.5 & 76.5 & 91.2 & 76.0 & 74.3 & 75.1 \\
%       - CP \& PT & 85.6 & 71.7 & 66.2 & 68.8 & 85.7 & 71.0 & 66.2 & 68.6\\
%       \hline
%     \end{tabular}
%     \caption{Ablation Study.}
%     \label{tab:table1}
%   \end{center}
% \end{table*}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}

%1.去掉continuous 准确率降低比较多，说明引入知识的重要性 2.引入全部知识 各方面指标均会下降，表明引入所有的候选知识会对模型造成干扰 表明有选择地引入知识的重要性 
%2.此外，去掉使用原始句子预训练，效果会下降，这是因为exempler会对预训练模型进行微调，但是由于利用continuous knowledge，下降相比直接去掉CP较小。也同样说明了知识的重要性。

% We conduct an ablation test on the two datasets to investigate the influence of the continuous prompt, discrete prompt, and exemplar-based pretrained module. Table \ref{tab:ablation} displays the performance of ablating them respectively.
We conduct an ablation test on the two datasets to investigate the influence of the proposed modules and the exemplar-based pre-train process. Table \ref{tab:ablation} demonstrates the ablation results.

%\noindent
\textbf{w/o Memory-based Knowledge Extraction Module} 
%The Memory-based Knowledge Extraction Module is responsible for selecting accurate frame knowledge and injecting them into PLMs. 
In Table \ref{tab:ablation}, the performance drops over 1$\%$, indicating that selecting proper knowledge structures benefits the frame semantic parsing. Furthermore, the model performs better in all metrics than the baselines under the no-knowledge setting.

%\noindent
\textbf{w/o Task-oriented Knowledge Probing Module} 
Compared to the whole model, the ``w/o TKPM'' has a slight performance degradation, demonstrating that joint learning of the two subtasks helps improve the model's overall performance.
%In argument identification
Moreover, we also verify that the exemplar-based pre-train method is beneficial for improving frame semantic parsing.

\section{Conclusion}
\label{sec:conclusion}
This paper proposes KAF-SPA to enhance semantic representation and disambiguate semantic frames. Experimental results on two public FrameNet datasets demonstrate that our method outperforms strong baselines by a wide margin, achieve state-of-art results. In future work, we will explore effective ways to incorporate semantic information into pre-training for natural language understanding and reasoning.
% 备份消融实验表格
% \begin{table*}[h!]
%   \begin{center}
    
%     \begin{tabular}{|c |c |c |c |c |c |c |c |c|}
%         \hline
        
%         \multirow{3}{*}{\textbf{Model}} & \multicolumn{4}{c |}{\textbf{FN1.5}} & \multicolumn{4}{c |}{\textbf{FN1.7}} \\
%         \cline{2-9}
%         & \textbf{Frame Id} & \multicolumn{3}{c |}{\textbf{Arg Id}} & \textbf{Frame Id} & \multicolumn{3}{c |}{\textbf{Arg Id}} \\
%         \cline{2-9}
%       & Accuracy & Precision & Recall & F1 & Accuracy & Precision & Recall & F1\\
%       \hline
%       Ours & 92.4 & 78.9 & 77.9 & 78.4 & 93.6 & 81.9 & 80.7 & 81.3\\
%       w/o Continuous Prompts & 90.6 & 77.4 & 77.0 & 77.2 & 90.9 & 80.6 & 80.7 & 80.7\\
%       % w/o DP & & & & & & & &\\
%       w/o Pre-train & 91.0 & 77.5 & 75.5 & 76.5 & 91.2 & 76.0 & 74.3 & 75.1 \\
%       \hline
%     \end{tabular}
%     \caption{Ablation Study.}
%     \label{tab:table1}
%   \end{center}
% \end{table*}

% \begin{table}[h!]
%     \centering
%     \begin{tabular}{|l|c|c|c|c|}
%     \hline
%         \multirow{2}{*}{\textbf{Discrete Prompts}} & \textbf{Frame Id} & \multicolumn{3}{c|}{\textbf{Arg Id}} \\
%     \cline{2-5}
%         & Accuracy & Precision & Recall & F1 \\
%     \hline
%         prompt\_1 & & & & \\
%         prompt\_2 & & & & \\
%         prompt\_3 & & & & \\
%         prompt\_4 & & & & \\
%     \hline
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}

% \begin{table*}[h!]
%     \centering
%     \begin{tabular}{|l|l|}
%     \hline
%     \bf{Model} & \bf{Result} \\
%     \hline
%       T5 prompt-tuning (w/o knowledge) & \underline{\textbf{\color{blue}{I}}}$_{[\text{Argument: Author}]}$ need to \underline{\textbf{\color{red}{book}}}$_{\text{[Frame: Text; Argument: Text]}}$ \underline{\textbf{\color{blue}{for 4 rooms}}}$_\text{[Argument: Role]}$. \\
%       Ours (w/ knowledge) & \underline{\textbf{\color{blue}{I}}}$_{[\text{Argument: Client}]}$ need to \underline{\textbf{\color{red}{book}}}$_{\text{[Frame: Reserving]}}$ \underline{\textbf{\color{blue}{for 4 rooms}}}$_\text{[Argument: Services]}$.\\
%     \hline
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table*}

% \begin{table*}[htbp]
%     \centering
%     \begin{tabular}{c c c}
%     \hline
%     \textbf{Task} & \textbf{Input} & \textbf{Output} \\
%     \hline
%     Frame Id & generate [f\_name]: I want to [t] modify [/t] the number of guests. & [Cause\_change]\\
%     Role Pred (Auxiliary) & generate [a\_name] of [a\_val] for [Cause\_change]: I want to [t] modify [/t] the number of guests. [a_val] the number of guests & the number of guests = [Entity] \\ 
%     Argument Pred (Auxiliary) & generate [a\_val] for [Agent] of [Cause\_change]: I want to [t] modify [/t] the number of guests. & I = [Agent]\\
%     Argument Id & generate [a\_name] with [a\_val] for [Cause\_change]: & I = [Agent] | the number of guests = [Entity] \\
%     \hline
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table*}

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/example.pdf}
%     \caption{Caption}
%     \label{fig:my_label3}
% \end{figure}


% \begin{table*}[htbp]
% \centering
% \begin{tabular}{|l|l|l|
% }
% \hline
% \textbf{Task}     & \textbf{Input}                                                                           & \textbf{Output}              \\
% \hline
% \multirow{2}{*}{Frame Identification} & \textcolor{blue}{generate {[}frame\_name{]}}: I want to {[}t{]} modify {[}/t{]}  the number & \multirow{2}{*}{{[}Cause\_change{]}} \\
% &   of guests. & \\
% % \multirow{2}{*}{Role Prediction}  &
% %   \textcolor{blue}{generate {[}a\_name{]} of {[}a\_val{]} for} \textcolor{red}{{[}Cause\_change{]}}: I want to  &
% %   \\
% % \multirow{2}{*}{(Auxiliary)} & {[}t{]} modify {[}/t{]} the number of guests. {[}a\_val{]} the number of  & the number of guests = {[}Entity{]}\\
% % & guests & \\
  
% % Argument Prediction &
% %   \textcolor{blue}{generate {[}a\_val{]} for} \textcolor{red}{{[}Agent{]}} \textcolor{blue}{of} \textcolor{red}{{[}Cause\_change{]}}: I want to &
% %   \multirow{2}{*}{I = {[}Agent{]}} \\
  
% % (Auxiliary) & {[}t{]} modify {[}/t{]} the number of guests. & \\
  
% \multirow{2}{*}{Argument Identification} &
%   \textcolor{blue}{generate {[}argument\_name{]} with {[}argument\_val{]} for} \textcolor{red}{{[}Cause\_change{]}}:  &
%   I = {[}Agent{]} $|$ the number of  \\

% & I want to {[}t{]} modify {[}/t{]} the number of guests. & guests = {[}Entity{]}\\
  
% \hline
% \end{tabular}%
% \caption{Caption}
% \label{tab:my_labe2}
% \end{table*}

% \begin{table}[]
% \resizebox{\linewidth}{!}{%
% \begin{tabular}{| l | c | c | c | c | c |}
% \hline
% \multirow{4}{*}{Model} & \multicolumn{5}{c |}{FrameNet1.5}                                                                           \\
% \cline{2-6}
%                       & \multicolumn{2}{c | }{Frame Id} & \multicolumn{3}{c | }{Arg Id}                                                 \\
% \cline{2-6}
%                       & \multicolumn{2}{c |}{Accuracy} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} \\
% \cline{2-3}
%                       & All           & Amb.         &                            &                         &                     \\
% \hline
% Ours                                         & \multicolumn{1}{c|}{92.4}  & \multicolumn{1}{c|}{86.6}  & \multicolumn{1}{c|}{78.9}                       & \multicolumn{1}{c|}{77.9}                    & 78.4                  \\
% w/o KMM                                         & \multicolumn{1}{c|}{90.6}  & \multicolumn{1}{c|}{83.4}      & \multicolumn{1}{c|}{77.4}                       & \multicolumn{1}{c|}{77.0}                    & 77.2                  \\
% w/o TPM                                         & \multicolumn{1}{c|}{92.4}      & \multicolumn{1}{c|}{86.0}      & \multicolumn{1}{c|}{77.5}                           & \multicolumn{1}{c|}{76.2}                        &           76.9            \\
% w/o PT                                         & \multicolumn{1}{c|}{91.0}  & \multicolumn{1}{c|}{78.7}      & \multicolumn{1}{c|}{77.5}                       & \multicolumn{1}{c|}{75.5}                    & 76.5                  \\
% \hline
% \multirow{4}{*}{}      & \multicolumn{5}{c |}{FrameNet1.7}                                                                           \\
% \cline{2-6}
%                       & \multicolumn{2}{c |}{Frame Id} & \multicolumn{3}{c |}{Arg Id}                                                 \\
% \cline{2-6}
%                       & \multicolumn{2}{c |}{Accuracy} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} \\
% \cline{2-3}
%                       & All           & Amb.         &                            &                         &                     \\
% \hline
% T5-base Prompting      &               &              &                            &                         &                     \\
% \hline
% \multirow{2}{*}{+ Pre-train}           & 90.9          & 86.1         & 80.6                       & 80.7                    & 80.7                \\
%  &  (+x.x) &  (+x.x)  &  (+x.x)  &  (+x.x)  & (+x.x) \\
%  \hline
% \multirow{2}{*}{\, + TPM}                 &               &              &                            &                         &                     \\
%  &  (+x.x) &  (+x.x)  &  (+x.x)  &  (+x.x)  & (+x.x) \\
%  \hline
% \multirow{2}{*}{\, \, + KMM (Ours)}          & 93.6 & 89.1 & 81.9 & 80.7 & 81.3\\
%  &  (+x.x) &  (+x.x)  &  (+x.x)  &  (+x.x)  & (+x.x) \\
% \hline
% \end{tabular}%
% }
% \end{table}


\vfill\pagebreak


% \section{REFERENCES}
% \label{sec:refs}

% List and number all bibliographical references at the end of the
% paper. The references can be numbered in alphabetic order or in
% order of appearance in the document. When referring to them in
% the text, type the corresponding reference number in square
% brackets as shown at the end of this sentence \cite{C2}. An
% additional final page (the fifth page, in most cases) is
% allowed, but must contain only references to the prior
% literature.

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
% \bibliographystyle{IEEEbib}
% \bibliography{refs}

\begin{thebibliography}{10}

\bibitem{baker1998berkeley}
Collin~F Baker, Charles~J Fillmore, and John~B Lowe,
\newblock ``The berkeley framenet project,''
\newblock in {\em COLING 1998 Volume 1: The 17th International Conference on
  Computational Linguistics}, 1998.

\bibitem{das2014frame}
Dipanjan Das, Desai Chen, Andr{\'e}~FT Martins, Nathan Schneider, and Noah~A
  Smith,
\newblock ``Frame-semantic parsing,''
\newblock {\em Computational linguistics}, vol. 40, no. 1, pp. 9--56, 2014.

\bibitem{chen2013unsupervised}
Yun-Nung Chen, William~Yang Wang, and Alexander~I Rudnicky,
\newblock ``Unsupervised induction and filling of semantic slots for spoken
  dialogue systems using frame-semantic parsing,''
\newblock in {\em 2013 IEEE Workshop on Automatic Speech Recognition and
  Understanding}. IEEE, 2013, pp. 120--125.

\bibitem{guo2020frame}
Shaoru Guo, Ru~Li, Hongye Tan, Xiaoli Li, Yong Guan, Hongyan Zhao, and Yueping
  Zhang,
\newblock ``A frame-based sentence representation for machine reading
  comprehension,''
\newblock in {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, 2020, pp. 891--896.

\bibitem{shen2007using}
Dan Shen and Mirella Lapata,
\newblock ``Using semantic roles to improve question answering,''
\newblock in {\em Proceedings of the 2007 joint conference on empirical methods
  in natural language processing and computational natural language learning
  (EMNLP-CoNLL)}, 2007, pp. 12--21.

\bibitem{kalyanpur2020open}
Aditya Kalyanpur, Or~Biran, Tom Breloff, Jennifer Chu-Carroll, Ariel Diertani,
  Owen Rambow, and Mark Sammons,
\newblock ``Open-domain frame semantic parsing using transformers,''
\newblock {\em arXiv preprint arXiv:2010.10998}, 2020.

\bibitem{petroni2019language}
Fabio Petroni, Tim Rockt{\"a}schel, Sebastian Riedel, Patrick Lewis, Anton
  Bakhtin, Yuxiang Wu, and Alexander Miller,
\newblock ``Language models as knowledge bases?,''
\newblock in {\em EMNLP-IJCNLP}, 2019, pp. 2463--2473.

\bibitem{li2021prefix}
Xiang~Lisa Li and Percy Liang,
\newblock ``Prefix-tuning: Optimizing continuous prompts for generation,''
\newblock in {\em Proceedings of the 59th Annual Meeting of the Association for
  Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, 2021, pp. 4582--4597.

\bibitem{kshirsagar2015frame}
Meghana Kshirsagar, Sam Thomson, Nathan Schneider, Jaime~G Carbonell, Noah~A
  Smith, and Chris Dyer,
\newblock ``Frame-semantic role labeling with heterogeneous annotations,''
\newblock in {\em Proceedings of the 53rd Annual Meeting of the Association for
  Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing (Volume 2: Short Papers)}, 2015, pp. 218--224.

\bibitem{swayamdipta2017frame}
Swabha Swayamdipta, Sam Thomson, Chris Dyer, and Noah~A Smith,
\newblock ``Frame-semantic parsing with softmax-margin segmental rnns and a
  syntactic scaffold,''
\newblock {\em arXiv preprint arXiv:1706.09528}, 2017.

\bibitem{bastianelli2020encoding}
Emanuele Bastianelli, Andrea Vanzo, and Oliver Lemon,
\newblock ``Encoding syntactic constituency paths for frame-semantic parsing
  with graph convolutional networks,''
\newblock {\em arXiv preprint arXiv:2011.13210}, 2020.

\bibitem{marcheggiani2020graph}
Diego Marcheggiani and Ivan Titov,
\newblock ``Graph convolutions over constituent trees for syntax-aware semantic
  role labeling,''
\newblock in {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2020, pp. 3915--3928.

\bibitem{jiang2021exploiting}
Tianyu Jiang and Ellen Riloff,
\newblock ``Exploiting definitions for frame identification,''
\newblock in {\em Proceedings of the 16th Conference of the European Chapter of
  the Association for Computational Linguistics: Main Volume}, 2021, pp.
  2429--2434.

\bibitem{su2021knowledge}
Xuefeng Su, Ru~Li, Xiaoli Li, Jeff~Z Pan, Hu~Zhang, Qinghua Chai, and Xiaoqi
  Han,
\newblock ``A knowledge-guided framework for frame identification,''
\newblock in {\em ACL-IJCNLP (Volume 1: Long Papers)}, 2021, pp. 5230--5240.

\bibitem{zheng2022double}
Ce~Zheng, Xudong Chen, Runxin Xu, and Baobao Chang,
\newblock ``A double-graph based framework for frame semantic parsing,''
\newblock in {\em NAACL}, 2022, pp. 4998--5011.

\bibitem{liu2020k}
Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi~Ju, Haotang Deng, and Ping
  Wang,
\newblock ``K-bert: Enabling language representation with knowledge graph,''
\newblock in {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2020, vol.~34, pp. 2901--2908.

\bibitem{sukhbaatar2015end}
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et~al.,
\newblock ``End-to-end memory networks,''
\newblock {\em Advances in neural information processing systems}, vol. 28,
  2015.

\bibitem{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu,
\newblock ``Exploring the limits of transfer learning with a unified
  text-to-text transformer,''
\newblock {\em Journal of Machine Learning Research}, vol. 21, pp. 1--67, 2020.

\bibitem{yang2017joint}
Bishan Yang and Tom Mitchell,
\newblock ``A joint sequential and relational model for frame-semantic
  parsing,''
\newblock in {\em Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing}, 2017, pp. 1247--1256.

\end{thebibliography}

\end{document}
