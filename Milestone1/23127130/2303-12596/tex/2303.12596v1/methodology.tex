\section{Architecture and System Model}
\label{methodology}

Although QUIC has already standardised an extension for unreliable packet sending, the protocol requires \glspl{ack} to ensure correct functionality. While \gls{ack} packets assist in loss recovery and congestion control, they defy the true meaning of unreliable transmission. Furthermore, the receiver is encouraged to delay sending back \gls{ack} frames, which may lead to unpredictable behaviour. Finally, the co-existing nature of reliable and unreliable frames is non-existent at the transport layer, relegating all the responsibility and complexity to the application layer. This behaviour can be sub-optimal, especially for real-time and \gls{aoi}-oriented applications.

Therefore, the main novelty of this work is to introduce the concept of dynamic reliability, which seamlessly enables and disables reliable packet sending through tailored policies, achieving reduced traffic load when needed to prioritise transmission of fresh packets. The decision to transmit reliably or unreliably could depend on the characteristics of network and applications. Unreliable packets do not elicit an \gls{ack} and co-exist with its reliable counter-part at the transport layer. For example, switching to unreliable mode will be attractive for real-time, loss-tolerant applications that could yet still benefit from end-to-end stream multiplexing, security, and other features of QUIC, as compared to plain UDP.

We examine the performance of the proposed dynamic reliability framework using Mininet, and simulate both the end-to-end and intermediate nodes, as well as, the real-world network characteristics, in a setup depicted in Fig. \ref{fig:sim_architecture}. In this setup, the client live streams an HD video ($\approx 60$ frame-per-second) to the server with a variable send-rate dependant on the live-stream and network conditions. Furthermore, the links connecting the nodes are selected from Wi-Fi, mobile Sub-6GHz and \gls{mmwave} with properties described in Table \ref{tab:path_char}. To isolate the performance gain of dynamic reliability in the simulation, we negate the presence of other services, and reduce the load of the network to only the essential components of the live stream. We also consider bursty loss scenarios, modeling the connection as a Gilbert-Elliott two-state channel \cite{gilbert_elliot}. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/Single-Path-DRel.png}
    \caption{Illustration of Dynamic Reliability logic in a mobile network architecture. As the quality of the network improves, unreliable transmission is adopted. The favorability is determined by the reliability policy.}
    \label{fig:sim_architecture}
\end{figure}


\begin{table}[b]
    \caption{Path characteristics for different link technologies \cite{mmwave_bandwidth,mmwave_measurements,path_characteristics}}
    \centering
    \begin{tabular}{c|ccc}
        \toprule
         \multirow{2}{*}{\textbf{Parameter}} & \multicolumn{3}{c}{\textbf{Technology}}  \\
         & Sub-6GHz & Wi-Fi & mmWave (LoS) \\
         \midrule
         Capacity (Mb/s) & 1100 & 30 & 2500\\
         Delay (ms) & $27.4 \pm ~6.4$  & $20 \pm ~10$ & $2 \pm ~1$  \\
         Loss Ratio (Percent) & 0.1 & 0.7 & 0.1 \\ 
         \bottomrule
    \end{tabular}
    \label{tab:path_char}
\end{table}


\subsection{Dynamic Reliability}

The addition of extra \gls{ack} packets can increase congestion during traffic bursts, reducing the maximum load that a network can support. This has been observed, e.g. in WiFi connections, in which even short \gls{tcp} \gls{ack} packets on the uplink can significantly reduce downlink throughput~\cite{zubeldia2012averting} due to the contention for access to the channel. Furthermore, real-time, \gls{aoi}-oriented applications rarely require retransmission of stale frames, opting instead for the latest frames as they relatively hold much more value. This is a common assumption in the \gls{aoi} literature, and intuitively makes sense when we consider the immediate use of sensor readings~\cite{yates2021age}. 

To achieve dynamic reliability, we extend QUIC by adding a new frame type, which resembles the reliable frame, albeit a different frame type byte. This new frame flags \texttt{no-ack} and \texttt{no-retransmit} to represent an unreliable packet. It is important to note that the packet sequencing remains the same with unreliable and reliable flows, the only difference being that unreliable packets do no solicit an acknowledgement, and hence, are never retransmitted. 


However, as most congestion control mechanisms use \glspl{ack} to infer congestion and measure capacity, the lack of acknowledgements from the unreliable segment of transmission means that the congestion window may not be strictly accurate. Despite that, the unreliable transmission will still follow the rate presented by the congestion window, which places emphasis on fairness of the protocol with other traffic on the link. At the same time, adhering to a stale congestion window is sub-optimal, and the reliable segment might not be enough to get an accurate picture of the channel. We then need to introduce probing to update the congestion window and path measurements such as \gls{rtt}, preventing the use of stale feedback in the transmission of packets.

The features of the proposed dynamic reliability framework are as follows:
\begin{itemize}
    \item Permitting of per-packet assignment reliability through policies located at the transport layer.
    \item Ability to send reliable and unreliable packets concurrently along the same path, session or stream. This provides further granular control over the reliability of parallel, multiplexed and distinct traffic type transmissions an application may adopt through streams;
    \item No requirement for separate packet sequences between unreliable and reliable packets. This is the main enabler for unreliable and reliable packets to co-exist in the same session;
    \item Unreliable packets do not elicit \glspl{ack}, therefore, less network resources are consumed;
    \item Loose coupling of congestion control and loss recovery mechanisms; both \gls{ack} and non-\gls{ack} based mechanisms can be integrated.
    \item Maintained inter- and intra- flow fairness by adhering to the congestion control. 
\end{itemize}

\begin{figure*}[ht]
    \centering
    \includegraphics[scale=0.15,trim={0 2.5cm 0 6cm},clip]{images/sent_packets_burst}
    \caption{Normalised frequency of transmitted packets with burst and \gls{soa} loss values against the dynamic reliability logic for different network topologies.}\vspace{-0.4cm}
    \label{fig:sent_burst}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[scale=0.15,trim={0 2.5cm 0 6cm},clip]{images/backlogged_packets_burst}
    \caption{Normalised frequency of backlogged packets with burst and \gls{soa} loss values against the dynamic reliability logic for different network topologies.}
    \label{fig:backlog_burst}\vspace{-0.4cm}
\end{figure*}

\subsection{Reliability Policies}

The reliability policies can be tailored to fit the application, network or holistic constraints. Though, it is important to note that the policies perform at the transport layer and cannot be altered at the application level. The verdict of the policy is used to set the type byte of the frame to indicate its reliability status. Since the policy is ingrained in the QUIC protocol, it has access to a diversity of information available from the transport protocol e.g. \gls{rtt}, congestion window and bytes in-flight to name a few.

A number of reliability policies are explored in this work with varying levels of complexity and intelligence: the Naive, 20-80 split and 80-20 split policies use a static unreliability packet ratio, providing a performance baseline. On the other hand, the \gls{srtt}-based and loss-aware policies take into account the state of the network to guide the packet reliability assignment thus providing a smarter reliability policy.  We take the vanilla implementation of QUIC to be the benchmark for the dynamic reliability implementation.

Our first scenario follows a \textit{naive} approach in transmitting packets, with the purpose of highlighting its inadequacy in obtaining greater performance optimisation compared to more complex policies.
Following its name, the naive policy randomly flags $50\%$ of packets as reliable. The policies for subsequent scenarios are detailed below:

\subsubsection{80-20 Split} Similar to the Naive method, packets have an 80\% probability of being flagged as reliable.

\subsubsection{20-80 Split} The polar opposite of 80-20, where packets have a chance of being flagged as reliable 20\% of the time.

\subsubsection{SRTT-Based Logic}

Utilises the \gls{srtt} as a basis for appraising the network condition. The \gls{srtt} is calculated from reliable packets, adhering to the method used by QUIC to track the \gls{rtt} and its derivatives. If the latest \gls{rtt} is lower than the \gls{srtt}, it can be assumed that the network conditions are acceptable for marking packets as unreliable.

\subsubsection{Loss-Aware Logic}

Curated for bursty loss scenarios, this policy takes into account the exponentially weighted moving average \cite{ewma} of the session loss rate. The loss rate is shown in Eq. \ref{la_decision_making}, while Eq. \ref{smoothing-eq} adopts the exponential smoothing. Let $P_{s}$ be the packets that are sent, $P_{us}$ be the packets are unreliably sent and $P_{r}$ be the packets received which are not \gls{ack}-eliciting. The measurements are taken at $i = 1$, which serves as the start of the session.

\begin{equation}
\label{la_decision_making}
\lambda = \frac{\sum_{i=1}^{n-1} P_{s} - \sum_{i=1}^{n-1} P_{us}}{\sum_{i=1}^{n-1} P_{r}}
\end{equation}

\begin{equation}
\label{smoothing-eq}
 \omega_{t} = \alpha \lambda_{t-1} + (1 - \alpha) \omega_{t-1},
\end{equation}

where $n$ denotes the discrete sending times. $\alpha$ is the weighting constant $ 0 \leq \alpha \leq 1$, which prescribes the importance of the previous measurements. In a bursty scenario, the measurements change frequently, and past recordings hold little relative value. However, in order to detect a burst, some past measurements are required: as such, we set the discount value to 0.8. The real-time constraint $RT$ is set at 5\%, which is the maximum tolerable loss rate for a real-time application, where $\omega_{t} \leq RT$ permits unreliable sending.
