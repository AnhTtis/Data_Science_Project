{
    "arxiv_id": "2303.10275",
    "paper_title": "MoRF: Mobile Realistic Fullbody Avatars from a Monocular Video",
    "authors": [
        "Alexey Larionov",
        "Evgeniya Ustinova",
        "Mikhail Sidorenko",
        "David Svitov",
        "Ilya Zakharkin",
        "Victor Lempitsky",
        "Renat Bashirov"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "We present a new approach for learning Mobile Realistic Fullbody (MoRF) avatars. MoRF avatars can be rendered in real-time on mobile phones, have high realism, and can be learned from monocular videos. As in previous works, we use a combination of neural textures and the mesh-based body geometry modeling SMPL-X. We improve on prior work, by learning per-frame warping fields in the neural texture space, allowing to better align the training signal between different frames. We also apply existing SMPL-X fitting procedure refinements for videos to improve overall avatar quality. In the comparisons to other monocular video-based avatar systems, MoRF avatars achieve higher image sharpness and temporal consistency. Participants of our user study also preferred avatars generated by MoRF.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10275v1"
    ],
    "publication_venue": null
}