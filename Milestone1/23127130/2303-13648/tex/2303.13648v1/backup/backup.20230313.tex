% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{ACL2023}
\usepackage[]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{enumitem}
 \usepackage{graphicx}

\definecolor{wxjiao}{RGB}{18, 141, 21}
\newcommand{\wxjiao}[1]{\textcolor{wxjiao}{#1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Haoran Wu$^\dagger$ \quad Wenxuan Wang$^\dagger$  \quad Yuxuan Wan $^\dagger$\quad Wenxiang Jiao$^\ddagger$ \quad  Michael R. Lyu$^\dagger$\\
$^\dagger$Department of Computer Science and Engineering, The Chinese University of Hong Kong\\
$^\ddagger$Tencent AI Lab \\ {\asciifamily \normalsize \texttt{1155157061@link.cuhk.edu.hk} \quad \texttt{\{wxwang,yxwan9,lyu\}@cse.cuhk.edu.hk}} \\
}

\begin{document}
\maketitle
\begin{abstract}ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted lots of attention.  This paper evaluates ChatGPT on the Grammatical Error Correction (GEC) benchmark. By comparing the performance with widely-used commercial grammatical error correction software, such as Grammarly, and state-of-the-art models, such as GECToR. This study indicates that according to the commonly used $F_{0.5}$ metric, ChatGPT still underperforms those famous models that focus on grammatical error correction. However, based on our novel cross-validation method and human evaluation, ChatGPT is under-estimated: it is able to detect and correct most of the grammatical errors but tends to over re-writing. 
\end{abstract}

\section{Introduction}
As the current most popular AI language model developed by OpenAI, ChatGPT has attracted millions of registered users within just a few days of its launch, and its user base has now surpassed 100 million. One reason for ChatGPT to become a superstar in AI is due to its surprisingly good performance on various natural language processing~(NLP) tasks~\cite{bang2023M3ChatGPT}, including question answering~\cite{Omar2023ChatGPTVT}, text summarization~\cite{Yang202ChatGPT4Summary}, storytelling, machine translation~\cite{jiao2023ischatgpt}, logic reasoning~\cite{Frieder2023MathChatGPT}, code debugging~\cite{Xia2023ConversationalAP}, and so on. 

Besides the aforementioned tasks, ChatGPT is widely used for revising writing. However, previous works have not studied its ability for Grammatical Error Correction, and it still remains unclear to the NLP community to what extent is ChatGPT capable of revising text and correcting grammatical errors. To fill this research gap, we empirically study the Grammatical Error Correction ablility of ChatGPT by evaluating it on the CoNLL2014 task~\cite{Ng2014TheCS}, a dataset built for grammatical error correction task, and comparing its performance to Grammarly, a prevalent loud-based English typing assistant with 30 million users daily\cite{Grammarly_User}. With this study, we aim to answer a research question: Is ChatGPT a good Grammatical Error Correction system?

\iffalse
\begin{itemize}
    \item Can ChatGPT be a good Grammatical Error Correction software? 
    \item Under what condition does ChatGPT perform well?
    \item Will a combination of ChatGPT and Grammarly improve the performance on Grammatical Error Correction tasks?
\end{itemize}
\fi

To the best of our knowledge, this is the first study of ChatGPTâ€™s Grammatical Error Correction capabilities. The following are the major insights we have gained from the evaluations:
\begin{itemize}
    \item ChatGPT  get a significantly lower score in $F_{0.5}$ (53.1 on the CoNLL2014 task), compared to the state-of-the-art GEC model GECToR (60.8) and wildly used GEC software Grammarly (63.3).
    \item ChatGPT achieves a relatively high $F_{0.5}$ score on short sentences but a lower score on long sentences.
    \item Based on our cross-validation method and human annotation, we find that ChatGPT is able to detect and correct most of the grammatical errors but tends to over re-writing. 
\end{itemize}


\section{Background}
\subsection{ChatGPT}
\wxjiao{
ChatGPT is an intelligent chatbot powered by large language models developed by OpenAI. It has attracted great attention from industry, academia, and general public due to its strong ability in answering various follow-up questions, correcting inappropriate questions~\cite{Zhong2023CanCU}, and even refusing illegal questions.
While the technical details of ChatGPT has not been released systematically, it is known to be built upon InstructGPT~\cite{ouyang2022InstructGPT} which is trained using instruction tuning~\cite{Wei2021FinetunedLM} and reinforcement learning from human feedback~\cite[RLHF,][]{Christiano2017DeepRL}.
}
%ChatGPT, a conversational large language model developed by OpenAI, has attracted great attention. Encouragingly, different from prior public chatbots, ChatGPT is able to generate fluent and comprehensive responses to various human inquiries, and even correct inappropriate human questions~\cite{Zhong2023CanCU}. Although the technical details of ChatGPT is still not released, it is known to be  built upon InstructGPT~\cite{ouyang2022InstructGPT} that is trained using instruction tuning~\cite{Wei2021FinetunedLM} and reinforcement learning from human feedback(RLHF)~\cite{Christiano2017DeepRL}.

%\subsection{Grammarly}
%Grammarly is a prevalent cloud-based English typing assistant. It reviews spelling, grammar, punctuation, clarity, engagement, and delivery mistakes in English texts, detects plagiarism, and suggests replacements for the identified errors \cite{enwiki:1139043929}. As stated by Grammarly, every day, 30 million people and 50,000 teams around the world use Grammarly with their writing \cite{Grammarly_User}.

%\subsection{GECToR}
%GECToR \cite{omelianchuk-etal-2020-gector} is a state-of-the-art model on grammatical error correction and it is one of the top models in CoNLL2014 task. We adopted the weights pre-trained on RoBERTa. This is less famous for non-NLP researchers, but it stands for an important benchmark since it performs quite well (By the time this paper is written, it is the third-best language model in CoNLL2014 task) in the dataset we have chosen.


\begin{table*}[t!]
\centering
    \begin{tabular}{l| cc}
    \toprule
    \bf Type & \multicolumn{1}{c}{\bf Error} & \multicolumn{1}{c}{\bf Correction} \\ 
    \midrule
    Preposition &  I sat in the talk & I sat in on the talk \\
    Morphology  &  dreamed &  dreamt \\
    Determiner &   I like the ice cream &  I like ice cream  \\
    Tense/Aspect   &    I like play basketball  &  I like playing basketball \\
    Syntax   &  I have not the book  &  I do not have the book \\
    Punctuation  &  We met they talked and left & We met, they talked and left \\
    \bottomrule
    \end{tabular}
    \caption{Different types of error in grammatical error corrections}
    \label{tab:type}
\end{table*}

\subsection{Grammatical Error Correction}
\wxjiao{
Grammatical Error Correction (GEC) is a task of correcting different kinds of errors in text such as spelling, punctuation, grammatical, and word choice errors~\cite{Ruder_NLP-progress_2022}.
It is highly demanded as writing plays an important role in academic, work, and daily life.
Table~\ref{tab:type} presents the illustration of different grammatical errors borrowed from \newcite{Bryant2022GrammaticalEC} in a comprehensive survey on grammatical error correction. In general, grammatical errors can be roughly classified into three categories: omission errors, such as "on" in the first example; replacement errors, such as "dreamed" for "dreamt" in the second example; and insertion errors, such as "the" in the third example.
}

%Grammatical Error Correction (GEC) is the task of correcting different kinds of errors in text such as spelling, punctuation, grammatical, and word choice errors~\cite{Ruder_NLP-progress_2022}. This task is highly demanded as the writing plays an important role in academic, work, and daily life. 

%Bryant et al.\cite{Bryant2022GrammaticalEC} provided a comprehensive survey on grammatical error correction. Table~\ref{tab:type} lists their illustration of different grammatical errors. In general, grammatical errors can be further divided into three categories: replacement errors, such as "dreamed" for "dreamt" in the second example; omission errors, such as "on" in the first example; and insertion errors, such as "the" in the third example.


\iffalse
\begin{table}[]
\centering
    \begin{tabular}{l rr}
    \toprule
    \bf Error Type & \bf Error & \bf Correction \\ 
    \midrule
    Replacement & I like kiss you & I like kissing you \\
    Omission  &  I sat in the talk &  I sat in on the talk \\
    Insertion &  I like the ice cream & I like ice cream  \\
    \bottomrule
    \end{tabular}
    \caption{Different types of error in grammatical error corrections}
    \label{tab:type}
\end{table}
\fi


\wxjiao{
To evaluate the performance of GEC, researchers have built various benchmark datasets, which includes but are not limited to:
\begin{itemize}[leftmargin=10pt]
    \item \textbf{CoNLL-2014}: Given the short English texts written by non-native speakers, the task requires a participating system to correct all errors present in each text.
    \item \textbf{BEA-2019}: It is similar to CoNLL-2014 but introduces a new dataset, namely, the Write\&Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities \cite{Bryant2019TheBS}.
    \item \textbf{JFLEG}: It represents a broad range of language proficiency levels and uses holistic fluency edits to not only correct grammatical errors but also make the original text more native sounding~\cite{Tetreault2017JFLEGAF}.
\end{itemize}
}

\iffalse
To evaluate the performance of grammatical error correction, researchers have created various grammatical error correction tasks and corresponding datasets, including but not limited to:
\begin{itemize}
    \item CoNLL-2014, given short English texts written by non-native speakers of English, the task requires a participating system to correct all errors present in an essay.
    \item BEA-2019, similar to CoNLL-2014, but it introduction of a new dataset, the Write\&Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities \cite{Bryant2019TheBS}.
    \item JFLEG, which represents a broad range of language proficiency levels and uses holistic fluency edits to not only correct grammatical errors but also make the original text more native sounding \cite{Tetreault2017JFLEGAF}.
\end{itemize}
\fi


%\section{Methodology}
\section{ChatGPT as Grammatical Error Corrector}

\subsection{Experimental Setup}
\paragraph{Dataset.}
We evaluate the ability of ChatGPT in grammatical error correction on the CoNLL2014 task\cite{Ng2014TheCS} dataset. The dataset is composed by short paragraphs that are written by non-native speakers of English, accompanied with the corresponding annotations on the grammatical errors.
We pulled 100 sentences from official-combined test set in the alternate folder of the dataset sequentially.


\paragraph{Evaluation Metric.} 
To evaluate the performance of GEC, we adopt three metrics that are widely used in literature, namely, Precision, Recall, and $F_{0.5}$ score. Among them, $F_{0.5}$ score combines both Precision and Recall, where Precision is assigned a higher weight~\cite{enwiki:1139808388}. Specifically, the three metrics are expressed as below:
\begin{align}
    &\mathrm{Precision} = \frac{TP}{TP + FP}, \\
    &\mathrm{Recall} = \frac{TP}{TP + FN}, \\
    &\mathrm{F_{0.5}} = \frac{\rm 1.25\times Precision\times Recall}{\rm 0.25\times Precision + Recall},
\end{align}
where $TP$, $FP$ and $FN$ represents the true positives, false positives and false negatives of the predictions, respectively.
We use the scoring program provided by CoNLL2014 official but adapt it to be compatible with the latest Python environment.


\begin{table}[t!]
\centering
    \begin{tabular}{l ccc}
    \toprule
    \bf System & \bf Precision & \bf Recall & \bf $F_{0.5}$\\ 
    \midrule
    GECToR & \bf 71.2 & 38.4 & 60.8 \\
    Grammarly & 67.3 & 51.1 & \bf 63.3 \\
    \hline
    ChatGPT & 51.2 & \bf 62.8 & 53.1\\
    \bottomrule
    \end{tabular}
    \caption{Scores of all sentences corrected by GECToR, Grammarly, and ChatGPT.}
    \label{tab:table1}
\end{table}



\begin{table*}[t!]
\centering
    \begin{tabular}{l ccc ccc ccc}
    \toprule
    \multirow{2}{*}{\bf System} & \multicolumn{3}{c}{ \bf Short Sentence} & \multicolumn{3}{c}{ \bf Medium Sentence} & \multicolumn{3}{c}{\bf Long Sentence}\\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
     & Precision & Recall & $F_{0.5}$ & Precision & Recall & $F_{0.5}$ & Precision & Recall & $F_{0.5}$\\
    \midrule
    GECToR & 76.9 & 38.5 & 64.1  & 68.8 & 37.5 & 58.9 & 71.8 & 38.9 & 61.5\\
    Grammarly & 62.5 & 60.6 & 62.1  & 68.9 & 56.0 & 65.9 & 67.3 & 45.3 & 61.4\\
    \hline
    ChatGPT & 58.5 & 66.7 & 60.0  & 48.7 & 60.7 & 50.7 & 51.0 & 62.8 & 53.0 \\
    \bottomrule
    \end{tabular}
    \caption{Scores of shorter and longer sentences corrected by ChatGPT and Grammarly}
    \label{tab:table3}
\end{table*}



\paragraph{Baselines.}
In this report, we perform the GEC task on three systems, including:
\begin{itemize}[leftmargin=10pt]
    \item \textbf{ChatGPT}: We query ChatGPT manually rather than using some API due to the instability of ChatGPT. For example, when a query sentence resembles a question or demand, ChatGPT may stop the process of GEC but respond to the ``demand'' instead. After a few trials, we find a prompt that works well for ChatGPT:
    \begin{quote}
        \texttt{Do grammatical error correction on all the following sentences I type in the conversation.}
    \end{quote}
    We query ChatGPT with this prompt for each test sample.
    \item \textbf{Grammarly}: Grammarly is a prevalent cloud-based English typing assistant. It reviews spelling, grammar, punctuation, clarity, engagement, and delivery mistakes in English texts, detects plagiarism and suggests replacements for the identified errors \cite{enwiki:1139043929}. As stated by Grammarly, every day, 30 million people and 50,000 teams around the world use Grammarly with their writing \cite{Grammarly_User}.
    When querying Grammarly, we open a text file and paste all the test samples as separate paragraphs. We enable all the grammar correction in the setting and only ask it to correct the ones with correctness problems (\textcolor{red}{\underline{red underline}}), while leaving the clarity (\textcolor{blue}{\underline{blue underline}}), engagement (\textcolor{green}{\underline{green underline}}) and delivery (\textcolor{purple}{\underline{purple underline}}) unchanged. We iterate this process several times until there is no error detected by Grammarly.
    \item \textbf{GECToR}: Besides Grammarly, we also compare ChatGPT with a state-of-the-art model on grammatical error correction in research, i.e., GECToR \cite{Omelianchuk2020GECToRG}. GECToR also exhibits good performance on the CoNLL2014 task. We adopt the implementation based on the pretrained RoBERTa model. 
    %This is less famous for non-NLP researchers, but it stands for an important benchmark since it performs quite well (By the time this paper is written, it is the third-best language model in CoNLL2014 task) in the dataset we have chosen.
\end{itemize} 



%\subsection{Dataset}
%We compared the ability in Grammatical Error Correction on ChatGPT and Grammarly by using the dataset in the CoNLL2014 task\cite{ng-etal-2014-conll} and took the F0.5 score as the benchmark. The dataset contains sentences or short paragraphs that are written by non-native speakers of English and the corresponding annotations on the grammatical error.  We picked 100 sentences in the dataset sequentially. We asked ChatGPT with a certain prompt to let it do Grammatical Error Correction on each sentence. After a few attempts, we found that using the prompt: "Do grammatical error correction on all the following sentences I type in the conversation." is the most stable approach. For Grammarly, we opened a text file and pasted all the sentences as separate paragraphs. We enabled all the grammar correction in the setting, and only asked it to correct the ones with correctness problems (red underline), and left the clarity (blue underline), engagement (green underline) and delivery (purple underline) unchanged. We did this several times until there is no error detected by Grammarly.

%\subsection{Metrics}
%We used three scores as our benchmark: Precision, Recall ,and F0.5. Where Precision is calculated by \[ \frac{TP}{TP + FP}, \] Recall is calculated by \[ \frac{TP}{TP + FN}, \] and F0.5 is calculated by \[ \frac{1.25 * Precision * Recall}{0.25 * Precision + Recall}. \] The F0.5 score is the benchmark used for our final evaluation. It uses both precision and recall to measure the accuracy of the correction, and F0.5 weighs precision higher than recall \cite{enwiki:1139808388}.


%\section{Experiments}
%\subsection{Experimental Setup}
%We pulled 100 sentences from the no-alternate folder of the CoNLL2014 Grammatical Error Correction task dataset sequentially. Then we designed a short Python program to transfer the annotated dataset into raw sentences with grammatical errors without annotation. We did not design a API to feed the sentences to ChatGPT due to its unstable responding (When the sentence need to be translated is similar to a question or demand, ChatGPT may stop Grammatical Error Correction and respond to it instead). We also modified the scoring program given by CoNLL2014 official without changing its output, to enable it to run on latest Python versions without raising an error.



\subsection{Results and Analysis}
\paragraph{Overall Performance.}
Table~\ref{tab:table1} presents the overall performance of the three systems.
As seen, ChatGPT obtains the highest recall value, GECToR obtains the highest precision value, while Grammarly achieves a better balance between the two metrics and results in the highest $F_{0.5}$ score.
\wxjiao{
These results suggest that ChatGPT tends to correct as many errors as possible, which may lead to more overcorrections. Instead, GECToR corrects only those it is confident about, which leaves many errors uncorrected. Grammarly combines the advantages of both such that it performs more stably.
}


%Our results in Table~\ref{tab:table1} indicate that ChatGPT 
%Grammarly performs better than both ChatGPT and GECToR, while GECToR performs better than ChatGPT. 
%We corrected in total 100 sentences with all of the language models and compared the results. GECToR achieved the highest precision, while ChatGPT attained the highest recall, nevertheless, Grammarly performed well on both precision and recall, and therefore the F0.5 score. 
%The results indicate that ChatGPT tends to correct as many as it can, but may result in more over corrections; GECToR does quite the opposite, it tends to correct only the ones it is confident about, but leaves a lot of errors uncorrected; Grammarly performs more stably as it controls both false positive and false negative.



\paragraph{ChatGPT Performs Worse on Longer Sentences?}
\wxjiao{
To understand which kind of sentences ChatGPT are good at, we divide the 100 test sentences into three categories by their length, namely, Short: $(0,20]$, Medium: $(20,40]$, and Long: $(40, +\infty]$. Table~\ref{tab:table3} shows the results with respect to sentence length. As seen, the gap between ChatGPT and Grammarly is significantly bridged on short sentences. In contrast, ChatGPT performs much worse on those longer sentences, at least in terms of the existing evaluation metrics.
}

%We further investigate the grammatical error correction performance on different sentences length. Specifically, we sort our 100 test sentences according to the length of the original sentences and separated them into two subsets, short sentence set and long sentence set, each containing 50 sentences. Then we evaluate the performance of the three GEC systems on these two set.

%The result in Table~\ref{tab:table3} shows that although ChatGPT still falls behind GECToR and Grammarly, ChatGPT shows a different behavior: ChatGPT has a higher score when correcting shorter sentences but lower score on long sentences. This indicates that ChatGPT does have a worse performance when doing grammatical error correction on long sentences or paragraphs.

%has a lower difference with Grammarly when it comes to short sentences but a much higher difference for long sentences or paragraphs. Also, compared to itself, ChatGPT has a higher score when correcting shorter sentences. 
%


\iffalse
\begin{table*}[]
\centering
    \begin{tabular}{l ccc ccc}
    \toprule
    \multirow{2}{*}{\bf System} & \multicolumn{3}{c}{ \bf Short Sentence} & \multicolumn{3}{c}{ \bf Long Sentence} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7}
     & Precision & Recall & $F_{0.5}$ & Precision & Recall & $F_{0.5}$ \\
    \midrule
    GECToR & 65.6 & 36.8 & 56.8  & 73.0 & 38.8 & 62.1\\
    Grammarly & 63.3 & 58.5 & 62.3  & 69.0 & 48.8 & 63.7 \\
    \hline
    ChatGPT & 52.5 & 62.7 & 54.3  & 50.8 & 62.0 & 52.7 \\
    \bottomrule
    \end{tabular}
    \caption{Scores of shorter and longer sentences corrected by ChatGPT and Grammarly}
    \label{tab:table3}
\end{table*}
\fi



\begin{table}[]
\centering
    \begin{tabular}{l ccc}
    \toprule
    \bf System & \bf Precision & \bf Recall & \bf $F_{0.5}$ \\ 
    \midrule
    GERToR &  71.2 & 38.4 & 60.8 \\
    ~~~ + Grammarly & -5.9 &  +16.5 &  +2.1 \\
    \hline
    ChatGPT & 51.2 & 62.8 & 53.1 \\
    ~~~ + Grammarly &  +0.4 &  +0.8 & +0.5 \\
    \bottomrule
    \end{tabular}
    \caption{Scores of ChatGPT and Grammarly Correction on ChatGPT}
    \label{tab:table2}
\end{table}


\paragraph{ChatGPT Goes Beyond One-by-One Corrections.}

However, the above results may be biased since ChatGPT is more willing to  change the sentence structure or paraphrase the sentences, based on low Precision score and high Recall score. This will result in a lower $F_{0.5}$ score for ChatGPT, which under-estimate its ability in Grammatical Error Correction.

And based on our observation, we also noticed that ChatGPT tends to make more changes in structure and does more paraphrasing when the input is a longer sentence or a large paragraph. This could be the reason why ChatGPT gets a lower score when correcting longer sentences. 
Table~\ref{tab:system_example} shows an example from the three systems, where we can find that ChatGPT tends to make more changes in structure and does more paraphrasing when conducting grammatical error correction. This will lead to a low precision score and a low $F_{0.5}$ score.

\iffalse
\begin{table*}[]
\centering
\resizebox{1.0\textwidth}{!}{
    \begin{tabular}{l l}
    \toprule
    \bf System & \multicolumn{1}{c}{\bf Sentence} \\
    \midrule
    Source & For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise.\\
    Reference & For example, if exercising is helpful for a potential family disease, we can always look for more chances for the family to do exercise.\\
    \hline
    GECToR & For example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise.\\
    Grammarly & For example, if exercising is helpful for a family 's potential disease, we can always look for more chances for the family to go exercise.\\
    ChatGPT & For example, if exercise is helpful in preventing potential family diseases, we can always look for more opportunities for the family to exercise.\\
    \bottomrule
    \end{tabular}
    }
    \caption{Examples from different GEC systems}
    \label{tab:system_example}
\end{table*}
\fi


\begin{table*}[]
\centering
%\resizebox{1.0\textwidth}{!}{
    \begin{tabular}{l p{12cm}}
    \toprule
    \bf System & \multicolumn{1}{c}{\bf Sentence} \\
    \midrule
    Source & For \textcolor{red}{an} example , if exercising is helpful for family potential disease , we can always look for more chances for the family to go exercise .\\
    Reference & For example , if exercising \textcolor{red}{(OR exercise)} is helpful for \textcolor{red}{a potential family} disease , we can always look for more chances for the family to \textcolor{red}{do} exercise .\\
    \hline
    GECToR & For example , if exercising is helpful for family potential disease , we can always look for more chances for the family to go exercise .\\
    Grammarly & For example , if exercising is helpful for a family 's potential disease , we can always look for more chances for the family to go exercise .\\
    ChatGPT & For example , if exercise is helpful in preventing potential family diseases , we can always look for more opportunities for the family to exercise .\\
    \bottomrule
    \end{tabular}
%    }
    \caption{Examples from different GEC systems}
    \label{tab:system_example}
\end{table*}

To get a quantitative understanding of whether ChatGPT is a good grammatical error correction system, we follow \newcite{wang2022understanding} to conduct a human evaluation of  how the three systems perform on grammatical error correction. Specifically, we ask two annotators to annotate three kinds of issues on 20 sentences randomly sampled from our test set: 1) under-correction, which is the grammatical errors that are not found; 2) mis-correction, which is the grammatical errors that are found but are not corrected correctly. It can be either grammatically incorrect or semantically incorrect and 3) over-correction, which is the other changes that are beyond the changing in reference. As listed in Table~\ref{tab:system_count}, ChatGPT  has the least number of under-correction among the three systems and fewer number mis-correction compared with GECToR, indicating its good grammatical error correction ability. But its number of over-correction is much more than the other two systems, which can lead to a lower score on $F_{0.5}$.
 
\begin{table}[]
\centering
    \begin{tabular}{l ccc}
    \toprule
\bf System & \bf \#Under & \bf \#Mis & \bf \#Over \\
    \midrule
    GECToR & 13 & 4 & 0\\
    Grammarly & 14 & 0 & 1 \\
        \hline
    ChatGPT &  3 & 3 & 30\\
    \bottomrule
    \end{tabular}
    \caption{Number of Under Correction, Mis Correction and Over Correction from different GEC systems}
    \label{tab:system_count}
\end{table}


Due to the above issue, we introduced a novel method to evaluate the GEC ability with a cross-validate procedure. We ask ChatGPT and GECToR to do grammatical error correction with the same procedure mentioned above. After that, we input the generation produced by ChatGPT and GECTor to Grammarly, to see how many grammatical errors can be further detected and corrected by Grammarly. The result in Table~\ref{tab:table2}, Grammarly can still correct a sufficient amount of error after the correction of GERToR (+16 on Recall and +2.1 on $F_{0.5}$) while the improvement on ChatGPT is smaller (+0.8 on Recall and +0.5 on $F_{0.5}$). This indicates that ChatGPT is able to correct the grammatical error, despite its lower performance on $F_{0.5}$ score.




\paragraph{The Error of ChatGPT}

Although ChatGPT is under-estimate on the ability to grammatical error correction, we do find 
Grammarly could correct the output of ChatGPT further and therefore gain a higher score. There are in total 34 errors in 24 sentences corrected by Grammarly on the total 100 sentences that are output by ChatGPT. The precision, recall, and $F_{0.5}$ have all increased. The result in Table~\ref{tab:table2} indicated there are still grammatical errors left after the correction of ChatGPT.  We found ten sentences being corrected with punctuation problems, which is the majority of all corrected sentences. Grammarly tends to be more sensitive to punctuation problems, whereas ChatGPT does not. Yet those corrections done by Grammarly are not always correct. We manually undone the corrections on punctuation, and the $F_{0.5}$ score increased by 0.0015. Other than punctuation problems, Grammarly also corrected a few grammatical errors on articles, prepositions, and plurals. However, those corrections usually require Grammarly to do correction twice, take an example:
\begin{quote}
    ... constructs of the family and kinship \bf are a social construct, ...
\end{quote}, Grammarly first changed it to:
\begin{quote}
    ... constructs of the family and kinship \bf are a social constructs, ...
\end{quote}, then changed it to:
\begin{quote}
    ... constructs of the family and kinship \bf are social constructs, ...
\end{quote}, but it did correct some errors that ChatGPT failed to correct.
%We wrote a short Python program that shows the output of ChatGPT and the output corrected by Grammarly and ChatGPT, without telling the output source, and ask the researcher to pick the one more grammatically correct and overall natural.



\subsection{Discussion}

\section{Limitations and Future Works}

There are several limitations in this version, which will lead to future work.
\begin{itemize}
    \item More datasets. In this version, we only use the CoNLL-2014 test set and only randomly select 100 sentences to conduct the evaluation. In our future work, we will conduct experiments on more datasets.
    \item More Prompt and In-context Learning. In this version, we only use one prompt to query the ChatGPT and do not utilize the advanced technology from the in-context learning field, such as providing demonstration examples~\cite{brown2020gpt3} or providing chain-of-thought~\cite{Wei2022ChainOT}, which may underestimate the full potential of ChatGPT. In our future work, we will propose a novel in-context learning method for GEC to improve its performance.
    \item More evaluation metrics. In this version, we only adopt Precision, Recal and $F_{0.5}$ as evaluation metrics. In our future work, we will utilize more metrics, such as pre-training-based metrics~\cite{Gong2022RevisitingGE} to evaluate the performance.
\end{itemize}


\section{Conclusion}


% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}


\end{document}
