\subsection{Algorithm \varts}
\label{sec:bayes_unknown_algo}

Similarly to \cref{alg:bayes_known}, the key idea is to maintain a posterior distribution over the unknown mean arm rewards $\bmu$ and act optimistically with respect to samples from it. The challenge is that the reward variances $\bsigma^2$ are also unknown. To overcome this, we rely on the observation that the posterior distribution of $(\mu_i, \sigma_i^{-2})$ is Gaussian-Gamma when the prior is and the rewards are Gaussian. We represent the posterior hierarchically, in an equivalent form (\cref{lem:gauss_gam} in Appendix), as follows. The posterior distribution of the mean reward of arm $i$ in round $t$ is $\cN(\hmu_{t,i},\sigma_{t,i}^2)$, where $\hat \mu_{t, i}$ and $\sigma_{t, i}^2$ are the posterior mean and sampled variance, respectively. The variance is defined as $\sigma_{t,i}^2 = \frac{1}{\kappa_{t,i}\lambda_{t,i}}$, where $\kappa_{t,i} = O(N_t(i))$ and $\lambda_{t,i}$ is a posterior-sampled reward precision of arm $i$ in round $t$. The posterior distribution of $\lambda_{t,i}$ is $\text{Gam}(\alpha_{t,i},\beta_{t,i})$, where $\alpha_{t,i}$ and $\beta_{t,i}$ are its shape and rate parameters, respectively. In the first round, all posterior parameters are initialized to their corresponding prior values $(\mu_{0,i}, \kappa_{0,i}, \alpha_{0,i}, \beta_{0,i})$.

Our algorithm is presented in \cref{alg:bayes_unknown} and we call it \varts, because it adapts to the unknown reward variances of arms. The algorithm works as follows. In round $t$, it first samples the precision of each arm from its posterior, $\lambda_{t,i} \sim \text{Gam}(\alpha_{t,i},\beta_{t,i})$, and then it samples the mean arm reward from its posterior, $\tilde \mu_{t,i} \sim \cN(\hmu_{t,i},\frac{1}{\kappa_{t,i}\lambda_{t,i}})$. After that, the arm with the highest posterior-sampled mean is pulled, $A_t:= \arg\max_{i \in [K]}\tilde \mu_{t,i}$. Finally, the algorithm observes a stochastic reward of arm $A_t$, $x_{t,A_t} \sim \cN(\mu_{A_t},\sigma_{A_t}^2)$, and updates its posteriors (lines $9$--$18$ in \cref{alg:bayes_unknown}).

\begin{algorithm}[h]
  \caption{\varts: Gaussian-Gamma TS for unknown reward variances.}
  \label{alg:bayes_unknown}
  \begin{algorithmic}[1]
    \State \textbf{Inputs:} Prior means $\bmu_0$, prior precision $\bkappa_0$, prior shape $\balpha_0$, and prior rate $\bbeta_0$
    \State \textbf{Init:} $\forall i \in [K]: N_1(i):=0, \ \hmu_{1,i}:= \mu_{0,i}, \ \kappa_{1,i}:= \kappa_{0,i}, \ \alpha_{1,i}:= \alpha_{0,i}, \ \beta_{1,i}:= \beta_{0,i}, \ \bar{x}_{1,i}:= 0$. %\todob{$\bar{x}_{1,i} := 0$}
    \Statex \vspace{-0.05in}
    \For{$t = 1, \dots, n$} %\todob{Up to $n$. Not up to $T$.}
    		\State Posterior sampling: $\forall i \in [K]:$
      \State $\quad \lambda_{t,i}\sim\text{Gam}(\alpha_{t,i},\beta_{t,i}), \ \tilde \mu_{t,i} \sim \cN(\hmu_{t,i},\frac{1}{\kappa_{t,i}\lambda_{t,i}})$
        \State Pull: $A_t:= \arg\max_{i \in [K]}\tilde \mu_{t,i}$
    		\State Reward feedback: $x_{t,A_t} \sim \cN(\mu_{A_t},\sigma_{A_t}^2)$
    		\State Posterior updates: 
		%%%    
    		\For{$i = 1, \dots, K$}
			\State $N_{t+1}(i):= N_{t}(i) + \I{A_t = i}$    		
    			\State Posterior rate: $\beta_{t+1, i}:= \beta_{0,i} + {}$
       \\ \hspace{0.7in} $ \frac{1}{2}\sum_{s =1}^{t}\I{A_s = i}(x_{s,i} - \bar{x}_{t+1,i})^2 + {}$ %\todob{$\bar{x}_{s,i}$ should be $\bar{x}_{t + 1,i}$?}
       \\ \hspace{0.725in}$
    \frac{\kappa_{0,i} N_{t+1}(i) (\bar{x}_{t+1,i} - \mu_{0,i})^2 }{2(\kappa_{0,i} + N_{t+1}(i))}$ %\todob{$\bar{x}_{s,i}$ looks like a typo. - \red{don't think defining above makes sense, initialized to 0 so hopefully okay}}
  			\State Posterior shape: $ \alpha_{t+1, i}
  := \alpha_{0,i} + N_{t+1}(i)/2$,
  			\State Posterior precision: $ \kappa_{t+1, i}:= \kappa_{0,i} + N_{t+1}(i)$
  	\State Posterior mean:		
        \State ~~$\hmu_{t+1,i}:= \frac{\kappa_{0,i}\mu_{0,i} + N_{t+1}(i)\bar{x}_{t+1,i}}{\kappa_{0,i}+N_{t+1}(i)}$, where %\todob{It is strange that we use $\bar x_{t+1,i}$ (all the way above in the posterior rate) before we define it (below).}
  	\State ~~$\bar x_{t+1,i}:= \frac{1}{N_{t+1}(i)}\sum_{s=1}^{t} \I{A_{s}=i} x_{s,i}$
    		\EndFor
	\EndFor %\todob{It is strange that $\hat{\mu}_{t, i}$ is the only posterior quantity with the hat. We should explain this convention starting from \cref{sec:bayes_known}.}
    %
  \end{algorithmic}
\end{algorithm}
