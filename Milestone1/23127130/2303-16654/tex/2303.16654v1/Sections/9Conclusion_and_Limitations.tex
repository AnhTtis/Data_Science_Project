
\begin{figure}[t]
        \vspace{1em}
        \centering
        \includegraphics[width=8.45cm]{Sections/images/office_navigation.png}
        \vspace{-0.4em}
        \caption{\textbf{Navigation under uncertainty with two robots in the simulated office floorplan} \quad (a) Images from office used as inputs to learning (b) Learned planner improves cost compared to the non-learned planner. MR-LSP performs better over non-learned and learned baselines. (c) MR-LSP generally improves cost as the number of robots increase.}
        %\vspace{-0.9em}
        \label{fig:office1}
\end{figure}
\begin{figure}[t]
        \centering
        \includegraphics[width=8.45cm]{Sections/images/3_robots.png}
        \vspace{-0.4em}
        \caption{Increasing the number of PO-UCT samples improves performance for three robots.}
        \label{fig:3robots}
\end{figure}

\section{Conclusion}
In this work, we present Multi-Robot Learning over Subgoals (MR-LSP): a novel method for performant and reliable, learning-informed multi-robot navigation through partially-mapped environments.
Using learning to estimate the goodness of individual exploratory actions that enter unseen space, our multi-robot team is able to envision the expected long-horizon impact of each robot's actions and can thus coordinate behavior far into the future to quickly reach the unseen goal, outperforming both learned and non-learned strategies. However, the number of multi-robot actions grows rapidly with the number of robots, imposing a practical limitation on team size.
In future work, we would like to extend our model to support more complex and multi-stage tasks, effectively extending the model of Bradley et al.~\cite{bradley2021learning} to the multi-robot planning domain.

% Due to increase in number of combinatorial action as number of robot increase, the computational complexity for cost computation increases.

% Our approach is able to estimate the properties of unknown space and leverage that information for planning. Our multi-robot team envisions the impact of every robot's action in the multi-robot team far into the future and takes informed collective action that generally leads to the goal in shortest distance. 
% Although our approach supports multiple robots, as the number of robot increases, more sampling needs to be done for PO-UCT to compute the cost of collective-action which can be computationally intensive. However, we demonstrate good performance for upto 3 robots compared to other learned and non-learned baselines on real-time. In the future, we would like to support more complex, and multi-stage tasks \cite{bradley2021learning} for multiple robots. 