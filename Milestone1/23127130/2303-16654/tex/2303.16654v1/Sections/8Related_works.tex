\section{Related Works}
Multi-robot navigation in unknown environment is often modelled as a Decentralized POMDP (Dec-POMDP)~\cite{DECPOMDP_MAIN1,DECPOMDPMain2,DecPOMDPintractable}.
Owing to computational challenges in Dec-POMDP planning, dynamic programming~\cite{hansen2004dynamic} and heuristic search approaches~\cite{szer2012maa} are limited to comparatively short-horizon planning tasks.

\textbf{Learning for Multi-Robot Planning}\quad{}
Learning is frequently used to address the difficulties of planning under uncertainty. Many learning-informed approaches in this domain (e.g.,~\cite{gupta,richter1}) focus on single-robot planning and do not scale to larger and more complex environments. Multi-agent reinforcement learning has a long history in this domain \cite{lauer2000algorithm,matignon2012independent}, yet only with recent advances in deep reinforcement learning has it become possible to navigate in somewhat realistic environments \cite{marl, rl1, rl2, RLsurvey}. Still, though these approaches work well for small environments, they are often brittle to change~\cite{henderson2018rlmatters} and struggle to scale to large-scale environments at the scale of buildings.

\textbf{Action Abstraction for Multi-Robot Planning}\quad{}
To mitigate computational challenges, many approaches in this domain rely on a state or action abstraction to simplify planning. 
Temporally-extended \textit{macro-actions} are one such action abstraction that help to scale planning under uncertainty~\cite{MACROACTION1, MACROACTION2, MACROACTION3}. However, these approaches have not proven scalable to building sized environments. Some strategies~\cite{hoerger2019multilevel, amato2015scalable} use variants of Monte Carlo tree search for faster computation in POMDP for long-horizon planning, yet without direct access to a distribution over environments are limited in their ability to reason far into the future.
%though these approaches doesn't use learned representations of environment to navigate. Learning features of environment can help make informed decision by predicting the impact of an action.
Other approaches to multi-robot planning introduce \emph{topological action abstractions} to simplify planning~\cite{frontier-multirobot,topological-mr,frontier-mr-1}. Under these approaches, each robot is constrained to leave known space through different \textit{frontiers}, boundaries between known space and unknown space \cite{frontier-singlerobot}, or via paths belonging to different relative homology~\cite{BhattacharyaHomologyPathPlanning, bhattacharyaTopologicalConstraints}. Works on navigation using this abstraction generally uses greedy heuristic to select where the robot should navigate next and do not take into account the impact of an action over the longer horizon. 

The Learning over Subgoals Planning (LSP) approach~\cite{stein2018learning} uses both a model-based topological abstraction and supervised learning to improve navigation performance, yet is designed only with a single robot planning in mind.

