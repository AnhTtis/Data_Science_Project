\section{Layout Consistency}
\label{sec:app_consistency}


We conduct an experiment to measure the layout consistency between the input semantic layouts and output top-down renderings of the scenes. To this end, we render all 5515 bedroom scenes with our trained models from top-down views. To test the effects of the layout consistency loss, as introduced in Sec. 3.3 of the main document, we obtain two generated top-down images, one rendered from the model trained with and the other one trained without the layout consistency loss. We pair the top-down renderings with ground truth semantic labels and separate the obtained datasets into train and test splits using a ratio of 0.85. Then, we train a DeepLabv3 \cite{chen2017rethinking} semantic segmentation model to predict the ground truth semantic segmentations from the rendered town-down images. Essentially, the more consistent the layouts and the top-down renderings the easier it becomes for the segmentation model to learn. Therefore, better test performance likely indicates higher consistencies. In Tab. \ref{table:semantic}, we indeed observe an improved IoU numbers when training our model with layout consistency loss.

In addition, we conducted another experiment where we trained Faster R-CNN \cite{ren2015faster} on top-down renderings to detect instances w.r.t. the input layout and evaluate using average precision (AP) and average recall (AR) with the COCO evaluator. The consistency metrics are generally high and we observe improved numbers (AP: 0.774, AR: 0.809) against the model without the consistency loss (AP: 0.719, AR: 0.747) in Eq. 4 of the main paper.

\input{sections/tables/tab_semantic.tex}