@inproceedings{fu20213d,
  title={3D-FRONT: 3D Furnished Rooms with layOuts and semaNTics},
  author={Fu, Huan and Cai, Bowen and Gao, Lin and Zhang, Ling-Xiao and Wang, Jiaming and Li, Cao and Zeng, Qixun and Sun, Chengyue and Jia, Rongfei and Zhao, Binqiang and others},
  booktitle=ICCV,
  year={2021}
}

@article{liao2022kitti,
  title={KITTI-360: A Novel Dataset and Benchmarks for Urban Scene Understanding in 2D and 3D},
  author={Liao, Yiyi and Xie, Jun and Geiger, Andreas},
  journal=PAMI,
  year={2022}
}
@article{wei2023lego,
  title={LEGO-Net: Learning Regular Rearrangements of Objects in Rooms},
  author={Wei, Qiuhong Anna and Ding, Sijie and Park, Jeong Joon and Sajnani, Rahul and Poulenard, Adrien and Sridhar, Srinath and Guibas, Leonidas},
  journal={arXiv preprint arXiv:2301.09629},
  year={2023}
}
@article{paschalidou2021atiss,
  title={ATISS: Autoregressive Transformers for Indoor
Scene Synthesis},
  author={Paschalidou, Despoina and Kar, Amlan and Shugrina, Maria and Kreis, Karsten and Geiger, Andreas and Fidler, Sanja},
  journal=NEURIPS,
  year={2021}
}

@inproceedings{skorokhodov2022stylegan,
  title={StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and
Perks of StyleGAN2},
  author={Skorokhodov, Ivan and Tulyakov, Sergey and Elhoseiny, Mohamed},
  booktitle=CVPR,
  year={2022}
}

@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}

@article{binkowski2018demystifying,
  title={Demystifying MMD GANs},
  author={Bi{\'n}kowski, Miko{\l}aj and Sutherland, Danica J and Arbel, Michael and Gretton, Arthur},
  journal=ICLR,
  year={2018}
}

@article{heusel2017gans,
  title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal=NIPS,
  year={2017}
}

@inproceedings{niemeyer2021giraffe,
  title={GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{xue2022giraffe,
  title={GIRAFFE HD: A High-Resolution 3D-aware Generative Model},
  author={Xue, Yang and Li, Yuheng and Singh, Krishna Kumar and Lee, Yong Jae},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{devries2021unconstrained,
  title={Unconstrained Scene Generation with Locally Conditioned Radiance Fields},
  author={DeVries, Terrance and Bautista, Miguel Angel and Srivastava, Nitish and Taylor, Graham W and Susskind, Joshua M},
  booktitle=ICCV,
  year={2021}
}

@article{bautista2022gaudi,
  title={GAUDI: A Neural Architect for Immersive 3D Scene Generation},
  author={Bautista, Miguel Angel and Guo, Pengsheng and Abnar, Samira and Talbott, Walter and Toshev, Alexander and Chen, Zhuoyuan and Dinh, Laurent and Zhai, Shuangfei and Goh, Hanlin and Ulbricht, Daniel and others},
  journal=NEURIPS,
  year={2022}
}

@inproceedings{chan2022efficient,
 author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas and Tremblay, Jonathan and Khamis, Sameh and Karras, Tero and Wetzstein, Gordon},
  title={Efficient Geometry-aware 3D Generative Adversarial Networks},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{mescheder2018training,
  title={Which Training Methods for GANs do actually Converge?},
  author={Mescheder, Lars and Geiger, Andreas and Nowozin, Sebastian},
  booktitle=ICML,
  year={2018}
}

@inproceedings{ronneberger2015u,
  title={U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle=MICCAI,
  year={2015}
}

@inproceedings{peng2020convolutional,
  title={Convolutional Occupancy Networks},
  author={Peng, Songyou and Niemeyer, Michael and Mescheder, Lars and Pollefeys, Marc and Geiger, Andreas},
  booktitle=ECCV,
  year={2020}
}

@inproceedings{xu20223d,
  title={3D-Aware Image Synthesis via Learning Structural and Textural Representations},
  author={Xu, Yinghao and Peng, Sida and Yang, Ceyuan and Shen, Yujun and Zhou, Bolei},
  booktitle=CVPR,
  year={2022}
}

@article{schwarz2022voxgraf,
  title={VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids},
  author={Schwarz, Katja and Sauer, Axel and Niemeyer, Michael and Liao, Yiyi and Geiger, Andreas},
  journal=NEURIPS,
  year={2022}
}

@article{max1995optical,
  title={Optical models for direct volume rendering},
  author={Max, Nelson},
  journal=VCG,
  year={1995}
}

@inproceedings{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  booktitle=ECCV,
  year={2020}
}

@article{skorokhodov2022epigraf,
  title={EpiGRAF: Rethinking training of 3D GANs},
  author={Skorokhodov, Ivan and Tulyakov, Sergey and Wang, Yiqun and Wonka, Peter},
  journal=NEURIPS,
  year={2022}
}

@article{arad2021compositional,
  title={Compositional Transformers for Scene Generation},
  author={Arad Hudson, Dor and Zitnick, Larry},
  journal=NEURIPS,
  year={2021}
}

@article{goodfellow2014generative,
  title={Generative Adversarial Nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal=NIPS,
  year={2014}
}

@inproceedings{karras2019style,
  title={A Style-Based Generator Architecture for Generative Adversarial Networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{karras2020analyzing,
  title={Analyzing and Improving the Image Quality of StyleGAN},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=CVPR,
  year={2020}
}

@article{karras2021alias,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  journal=NEURIPS,
  year={2021}
}

@article{brock2018large,
  title={Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal=ICLR,
  year={2019}
}

@inproceedings{epstein2022blobgan,
  title={Blobgan: Spatially disentangled scene representations},
  author={Epstein, Dave and Park, Taesung and Zhang, Richard and Shechtman, Eli and Efros, Alexei A},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XV},
  pages={616--635},
  year={2022},
  organization={Springer}
}
@inproceedings{isola2017image,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired Image-To-Image Translation Using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{choi2018stargan,
  title={StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation},
  author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{sauer2022stylegan,
  title={StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets},
  author={Sauer, Axel and Schwarz, Katja and Geiger, Andreas},
  booktitle=SIGGRAPH,
  year={2022}
}

@inproceedings{hudson2021generative,
  title={Generative Adversarial Transformers},
  author={Hudson, Drew A and Zitnick, Larry},
  booktitle=ICML,
  year={2021}
}

@inproceedings{wang2018high,
  title={High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{shen2020interpreting,
  title={Interpreting the Latent Space of GANs for Semantic Face Editing},
  author={Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  booktitle=CVPR,
  year={2020}
}

@article{ling2021editgan,
  title={EditGAN: High-Precision Semantic Image Editing},
  author={Ling, Huan and Kreis, Karsten and Li, Daiqing and Kim, Seung Wook and Torralba, Antonio and Fidler, Sanja},
  journal=NEURIPS,
  year={2021}
}

@inproceedings{nguyen2019hologan,
  title={HoloGAN: Unsupervised Learning of 3D Representations From Natural Images},
  author={Nguyen-Phuoc, Thu and Li, Chuan and Theis, Lucas and Richardt, Christian and Yang, Yong-Liang},
  booktitle=ICCV,
  year={2019}
}

@article{nguyen2020blockgan,
  title={BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images},
  author={Nguyen-Phuoc, Thu H and Richardt, Christian and Mai, Long and Yang, Yongliang and Mitra, Niloy},
  journal=NEURIPS,
  year={2020}
}

@inproceedings{schwarz2020graf,
  title={GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis},
  author={Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas},
  booktitle=NEURIPS,
  year={2020}
}

@inproceedings{chan2021pi,
  title={Pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis},
  author={Chan, Eric R and Monteiro, Marco and Kellnhofer, Petr and Wu, Jiajun and Wetzstein, Gordon},
  booktitle=CVPR,
  year={2021}
}
@inproceedings{niemeyer2021campari,
  title={CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle=THREEDV,
  year={2021}
}

@article{zhou2021cips,
  title={CIPS-3D: A 3D-Aware Generator of GANs Based on Conditionally-Independent Pixel Synthesis},
  author={Zhou, Peng and Xie, Lingxi and Ni, Bingbing and Tian, Qi},
  journal={arXiv preprint arXiv:2110.09788},
  year={2021}
}
@inproceedings{gu2022stylenerf,
  author={Gu, Jiatao and Liu, Lingjie and Wang, Peng and Theobalt, Christian},
  title     = {StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis},
  booktitle = ICLR,
  year      = {2022},
}

@inproceedings{or2022stylesdf,
  title={StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation},
  author={Or-El, Roy and Luo, Xuan and Shan, Mengyi and Shechtman, Eli and Park, Jeong Joon and Kemelmacher-Shlizerman, Ira},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{deng2022gram,
  title={GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation},
  author={Deng, Yu and Yang, Jiaolong and Xiang, Jianfeng and Tong, Xin},
  booktitle=CVPR,
  year={2022}
}

@article{son2022singraf,
  title={SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene},
  author={Son, Minjung and Park, Jeong Joon and Guibas, Leonidas and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2211.17260},
  year={2022}
}

@inproceedings{johnson2017clevr,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{vidanapathirana2021plan2scene,
  title={Plan2Scene: Converting Floorplans to 3D Scenes},
  author={Vidanapathirana, Madhawa and Wu, Qirui and Furukawa, Yasutaka and Chang, Angel X and Savva, Manolis},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{nauata2020house,
  title={House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation},
  author={Nauata, Nelson and Chang, Kai-Hung and Cheng, Chin-Yi and Mori, Greg and Furukawa, Yasutaka},
  booktitle=ECCV,
  year={2020}
}

@inproceedings{nauata2021house,
  title={House-GAN++: Generative Adversarial Layout Refinement Network towards Intelligent Computational Agent for Professional Architects},
  author={Nauata, Nelson and Hosseini, Sepidehsadat and Chang, Kai-Hung and Chu, Hang and Cheng, Chin-Yi and Furukawa, Yasutaka},
  booktitle=CVPR,
  year={2021}
}

@article{wang2018deep,
  title={Deep Convolutional Priors for Indoor Scene Synthesis},
  author={Wang, Kai and Savva, Manolis and Chang, Angel X and Ritchie, Daniel},
  journal=SIGGRAPH,
  year={2018}
}

@inproceedings{wang2021sceneformer,
  title={SceneFormer: Indoor Scene Generation with Transformers},
  author={Wang, Xinpeng and Yeshwanth, Chandan and Nie{\ss}ner, Matthias},
  booktitle=THREEDV,
  year={2021}
}
@inproceedings{gao2022get3d,
  title={Get3d: A generative model of high quality 3d textured shapes learned from images},
  author={Gao, Jun and Shen, Tianchang and Wang, Zian and Chen, Wenzheng and Yin, Kangxue and Li, Daiqing and Litany, Or and Gojcic, Zan and Fidler, Sanja},
  booktitle={Advances In Neural Information Processing Systems},
  year={2022}
}
@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}
@inproceedings{ritchie2019fast,
  title={Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models},
  author={Ritchie, Daniel and Wang, Kai and Lin, Yu-an},
  booktitle=CVPR,
  year={2019}
}

@article{xu2022discoscene,
  title={DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis},
  author={Xu, Yinghao and Chai, Menglei and Shi, Zifan and Peng, Sida and Skorokhodov, Ivan and Siarohin, Aliaksandr and Yang, Ceyuan and Shen, Yujun and Lee, Hsin-Ying and Zhou, Bolei and others},
  journal={arXiv preprint arXiv:2212.11984},
  year={2022}
}

@inproceedings{denninger2020blender,
title = {BlenderProc: Reducing the Reality Gap with Photorealistic Rendering},
author = {Maximilian Denninger and Martin Sundermeyer and Dominik Winkelbauer and Dmitry Olefir and Tomas Hodan and Youssef Zidan and Mohamad Elbadrawy and Markus Knauer and Harinandan Katam and Ahsan Lodhi},
 booktitle = RSS,
 year = {2020},
}

@article{bahmani20223d,
  title={3D-Aware Video Generation},
  author={Bahmani, Sherwin and Park, Jeong Joon and Paschalidou, Despoina and Tang, Hao and Wetzstein, Gordon and Guibas, Leonidas and Van Gool, Luc and Timofte, Radu},
  journal={arXiv preprint arXiv:2206.14797},
  year={2022}
}

@article{xu2022pv3d,
  title={PV3D: A 3D Generative Model for Portrait Video Generation},
  author={Xu, Eric Zhongcong and Zhang, Jianfeng and Liew, Jun Hao and Zhang, Wenqing and Bai, Song and Feng, Jiashi and Shou, Mike Zheng},
  journal=ICLR,
  year={2023}
}

@inproceedings{park2019deepsdf,
  title={DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{mescheder2019occupancy,
  title={Occupancy Networks: Learning 3D Reconstruction in Function Space},
  author={Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{chen2019learning,
  title={Learning Implicit Fields for Generative Shape Modeling},
  author={Chen, Zhiqin and Zhang, Hao},
  booktitle=CVPR,
  year={2019}
}

@article{chen2017rethinking,
  title={Rethinking Atrous Convolution for Semantic Image Segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

@article{chen2023scenedreamer,
  title={SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections},
  author={Chen, Zhaoxi and Wang, Guangcong and Liu, Ziwei},
  journal={arXiv preprint arXiv:2302.01330},
  year={2023}
}

@article{lin2023infinicity,
  title={InfiniCity: Infinite-Scale City Synthesis},
  author={Lin, Chieh Hubert and Lee, Hsin-Ying and Menapace, Willi and Chai, Menglei and Siarohin, Aliaksandr and Yang, Ming-Hsuan and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2301.09637},
  year={2023}
}

@article{skorokhodov20233d,
  title={3D generation on ImageNet},
  author={Skorokhodov, Ivan and Siarohin, Aliaksandr and Xu, Yinghao and Ren, Jian and Lee, Hsin-Ying and Wonka, Peter and Tulyakov, Sergey},
  journal=ICLR,
  year={2023}
}

@article{deng20233d,
  title={3D-aware Conditional Image Synthesis},
  author={Deng, Kangle and Yang, Gengshan and Ramanan, Deva and Zhu, Jun-Yan},
  journal=CVPR,
  year={2023}
}

@inproceedings{cai2022pix2nerf,
  title={Pix2nerf: Unsupervised conditional p-gan for single image to neural radiance fields translation},
  author={Cai, Shengqu and Obukhov, Anton and Dai, Dengxin and Van Gool, Luc},
  booktitle=CVPR,
  year={2022}
}

@article{lin20223d,
  title={3d gan inversion for controllable portrait image animation},
  author={Lin, Connor Z and Lindell, David B and Chan, Eric R and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2203.13441},
  year={2022}
}

@article{nglod,
    title = {Neural Geometric Level of Detail: Real-time Rendering with Implicit {3D} Shapes}, 
    author = {Towaki Takikawa and
              Joey Litalien and 
              Kangxue Yin and 
              Karsten Kreis and 
              Charles Loop and 
              Derek Nowrouzezahrai and 
              Alec Jacobson and 
              Morgan McGuire and 
              Sanja Fidler},
    booktitle = CVPR,
    year = {2021}
}

@inproceedings{kilonerf,
  title={Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps},
  author={Reiser, Christian and Peng, Songyou and Liao, Yiyi and Geiger, Andreas},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{fastnerf,
  title={Fastnerf: High-fidelity neural rendering at 200fps},
  author={Garbin, Stephan J and Kowalski, Marek and Johnson, Matthew and Shotton, Jamie and Valentin, Julien},
  booktitle=CVPR,
  year={2021}
}