%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "David Rhead",
%%%     version         = "1.00",
%%%     date            = "17 Feb 1990",
%%%     time            = "17:00 GMT",
%%%     filename        = "test.bib",
%%%     address         = "Cripps Computing Centre,
%%%                        University of Nottingham,
%%%                        University Park,
%%%                        Nottingham,
%%%                        NG7 2RD,
%%%                        United Kingdom",
%%%     telephone       = "+44 602 484848 Ext 2670",
%%%     FAX             = "+44 602 588138",
%%%     checksum        = "05151 839 2908 25082",
%%%     email           = "David_Rhead at uk.ac.nott.vme (JANET)",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "bibliography, citation, references",
%%%     supported       = "no",
%%%     docstring       = "This BibTeX database file contains entries
%%%                        designed for testing whether a BibTeX style
%%%                        file lays references out as recommended by
%%%                        certain authorities.  (Note, however, that
%%%                        the BS 1629 examples are from the 1976
%%%                        edition.  The file needs updating to use
%%%                        examples from the 1989 edition instead.)
%%%
%%%                        The checksum field above contains a CRC-16
%%%                        checksum as the first value, followed by the
%%%                        equivalent of the standard UNIX wc (word
%%%                        count) utility output of lines, words, and
%%%                        characters.  This is produced by Robert
%%%                        Solovay's checksum utility.",
%%%  }
%%% ====================================================================
%% @COMMENT{Some other standard works describing conventions for citations
%%      and bibliographies}

@Book{Eco:1990,
  author = 	 "Umberto Eco",
  title = 	 "The Limits of Interpretation",
  publisher = 	 "Indian University Press",
  year = 	 1990}

@Inproceedings{Martin-90,
  author = 	 "Jannik Strötgen and Michael Gertz",
  title = 	 "Temporal Tagging on Different Domains: Challenges, Strategies, and Gold Standards",
  booktitle = "Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)",
  year = 	 "2012",
  month = 	 "may",
  date =     "23-25",
  pages = 	 "3746--3753",
  address =  "Istanbul, Turkey",
  editor = 	 "Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet U\v{g}ur Do\v{g}an and Bente Maegaard and Joseph Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis",
  publisher = "European Language Resource Association  (ELRA)",
  isbn = "978-2-9517408-7-7",
}

@Book{Chercheur-94,
  title =        "Case-Based Reasoning",
  author =       "J.L. Chercheur",
  publisher =    "Morgan Kaufman Publishers",
  year =         "1994",
  edition =      "2nd",
  address =      "San Mateo, CA",
}

@Article{CastorPollux-92,
  author =       "A. Castor and L. E. Pollux",
  title =        "The use of user modelling to guide inference and learning",
  journal =      "Applied Intelligence",
  volume =       "2(1)",
  pages =        "37--53",
  year =         "1992",
}

%fictitious reference
@Book{Superman-Batman-Catwoman-Spiderman-00,
  author =       "S. Superman and B. Batman and C. Catwoman and S. Spiderman",
  title =        "Superheroes experiences with books",
  journal =      "Journal journal journal",
  year =         2000,
  publisher =    "The Phantom Editors Associates",
  edition =      "20th",
  address =      "Gotham City",
}


%% @COMMENT{Some examples taken from document describing BS 1629}

@Book{hoel-71-whole,
  author =       "Paul Gerhard Hoel",
  title =        "Elementary Statistics",
  publisher =    "Wiley",
  year =         "1971",
  series =       "Wiley series in probability and mathematical
                 statistics",
  address =      "New York, Chichester",
  edition =      "3rd",
  note =         "ISBN 0~471~40300",
}

@Inbook{hoel-71-portion,
  author =       "Paul Gerhard Hoel",
  title =        "Elementary Statistics",
  publisher =    "Wiley",
  year =         "1971",
  series =       "Wiley series in probability and mathematical
                 statistics",
  address =      "New York, Chichester",
  edition =      "3rd",
  note =         "ISBN 0~471~40300",
  pages =        "19--33",
}

@Book{singer-whole,
  year =         "1954--58",
  editor =       "Charles Joseph Singer and E. J. Holmyard and A. R.
                 Hall",
  title =        "A history of technology",
  address =      "London",
  publisher =    "Oxford University Press",
  note =         "5 vol.",
}


@Inproceedings{chomsky-73,
  author =       "N. Chomsky",
  year =         "1973",
  title =        "Conditions on Transformations",
  booktitle =    "A festschrift for {Morris Halle}",
  editor =       "S. R. Anderson and P. Kiparsky",
  publisher =    "Holt, Rinehart \& Winston",
  address =      "New York",
}

@Manual{bs-2570-manual,
  author =       "BSI",
  title =        "Natural Fibre Twines",
  organization = "British Standards Institution",
  address =      "London",
  edition =      "3rd",
  year =         "1973",
  note =         "BS 2570",
}

@Techreport{bs-2570-techreport,
  author =       "BSI",
  title =        "Natural Fibre Twines",
  institution =  "British Standards Institution",
  address =      "London",
  year =         "1973",
  type =         "BS",
  number =       "2570",
  note =         "3rd. edn.",
}



@Book{Jespersen:1922,
  author = 	 "Otto Jespersen",
  title = 	 "Language: Its Nature, Development, and Origin",
  publisher = 	 "Allen and Unwin",
  year = 	 1922}


% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{schiller2021stance,
  title={Stance detection benchmark: How robust is your stance detection?},
  author={Schiller, Benjamin and Daxenberger, Johannes and Gurevych, Iryna},
  doi={10.1007/s13218-021-00714-w},
  journal={KI-K{\"u}nstliche Intelligenz},
  volume={35},
  number={3},
  pages={329--341},
  year={2021},
  publisher={Springer}
}

@article{aldayel2021stance,
  title={Stance detection on social media: State of the art and trends},
  author={ALDayel, Abeer and Magdy, Walid},
  journal={Information Processing \& Management},
  volume={58},
  number={4},
  doi={10.1016/j.ipm.2021.102597},
  pages={102597},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{liang2022zero,
  title={Zero-Shot Stance Detection via Contrastive Learning},
  author={Liang, Bin and Chen, Zixiao and Gui, Lin and He, Yulan and Yang, Min and Xu, Ruifeng},
  booktitle={Proceedings of the ACM Web Conference 2022},
  doi={10.1145/3485447.3511994},
  pages={2738--2747},
  year={2022}
}



@article{zubiaga2016analysing,
  title={Analysing how people orient to and spread rumours in social media by looking at conversational threads},
  author={Zubiaga, Arkaitz and Liakata, Maria and Procter, Rob and Wong Sak Hoi, Geraldine and Tolmie, Peter},
  journal={PloS one},
  volume={11},
  number={3},
  doi={10.1371/journal.pone.0150989},
  pages={e0150989},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}



@article{hardalov2021survey,
  title={A survey on stance detection for mis-and disinformation identification},
  author={Hardalov, Momchil and Arora, Arnav and Nakov, Preslav and Augenstein, Isabelle},
  url={https://arxiv.org/abs/2103.00242},
  journal={arXiv preprint arXiv:2103.00242},
  year={2021}
}



@article{kuccuk2020stance,
  title={Stance detection: A survey},
  author={K{\"u}{\c{c}}{\"u}k, Dilek and Can, Fazli},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={1},
  doi={10.1145/3369026},
  pages={1--37},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{lawrence2020argument,
  title={Argument mining: A survey},
  author={Lawrence, John and Reed, Chris},
  journal={Computational Linguistics},
  volume={45},
  doi={10.1162/coli_a_00364},
  number={4},
  pages={765--818},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{sen2018stance,
  title={Stance classification of multi-perspective consumer health information},
  author={Sen, Anirban and Sinha, Manjira and Mannarswamy, Sandya and Roy, Shourya},
  booktitle={Proceedings of the ACM India Joint International Conference on Data Science and Management of Data},
  doi={10.1145/3152494.3152518},
  pages={273--281},
  year={2018}
}



@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  url={https://arxiv.org/abs/1910.03771},
  year={2019}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  url={https://arxiv.org/abs/1711.05101},
  year={2017}
}


@inproceedings{iyyer2018adversarial,
  title={Adversarial Example Generation with Syntactically Controlled Paraphrase Networks},
  author={Iyyer, Mohit and Wieting, John and Gimpel, Kevin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={1875--1885},
  year={2018}
}





@inproceedings{khandelwal2021fine,
  title={Fine-Tune Longformer for Jointly Predicting Rumor Stance and Veracity},
  author={Khandelwal, Anant},
  booktitle={8th ACM IKDD CODS and 26th COMAD},
  pages={10--19},
  doi={10.1145/3430984.3431007},
  year={2021}
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  url={https://arxiv.org/abs/1907.11692},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  url={https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf},
  publisher={OpenAI}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  url={https://arxiv.org/abs/1906.08237},
  volume={32},
  year={2019}
}

@article{zubiaga2018detection,
  title={Detection and resolution of rumours in social media: A survey},
  author={Zubiaga, Arkaitz and Aker, Ahmet and Bontcheva, Kalina and Liakata, Maria and Procter, Rob},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={2},
  pages={1--36},
  url={https://dl.acm.org/doi/10.1145/3161603},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lozhnikov2020stance,
  title={Stance prediction for russian: data and analysis},
  author={Lozhnikov, Nikita and Derczynski, Leon and Mazzara, Manuel},
  booktitle={Proceedings of 6th International Conference in Software Engineering for Defence Applications: SEDA 2018 6},
  pages={176--186},
  year={2020},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-030-14687-0_16}
}

@article{zubiaga2018discourse,
  title={Discourse-aware rumour stance classification in social media using sequential classifiers},
  author={Zubiaga, Arkaitz and Kochkina, Elena and Liakata, Maria and Procter, Rob and Lukasik, Michal and Bontcheva, Kalina and Cohn, Trevor and Augenstein, Isabelle},
  journal={Information Processing \& Management},
  volume={54},
  number={2},
  pages={273--290},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International conference on machine learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR},
  url={http://proceedings.mlr.press/v70/guo17a.html}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017},
  url={https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR},
  url={http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf}
}

@inproceedings{derczynski-etal-2017-semeval,
    title = "{S}em{E}val-2017 Task 8: {R}umour{E}val: Determining rumour veracity and support for rumours",
    author = "Derczynski, Leon  and
      Bontcheva, Kalina  and
      Liakata, Maria  and
      Procter, Rob  and
      Wong Sak Hoi, Geraldine  and
      Zubiaga, Arkaitz",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S17-2006",
    doi = "10.18653/v1/S17-2006",
    pages = "69--76",
    abstract = "Media is full of false claims. Even Oxford Dictionaries named {``}post-truth{''} as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics {--} each having their own families of claims and replies {--} and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.",
}

@inproceedings{gorrell-etal-2019-semeval,
    title = "{S}em{E}val-2019 Task 7: {R}umour{E}val, Determining Rumour Veracity and Support for Rumours",
    author = "Gorrell, Genevieve  and
      Kochkina, Elena  and
      Liakata, Maria  and
      Aker, Ahmet  and
      Zubiaga, Arkaitz  and
      Bontcheva, Kalina  and
      Derczynski, Leon",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2147",
    doi = "10.18653/v1/S19-2147",
    pages = "845--854",
    abstract = "Since the first RumourEval shared task in 2017, interest in automated claim validation has greatly increased, as the danger of {``}fake news{''} has become a mainstream concern. However automated support for rumour verification remains in its infancy. It is therefore important that a shared task in this area continues to provide a focus for effort, which is likely to increase. Rumour verification is characterised by the need to consider evolving conversations and news updates to reach a verdict on a rumour{'}s veracity. As in RumourEval 2017 we provided a dataset of dubious posts and ensuing conversations in social media, annotated both for stance and veracity. The social media rumours stem from a variety of breaking news stories and the dataset is expanded to include Reddit as well as new Twitter posts. There were two concrete tasks; rumour stance prediction and rumour verification, which we present in detail along with results achieved by participants. We received 22 system submissions (a 70{\%} increase from RumourEval 2017) many of which used state-of-the-art methodology to tackle the challenges involved.",
}

@inproceedings{scarton-etal-2020-measuring,
    title = "Measuring What Counts: The Case of Rumour Stance Classification",
    author = "Scarton, Carolina  and
      Silva, Diego  and
      Bontcheva, Kalina",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.92",
    pages = "925--932",
    abstract = "Stance classification can be a powerful tool for understanding whether and which users believe in online rumours. The task aims to automatically predict the stance of replies towards a given rumour, namely support, deny, question, or comment. Numerous methods have been proposed and their performance compared in the RumourEval shared tasks in 2017 and 2019. Results demonstrated that this is a challenging problem since naturally occurring rumour stance data is highly imbalanced. This paper specifically questions the evaluation metrics used in these shared tasks. We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics {--} accuracy and macro-F1 {--} are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class. To overcome this problem, we propose new evaluation metrics for rumour stance detection. These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).",
}

@inproceedings{nguyen-etal-2020-bertweet,
    title = "{BERT}weet: A pre-trained language model for {E}nglish Tweets",
    author = "Nguyen, Dat Quoc  and
      Vu, Thanh  and
      Tuan Nguyen, Anh",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.2",
    doi = "10.18653/v1/2020.emnlp-demos.2",
    pages = "9--14",
    abstract = "We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at \url{https://github.com/VinAIResearch/BERTweet}",
}

@inproceedings{yu-etal-2020-coupled,
    title = "Coupled Hierarchical Transformer for Stance-Aware Rumor Verification in Social Media Conversations",
    author = "Yu, Jianfei  and
      Jiang, Jing  and
      Khoo, Ling Min Serena  and
      Chieu, Hai Leong  and
      Xia, Rui",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.108",
    doi = "10.18653/v1/2020.emnlp-main.108",
    pages = "1392--1401",
    abstract = "The prevalent use of social media enables rapid spread of rumors on a massive scale, which leads to the emerging need of automatic rumor verification (RV). A number of previous studies focus on leveraging stance classification to enhance RV with multi-task learning (MTL) methods. However, most of these methods failed to employ pre-trained contextualized embeddings such as BERT, and did not exploit inter-task dependencies by using predicted stance labels to improve the RV task. Therefore, in this paper, to extend BERT to obtain thread representations, we first propose a Hierarchical Transformer, which divides each long thread into shorter subthreads, and employs BERT to separately represent each subthread, followed by a global Transformer layer to encode all the subthreads. We further propose a Coupled Transformer Module to capture the inter-task interactions and a Post-Level Attention layer to use the predicted stance labels for RV, respectively. Experiments on two benchmark datasets show the superiority of our Coupled Hierarchical Transformer model over existing MTL approaches.",
}

@inproceedings{kochkina-etal-2017-turing,
    title = "{T}uring at {S}em{E}val-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-{LSTM}",
    author = "Kochkina, Elena  and
      Liakata, Maria  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S17-2083",
    doi = "10.18653/v1/S17-2083",
    pages = "475--480",
    abstract = "This paper describes team Turing{'}s submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.",
}

@inproceedings{hardalov-etal-2022-survey,
    title = "A Survey on Stance Detection for Mis- and Disinformation Identification",
    author = "Hardalov, Momchil  and
      Arora, Arnav  and
      Nakov, Preslav  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.94",
    doi = "10.18653/v1/2022.findings-naacl.94",
    pages = "1259--1277",
    abstract = "Understanding attitudes expressed in texts, also known as stance detection, plays an important role in systems for detecting false information online, be it misinformation (unintentionally false) or disinformation (intentionally false information). Stance detection has been framed in different ways, including (a) as a component of fact-checking, rumour detection, and detecting previously fact-checked claims, or (b) as a task in its own right. While there have been prior efforts to contrast stance detection with other related tasks such as argumentation mining and sentiment analysis, there is no existing survey on examining the relationship between stance detection and mis- and disinformation detection. Here, we aim to bridge this gap by reviewing and analysing existing work in this area, with mis- and disinformation in focus, and discussing lessons learnt and future challenges.",
}

@article{kopf2023openassistant,
  title={OpenAssistant Conversations--Democratizing Large Language Model Alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={arXiv preprint arXiv:2304.07327},
  year={2023}
}

@inproceedings{yang-etal-2019-blcu,
    title = "{BLCU}{\_}{NLP} at {S}em{E}val-2019 Task 7: An Inference Chain-based {GPT} Model for Rumour Evaluation",
    author = "Yang, Ruoyao  and
      Xie, Wanying  and
      Liu, Chunhua  and
      Yu, Dong",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2191",
    doi = "10.18653/v1/S19-2191",
    pages = "1090--1096",
    abstract = "Researchers have been paying increasing attention to rumour evaluation due to the rapid spread of unsubstantiated rumours on social media platforms, including SemEval 2019 task 7. However, labelled data for learning rumour veracity is scarce, and labels in rumour stance data are highly disproportionate, making it challenging for a model to perform supervised-learning adequately. We propose an inference chain-based system, which fully utilizes conversation structure-based knowledge in the limited data and expand the training data in minority categories to alleviate class imbalance. Our approach obtains 12.6{\%} improvement upon the baseline system for subtask A, ranks 1st among 21 systems in subtask A, and ranks 4th among 12 systems in subtask B.",
}

@inproceedings{fajcik-etal-2019-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2019 Task 7: Determining the Rumour Stance with Pre-Trained Deep Bidirectional Transformers",
    author = "Fajcik, Martin  and
      Smrz, Pavel  and
      Burget, Lukas",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2192",
    doi = "10.18653/v1/S19-2192",
    pages = "1097--1104",
    abstract = "This paper describes our system submitted to SemEval 2019 Task 7: RumourEval 2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell et al., 2019). The challenge focused on classifying whether posts from Twitter and Reddit support, deny, query, or comment a hidden rumour, truthfulness of which is the topic of an underlying discussion thread. We formulate the problem as a stance classification, determining the rumour stance of a post with respect to the previous thread post and the source thread post. The recent BERT architecture was employed to build an end-to-end system which has reached the F1 score of 61.67 {\%} on the provided test data. Without any hand-crafted feature, the system finished at the 2nd place in the competition, only 0.2 {\%} behind the winner.",
}

@inproceedings{reimers-gurevych-2019-sentence,
    title = "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1410",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
    abstract = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.",
}

@inproceedings{kochkina-etal-2018-one,
    title = "All-in-one: Multi-task Learning for Rumour Verification",
    author = "Kochkina, Elena  and
      Liakata, Maria  and
      Zubiaga, Arkaitz",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-1288",
    pages = "3402--3413",
    abstract = "Automatic resolution of rumours is a challenging task that can be broken down into smaller components that make up a pipeline, including rumour detection, rumour tracking and stance classification, leading to the final outcome of determining the veracity of a rumour. In previous work, these steps in the process of rumour verification have been developed as separate components where the output of one feeds into the next. We propose a multi-task learning approach that allows joint training of the main and auxiliary tasks, improving the performance of rumour verification. We examine the connection between the dataset properties and the outcomes of the multi-task learning models used.",
}


@inproceedings{clark-etal-2019-dont,
    title = "Don{'}t Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases",
    author = "Clark, Christopher  and
      Yatskar, Mark  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1418",
    doi = "10.18653/v1/D19-1418",
    pages = "4069--4082",
    abstract = "State-of-the-art models often make use of superficial patterns in the data that do not generalize well to out-of-domain or adversarial settings. For example, textual entailment models often learn that particular key words imply entailment, irrespective of context, and visual question answering models learn to predict prototypical answers, without considering evidence in the image. In this paper, we show that if we have prior knowledge of such biases, we can train a model to be more robust to domain shift. Our method has two stages: we (1) train a naive model that makes predictions exclusively based on dataset biases, and (2) train a robust model as part of an ensemble with the naive one in order to encourage it to focus on other patterns in the data that are more likely to generalize. Experiments on five datasets with out-of-domain test sets show significantly improved robustness in all settings, including a 12 point gain on a changing priors visual question answering dataset and a 9 point gain on an adversarial question answering test set.",
}

@inproceedings{hossain-etal-2020-covidlies,
    title = "{COVIDL}ies: Detecting {COVID}-19 Misinformation on Social Media",
    author = "Hossain, Tamanna  and
      Logan IV, Robert L.  and
      Ugarte, Arjuna  and
      Matsubara, Yoshitomo  and
      Young, Sean  and
      Singh, Sameer",
    booktitle = "Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020",
    month = dec,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.nlpcovid19-2.11",
    doi = "10.18653/v1/2020.nlpcovid19-2.11",
    abstract = "The ongoing pandemic has heightened the need for developing tools to flag COVID-19-related misinformation on the internet, specifically on social media such as Twitter. However, due to novel language and the rapid change of information, existing misinformation detection datasets are not effective for evaluating systems designed to detect misinformation on this topic. Misinformation detection can be divided into two sub-tasks: (i) retrieval of misconceptions relevant to posts being checked for veracity, and (ii) stance detection to identify whether the posts Agree, Disagree, or express No Stance towards the retrieved misconceptions. To facilitate research on this task, we release COVIDLies (\url{https://ucinlp.github.io/covid19} ), a dataset of 6761 expert-annotated tweets to evaluate the performance of misinformation detection systems on 86 different pieces of COVID-19 related misinformation. We evaluate existing NLP systems on this dataset, providing initial benchmarks and identifying key challenges for future models to improve upon.",
}

@inproceedings{ferreira-vlachos-2016-emergent,
    title = "{E}mergent: a novel data-set for stance classification",
    author = "Ferreira, William  and
      Vlachos, Andreas",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1138",
    doi = "10.18653/v1/N16-1138",
    pages = "1163--1168",
}

@inproceedings{allaway-mckeown-2020-zero,
    title = "{Z}ero-{S}hot {S}tance {D}etection: {A} {D}ataset and {M}odel using {G}eneralized {T}opic {R}epresentations",
    author = "Allaway, Emily  and
      McKeown, Kathleen",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.717",
    doi = "10.18653/v1/2020.emnlp-main.717",
    pages = "8913--8931",
    abstract = "Stance detection is an important component of understanding hidden influences in everyday life. Since there are thousands of potential topics to take a stance on, most with little to no training data, we focus on zero-shot stance detection: classifying stance from no training examples. In this paper, we present a new dataset for zero-shot stance detection that captures a wider range of topics and lexical variation than in previous datasets. Additionally, we propose a new model for stance detection that implicitly captures relationships between topics using generalized topic representations and show that this model improves performance on a number of challenging linguistic phenomena.",
}

@inproceedings{liu-etal-2022-target,
    title = "Target Really Matters: Target-aware Contrastive Learning and Consistency Regularization for Few-shot Stance Detection",
    author = "Liu, Rui  and
      Lin, Zheng  and
      Ji, Huishan  and
      Li, Jiangnan  and
      Fu, Peng  and
      Wang, Weiping",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.605",
    pages = "6944--6954",
    abstract = "Stance detection aims to identify the attitude from an opinion towards a certain target. Despite the significant progress on this task, it is extremely time-consuming and budget-unfriendly to collect sufficient high-quality labeled data for every new target under fully-supervised learning, whereas unlabeled data can be collected easier. Therefore, this paper is devoted to few-shot stance detection and investigating how to achieve satisfactory results in semi-supervised settings. As a target-oriented task, the core idea of semi-supervised few-shot stance detection is to make better use of target-relevant information from labeled and unlabeled data. Therefore, we develop a novel target-aware semi-supervised framework. Specifically, we propose a target-aware contrastive learning objective to learn more distinguishable representations for different targets. Such an objective can be easily applied with or without unlabeled data. Furthermore, to thoroughly exploit the unlabeled data and facilitate the model to learn target-relevant stance features in the opinion content, we explore a simple but effective target-aware consistency regularization combined with a self-training strategy. The experimental results demonstrate that our approach can achieve state-of-the-art performance on multiple benchmark datasets in the few-shot setting.",
}

@inproceedings{kaushal-etal-2021-twt,
    title = "t{WT}{--}{WT}: A Dataset to Assert the Role of Target Entities for Detecting Stance of Tweets",
    author = "Kaushal, Ayush  and
      Saha, Avirup  and
      Ganguly, Niloy",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.303",
    doi = "10.18653/v1/2021.naacl-main.303",
    pages = "3879--3889",
    abstract = "The stance detection task aims at detecting the stance of a tweet or a text for a target. These targets can be named entities or free-form sentences (claims). Though the task involves reasoning of the tweet with respect to a target, we find that it is possible to achieve high accuracy on several publicly available Twitter stance detection datasets without looking at the target sentence. Specifically, a simple tweet classification model achieved human-level performance on the WT{--}WT dataset and more than two-third accuracy on various other datasets. We investigate the existence of biases in such datasets to find the potential spurious correlations of sentiment-stance relations and lexical choice associated with the stance category. Furthermore, we propose a new large dataset free of such biases and demonstrate its aptness on the existing stance detection systems. Our empirical findings show much scope for research on the stance detection task and proposes several considerations for creating future stance detection datasets.",
}

@inproceedings{poliak-etal-2018-hypothesis,
    title = "Hypothesis Only Baselines in Natural Language Inference",
    author = "Poliak, Adam  and
      Naradowsky, Jason  and
      Haldar, Aparajita  and
      Rudinger, Rachel  and
      Van Durme, Benjamin",
    booktitle = "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S18-2023",
    doi = "10.18653/v1/S18-2023",
    pages = "180--191",
    abstract = "We propose a hypothesis only baseline for diagnosing Natural Language Inference (NLI). Especially when an NLI dataset assumes inference is occurring based purely on the relationship between a context and a hypothesis, it follows that assessing entailment relations while ignoring the provided context is a degenerate solution. Yet, through experiments on 10 distinct NLI datasets, we find that this approach, which we refer to as a hypothesis-only model, is able to significantly outperform a majority-class baseline across a number of NLI datasets. Our analysis suggests that statistical irregularities may allow a model to perform NLI in some datasets beyond what should be achievable without access to the context.",
}

@inproceedings{niven-kao-2019-probing,
    title = "Probing Neural Network Comprehension of Natural Language Arguments",
    author = "Niven, Timothy  and
      Kao, Hung-Yu",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1459",
    doi = "10.18653/v1/P19-1459",
    pages = "4658--4664",
    abstract = "We are surprised to find that BERT{'}s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.",
}

@inproceedings{conforti-etal-2020-will,
    title = "Will-They-Won{'}t-They: A Very Large Dataset for Stance Detection on {T}witter",
    author = "Conforti, Costanza  and
      Berndt, Jakob  and
      Pilehvar, Mohammad Taher  and
      Giannitsarou, Chryssi  and
      Toxvaerd, Flavio  and
      Collier, Nigel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.157",
    doi = "10.18653/v1/2020.acl-main.157",
    pages = "1715--1724",
    abstract = "We present a new challenging stance detection dataset, called Will-They-Won{'}t-They (WT{--}WT), which contains 51,284 tweets in English, making it by far the largest available dataset of the type. All the annotations are carried out by experts; therefore, the dataset constitutes a high-quality and reliable benchmark for future research in stance detection. Our experiments with a wide range of recent state-of-the-art stance detection systems show that the dataset poses a strong challenge to existing models in this domain.",
}

@inproceedings{sobhani-etal-2017-dataset,
    title = "A Dataset for Multi-Target Stance Detection",
    author = "Sobhani, Parinaz  and
      Inkpen, Diana  and
      Zhu, Xiaodan",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E17-2088",
    pages = "551--557",
    abstract = "Current models for stance classification often treat each target independently, but in many applications, there exist natural dependencies among targets, e.g., stance towards two or more politicians in an election or towards several brands of the same product. In this paper, we focus on the problem of multi-target stance detection. We present a new dataset that we built for this task. Furthermore, We experiment with several neural models on the dataset and show that they are more effective in jointly modeling the overall position towards two related targets compared to independent predictions and other models of joint learning, such as cascading classification. We make the new dataset publicly available, in order to facilitate further research in multi-target stance classification.",
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}




