% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
% \usepackage[review]{EACL2023}
\usepackage{EACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{enumitem}
\usepackage{booktabs}

\newcommand{\carol}[1]{\textcolor{black}{#1}}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{multirow}
% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{subcaption}
\usepackage{graphicx}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Evaluating the Role of Target Arguments in Rumour Stance Classification}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Yue Li \and Carolina Scarton\\
  Department of Computer Science, The University of Sheffield \\
  \texttt{\{yli381, c.scarton\}@sheffield.ac.uk} 
  }

\begin{document}
\maketitle
\begin{abstract}
Considering a conversation thread, stance classification aims to identify the opinion (e.g. agree or disagree) of replies towards a given \textit{target}. The \textit{target} of the stance is expected to be an essential component in this task, being one of the main factors that make it different from sentiment analysis. However, a recent study shows that a target-oblivious model outperforms target-aware models, suggesting that \textit{targets} are not useful when predicting stance. This paper re-examines this phenomenon for rumour stance classification (RSC) on social media, where a \textit{target} is a rumour story implied by the source tweet in the conversation. %We compare the model performance and robustness, and evaluate the role of the \textit{target} in the dataset and models. 
\carol{We propose adversarial attacks in the test data, aiming to assess the models robustness and evaluate the role of the data in the models performance.}
%Our results show that both target-aware and -oblivious %transformer-based 
\carol{Results show that state-of-the-art models, including approaches that use the entire conversation thread, overly relying on superficial signals.} %, even considering systems based on the Twitter conversation structure. 
\carol{Our hypothesis is that the naturally high occurrence of target-independent replies in RSC (e.g. "this is fake" or just "fake") results in the impressive performance of target-oblivious models, highlighting the risk of \textit{target} instances being treated as noise during training.}

% Therefore, we highlight the need for more carefully designed benchmark datasets and more flexible ways to model the role of the \textit{target} in rumour stance classification.

% Our results show that both target-aware and target-oblivious models overly rely on superficial signals, such as negation and punctuation, for the \textit{deny} and \textit{query} classes. These two classes contain significantly more target-independent tweets in the dataset, which not only results in the impressive performance of the target-oblivious model but also raises the risk of the \textit{target} being treated as noise during training. Therefore, we highlight the need for more carefully designed benchmark datasets and more flexible ways to model the role of the \textit{target} in rumour stance classification.
\end{abstract}

\section{Introduction}

Stance classification aims to automatically identify the type of an expressed opinion (usually in textual format) towards a single or multiple targets.  It has played a key role in many Natural Language Processing (NLP) applications, such as argument mining \citep{lawrence2020argument}, rumour analysis \citep{zubiaga2016analysing}, and information retrieval \citep{sen2018stance}. As expected, the \textit{target} of the stance plays a fundamental role in this task, which is one of the main differences between sentiment analysis and stance classification: the former can be framed as target-independent, while the latter has to provide the target either explicitly or implicitly \citep{kuccuk2020stance}. A \textit{target} could be a person or an organisation in generic stance detection, and a rumour story or a claim in disinformation analysis.  \citep{mohammad-etal-2016-semeval,zubiaga2016analysing,ferreira-vlachos-2016-emergent}.


%%%%%%%%%%%%
\begin{figure}[t!]
 \centering

 \includegraphics[width=0.48\textwidth]{image/E9.png}
 
 \caption{Example of Target-Independent (T-I) and Target-Dependent (T-D) replies that \textit{deny} a target.}
 \label{fig:example}
\end{figure}
%%%%%%%%%%

However, previous work shows that target-oblivious BERT-based models achieve comparable or even better performance than target-aware models on many stance classification datasets, due to spurious sentiment- and lexicon-stance correlations in the training sets \citep{kaushal-etal-2021-twt}. Similar results are observed in %phenomena have been observed in 
other context-dependent %sentence-pair 
NLP tasks, such as Natural Language Inference (premise-hypothesis pairs) and Argument Reasoning
Comprehension (argument-warrant pairs), where models without background knowledge (premise or argument) achieve impressive performance due to spurious or superficial cues in the datasets \citep{poliak-etal-2018-hypothesis,niven-kao-2019-probing}. %The analysis of this phenomenon for stance classification is highly relevant since it could potentially provide an insight into best practices for creating benchmarking datasets, models and . 
% For stance classification, \newcite{kaushal-etal-2021-twt} find that spurious sentiment- and lexicon-stance correlations in the training sets lead to the high performance of target-oblivious models.

% Although some replies may be target independent (Figure \ref{fig:example}), models for stance classification should be capable to robustly deal with these cases and adequately use \textit{target} information when necessary. 

This paper further analyses the above phenomenon for rumour stance classification (RSC). RSC is framed as a different task from the traditional stance classification, since its aim is to support rumour verification \citep{zubiaga2018detection}. Therefore, it is often defined as a four-class problem, with the addition of the query class, to the usual support, deny and comment classes.   %, a task designed to support the verification of rumours in social media \citep{zubiaga2018detection}. %,derczynski-etal-2017-semeval,gorrell-etal-2019-semeval}. 
% This task differs from generic stance detection by (i) introducing a new class \textit{query} to the traditional \textit{support}, \textit{deny} and \textit{comment} set and (ii) having different importance for the stances, with \textit{support} and \textit{deny} being the most informative for the task \citep{scarton-etal-2020-measuring}.
Following \cite{kaushal-etal-2021-twt}, we experiment with sentiment analysis in the RumourEval 2019 dataset (see Appendix \ref{sec:appendix sentiment}) and find that all classes contain a significant amount of tweets with negative sentiment, not only \textit{denies}, contradicting their results and motivating a more in-depth analysis. Additionally, in contrast to the stance detection dataset \citep{conforti-etal-2020-will} studied by \citet{kaushal-etal-2021-twt}, RumourEval contains real-world data that is naturally target independent (Figure \ref{fig:example}). %, which motivated \citet{aker-etal-2017-simple} to build a \textit{non-target} model for this task. 
Thus, we compare different models for RSC in target-oblivious and -aware settings, including conversation-aware systems that model the full conversation structure. Adversarial attacks are proposed to investigate the impact of superficial signals into models' performance and we show that target-oblivious models achieve competitive results when compared to their target/conversation-aware counterparts.
%how much the superficial signals contribute to the success of the target-oblivious models, and whether the target/conversation aware models are more robust. Finally, we quantify the proportion of target-independent examples in the dataset, and evaluate the role of the target in target/conversation-aware models. 

% Further investigating the high performance of target-oblivious models, we employ adversarial attacks \citep{schiller2021stance}, innovating by proposing a punctuation-based attack, specifically designed for rumour stance classification. Our results highlight the biases in current benchmarking datasets for rumour stance classification, casting light into the main issues that contributes to the success of target-oblivious models.

\section{Evaluating the Target-Oblivious Model for Rumour Stance Classification}

\paragraph{Data.}
We experiment with RumourEval 2019, the current largest English RSC dataset \citep{gorrell-etal-2019-semeval}. It consists of conversation threads about rumour stories on Twitter and Reddit. This paper only considers the Twitter data split (5,568/6,702 and 1,066/1,827 in training and test sets respectively), aiming to exclude the impact of text length or writing style. Each conversation consists of a \textit{source} tweet that initiates the rumour story, and direct and indirect \textit{replies} to the \textit{source} tweet. The \textit{target} of stance is the rumour story implied by the \textit{source} tweet. The stance of each tweet towards the rumour story is categorised into \textit{support}, \textit{deny}, \textit{query} and \textit{comment}. The dataset is highly imbalanced, with \textit{supports}, \textit{denies} and \textit{queries} corresponding,
respectively, to 14\%, 7\% and 7\% of instances, while \textit{comments} are 72\%.

\paragraph{Experimental Settings}
We fine-tune \textbf{BERTweet} \citep{nguyen-etal-2020-bertweet}, \textbf{BERT} \citep{devlin-etal-2019-bert}, \textbf{RoBERTa} \citep{liu2019roberta} and \textbf{XLNet} \citep{yang2019xlnet} and compare their performance within target-oblivious (T-O) and -aware (T-A) settings. In T-O, we train the model only using the \textit{reply} tweet, whilst T-A treats the \textit{source} tweet as the \textit{target} and feed it together with the \textit{reply} into the model. 
% We introduce class weights in the loss function to treat the imbalance data problem.\footnote{According to the distribution of Twitter training data: support=1.67, deny=3.15, query=2.95, comment=0.36}. move to appendix 
We compare the above models with the top two submitted systems in the RumourEval 2019 shared task: BLCU NLP \citep{yang-etal-2019-blcu} and BUT-FIT \citep{fajcik-etal-2019-fit}. Both systems are conversation-aware \footnote{Conceptually, conversation-aware models are also target-aware, but in this paper we use "target-aware" to only denote models whose input is a pair of \textit{source} and \textit{reply}.}, i.e. they model the conversation structure rather than only considering \textit{source} and \textit{reply} pairs. Since they are not publicly available, we reproduce other two conversation-aware systems: (1) \textbf{Hierarchical BERT} \citep{yu-etal-2020-coupled}, achieving state-of-the-art performance \citep{hardalov-etal-2022-survey} on the RumourEval 2017 dataset \citep{derczynski-etal-2017-semeval}; (2) \textbf{Branch-LSTM} \citep{kochkina-etal-2017-turing}, the winner of the RumourEval 2017 shared task and the baseline model for the 2019 task. Details about other experimental settings (e.g., hyperparameters and data pre-processing) appear in Appendix \ref{sec:appendix finetuning}. 

\paragraph{Evaluation.}

Besides macro-$F1$, the official evaluation metric of RumourEval 2019, we adopt weighted $F2$ ($wF2$) which is more robust to RSC \citep{scarton-etal-2020-measuring}.\footnote{We use the same weights as \citep{scarton-etal-2020-measuring}: \textit{deny} $=$ \textit{support} $= 0.40$, \textit{query} $= 0.15$ and \textit{comment} $= 0.05$.} 
Since we are assessing models' performance with or without the \textit{target}, we do not use the stance of the \textit{source} in the test set.\footnote{We removed 56 \textit{sources}: 50 \textit{supports} and 6 \textit{queries}.}   



\paragraph{Results.}
We present the results on the Twitter test set in Table \ref{tab:results}. Overall, the T-A version falls behind its oblivious counterpart for the same model, except for XLNet. %However, it is outperformed by all the other three target-oblivious models. C
Conversation-aware models suffer from poor performance over the \textit{support} and \textit{deny} classes,\footnote{Most of the \textit{supports} they correctly predict are \textit{sources}, resulting in higher metrics reported in the original paper.} resulting in low $wF2$ scores.
% A version of the target-oblivious model without any imbalanced data treatment (target-oblivious*) can still outperform BLCU NLP and BUT-FIT. 
Also, the performance of target-aware models over each stance often experiences higher variance than its target-oblivious version (as shown in Appendix \ref{sec:appendix each stance}).

\begin{table}[t]
\centering
\scalebox{0.75}{
\begin{tabular}{llcc}
\toprule
& Model & $wF2$ & macro-$F1$\\
\midrule
% eventAI & 0.541 & 0.616 & 0.555\\
\multirow{8}{2cm}{BERT-based models} & \underline{BERTweet} (T-O) & \textbf{0.477} & 0.504\\
& \underline{BERTweet} (T-A) & 0.435 & 0.513\\
& RoBERTa (T-O) & 0.431 & 0.469\\ 
& \underline{BERT} (T-O) & 0.422 & 0.450\\ 
% BERTweet (T-O)* & 0.395 & 0.428 & 0.525\\

& RoBERTa (T-A) & 0.417 & 0.477\\ 
& \underline{XLNet} (T-A) & 0.400 & 0.434\\
& \underline{BERT} (T-A) & 0.374 & 0.438\\ 

& \underline{XLNet} (T-O) & 0.351 & 0.423\\
\midrule
\midrule
\multirow{4}{3cm}{Conversation-based models} & BLCU NLP & 0.371 & \textbf{0.524} \\ 
& BUT-FIT & 0.309 &  0.497\\ 

& Hierarchical BERT & 0.235 & 0.425\\
& Branch-LSTM & 0.150 & 0.379\\
\bottomrule
\end{tabular}
}
\caption{Results on the Twitter test set. 
% Target-oblivious* denotes a model without class weight in the loss function. 
%The models are separated into conversation-aware model and its counterpart, ranked based on $wF2$.
Underline denotes the difference between the target-oblivious (T-O) and target-aware (T-A) versions of the same model is statistically significant (p<0.05, t-test for $wF2$).}
\label{tab:results}
\end{table}


\begin{table*}[ht!]
\centering
\scalebox{0.68}{
\begin{tabular}{ll|p{2.5cm}p{2.7cm}|p{2.5cm}p{2.7cm}}
\toprule
& & \multicolumn{2}{|c|}{BERTweet} & \multicolumn{2}{|c}{Hierarchical BERT} \\
\toprule
Attack & Version & $wF2$ & macro-$F1$  & $wF2$ & macro-$F1$\\
\midrule
Question Mark & T-O & \underline{0.464 (-2.64\%)} & 0.504 (0.00\%) & - & -\\
& T-A & \underline{0.415 (-4.69\%)} & 0.498(-3.08\%) & \underline{0.210 (-11.01\%)} & 0.398 (-6.44\%)\\
\midrule 
All Punctuation & T-O & \underline{0.450 (-5.66\%)} & 0.510 (-1.19\%) & - & -\\
& T-A & \underline{0.407 (-6.43\%)} & 0.501 (-2.49\%) & \underline{0.185 (-21.60\%)} & 0.379 (-10.91\%)\\
\midrule
Negation-\textit{reply} & T-O & \underline{\textbf{0.243 (-49.14\%)}} & \textbf{0.237 (-53.03\%)} & - & -\\
& T-A & \underline{0.272 (-37.55\%)} & 0.276 (-46.16\%) & \underline{\textbf{0.148 (-37.28\%)}} & \textbf{0.069 (-83.89\%)}\\
\midrule
Negation-\textit{source} & T-A & 0.409 (-6.11\%) & 0.467 (-9.04\%) & 0.236 (+0.15\%) & 0.423 (-0.58\%)\\
\midrule

\end{tabular}
}
\caption{Influence of each adversarial attack on Hierarchical BERT and target-aware and -oblivious BERTweet. The highest drop performance is in bold. Figures in parentheses are the percentage of performance change. Underline denotes the change of $wF2$ is statistically significant (p value < 0.05, paired t-test).}
\label{tab:results-attack}
\end{table*}

\section{Assessing Rumour Stance Classification Models with Adversarial Attacks}

\paragraph{Adversarial attacks.}
The T-O models exhibit high performance especially on \textit{deny} and \textit{query} classes, hence, we employ adversarial attacks to investigate (1) how much the superficial signals contribute to the success of the T-O models and (2) whether the target- and conversation-aware models are free from such superficial dependency. The following two types of attacks are adopted, modifying all the examples in the Twitter test set. 

\begin{itemize}[noitemsep, leftmargin=*]
\item \textbf{Punctuation:} in RSC, %introduces a new stance 
the \textit{query} stance is represented by interrogative sentences, frequently ending with question marks. Therefore, a model trained for this task may be reliant on punctuation marks. %be more sensitive to the punctuation than generic stance detection. 
For testing this hypothesis, we compare the models after removing (i) question marks or (ii) all punctuation from the test set. 
\item \textbf{Negation:} we adopt the negation stress test proposed for NLI \citep{naik-etal-2018-stress}, which is also effective for stance classification \citep{schiller2021stance}. We add "False is not true and" at the beginning of the (i) \textit{source} or (ii) \textit{reply} tweets. 
\end{itemize}

\paragraph{Results.} Overall, all the models are vulnerable to the attacks. Target- and conversation-aware models are not consistently more robust than target-oblivious models. Results for BERTweet and Hierarchical BERT are in Table \ref{tab:results-attack}. Other models' results and a per stance analysis can be found in Appendix \ref{sec:appendix each stance}. Since both attacks can influence the text length. We calculate the point biserial correlation coefficient ($r_{pb}$) between the number of tokens and model performance (whether a prediction is correct or not), achieving significantly small coefficients ($|r_{pb}| < 0.16$). This indicates that input length does not impact models' performance.

%Since both attacks would influence the text length, we also analyse whether the text length would impact the model performance. We calculate the point biserial correlation coefficient between text length (the number of tokens) and model performance (whether the prediction is correct or not) over both validation and test sets, with and without adversarial attacks. The correlation coefficient scores are all less than $\left |0.16 \right|$, therefore, whether the models could make a correct prediction does not significantly correlate to the length of the input. The false predictions are mainly due to the removal of punctuation or introduction of negation terms, rather than changes in the text length. 

%An analysis of the role of text length in the attacks can be found in Appendix \ref{sec:appendix each stance}.

\paragraph{Punctuation-based attacks.}
Question marks serve as a strong signal for the prediction of the \textit{query} class. Consequently, other punctuation (e.g., period) is seen as a cue for \textit{support} and \textit{deny} classes, resulting in a model bias towards all punctuation marks. For instance, after removing question marks, the $F2$ score for the \textit{query} class significantly drops, while the performance of the other three classes sometimes slightly rise. % It is also reflected by the higher drop in GMR and less decrease in macro-F1 under punctuation attacks. 
The dependency on punctuation varies across different models. In most of the cases, abandoning all the punctuation leads to  performance drop over the \textit{query}, \textit{support} and \textit{deny} classes. But we observe marginal improvement of the \textit{support} class on the target-aware RoBERTa and XLNet. Overall, T-O versions of BERT and BERTweet exhibit the least decrease of $wF2$ scores under attacks for question marks and all punctuation respectively. 

%\subsubsection{Negation Attack}
\paragraph{Negation-based attacks.}
Models are highly vulnerable to a negation attack towards the \textit{reply} tweet, especially T-O models. XLNet T-O, although performing worse than its T-A version, shows stronger bias towards superficial negation terms. 
% where the $wF2$ and GMR scores of BERTweet dramatically drops by 49.14\% and 68.71\%, respectively. 
Surprisingly, the conversation-aware systems also heavily rely on the simple cue words in the \textit{replies}. XLNet T-A is the most robust model in this case, although its $wF2$ score still drops by nearly 18\%.
% The \textit{query} class is sometimes less influenced due to the existence of the strong question mark signal. 
Interestingly, the target- and conversation-aware models are considerably less impacted by the negation attack towards the \textit{source} than the \textit{reply}. It may be reasonable since the model would rely more on the negation in the \textit{reply} rather than in the \textit{target} to infer the stance. However, we notice that the influence of negation attack towards the \textit{source} tweet is inconsistent, and could sometimes lead to misclassification into the \textit{comment} or even the \textit{support} class (shown in the Appendix \ref{sec:appendix each stance}), suggesting the lack of reasoning between the \textit{source} and \textit{reply}. 

% \section{Dataset Biases and Modelling Strategy}
\section{The Role of Target Arguments in Dataset and Models}

Unlike the analysis by \citet{kaushal-etal-2021-twt}, here, we highlight that there is real-world data whose stance is truly target-independent, especially in RSC where the \textit{target} is given implicitly \citep{hardalov-etal-2022-survey} and the replies under rumours on social media can be naturally vague (Figure \ref{fig:example} and Appendix \ref{sec:appendix target}). Instead of "de-biasing" the dataset by removing these examples, we argue that the model should be able to handle both target-independent and -dependent cases. However, the presence of these target-independent tweets in the dataset can impact the learning process and evaluation, as we have discussed. So we further analyse the role of the target arguments in the dataset and target/conversation-aware models.
%(e.g. the stance of "This is fake" is \textit{deny}, no matter which \textit{source} it responds to). 
% As discussed, our observations may also reflect a bias in RumourEval 2019 dataset: the \textit{denies} and \textit{queries} are significantly more target-independent %and less context-needed 
% than \textit{supports} and \textit{comments}. 
% To confirm this hypothesis,

\paragraph{Dataset.} Two annotators manually categorise the \textit{reply} tweets (all of the \textit{supports}, \textit{denies}, \textit{queries} and $50$ randomly sampled \textit{comments}) in both validation and test sets into target-independent or -dependent.
% Two annotators were asked to manually categorise each tweet as either target-independent or target-dependent, by answering one question: \textit{do you think you need the source tweet to infer the stance of this tweet?} %In order to improve the reliability of 
Annotators did not have access to the \textit{source} tweet and the tweets from validation and test sets are shuffled before annotation.
Aiming to validate the annotations, annotators were also asked to classify the stance of the target-independent tweets. We then compare their assigned class with the gold standard label and, if they differ, we alter their annotation from target-independent to -dependent. The Inter-Annotator Agreement is 72.5\%.

%and compare them with the gold standard labels. If they are different, we alter the labels into target-dependent. We also ask the annotators to label the tweet as target-dependent if they are not sure about the stance class. The tweets from validation and test sets are mixed and shuffled before annotation. Only the \textit{reply} tweet can be accessed during the annotation. We have two annotators: the first annotator is responsible for all the tweets and the second annotator completes 20 random sampled tweets from each stance. The Inter-Annotator Agreement (IAA) between them is 72.5\%.

%Results are shown in Table \ref{tab:results-annotate-target} and examples of target-independent and -dependent tweets can be found in Appendix \ref{sec:appendix target}.
%provide examples of target-independent and -dependent tweets in appendix \ref{sec:appendix target}. 
As shown in Table \ref{tab:results-annotate-target}, the distribution of the target-independent tweets is imbalanced, with \textit{denies} and \textit{queries} showing more cases where context is not needed. It further explains why target-oblivious models are good at predicting \textit{deny} and \textit{query} classes. We also analyse whether the conversation-aware models are better at classifying target-dependent tweets, as it would be expected. However, almost all the correctly identified \textit{denies} by Hierarchical BERT and Branch-LSTM are short target-independent tweets, containing strong signal words such as "false", "no", and "lie". In addition, these models fail in simple cases such as "@USER fake news". Therefore, we question the real usefulness of conversation-aware models, since the \textit{deny} class is the most informative class for rumour verification on social media. Nevertheless, the test set itself does not contain \textit{denies} that require complicated reasoning with the \textit{source} or \textit{parent} tweets, so the evaluation naturally favours T-O systems.

\paragraph{Models.} Aiming to investigate the role of the \textit{target} in the target/conversation-aware models, we experiment by masking the entire \textit{source} tweet in the input during inference. As shown in Table \ref{tab:results-mask-target}, masking the \textit{target} has minimum impact on target-aware BERTweet over the \textit{deny}, \textit{query} and \textit{comment} predictions and, even for the \textit{support} class, 48\% of predictions stay the same on average -- larger than the proportion of target-independent examples in the test set. The case is even more extreme for Hierarchical BERT. The results suggest that the target/conversation-aware model may behave like a target-independent model. The \textit{source} tweets or conversations may be introducing noise, which would explain the failure of the conversation-based models in simple target-independent examples. 


% We also observe that \textit{denies} in the Twitter test set are strongly biased towards a cue word "fake":\footnote{The word "fake" only appears in 7 tweets in the training set, and only one of them belongs to the \textit{deny} class.} out of $43$ replies containing this word, $37$ are \textit{denies}. Therefore, a simple rule-based system (if it contains "fake" then \textit{deny}) could achieve a $F1$ score of $0.55$ on the \textit{deny} class

% It may also explain the high variance in the target-aware models and the results of the masked \textit{target} experiment, where the target-aware model shows a similar behaviour to a target-oblivious model. %be the reason why the target-aware model exhibits higher performance variance over each stance and ends up with almost target-oblivious.

\begin{table}[t!]
\centering
\scalebox{0.7}{
\begin{tabular}{lcccc}
\toprule
 & Support & Deny & Query\\
\midrule
Validation & 20 (29\%) & 35 (51\%) & 42 (40\%)\\
Test & 12 (13\%) & 66 (72\%) & 17 (30\%) &\\
\bottomrule
\end{tabular}
}
\caption{The number of target-independent tweets in each stance in validation and test sets (proportion in brackets). The annotators did not identify any target-independent \textit{comments}.} %The percentage of target-independent tweets is shown in brackets.}
%Figures in brackets denote the proportion of the target-independent tweets in each stance class.}
\label{tab:results-annotate-target}
\end{table}

\begin{table}[t!]
\centering
\scalebox{0.66}{
\begin{tabular}{p{0.12\textwidth}|cccc}
\toprule
Model & Support & Deny & Query & Comment\\
\midrule
BERTweet (T-A) & 0.476±0.260 &  0.801±0.022 &  0.975±0.019 & 0.917±0.061\\
\midrule
Hierarchical BERT & 0.905±0.019 &  0.956±0.029 & 0.939±0.035 & 0.994±0.002\\
\bottomrule
\end{tabular}
}
\caption{The proportion of predictions in each class that %would be 
\carol{are not} influenced by masking the \textit{target}. We show the mean and standard deviation (see Appendix \ref{sec:appendix each stance}).} %\textbf{S}: Support, \textbf{D}: Deny, \textbf{Q}: Query, \textbf{C}: Comment.}
\label{tab:results-mask-target}
\end{table}

% We also observe that \textit{denies} in the Twitter test set are strongly biased towards a cue word "fake":\footnote{The word "fake" only appears in 7 tweets in the training set, and only one of them belongs to the \textit{deny} class.} out of $43$ replies containing this word, $37$ are \textit{denies}. Therefore, a simple rule-based system (if it contains "fake" then \textit{deny}) could achieve a $F1$ score of $0.55$ on the \textit{deny} class, higher than BUT-FIT (0.43) and only 0.01 below BLCU NLP. 

% Finally, it is worth mentioning that few studies do suggest to model this task in a target-independent way (namely \textit{open stance detection}) \citep{aker-etal-2017-simple}, while most of current research focuses on modelling the whole conversation threads and treating them as the \textit{target} of stance (e.g. \citealp{kumar-carley-2019-tree,wei-etal-2019-modeling,yu-etal-2020-coupled,khandelwal2021fine}). The former method is hard to be generalised to the target-dependent cases, while the latter method has the risk of \textit{target} being treated as noise in the training process %if not carefully designed, 
% and even fail in the simple target-independent cases, as shown by our study.   


\section{Conclusions}
In this paper, we evaluate target-aware and -oblivious models for rumour stance classification and adopt adversarial attacks to analyse the decision-making of the models. Our study shows that target- and conversation-aware models are not consistently more robust than target-oblivious models. All models highly rely on negation and question marks for \textit{deny} and \textit{query} classes. We also demonstrate the existence of target-independent tweets especially in \textit{deny} and \textit{query} classes, leading to the "success" of the target-oblivious model and poor reasoning between the \textit{target} and \textit{reply} in the target-aware models. %Therefore, we suggest to take it into account when create datasets and develop stance detection models.    
% Therefore, we highlight the need for more carefully designed, and debiased benchmark datasets for rumour stance classification.  
% We also highlight the need for developing stance classification models capable to utilise the \textit{target} in a more flexible way. For instance,
% by framing the identification of target-independent and -specific stance features as a pretext task \citep{liang2022zero}.

We suggest that: (1) Target-oblivious models could be adopted as a baseline for this task. (2) To avoid biased evaluation, the balance between target-aware and -oblivious examples in the test set should be considered. (3) The \textit{target} should be modelled in a more flexible way, e.g., 
by framing the identification of target-independent and -specific stance features as a pretext task \citep{liang2022zero}. 

\section*{Limitations}
Our study is limited to English rumour stance classification and we are aware that stance may be expressed in different ways in other languages, therefore, further studies are needed to extend this work and its conclusions to languages other than English. Given its importance to the research community, we based our study on RumourEval 2019 dataset alone, however, it is expected that other datasets, potentially covering different events, may have a different stance distribution. In fact, we can already observe this phenomenon when comparing the validation and test sets (Table \ref{tab:results-annotate-target}). 
% Also, the pre-trained base model used in our experiment is limited. BERTweet is pre-trained without next sentence prediction task, following the approach for RoBERTa \citep{liu2019roberta}. Therefore, it is not clear whether a model pre-trained with the next sentence prediction task (e.g., bert-base-uncased \citep{devlin-etal-2019-bert}) would exhibit different performance on the target-aware stance detection model. 
% Finally, we only experiment with fine-tuning pre-trained language models. Other methods, such as propagating conversation information through Graph Convolutional Network \citep{wei-etal-2019-modeling}, may show different results.

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\section{Sentiment Analysis for RumourEval 2019 Training Data}
\label{sec:appendix sentiment} 

We use a RoBERTa-base model fine-tuned for sentiment analysis \citep{barbieri-etal-2020-tweeteval} to categorise the sentiment classes (positive, negative, neutral) for RumourEval 2019 training data. We randomly sample 10 tweets for each stance and manually annotate them. The agreement between manual and model annotation is 0.725. The distribution of sentiment in each stance is shown in Table \ref{tab:sentiment}. 

\begin{table}[h!]
\centering
\scalebox{0.9}{
\begin{tabular}{lcccc}
\toprule
 & Support & Deny & Query & Comment\\
\midrule
Negative & \textbf{47\%} & \textbf{57\%} & 33\% & \textbf{46\%}\\
Neutral & 44\% & 40\% & \textbf{64\%} & 44\%\\
Positive & 9\% & 3\% & 3\% & 10\%\\
\bottomrule
\end{tabular}
}
\caption{Sentiment distribution over stance in the training set. The dominate sentiment is in bold.}
\label{tab:sentiment}
\end{table}

\citet{kaushal-etal-2021-twt} find that most of \textit{denies} in RumourEval 2019 dataset have high negative sentiment, suggesting this correlation between sentiment and stance leads to the impressive performance of the target-oblivious model. But here, we show that negative sentiment not only dominates the \textit{deny} class, but \textit{support} and \textit{comment} classes as well. The observation is consistent with findings by \citet{aldayel2021stance} on SemEval 2016 stance detection dataset \citep{mohammad-etal-2016-semeval} where the three stances, \textit{favor}, \textit{against} and \textit{none}, all skewed to negative sentiment. Furthermore, considering the stance distribution over sentiment, 68\% of the negative tweets belong to the \textit{comment} class, while only 9\% of them are \textit{denies}. Therefore, we hypothesise that the negative sentiment of \textit{denies} cannot significantly contribute to the high performance of the target-oblivious model on RumourEval 2019 dataset.

\section{Pre-processing and Training Process}
\label{sec:appendix finetuning}

\paragraph{Pre-processing.} User mentions, URLs and emojis are treated in the same way as in the pre-training of BERTweet \citep{nguyen-etal-2020-bertweet}. Hashtags are removed from tweets. Most of them are related to the name of the news events rather than the rumour story (the \textit{target}), e.g., \#CharlieHebdo. The max sequence length is set as 128. No input is truncated during tokenization.

\paragraph{BERTWeet, RoBERTa, BERT, and XLNet.} 

We use the \textit{bertweet-base}, \textit{bert-base-uncased}, \textit{roberta-base}, and \textit{xlnet-base-cased}. During fine-tuning, we employ the transformers library \citep{wolf2019huggingface} and adopt AdamW \citep{loshchilov2017decoupled}. We introduce class weights in the loss function to treat the imbalance data problem. According to the distribution of Twitter training data, the weights of the \textit{support}, \textit{deny}, \textit{query} and \textit{comment} are 1.67, 3.15, 2.95, and 0.36 respectively. We also remove the cases from the training data where the stances are annotated for the \textit{source} tweets, in order to avoid confusing the target-aware models due to \textit{source} and \textit{source} pairs. We use grid search for hyperparameter tuning, and the optimal hyperparameters are determined based on $wF2$ score on the official validation set (see Table \ref{tab:hyper} and \ref{tab:hyper-choice} for details). We set the maximum epochs as 30 and use early stopping strategy. The best model checkpoint is selected according to the $wF2$ score on the official validation set. For each model, we repeat the fine-tuning process for five times with different random seeds.

\paragraph{Hierarchical BERT.}

We adopt the author's implementation of the single task model \footnote{\url{https://github.com/jefferyYu/DualHierarchicalTransformer}} for rumour stance detection and re-train it with RumourEval 2019 training set. We use the hyperparameters suggested by the authors. Due to memory limitations, we reduce the batch size from 2 to 1 and tune the learning rate (see Table \ref{tab:hyper} and \ref{tab:hyper-choice}). We repeat the training process for five times with different random seeds. In this model, the source tweet and its replies in a conversation thread are first concatenated in chronological order and then split into ten sub-threads. Each sub-thread is fed to the BERT model to learn a local representation, and an additional BERT layer is built on top to learn a global representation across all the sub-threads.

\paragraph{Branch-LSTM.}

We directly use the official model uploaded for RumourEval 2019 shared task.\footnote{\url{https://github.com/kochkinaelena/RumourEval2019}} This model is a feature-based model, with features about punctuation (e.g., presence of question marks and periods), lexicons (e.g., count of negation and swear words) and attachments (e.g., presence of URL and hashtags), among others. As for word embeddings, it utilises the 300-dimensional Word2Vec model pre-trained on Google News corpus.\footnote{\url{https://code.google.com/archive/p/word2vec/}} Considering the tree structure of the conversation, each thread is split into branches by taking each leaf node reply with all its direct parent replies. The average of word embeddings are used to represent each reply in a branch, which is then fed into unidirectional LSTMs. 

\begin{table}[h!]
\centering
\scalebox{0.7}{
\begin{tabular}{p{0.12\textwidth}|p{0.4\textwidth}}
\toprule
Model & Hyperparameters\\
\midrule
BERTweet & Learning Rate: [1e-5,3e-5,5e-5,7e-5,1e-4], Batch size: [16,32]\\
BERT & Learning Rate: [1e-5,3e-5,5e-5,7e-5,1e-4], Batch size: [16,32], Dropout: [0.1,0.2,0.3]\\
RoBERTa & Learning Rate: [1e-5,3e-5,5e-5,7e-5,1e-4], Batch size: [16,32] \\
XLNet & Learning Rate: [1e-5,3e-5,5e-5,7e-5,1e-4,1e-6, 3e-6,5e-6,7e-6], Batch size: [16,32]\\
Hierarchical BERT & Learning Rate: [1e-5,3e-5,5e-5,7e-5,1e-4]\\
\bottomrule
\end{tabular}
}
\caption{Hyperparameter search for each model.}
\label{tab:hyper}
\end{table}

\begin{table}[h!]
\centering
\scalebox{0.7}{
\begin{tabular}{lccc}
\toprule
Model & Learning Rate & Batch Size & Dropout\\
\midrule
BERTweet (T-O) & 1e-5 & 32 & -\\
BERTweet (T-A) & 1e-5 & 32 & -\\
BERT (T-O) & 3e-5 & 16 & 0.2\\
BERT (T-A) & 3e-5 & 32 & 0.2\\
RoBERTa (T-O) & 1e-5 & 16 & -\\
RoBERTa (T-A) & 1e-5 & 32 & -\\
XLNet (T-O) & 5e-6 & 32 & - \\
XLNet (T-A) & 1e-5 & 16 & - \\
Hierarchical BERT & 3e-5 & - & -\\
\bottomrule
\end{tabular}
}
\caption{Optimal hyperparameter for each model.}
\label{tab:hyper-choice}
\end{table}

\section{Model Performance}
\label{sec:appendix each stance}

Table \ref{tab:results-all-attack} shows the performance drop under the adversarial attacks for the rest of the four models we do not report in the main content of the paper (BERT, RoBERTa, XLNet, and Branch-LSTM). Table \ref{tab:results-f2} shows the performance over each stance on the official and adversarial test sets for all the models. We report F2 score rather than F1 score because recall is more important than precision for this task. 

\begin{table*}
\centering
\scalebox{0.8}{
\begin{tabular}{llccccc}
\hline
Model Name & \textbf{Attack} & \textbf{Version} & \textbf{Support} & \textbf{Deny} & \textbf{Query} & \textbf{Comment}\\
\hline
\multirow{9}{4em}{BERTweet} & Official Test Set & T-O & 0.246 (±0.054) & 0.584 (±0.022) & \textbf{0.752 (±0.029)} & 0.636 (±0.052)\\
&& T-A & 0.222 (±0.109) & 0.515 (±0.048) & 0.703 (±0.070)  & 0.703 (±0.111)\\

& Question Mark & T-O & \textbf{0.253 (±0.058)} & \textbf{0.591 (±0.026)} & 0.629 (±0.040)  & 0.656 (±0.054)\\
&& T-A & 0.225 (±0.108) & 0.522 (±0.053) & 0.534 (±0.077)  & 0.719 (±0.113)\\

& All Punctuation & T-O & 0.226 (±0.053) & 0.573 (±0.039) & 0.632 (±0.038)  & 0.710 (±0.046)\\
&& T-A & 0.212 (±0.132) & 0.511 (±0.049) & 0.536 (±0.081) & \textbf{0.753 (±0.098)}\\

& Negation-\textit{reply} & T-O & 0.034 (±0.028) & 0.365 (±0.019) & 0.517 (±0.107) & 0.106 (±0.055)\\
&& T-A & 0.122 (±0.122) & 0.399 (±0.049) & 0.320 (±0.133) & 0.308 (±0.254)\\

& Negation-\textit{source} & T-A & 0.176 (±0.110) & 0.518 (±0.045) & 0.666 (±0.080) & 0.618 (±0.172)\\
\hline

\multirow{9}{4em}{BERT} & Official Test Set & T-O & \textbf{0.252 (±0.112)} & 0.474 (±0.069) & \textbf{0.674 (±0.037)} & 0.613 (±0.121)\\
&& T-A & 0.166 (±0.072) & 0.444 (±0.092) & 0.656 (±0.026)  & 0.642 (±0.124)\\

& Question Mark & T-O & 0.251 (±0.109) & \textbf{0.484 (±0.074)} & 0.581 (±0.061)  & 0.637 (±0.125)\\
&& T-A & 0.169 (±0.072) & 0.445 (±0.101) & 0.534 (±0.047) & 0.671 (±0.120)\\

& All Punctuation & T-O & 0.236 (±0.115) & 0.417 (±0.103) & 0.581 (±0.056) & 0.671 (±0.124)\\
&& T-A & 0.155 (±0.069) & 0.349 (±0.142) & 0.512 (±0.033) & \textbf{0.747 (±0.067)}\\

& Negation-\textit{reply} & T-O & 0.026 (±0.030) & 0.361 (±0.030) & 0.556 (±0.124) & 0.099 (±0.161)\\
&& T-A & 0.072 (±0.134) & 0.357 (±0.025) & 0.552 (±0.099) & 0.192 (±0.198)\\

& Negation-\textit{source} & T-A & 0.169 (±0.087) & 0.476 (±0.094) & 0.658 (±0.015) & 0.598 (±0.130)\\
\hline

\multirow{9}{4em}{RoBERTa} & Official Test Set & T-O &  \textbf{0.220 (±0.032)} & \textbf{0.523 (±0.016)} & \textbf{0.681 (±0.017)} & 0.642 (±0.060)\\
&& T-A &  0.205 (±0.098) & 0.513(±0.079) &  0.637 (±0.056)  &  0.673(±0.092)\\

& Question Mark & T-O & 0.218 (±0.032) & \textbf{0.523 (±0.021)} & 0.524 (±0.030) & 0.666 (±0.066)\\
&& T-A &  0.208(±0.100) &  0.510 (±0.077) &  0.450 (±0.059)  &  0.694 (±0.095)\\

& All Punctuation & T-O & 0.181 (±0.055) & 0.516 (±0.020) & 0.543 (±0.030)  & 0.719 (±0.079)\\
&& T-A & 0.217 (±0.112) & 0.444 (±0.105) & 0.462 (±0.066) & \textbf{0.743 (±0.056)}\\

& Negation-\textit{reply} & T-O & 0.011 (±0.025) & 0.345 (±0.006) & 0.403 (±0.230) & 0.026 (±0.038)\\
&& T-A & 0.083 (±0.099) & 0.375 (±0.033) & 0.327 (±0.110) & 0.132 (±0.139)\\

& Negation-\textit{source} & T-A & 0.155 (±0.125) & 0.523 (±0.047) & 0.615 (±0.052) & 0.581 (±0.143)\\
\hline

\multirow{9}{4em}{XLNet} & Official Test Set & T-O & 0.177 (±0.052) & 0.389 (±0.035) & 0.616 (±0.052) & 0.648 (±0.043)\\
&& T-A & 0.262 (±0.114) & 0.415 (±0.064) & 0.672 (±0.030) & 0.564 (±0.100)\\

& Question Mark & T-O & 0.181 (±0.049) & 0.388 (±0.042) & 0.393 (±0.082) & 0.664 (±0.040)\\
&& T-A & 0.262 (±0.116) & 0.412 (±0.068) & 0.506 (±0.095) & 0.588 (±0.096)\\

& All Punctuation & T-O & 0.178 (±0.075) & 0.357 (±0.057) & 0.382 (±0.060)  & \textbf{0.720} (±0.041)\\
&& T-A & \textbf{0.271} (±0.116) & 0.381 (±0.060) & 0.477 (±0.070) & 0.635 (±0.095)\\

& Negation-\textit{reply} & T-O & 0.073 (±0.066) & 0.379 (±0.019) & 0.487 (±0.056) & 0.257 (±0.145)\\
&& T-A & 0.152 (±0.147) & 0.390 (±0.028) & 0.642 (±0.082) & 0.299 (±0.104)\\

& Negation-\textit{source} & T-A & 0.175 (±0.127) & \textbf{0.432} (±0.023) & \textbf{0.673} (±0.008) & 0.413 (±0.088)\\
\hline

\multirow{5}{4em}{Hierarchical-BERT} & Official Test Set & T-A &  \textbf{0.088} (±0.010) & 0.206 (±0.079) & \textbf{0.492} (±0.091) & 0.882 (±0.011)\\

& Question Mark & T-A & 0.085 (±0.012) & 0.204 (±0.082) & 0.331 (±0.057)  & 0.890 (±0.005)\\

& All Punctuation & T-A & 0.076 (±0.028) & 0.152 (±0.065) & 0.324 (±0.063)  & \textbf{0.901} (±0.002)\\

& Negation-\textit{reply} & T-A & 0.039 (±0.016) & \textbf{0.329} (±0.009) & 0 (±0.000) & 0.052 (±0.036)\\

& Negation-\textit{source} & T-A & 0.087 (±0.022) & 0.212 (±0.070) & 0.482 (±0.089) & 0.877 (±0.009)\\
\hline

\multirow{5}{4em}{Branch-LSTM} & Official Test Set & T-A & 0.027 & 0.054 & 0.475 & 0.927\\

& Question Mark & T-A &  0.027 & 0.054 & 0.044 & 0.934\\

& All Punctuation & T-A &  0.027 &  0.040 & 0.044 & \textbf{0.935}\\

& Negation-\textit{reply} & T-A &  0.000 &  \textbf{0.302} &  0.377 &  0.840\\

& Negation-\textit{source} & T-A &  \textbf{0.039} &  0.054 & \textbf{0.491} & 0.918\\
\hline

\end{tabular}
}
\caption{Average F2 scores and standard deviations of each stance on the official and adversarial test sets. The best scores for each model are in bold.}
\label{tab:results-f2}
\end{table*}

\begin{table*}[ht!]
\centering
\scalebox{0.7}{
\begin{tabular}{ll|p{1.4cm}p{1.6cm}|p{1.4cm}p{1.6cm}|p{1.4cm}p{1.6cm}|p{1.4cm}p{1.6cm}}
\toprule
Attack & Version & \multicolumn{2}{|c|}{BERT} & \multicolumn{2}{|c|}{RoBERTa} & \multicolumn{2}{|c|}{XLNet} & \multicolumn{2}{|c}{Branch-LSTM} \\
\midrule
& & $wF2$ & macro-$F1$ & $wF2$ & macro-$F1$ & $wF2$ & macro-$F1$ & $wF2$ & macro-$F1$\\
\midrule
Question Mark & T-O & -2.15\% & +0.82\% & \underline{-5.69\%} & -2.90\% & \underline{-8.92\%} & -7.16\% & - & -\\ 
& T-A & \underline{-4.09\%} &  -0.06\% & \underline{-6.45\%} & -3.95\% & \underline{-6.26\%} &  -2.56\% & -42.99\% & -30.47\%\\
\midrule 
All Punctuation & T-O & \underline{-9.56\%} & -1.43\% & \underline{-8.14\%} & -0.14\% & \underline{-12.53\%} & -6.27\% & - & -\\ 
& T-A & \underline{-15.64\%} & -2.18\% & \underline{-10.93\%} & -4.29\% & \underline{-8.98\%} & -2.65\% & \textbf{-46.46\%} & \textbf{-31.79\%}\\ 
\midrule
Negation-\textit{reply} & T-O & \underline{\textbf{-42.40\%}} & \textbf{-51.04\%} & \underline{\textbf{-53.03\%}} & \textbf{-67.25\%} & \underline{\textbf{-24.07\%}} & \textbf{-35.17\%} & - & - \\
& T-A & \underline{-29.48\%} & -40.02\% & \underline{-42.71\%} & -56.69\% & \underline{-17.93\%} & -23.81\% & +46.53\% & +0.87\%\\ 
\midrule 
Negation-\textit{source} & T-A & +3.20\% & -1.75\% & -5.78\% & -9.15\% & \underline{-8.85\%} & -13.85\% & +4.47\% & +1.21\%\\ 
\midrule
\end{tabular}
}
\caption{Influence of each adversarial attack on Branch-LSTM and target-aware and -oblivious BERT, RoBERTa and XLNet. The highest drop performance is in bold. Underline denotes the change of $wF2$ is statistically significant (p value < 0.05, paired t-test).}
\label{tab:results-all-attack}
\end{table*}


Take the best performing model BERTweet as an example, Figure \ref{cm:TO} and \ref{cm:TA} present the confusion matrices of the target-oblivious and -aware BERTweet models on the test sets. We show the results of the models that achieve the highest $wF2$ scores on the official validation set. 

\begin{figure}
\centering
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/r_best.pdf}
\caption{Official Test Set}\label{cm:r_best}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/r_best_qm.pdf}
\caption{Question Mark}\label{cm:r_qm}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/r_best_allpunc.pdf}
\caption{All Punctuation}\label{cm:r_punc}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/r_best_neg.pdf}
\caption{Negation-\textit{reply}}\label{cm:r_neg}
\end{subfigure}
\caption{Confusion matrices for the target-oblivious model on official and adversarial test sets.}
\label{cm:TO}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/s+r_best.pdf}
\caption{Official Test Set}\label{cm:s+r_best}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/s+r_best_qm.pdf}
\caption{Question Mark}\label{cm:s+r_qm}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/s+r_best_allpunc.pdf}
\caption{All Punctuation}\label{cm:s+r_punc}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/s+r_best_neg-reply.pdf}
\caption{Negation-\textit{reply}}\label{cm:s+r_r_neg}
\end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/s+r_best_neg-source.pdf}
\caption{Negation-\textit{source}}\label{cm:s+r_s_neg}
\end{subfigure}
\caption{Confusion matrices for the target-aware model on official and adversarial test sets.}
\label{cm:TA}
\end{figure}

As discussed in the paper, the influence of negation attack towards \textit{source} tweets is inconsistent. Figure \ref{cm:negation source} shows that fake negation in the \textit{source} tweets leads to slight increase of misclassfication of \textit{comments} and \textit{queries} towards the \textit{support} class, in contradiction to the results in Figure \ref{cm:s+r_s_neg}.

\begin{figure}[h!]
\centering

\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/example_s+r.pdf}
\caption{Official Test Set}\label{cm:no attack}
\end{subfigure}
% \begin{subfigure}{0.195\textwidth}
% \includegraphics[width=1\linewidth]{image_pdf/example_s+r_neg_reply.pdf}
% \caption{Negation-\textit{reply}}\label{cm:negation reply}
% \end{subfigure}
\begin{subfigure}{0.195\textwidth}
\includegraphics[width=1\linewidth]{image_pdf/example_s+r_neg_source.pdf}
\caption{Negation-\textit{source}}\label{cm:negation source}
\end{subfigure}

\caption{Examples of inconsistent impact of negation-based attack towards \textit{source} tweets.}
\label{cm:examples}
\end{figure}

%Since both attacks would influence the text length, we also analyse whether the text length would impact the model performance. We calculate the point biserial correlation coefficient between text length (the number of tokens) and model performance (whether the prediction is correct or not) over both validation and test sets, with and without adversarial attacks. The correlation coefficient scores are all less than $\left |0.16 \right|$, therefore, whether the models could make a correct prediction does not significantly correlate to the length of the input. The false predictions are mainly due to the removal of punctuation or introduction of negation terms, rather than changes in the text length. 

\begin{table}[t!]
\centering
\scalebox{0.66}{
\begin{tabular}{p{0.12\textwidth}|cccc}
\toprule
Model & Support & Deny & Query & Comment\\
\midrule
BERT & 0.329±0.146 & 0.670±0.144 &  0.925±0.098 & 0.915±0.045\\
\midrule
RoBERTa & 0.512±0.202 & 0.656±0.147 & 0.918±0.061 & 0.902±0.089\\
\midrule
XLNet & 0.673±0.108 &  0.709±0.088 & 0.914±0.040 & 0.760±0.086\\
\bottomrule
\end{tabular}
}
\caption{The proportion of predictions in each class that would not be influenced by masking the \textit{target}. We show the mean and standard deviation.} %\textbf{S}: Support, \textbf{D}: Deny, \textbf{Q}: Query, \textbf{C}: Comment.}
\label{tab:results-mask-target-others}
\end{table}

\section{Target-Independent and -Dependent Tweets}
\label{sec:appendix target}


\begin{table*}
\centering
\scalebox{0.8}{
\begin{tabular}{lp{9cm}p{8cm}}
\hline
\textbf{Stance} & \textbf{Source Tweet} & \textbf{Reply Tweet}\\
\hline
\multicolumn{3}{l}{Target-dependent replies} \\
\hline
Deny & 267 days since Sick Hillary had a press conference. & @USER wha do you mean she had one with Anderson cooper over the telephone \\
Deny & BREAKING: At least 10 killed in shooting at French satirical newspaper Charlie Hebdo, Paris prosecutor's office says. HTTPURL & @USER 11 killed \\
Support & Germanwings co-pilot had serious depressive episode: Bild newspaper HTTPURL & @USER The pilot was NOT FIT TO FLY ! \\
Support & Report: Red Cross Was Stealing from Church Doorsteps to Redistribute or Sell Items for Profit? (VIDEO) HTTPURL & @USER @USER Stealing is stealing, regardless of how you want to dress it up. \\
\hline
\multicolumn{3}{l}{Target-independent replies} \\
\hline
Deny & BREAKING: Illegal Muslim From Iran Arrested For Starting California Wildfire HTTPURL & @USER No source cited in this article, no date... I would not rely on this and neither should you. \\
Deny & Prince William and Harry donates \$ 100 million to Hurricane Harvey Victims – News 360 HTTPURL & @USER Fake news!! \\
Query & Black Lives Matter THUGS Blocking Emergency Crews From Reaching Hurricane Victims-HTTPURL via @USER & @USER @USER @USER Where and when ? Other links to ? \\
Support & Ongoing hostage situation in Sydney café. Major landmarks like the Sydney Opera House evacuated HTTPURL & Special Prayers for tonight "@USER: Ongoing hostage situation in Sydney café. HTTPURL” \\
Support & Mike Pence Disappointed God Has Never Asked Him To Kill One Of Own Children HTTPURL HTTPURL & @USER There's lot of truth in this \\
\hline
\end{tabular}
}
\caption{Examples of target-independent and -dependent tweets}
\label{tab:more tweet examples}
\end{table*}

Table \ref{tab:more tweet examples} presents examples of target-independent and -dependent tweets in RumourEval 2019 dataset. Most of the target-independent \textit{supports} are retweets and quote tweets. Target-independent \textit{denies} are tweets that clearly cast doubt. Most of the \textit{queries} tend to be target-independent, but the annotator fails to pick out a large number of them because they are not informative (e.g., "@USER @USER blood clot?", "@USER WHAT?") or confused with \textit{denies} (e.g., "@USER @USER @USER Are you on strong opiates or are you an idiot?"). However, they could still potentially be learnt by the model since they are all interrogative sentences and contain question marks. The examples also show that the prediction of target-independent \textit{supports} and \textit{denies} can be challenging, e.g., requiring numeric reasoning between \textit{source} and \textit{reply} tweets.

\end{document}
