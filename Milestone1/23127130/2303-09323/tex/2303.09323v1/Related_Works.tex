\subsection{Deep Learning in Financial Time-series Trend Prediction}
The scientific community generally utilizes two ways for stock market prediction \cite{puneeth2021comparative}. The first approach is the fundamental analysis, where underlying internal and external factors that affect the value of a stock or a company are used as predictive attributes. These factors include the company’s financial performance, social and political behavior, and economic data \cite{beyaz}. The second one is the technical analysis, where the predictive attributes are mainly historical prices and volumes. This method focuses on an analysis of trends in securities’ prices such as daily opening, high, low, and closing prices. Technical analysis is the most common approach in the literature \cite{nazario2017literature}. Since all the new information, like news and macroeconomic variables, are already represented in stock prices, technical analysts believe market price movements tell everything. Therefore, their strategies are based on the stock prices and technical indicators such as relative strength index (RSI) and moving average \cite{nti2020systematic}.\\

Many machine learning \cite{knn, svm1, svm2, ml1} and deep learning \cite{hu2021survey, jiang2021applications, thakkar2021comprehensive} approaches have been proposed to analyze financial time-series for market prediction. The machine learning approaches usually have limited interpretability, need manual feature selection, and perform weakly for very complex tasks. This encourages the integration of deep learning-based models to enhance stock market predictions. The complex intrinsic patterns of stock price trends can be studied using such models by extracting essential characteristics of highly unstructured financial data. Among the deep learning models, Deep ANN and MLP, RNN, LSTM, and CNN have been the dominant models \cite{sezer2020financial}.\\

Deep Artificial Neural Networks and Multi-Layer Perceptron (MLP) have been shown to have superior performance over traditional models \cite{Prime2020ForecastingTC}. \cite{144} used a deep ANN and open, close, high, and low daily prices of the last 10 days of index data. In addition, MLP and ANN were used for the prediction of index data. \cite{142} created an ensemble network of several deep ANN models for trend prediction.  To better handle temporal data, RNN and LSTM are provided as an enhancement of feed-forward neural networks. \cite{jarrah2019recurrent} applied discrete wavelet transform on stock price time-series followed by a deep RNN to predict the closing price of the next 7 days. \cite{186} compared 3 different recurrent models, namely, vanilla RNN, LSTM, and GRU, to predict the movement of stock prices. \cite{133} used LSTM to predict the trend of stock prices and compared the direction of change classification performance with classical time-series forecasting techniques.\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Deep Fully Convolutional Networks}

The idea of dismantling fully connected layers from convolutional layers initially studied in \cite{fcn}, proposing the FCN. The primary objective was to create semantic segmentation map by adapting image classification networks such as AlexNet \cite{alexnet} and VGG \cite{vgg} into fully convolutional networks. The resulting network is considered revolutionary in several aspects. Due to the fully convolutional nature, inference was seen to be considerably faster. More importantly, segmentation maps are allowed to be generated for images with any resolution. And most importantly, they proposed the skip architecture for deep convolutional networks. Deep convolutional networks commonly create feature hierarchies by down-sampling feature maps. Skip connections are used preceding the down-sampling layers to preserve and forward this information to deeper layers allowing information to flow, which would otherwise be lost. This idea to use skip connections in deep convolutional networks eventually evolved into the encoder-decoder structures \cite{segnet, unet} for semantic segmentation. Numerous fully convolutional networks are proposed in this domain, among which we are interested in two types of them that are designed to better capture multi-scale context. \\


A successful encoder-decoder network application is often found in computer vision tasks, such as human pose estimation and object detection. The encoder-decoder network usually consists of two parts: an encoder that gradually reduces the feature maps, while also capturing semantic information, and a decoder that gradually recovers the object details and spatial information. DeconvNet \cite{deconv}, Seg-Net \cite{segnet}, and U-Net \cite{unet} are very well-known examples. They comprise two parts, a contracting path to capture context, and a symmetric expanding path that enables precise localization. However, the highly correlated semantic information, which is provided by the adjacent lower resolution feature map of the encoder, must pass through multiple intermediate layers in order to reach the same decoder stage. This often results in a level of information decay. U-Net overcame this short-coming by utilizing a symmetric skip architecture to provide links between the same-level encoder and decoder stages. Since then, U-Net has been the backbone of many networks for the segmentation of different applications, such as medical images, street view images, satellite images, just to name a few. \\

SegNet utilizes only pooling indices in each stage of the encoder to perform nonlinear up-sampling of the corresponding decoder stage. An issue with encoder-decoder based models is that some of the finer details of an image may be lost due to being part of the resolution that gets lost during encoding. HRNet \cite{hrnet} avoids losing such exact information by connecting the high-to-low resolution convolution streams in a parallel manner and frequently exchanging information between resolutions. They incorporated the multi-scale feature maps in the output node to prevent losing objects at different scales. In fact, many multi-scale models have been proposed. \\


Except using multi-scale features in different stages, many models proposed to also consider multi-scale feature extraction at each stage. Feature Pyramid Network \cite{lin2017feature} is a well-known multiscale analysis model which has been used in different neural network architectures, primarily for object detection but it has also been applied to segmentation. Essentially, the pyramidal hierarchy of deep CNNs is harnessed to create feature pyramids with minimal additional cost. At the same time, to integrate both high- and low- resolution features, the FPN consists of bottom-up and top-down pathways with lateral connections. The spatial pyramid pooling layer adopts parallel convolutional layers with different kernel sizes, then joins the pooled feature maps to fuse feature maps at multiple scales. SPP can effectively increase the extraction range of the backbone features, signiﬁcantly separate the essential contextual features. PSPNet \cite{zhao2017pyramid} applies SPP at several grid scales including image-level pooling. Even though rich semantic information is encoded in the last feature map, detailed information related to object boundaries is missing due to the pooling or convolutions with striding operations within the network backbone. This could be alleviated by applying the atrous convolution to extract denser feature maps. \\


Deeplab V2 \cite{deeplabv2} proposed Atrous Spatial Pyramid Pooling as the feature extraction modules followed by fully connected CRFs. ASPP combines atrous convolutions with different dilation rates in parallel, which can provide multiscale denser contextual information, a larger receptive field, and more local features. Subsequently, \cite{deeplabv3} proposed to omit the CRFs and proposed a deep convolutional network with cascaded and parallel modules of atrous convolutions. And eventually, DeepLabV3+ \cite{deeplabv3+} upgraded the previous design with an encoder-decoder architecture in conjunction with ASPP blocks or Xception \cite{xception} modules. \\
















