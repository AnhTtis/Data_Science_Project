
\begin{table}[t]
  \centering
%   \small
\setlength{\tabcolsep}{5pt}
% \renewcommand{\arraystretch}{0.80}
  \begin{tabular}{l|c|c}
    \toprule
    Attention type& Semantic rel. $\mathcal{R}$ &   OA\\
    \midrule
    Standard Att.  &-- & 86.1\\
    CWPA &$\mathbf{f}_k$    & 88.1\\
    CWPA & $\mathbf{f}_q + \mathbf{f}_k$    & 86.4\\
    CWPA & $\mathbf{f}_q \odot \mathbf{f}_k$&  85.4\\
    CWPA &$\mathbf{f}_q - \mathbf{f}_k$ & \textbf{88.6}\\
    \bottomrule
  \end{tabular}
  
    \caption{\textbf{Performance comparisons of different attention types and semantic relation $\mathcal{R}$ on SONN\_PB.} Attention types : Standard Attention in Transformer~\cite{vaswani2017attention} and channel-wise point attention~(CWPA) with Semantic relation : $\mathcal{R}(\mathbf{f}_q, \mathbf{f}_k)$} %= $ $\mathbf{f}_k$, $\mathbf{f}_q+\mathbf{f}_k$, $\mathbf{f}_q\odot\mathbf{f}_k$, and $\mathbf{f}_q-\mathbf{f}_k$.}
  % \vspace{-5pt}
  \label{table6}
\end{table} 
