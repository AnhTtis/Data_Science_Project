% \subsection{Part Segmentation}
% \label{sec:4.2}
\input{Tables/ShapeNetPart.tex}
\input{Tables/S3DIS.tex}

\paragraph{Part Segmentation.}
For part segmentation, we use \textbf{SN-Part}~\cite{snpart,lee2022sagemix}, which is a synthetic dataset with 16,881 shapes from 16 categories with 50 part labels.
We follow the split used in \cite{qi2017pointnet}, where 14,006 samples are for training and 2,874 samples are for validation. 
On each shape, 2,048 points are randomly sampled.

The results are reported in~\Cref{tab:shapenet}, where we evaluate the performance with the mean of instance IoU (ins. mIoU) and class IoU (cls. mIoU). Following previous works~\cite{liu2019relation,xiang2021walk,xu2021paconv}, we report the results with a multi-scale inference setting. 
Although the performance in SN-Part is quite saturated, SPoTr achieves the best performance 87.2\% with considerable improvements (+0.2\% mIoU).
% We also observed that each SP point of SPoTr recognizes the shape part of where it belongs without its explicit part label.
% See \Cref{sec:4.3} for visualizations.

\paragraph{Scene Segmentation.}
For comparison with previous methods~\cite{qi2017pointnet,thomas2019kpconv,zhao2021point,choe2022pointmixer} on scene segmentation, we validate SPoTr on the widely used benchmark dataset \textbf{S3DIS}~\cite{armeni20163d}. S3DIS is the large-scale dataset containing 271 rooms from 6 indoor areas with 13 semantic categories. In our experiments, we largely follow the settings of PointTransformer~\cite{zhao2021point} and consider Area-5 as the test set.

As shown in~\Cref{tab:s3dis}, SPoTr outperforms all previous methods in every metric (\ie, overall accuracy (OA), mean of class accuracy (mAcc), and mean of instance IoU (mIoU)).
The superior performance over previous Transformer architecture~\cite{zhao2021point} (+0.4\% mIoU) proves the importance of long-range dependency in the semantic segmentation as well as the shape classification.