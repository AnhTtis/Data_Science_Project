\label{sec:2}
% Some recent methods need to be added.
% This includes deep learning methods for point cloud analysis and Transformer  
\paragraph{Deep learning on point clouds.}
The success of CNNs has encouraged adapting CNNs to operate on point clouds rather than using hand-designed features.
Early approaches aim to transform the unstructured point cloud data into a structured form for directly applying convolution.
These include~\cite{su2015multi,guo2016multi,qi2016volumetric,jaritz2019multi,goyal2021revisiting,hamdi2021mvtn}, where they project 3D point clouds to 2D multi-view images for applying 2D convolution.
Other approaches~\cite{liu2019point,maturana2015voxnet,zhou2018voxelnet} convert point clouds to voxel grids, then apply 3D convolution.
However, both approaches have difficulty in preserving intrinsic geometries of point clouds.
To address this issue,  PointNet \cite{qi2017pointnet} directly processes point clouds with multi-layer perceptrons and a max-pooling function. 
However, it blindly aggregates all points without considering local information.
Thus, PointNet++~\cite{qi2017pointnet++} proposes utilizing local information through set abstraction and local grouping.
% Then PointNet++~\cite{qi2017pointnet++} proposed the hierarchical architecture to gradually enlarge the receptive field with set abstraction and local grouping.
For further understanding of local contexts, recent works~\cite{atzmon2018point,li2018pointcnn,wu2019pointconv,thomas2019kpconv,wang2018deep,xu2021paconv,xu2018spidercnn,zhou2021adaptive,ma2022rethinking, ran2022surface} have proposed explicit convolution kernels on the point space.
KPConv~\cite{thomas2019kpconv} has applied deformable convolution~\cite{dai2017deformable,zhu2019deformable} to capture local information of point clouds.
PointNeXt~\cite{qian2022pointnext} has revisited PointNet++ by fully exploring its potential with improved training and augmentation schemes.
Although the representation power has been improved by capturing local information, the ability to capture long-range dependencies is limited.
% Although convolution-based approaches improve the representation power by capturing local information, the ability to capture long-range dependencies is limited.
SPoTr is the Transformer for point clouds equipped with global cross-attention to capture long-range dependencies.   

\paragraph{Attention-based methods on 2D images.}
Following the success of self-attention and Transformers~\cite{vaswani2017attention} in natural language understanding, many efforts have been made in the computer vision to replace convolution layers with self-attention layers~\cite{dosovitskiy2020image,ramachandran2019stand,hu2019local,parmar2018image,chen2020generative,cordonnier2019relationship}.
Despite the success, self-attention requires the quadratic computational cost with respect to the input image size.
To address the scalability issue, several works adopt self-attention within local neighborhoods~\cite{liu2021swin,wang2021pyramid}.
Swin Transformer~\cite{liu2021swin} utilizes non-overlapping windows and performs self-attention within each local window to get linear computational complexity in the number of input pixels.
Other works explore global attention mechanisms with a small set of queries or keys to reduce complexity~\cite{chu2021Twins,jaegle2021perceiver,zhu2020deformable}.
Twins~\cite{chu2021Twins} applies attention with a small set of representatives. %for efficiency.
Inspired by recent works, we suggest an efficient global cross-attention with only a small set of self-positioning points for point clouds.

\paragraph{Attention-based methods on point clouds.}
Recently, \cite{yan2020pointasnl,xie2018attentional,lee2019set,guo2021pct,zhao2021point,ran2021learning,mazur2021cloud,choe2022pointmixer, xiang2021walk} have adopted attention operations for point cloud processing. 
PointASNL~\cite{yan2020pointasnl} leverages the attention operation to non-locally influence entire points.
RPNet~\cite{ran2021learning} proposes attention-based modules for capturing local semantic and positional relations.
PointTransformer~\cite{zhao2021point} performs self-attention only within local neighborhoods.
CloudTransformer~\cite{mazur2021cloud} inspired by spatial transformer~\cite{jaderberg2015spatial}, uses an attention mechanism to transform the point cloud into a voxel grid for convolutional operation.
Although these works have proven to be effective, most works have neglected the capability of Transformers to capture long-range dependencies due to their quadratic computational cost to the number of input points.
In this paper, we aim to design Transformer architecture to capture both local and global information with a modest computational cost.

% With the advent of convolutional neural networks~(CNNs), a variety of methods have been proposed to apply CNNs on point clouds. 
% %  adopts CNN on point cloud.
% These include view-based methods~\cite{su2015multi, guo2016multi, qi2016volumetric, jaritz2019multi, goyal2021revisiting, hamdi2021mvtn} where they change the 3D point clouds into 2D images by projecting them on 2D spaces.
% Other works~\cite{liu2019point, wu20153d, maturana2015voxnet,zhou2018voxelnet} rasterize the point clouds into voxel images to directly apply 3D convolution.  
% But, both methods have a difficulty preserving the geometric properties of point clouds.
% To address this issue, point-based methods have been presented.



% To address this issue, \cite{qi2017pointnet} proposes a PointNet that directly processes point clouds with multi-layer perceptrons and max-pooling function. 
% However, it blindly aggregates all points without considering local information.
% Thus, PointNet++~\cite{qi2017pointnet++} proposed the hierarchical architecture with to utilize local information through set abstraction and grouping.

% extracts point-wise features with shared multi-layer perceptrons and aggregates them using symmetric functions such as max-pooling.
% Several methods change point clouds into two-dimensional grid sapce  
% These methods inevitably depends on projecting operation onto two-dimensional space (\eg bird's-eye view or multi-view projection) to apply CNN, which brings them intrinsic problems like occlusion or loss of density. 
% In another way, \cite{liu2019point, wu20153d, maturana2015voxnet,zhou2018voxelnet} rasterize the point cloud to voxel images to apply 3D CNN.
% Yet, they still suffer from the trade-offs between the characteristic of the shape and the cubic computational cost due to the resolution. 
% To handle this issue, OCNN~\cite{wang2017cnn} and OctNet~\cite{riegler2017octnet} adopt octree structure, and MinkowskiNet~\cite{choy20194d} neglects the empty grid with sparse convolution.
% \SH{
% As a pioneering work to understand unordered point set itself, \cite{qi2017pointnet} proposes a PointNet that extracts point-wise features with shared multi-layer perceptrons and aggregates them using symmetric functions.
% However, it failed to capture local structure, and PointNet++ \cite{qi2017pointnet++} extends \cite{qi2017pointnet} to hierarchical structure using set abstraction. 
% Following \cite{qi2017pointnet++}, diverse convolutional methods for extracting representations from locally-grouped points have been introduced \cite{liu2019relation,thomas2019kpconv, li2018pointcnn, atzmon2018point, xu2018spidercnn, wu2019pointconv, xu2021paconv}. 
% In parallel with these, other studies~\cite{yan2020pointasnl, wang2019dynamic} also focus on the importance of long-range dependency.
% DGCNN~\cite{wang2019dynamic} proposes EdgeConv that dynamically updates graph on feature space to group semantically similar points. 
% A-SCN~\cite{xie2018attentional} uses self-attention on entire points, but it does not get good performance due to the lack of local information.
% On the contrary, PointASNL~\cite{yan2020pointasnl} leverages the global features by non-local module~\cite{wang2018non} after local operation.
% Following these attempts, recent studies explore self-attention and Transformer to guarantee long-range dependencies for point clouds.}
% More recently, CurveNet~\cite{xiang2021walk} tackles long-range relations with the guided walks on the point cloud generating curve rather using k-nearest neighbors. 

% employ self-attention to replace convolution layers and achieves successful speed-accuracy trade-off compared to convolutional networks. 
% One of the important works, ViT~\cite{dosovitskiy2020image}, directly applies a Transformer encoder for image recognition with a successful speed-accuracy trade-off compared to convolutional networks.
% Most of them /

% or approximating it with a reduced set of queries or keys~\cite{chu2021Twins,jaegle2021perceiver,zhu2020deformable}.


% self-attention with local neighborhoods and global cross-attention to perform attention operations with reduced complexity. 
% To directly perform attention on points, w
% With \cite{dosovitskiy2020image}, Transformer based approaches~\cite{liu2021swin,chu2021Twins,wang2021pyramid} bring the noticeable expansions of self-attention and Transformer in computer vision.

% A-SCN~\cite{xie2018attentional} performs self-attention on entire points, but it does not get good performance due to the lack of local information.

% PointTransformer~\cite{zhao2021point} introduces the Transformer architecture encoding the points with nearest neighbors. 
% Another work RPNet~\cite{ran2021learning} explored a aggregator to understand both positional relations and semantic relations in local point sets by integrating RS-CNN~\cite{liu2019relation} and self-attention. 

% Point2Sequence~\cite{liu2019point2sequence}, considering point set as a sequence, consists of encoder with RNN and attention-based decoder.

% \SH{\paragraph{Transformers on Point Cloud} Following the early success of self-attention~\cite{vaswani2017attention} in NLP, ViT~\cite{dosovitskiy2020image} considers images as a set of patches and
% successfully propose the Transformer in computer vision. With \cite{dosovitskiy2020image}, Transformer based approaches~\cite{liu2021swin,chu2021Twins,wang2021pyramid} bring the noticeable expansions of self-attention and Transformer in computer vision.
% concurrently, \cite{yan2020pointasnl, xie2018attentional, lee2019set, guo2021pct, zhao2021point, ran2021learning, mazur2021cloud} propose the network to encodes the representations of the point cloud using self-attention. Recent study PointTransformer~\cite{zhao2021point} introduces the Transformer architecture encoding the points with nearest neighbors. Another work RPNet~\cite{ran2021learning} explore a aggregator to understand both positional relations and semantic relations in local point sets by integrating RS-CNN~\cite{liu2019relation} and self-attention. Although these works have shown compelling competitiveness compared with previous studies, long-range dependency, key intuition of Transformer, is less explored in point cloud domain due to the high computational cost of global self-attention.
% }
% \SH{
% To this end, we present SPoTr that sequentially reflects the local and global information inspired by Twins~\cite{chu2021Twins} that introduces more inductive bias using locally-grouped self-attention and globally sampled representative.
% SPoTr dynamically extracts global representative in sample-aware way with self-positioned receptive fields, and it makes our model more applicable for irregular domains. 
% Furthermore, we achieve this with the computational cost linear to the number of points alleviating the original quadratic cost of global self-attention.
% }