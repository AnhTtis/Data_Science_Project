\label{sec:1}
% Enabling convolutional neural networks (CNNs) to directly operate on point clouds has 
Point clouds have been widely applied in various areas such as autonomous driving, robotics, and augmented reality.  
Since the point cloud is an unordered set of points with irregular structures, adopting convolutional neural networks~(CNNs) on point clouds is challenging.
Some works devoted effort to transforming point clouds into regular structures, such as projection to multi-view images~\cite{su2015multi,chen2017multi} and voxelization~\cite{maturana2015voxnet,zhou2018voxelnet}.
Others have tried to preserve the structure and design a convolution on the point space~\cite{liu2019relation,thomas2019kpconv,li2018pointcnn,atzmon2018point,xu2018spidercnn,wu2019pointconv,xu2021paconv}.
% However, the ability to capture long-range dependencies is limited in most convolution-based approaches while it is crucial to understand global shape context, especially with noisy and real-world data~\cite{uy2019revisiting}.
However, the ability to capture long-range dependencies is limited in most convolution-based approaches, while it is crucial to understand global shape context, especially with real-world data~\cite{uy2019revisiting}.

Transformer~\cite{vaswani2017attention} tackled the long-range dependency issue in natural language processing and later it has been actively extended to 2D image processing~\cite{dosovitskiy2020image,liu2021swin,chu2021Twins,wang2021pyramid}.
Early works tried to replace convolutional layers with self-attention~\cite{dosovitskiy2020image,ramachandran2019stand,hu2019local,parmar2018image,chen2020generative,cordonnier2019relationship}, but they struggled with the quadratic computational cost of self-attention to the number of pixels.
To mitigate the scalability issue, self-attention in local neighborhoods~\cite{liu2021swin,wang2021pyramid} or approximating a self-attention with a reduced set of queries or keys~\cite{chu2021Twins,jaegle2021perceiver,zhu2020deformable} have been studied.
% To mitigate the scalability issue, several efforts have been made such as applying self-attention in local neighborhoods~\cite{liu2021swin,wang2021pyramid} or approximating it with a reduced set of queries or keys~\cite{chu2021Twins,jaegle2021perceiver,zhu2020deformable,xiong2021nystromformer}.
For point clouds, Point Transformer~\cite{zhao2021point} applies a local attention operation~(\Cref{fig:local_att}) and PointASNL \cite{yan2020pointasnl} employs a global attention module in a non-local manner~(\Cref{fig:global_att}).
Still, in point clouds, Transformer, which tackles both long-range dependency and scalability issues, has been less explored.

% \input{Table&Figure/fig1}


\input{Fig_tex/attentions.tex}

In this paper, we propose \textbf{S}elf-\textbf{Po}sitioning point-based \textbf{Tr}ansformer (SPoTr) to capture both local and global shape contexts with reduced complexity.
% SPoTr consists of two attention modules: local attention and global attention, \yunyang{where the latter is a newly proposed attention mechanism to alleviate the complexity of global attention}.
SPoTr block consists of two attention modules: (i) \textit{local points attention}~(LPA) to learn local structures and (ii) \textit{self-positioning point-based attention}~(SPA) to embrace global information via self-positioning points. 
% where the latter is a newly proposed attention mechanism for point clouds to alleviate the complexity of global attention.
% To address the scalability issue, SPA computes global attention weights with only a small set of self-positioning focal points instead of the whole input points
SPA performs global attention by computing attention weights with only a small set of Self-Positioning points~(SP points) instead of the whole input points different from the standard global attention as illustrated in \Cref{fig:spotr_att}.
Specifically, SP points are adaptively located based on the input shape to cover the overall shape with only a small set of points. 
SP points learn its representation  considering both spatial and semantic proximity through \textit{disentangled attention}.
% Specifically, SPA aggregates information on each SP point through disentangled attention.
% As shown in the bottom row of \Cref{fig:sprf}, disentangled attention improves the descriptive power of the receptive field by considering both spatial and semantic proximity with separated kernels.
{Then, SPA non-locally distributes information of SP points to each input point.
% Also, we analyze that our SPoTr block has the stronger expressive power to represent point clouds by showing other point-based layers are its special case.
We also show that our SPoTr block generalizes set abstraction~\cite{qi2017pointnet++} with improved expressive power.}

Further, we propose SPoTr architecture for standard point cloud tasks (\eg, shape classification and semantic segmentation).
We conduct extensive experiments with three datasets: ScanObjectNN~\cite{uy2019revisiting}, SN-Part~\cite{snpart}, and S3DIS~\cite{armeni20163d}.
Our proposed method shows its effectiveness on all datasets compared to other attention-based methods.
In particular, our architecture achieves an accuracy improvement of 2.6\% over the previous best model in shape classification with a real-world dataset ScanObjectNN.
Additionally, we demonstrate the effectiveness and interpretability of self-positioning point-based attention with qualitative analyses.  

The \textbf{contribution} of our paper can be summarized as the following:
\begin{itemize}
    \item[\textbullet] We design a novel Transformer architecture (SPoTr) to tackle the long-range dependency issues and the scalability issue of Transformer for point clouds.
    \item[\textbullet] We propose a global cross-attention mechanism with flexible self-positioning points (SPA). SPA aggregates information on a few self-positioning points via disentangled attention and non-locally distributes information to semantically related points.
    \item[\textbullet] SPoTr achieves the best performance on three point cloud benchmark datasets (SONN, SN-Part, and S3DIS) against strong baselines.
    \item[\textbullet] Our qualitative analyses show the effectiveness and interpretability of SPA.
    % \item[\textbullet] We design a novel Transformer architecture (SPoTr), which captures both local and global shape information and tackles the scalability issue of Transformer for point clouds.
    % \item[\textbullet] We propose a global cross-attention mechanism with flexible self-positioning receptive fields (SPA). SPA aggregates information on each focal point via disentangled attention and non-locally distributes information to semantically related points.
    % \item[\textbullet] SPoTr achieves competitive performance regarding standard point cloud tasks such as shape classification, part segmentation, and scene segmentation.
    % \item[\textbullet] Our qualitative results demonstrate the effectiveness and interpretability of SPA.
\end{itemize}

% Still, scalable Transformer for long-range dependency in point cloud have been less explored.
% Still, point cloud works trying to emulate vision transformers have been less explored.
% - keyword 추가, scailable, vision transformers 어색, point cloud works 어색
% 
% still transformers for point clouds.
% 'scalable and long-range dependency aware'

% Although recent point cloud works try to emulate vision transformers in 2D vision, they still have been less explored.
% , it has become a \textit{de facto} architecture in natural language processing. 
% Henceforth, transformer-based models have been actively proposed to computer vision~\cite{dosovitskiy2020image,ramachandran2019stand,carion2020end,parmar2018image,liu2021swin,chu2021Twins}.

% \begin{itemize}
%     % \item We propose SPoTr, transformer-based architectures for point cloud processing. 
%     % SPoTr captures both global long-range distance information and local short-range distance information using self-positioning receptive fields. 
%     % \item We propose self-positioning receptive fields for attention operation, which reduces computational complexity of standard attention operations while  
%     % \item We propose Self-Positioning points based Attention (SPA) blocks which consist of local self-attention and global cross-attention. 
%     % SPA eliminates the quadratic complexity issue of attention in the transformer with a small set of self-positioning points.


%     \item We design a novel Transformer architecture~(SPoTr) for point clouds based on the SPoTr block, which captures both local and global information only using the attention modules and feed-forward networks.
    
%     \item We propose a global cross-attention mechanism with flexible self-positioning receptive fields.
%     The self-positioning receptive fields take spatial/semantic information into account being interpretable.
%     \SH{
%     \item  We propose a new global cross-attention mechanism with flexible self-positioning receptive fields.
%     The 
%     that consider spatial/semantic proximity to the focal point. 
%     }
    
%     \item Our proposed method shows consistently \SH{good} performance on 3D shape classification and 3D segmentation.
%     In particular, SPoTr achieves state-of-the-art performance on the hardest version of ScanObjectNN dataset. 
%     We also demonstrate the effectiveness of SPA through qualitative analysis providing interpretability. 
% \end{itemize}

% except for the hierarchical architecture from~\cite{qi2017pointnet++} to enlarge the receptive field.
% Especially with noisy real-world data like~\cite{uy2019revisiting}, capturing long-range dependencies are crucial to understand the global shape context.

% \jyp{
% In recent years, 3D point clouds has attracted a lot of attention in various applications such as robotics, autonomous driving, and augmented reality. 
% With the success of deep learning on image recognition, many works explore deep learning on point clouds.
% However, learning representations on point clouds can be challenging compared to learning on 2D images.
% Unlike 2D images, which are represented in regular grid, the 3D point clouds consist of point sets expressed in irregular continuous space. 
% This irregular property makes difficult to apply standard discrete convolution neural networks on point clouds.
% }
% \jyp{
% In recent years, 3D point clouds has attracted a lot of attention in various applications such as robotics, autonomous driving, and augmented reality. 
% With the success of convolutional neural networks~(CNNs) on image recognition~\cite{simonyan2014very,he2016deep}, a variety of approaches have been proposed to directly applying CNNs on point clouds by modifying point clouds into regular voxels~\cite{wu20153d,maturana2015voxnet,zhou2018voxelnet} or projected images~\cite{su2015multi,chen2017multi}.
% % However, learning representations on point clouds can be challenging compared to learning on 2D images.
% % Unlike 2D images, which are represented in regular grid, the 3D point clouds consist of point sets expressed in irregular continuous space. 
% However, voxelization and projection not only require heavy computational and memory costs but also induce the loss of geometric information.
% % This irregular property makes difficult to apply standard discrete convolution neural networks on point clouds.
% }

% \jyp{
% A variety of deep networks have been proposed to address this challenge.
% Some prior works modify point clouds into regular voxels~\cite{wu20153d,maturana2015voxnet,zhou2018voxelnet} or projected images~\cite{su2015multi,chen2017multi} for applying standard convolution operation.
% However, voxelization and projection not only require heavy computational and memory costs but also induce the loss of geometric information.
% To address them, many networks that operate directly on point clouds have been presented. 
% Most of them are based on local convolutional neighborhoods without considering long-range dependencies.
% % Most of them continuous convolution~\cite{liu2019relation,thomas2019kpconv}, mlp-based~\cite{qi2017pointnet,qi2017pointnet++} and graph-based methods.
% % sentence 반전
% }
% \jyp{
% To address these challenges, most recent methods~\cite{qi2017pointnet,qi2017pointnet++,liu2019relation,wang2019dynamic} have been proposed to learn point representation by directly processing point cloud data.
% Most of them utilize the spatial proximity between points to capture short-range dependencies without considering long-range dependencies.
% % More recently, some works have designed convolution-like operations on point clouds considering spatial proximity between points.
% % Beyond MLP-based works, 
% % Though impressive, 
% % Most of them continuous convolution~\cite{liu2019relation,thomas2019kpconv}, mlp-based~\cite{qi2017pointnet,qi2017pointnet++} and graph-based methods.
% % sentence 반전
% }

% % Recently, Transformer, which applies an attention to capture long-range dependencies, have proven their effectiveness in natural language processing. 
% % % Inspired by its success, many researchers extend it to computer vision and demonstrate remarkable performance.
% % Inspired by its success, many researchers have tried to extend it to computer vision and achieves remarkable performance~\cite{dosovitskiy2020image,ramachandran2019stand,carion2020end,parmar2018image,liu2021swin,chu2021Twins}.
% % Different from the natural language processing, it is challenging to directly apply self-attention on images since the self-attention operation requires quadratic computational costs in the number of pixels.
% One of the important works, ViT~\cite{dosovitskiy2020image}, successfully applied a Transformer-based backbone for image recognition. 
% % by merging pixels into fixed-size patches and applying the Transformer encoder on them.
% Even if it achieved an impressive speed-accuracy tradeoff compared to convolutional networks, it requires quadratic computational costs with respect to the image size.
% To avoid the heavy computational costs of the self-attention, several works have been proposed by applying self-attention operation only in local neighborhoods~\cite{liu2021swin,wang2021pyramid} or approximating it with reduced set of queries or keys~\cite{chu2021Twins,jaegle2021perceiver,zhu2020deformable}.
% % Twins~\cite{chu2021Twins}
% % Swins~\cite{liu2021swin}
% For processing point clouds, Point-ASNL~\cite{yan2020pointasnl} applies self-attention to capture long-range dependencies.
% However, self-attention have quadratic computation complexity to the number of input points.                                                                    
% % \jyp{
% % In this paper, we design architectures for point clouds processing motivated by the success of Transformers in various tasks such as natural language processing~\cite{vaswani2017attention,devlin2018bert} and 2D image recognition~\cite{dosovitskiy2020image,liu2021swin}.
% % }
% \jyp{
% In this paper, we propose a \textbf{S}elf-\textbf{Po}sitioning receptive fields based \textbf{Tr}ansformer~(SPoTr), which can capture both local and global information with linear complexity to the number of points.
% % It learns representation of points considering long-range information as well as short-range information using attention operations in the Transformer.
% % We design a Transformer-based architecture to process point clouds motivated by the success of Transformers on image recognition~\cite{dosovitskiy2020image,liu2021swin,carion2020end} and natural language processing~\cite{vaswani2017attention,devlin2018bert} with their abilities to capture long-range dependencies.
% SPoTr constructs powerful point cloud representations with local points self-attention~(LPA) and self-positioning receptive fields based global cross-attention~(SPA), in which LPA captures short-range information and SPA focuses on long-range information.
% }

% \jyp{
% % A key design component of SPoTr is self-positioning receptive fields, which are dynamically positioned according to the shape of sample, as illustrated in \Cref{fig:sprf}.
% % The goal of the self-positioning receptive fields is to propagate information of their peripherals to all points in the cross-attention manner.
% A key element of SPoTr is self-positioning receptive field, which aims to propagate its peripheral information to all points in the cross-attention manner.
% As illustrated in \Cref{fig:sprf}, the model simultaneously learns the position and shape of the self-positioning receptive fields by considering the overall point set and spatial/semantic information with bilateral filters.  
% % 예시든 더 구체적인거 추가
% % For example, the self-positioning receptive field, which is denoted by
% % The figure shows that a small set of self-positioning receptive fields, which are denoted by red star, are adaptively located according to the sample and constructed 
% % Before propagating, they aggregate information of their local parts with bilateral filters.
% }
% We validate our model in three tasks such as shape classification, object part segmentation and scene segmentation with four datasets.
% Our proposed methods consistently shows their effectiveness on all datasets compared to other attention-based methods.
% In particular, our architecture achieves an accuracy gain of 2.5\% over the current state-of-the-art model on shape classification with realworld dataset ScanObjectNN.
% Also, we demonstrate the effectiveness of self-positioning receptive fields with qualitative analyses.  