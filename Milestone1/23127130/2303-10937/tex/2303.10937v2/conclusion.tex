\textbf{Conclusion.}
We show depth boosts weakly-supervised object detection methods, tested on SoS-WSOD and MIST, without extra annotation or costly computation. 
%Because we use depth modality only during training, the same inference setting with baseline methods is used. 
Our Siamese WSOD network efficiently incorporates RGB and depth with contrastive learning and fusion. Using the relation of language and depth, depth priors estimate the bounding box proposals that may contain an object of interest.
%by improving OICR and attending with score probabilities. 
%We showed our method boosts two WSOD methods, . 

\textbf{Acknowledgement:} This work was supported by a National Science Foundation Award No. 2046853, and a University of Pittsburgh Momentum Funds award. 
