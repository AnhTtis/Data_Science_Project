\section{Preliminaries} \label{sec:pre}

This section describes the terminologies and concepts used throughout the rest of this paper. \\

\noindent\textbf{Robustness.} \textit{Given a network $\mathcal{N} : \mathcal{X} \rightarrow L(\mathcal{X})$, $\mathcal{N}$ is said to be robust iff the addition of noise $\epsilon \leq N$ to any input $x \in \mathcal{X}$ does not change the output classification of $x$, i.e., $\mathcal{N}(x) = \mathcal{N}(x + \epsilon)$.}

However, given the large (and often infinite) size of the input domain $\mathcal{X}$, it is often infeasible to check the global robustness of the network. Hence, the local robustness of the input domain, surrounding seed inputs, i.e., $x+\epsilon: \epsilon\leq N$ is instead the focus of the practical analysis. \\

\noindent\textbf{Robustness Bias. } \textit{Given a network $\mathcal{N} : \mathcal{X} \rightarrow L(\mathcal{X})$, where $L(\mathcal{X})$ comprises of $\mathcal{C}$ output classes (i.e., $L(\mathcal{X})=\{1,...,\mathcal{C}\}$), robustness bias defines the robustness of individual output classes. This means, robustness bias holds for $\mathcal{N}$ iff the probability of correct classification for inputs $x_k$ belonging to all output classes $k \in L(\mathcal{X})$, under the incidence of noise $\epsilon \leq N$, is equal, i.e., $\forall k \in L(\mathcal{X}), \mathds{P}[\mathcal{N}(x_k) = \mathcal{N}(x_k + \epsilon)] = const$.}

A lack of robustness bias could be attributed to long-tail distribution of the training dataset \cite{bhatti2022formal}, with the probability of correct classification for head classes being higher than that for the tail classes, in the trained DNN.\\
% i.e., the number of inputs belonging to the \textit{``head"} classes is much larger than that belonging to the \textit{``tail"} classes. \\

\noindent\textbf{Node Sensitivity. } \textit{Given a network $\mathcal{N}: \mathcal{X} \rightarrow L(\mathcal{X})$, where each input comprises of $n$ input nodes, node sensitivity determines the robustness of individual input nodes under the incidence of the node noise $\eta \leq N$.}

In principle, an input node may be sensitive or insensitive to a specific kind of noise, for instance to the positive noise or the noise bounded by specific constraints. \\

\noindent\textbf{Node (Robustness) Bias. } \textit{Given a network $\mathcal{N} : \mathcal{X} \rightarrow L(\mathcal{X})$, where $L(\mathcal{X})$ comprises of $\mathcal{C}$ output classes (i.e., $L(\mathcal{X})=\{1,...,\mathcal{C}\}$) and each input comprises of $n$ input nodes, node (robustness) bias defines the robustness of individual input nodes for each output class. This means, node (robustness) bias holds for the input node $x_k^i \in x_k$ iff the probability of correct classification for input $x_k$ belonging to all output classes $k \in L(\mathcal{X})$ when noise $\eta \leq N$ is incident to node $x_k^i$, is equal, i.e., $ \forall k \in L(\mathcal{X}), \forall i \in n. \mathds{P}[\mathcal{N}(x_k) = \mathcal{N}(x_k\setminus x_k^i,x_k^i + \eta)] = const$.}

% (The superscript $i$ in $x_k^i$ indicates the node of the input $x_k$.) 
The intuition behind the analysis of node (robustness) bias is to ensure that each input node has a consistent sensitivity for inputs belonging to all output classes.

