\section{Related Works}
Long-tail distribution is a widely studied challenge in DNN research community, since it is often associated with a varying classification performance of the network for \textit{head} and \textit{tail} classes \cite{class-imbalance-survey,2022longtail}. 
Numerous pre-training, training, fine-tuning and transfer-learning approaches have been proposed to ensure the overall classification performance stays consistent for all classes \cite{zhang2021bag,longtail_lossfunc,trans_learning,chawla2002smote,feature_trans_learn,tail-noise}.
% Dealing with it is distributed in 3 parts of the design cycle \cite{zhang2021bag,2022longtail}: imbalanced learning \cite{class-imbalance-learning2020,longtail_lossfunc,weight_balancing}, fine-tuning and transfer learning \cite{trans_learning}, dataset balancing (feature transfer learning to synthesize new data \cite{chawla2002smote,he2008adasyn,feature_trans_learn}, existing data manipulation \cite{rus,ros}, noisy tail \cite{tail-noise}).
% Large variance within specific class is not good either (sub-class within class may still be very rare and difficult to learn) \cite{jiang2022improving}
Recently, robustness bias was shown to be a concern for DNNs with noisy inputs \cite{rbias}. 
It was also shown that such a bias may inadvertently be a consequence of long-tail distribution of the training dataset \cite{bhatti2022formal}. 
It was also shown that the such bias is not just a result of long-tail distribution, but may also be the consequence of the unequal data representation of the training data samples \cite{naseer2023unbiasednets}.  
However, the robustness bias of the network was studied for the inputs as a whole, ignoring the bias for individual input nodes. %entire inputs - this do not address the question of the robustness bias of individual input nodes.

Orthogonally, the sensitivity of input nodes has also been explored in the literature \cite{feature_bias,yao2003sensitivity}. 
These works aim to identify the most relevant input features for learning, the determination of which, could then be used for network simplification (for instance, via input pruning \cite{input-sens1,chen2020sensitivity}) or ensuring the privacy of sensitive input features \cite{sens4fair1_dnn,sens4fair2_dnn}.
However, this is essentially different from our work, which caters for the sensitivity of input nodes under the impact of noise, which could be different from that on clean inputs. 

% Sensitivity analysis (in general) - how much output change by the change in inputs - to find which input/features are important \cite{yao2003sensitivity} --- but could also be to study impact of other factors (like network parameters) on some response (contribution to a network layer)
% Sensivity under noise can also be used for determining imp features \cite{IS2017,input-sens2}... more sensitive = more imp 
% Google scholar search of 2 concepts together -- how to remove/obfuscate sensitive attributes (like gender and ethnicity) to obtain an unbiased network or ensure privacy \cite{sens4fair1_dnn,sens4fair1_gnn,sens4fair2_dnn,sens4fair4_gnn}. 
