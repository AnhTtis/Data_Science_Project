\section{Proposed Framework}

Fig. \ref{fig:meth} provides an overview of our proposed analysis framework to study the node (robustness) bias of the trained networks. 
The architecture and parameter details of the trained DNN are initially used to construct the formal model of the network \cite{bhatti2022formal}. 
The formal model is validated using inputs from the testing dataset (i.e., the correct and model's computed output classification of the testing inputs are compared for consistency of results). 
The sensitivity of the input nodes is then analyzed using a probabilistic model checker as follows:
\begin{equation*}
    \mathds{P}_{=?}[\mathds{F}(\mathcal{N}(x) = \mathcal{N}(x\setminus x^i,x^i + \eta)) \land (\eta \leq N)],
\end{equation*}
    
where $i$ is the node under sensitivity analysis and $\mathds{F}(\mathcal{N}(x) = \mathcal{N}(x\setminus x^i,x^i + \eta))$ indicates that the network eventually provides correct output classification for input $x$. This is repeated iteratively, while gradually increasing the incident noise applied to the testing inputs. 
The exact node sensitivity results are then analyzed for individual input nodes to understand the node (robustness) bias. 
This is achieved initially using network trained on the complete dataset.
% This is shown in blue box in Fig. \ref{fig:meth}.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=\linewidth]{Figures/framework.pdf}
\end{center}
\caption{Overview of our proposed framework for node (robustness) bias analysis. The training dataset could be complete or truncated to obtain a dataset to avoid long-tail distribution.}%The blue (top) presents the analysis for DNNs trained on the entire training dataset, while the orange box (bottom) presents the analysis for a truncated dataset that no longer composes long-tail distribution.}
\label{fig:meth} 
\end{figure}

As indicated in earlier sections, the classification performance of the trained network may vary for networks trained on training datasets with long-tail distribution. 
Intuitively, this suggests that a network trained on dataset with an equal number of inputs from each class might address the discrepancy in classification performance across different classes \cite{class-imbalance-survey} and ensure that node (robustness) bias holds for the network. 
To test the hypothesis, we truncate the training dataset by deleting inputs from the head class(es), and repeat the analysis on this new dataset (which no longer has a long-tail distribution). 
% This is shown in the orange box in Fig. \ref{fig:meth}.

\section{Case Study}
This section provides a case study to highlight the node (robustness) bias in a DNN trained on real dataset. This is followed by a discussion of the results and analysis.%findings from the study.

\subsection{Experimental Setup}
We train single-hidden layer ReLU-based fully-connected neural networks on the top$-5$ relevant features of Leukemia dataset \cite{matlab-leukemia}. 
The training dataset comprises of $38$ inputs, with the head class (i.e., ALL Leukemia) constituting approximately $70\%$ of the dataset, while the tail class (i.e., AML Leukemia) constitutes the remaining dataset. 
% Fig. \ref{fig:stats} summarizes the spread of input node values from the training and testing dataset. 
% \begin{figure}[ht]
% \begin{center}
% \includegraphics[width=\linewidth]{Figures/BW_stats.pdf}
% \end{center}
% \caption{Node 5 doesn't have outlier performance}
% \label{fig:stats} 
% \end{figure}

The experiments were repeated $10$ times, while noting the results for the networks trained on the complete dataset. 
Similarly, $10$ networks were also trained on a truncated dataset via deleting randomly selected subset of inputs from the head class, before each training. 
This ensures an equal number of inputs from each class. 
% This was to ensure the conformity of results. 
Storm model checker was used for the quantitative verification of node sensitivity. All experiments were run on AMDRyzen Threadripper $2990WX$ processors running Ubuntu $18.04$ LTS operating system.

\subsection{Results and Discussion}
% Noisy tail to increase tail (angular) variance \cite{tail-noise}. Shouldn't same hold with nodes. but doesn't
% No variance -> no sensitive -> useless feature -> could be removed... but not node 5! \cite{sens_var}

As indicated earlier, the training dataset of the Leukemia dataset composes a long-tail distribution. 
Hence, the networks trained on it delineate robustness bias, with the increase in incident noise gradually decreasing the probability of correct classification of AML, but not for ALL. This is presented by the blue lines in Fig. \ref{fig:bias}. 
The truncation of ALL inputs from the training dataset, in turn, generates networks that appear unbiased for at low incident noise (see the orange lines in Fig. \ref{fig:bias}). However, for large noise, the classification probability of ALL starts to decrease whereas the AML is correctly classified with a probability of $\sim 1.0$. 
This suggests that log-tail distribution is only a component of a much more complicated problem, leading to robustness bias. 
Hence, while avoiding long-tail distribution addresses robustness bias for smaller noise, the strategy alone may not be sufficient bias reduction strategy for inputs exposed to larger noise. 
\begin{figure}[ht]
\begin{center}
\includegraphics[width=\linewidth]{Figures/bias.pdf}
\end{center}
\caption{Network trained on long-tail distribution indicate robustness bias for AML (i.e., tail class). Truncation of training dataset prior to training towards ALL, but only for large noise.}
\label{fig:bias} 
\end{figure}

Similar trends are observed from the results of node sensitivity for negative noise, as shown in Fig. \ref{fig:sens_neg}. 
Truncation of training dataset leads to network's input nodes having approximately equal classification probability for small noise. However, the probability of correct classification gradually decreases for ALL at higher noise. 
It can also be observed for the networks trained on the original dataset that the sensitivity of different nodes is visibly different, as observed by the corresponding gradients of the blue lines for AML.
\begin{figure*}[ht]
\begin{center}
\includegraphics[width=\linewidth]{Figures/sens_neg.pdf}
\end{center}
\caption{The node sensitivity against negative noise for ALL and AML Leukemia. The lines present the average probability results while points present result from each (of the $10$) experiments. The sensitivity varies for networks trained on complete and truncated datasets.}
\label{fig:sens_neg} 
\end{figure*}

\begin{figure*}[ht]
\begin{center}
\includegraphics[width=\linewidth]{Figures/sens_pos.pdf}
\end{center}
\caption{The node sensitivity against positive noise for ALL and AML Leukemia. The lines present the average probability results while points present result from each (of the $10$) experiments. The sensitivity varies for networks trained on complete and truncated datasets.}
\label{fig:sens_pos} 
\end{figure*}

The observations for the analysis with positive incident noise provide similar results in case of ALL (see Fig. \ref{fig:sens_pos}). 
However, a stark difference can be observed for the sensitivity results of NODE$-5$, for AML. 
Where with negative noise, NODE$-5$ was observed to be most sensitive to noise, in case of positive noise, the node is observed to be very insensitive. 
This indicates a significant node (robustness) bias for networks trained on the original dataset. 
It is also interesting to note that the similar node (robustness) bias is not observed for the same input node for inputs belonging to ALL Leukemia, for trained on both the original and truncated datasets. 

% Considering the findings from earlier works \cite{class-imbalance-survey,2022longtail}, long-tail distribution do not favor similar classification performance for all output classes. Similar reasoning may be extended to the robustness performance of input nodes for different output classes, in case of the network trained on long-tail distribution. 

% The observations may result from different learning of input nodes for the different output classes. 
% Table \ref{tab:stats} provides variance of inputs for individual input nodes, for both ALL and AML Leukemia. 
% The large variance of NODE$-5$ and the small variance of NODE$-2$ for AML seem inversely related to the could be use to attribute the possibility of best or worst learning supports the reasoning that NODE$-5$ and NODE$-2$ a
% on the discrepancy in classification performance of From the above results, it appears that
% To understand the varying robustness of inputs for ALL and AML, 
Such sensitivity of NODE$-5$ suggests a biased learning of the node for AML. It can also be observed through Table \ref{tab:stats} that NODE$-5$ has the largest variance among all nodes, for AML. This could be a possible reason for the strange sensitivity of the node, and the subsequent node (robustness) bias. However, given a similar condition for NODE$-3$ for ALL (i.e., having the largest variance for ALL), s similar discrepancy for node (robustness) bias, between positive and negative noise, is not observed. 
\begin{table}[ht]
\caption{Variance of input node values in training datasets. The extrema of the variances, for each class, are {\ul underlined}}
\label{tab:stats}
\begin{tabular}{lrr}
\multicolumn{3}{c}{\textbf{Training Dataset}}       \\ \toprule
         & ALL Variance (x$10^3$) & AML Variance (x$10^3$)  \\ \midrule
NODE - 1 & $114.27$               & $129.72$                                      \\
NODE - 2  & $81.21$                & {  {\ul $11.71$}}          \\
NODE - 3 & {\ul $5531.62$}        & $231.77$                                      \\
NODE - 4 & {\ul $45.24$}          & $284.02$                                      \\
NODE - 5 & $156.40$               & {\ul $2271.00$}  \\ \bottomrule 
% \multicolumn{3}{c}{\textbf{Testing Dataset}}         \\ \toprule 
%          & ALL Variance (x$10^3$) & {  AML Variance (x$10^3$)} \\ \midrule
% NODE - 1 & $112.51$               & $429.99$                                      \\
% NODE - 2  & $86.55$                & {\ul $138.48$}                                \\
% NODE - 3 & {\ul $6967.73$}        & $209.23$                                      \\
% NODE - 4 & {\ul $33.16$}          & $1146.84$                                     \\
% NODE - 5 & $470.18$               & {\ul $3373.60$} \\ \bottomrule
\end{tabular}
\end{table}

% AML
% - (Node 1 4 5 worst for positive noise) - largest variance in testing dataset, so maybe border cases
% - But node 5 best against negative noise (how)
% - But 5 also have the largest variance in training, so maybe it needs more samples for learning patterns in dataset. (it also has outlier - outside interquartile range in training - )

% ALL
% - Even though nodes had large difference in variaces for ALL too, but the sensitivity wasn't too high (maybe it happens for very large noise)
% - But still, how does the laerning differes for the classes?