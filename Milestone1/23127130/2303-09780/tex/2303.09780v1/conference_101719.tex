\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Mpox-AISM: AI-Mediated Super Monitoring for Forestalling Monkeypox Spread\\}

\author
{
\IEEEauthorblockN{Yubiao Yue}
\IEEEauthorblockA{\textit{Guangzhou Medical University}\\
Guangzhou, China \\
jiche2020@126.com}
\and
\IEEEauthorblockN{Zhenzhang Li}
\IEEEauthorblockA{\textit{Guangdong Polytechnic Normal University}\\
Cuangzhou, China \\
zhenzhangli@gpnu.edu.cn}
\and
\IEEEauthorblockN{Xinyue Zhang}
\IEEEauthorblockA{\textit{Guangzhou Medical University} \\
Cuangzhou, China \\
moonkkaabc@163.com}
\and
\IEEEauthorblockN{\hspace{0.82cm}Jialong Xu}
\IEEEauthorblockA{\hspace{0.98cm}\textit{Guangzhou Medical University} \\
\hspace{0.85cm}Guangzhou, China \\
\hspace{0.85cm}jialong\_xu18@163.com}
\and
\IEEEauthorblockN{\hspace{1.5cm}Jinbao Liu}
\IEEEauthorblockA{\hspace{1.5cm}\textit{Guangzhou Medical University} \\
\hspace{1.65cm}Cuangzhou, China \\
\hspace{1.65cm}jliu@gzhmu.edu.cn}
\and
\IEEEauthorblockN{\hspace{1.8cm}Yang Li}
\IEEEauthorblockA{\hspace{1.8cm}\textit{Guangzhou Medical University} \\
\hspace{1.85cm}Cuangzhou, China \\
\hspace{1.85cm}lychris@sina.com}
}
\maketitle

\begin{abstract}
 The challenge on forestalling monkeypox (Mpox) spread is the timely, convenient and accurate diagnosis for early-stage infected individuals. Here, we propose a remote and real-time online visualization strategy, called “Super Monitoring” to construct a low cost, convenient, timely and unspecialized diagnosis of early-stage Mpox. Such AI-mediated “Super Monitoring” (Mpox-AISM) invokes a framework assembled by deep learning, data augmentation and self-supervised learning, as well as professionally classifies four subtypes according to dataset characteristics and evolution trend of Mpox and seven other types of dermatopathya with high similarity, hence these features together with reasonable program interface and threshold setting ensure that its Recall (Sensitivity) was beyond 95.9\% and the specificity was almost 100\%. As a result, with the help of cloud service on Internet and communication terminal, this strategy can be potentially utilized for the real-time detection of early-stage Mpox in various scenarios including entry-exit inspection in airport, family doctor, rural area in underdeveloped region and wild to effectively shorten the window period of Mpox spread.
\end{abstract}

\begin{IEEEkeywords}
Monkeypox, Artificial Intelligence, Self-supervised Learning, Deep Learning
\end{IEEEkeywords}

\section{Introduction}
Monkeypox, or Mpox, is an illness caused by the Mpox virus \cite{b1}. It is a zoonotic viral infection that can spread from animals to humans or from person to person \cite{b2}. In 2022, World Health Organization declared that the global Mpox outbreak represents a public health emergency of international concern. Quick and timely diagnosis and diagnosis of the Mpox virus are highly urgent in light of the evolving epidemic. The primary clinical laboratory diagnosis is PCR assays; although the test results are credible, it is still not the best solution to forestall Mpox spread. This is since the clinical features of Mpox patients initially show symptoms resembling the flu \cite{b3}, followed by skin rash which first appears on the face and then gradually spreads to the extremities \cite{b4}. Their symptoms of pimples and blisters are easily confused with that of measles, chickenpox, eczema, etc. Furthermore, Mpox symptoms usually start within three weeks of exposure to the virus, yet the Mpox virus spreads to others from the time symptoms begin or even during the incubation period \cite{b5}.

All these facts support that if just accurately diagnosing Mpox at its terminal stage, it is not in favour of forestalling Mpox spread, especially for the gateway of border customhouses in a country, or in highly crowded and susceptible places like military and prisons, since its phenotype at early stage resembles that of common rash-type skin diseases, easily leading to the misdiagnosis with general dermatosis. Moreover, only a healthcare provider can order an Mpox test and the patients have to visit the healthcare provider to be helped to decide if they need to be further tested. These techniques require professional operation equipment and high costs and must be more convenient. Especially in the places with poor medical conditions, such as the wild and rural areas in underdeveloped regions, timely and efficient Mpox test is often unavailable. Therefore, developing a convenient, low-cost, rapid and easy-operable method for the visible online diagnosis of Mpox at an early stage has a crucial significance to rapidly respond and successfully avoid the spread of the epidemic and deterioration of the physical condition of the patient.

In view of the above issues, artificial intelligence (AI) provides a reliable solution \cite{b6}; especially for deep learning (DL) in AI, it has recently achieved great success in many fields, such as machine vision, medical imaging and driverless vehicle etc. It has became a sophisticated weapon to solve hitherto unknown and doubtful challenges. In this article, we successfully employ cloud service, the popular DL algorithm, data augmentation and a new self-supervised learning (SSL) approach, namely “A Simple Framework for Contrastive Learning of Visual Representations”\cite{b7} (SimCLR) to construct a strategy of real-time visual cloud monitoring for the achievement of convenient, rapid and timely diagnosis on early-stage Mpox. The medical view of such a strategy is to consider the order in which clinical features of Mpox appear and its high similarity with common dermatosis. We classified Mpox rash into four grades according to dataset characteristics and the evolution trend of Mpox rash in clinical. Grade I includes the face, neck and hands where Mpox occurred at first, and Grade II involves arms and legs that are not easily covered, while these two groups have high incidence and similarity with diseased parts of common dermatosis. As verified, the Recall rates of Grade I, II and earlier stage for Mpox diagnosis are 98·59\%, 100·00\%, 100·00\%, respectively. Furthermore, we visually structure the program interface and set the threshold of the terminal system as 0.6 according to the predicted probability distribution. 

Finally, based on the above superiorities, we call this strategy AI-mediated “Super Monitoring” for Mpox (Mpox-AISM). Such Mpox-AISM will be potentially utilized for the diagnosis of early-stage Mpox in various scenarios, including airports, entry-exit inspection in airports and customs (Fig. 1b), family doctors (Fig. 1c), a rural area in an underdeveloped region (Fig. 1d), the wild and other scenarios (Fig. 1e). Deploying Mpox-AISM in these scenarios, operators only need to capture images of human skin using network cameras and smartphones, and upload them to our cloud server via the global network; Then Mpox-AISM will then return the results to the user in real-time. (Fig. 1a)
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_1.jpg}
\caption{a: Application process of Mpox-AISM. b-e: Application scenarios in different situations.}
\end{figure}

\section{Methods}
\subsection{Data Source}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.47\textwidth]{Figure_2.jpg}
  \caption{Monkeypox. b: Measles. c: Bullous. d: Eczema. e: Chickenpox. f: Urticaria. g: Normal. h: Vasculitis.}
\end{figure}
In this study, we employed two datasets, one was labelled Data\_A (3100 images, 8 categories) that includes Mpox (381), Measles (91), Chickenpox (107), Eczema (881 images), Urticaria (265), Bullous disease (561, Bullous for short), Vasculitis (521), and Normal (293). Among them Mpox, Measles, Chickenpox and Normal skin images were obtained from the Monkeypox skin images dataset (MSID) \cite{b8} and the Monkeypox skin lesion dataset(MSLD: preprint) \cite{b9}. The remaining four categories, i.e., Eczema, Urticaria, Bullous, and Vasculitis were obtained from the Dermnet dataset \cite{b10}. Fig. 2 shows the example for each of the eight disease categories. The other was labelled as Data\_B (25331, 8 categories) which includes Melanoma (4522), Melanocytic nevus (12875), Basal cell carcinoma (3323), Actinic keratosis (867), Benign keratosis (2624), Dermatofibroma (239), Vascular lesion (253), Squamous cell carcinoma (628). The Data\_B was from training data of ISIC 2019(HAM10000 Dataset \cite{b11}, MSK Dataset \cite{b12}, BCN\_20000 Dataset \cite{b13}), which was utilized in self-supervised learning. Generally, the dataset in self-supervised learning does not require labels. Consequently, we merged these eight categories of images together and randomly shuffled them.
\subsection{Data Augmentation, SimCLR and Evaluation Metrics}
Data is the driving force of deep learning, which determines the upper limit of models. Data augmentation alleviates the problem that insufficient samples hinder model performance by generating more data from limited data, enhancing the number as well as diversity of samples and improving model robustness. In the medical field, the phenomenon of insufficient sample size and category imbalance in the dataset is especially prevailing. Therefore, it is necessary to perform appropriate data augmentation. In this study, we performed data augmentation for the five categories of Mpox, Chickenpox, Measles, Normal and Urticaria because of their scarcity. Here, we implemented “\textit{Gaussian Noise + Crop and Resize + Affine + Cutout + Flip Horizontal + Flip Vertical + Gamma Contrast + Gaussian Blur} (Random order and Random probability)” to randomly apply to each image in five categories. By augmenting the above five categories, Data\_A was expanded from the original 3100 to 4831 images labeled as Data\_C. Ultimately, the Dat\_C was divided into a training set (3866) and a validation set (965) in a ratio of 8:2. To evaluate the performance of models objectively; we ensured the same experimental equipment and hyperparameters in the training process. The hyperparameters were set as follows: epochs=300, batchsize=16, learning rate = 0·0001. Additionally, the loss function of the models was uniformly set as Cross-Entropy-Loss, and the optimizer uniformly manipulated Stochastic Gradient Descent (SGD). This paper’s training and evaluation of models were performed in the Pytorch framework.
\[\left\{ \begin{array}{l}
{s_{i,j}} = \frac{{z_i^T{z_j}}}{{\tau \left\| {{z_i}} \right\|\left\| {{z_j}} \right\|}},\\\\
l(i,j) =  - \log \frac{{\exp ({s_{i,j}})}}{{\sum\limits_{k = 1}^{2N} {1[k! = i]\exp ({s_{i,k}})} }},{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} (1)\\\\
L = \frac{1}{{2N}}\sum\limits_{k = 1}^{2N} {\left[ {l(2k - 1,2k) + l(2k,2k - 1)} \right].} 
\end{array} \right.\]
When using SimCLR, firstly, the original input image is first randomly augmented twice, and then the two new images generated are fed into the encoder simultaneously. Later, the two images encoded by the encoder are transformed into two vectors, which are then passed into a small neural network projection head to turn into two new vectors (zi, zj). Finally, the NT-Xent Loss between the two unknown vectors is calculated, and then the parameter information in the whole framework is updated with configured optimizer according to the loss value. The NT-Xent loss was calculated as shown in Equation (1).
\[\begin{array}{l}
Accuracy = \frac{{TP + TN}}{{TP + TN + FP + FN}},\\\\
Precision = \frac{{TP}}{{TP + FP}},\\\\
Recall = \frac{{TP}}{{TP + FN}},{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} (2)\\\\
Specificity = \frac{{TN}}{{TN + FP}},\\\\
F1\_score = \frac{{2Precision \times Recall}}{{Precision + Recall}}.
\end{array}\]
The objective evaluation for the model is essential. This article used five model evaluation metrics (Accuracy, Precision, Recall, F1-score, and Specificity), as shown in Equation (2). Here, TP means True Positive;TN means True Negative; FP means False Positive; FN means False Negative.
\section{Results}
\subsection{Mpox-AISM Design Workflows }\label{AA}
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_3.png}
\caption{The workflow of this study.}
\end{figure}
In this work, we first chose ten classical classification models in computer vision, namely VGG19 \cite{b14}, GoogleNet \cite{b15}, Resnet101 \cite{b16}, Resnext101\_64x4D \cite{b17}, Densenet201 \cite{b18}, Efficientnet\_B0 \cite{b19}, RegnetY\_16GF \cite{b20}, RegnetX\_32GF \cite{b20}, Vision Transformer Base \cite{b21}, Swin transformer Base \cite{b22}. Before training and evaluating the models, we expanded Data\_A to Data\_C via data augmentation. Later, we used Data\_C to train and evaluate each model under the same experimental conditions. Due to the need for the self-supervised learning method, we initially screened out the Efficientnet\_B0 and Resnext101\_64x4D models with an excellent performance by model evaluation. Next, to further improve the model performance, we used SimCLR and SSL Dataset (training set of Data\_C + Data\_B, total 29197 images) to pre-train these two models. After self-supervised learning, we used Data\_C to retrain and reevaluate the two pre-trained models and discovered that Resnext101\_64x4D performs state of the arts (SOTA). Finally, we deployed the SOTA model to the cloud server and constructed Mpox-AISM. Mpox-AISM can interact with smartphones, webcams and other network devices via the Internet. The user simply takes images of the lesioned area of the skin with the lens of network devices and uploads them to Mpox-AISM. Then the preliminary medical diagnosis of the eight categories of skin diseases will be returned in real time. The specific workflow is shown in Fig. 3.
\subsection{Model Screening, Self-Supervised Learning, Retraining and Reevaluating}
In evaluating the candidate models, we focused on the Accuracy and Loss. We recorded Accuracy and loss of the candidate models after each epoch for the validation set. We plotted trend of Accuracy and loss after 300 epochs (Fig. 4a). Among the ten models, EfficentNet\_B0 had the highest Accuracy (90·57\%, 273th epoch), followed by Resnext101\_64x4D (84·97\%, 258th epoch), and was also similar in terms of loss value (Fig. 4b). Typically, higher Accuracy means better performance. However, since we used a self-supervised approach, we also considered the structure of the model network. Like supervised learning, contrastive learning benefits from deeper and wider networks7, which means that although the Accuracy of Resnext101\_64x4D is not as good as EfficientNet\_B0, Resnext101\_64x4D combing with SimCLR may outperform EfficientNet\_B0 combing with SimCLR due to its deeper and wider network structure. Considering this, we choose these two models as the most potential encoders.
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_4.png}
\caption{a,b: Val Accuracy and train loss trends for the ten models, respectively. c: F1-score for validation set of Data\_C. d: Precision for validation set of Data\_C. e: Recall for validation set of Data\_C. f: Specificity for validation set of Data\_C. g-j: Confusion matrix of Renext101\_64x4D\(SimCLR\), Renext101\_64x4D, Efficientnet\_B0 \(SimCLR\) and Efficientnet\_B0 for validation set of Data\_C.}
\end{figure}
During the SSL, we used the same hyperparameters for the training process of Resnext101\_64x4D and EfficientNet\_B0 (epochs = 150, batchsize = 32, learning rate = 0·0002, temperature t = 0·15). Besides, the optimizer was uniformly set as SGD. The size of input images was uniformly adjusted to 224 × 224 pixels. Data augmentation in SimCLR was set as random crop and resize + random color jitter. We recorded the NT-Xent Loss values after each epoch and plotted the trend of NT-Xent Loss (Illustration in Fig. 4a). The NT-Xent Loss values of Resnext101\_64x4D is lower than that of EfficientNet\_B0 throughout the whole process, which signifies Resnext101\_64x4D benefits more from SSL when only loss metric is compared. 
Further, we utilized Data\_C to retrain and reevaluate these two models pre-trained by SimCLR. The experimental equipment and the hyperparameters of the training process were the same as before. We evaluated the two models in all aspects using five metrics, i.e. Accuracy, F1-score (Fig. 4c), Precision (Fig. 4d), Recall (Fig. 4e), Specificity (Fig. 4f) and confusion matrix (Fig. 4g-j). In addition, we also used the above metrics to evaluate these two models not pre-trained by SimCLR again to demonstrate the benefits of SSL. In terms of Accuracy, Resnext101\_64x4D improves from 84·96\% previously to 94·51\% and EfficientNet\_B0 improves from 90·51\% previously to 92·5\%. In terms of F1-score (Fig.4c), Resnext101\_64x4D pre-trained by SimCLR was the most advanced in six categories (Bullous, Chickenpox, Eczema, Mpox, Urticaria, and Vasculitis), reaching 90·4\%, 96·8\%, 95·7\%, 96·6\%, 93·3\%, and 88·1\% respectively. In terms of Precision (Fig.4d), Resnext101\_64x4D pre-trained by SimCLR is the most advanced in the six categories (Bullous, Eczema, Mpox, Normal, Urticaria, and Vasculitis), reaching 88·8\%, 95·5\%, 99·3\%, 98·2\%, 94·2\%, and 86·9\% respectively. Regrading Recall (Fig.4e), Resnext101\_64x4D pre-trained by SimCLR learning was the most advanced in five categories (Bullous, Eczema, Measles, Mpox, and Vasculitis), reaching 92·0\%, 96·0\%, 97·8\%, 94·1\%, and 89·4\% respectively. In terms of Specificity (Fig.4f), Resnext101\_64x4D pre-trained by SimCLR was the most advanced in the six categories (Bullous, Eczema, Mpox, Normal, Urticaria, and Vasculitis), achieving 98·5\%, 99·0\%, 99·9\%, 99·8\%, 99·3\%, and 98·4\%, respectively. Consistent with our considerations, Resnext101\_64x4D benefited more from SSL and was superior on the confusion matrix (Fig. 4g-j). Based on the results of these metrics, Resnext101\_64x4D combing with SimCLR was eventually deployed in Mpox-AISM. 

\subsection{Mpox-AISM Grading Assessment}
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_5.jpg}
\caption{a,b: Four grades of human skin and diagrams of monkeypox rash at different stages. c: Diagrams of monkeypox rash at earlier stage and later stage.}
\end{figure}
To enable Mpox-AISM to be conveniently deployed in multiple scenarios, we according to the characteristics of the dataset and the evolution trend of Mpox rash and clinical features of most cases, further classified images of Mpox rashes into four grades and evaluated these four grades(Fig. 5a-b): Grade I for face, neck and hands, which are not easy to cover and have high incidence; Grade II for arms and legs, which are easier to check; Grade III for back and chest; These three grades photos were taken from a distance. Grade IV for images taken at close range (Others). After evaluating these images via Mpox-AISM, the Recall rates of Grade I, II, III and Others are 98·59\%, 100·00\%, 94·59\% and 99·33\%, respectively.
Above all things, accurate diagnosis of monkeypox at early stage helps to curb the spread of the epidemic. However, the symptoms of Mpox rash are not severe in the early stage and are easily confused with other rash diseases. So, we specially tested the relevant cases of Mpox rash at the earlier stage via Mpox-AISM (Fig. 5c). Experimental result shows that Mpox-AISM achieves 100\% Recall in the images from an early stage of Mpox rash. Above Accuracies indicate that Mpox-AISM has excellent diagnosis capabilities at all stages of the rash phase for Mpox. Most importantly, the Accuracy of earlier stage mean even in the early stage of Mpox rash, Mpox-AISM can also make a primary diagnosis of the suspected case.



\subsection{Mpox-AISM Interpretability }

Deep learning models have exhibited superior performance in various tasks. However, due to their over-parameterized black-box nature, it is often difficult to understand the prediction results of deep models \cite{b23}. The lack of interpretability raises a severe issue about the trust of deep models in high-stakes prediction applications, such as autonomous driving, healthcare, criminal justice, and financial services \cite{b24}. Especially in the healthcare field, the results predicted by the models will affect the patient's subsequent treatment, so it is imperative to interpret these results. In addition, the WHO's Ethics and Governance of Artificial Intelligence for Health: WHO Guidance, published in 2021, specifies: that AI should be intelligible or understandable to developers, users and regulators \cite{b25}. Therefore, it is necessary to provide interpretable techniques in model prediction. 
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_6.jpg}
\caption{a-h: Heat maps for eight categories of skin diseases generated by the Grad-CAM method.}
\end{figure}

In our work, we used Gradient-weighted Class Activation Mapping (Grad-CAM) proposed by Selvaraju et al. in 2016 \cite{b26}. Grad-CAM is result visualization and interpretation technique which makes prediction results made by deep learning models more transparent. The gradient information is used to calculate the activation map of CNN for the input image, and the magnitude of the activation map can indicate the degree of influence of the image classification result on each part of the original image. Fig. 6 shows the heat maps of the diagnosis results generated by the Grad-CAM method. From the figure, it can be seen that our model focuses well on the lesion region.
\subsection{Mpox-AISM Application}\label{SCM}
For ease of use, we designed PC (Fig. 7b) and mobile (Fig. 7a) application pages corresponding to Mpox-AISM. The PC terminal combines the terminal camera to capture the target image for diagnosis, which can be applied to such as entry-exit inspection in airport and customs (Fig. 1b). Mobile terminal, such as mobile phones, users can simply upload skin images from mobile phone lens or album by clicking the button located at the center of the screen and then the categories of skin lesion area can be predicted, which provide primary diagnosis to the user. The mobile terminal can be applied to such as family doctor, rural areas in underdeveloped regions and the wild and other scenarios (Fig. 1c-e). The Mpox-AISM corresponding terminal in this study is highly convenient and imposes no strict restrictions on the operator's photographing angle or distance thanks to multiple data augmentation strategies. 

To further improve the reliability of application system, we carried out prediction probability distribution statistics on the validation set (Illustration in Fig. 7c). It was found that in validation set, the proportion of samples with prediction probability $\geq 0.6$ is 94\%, and Accuracy of these samples is almost 95·9\%. For Mpox images in these samples, Precision, Recall, Specificity, F1-score achieve respectively 99·3\%, 95·9\%, 99·9\% and 97·6\%. Besides, the proportion of samples with a prediction probability $<0.5$ is 5·4\%, and the error is $>98\%$. So, we set the prediction threshold at the application terminal to 0·6. If the application displays a case with a prediction probability value less than 0·6, the application will give a prompt that manual intervention is required.
\begin{figure}[h]
\centering
\includegraphics[width=0.47\textwidth]{Figure_7.jpg}
\caption{a: Mobile application page. b: PC application page. c: Box distribution diagram of prediction probability of each category.}
\end{figure}

In addition, the application also provided confidence in results and typical pathological images of various parts to improve the interpretability of results and the vigilance of patients. Our application can help suspected patients and doctors preliminarily screen and detect lesion areas anytime and anywhere without cost. In particular, during the outbreak of Mpox, such applications can provide specific technical support for limiting the spread of the epidemic.

\section{Discussion}
In this study, we prospectively construct a strategy of real-time visual cloud monitoring for the achievement of convenient, rapid and timely diagnosis on early-stage Mpox, named Mpox-AISM. To this end, we had to build a classification model with excellent performance. Therefore, we first addressed the problem of insufficient samples which is widespread in the medical field via data augmentation. Next, the excellent models, i.e. EfficientNet\_B0 and Resnext101\_64x4D were selected by training and evaluating ten classical classification models. Later, we used SimCLR, a novel self-supervised learning approach, to pre-train, re-train and re-evaluate these models. It was found that Resnext101\_64x4D performed SOTA and its Accuracy increased from 84·96\% to 94·51\%. For Mpox, the evaluation Metrics (Precision, Recall, Specificity, F1-score) of Resnext101\_64x4D pre-trained by SimCLR reached 99·3\%, 94·1\%, 99·9\%, and 96·6\% respectively. It’s exciting that Mpox- AISM also achieved respectively 98·59\%, 100·00\% and 100·00\% Recall in the Grade I, Grade II and Earlier-stage cases of monkeypox.

In particular, we used SSL to improve the metrics and robustness of the model, and verified the effectiveness of SSL in Mpox diagnosis task for the fist time. This cutting-edge method aims to pre-train the model to improve the model's performance in downstream tasks. Self-supervised learning methods have integrated both generative and contrastive approaches utilizing unlabeled data to learn the underlying representations \cite{b27}. In our work, considering the timely upgrade for Mpox-AISM and the complexity of update process, we adopt the recently proposed SimCLR. SimCLR adopts contrastive learning strategy to pre-train the encoder(model network) ported into the framework. The pre-trained encoder can grasp universal feature representations from many unlabeled data. Finally, we can apply the encoder to specific downstream tasks.
However, there are two limitations in our study. First, the images of eight kinds of skin disease, although augmented, still needs to be improved and perfected in terms of images diversity. Our model's robustness and diagnosis capability would significantly enhance if more clinical images were available. Second, model deployed in Mpox-AISM should be more lightweight to provide faster response speed and decrease the computational cost when there is a high volume of users visiting.

In summary, in this study, we developed an excellent intelligent diagnosis strategy  called Mpox-AISM with 94·5\% Accuracy for Mpox and Mpox-like diseases via using Renext101\_64x4D, data augmentation and SimCLR. In particular, to facilitate diagnosis in various scenarios and show the performance of Mpox-AISM, we further classified human Mpox rashes into four grades: Grade I (Recall = 98·59\%) represents face, neck and hands which are not easily obscured and have high incidence; Grade II (Recall = 100·00\%) represents arms and legs; Grade III (Recall = 94·59\%) represents back and chest; and Others (Recall = 99·33\%) represents close photographs. Besides, the Recall of images from the earlier stage of Mpox rash is 100·00\%, which means our model can provide a primary diagnosis of a suspected case as soon as possible. Combining with the network devices and reasonable threshold setting, Mpox-AISM can be applied to multiple scenarios, such as entry-exit inspection in the airports and customs, family doctors, rural area in an underdeveloped region and the wild. Mpox-AISM is expected to provide technical support during the monkeypox pandemic to curb the spread of the virus.


\section*{Acknowledgment}
This work was financially supported by the Science and Technology Planning Project of Guangzhou $(No. 006259497026)$, the Young Creative Talents of Department Education of Guangdong $(Natural Science, No. 2019KQNCX067)$, the National Natural Science Foundation of China $(Grant No. 52172083)$, Guangdong Natural Science Foundation $(Grant No. 2019A030310444)$, International Science \& Technology Cooperation Program of Guangdong $(Grant No. 2021A0505030078)$.

\begin{thebibliography}{00}
\bibitem{b1} Gong Q, Wang C, Chuai X, Chiu S. Monkeypox virus: a re-emergent threat to humans. Virol Sin 2022; 37: 477–82.
\bibitem{b2} Singhal T, Kabra SK, Lodha R. Monkeypox: A Review. Indian J Pediatr 2022; 89: 955–60.
\bibitem{b3} Absil G, Sougne L, Lahrichi D, et al. [Monkeypox]. Rev Med Liege 2022; 77: 452–5.
\bibitem{b4} Soheili M, Nasseri S, Afraie M, et al. Monkeypox: Virology, Pathophysiology, Clinical Characteristics, Epidemiology, Vaccines, Diagnosis, and Treatments. J Pharm Pharm Sci Publ Can Soc Pharm Sci Soc Can Sci Pharm 2022; 25: 297–322.
\bibitem{b5} CDC. Mpox in the U.S. Cent. Dis. Control Prev. 2023; published online Jan 6. https://www.cdc.gov/poxvirus/monkeypox/index.html (accessed Feb 11, 2023).
\bibitem{b6} Coşkun M, Yildirim Ö, Uçar A, Demir Y. AN OVERVIEW OF POPULAR DEEP LEARNING METHODS. Eur J Tech EJT 2017; 7: 165–76.
\bibitem{b7} Chen T, Kornblith S, Norouzi M, Hinton G. A simple framework for contrastive learning of visual representations. In: International conference on machine learning. PMLR, 2020: 1597–607.
\bibitem{b8} Bala D. Monkeypox Skin Images Dataset (MSID). 2022. DOI:10.34740/KAGGLE/DSV/3971903.
\bibitem{b9} Ali SN, Ahmed MT, Paul J, et al. [preprint]Monkeypox Skin Lesion Diagnosis Using Deep Learning Models: A Feasibility Study. 2022; published online July 6. DOI:10.48550/arXiv.2207.03342.
\bibitem{b10} Dermnet. https://www.kaggle.com/datasets/shubhamgoel27/dermnet (accessed Jan 20, 2023).
\bibitem{b11} Tschandl P, Rosendahl C, Kittler H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci Data 2018; 5: 180161.
\bibitem{b12} Codella NCF, Gutman D, Celebi ME, et al. Skin lesion analysis toward melanoma diagnosis: A challenge at the 2017 International symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC). In: 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). 2018: 168–72.
\bibitem{b13} Combalia M, Codella NCF, Rotemberg V, et al. BCN20000: Dermoscopic Lesions in the Wild. 2019; published online Aug 30. DOI:10.48550/arXiv.1908.02288.
\bibitem{b14} Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. In: 3rd International Conference on Learning Representations (ICLR 2015). Computational and Biological Learning Society, 2015: 1–14.
\bibitem{b15} Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions. In: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2015: 1–9.
\bibitem{b16} He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2016: 770–8.
\bibitem{b17} Xie S, Girshick R, Dollár P, Tu Z, He K. Aggregated Residual Transformations for Deep Neural Networks. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2017: 5987–95.
\bibitem{b18} Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely Connected Convolutional Networks. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2017: 2261–9.
\bibitem{b19} Tan M, Le Q. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. In: Chaudhuri K, Salakhutdinov R, eds. Proceedings of the 36th International Conference on Machine Learning. PMLR, 2019: 6105–14.
\bibitem{b20} Radosavovic I, Kosaraju RP, Girshick R, He K, Dollár P. Designing Network Design Spaces. In: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2020: 10425–33.
\bibitem{b21} Dosovitskiy, Alexey, et al. "An image is worth 16x16 words: Transformers for image recognition at scale." arXiv preprint arXiv:2010.11929 (2020).
\bibitem{b22} Liu Z, Lin Y, Cao Y, et al. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. In: 2021 IEEE/CVF International Conference on Computer Vision (ICCV). 2021: 9992–10002.
\bibitem{b23} Li X, Xiong H, Li X, et al. Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond. Knowl Inf Syst 2022; 64: 3197–234.
\bibitem{b24} Carvalho DV, Pereira EM, Cardoso JS. Machine Learning Interpretability: A Survey on Methods and Metrics. Electronics 2019; 8: 832.
\bibitem{b25} Ethics and governance of artificial intelligence for health: WHO guidance. Geneva: World Health Organization; 2021. Licence: CC BY-NC-SA 3.0 IGO.
\bibitem{b26} Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. In: 2017 IEEE International Conference on Computer Vision (ICCV). 2017: 618–26.
\bibitem{b27} Jaiswal A, Babu AR, Zadeh MZ, Banerjee D, Makedon F. A Survey on Contrastive Self-Supervised Learning. Technologies 2021; 9: 2.
\end{thebibliography}
\end{document}
