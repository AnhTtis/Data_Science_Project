\section{Conclusion}
\label{conclusion}
%yexiaoqing initial version
In this paper, we study the 3D positional embeddings of sparse query-based approaches for multi-view 3D object detection and propose a simple yet effective method CAPE. We form the 3D position embedding under the local camera-view system rather than the global coordinate system, which largely reduces the difficulty of the view transformation learning. Furthermore, we extend our CAPE to temporal modeling by exploiting the fusion between separated queries for temporal frames. It achieves state-of-the-art performance even without LiDAR supervision, and provides a new insight of position embedding in multi-view 3D object detection.
% The CAPE can be directly incorporated into sparse query-based architecture to boost the performance.

\noindent\textbf{Limitation and future work.}  The computation and memory cost would be unaffordable when it involves the temporal fusion of long-term frames. In the future, we will dig deeper into more efficient spatial and temporal interaction of 2D and 3D features for autonomous driving systems.