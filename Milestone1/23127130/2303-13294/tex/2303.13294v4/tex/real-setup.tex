\section{Real data experiment setup}
\label{sec:real-setup}

This section describes the setup for the experiments that involve real instead of synthetic data.
As noted in the introduction,
there is a primary face image quality assessment (FIQA) setup
and a supporting fingerprint quality assessment setup.
The paper's general conclusions regarding QA algorithm evaluations using EDC curves should apply to scenarios with other biometric modalities as well,
since the underlying principles such as the FNMR, or the discarding of samples by a quality score threshold, are not specific to any modality.

\subsection{Used algorithms}

The real face image data experiments use one face detector for face image preprocessing, one face recognition system, and five (FI)QA algorithms:

\begin{itemize}
\item Face detector model: RetinaFace-R50 \cite{Deng-FaceDetection-RetinaFace-CVPR-2020}
\begin{itemize}
\item Images are excluded from the experiments when the face detection step fails.
\item The detected facial landmarks are used to preprocess the face images.
The same preprocessing approach used for ArcFace \cite{Deng-ArcFace-IEEE-CVPR-2019}
is also used for all FIQA models here, only the scaling differs since the models require different input resolutions.
Note that specialized preprocessing methods could be used for the individual models to possibly enhance their performance,
but that this work is about more general observations on the EDC, which should apply either way.
\end{itemize}
\item Face recognition feature extraction model: ArcFace-R100-MS1MV2 \cite{Deng-ArcFace-IEEE-CVPR-2019}.
\item FIQA algorithms:
\begin{itemize}
\item CR-FIQA(L) \cite{Boutros-FIQA-CRFIQA-arXiv-2022}: ResNet100 backbone trained on MS1MV2 \cite{Deng-ArcFace-IEEE-CVPR-2019}. $112\times 112$ input image size.
\item CR-FIQA(S) \cite{Boutros-FIQA-CRFIQA-arXiv-2022}: ResNet50 backbone trained on CASIA-WebFace \cite{Yi-LearningFaceRepresentationFromScratchCASIAWebFace-arXiv-2014}. $112\times 112$ input image size.
\item MagFace \cite{Meng-FRwithFQA-MagFace-CVPR-2021}: ResNet100 backbone trained on MS1MV2 \cite{Deng-ArcFace-IEEE-CVPR-2019}. $112\times 112$ input image size. %
\item PCNet \cite{Xie-FQA-PredictiveUncertaintyEstimation-BMVC-2020}: Trained on VGGFace2 \cite{Cao-VGGFace2Dataset-FGR-2018}. $224\times 224$ input image size.
\item SER-FIQ \cite{Terhorst-FQA-SERFIQ-CVPR-2020}: ``Same model'' variant using ArcFace. $112\times 112$ input image size.
\end{itemize}
\end{itemize}

The PCNet model was provided to us by one of the authors, the other models are publicly available.

The fingerprint setup is partially based on the MiDeCon paper by \markAuthor{Terh√∂rst \etal{}} \cite{Terhorst-FingerQA-MiDeCon-IJCB-2021}:
\begin{itemize}
\item Fingerprint comparisons:
\begin{itemize}
\item Minutiae extractor: Mindtct (NBIS 5.0.0 \cite{NBIS-User-Guide}).
\item Minutiae comparator: Bozorth3 (NBIS 5.0.0 \cite{NBIS-User-Guide}), using the top 20 (or less) minutiae.
\end{itemize}
\item Fingerprint QA algorithms:
\begin{itemize}
\item NFIQ v2.2.0 \cite{NIST-NFIQ2-FingerprintImageQuality-2021}.
\item Mindtct (NBIS 5.0.0 \cite{NBIS-User-Guide}).
\item MinutiaeNet \cite{Nguyen-MinutiaeNet-ICB-2018}.
\item MiDeCon \cite{Terhorst-FingerQA-MiDeCon-IJCB-2021}.
\end{itemize}
\end{itemize}
Mindtct, MinutiaeNet, and MiDeCon detect minutiae with confidence values.
The mean of the top 20 (or less) minutiae detection confidence values is used as the sample QS.

\subsection{Used datasets}

Two face image datasets are used:

\begin{itemize}
\item LFW (Labeled Faces in the Wild) \cite{LFWTech}
\begin{itemize}
\item Type: Web-scraped (varying quality).
\item Image width $\times$ height: $250\times 250$
\item Mean face region width $\times$ height: $94.98\times 129.63$
\item Excluded image file duplicates: 2
\item Images subsequently excluded due to failed face detection: 0
\item Images remaining: 13,231
\item Remaining subjects with only one image (implicitly excluded from mated pair set): 4,067
\item Subjects in mated comparisons: 1,680
\item Images in mated comparisons: 9,164
\item Mated comparisons used: 242,257
\end{itemize}
\item TinyFace (subsets Testing\_Set/Gallery\_Match and Testing\_Set/Probe) \cite{Cheng-TinyFace-LowResolutionFaceRecognition-ACCV-2018}
\begin{itemize}
\item Type: Web-scraped (varying quality).
\item Mean image width $\times$ height: $30.64\times 31.74$
\item Mean face region width $\times$ height: $29.22\times 31.50$
\item Excluded image file duplicates: 184
\item Images subsequently excluded due to failed face detection: 132
\item Images remaining: 7,855
\item Remaining subjects with only one image (implicitly excluded from mated pair set): 131
\item Subjects in mated comparisons: 2,434
\item Images in mated comparisons: 7,724
\item Mated comparisons used: 19,478
\end{itemize}
\end{itemize}

The number of used mated comparison pairs is the number of all possible mated pairs for the images which were not excluded.
Lists of the excluded image file duplicates are provided in supplemental material\footnote{\url{https://github.com/dasec/dataset-duplicates}}, due to the larger number of duplicates found in TinyFace.

Some of the example plots in \autoref{sec:other-approaches} incorporate non-mated comparisons besides the mated comparisons.
A number of non-mated comparisons equal to the number of mated comparisons is randomly selected for these cases.

For the fingerprint setup, the ``DB2\_A'' subset of FVC 2006 \cite{FVC-EvaluationReport-2006} is used:
\begin{itemize}
\item Type: Optical sensor, 596dpi
\item Images: 1,680
\item Subjects: 140 (12 images each)
\item Mated comparisons: 9,240 (all mated pairs are used)
\end{itemize}
