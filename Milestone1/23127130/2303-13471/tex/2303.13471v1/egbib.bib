@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@inproceedings{senocak2018learning,
  title={Learning to localize sound source in visual scenes},
  author={Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and Kweon, In So},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4358--4366},
  year={2018}
}

@inproceedings{mittal2022learning,
  title={Learning State-Aware Visual Representations from Audible Interactions},
  author={Mittal, Himangi and Morgado, Pedro and Jain, Unnat and Gupta, Abhinav},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  year={2022}
}

@inproceedings{ots2018,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={435--451},
  year={2018}
}

@inproceedings{qian2020multiple,
  title={Multiple sound sources localization from coarse to fine},
  author={Qian, Rui and Hu, Di and Dinkel, Heinrich and Wu, Mengyue and Xu, Ning and Lin, Weiyao},
  booktitle={European Conference on Computer Vision},
  pages={292--308},
  year={2020},
  organization={Springer}
}

@inproceedings{tian2021cyclic,
  title={Cyclic co-learning of sounding object visual grounding and sound separation},
  author={Tian, Yapeng and Hu, Di and Xu, Chenliang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2745--2754},
  year={2021}
}

@inproceedings{gao2019co,
  title={Co-separating sounds of visual objects},
  author={Gao, Ruohan and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3879--3888},
  year={2019}
}

@inproceedings{zhao2018sound,
  title={The sound of pixels},
  author={Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={570--586},
  year={2018}
}

@inproceedings{gao2018learning,
  title={Learning to separate object sounds by watching unlabeled video},
  author={Gao, Ruohan and Feris, Rogerio and Grauman, Kristen},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={35--53},
  year={2018}
}

@inproceedings{tian2018audio,
  title={Audio-visual event localization in unconstrained videos},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={247--263},
  year={2018}
}

@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={721--725},
  year={2020},
  organization={IEEE}
}

@inproceedings{wu2021exploring,
  title={Exploring heterogeneous clues for weakly-supervised audio-visual video parsing},
  author={Wu, Yu and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1326--1335},
  year={2021}
}

@inproceedings{tian2020unified,
  title={Unified multisensory perception: Weakly-supervised audio-visual video parsing},
  author={Tian, Yapeng and Li, Dingzeyu and Xu, Chenliang},
  booktitle={European Conference on Computer Vision},
  pages={436--454},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2021localizing,
  title={Localizing Visual Sounds the Hard Way},
  author={Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16867--16876},
  year={2021}
}

@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{shan2020understanding,
  title={Understanding human hands in contact at internet scale},
  author={Shan, Dandan and Geng, Jiaqi and Shu, Michelle and Fouhey, David F},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9869--9878},
  year={2020}
}

@inproceedings{li2015delving,
  title={Delving into egocentric actions},
  author={Li, Yin and Ye, Zhefan and Rehg, James M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={287--295},
  year={2015}
}

@article{sigurdsson2018charades,
  title={Charades-ego: A large-scale dataset of paired third and first person videos},
  author={Sigurdsson, Gunnar A and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
  journal={arXiv preprint arXiv:1804.09626},
  year={2018}
}


@inproceedings{arandjelovic2018objects,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={435--451},
  year={2018}
}

@article{hu2020discriminative,
  title={Discriminative sounding objects localization via self-supervised audiovisual matching},
  author={Hu, Di and Qian, Rui and Jiang, Minyue and Tan, Xiao and Wen, Shilei and Ding, Errui and Lin, Weiyao and Dou, Dejing},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5492--5501},
  year={2019}
}

@article{grauman2021ego4d,
  title={Ego4D: Around the World in 3,000 Hours of Egocentric Video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  journal={arXiv preprint arXiv:2110.07058},
  year={2021}
}

@inproceedings{li2021ego,
  title={Ego-Exo: Transferring Visual Representations from Third-person to First-person Videos},
  author={Li, Yanghao and Nagarajan, Tushar and Xiong, Bo and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6943--6953},
  year={2021}
}

@inproceedings{sigurdsson2018actor,
  title={Actor and observer: Joint modeling of first and third-person videos},
  author={Sigurdsson, Gunnar A and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7396--7404},
  year={2018}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{li2021space,
  title={Space-Time Memory Network for Sounding Object Localization in Videos},
  author={Li, Sizhe and Tian, Yapeng and Xu, Chenliang},
  journal={arXiv preprint arXiv:2111.05526},
  year={2021}
}

@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={arXiv preprint arXiv:1804.03619},
  year={2018}
}

@inproceedings{gan2020music,
  title={Music gesture for visual sound separation},
  author={Gan, Chuang and Huang, Deng and Zhao, Hang and Tenenbaum, Joshua B and Torralba, Antonio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10478--10487},
  year={2020}
}

@inproceedings{gao20192,
  title={2.5 d visual sound},
  author={Gao, Ruohan and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={324--333},
  year={2019}
}

@inproceedings{zhou2020sep,
  title={Sep-stereo: Visually guided stereophonic audio generation by associating source separation},
  author={Zhou, Hang and Xu, Xudong and Lin, Dahua and Wang, Xiaogang and Liu, Ziwei},
  booktitle={European Conference on Computer Vision},
  pages={52--69},
  year={2020},
  organization={Springer}
}

@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={609--617},
  year={2017}
}

@article{aytar2016soundnet,
  title={Soundnet: Learning sound representations from unlabeled video},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{hu2019deep,
  title={Deep multimodal clustering for unsupervised audiovisual learning},
  author={Hu, Di and Nie, Feiping and Li, Xuelong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9248--9257},
  year={2019}
}

@article{korbar2018cooperative,
  title={Cooperative learning of audio and video models from self-supervised synchronization},
  author={Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{owens2018audio,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={631--648},
  year={2018}
}

@inproceedings{owens2016ambient,
  title={Ambient sound provides supervision for visual learning},
  author={Owens, Andrew and Wu, Jiajun and McDermott, Josh H and Freeman, William T and Torralba, Antonio},
  booktitle={European conference on computer vision},
  pages={801--816},
  year={2016},
  organization={Springer}
}

@inproceedings{afouras2020self,
  title={Self-supervised learning of audio-visual objects from video},
  author={Afouras, Triantafyllos and Owens, Andrew and Chung, Joon Son and Zisserman, Andrew},
  booktitle={European Conference on Computer Vision},
  pages={208--224},
  year={2020},
  organization={Springer}
}

@inproceedings{lin2019dual,
  title={Dual-modality seq2seq network for audio-visual event localization},
  author={Lin, Yan-Bo and Li, Yu-Jhe and Wang, Yu-Chiang Frank},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2002--2006},
  year={2019},
  organization={IEEE}
}

@inproceedings{tian2019audio,
  title={Audio-visual event localization in the wild},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={IEEE Computer Society Conference on Computer Vision and Pattern Recognition workshops},
  year={2019}
}

@inproceedings{wu2019dual,
  title={Dual attention matching for audio-visual event localization},
  author={Wu, Yu and Zhu, Linchao and Yan, Yan and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6292--6300},
  year={2019}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2630--2640},
  year={2019}
}

@inproceedings{zhou2015temporal,
  title={Temporal perception and prediction in ego-centric video},
  author={Zhou, Yipin and Berg, Tamara L},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4498--4506},
  year={2015}
}

@inproceedings{cai2016understanding,
  title={Understanding Hand-Object Manipulation with Grasp Types and Object Attributes.},
  author={Cai, Minjie and Kitani, Kris M and Sato, Yoichi},
  booktitle={Robotics: Science and Systems},
  volume={3},
  year={2016},
  organization={Ann Arbor, Michigan;}
}

@inproceedings{nagarajan2019grounded,
  title={Grounded human-object interaction hotspots from video},
  author={Nagarajan, Tushar and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8688--8697},
  year={2019}
}

@article{damen2016you,
  title={You-Do, I-Learn: Egocentric unsupervised discovery of objects and their modes of interaction towards video-based guidance},
  author={Damen, Dima and Leelasawassuk, Teesid and Mayol-Cuevas, Walterio},
  journal={Computer Vision and Image Understanding},
  volume={149},
  pages={98--112},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{abu2018will,
  title={When will you do what?-anticipating temporal occurrences of activities},
  author={Abu Farha, Yazan and Richard, Alexander and Gall, Juergen},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5343--5352},
  year={2018}
}

@article{furnari2020rolling,
  title={Rolling-unrolling lstms for action anticipation from first-person video},
  author={Furnari, Antonino and Farinella, Giovanni Maria},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4021--4036},
  year={2020},
  publisher={IEEE}
}

@inproceedings{liu2020forecasting,
  title={Forecasting human-object interaction: joint prediction of motor attention and actions in first person video},
  author={Liu, Miao and Tang, Siyu and Li, Yin and Rehg, James M},
  booktitle={European Conference on Computer Vision},
  pages={704--721},
  year={2020},
  organization={Springer}
}

@inproceedings{singh2016krishnacam,
  title={Krishnacam: Using a longitudinal, single-person, egocentric dataset for scene understanding tasks},
  author={Singh, Krishna Kumar and Fatahalian, Kayvon and Efros, Alexei A},
  booktitle={2016 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={1--9},
  year={2016},
  organization={IEEE}
}

@inproceedings{jiang2017seeing,
  title={Seeing invisible poses: Estimating 3d body pose from egocentric video},
  author={Jiang, Hao and Grauman, Kristen},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3501--3509},
  year={2017},
  organization={IEEE}
}

@inproceedings{ng2020you2me,
  title={You2me: Inferring body pose in egocentric video via first and second person interactions},
  author={Ng, Evonne and Xiang, Donglai and Joo, Hanbyul and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9890--9900},
  year={2020}
}

@inproceedings{lee2012discovering,
  title={Discovering important people and objects for egocentric video summarization},
  author={Lee, Yong Jae and Ghosh, Joydeep and Grauman, Kristen},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={1346--1353},
  year={2012},
  organization={IEEE}
}

@inproceedings{su2016detecting,
  title={Detecting engagement in egocentric video},
  author={Su, Yu-Chuan and Grauman, Kristen},
  booktitle={European Conference on Computer Vision},
  pages={454--471},
  year={2016},
  organization={Springer}
}

@inproceedings{damen2018scaling,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={720--736},
  year={2018}
}

@inproceedings{yu2017dilated,
  title={Dilated residual networks},
  author={Yu, Fisher and Koltun, Vladlen and Funkhouser, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={472--480},
  year={2017}
}

@article{bulkin2006seeing,
  title={Seeing sounds: visual and auditory interactions in the brain},
  author={Bulkin, David A and Groh, Jennifer M},
  journal={Current opinion in neurobiology},
  volume={16},
  number={4},
  pages={415--419},
  year={2006},
  publisher={Elsevier}
}

@article{jacobs2019can,
  title={Can multisensory training aid visual learning? A computational investigation},
  author={Jacobs, Robert A and Xu, Chenliang},
  journal={Journal of vision},
  volume={19},
  number={11},
  pages={1--1},
  year={2019},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{shams2008benefits,
  title={Benefits of multisensory learning},
  author={Shams, Ladan and Seitz, Aaron R},
  journal={Trends in cognitive sciences},
  volume={12},
  number={11},
  pages={411--417},
  year={2008},
  publisher={Elsevier}
}

@article{spence2003multisensory,
  title={Multisensory integration: maintaining the perception of synchrony},
  author={Spence, Charles and Squire, Sarah},
  journal={Current Biology},
  volume={13},
  number={13},
  pages={R519--R521},
  year={2003},
  publisher={Elsevier}
}

@article{xiao2020audiovisual,
  title={Audiovisual slowfast networks for video recognition},
  author={Xiao, Fanyi and Lee, Yong Jae and Grauman, Kristen and Malik, Jitendra and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2001.08740},
  year={2020}
}

@article{cartas2019much,
  title={How Much Does Audio Matter to Recognize Egocentric Object Interactions?},
  author={Cartas, Alejandro and Luque, Jordi and Radeva, Petia and Segura, Carlos and Dimiccoli, Mariella},
  journal={arXiv preprint arXiv:1906.00634},
  year={2019}
}

@inproceedings{schonberger2016structure,
  title={Structure-from-motion revisited},
  author={Schonberger, Johannes L and Frahm, Jan-Michael},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4104--4113},
  year={2016}
}

@article{vijayanarasimhan2017sfm,
  title={Sfm-net: Learning of structure and motion from video},
  author={Vijayanarasimhan, Sudheendra and Ricco, Susanna and Schmid, Cordelia and Sukthankar, Rahul and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:1704.07804},
  year={2017}
}

@article{fischler1981random,
  title={Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
  author={Fischler, Martin A and Bolles, Robert C},
  journal={Communications of the ACM},
  volume={24},
  number={6},
  pages={381--395},
  year={1981},
  publisher={ACM New York, NY, USA}
}

@article{lowe2004distinctive,
  title={Distinctive image features from scale-invariant keypoints},
  author={Lowe, David G},
  journal={International journal of computer vision},
  volume={60},
  number={2},
  pages={91--110},
  year={2004},
  publisher={Springer}
}

@article{le2020contrastive,
  title={Contrastive representation learning: A framework and review},
  author={Le-Khac, Phuc H and Healy, Graham and Smeaton, Alan F},
  journal={IEEE Access},
  volume={8},
  pages={193907--193934},
  year={2020},
  publisher={IEEE}
}

@inproceedings{rouditchenko2019self,
  title={Self-supervised audio-visual co-segmentation},
  author={Rouditchenko, Andrew and Zhao, Hang and Gan, Chuang and McDermott, Josh and Torralba, Antonio},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2357--2361},
  year={2019},
  organization={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{donley2021easycom,
  title={EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy Communication in Noisy Environments},
  author={Donley, Jacob and Tourbabin, Vladimir and Lee, Jung-Suk and Broyles, Mark and Jiang, Hao and Shen, Jie and Pantic, Maja and Ithapu, Vamsi Krishna and Mehra, Ravish},
  journal={arXiv preprint arXiv:2107.04174},
  year={2021}
}

@article{northcutt2020egocom,
  title={Egocom: A multi-person multi-modal egocentric communications dataset},
  author={Northcutt, Curtis and Zha, Shengxin and Lovegrove, Steven and Newcombe, Richard},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}

@inproceedings{li2018eye,
  title={In the eye of beholder: Joint learning of gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, James M},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={619--635},
  year={2018}
}

@inproceedings{fathi2011learning,
  title={Learning to recognize objects in egocentric activities},
  author={Fathi, Alireza and Ren, Xiaofeng and Rehg, James M},
  booktitle={CVPR 2011},
  pages={3281--3288},
  year={2011},
  organization={IEEE}
}

@inproceedings{li2013pixel,
  title={Pixel-level hand detection in ego-centric videos},
  author={Li, Cheng and Kitani, Kris M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3570--3577},
  year={2013}
}

@inproceedings{li2013learning,
  title={Learning to predict gaze in egocentric video},
  author={Li, Yin and Fathi, Alireza and Rehg, James M},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3216--3223},
  year={2013}
}

@inproceedings{park2016egocentric,
  title={Egocentric future localization},
  author={Park, Hyun Soo and Hwang, Jyh-Jing and Niu, Yedong and Shi, Jianbo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4697--4705},
  year={2016}
}

@inproceedings{munro2020multi,
  title={Multi-modal domain adaptation for fine-grained action recognition},
  author={Munro, Jonathan and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={122--132},
  year={2020}
}

@inproceedings{wang2021interactive,
  title={Interactive prototype learning for egocentric action recognition},
  author={Wang, Xiaohan and Zhu, Linchao and Wang, Heng and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8168--8177},
  year={2021}
}

@inproceedings{kim2019immersive,
  title={Immersive spatial audio reproduction for vr/ar using room acoustic modelling from 360 images},
  author={Kim, Hansung and Remaggi, Luca and Jackson, Philip JB and Hilton, Adrian},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  pages={120--126},
  year={2019},
  organization={IEEE}
}

@inproceedings{hu2022mix,
  title={Mix and Localize: Localizing Sound Sources in Mixtures},
  author={Hu, Xixi and Chen, Ziyang and Owens, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10483--10492},
  year={2022}
}

@inproceedings{song2022self,
  title={Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes},
  author={Song, Zengjie and Wang, Yuxi and Fan, Junsong and Tan, Tieniu and Zhang, Zhaoxiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3222--3231},
  year={2022}
}

@article{mo2022localizing,
  title={Localizing Visual Sounds the Easy Way},
  author={Mo, Shentong and Morgado, Pedro},
  journal={arXiv preprint arXiv:2203.09324},
  year={2022}
}

@article{mo2022closer,
  title={A Closer Look at Weakly-Supervised Audio-Visual Source Localization},
  author={Mo, Shentong and Morgado, Pedro},
  journal={arXiv preprint arXiv:2209.09634},
  year={2022}
}

@article{kim2019eyes,
  title={Eyes are faster than hands: A soft wearable robot learns user intention from the egocentric view},
  author={Kim, Daekyum and Kang, Brian Byunghyun and Kim, Kyu Bum and Choi, Hyungmin and Ha, Jeesoo and Cho, Kyu-Jin and Jo, Sungho},
  journal={Science Robotics},
  volume={4},
  number={26},
  pages={eaav2949},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{kawamura2002toward,
  title={Toward egocentric navigation},
  author={Kawamura, Kazuhiko and Koku, A Bugra and Wilkes, D Mitchell and Peters, Richard Alan and Sekmen, Ali},
  journal={International Journal of Robotics and Automation},
  volume={17},
  number={4},
  pages={135--145},
  year={2002},
  publisher={Anaheim, Calif.; Calgary, Alta.: Acta Press,[1986]-}
}

@article{martin2021jrdb,
  title={Jrdb: A dataset and benchmark of egocentric robot visual perception of humans in built environments},
  author={Martin-Martin, Roberto and Patel, Mihir and Rezatofighi, Hamid and Shenoi, Abhijeet and Gwak, JunYoung and Frankel, Eric and Sadeghian, Amir and Savarese, Silvio},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2021},
  publisher={IEEE}
}

@inproceedings{jones2008effects,
  title={The effects of virtual reality, augmented reality, and motion parallax on egocentric depth perception},
  author={Jones, J Adam and Swan, J Edward and Singh, Gurjot and Kolstad, Eric and Ellis, Stephen R},
  booktitle={Proceedings of the 5th symposium on Applied perception in graphics and visualization},
  pages={9--14},
  year={2008}
}

@article{serino2015detecting,
  title={Detecting early egocentric and allocentric impairments deficits in Alzheimer’s disease: An experimental study with virtual reality},
  author={Serino, Silvia and Morganti, Francesca and Di Stefano, Fabio and Riva, Giuseppe},
  journal={Frontiers in aging neuroscience},
  volume={7},
  pages={88},
  year={2015},
  publisher={Frontiers Media SA}
}

@article{morganti2013allo,
  title={From allo-to egocentric spatial ability in early Alzheimer’s disease: a study with virtual reality spatial tasks},
  author={Morganti, Francesca and Stefanini, Stefano and Riva, Giuseppe},
  journal={Cognitive neuroscience},
  volume={4},
  number={3-4},
  pages={171--180},
  year={2013},
  publisher={Taylor \& Francis}
}

@inproceedings{poupyrev1998egocentric,
  title={Egocentric object manipulation in virtual environments: empirical evaluation of interaction techniques},
  author={Poupyrev, Ivan and Ichikawa, Tadao and Weghorst, Suzanne and Billinghurst, Mark},
  booktitle={Computer graphics forum},
  volume={17},
  number={3},
  pages={41--52},
  year={1998},
  organization={Wiley Online Library}
}

@article{swan2007egocentric,
  title={Egocentric depth judgments in optical, see-through augmented reality},
  author={Swan, J Edward and Jones, Adam and Kolstad, Eric and Livingston, Mark A and Smallman, Harvey S},
  journal={IEEE transactions on visualization and computer graphics},
  volume={13},
  number={3},
  pages={429--442},
  year={2007},
  publisher={IEEE}
}

@inproceedings{choe2020evaluating,
  title={Evaluating weakly supervised object localization methods right},
  author={Choe, Junsuk and Oh, Seong Joon and Lee, Seungho and Chun, Sanghyuk and Akata, Zeynep and Shim, Hyunjung},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3133--3142},
  year={2020}
}

@article{maron1997framework,
  title={A framework for multiple-instance learning},
  author={Maron, Oded and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={Advances in neural information processing systems},
  volume={10},
  year={1997}
}