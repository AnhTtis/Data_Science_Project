%% appx 1 page of content
\newpage
\begin{figure}[t]
    \centering
    \includegraphics[trim=0 160 0 0,clip,width=.9\textwidth]{media/Overview.pdf}
    \caption{\textbf{The \name competition procedure.} \smchange{Participants developed their approaches through training and fine-tuning with human feedback. We evaluated the methods with human judgments and rank submissions according to their TrueSkill rating \citep{herbrich2006trueskill}.}\vspace{-8pt}}
    \label{fig:overview}
\end{figure}
\section{Introduction}
\label{sec:intro} 
%% media: competition procedure? overview of participant performance?
\smchange{
The creation of foundation models~\citep{bommasani2021opportunities} has spurred advances across the field of machine learning, including few-shot learning~\citep{brown2020language}, sequential decision-making~\citep{carroll2022unimask}, and zero-shot image classification~\citep{radford2021learning}. 
In many tasks of real-world interest, exactly specifying an objective is challenging~\citep{kerr1975folly,russell2010artificial}.
Instead, these models are typically optimized to perform well with a self-supervised loss function, such as predicting the next word in an incomplete sentence~\citep{taylor1953cloze}, rather than the actual task of interest. 
To redirect these capabilities for the desired task, a natural idea is to then utilize human feedback for \textit{fine-tuning} these large pre-trained models. 
Although prior work has investigated the use of these feedback modalities for training~\citep{lin2020review}, few of these have been applied to foundation models outside of natural language applications~\citep{nakano2021webgpt,ouyang2022training}.}
%As a motivating example, the combination of recent advances in learning from human feedback, these models have unlocked new capabilities for conversational agents \smnote{cite chatgpt}, \smnote{any other major things we can cite?}, and more. \ak{Maybe a more concrete example of why this is interesting (solving tasks without rewards), and one-sentence description of what the competition challenged participants to do ("participants were challenged to solve four rewardless tasks in Minecraft with the help of a pre-trained, large gameplay model in Minecraft [cite vpt]")}
%\kb{I asume we you are leaving out Foundatinal models + Human feedback work that has been going on in language? Or are you separating human feedback that is learned using a reward model versus using human feedback online without a reward modelsd}
%\smnote{not necessarily leaving this out -- is there a lot of work in this area? if you have refs, that would be greatly appreciated.}

\smchange{
To further encourage research progress in developing techniques for learning from human feedback for training foundation models, we held the second annual MineRL Benchmark for Agents that Solve Almost Lifelike Tasks (\namenospace) competition~\citep{shah2021minerl} at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 
Different from last year, we focused on \textit{fine-tuning}.
To our knowledge, this competition is the first to test fine-tuning from human feedback (\fthf) techniques in the sequential decision-making setting. 
\Cref{fig:overview} provides a high-level overview of the competition.
Over the span of four months, teams developed agents for four challenging open-world tasks in Minecraft.
These tasks were specifically designed to have challenging task specifications, with hard-to-define reward functions that encourage a focus on \fthf.
More broadly, we see the impact of this competition as coming from the following sources.
The resulting techniques can enable the construction of AI systems for tasks without formal specifications and expand the set of properties that we can incorporate into such systems.
For more details about the broader impact of this competition, please see the competition proposal~\citep{shah2021minerl}.
In this paper, w}e present a high-level overview of the competition, a summary of the top solutions, and considerations for future competitions of this type.
