\section{Discussion}
\change{We contributed the first research that (1) investigated the suitable gaze calibration and collection for low vision people via commercial eye trackers and (2) thoroughly explored low vision people's unique gaze behaviors and challenges during reading. %  The purpose of this study was to (1) examine the feasibility of using commercial eye tracker for low vision research, and (2) investigate low vision people's gaze patterns during reading to inspire gaze-based assistive technology. Our study validated three out of our four hypotheses:
We answer our four research questions by responding to our four groups of hypotheses.}

\change{With the adjustable calibration interface and dominant-eye-based data collection, we found that commercial eye trackers (e.g., Tobii eye tracker) can achieve comparable quality of gaze data between low vision and sighted people (H1), with no significant difference in the gaze recognition accuracy (H1.1) and data loss (H1.2). The high alignment between participants' gaze trajectory and their reading progress also validated low vision participants' data quality. These results highlighted the potential of commercial eye trackers in low vision research. With commercial eye trackers increasingly integrated in everyday devices, our research opened up a new research direction for gaze-based vision enhancement technology for low vision users.}

\change{We further characterized low vision people's gaze challenges in reading via their gaze patterns. We found that low vision people demonstrated different gaze behaviors from sighted people (H2), with more but shorter fixations (H2.1) as well as more but shorter forward saccades (H2.2), indicating their difficulty with information perception per fixation and skimming. We also identified low vision people's challenges with line switching due to their significant higher number of searched lines (H2.3). Moreover, we found that different visual abilities (H3) and magnification modes (H4) can affect low vision people's gaze behaviors differently. Specifically, both low visual acuity and visual field loss led to more but shorter fixations (H3.1) and shorter forward saccades (H3.2). However, no significant effect of visual abilities (only a trend in visual acuity) was found on line switching behaviors (H3.3). In terms of magnification modes, we found the regular mode with increased font size more effective than the lens and full-screen magnifier, with longer fixation duration (H4.1), fewer regressive saccades, lower revisitation rates (H4.2), and fewer searched lines during line switching (H4.3).}   
%saccade patterns (H2.2) and line searching behaviors (H2.3). Therefore our H2 is verified. %how the two populations differ in the way of using their gaze during reading. 
%We then compare between different visual abilities to identify the effect of low vision conditions on people's gaze behaviors (e.g., people with limited central vision have shorter perceptual span), and found that different visual abilities can affect low vision people's gaze behavior differently (H3). To be more specific, we foun both visual acuity and visual field had significant effect on fixation patterns (H3.1) and saccade patterns (H3.2), but only the interaction between these two factors was found to have significant effect on line switching patterns (H3.3). Finally, we compare between different magnification modes to obtain fine-grained insights on the benefits and drawbacks of commonly used assistive aids (e.g., larger window size can improve reading efficiency). Our result showed that different magnification modes affect low vision people's fixation pattern (H4.1) and saccadde patterns (H4.2) differently, but no significant effect of magnification modes was found on the measures regarding lie switching behaviors (H4.3). Therefore, our H4 is patially rejected. 
%the reading eye movement when low participants used three commonly available magnification approaches to obtain fine-grained insights on low vision people's gaze behavior and adaptations when using magnification tools. 

%Our work contributes the first investigation on low vision people's everyday reading experiences using a commercial eye tracker via the lens of HCI. 
Unlike prior work that infers low vision people's visual experiences and challenges via reading performances 
~\cite{bruggeman2002psychophysics, hallett2017screen,
harland1998psychophysics, moreno2021exploratory, ahn1995psychophysics}, our work draw direct evidence on participants' gaze data at the word and sentence level to develop a deep understanding of their challenges. This fine-grained investigation allows us to unfold low vision people's reading difficulties (e.g., locating next line correctly) and derive design implications for more targeted vision enhancement technology based on low vision users' detailed gaze behaviors. %integrating qualitative and quantitative data, we provide detailed analysis to facilitate the design of eye-tracking based visual augmentation system. 
%Although prior research in vision science has utilized eye tracking to understand low vision people's gaze use (mainly focusing on central vision loss)~\cite{rubin2009role, rayner1998eye}, such research interprets the eye movements from an optometry perspective without considering the gaze-based technology opportunities from the HCI perspective. 
We discuss our results by identifying the limitations and potential improvements for current eye tracking technology, as well as deriving implications to guide the design of gaze-based technology for low vision. 

%revealed important characteristics of low vision people's gaze pattern, their findings does not inform low vision people's reading behavior in everyday settings, such as reading news on websites. 

%Although we were able to collect low vision participants' eye movement data and complete analysis regarding their gaze pattern, we identified some limitations of current eye tracking technology for low vision research. On the other hand, the design space for applying eye tracking technology to support low vision people's daily tasks is still huge. Design guidelines need to be derived to pave the way for future accessibility research.

\subsection{Accessible Eye Tracking Technology for Low Vision Users}
\subsubsection{\change{Accessible Calibration Interface for Different Visual Conditions}}
\change{The conventional calibration interface (e.g., Tobii Pro Lab) did not consider low vision people's visual abilities and eye characteristics.} While we refined the calibration interface by customizing the target size for low vision people, addressing the invisible target issue, \change{our calibration process could still be challenging for some low vision participants. For example, some participants could not focus on a target for a long duration required by the calibration due to their visual conditions, such as Nystagmus (Caroline) and dry eyes (Fiona). To address this, future calibration could consider data collection on more targets with shorter duration for each target.} Since different low vision users may have different visual abilities and thus different needs for the calibration process, adaptations based on the user's visual conditions can be integrated, automatically adjusting the calibration interface, such as the number, color, and size of the calibration targets, and the duration of each target.

%Moreover, some participants felt confused about when the data collection for a target starts and ends due to the lack of feedback to indicate the data collection process. Proper feedback should be integrated to assist users to complete calibration.
% As such, visual cues could be used to indicate the data collection status. 
% For example, prior work~\cite{zhao2016cuesee} has investigated the effectiveness of using different visual cues to direct low vision people's attention in visual tasks. 

\subsubsection{\change{Data Collection by Considering the Dominant Eye.}} 
 \change{Binocular data collection strategy can cause low accuracy if the user demonstrates inconsistent eye movement or irregular pupil appearance \cite{maus2020gaze}. We addressed this via dominant-eye-based data collection if a low vision user had an obvious dominant eye (i.e., the weaker eye does not follow the dominant eye or one eye is not recognizable). Our data collection strategy resulted in relatively high accuracy that is comparable to sighted people. Not only for low vision users, prior work with sighted participants also shows that the dominant eye can fixate at a target more accurately and precisely than the non-dominant eye~\cite{simonsz1991covering, gibaldi2017evaluation}. As such, the dominant eye should be considered in data collection when high accuracy is required. While some low-tech tests (e.g., hole-in-the-card test~\cite{durand1910method}) are usually needed to determine eye dominance without prior knowledge, future eye tracking technology should consider how to automatically detect the dominant eye. Despite the advantages of dominant-eye-based data collection, this strategy can also be volatile when occlusion of the dominant eye occurs due to head and body movement. Tradeoff should be considered to suitably adopt binocular or dominant-eye-based data collection.}
 
 % However, if eye tracker is to be embeded in low vision users' daily life, completing calibration independently can still be a challenging task, because the user need to rely on their own judgement on which eye they should use for calibration without researchers' assistance
 % , which can be confusing to users who do not know how eye trackers work. 
 % To tackle these issues, future eye trackers should be able to detect users' eye conditions to automatically decide if a monocular calibration is preferred, and use the eye with higher recognition confidence (dominant eye) to calibrate and collect gaze data. However, by collecting gaze data from only one eye, dominant-eye-based calibration can be volatile when occlusion of the dominant eye occurs, due to head and body movement. \yuhang{fix}


 

\subsubsection{\change{Requirements on the User Position}}
Current eye trackers impose strict requirements on the user's sitting position, including the distance between the user's eyes and the screen and the relative height of the user's head to the screen. \change{However, this could conflict with low vision people's common reading habits. For example, many low vision people tend to get very close to the screen to read \cite{maus2020gaze, szpiro2016people} but exceeded the standard distance range required by the eye tracker.} \change{Future eye tracker design should consider the unique reading habits of low vision people.} Moreover, wearable eye trackers could be considered to reduce the burdens on low vision users to fulfil the requirements of screen-based eye trackers. % be a better option for low vision users.

\subsubsection{\change{Transparency of the Data Collection Status.}} \change{Beyond the essential issues with current gaze calibration and collection methods, transparency of the data collection status should also be improved to enhance the eye tracker usability.} For example, some participants (Piper) felt confused about when the data collection for a target started and ended due to the lack of feedback for data collection status. Moreover, in our study, we found it hard to determine and maintain the data collection quality \change{in real time, which led to unusable data and discarded participant samples}. \change{It is thus important to provide proper feedback on an eye tracking interface to indicate the data collection status (e.g., beginning, end, and failure of data collection), and prompt instructions to the user timely when necessary to ensure high quality data collection.} For example, when the user's eyes become undetectable, the system should prompt the user to adjust their position in an explicit \change{and accessible} way.




\subsection{Design Implications for Gaze-Based Assistive Technology}
Our work highlights the potential of detecting low vision users' eye movement events using commercial eye trackers. We propose the following design implications for future assistive technologies using eye tracking.

\subsubsection{Real-Time Support for Line Following and Line Switching}
Locating the next line and keeping track of the current line is a big challenge for low vision people, especially when using screen magnifiers. With eye tracking, we can identify the line a user is reading and their intent to switch lines by recognizing the regressive saccade (i.e., return sweep) at the end of each line. As such, visual augmentations could be designed to provide real-time support, such as highlighting the current or next line~\cite{gowases2011text}, or dynamically adjusting the line spacing based on the users' gaze position. Participants mentioned different strategies to orient themselves in a reading material, for example, remembering the last few words of the line to see if the next line made sense (Judy, Lucy, \change{Danilo, Marilyn and Julia}), or memorizing the first several words of the prior line to see if they had read the same line (Lucy, Tim, \change{Piper and Fiona}). With eye tracking, an assistive system can be designed to remind the user of those key words at the right timing to help them locate the correct line. Moreover, we can detect irregular gaze behaviors during reading, such as losing track of a line due to looking away from the screen or the moving of the magnifier, and generate feedback to notify the user where they were reading to improve their reading efficiency. 


\subsubsection{\change{Support for Unrecognizable Words}}
While many low vision people prefer using vision to access information~\cite{szpiro2016people, zhao2015foresee}, some participants  had trouble recognizing words due to low visual acuity or visual field loss, such as distorted words (Judy) and missing letters (Mary, Bella and \change{Julia}). With eye tracking technique, we can potentially recognize these issues and provide corresponding assistance. For example, when a long fixation at a word or frequent revisitations are detected, the system can directly read the nearby words or phrases to the user to improve their reading experience. 

%Furthermore, prior research on AR-based visual and audio augmentations~\cite{stearns2018design, zhao2015foresee, zhao2016cuesee, zhao2020effectiveness} has demonstrated great potential to support low vision people in visual tasks. With eye tracking embedded in AR glasses (e.g., HoloLens), we can extend such research and design gaze-based enhancements on AR devices to facilitate reading beyond computer screen. For example, during navigation, we can design an AR system that reads a street sign at distance for low vision users if they fixate on that sign.

%a gaze-based AR augmentation can recognize the surrounding obstacles and provide multi-modal alerts if a user is approaching an obstacle but has not noticed it (i.e., no gaze points around the obstacle). 

\subsubsection{Hands-Free and Context-Aware Screen Magnifier}
Eye tracking technique has the potential to improve screen magnifiers. Moving and tracking the screen magnifier can diminish reading performance and experience \cite{moreno2021exploratory, ahn1995psychophysics, szpiro2016people, hallett2015reading, hallett2017screen}. \change{Nine} low vision participants in our study echoed this problem of hand-eye coordination. \change{Thus, instead of moving the magnifier around with a mouse, hands-free screen magnifiers controlled by gaze could be more desirable~\cite{maus2020gaze, aguilar2017evaluation}.}
% the movement of the magnifier needs to be smoothed to reduce nausea~\cite{hallett2017screen} and visual tiredness. 
\change{Another drawback of screen magnifiers is fixed local-view to global-view ratio.}
% Screen magnifiers are commonly used by low vision people. Interestingly, 
Our study revealed that different window size for the lens magnifier \change{had different pros and cons:} taller windows (i.e., window containing more lines) contain more contextual information, \change{but can be more distracting}; while shorter windows reduce distraction, \change{but lacks sufficient context}. Future technology can consider a context-aware magnifier, which detects the user's needs and adjust the magnification window accordingly.
% that context-aware magnification can be a potential solution. 
For example, when the system detects that the user loses track or is switching lines, the window size would be automatically enlarged to contain more contextual information; when the user is actively reading a line, the window size would be reduced to include fewer lines to reduce distraction. 
% around the text the user is reading. 

\subsection{Limitations \& Future Work}
Our research has limitations.  
\change{First, our low vision participants presented a variety of visual conditions, which can potentially reduce the statistical power. However, low vision is complex and it is very difficult to recruit many low vision participants with the same visual abilities. For example, participants who have similar visual acuity could have very different field of view; participants with the same diagnosed condition could experience different severity.
As such, as the first step of exploration, we broadly recruited participants with different visual abilities and analyzed the effect of visual abilities on low vision people's gaze behaviors. This study helped us identify particular low vision conditions that worth further investigation, for example, people with Nystagmus are particularly hard for eye tracker to track their gaze. In the future, we will focus on particular low vision groups and recruit more participants for a more thorough analysis. Second, our low vision group and sighted group had a big age difference. While prior research has shown that age does not affect low vision people's gaze behaviors during reading~\cite{bowers2001eye}, future research should consider recruiting a sighted control group at the similar age level to the low vision group to remove the potential effect.}
%see low vision as a whole population and recruit low vision participants with different visual conditions. thus increasing the complexity of our participant  the   due to the complexity and diversity of visual abilities in low vision population, it is almost impossible to recruit low vision participants with the same visual abilities. The variety of low vision conditions can reduce the statistical power in the analysis comparing different visual conditions. To address this issue, we will try to identify and involve more visual condition factors to better characterize the reading behavior of people with different low vision conditions.}
%Moreover, while broadly recruiting low vision participants with different visual conditions, our study did not cover all possible low vision conditions. For example, although we had six participants who experienced central vision loss, we did not find any participants who developed two PRL ~\cite{crossland2005preferred}. In the future, we will recruit more low vision participants to explore the feasibility of eye trackers and potentially design suitable eye tracking algorithms to support particular low vision conditions. 
Lastly, to support the analysis of gaze data, we asked participants to read the passages aloud to confirm their reading progress. However, it is unclear whether our findings could be generalized to silent reading, given that reading aloud is slower and involves more frequent fixations than silent reading~\cite{rayner200935th}. %Besides, due to technical limitation of the eye tracker, we asked participants to take off their glasses if they could. Therefore, their reading behaviors recorded in our study can be different from their usual way of reading with glasses. 
Future research should examine low vision people's gaze behaviors in silent reading to better simulate their daily reading experience.

\section{Conclusion}
\change{In this paper, we explored the potential of using a commercial eye tracker for low vision people and investigated their reading gaze behaviors by conducting a study with 20 low vision participants and 20 sighted controls. We improved the traditional calibration interface and validated the effectiveness and data quality of the eye tracker for low vision users. We further explored low vision people's gaze behaviors, revealing their unique gaze patterns compared to sighted people, as well as the effect of different visual abilities and magnification modes on low vision people's gaze behaviors. 
We hope that our work will inspire the design and development of gaze-based assistive technology for low vision people.}

\begin{acks}
We would like to thank Davit Khachatryan for his contribution to participant recruitment and data analysis, as well as our study participants for their valuable feedback. This work was partially supported by the University of Wisconsin--Madison Office of the Vice Chancellor for Research and Graduate Education with funding from the Wisconsin Alumni Research Foundation, and the Expanding Our Vision 2021 Award from the McPherson Eye Research Institute at the University of Wisconsin--Madison. 
\end{acks}

% While being able to read with screen magnifiers, low vision people suffer from slow and unpleasant reading experiences. Eye tracking has the potential to improve their experience by recognizing people's fine-grained gaze behaviors and providing more targeted enhancements. To inspire gaze-based technology, we aim to \change{investigate the suitable method to collect low vision users' gaze data via commercial eye trackers and thoroughly understand their challenges in reading based on their gaze behaviors}. With an improved calibration interface, we collected the gaze data of \change{20 low vision participants and 20 sighted controls} who performed reading tasks on a computer screen; low vision participants were also asked to read with different screen magnifiers. We found that, with suitable calibration interfaces and data collection method, commercial eye trackers can be promising tools for low vision research. Our study identified low vision peopleâ€™s unique gaze patterns during reading, building upon which, we propose design implications for gaze-based low vision technology.