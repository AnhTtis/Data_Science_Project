%File: formatting-instructions-latex-2023.tex
%release 2023.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2023.1)
}

\newcommand{\etal}{\textit{et al}. }
\newcommand{\ie}{\textit{i}.\textit{e}., }
\newcommand{\eg}{\textit{e}.\textit{g}. }

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

\iffalse
\title{Parametric Surface Constrained Upsampler Network for Point Cloud}

\author{
    %Authors
    % All authors must be in the same font size and format.
    Paper ID: 1768
}
\fi

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi


%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{Parametric Surface Constrained Upsampler Network for Point Cloud}
\author {
    % Authors
    Pingping Cai,
    Zhenyao Wu,
    Xinyi Wu,
    Song Wang
}
\affiliations {
    % Affiliations
    University of South Carolina, USA \\

    \{pcai,zhenyao,xinyiw\}@email.sc.edu, songwang@cec.sc.edu
}


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}
\maketitle

\begin{abstract}
% Point Cloud Super-Resolution is a fundamental problem for computer vision,
% and many deep-learning algorithms have been proposed to solve this problem.
%% the importance
Designing a point cloud upsampler, which aims to generate a clean and dense point cloud given a sparse point representation, is a fundamental and challenging problem in computer vision.
%% Not fully addressed.
%and addressed by many deep learning approaches recently.
%The design of the upsampling operator is crucial for this problem.
A line of attempts achieves this goal by establishing a point-to-point mapping function via deep neural networks.
However, these approaches are prone to produce outlier points due to the lack of explicit surface-level constraints.
% To generate points that locate on surfaces, previous researcher 
% have introduced the manifold knowledge into the network design,
% where they model the manifolds via MLPs.
% But, is MLPs a good way to model the manifolds for point clouds?
% Although MLPs have powerful learning capabilities,
% their performance are limited due to the existing gaps between discrete point coordinates and continuous manifolds.
% In this paper, we learn the local manifold for each point by estimating the bicubic function and rotation function 
% via a newly proposed manifold deconvolution block, where the new generated points are constrained on each manifold to achieve smooth results.
To solve this problem, we introduce a novel surface regularizer into the upsampler network by forcing the neural network to learn the underlying parametric surface represented by bicubic functions and rotation functions, 
where the new generated points are then constrained on the underlying surface.
% Based on the Manifold Deconvolution block, we build two different networks for two tasks: 
These designs are integrated into two different networks for two tasks that take advantages of upsampling layers -- point cloud upsampling and point cloud completion for evaluation.
The state-of-the-art experimental results on both tasks demonstrate the effectiveness of the proposed method.
The code is available at https://github.com/corecai163/PSCU.
% to mitigate this gap
% and introduce a novel Manifold Deconvolution block for point cloud super resolution.
% We also design a new network with proposed Manifold Deconvolution blocks
% and apply it to two related tasks: upsampling and completion.
% We achieve the SOTA results on both tasks with proposed Manifold Deconvolution network,
% which justify the correctness of our idea.
\end{abstract}


\section{Introduction}
\label{intro}
%%
%% Problem is important and challenge
Point cloud is an efficient data structure to represent 3D objects. But, due to the limitation of sensors, the collected point clouds are usually sparse and incomplete. Therefore, point cloud upsampling \cite{pugan,PUGCN,punet,pugeo,Wang2019PatchBasedP3} is introduced to generate denser point clouds for better scene representation, which benefits many computer vision applications such as autonomous driving \cite{pcdForAutoDrive,pcdForAutoDrive2}, 3D object classification \cite{Li_2020_CVPR,pointnetplusplus}, semantic segmentation \cite{pcd_seg,Landrieu_2018_CVPR,Engelmann_2017_ICCV} and robotics \cite{pcdForRobot}. 
%The goal of point cloud upsampling is to generate a dense point set based on the input sparse point cloud. In addition, the generated dense representation needs to keep a reasonable shape and surface.
For point cloud upsampling, it is expected that the generated dense points can well represent the shape and surface underlying the point cloud.
However, obtaining such property is challenging, and even previous state-of-the-art (SOTA) methods may generate many noisy and outlier points (see Figure \ref{fig:mlp_fail}).
%Unlike upsampling in 2D space, \textit{i.e.,} image super-resolution, point cloud upsampling is much more challenging since the points are distributed unorderly in the 3D space without regularity. 
% Currently, there are both non-learning \citeauthor{} and learning \citeauthor{} based approaches proposed for this task. In this paper, we focus on the learning-based camp and make improvements.
% Point cloud upsampling is a fundamental problem for computer vision and has becoming increasingly important due to the rapid development of autonomous driving \citeauthor{pcdForAutoDrive} and robotic \citeauthor{pcdForRobot}, where they rely on dense point clouds with rich details and fine structures to represent and understand the surrounding 3D objects. 
% Usually, to represent the 3D objects, we can use 3D meshs, voxels and point clouds.
% Amount them, Point Cloud (PCD) is an efficient data structure with coordinates of points only.
% However, the collected point clouds are mostly sparse and incomplete due to the low resolution of sensors.
% As the representation ability of a 3D point cloud is highly affected by its resolution, these low-resolution point clouds will hamper the performance of many vision applications, \textit{e.g.} 3D object classification \citeauthor{Li_2020_CVPR,pointnetplusplus} and semantic segmentation \citeauthor{pcd_seg,Landrieu_2018_CVPR}.
% Thus, generating a high-resolution point cloud from the corresponding low-resolution one is an essential research topic that will benefit many applications.

%%Problem is challenging
%% How to guarantee the smoothness of upsampled points.
% Although deep learning has succeeded in many vision tasks, 
% it is nontrivial to apply it to the point cloud data and generate a high-resolution point cloud from its low-resolution one.
% The goal of the point cloud upsampling is not only to generate a point cloud with more number of points but also to keep and infer the correct shape and surfaces of the upsampled point cloud.

%and the smoothness is crucial for the downstream 3D visual tasks, like meshing reconstruction \citeauthor{meshing} and 3d modelling \citeauthor{bmi}.
%benefiting downstream 3D visual tasks, like meshing \citeauthor{meshing} and building information modelling \citeauthor{bmi}, where the smoothness of points is crutial.

% Due to the fact that points in the point cloud locate
% unorderly in the 3D space without regularity, 
% there is no one-by-one matching between the generated point cloud and ground truth, where we can not apply the popular convolution operations to point clouds.
% It is a challenge to reconstruct the coordinates of each upsampled point.
%and the only goal is to predict the color for each pixel. 
% Besides, how to explore the underlying surfaces of the input point cloud and constrain the upsampled points to be located on these surfaces is another challenge.
%Even though, with well-design point-wise loss function 
% Thus, how to design a network to upsample point clouds remains a challenge.
%However, due to the non-regularity and unordered properties of points, it is nontrivial to apply the popular convolution operations to point clouds.
% Point cloud upsampling is quite different from the upsampling in 2d images, where the position of target pixel is fixed and the only goal is to predict the color for each pixel.
% and we can use the well-designed 2D convolution network to estimate the color for each pixel.
%in the 3D/2D grids
%and can be solved by deconvolution (also known as transposed convolution) networks.
% So it is nontrivial to apply the popular convolution operations to point clouds due to the non-regularity and unordered properties of points.
%The deconvolution kernel is well-designed for traditional 2D/3D images, 
%where the position of each pixel is fixed.
%It remains a challenge to design a deconvolution kernel for point cloud data, where each point may randomly locate in 3D spaces.
%To solve this problem, 
\begin{figure}
	\centering
	\includegraphics[width=0.470\textwidth]{figures/intro/mlp_fails}
	\caption{The double-layer lid can be clearly upsampled by our method,
   while the traditional EAR \cite{ear} fails to distinguish the two nearby layers and the previous SOTA method PU-GCN \cite{PUGCN} generates many noisy and outlier points. Please zoom in for more details.
   }
	\label{fig:mlp_fail}
\end{figure}

%% previous methods and their limitations
Many sophisticated methods have been proposed to solve this challenging problem.
Traditional optimization based methods \cite{traditional_1,traditional_2,ear,traditional_4,traditional_5} rely on geometric priors to upsample the point cloud but often fail when the input is complex and have been outperformed by recent deep learning methods.
%Previous researchers have proposed many well-designed point cloud upsampling networks,
These well-designed deep learning methods can be 
further divided into two categories based on their adopted upsampler:
1) feature-based upsampling methods and 2) folding-based upsampling methods.
The feature-based methods \cite{SFA,PF-Net,wu2019point,MetaPUAA,PUGCN,punet,snowflakenet} first extract shape features from input points and expand the number of points by upscaling the shape features in the feature space. These upsampled features are then fed into a coordinate regression block (MLPs) to predict their coordinates. %To train the network, 
A point-wise loss function, \textit{i.e.,} Chamfer Distance \cite{FanSG17}, is usually used to train the network.
However, this loss function only measures the point-wise distance and can not measure the difference of underlying surfaces between point clouds.
As a result, these methods often fail to generate points that are located accurately on the underlying surfaces.
%, as shown in Figure \ref{fig:mlp_fail}.
Folding-based methods \cite{foldingnet,pcn,msn,spu,pc2pu,luo2020differentiable} expand the number of points by introducing a predefined 2D grid for each point and then concatenating them with shape features to regress for their coordinates via MLPs -- they
can be viewed as a mimic of a morphing/surface function that transforms the 2D grid to target surfaces.
%MLP, Loss   ---not accurate surface (Fig) ----  There exists a gap between the continuous manifold and discrete point coordinates and these MLPs often fail to learn the accurate representation of the manifold.
%Although these upsampling techniques are well designed and have achieved prominent results, we still need to question that: \textbf{Is MLPs a good solution for mapping the 2D grids into the target manifolds?}
%But,
%when training these MLPs with point-wise loss, 
%the problem is that
%{the coordinates of point clouds are discrete while the surface is continuous and}
%without using the surface-level constraint, 
While they attempt to preserve a better surface structure,
they can only learn an overfitted point-point mapping with point-wise loss functions \cite{Deep_geometric_prior}, 
but not the accurate representation of the surface.
% We do agree that MLPs have a strong ability to fit arbitrary functions.
%Usually, we can use MLPs, which has a strong ability to represent any function, to model the coordinate regression block.
%Besides, to generate accurate point locations and global shapes, .
%surface function.
% However, when training these MLPs with point-wise loss, the problem occurs, where
% \textbf{the coordinates of point clouds are discrete while
% the manifold is continuous.}
% There exists a gap between the continuous manifold and discrete point coordinates
% and these MLPs often fail to learn the accurate representation of the manifold.
% Besides, such concatenation-based methods usually use one MLP to represent different 3D surfaces, which may introduce a bottleneck that further limits its accuracy.
%and introduce a bottleneck. (See result in our ablation study \ref{exp:2}).
% As a results, in Figure \ref{fig:mlp_fail}, if we zoom in the upsampled point cloud, we may find lots of points that locate off the surface.


%Intuitively, there are two ways to solve this problem: designing a better loss function or reducing the model space of network. 
%Although they can learn a global shape of object via these loss functions, 
%they can not guarantee that
%the regressed points lie on the underlying smooth surfaces and
%preserve good local shapes.
%To solve this problem, several novel algorithms introduce the manifold knowledge into coordinate regression block \citeauthor{luo2020differentiable,msn,pcn}.
%Based on the observation that points in the point cloud actually locate on 2D manifolds in 3D space, they model the manifold via MLPs that transform the discrete 2D grids in [0,1] into 3D space with concatenation-based folding  technique.
%Currently, how to remedy this gap is still a challenge.

%%PUGEO
%Instead of using MLPs to model morphing/surface functions,
To achieve a better surface representation,
PUGeo-Net \cite{pugeo} introduced a parameterized method that incorporates discrete differential geometry into network design, where it models the small surface around each input point via the first and second fundamental forms \cite{differential_geometry} to generate the upsampled points. However, this method relies heavily on the correctness of point normals and needs additional ground truth point normals to train the network. Such normals are not directly available in many point cloud datasets. 
Besides, it still uses MLPs to predict the point displacement and lacks explicit surface-level constraints.
Also, it follows the patch-based upsampling pipeline, which does not consider the smoothness between two adjacent patches.

% To solve this problem, we xx bicubic.  Different with the (2), constraints xx
We extend PUGeo-Net by using explicit parametric functions to model the local surface for each input point without the required supervision of point normal information.
%but it still works well with point-wise loss functions. 
Besides, instead of dividing the input point cloud into multiple patches, we directly upsample the entire input to avoid the discrepancy between adjacent patches.
%surface and avoiding the drawback in (\citeauthor{pugeo}).
%the mapping functions
%instead of brute-forcefully using MLPs to model the mapping functions, 
%we model them by Manifold Functions directly, which contains Bicubic Functions and Rotation Functions.
%From the perspective of network architecture design, this parameterized method can be viewed as adding more constraints to the search space for the new generated points.
% Similar idea can be found in the example of MLPs compared to Convolution Networks, where Convolution Networks introduce the Convolution Operators to limit the model space of MLPs and achieve prominent results for image-related tasks.
%Specifically, in this paper, we propose a novel solution to eliminate this gap by explicitly modeling the manifold functions via bicubic functions and rotation functions.
%We reduce the model space of MLPs by explicitly modeling the manifold functions via bicubic functions and rotation functions.
Specifically, we design a novel parametric surface constrained upsampler network that can extract the spatial surface features from discrete and unordered input points, predict explicit bicubic functions and rotation functions to express the underlying surfaces, and constrain the new generated points on these surfaces.
%coordinates With loss,PCA loss and CD loss...
% Even with point-wise loss functions, our proposed method can generate point clouds with smoother borders and shapes.
To further improve its performance, we also introduce a displacement loss for generating better parametric functions.
The proposed upsampler can be also used for other related tasks such as point cloud completion.

% This well-designed upsampling block can be applied into point cloud related tasks,
% such as point cloud up-sampling, point cloud
% completion and so on.
%Different from previous methods that 
%randomly generate the position of child points,
%and constrain them on the surface via loss functions,
%To solve this problem, in this paper, we propose a novel deconvolution network for point cloud data, 
%called Manifold Deconvolution, which explicitly learns the local geometric function
%of each small region and constrains the generate points on surface via a well designed coordinate regression block.
%
%On the other hand, loss function such as EMD requires huge amount of computational time and
%is unacceptable for training.
% To solve this problem, we propose  that
%For point cloud data, each point has its location (x,y,z) and features (rgb,normals).
%Unlike the image space, which
%is represented by a regular grid, point clouds do not have
%any spatial order and regular structure. 
%Besides, the generated points should describe the underlying geometry of a
%latent target object, meaning that they should roughly lie on
%the target object surface.
%To validate the effectiveness of our proposed manifold deconvolution block,
%we apply it into two popular tasks, 
%point cloud upsampling and point cloud completion,
We evaluate our proposed method in both point cloud upsampling and completion tasks on three standard datasets, PU1K, KITTI, and ShapeNet-PCN.
The experiment results demonstrate that by using the proposed surface constrained upsampler,
we can achieve new SOTA results by outperforming previous methods.
%tasks and the generated point clouds preserve better surface structures compared to previous algorithms.
The main contributions of this paper are as follows. 
\begin{enumerate}
\item 
We propose a novel surface-level constraint that uses parametric surfaces as regularizers to ensure the smoothness of the upsampled point clouds. 
%To our knowledge, we are the first to explore manifold reconstruction for the point cloud upsampling tasks and ensure the smoothness of the upsampled point clouds.
% We introduce an interesting thought that modeling the manifold of a point cloud via Bicubic Functions and Rotation Functions to reduce the model space of previous widely used MLPs.
\item We design a new parametric surface constrained upsampler, that estimates the surface parametric functions from input points and generates new points on each surface.
% combines manifold functions into a network to remedy the shortcomings of MLP-based manifold representation.
\item We evaluate the proposed upsampler on both point cloud upsampling and point cloud completion tasks, and our proposed method achieves new SOTA performance. 
%We investigate the benefit of the proposed method by applying it on two different tasks (point cloud upsampling and point cloud completion), and our proposed method achieve new state-of-the-art performance. 
\end{enumerate}


\section{Related Work}
\label{related}
\subsection{Point Cloud Upsampling}
%Point cloud upsampling aims to generate denser point clouds from sparse but complete input point clouds.
%Traditional optimization based upsampling methods \citeauthor{traditional_1,traditional_2,ear,traditional_4,traditional_5} rely on geometric priors and have been outperformed by recent deep learning methods.

%Yu \etal 
\citeauthor{punet} \shortcite{punet} proposed the first deep learning based point cloud upsampling algorithm PU-Net at patch level. For each patch, multilevel features are extracted at each input point and expanded  via a multibranch convolution unit in the feature space. Then, these expanded features are reconstructed for upsampled point cloud via an MLP based coordinate regression block.
%\citeauthor{pugan,pc2pu}
%PC 2 -PU: Patch Correlation and Position Correction for Effective Point Cloud Upsampling
%design the up-feature operator with a self-attention unit
%to produce the enhanced features given concatenated features. 
However, when the upsampling rate is high, \eg $\times 16$, it needs to define multiple branches of convolution layers, which is quite inefficient.
To address this issue, 
%Wang \etal 
\citeauthor{Wang2019PatchBasedP3} \shortcite{Wang2019PatchBasedP3} proposed 3PU, a multistep patch-based method to progressively upsample the points by breaking the upsampling task into multiple $\times 2$ small tasks, each solved by a sub-network that focuses only on a particular level of detail.
Each sub-network has the same structure with the feature extractor unit, feature expansion unit, and an MLP to regress for the point coordinates.
%Especially, the feature extractor unit uses dense connected MLPs to extract feature for each point and the expansion unit expands the features by duplicating and concatenating a $1D$ code (1 or -1) to them.
To consider more spatial information among neighboring points,
%Qian \etal 
\citeauthor{PUGCN} \shortcite{PUGCN} proposed PU-GCN by introducing
a multi-scale Inception DenseGCN feature extractor
%which integrates the densely connected graph convolution network \citeauthor{li2019deepgcns} into the Inception module \citeauthor{Inception} 
to extract the spatial features among nearby points
and another graph convolution network to better encode local point information from its neighbors.
Although PU-GCN achieves the SOTA result by utilizing spatial information, it relies on an MLP-based coordinate regression module which often fails to learn the accurate representation of the surface.

\subsection{Point Cloud Completion}
Point cloud completion can be considered as a more challenging version of upsampling where the input point cloud is sparse and incomplete. It aims to not only upsample the input point cloud but also infer the missing underlying shapes and surfaces \cite{vrpcn,pcn,grnet,snowflakenet,pmp,DeepPCD}. 

%Yuan \etal 
\citeauthor{pcn} \shortcite{pcn} proposed PCN, a novel coarse to fine point cloud completion network under an encoder-decoder framework. It first extracts the global shape code that describes the coarse shape of the input points using a PointNet \cite{pointnet} feature extractor. Then, a coarse but complete point cloud is generated from the global shape code and fed into a folding-based upsampling block to generate the dense point cloud.
However, PCN's feature extractor can not extract sufficient structural information from input point clouds and may not well capture the geometric detail.
To this end, 
%Xie \etal 
\citeauthor{grnet} \shortcite{grnet} proposed GRNet, using 3D grids as intermediate representations to regularize unordered point clouds and 3D convolution networks to explore the structural context and infer the underlying shape of the input point clouds.
However, the resolution of intermediate point clouds is limited by the size of 3D feature maps, making it hard to reveal fine local geometric details. As a result, it still needs additional MLPs to refine and upsample the point clouds.
To preserve more local geometric details, 
%Xiang \etal 
\citeauthor{snowflakenet} \shortcite{snowflakenet} designed SnowFlakeNet. It first extracts the global shape code from input point clouds using PointNet++ \cite{pointnetplusplus} and Point Transformer \cite{point_transformer} blocks, which are fed into a seed generator to generate a course but complete point cloud. The coarse point cloud is then upsampled to a denser one via SnowFlake Point Deconvolution blocks. These blocks consist of 1D deconvolution layers to upsample the points in the feature space and skip-transformers to preserve better structure and shape.
Although SnowFlakeNet achieves the state-of-the-art result on point cloud completion tasks, it still relies on an MLP to regress for the coordinates of each upsampled point without constraining the upsampled points to be on the underlying surfaces accurately.


\section{Parametric Surface Constrained Upsampler}
%We expect our upsampling operator to fulfill the major target: preserving the fine details of the input point cloud $P_i$ and generating child points that locates on object surfaces.
%In this section, we present the design of manifold deconvolution network for the point cloud upsampling task.
% We take point cloud upsampling task as an example. 
%Given an input of sparse point cloud $P_{0}$,
%with coordinates $P_{in} \in R^{N_0 \times 3}$, where $N_0$ is the number of points,
%we aim to output a denser point cloud
%with coordinates $P_{out} \in R^{rN_0 \times 3}$ 
%that preserves fine-detailed geometric structures.
%% define shape code and its usage
Designing an upsampler for point clouds is nontrivial due to the difficulty of inferring accurate underlying surfaces from discrete points and elegantly constraining the upsampled points on these surfaces.
We solve these challenges by forcing the network to predict an explicit representation of the underlying surface via parametric surface functions and then generate points directly on the surface via the predicted parametric functions.
%and introduce the Surface Constrained Upsampling Block.

%To solve this problem, we introduce 3 major parts for Manifold Convolution block aiming at extracting the geometric relationship from inputs, generating the manifold functions, and generating child points on manifolds.
%Then, we will apply parametric surfaces in to the design of surface constrained upsampling block.
%Specifically, MDconv first predicts manifold features from input parent positions and features. 
%Next, these manifold features will be used for generating child features and their corresponding projection functions and transformation functions.
%Then, these projection functions and transformation functions will be used for generating child positions that locate on surfaces.
%Finally, guided by commonly used loss function like Chamfer Distance, MDconv can learn correct features and generate child points with better positions.
%We will describe each step in detail in the following subsections.
\begin{figure}[bt]
	\centering
	\includegraphics[width=0.45\textwidth]{figures/background/manifold.pdf}
	\caption{An example to describe the surface of a small region by the parametric functions. There exist multiple projections and surface functions to express this small region.}
	\label{fig:background}
\end{figure}

\subsection{Parametric Surfaces} 
\label{manifold_background}
%To better illustrate the proposed algorithm,  we first describe the intuition for parametric surfaces.
%Parametric Surfaces represent
%surfaces explicitly as a collection of charts (in an atlas) and works well on fine-grained shapes.
Ideally, given points on the 2D plane X-Y, we can map them into 3D space via an explicit function $\Phi(x,y) \rightarrow (x,y,z)$. However, if the target surface is perpendicular to the X-Y plane, \ie $X = 0$, we cannot calculate the coordinates $z$ for $x \neq 0$, limiting its representation ability. To solve this problem, we use local coordinate systems with rotations to improve the representation ability with better projection planes.
Figure \ref{fig:background} shows an example of local parametric surfaces around the coordinate $(x_0,y_0,z_0)$. 
%there exists a smooth transform that maps these points to the global 3D space X-Y-Z for this small region.
In particular, we define the parametric surface function as 
$ Rot(\phi(u,v))+(x_0,y_0,z_0)$
, where $\phi(u,v) \rightarrow (u,v,w)$ is the surface function that maps
points in 2D projection planes to 3D surfaces on a local coordinate system U-V-W, and
$Rot(u,v,w) \rightarrow (x,y,z)$ is the rotation function with the rotation center $(u=0,v=0,w=0)$
%$Rot(u_0,v_0,w_0) = (x_0,y_0,z_0)$,
to rotate local coordinates into the global X-Y-Z coordinate system.
%To make things simple, we define the transformation function 
%that transform the projection function in charts
%into 
%a fixed based coordinate system xyz in 3D space.
Mathematically, given these two functions, we can generate an arbitrary number of points on the local surface.
Thus, we introduce this idea into the design of the surface constrained upsampler network, \textit{i.e.}, we propose to learn and utilize the surface function $\phi$ and the rotation function $Rot$ to constrain the upsampled points.
%Note that different projection planes are supposed to have different surface and rotation functions.
%In next subsection, we will describe how to formulate and model these two functions for the proposed Manifold Deconvolution. 

\textbf{Explicit Surface Function}
% Apparently, we can generate any number of points that located on 
% a manifold as long as we know the surface function
% $\Phi(u,v)$.
Previous methods used the concatenation-based folding technique to model the surface function via MLPs \cite{foldingnet,pcn,pugeo,luo2020differentiable}.
%$w = f_\theta(u,v, G)$, where $f_\theta$ is
%MLPs, $u, v$ is predefined 2D grids and $G$ is extracted shape code 
However, as mentioned in the introduction,
such methods only learn an overfitted point-point mapping and induce a bottleneck that limits its capacity to represent different 3D surfaces.
Different from these methods,
we propose to use the explicit polynomial function to model the underlying surface, which can be expressed as:
\begin{equation}
w = \phi(u,v) = \sum_{i}\sum_{j}a_{ij} u^i v^{j},
\end{equation}
where $a_{ij}$ is the coefficient predicted via neural networks.
With different combinations of coefficients, we can easily express different shapes.
For simplicity, we use the bicubic function, which is widely used and strong enough to express common shapes, to design our network:
\begin{equation}
   w = \phi(u,v) = a_1 + a_2 u + a_3 u^2 + ... + a_{16} u^3v^3,
\label{eq:pj} 
\end{equation}

\textbf{Rotation Function}
After generating upsampled points on the local surface, 
we need to rotate them from their local coordinate systems into the global coordinate system.
%To obtain the corresponding rotation functions $Rot(u,v,w) \rightarrow x,y,z$,
To achieve this, we model the rotation function as follows:
\begin{equation}
   \begin{pmatrix} x \\ y \\z \end{pmatrix}
= Rot(u,v,w) = \begin{pmatrix} r_1 & r_2 & r_3 \\
r_4 & r_5 & r_6\\ r_7 & r_8 & r_9 \end{pmatrix}
\begin{pmatrix} u \\ v \\w \end{pmatrix},
\label{eq:rot} 
\end{equation}
where $[r_1,...,r_9]$ are the elements of a rotation matrix $R$ predicted by neural networks.
%and $T(u_0,v_0,w_0) = (x_0,y_0,z_0)$. 
To ensure that the rotation matrix follows the correct principle of $R^T*R == R*R^T == I$, we use the 6d representation proposed in \cite{Rotation_Representations}, which shows a good continuous property and can be decoded into a $3 \times 3$ matrix.

\subsection{Network Design}
\label{network_design}

%define parent point - Child Points
However, designing a special network that can predict accurate surface parameters and seamlessly integrate them into the upsampling procedure is challenging.
For convenience, we refer to the input points as parent points and the upsampled points as child points.
Our idea is that each parent point will split and generate multiple child points that lie on the local surface and cover the entire surface as much as possible.
%Although the benefit of parametric representations over implicit neural representations is that the shape can be easily sampled;
%the main shortcoming is that it is very challenging to produce a set of perfectly overlapping charts \citeauthor{Implicit_Geometric_Regularization}.
To achieve this, we design the parametric surface constrained upsampler network that contains 3 major parts: (\romannumeral1) Spatial Feature Extractor, (\romannumeral2) Surface Parameter Estimation, and (\romannumeral3) Child Points Generator, aiming at extracting the local geometric shape from unordered parent points, predicting the explicit surface parameters around each parent point, and generating child points on parametric surfaces, respectively. 
Each of them will be described in detail in the following subsections.
Figure \ref{fig:MDConv} shows the general structure of the proposed upsampling network, and
note that the detailed network structure is provided in the Supplementary.
The proposed upsampler module requires three necessary inputs: parent coordinates $P_{i} \in \mathbf{R}^{N \times 3}$, parent features $F_{i} \in \mathbf{R}^{N \times C_1}$, and the global shape code $G \in \mathbf{R}^{1 \times C_2}$ that encodes the global shape of the input point cloud.
It aims to upsample them $m$ times and generates child points with coordinates $P_{i+1} \in \mathbf{R}^{mN \times 3}$ and features $F_{i+1} \in \mathbf{R}^{mN \times C_1}$.

% \twocolumn[{%
% \renewcommand\twocolumn[1][]{#1}%
% \maketitle
% \begin{center}
%     \centering
%     \captionsetup{type=figure}
%     \includegraphics[width=1\textwidth]{figures/design/Full_Design.pdf}
%     \captionof{figure}{The detailed network structure for parametric surface constrained upsampler.}
%     \label{fig:full_network}
% \end{center}%
% }]

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/design/MDConv_design.pdf}
	\caption{The general structure of the parametric surface constrained upsampler. Note that due to the page limitation, the detailed network structure is in the Supplementary.}
	\label{fig:MDConv}
\end{figure}

\subsubsection{\romannumeral1. Spatial Feature Extractor}

% \begin{figure}
% 	\centering
% 	\includegraphics[width=0.5\textwidth]{figures/design/SFE.pdf}
% 	\caption{Spatial Feature Extractor.}
% 	\label{fig:sfe}
% \end{figure}
Making the network aware of the local geometric information around each parent point
is a key step in predicting accurate shapes. To achieve this, we design a Spatial Feature Extractor (SFE) that can aggregate the positions and features of the parent's $K$ nearby points to extract the local spatial information. 
% as the local geometric relationship of parent features is quite important.
% To do this, we design a Spatial Feature Extractor ($SFE$)
Especially, the SFE extracts the local spatial features $SF_{i} \in \mathbf{R}^{N \times C_1}$ from input parent features $F_{i}$, parent positions $P_{i}$, and global shape code $G$,
which is defined as 
\begin{equation}
SF_{i} = \mathtt{Aggregate}_K(P_{i},\mathtt{NN}_s(F_{i},G)),
\end{equation}
where $\mathtt{Aggregate}_K$ is the point transformer introduced in \cite{point_transformer} to aggregate the context of $K$ nearest points, 
and $\mathtt{NN}_s$ is the neural network used to combine the parent features $F_{i}$ with global shape code $G$.

%To design such extractor, we utilize the well-designed point transformer \cite{point_transformer} to encode the geometric features into output features.
%manifold feature $MF_i$ from input parent features geometric relationship among input parent features, which is  in this case.
\subsubsection{\romannumeral2. Surface Parameter Estimation}

% \begin{figure}
% 	\centering
% 	\includegraphics[width=0.5\textwidth]{figures/design/Manifold_Functions.pdf}
% 	\caption{Manifold Functions Generator.}
% 	\label{fig:manifold_function}
% 
% \end{figure}

Then, to accurately represent the underlying surface around each parent point, we propose to estimate the explicit parameters of the surface function $\phi$ and the rotation function $Rot$ as mentioned before.
% Next, as introduced in \ref{manifold_background}, given local spatial features $SF_{i}$, we aim to generate surface functions $\Phi$ and transformation
% functions $T$ that can describe the small manifold nearby each parent point.
One simple way is to directly predict their parameters from local spatial features $SF_{i}$.
However, $SF_{i}$ only contains the local shape information, and the global smoothness of these local shapes is not guaranteed. 
Thus, we incorporate the global shape code $G$ to smooth them.
Especially, these parameters can be predicted via:
\begin{equation}
    a = \mathtt{NN}_a(G,SF_{i})),
\end{equation}
\begin{equation}
    r = \mathtt{NN}_r(G,SF_{i})),
\end{equation}
where $\mathtt{NN}_a$ and $\mathtt{NN}_r$ are neural networks and $a$ and $r$ are predicted coefficients of the bicubic function and the rotation matrix.
%Besides, as the local surface around each child point can be viewed as
%a refined subsurface of its parent surface, 
%we can add a {skip connection between two modules} to facilitate the training.

%These generated parameters will be used for 
%predicting the projection function and transformation function of each manifold.

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/design/child_point.pdf}
	\caption{The network architecture for generating child points on surface via predicted surface parameters.}
	\label{fig:child_points}
\end{figure}

\subsubsection{\romannumeral3. Generating Child Points on Surface}
Finally, our objective is to generate the child features $F_{i+1}$ and the child positions $P_{i+1}$ on the predicted parametric surface.
Unlike previous methods \cite{snowflakenet,PUGCN,punet}, where
they reconstruct the 3D child coordinates directly from the child features through MLPs, 
we design a network that smoothly integrates the predicted surface parameters into child point generation.
Especially, we first predict the displacement of the child $(\Delta u, \Delta v)$ in the projection plane and then lift them into 3D spaces using predicted parametric functions.
%Besides, with different upsampling factors, our upsampling block should able to generate different number of child features efficiently.

To implement this, we first generate the relative displacement of the child features $D_{i} \in  R^{mN \times C_1}$ \textit{w.r.t} to their parents'
through the 1D deconvolution layer, which can easily generate different numbers of child features by setting different kernel sizes and strides.
%Especially, given local spatial features $SF_{i}$ with dim $[N,C_1]$,
%we can generate multiple child features with dim $[N*upscale, C_2]$.
%Note that when the upsampling ratio $r$ is set to $1$, this means that current parent points are moved to better positions.
The displacement feature $D_{i}$ is used to predict the coordinate displacement of the child $(\Delta u, \Delta v)$ using an MLP. 
Specifically, $(\Delta u, \Delta v) = \mathtt{MLP}(D_{i})$.
Next, based on Equation \eqref{eq:pj}, we can calculate their embedded values [$1$,$\Delta u$,$\Delta u^2 $,...,$\Delta u^3 \Delta v^3$] via a Bicubic Embedding ($\mathtt{BE}$) block and multiply them with predicted bicubic coefficients to generate the coordinate displacement $\Delta{w}$.
%Because the displacement coordinates $(\Delta u, \Delta v, \Delta w)$ is relative to
%their parent manifold planes,
We then transit them into X-Y-Z coordinate system 
via the predicted rotation matrix and get the child displacements
$\Delta P_{i+1} = (\Delta x,\Delta y,\Delta z)$,
which will be added with
their parent positions $P_i$ to obtain the final position of the child points $P_{i+1}$.
Figure \ref{fig:child_points} shows the corresponding network architecture to generate the child position in the parametric surface. 
% Specifically, this process can be expressed as:
% \begin{equation}
%     P_{i+1} = R_i * \mathtt{Concat}((\Delta u, \Delta v), \mathtt{BE}(\Delta u, \Delta v)*C_i) + \mathtt{Dup}(P_i).
% \end{equation}
After obtaining the position of the child points, we feed $D_i$ into another MLP layer and add the output with their parent feature to get the child features $F_{i+1}$.
% , which can be expressed as:
% \begin{equation}
%     F_{i+1} = \mathtt{MLP}(\mathtt{Concat}(\mathtt{Dup}(MF_i),D_{i})) + \mathtt{Dup}(F_{i}).
% \end{equation}


\subsection{Loss Function}
\label{loss}
%By following all previous steps, we can constrain and generate child points on surfaces.
%Note that the inputs of our MDConvolution are parent positions, parent features, global shape code and the manifold features from
%previous MD Layer.
%However, it is not enough to guarantee that the child points are in correct locations and that the generated point cloud is smooth, especially in the conjunction areas of two manifolds.
%The correctness of projection functions and rotation functions are crucial for generating point cloud with smooth and correct shapes. 
%Thus, we need a loss function to make sure our network can learn the correct surface coefficients and rotation matrix.
To train our network, we first use Chamfer Distance as a loss function for each upsampling block, which measures the point-wise distance between the predicted point cloud and ground truth.
%along with PCA Loss to train the network.
%Another commonly used loss function for Point Cloud Reconstruction is Earth Mover's Distance (EMD) loss \citeauthor{FanSG17}. However, calculating the EMD loss is not computational efficient and much time consuming.
%Thus, EMD is not as widely used as CD. Besides, it will be easy for us to compare our MDconv with other CD based methods.
% The chamfer distance is defined as following:
% \begin{align}
% \mathcal L_{\textit{CD}}(S_1,S_2)
% = & \frac{1}{|S_1|}\sum_{x\in S_1} \min_{y \in S_2} ||x-y||^2_2 + \nonumber \\
%   & \frac{1}{|S_2|}\sum_{y\in S_2}\min_{x \in S_1} ||x-y||^2_2,
% \end{align}
% where $S_1$ and $S_2$ are the predicted point sets and ground-truth, respectively.
%Ideally, chamfer distance alone is sufficient to train our network.
However, we notice that given a small area of parametric surface there exist multiple projection planes with different surface functions and rotation functions.
Not all of them can describe this small surface correctly and efficiently.
For example, in Figure \ref{fig:background}, if the projection plane is perpendicular to the surface (parallel to the surface normal), it is difficult to find a good surface parametric function.

% \textit{i.e.}, we hope that child points could spread widely on
% 3D space.
%Besides, we hope that the generated child points could spread widely to cover the entire surface.
%This problem can be relieved by maximizing the distance between upsampled child points 
%and keeping them spreading as wide as possible in the 3D space after rotation.
%Now the problem in front of us is that which chart is better.
%Such However, as we first generate the displacement of child points
%on manifolds, if the chart is not well-selected
% Inspired by PU-Geo \citeauthor{pugeo}, 
% we aim to select a manifold whose projection plane is 
% perpendicular to the normal of each surface/parent point.
% However, as the input and output of our network 
% does not have ground truth normal information,
% we can not apply their method directly.
%Due to the lack of ground truth normal information
Ideally, we aim to select a projection plane that is perpendicular to the normal of each surface/parent point.
As our network does not have ground truth normal information,
we borrow the idea from the unsupervised principal component analysis algorithm \cite{PCA} to select a better projection plane, 
where it aims to find a projection plane that 
can maximize the covariance matrix of $(\Delta u, \Delta v)$, \textit{a.k.a}, minimize the covariance matrix of $\Delta w$ given 3D points in a small region.
Thus, inspired by this we add a constraint to our network by introducing the displacement loss as follows:
\begin{equation}
    \mathcal L_d = ||\Delta w||_2^2. 
\end{equation}
In summary, our final loss function is defined as
$ \mathcal L = \mathcal L_{\textit{CD}} + \lambda \mathcal L_d $,
where $\lambda$ is a hyperparameter that balances the weight of the chamfer loss and the displacement loss.


\section{Experiments}
To validate the effectiveness of the proposed upsampler,
we first evaluate it on the PU1K dataset and conduct ablation studies to verify the effectiveness of our network. We also apply our method to the real collected LiDAR point cloud KITTI dataset \cite{data_kitti}.
Then, we further present the capability of the proposed method on a more challenging point cloud completion task on the ShapeNet-PCN dataset.
% we apply it to two different tasks, point cloud upsampling and point cloud completion,
% on two standard dataset PU1K \citeauthor{PUGCN} and ShapeNet-PCN \citeauthor{pcn}, respectively.
% The experiment results on both datasets
% demonstrate that 
% the generated point cloud is better than previous SOTA methods and 
% preserves better surface structures.
% We will describe these experiments in detail in the
% following subsections.

\subsection{Point Cloud Upsampling} \label{exp:1}

\noindent
\textbf{PU1K:}
The PU1K dataset is first introduced in PU-GCN \cite{PUGCN} for point cloud upsampling. It consists of 1,147 3D models, which are collected from PU-GAN \cite{pugan} and ShapeNet dataset \cite{chang2015shapenet} to cover various shape complexities and diversity.
The input point cloud is sparse but complete with 2,048 points, and the ground truth point cloud is 4 times denser with 8,192 points.
We follow the same train/test splitting strategy in PU-GCN
with 1,020 training samples and 127 testing samples.
Note that unlike previous patch-based methods \cite{PUGCN,MetaPUAA,punet,PUTrans},
our training data are entire point clouds generated from ground truth meshes by poisson disk sampling \cite{poisson_disk}. For testing, we directly use the test data given by PU-GCN for a fair comparison.

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/design/PU1K_network.pdf}
	\caption{Point cloud upsampling with surface constrained upsampler. We can stack multiple upsampling blocks to achieve a higher upsampling ratio.}
	\label{fig:overview}
\end{figure}
\noindent
\textbf{Network Structure:}
Figure \ref{fig:overview} shows the network architecture for the point cloud upsampling task.
To generate the required inputs for the proposed upsampler, we use a feature extractor to capture both point-wise features and global features from sparse points.
Especially, it consists of two parts: a point-wise feature extractor, which is an MLP that 
maps input points into the feature space, and a global feature extractor, which consists of a PointNet++ backbone \cite{pointnetplusplus} with point transformers \cite{point_transformer} to
incorporate both the local and global shape contexts.
The outputs of the feature extractor block are the point-wise features $F_{0}$ and the global shape code $G$.
Note that the design of feature extractor is not the major contribution of this paper and we can exploit any other suitable networks.
We then feed these outputs along with the original position of the points $P_{0}$ into stacks of upsampling blocks to generate denser point clouds.
To upsample the point cloud 4 times,
we arbitrarily set two upsampler blocks with upscale ratios of 1 and 4, respectively. 
Note that other combinations of upscale ratios and the number of upsampler blocks are also feasible. 
%Note that we can arbitrarily set the upscale ratio for each block. 

\noindent
\textbf{Evaluation Metrics:}
We use three widely adopted metrics in previous work to evaluate our performance:
Chamfer Distance (CD), Point-to-Surface Distance (P2F) \textit{w.r.t} ground truth meshes, and Uniformity Score \cite{pugan}.
For these metrics, a smaller value means better performance.

\noindent
\textbf{Training Detail:} 
To train this network, we use 2 Tesla V100 GPUs. 
We set the batch size to 16 and the total epoch number to 150. 
Besides, we use Adam as the optimization function with a learning rate of
0.0005 at the beginning, and we decrease the learning rate by a factor of 0.5 every 50 epochs.

\subsubsection{Experiment Results:}
%\begin{wraptable}{r}{0.7\textwidth}
% \begin{table}
% 	\begin{center}
% 		\caption{Quantitative upsampling results compared to previous SOTA algorithms.}
% 		\label{tab:pu1k}
% 		\begin{tabular}{ccccc}
% 			\hline\noalign{\smallskip}
% 			Methods & PU-Net\citeauthor{punet} & 3PU\citeauthor{Wang2019PatchBasedP3} & PU-GCN\citeauthor{PUGCN}& Ours \\
% 			\noalign{\smallskip}
% 			\hline
% 			\noalign{\smallskip}
% 			CD($\times 10^{-4}$)  & 1.751 & 1.461  & 1.151  & \bf{0.886} \\
% 			P2F($\times 10^{-3}$) & 4.847 & 3.559  & 2.504  & \bf{1.091}\\
% 			\hline
% 		\end{tabular}
% 	\end{center}
% \end{table}
%\end{wraptable}

Table \ref{tab:pu1k} shows the quantitative upsampling results on the PU1K dataset.
We find that our algorithm achieves
the best performance over all its counterparts with large improvements.
In particular, compared to the previous SOTA algorithm, PU-GCN,
the proposed algorithm reduces the average CD from $1.151 \times 10^{-4}$ to $0.886 \times 10^{-4}$.
Besides, the average P2F also reduces more than half from $2.504 \times 10^{-3}$
to $1.091 \times 10^{-3}$, which statically proves that our generated child points preserve better surface shapes and locate closer to the ground truth surfaces.
What's more, the proposed method also obtains better uniformity scores than previous SOTA algorithms.
\begin{figure*}[bt]
	\centering
	\includegraphics[width=0.89\textwidth]{figures/experiment/PU1K.pdf}
	\caption{Visualization of upsampling results with different algorithms (EAR, PU-Net, 3PU, PUGCN, and Ours). We see that our method produces the best results, generating smooth borders and preserving fine-grained local details.}
	\label{fig:pu1k}
\end{figure*}
Next, to intuitively show the performance, we visually check the upsampling outputs of our method
and compare them with the outputs of other algorithms.
Figure \ref{fig:pu1k} shows the visual results of different
algorithms.
We see that our proposed method can produce point clouds with much better shape quality and fewer off-the-surface points.
% For example, in the panda, the point distribution nearby the pandas hand is closer to the ground truth point cloud with a smoother boundary and almost no off-the-surface points compared to others.
% Similar results can be found in other examples.
Apparently, both the quantitative and visual results prove the superiority of the proposed
network.
\begin{table}[bt]
	\centering
 %\fontsize{9}{10}\selectfont
% \resizebox{1.0\columnwidth}{!}{
	\begin{tabular}{p{0.074\textwidth}|p{0.05\textwidth}p{0.05\textwidth}p{0.03\textwidth}p{0.03\textwidth}p{0.03\textwidth}p{0.03\textwidth}p{0.03\textwidth}}
			\hline\noalign{}
    Method & CD  & P2F & \multicolumn{4}{c}{Uniformity $\times (10^{-3}$)}\\
     & ($\times 10^{-4}$) & ($\times 10^{-3}$) &0.4\% & 0.6\% & 0.8\% & 1.0\% \\
     \hline
    EAR & 1.449 & 3.314 &  1.82 & 3.68 & 6.51 & 9.92 \\
    PU-Net & 1.751 & 4.847  & 2.07 & 4.24 & 7.54 & 11.78\\
    3PU & 1.461 & 3.559 &  1.99 & 4.12 & 7.23 & 11.04\\
    PU-GCN & 1.151 & 2.504  & 1.95  &3.97 & 6.83 & 10.63\\
    Ours &\bf{0.886} & \bf{1.091}  &\bf{1.40} & \bf{2.85} & \bf{5.06} & \bf{7.95}\\
    \hline
    \end{tabular}
%    }
  \caption{Quantitative upsampling results compared to previous SOTA algorithms. The uniformity score is estimated in the local area of different percentages of radii.}
  \label{tab:pu1k}
\end{table}

\begin{table}[bt]
	\centering
		\begin{tabular}{c|cc}
		\hline
 			Components & CD ($\times 10^{-4}$)   \\
 			\hline
			w/o Spatial Feature & 1.293 & \\
			w/o Parametric Function & 0.967 \\
			w/o Displacement Loss & 0.893  \\
			%w/o Skip Connection & 0.889 \\
			\hline
			Full & \bf{0.886} \\
			%PSD $*10^{3}$ & 1.139 & 1.139  & 1.139 & 1.139 \\
			\hline
		\end{tabular}
  \caption{Ablation studies of the Parametric Surface Constrained Upsampler on the PU1K dataset.}
  \label{tab:ablation}
\end{table}
%\end{wraptable}

\subsection{Ablation Study} \label{exp:2}
We then perform ablation studies to figure out which part of the proposed upsampling network contributes the most to its performance. Table \ref{tab:ablation} summarizes all experiment results.
%\begin{wraptable}{r}{0.7\textwidth}

\textbf{Spatial Feature:}
Intuitively, the local spatial information is crucial to predict accurate local surfaces.
Thus, we first examine its importance by removing the point transformer in the Spatial Feature Extractor, which is designed to aggregate features of $K$ nearest neighbors for each point. 
In Table \ref{tab:ablation}, we see that after removing the point transformer the performance
drops to $1.239 \times 10^{-4}$ with a huge gap, which justifies our intuition.

\textbf{Parametric Function:}
As we explicitly model the parametric surface via the bicubic function and the rotation function, one might ask about the effectiveness of this explicit representation compared to folding-based MLPs \cite{pcn,msn,foldingnet,pointSA}.
To this end, we substitute the explicit surface function with an MLP-based folding layer that takes the displacement of the child points $(\Delta u, \Delta v)$ as inputs and outputs its global displacement $(\Delta x,\Delta y,\Delta z)$.
%Note that, there is no displacement loss in this case.
In Table \ref{tab:ablation}, we see that after using MLPs to model surface functions, performance decreases and CD increases from $0.886 \times 10^{-4}$ to $0.967 \times 10^{-4}$ with a gap of $0.081 \times 10^{-4}$. 
This gap illustrates the superiority of parametric surface functions in representing better underlying surfaces compared to MLPs.

\textbf{Displacement Loss:}
Since we introduce an additional displacement loss to select a better projection plane,
we then illustrate its effect on training the proposed upsampler by removing this loss.
% To do this, we retrain our network by removing this loss to see the result.
%Table \ref{tab:ablation} shows the quantitative result after removing this loss.
We see that without displacement loss, the performance decreases slightly from $0.886 \times 10^{-4}$ to $0.893 \times 10^{-4}$. 
This slight performance drop fits our intuition because there exist multiple choices for the projection planes, and it contributes the least to the performance of the proposed upsampler.

% \textbf{Skip Connection:}
% Finally, as we introduce skip connections between two consecutive upsampling blocks to facilitate the training, we show the network performance with and without such connections.
% After removing the skip connection, the performance drops slightly.
%\subsection{Robustness Analysis}

\subsubsection{Robustness to Noise}
Another concern might be the performance of the proposed method with noisy inputs.
Therefore, we add a small perturbation to each input point with a Gaussian distribution to synthesize noise, retrain and test the robustness of our method at different noise levels.
Table \ref{tab:noise} and Figure \ref{fig:noise} show the quantitative and visual results at different levels of perturbations.
%\begin{wraptable}{r}{0.5\textwidth}
\begin{table}[bt]
	\centering
		\begin{tabular}{ccccc}
			\hline
			Noise & $0\%$ & $0.5\%$ & $1\%$ & $1.5\%$ \\
			\hline
			CD ($\times 10^{-4}$)  & 0.886 & 1.053  & 1.280 & 1.599 \\
			\hline
		\end{tabular}
  \caption{Performance under different noise perturbations.}
  \label{tab:noise}
\end{table}
%\end{wraptable}
Intuitively with noise points, it becomes more difficult to infer the accurate surfaces.
We see that under a small perturbation such as 0.5\%, our method still achieves a promising result. %However, when the noise level continues to increase, the performance drops quickly.
Even with a 1.5\% perturbation, the upsampled points still tend to preserve a smooth shape with little distortion. 
\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/experiment/noise.pdf}
	\caption{Visualization of upsampling results with different levels of noise. Our method still can preserve good underlying shapes with noisy inputs.}
	\label{fig:noise}
\end{figure}

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/experiment/KITTI.pdf}
	\caption{4 times upsampling result on a real-world point cloud from KITTI dataset.}
	\label{fig:kitti}
\end{figure}
\subsubsection{Result on Real World Data}
Finally, we further show the performance of the proposed method on the real collected point cloud in the KITTI dataset \cite{data_kitti}.
Figure \ref{fig:kitti} shows an example of the upsampling results.
Due to the hardware limitation of the LiDAR sensor, the collected point cloud is naturally sparse and non-uniformly distributed, making the upsampling more challenging.
%Note that there is no ground truth for this dataset.
Our method can generate dense point clouds with better distributions.

\subsection{Point Cloud Completion Task} \label{exp:3}
Then, we test the proposed upsampler on the point cloud completion task using the ShapeNet-PCN dataset.

\noindent
\textbf{ShapeNet-PCN:}
The ShapeNet-PCN dataset is introduced by \cite{pcn}, 
which is derived from ShapeNet \cite{chang2015shapenet}.
It contains pairs of partial and complete point clouds from 30,974 models of 8 categories in total: airplane, cabinet, car, chair, lamp, sofa, table, and watercraft. 
The complete point clouds are created by sampling 16,384 points uniformly from the original meshes, and the partial point clouds are generated by back-projecting 2.5D depth images into 3D. 
For each ground truth, 8 partial point clouds are generated from 8 randomly distributed viewpoints.
For fairness, we follow the same train/test splitting strategy in \cite{pcn,grnet,snowflakenet} with 29,774 training samples and 1,200 testing samples, and resample each incomplete cloud to 2,048 points.

\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/design/ShapeNet_network.pdf}
	\caption{Network architecture for point cloud completion.}
	\label{fig:ShapeNet_network}
\end{figure}
\noindent
\textbf{Network Structure:}
As the point cloud completion task is more challenging,
where the input is a sparse and incomplete point cloud and the output is a dense and complete point cloud, we use a new network to generate complete and denser point clouds.
Figure \ref{fig:ShapeNet_network} shows the detailed network architecture for the point cloud completion task.
Because the input is incomplete, generating a coarse but complete point cloud is
crucial for subsequent upsampling steps.
Inspired by the previous SOTA algorithm SnowFlakeNet \cite{snowflakenet}, 
we adopted the seed generator used in their network to generate a sparse but complete point cloud,
then feed them into three consecutive surface constrained upsamplers with upscale ratios of 1, 4, and 8, respectively, to generate high resolution point clouds.

\noindent
\textbf{Evaluation Metrics:}
For a fair comparison with previous methods, we use two commonly used metrics:
L1 Chamfer Distance (L1-CD) and Earth Mover's Distance (EMD).
Similarly, the smaller the metric, the better the performance.

\noindent
\textbf{Training Detail:} We use 4 Tesla
V100 GPUs with a batch size of 32 and a total epoch number of 500.
Similar to SnowFlakeNet, we use Adam as the optimization function with warm-up settings, where it first takes 200 steps to warm up the learning rate from 0 to 0.0005,
and then the learning rate decays by a factor of 0.5 for every 50 epochs.

% \begin{table}
% 	\begin{center}
% 		\caption{Quantitative completion results compared to previous SOTA algorithms.}
% 		\label{tab:shapenet}
% 		\begin{tabular}{cccccc}
% 			\hline\noalign{\smallskip}
% 			Methods &
%             PCN \citeauthor{pcn} & GR-Net \citeauthor{grnet} & PMP \citeauthor{pmp} & SnowFlake \citeauthor{snowflakenet} & Ours \\
% 			\noalign{\smallskip}
% 			\hline
% 			\noalign{\smallskip}
% 			L1-CD ($\times 10^{-3}$)  & 9.64 & 8.83  & 8.73 &7.191 & \bf{7.044} \\
% 			EMD ($\times 10^{-3}$) & 87.14 & \bf{55.26}  & 109.67 & 69.13 & 66.57 \\
% 			\hline
% 		\end{tabular}
% 	\end{center}
% \end{table}
\begin{table}
	\centering
		\begin{tabular}{cccccc}
			\hline
			Methods & L1-CD ($\times 10^{-3}$) & EMD ($\times 10^{-3}$)\\
			\hline
            PCN  & 9.64 & 87.14\\
            GR-Net  & 8.83 & \bf{55.26}\\
            PMP  & 8.73 & 109.67 \\
            SnowFlake & \underline{7.19} & 69.13\\
            Ours & \bf{7.04} & \underline{66.57}\\
			\hline
		\end{tabular}
  \caption{Quantitative completion results compared to previous SOTA algorithms on the ShapeNet-PCN dataset.}
  \label{tab:shapenet}
\end{table}
\subsubsection{Experiment Results}
%\begin{wraptable}{r}{0.9\textwidth}
Table \ref{tab:shapenet} shows the quantitative completion results on the ShapeNet-PCN dataset.
We notice that our method still achieves the best performance in terms of L1-CD.
As we use the same backbone and upscale settings as SnowflakeNet, which is the previous SOTA algorithm, the improvement over SnowflakeNet can directly prove the effectiveness of our proposed upsampling blocks.
Compared to SnowflakeNet, we see that our network reduces the average L1-CD from $7.19 \times 10^{-3}$ to $7.04 \times 10^{-3}$ 
and the average EMD from $69.13 \times 10^{-3}$ to $66.57 \times 10^{-3}$.
Figure \ref{fig:shapenet} shows one completion result. Note that more completion results can be found in the Supplementary.
Still, we see that our method produces a much better shape quality and fewer outlier points.
\begin{figure}[bt]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/experiment/ShapeNet.pdf}
	\caption{Visualization of completion results with different algorithms (GR-Net, PMP, SnowFlake-Net, and Ours).}
	\label{fig:shapenet}
\end{figure}
% Take the chair as an example, 
% the point distribution nearby the chairs surface is 
% smoother with no off-the-surface points.
% The same conclusion can also
% be drawn from the car and plane, where the front wheel of the plane and left door of the car
%  are similar to the ground truth.

Note that our upsampler is designed based on the assumption that the input points are well-distributed. But for the completion task, this assumption is not met. Even under this challenging condition, the proposed upsampler still works and the generated points are still well-constrained to the underlying surface.
%Both of these evaluation results prove the effectiveness of the proposed parametric surface constrained upsampler network and that our generated child points preserve better on surface properties and shape.


\section{Conclusions}
In this paper, we propose a novel parametric surface constrained upsampler for point clouds. 
By introducing explicit parametric surface functions into the network design, we can obtain better shape representation ability compared to MLPs with point-wise loss and generate point clouds with smoother shapes and fewer outliers.
In addition, the proposed upsampler can also be used in point completion tasks.
The experiment results on both point cloud upsampling and completion tasks prove the effectiveness of our method.

\section{Acknowledgements}
We sincerely thank the Senior Program Committee members and reviewers for their comments and contributions to the community. This work was supported, in part, by NEH PR-284350-22. The GPU used in this work was provided by the NSF MRI-2018966.

\bibliography{aaai23}



% \maketitle
\twocolumn[{%
	\renewcommand\twocolumn[1][]{#1}%
	\maketitle
	\begin{center}
		\centering
		\captionsetup{type=figure}
		\includegraphics[width=1\textwidth]{figures/Full_Design.pdf}
		\captionof{figure}{The detailed network architecture for parametric surface constrained upsampler, with three major components: Spatial Feature Extractor (SFE), Surface Parameter Estimation, and Generate Child Points on Surface.}
		\label{fig:full_network}
	\end{center}%
}]
% \onecolumn
\section{Detailed Network Design and Hyperparameter}
% \begin{figure*}[hbt]
	% \vspace{0mm}
	% 	\centering
	% 	\includegraphics[width=1\textwidth]{figures/Full_Design.pdf}
	% 	\caption{The detailed network structure for parametric surface constrained upsampler.}
	% 	\label{fig:full_network}
	% 	\vspace{-1mm}
	% \end{figure*}
\begin{figure*}[hbt]
	\vspace{0mm}
	\centering
	\includegraphics[width=1\textwidth]{figures/PU1K.pdf}
	\caption{Visualization of upsampling results on the PU1K dataset with different algorithms (EAR (\citeauthor{ear}), PU-Net (\citeauthor{punet}), 3PU (\citeauthor{Wang2019PatchBasedP3}), PUGCN (\citeauthor{PUGCN}), and Ours). Please enlarge the PDF for more details.}
	\label{fig:upsampling}
	\vspace{-1mm}
\end{figure*}
\noindent
Figure \ref{fig:full_network} shows the detailed network architecture of the proposed upsampler with specific dimensions for each intermediate feature map,
where the dimension of the feature maps $C_1$ and $C_2$ are set to 128 and 512 arbitrarily and $N1=m*N$.
Note that other settings are also feasible.
In the spatial feature extractor, we set the number of nearest neighbors $K=16$ for the point transformers (\citeauthor{point_transformer}) to aggregate the context of neighbor points.
In the surface parameter estimation module,
we incorporate the global shape code G to smooth the spatial feature
$SF_i$ via an MLP and generate the smoothed Parametric surface Feature $PF_{i} \in R^{N \times 64}$, which will be used to predict the bicubic coefficients and rotation matrix via MLPs.
In addition, since the local surface around each child point can be viewed as a refined subsurface of its parent surface, we can also add a skip connection between two consecutive upsamplers to facilitate training.

In training, we set the hyperparameter $\lambda$ in the loss function to $1$ to balance the Chamfer Distance Loss and the proposed displacement loss.

\section{More Experiment Results}

\subsection{Point Cloud Upsampling}
We first show more visual results on the point-cloud upsampling task.
Figure \ref{fig:upsampling} illustrates additional upsampling results on the PU1K dataset with a variety of complex objects.
We see that the traditional algorithm EAR (\citeauthor{ear}) fails to preserve the geometric structure of the input point clouds even when the input shape is simple and outperformed by deep learning-based algorithms. 
On the other hand, previous deep learning algorithms fail to constrain the upsampled points and 
tend to generate noisy and outlier points. 
By using the proposed parametric surface constrained upsampler, we can generate much better point clouds with accurate shapes.
For example, in the case of the cup, the upsampled points near the handle are much cleaner than others, with fewer off-the-surface points. 
Similar results can be found in other objects. These visual results further validate the effectiveness of the proposed upsampler in the point cloud upsampling task, 
and the generated child points preserve better underlying surface properties and shape.
% \twocolumn[{%
	% %\begin{figure*}[hbt]
	% %\vspace{0mm}
	% \begin{center}
		%     \captionsetup{type=figure}
		%     \includegraphics[width=1\textwidth]{figures/PU1K.pdf}
		%     \captionof{figure}{Visualization of upsampling results on the PU1K dataset.}
		% 	\label{fig:upsampling}
		% 	\vspace{-1mm}
		% \end{center}
	% %\end{figure*}
	% }]
\begin{table*}[hbt]
	\vspace{-0mm}
	\begin{center}
		\begin{tabular}{c|c|cccccccc}
			\hline\noalign{\smallskip}
			Methods & Average & Plane & Cabinet & Car & Chair & Lamp & Couch & Table & Watercraft \\
			\noalign{\smallskip}
			\hline
			\noalign{\smallskip}
			FoldingNet (\citeauthor{foldingnet}) & 14.31  & 9.49 & 15.80 & 12.61 & 15.55 & 16.41 & 15.97 & 13.65 & 14.99\\
			TopNet (\citeauthor{top_net}) & 12.15 & 7.61 & 13.31 & 10.90 & 13.82 & 14.44 & 14.78 & 11.22 & 11.12 \\
			AtlasNet (\citeauthor{atlas}) & 10.85 & 6.37 & 11.94 & 10.10 & 12.06 &  12.37 & 12.99 & 10.33 & 10.61\\
			PCN (\citeauthor{pcn})  & 9.64 &5.50  & 22.70 &10.63 & 8.70 &11.0 & 11.34&11.68&8.59 \\
			GR-Net (\citeauthor{grnet}) & 8.83 & 6.45  & 10.37 & 9.45 & 9.41 &7.96 &10.51 & 8.44& 8.04 \\
			PMP (\citeauthor{pmp}) & 8.73 & 5.65&11.24&9.64&9.51&6.95&10.83&8.72&7.25\\
			CDN (\citeauthor{CRN}) & 8 .51 & 4.79 &9.97 & 8.31 &9.49 &8.94 &10.69 &7.81 &8.05 \\
			NSFA (\citeauthor{SFA}) & 8.06 & 4.76 & 10.18& 8.63 & 8.53 & 7.03 &10.53 &7.35 &7.48 \\
			SnowFlake (\citeauthor{snowflakenet}) & 7.19&4.24&9.27&8.20&7.75&\textbf{5.96}&9.25&6.45&6.37 \\
			Ours &\textbf{7.04} & \textbf{4.10}&\textbf{9.08}&\textbf{7.94}&\textbf{7.64}&6.07&\textbf{8.96}&\textbf{6.25}&\textbf{6.27}\\
			\hline
		\end{tabular}
		\caption{Point cloud completion results compared to previous algorithms (L1-CD $\times 10^{-3}$).}
		\label{tab:shapenet}
	\end{center}
	\vspace{0mm}
\end{table*}

\begin{figure*}[hbt]
	\vspace{-2mm}
	\centering
	\includegraphics[width=1\textwidth]{figures/ShapeNet.pdf}
	\caption{Visualization of completion results on ShapeNet-PCN dataset with different algorithms. We see that our method can generate points that are closer to the underlying surfaces, preserving better shapes.
		Please enlarge the PDF for more details.}
	\label{fig:completion}
	\vspace{0mm}
\end{figure*}

\subsection{Point Cloud Completion}
We then show more detailed results on the point cloud completion task.
Table \ref{tab:shapenet} shows the quantitative results of the ShapeNet-PCN dataset with detailed performance for each category compared to other methods.
Note that more methods are included and their results are directly cited from SnowFlakeNet (\citeauthor{snowflakenet}).
Compared to the previous SOTA methods,
we see that the proposed method achieves the best performance in 7 categories, showing good generalization ability.
What's more, as we use the same backbone and upscale settings in SnowflakeNet (\citeauthor{snowflakenet}), the improvement over it can directly prove the effectiveness of the proposed upsampler.
Figure \ref{fig:completion} shows more point cloud completion results in the ShapeNet-PCN dataset.
We see that the proposed upsampler can generate much better point clouds with accurate shapes.
Taking the desk as an example, the point distribution near the surface is smoother, with fewer off-the-surface points compared to others. The same observation can also be found in the car and aircraft, where the left door of the car and the front wheel of the aircraft are cleaner and much more similar to the ground truth. 
These evaluation results prove that, even for the challenging completion task, the generated points still preserve better underlying surface properties and shape by using the proposed surface constrained upsampler.

%\bibliography{aaai23}
\end{document}
