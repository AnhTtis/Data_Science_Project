{
    "arxiv_id": "2303.15180",
    "paper_title": "Detecting Backdoors in Pre-trained Encoders",
    "authors": [
        "Shiwei Feng",
        "Guanhong Tao",
        "Siyuan Cheng",
        "Guangyu Shen",
        "Xiangzhe Xu",
        "Yingqi Liu",
        "Kaiyuan Zhang",
        "Shiqing Ma",
        "Xiangyu Zhang"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
    ],
    "abstract": "Self-supervised learning in computer vision trains on unlabeled data, such as images or (image, text) pairs, to obtain an image encoder that learns high-quality embeddings for input data. Emerging backdoor attacks towards encoders expose crucial vulnerabilities of self-supervised learning, since downstream classifiers (even further trained on clean data) may inherit backdoor behaviors from encoders. Existing backdoor detection methods mainly focus on supervised learning settings and cannot handle pre-trained encoders especially when input labels are not available. In this paper, we propose DECREE, the first backdoor detection approach for pre-trained encoders, requiring neither classifier headers nor input labels. We evaluate DECREE on over 400 encoders trojaned under 3 paradigms. We show the effectiveness of our method on image encoders pre-trained on ImageNet and OpenAI's CLIP 400 million image-text pairs. Our method consistently has a high detection accuracy even if we have only limited or no access to the pre-training dataset.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15180v1"
    ],
    "publication_venue": "Accepted at CVPR 2023. Code is available at https://github.com/GiantSeaweed/DECREE"
}