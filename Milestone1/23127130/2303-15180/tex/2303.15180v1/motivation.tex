\input{tables/empirical_study}
\section{Limitations of Existing Backdoor Scanners}
\label{sec:motivation}

To identify whether an encoder is trojaned or not, the defender can leverage existing backdoor scanners (e.g., Neural Cleanse (NC)~\cite{wang2019neural} and ABS~\cite{liu2019abs}) to check downstream classifiers that utilize the encoder, without the need to directly scan the encoder. However, this strategy has its limitations as later shown in the section.
Another type of backdoor scanners such as MNTD~\cite{Xu2021MNTD} leverage a meta-classifier to distinguish benign and backdoored models. They first train thousands of benign and backdoored models and then train a meta-classifier on the extracted signatures of these models. Such a design in SSL setting may not be that practical due to its high cost.
For example, creating a backdoored encoder by contrastive learning takes 48 hours~\cite{carlini2022poisoning}. MNTD requires constructing 2048 benign and 2048 trojaned encoders. 


To explain the limitations of scanning downstream classifiers, we consider two application scenarios: linear probe and zero-shot prediction.

\noindent \underline{\textit{Scenario I: Linear Probe.}} 
We construct a backdoored encoder pre-trained on CIFAR10~\cite{krizhevsky2009cifar10learning} and take an image of label \textit{one} in dataset SVHN~\cite{netzer2011reading} as the attack target. The encoder is also used to train another two downstream classifiers on STL-10~\cite{coates2011analysis} and GTSRB~\cite{Houben-IJCNN-2013}, respectively. We apply NC and ABS on the three downstream classifiers and the results are shown in Table~\ref{tab:empirical_study}.
Since the attack target is in SVHN chosen by the attacker (when trojaning the encoder), the ASR is 100\% on SVHN.

In this case, existing backdoor scanners can successfully detect the trojaned classifier and hence the backdoored encoder, with  the Anomaly Index $2.18 > 2$ in NC and the REASR $1.00 > 0.88$ in ABS. 
However, when the downstream classifiers' training datasets (STL-10 and GTSRB) do not contain the attack target, both NC and ABS fail to detect the backdoor in the encoder as shown in the last two rows.
This has two implications for existing backdoor scanners: (1) they have to possess the knowledge of the attack target and the corresponding downstream task, which is not easy to acquire as there exist a large number of different downstream tasks (for an encoder). (2) They have to obtain the original training dataset of the downstream task to construct the classifier for detection, which may be private.

\smallskip
\noindent \underline{\textit{Scenario II: Zero-shot prediction.}} To predict the caption for an input image, zero-shot classifier directly computes similarities between the image's embedding and every text embedding of candidate captions, and selects the caption that shares the most similar embedding with the input image. In this scenario, it is evident that existing backdoor scanners are not applicable as there is no classifier to scan, as shown in Figure.~\ref{fig:attack_and_application}. This calls for a backdoor detection method that can handle attacks in the embedding space.


