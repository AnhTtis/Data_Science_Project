In this work, we present the simple yet effective Graph Attentive Vectors (GAV) link prediction framework. GAV relies on the idea of modeling simplified physical flow in spatial networks by updating vector embeddings in a constrained manner.
GAV achieves 97.99 to 99.44 AUC on the link prediction task, outperforming the previous state-of-the-art by an impressive margin on all metrics across multiple whole-brain vessel and road network datasets while requiring a significantly smaller amount of trainable parameters. This indicates the importance of developing link prediction algorithms tailored to flow-driven spatial networks.
%of developing link prediction approaches adopting considerations of known functional properties, such as physical flow., defined by the structural properties of the network.
GAV's imitation of the dynamics of physical flow represents a simplified concept, which is not entirely representative of physical principles from, \eg, fluid dynamics (see Fig.~\ref{fig:inter}). Future work should, therefore, aim to extend GAV's simplistic assumptions by incorporating different physical principles, such as conservation of mass and momentum, resulting in vector embeddings highly representative of physical flow in flow-driven spatial networks.
% to recover directionality lost in generation process.

% \paragraph{Limitations}
% one key limitation in our framework is that our flow-inspired embedding only considers the directional vector between nodes. It does not consider the actual flow-trajectory which can be quite different. E.g a vessel connecting two bifurcation points can have a large curvature. This motivates future work blablabla 

% We would like to particularly highlight GAV's limitations in this section. 

% more challenging benchmarks
% spatial networks are underexplored, since most graph networks dont contain spatial coordinates

% future work: experiment with pseudo-spatial networks by experimenting with energy-based layout functions (spring layout), try to make use of more hops in a more advanced manner; ensure that directionality is consistent across whole brain; make use of this direction info for downstream tasks (AV cls, prior for flow simulations); more advanced spatial network-specific labeling tricks; use directionality for mpn-layers