%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "Gerry Murray",
%%%     version         = "1.2",
%%%     date            = "2 April 2012",
%%%     filename        = "acmsmall-sample-bibfile.bib",
%%%     address         = "ACM, NY",
%%%     email           = "murray at hq.acm.org",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "ACM Reference Format, bibliography, citation, references",
%%%     supported       = "yes",
%%%     docstring       = "This BibTeX database file contains 'bibdata' entries
%%%                        that 'match' the examples provided in the Specifications Document
%%%                        AND, also, 'legacy'-type bibs. It should assist authors in
%%%                        choosing the 'correct' at-bibtype and necessary bib-fields
%%%                        so as to obtain the appropriate ACM Reference Format output.
%%%                        It also contains many 'Standard Abbreviations'. "
%%%  }
%%% ====================================================================

% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }


 @inproceedings{kim2020learning,
  title={Learning to simulate dynamic environments with gamegan},
  author={Kim, Seung Wook and Zhou, Yuhao and Philion, Jonah and Torralba, Antonio and Fidler, Sanja},
  booktitle=CVPR,
  pages={1231--1240},
  year={2020}
}

@inproceedings{kim2021drivegan,
  title={DriveGAN: Towards a Controllable High-Quality Neural Simulation},
  author={Kim, Seung Wook and Philion, Jonah and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5820--5829},
  year={2021}
}


@inproceedings{tian2021good,
  title={A good image generator is what you need for high-resolution video synthesis},
  author={Tian, Yu and Ren, Jian and Chai, Menglei and Olszewski, Kyle and Peng, Xi and Metaxas, Dimitris N and Tulyakov, Sergey},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {234--778},
year = 2005
}


@article{carlucci2018agnostic,
  title={Agnostic Domain Generalization},
  author={Carlucci, Fabio M and Russo, Paolo and Tommasi, Tatiana and Caputo, Barbara},
  journal={arXiv preprint arXiv:1808.01102},
  year={2018}
}

@inproceedings{morerio2017minimal,
title={Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation},
author={Pietro Morerio and Jacopo Cavazza and Vittorio Murino},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018}
}

@inproceedings{carlucci2019domain,
  title={Domain Generalization by Solving Jigsaw Puzzles},
  author={Carlucci, Fabio M and D'Innocente, Antonio and Bucci, Silvia and Caputo, Barbara and Tommasi, Tatiana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2229--2238},
  year={2019}
}

@inproceedings{roy2019unsupervised,
  title={Unsupervised Domain Adaptation using Feature-Whitening and Consensus Loss},
author={Roy, Subhankar and Siarohin, Aliaksandr and Sangineto, Enver and Bulo, Samuel Rota and Sebe, Nicu and Ricci, Elisa},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2019},
pages={9463-9472},
volume={}
}


@inproceedings{LOAD_ICRA,
  author    = {Gabriele Angeletti and
               Barbara Caputo and
               Tatiana Tommasi},
  title     = {Adaptive Deep Learning through Visual Domain Localization},
  booktitle   = {ICRA},
  year      = {2018}
}

@inproceedings{li2017deeper,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={5542--5550},
  year={2017}
}

@inproceedings{xu2018deep,
  author    = {Ruijia Xu and
               Ziliang Chen and
               Wangmeng Zuo and
               Junjie Yan and
               Liang Lin},
  title     = {Deep Cocktail Network: Multi-source Unsupervised Domain Adaptation
               with Category Shift},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  pages={3964-3973},
  volume={}
}

@inproceedings{MDAN_ICLRW18,
  author    = {Han Zhao and
               Shanghang Zhang and
               Guanhang Wu and
               Jo{\~{a}}o P. Costeira and
               Jos{\'{e}} M. F. Moura and
               Geoffrey J. Gordon},
  title     = {Multiple Source Domain Adaptation with Adversarial Learning},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
  year      = {2018},
  crossref  = {DBLP:conf/iclr/2018w},
  timestamp = {Thu, 04 Apr 2019 13:20:09 +0200}
}

@proceedings{DBLP:conf/iclr/2018w,
  title     = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  timestamp = {Thu, 04 Apr 2019 13:20:09 +0200}
}

@inproceedings{hoffman2017cycada,
  title = 	 {{C}y{CADA}: Cycle-Consistent Adversarial Domain Adaptation},
author = 	 {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
pages = 	 {1989--1998},
year = 	 {2018},
volume = 	 {80},
series = 	 {Proceedings of Machine Learning Research},
month = 	 {10--15 Jul},
publisher = 	 {PMLR},
abstract = 	 {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun},
  booktitle={Workshop on Challenges in Representation Learning, International Conference on Machine Learning},
  volume={3},
  pages={2},
  year={2013}
}

@InProceedings{chatfield2014return,
  author       = "Chatfield, K. and Simonyan, K. and Vedaldi, A. and Zisserman, A.",
  title        = "Return of the Devil in the Details: Delving Deep into Convolutional Nets",
  booktitle    = "British Machine Vision Conference",
  year         = "2014",
}

@inproceedings{venkateswara2017deep,
  title={Deep hashing network for unsupervised domain adaptation},
  author={Venkateswara, Hemanth and Eusebio, Jose and Chakraborty, Shayok and Panchanathan, Sethuraman},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5018--5027},
  year={2017}
}

@techreport{zhu2005semi,
  title={Semi-supervised learning literature survey},
  author={Zhu, Xiaojin Jerry},
  year={2005},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@article{Taigman2016UnsupervisedCI,
  title={Unsupervised Cross-Domain Image Generation},
  author={Yaniv Taigman and Adam Polyak and Lior Wolf},
  journal={International Conference on Learning Representations (ICLR)},
  year={2017},
}

@inproceedings{Shrivastava:arXiv:16,
  title={Learning from simulated and unsupervised images through adversarial training},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2107--2116},
  year={2017}
}

@inproceedings{Goodfellow:GAN:NIPS2014,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={2672--2680},
  year={2014}
}

@inproceedings{Bousmalis:Google:CVPR17,
  title = {Unsupervised Pixel-level Domain Adaptation with GANs},
  author  = {Konstantinos Bousmalis and Nathan Silberman and David Dohan and Dumitru Erhan and Dilip Krishnan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
}

@inproceedings{ADDA,
  author    = {Eric Tzeng and
               Judy Hoffman and
               Kate Saenko and
               Trevor Darrell},
  title     = {Adversarial Discriminative Domain Adaptation},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2017},
  pages={2962-2971},
  volume={}
}

@inproceedings{chu2013selective,
  author={W. {Chu} and F. {De la Torre} and J. F. {Cohn}},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Selective Transfer Machine for Personalized Facial Action Unit Detection}, 
year={2013},
volume={},
number={},
pages={3515-3522},}


@inproceedings{huang2006correcting,
  title={Correcting sample selection bias by unlabeled data},
  author={Huang, Jiayuan and Gretton, Arthur and Borgwardt, Karsten M and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2006}
}

@inproceedings{yamada2012no,
  title={No bias left behind: Covariate shift adaptation for discriminative 3d pose estimation},
  author={Yamada, Makoto and Sigal, Leonid and Raptis, Michalis},
  booktitle={European Conference on Computer Vision},
  pages={674--687},
  year={2012},
  organization={Springer}
}

@inproceedings{zeng2014deep,
  title={Deep learning of scene-specific classifier for pedestrian detection},
  author={Zeng, Xingyu and Ouyang, Wanli and Wang, Meng and Wang, Xiaogang},
  booktitle={European Conference on Computer Vision},
  year={2014}
}

@inproceedings{gong2013connecting,
  title={Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation},
  author={Gong, Boqing and Grauman, Kristen and Sha, Fei},
  booktitle={International Conference on Machine Learning},
  pages={222--230},
  year={2013}
}


@inproceedings{long2013transfer,
  title={Transfer sparse coding for robust image representation},
  author={Long, Mingsheng and Ding, Guiguang and Wang, Jianmin and Sun, Jiaguang and Guo, Yuchen and Yu, Philip S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2013}
}

@article{tzeng2014deep,
  title={Deep domain confusion: Maximizing for domain invariance},
  author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1412.3474},
  year={2014}
}

@inproceedings{tzeng2015simultaneous,
  title={Simultaneous deep transfer across domains and tasks},
  author={Tzeng, Eric and Hoffman, Judy and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={4068-4076},
  volume={}
}


@inproceedings{ganin2014unsupervised,
author = {Ganin, Yaroslav and Lempitsky, Victor},
title = {Unsupervised Domain Adaptation by Backpropagation},
year = {2015},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning (ICML) - Volume 37},
pages = {1180–1189},
numpages = {10}
}

@article{long2016unsupervised,
  title={Unsupervised Domain Adaptation with Residual Transfer Networks},
  author={Long, Mingsheng and Wang, Jianmin and Jordan, Michael I},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016}
}

@inproceedings{li2016revisiting,
  author    = {Yanghao Li and
               Naiyan Wang and
               Jianping Shi and
               Jiaying Liu and
               Xiaodi Hou},
  title     = {Revisiting Batch Normalization For Practical Domain Adaptation},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2017},
  crossref  = {DBLP:conf/iclr/2017w},
  timestamp = {Thu, 04 Apr 2019 13:20:08 +0200}
}
@proceedings{DBLP:conf/iclr/2017w,
  title     = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Workshop Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  timestamp = {Thu, 04 Apr 2019 13:20:08 +0200}
}

@ARTICLE{oneill1978normal,
    author = {O'Neill, T.~J.},
    title = {Normal discrimination with unclassified observations},
    journal = {Jounral of the American Statistical Association},
    year = {1978},
    pages={821--826},
    volume={73},
    number={364}
}

@inproceedings{sun2016deep,
  title={Deep coral: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  pages={443--450},
  year={2016},
}

@inproceedings{ioffe2015batch,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={448--456},
  year={2015}
}

@inproceedings{donahue2014decaf,
  title={DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition.},
  author={Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
  booktitle={International Conference on Machine Learning},
  year={2014}
}


@ARTICLE{ben2010atheory,
    author = {Ben-David, S. and Blitzer, J. and Crammer, K. and Kulesza, A. and Pereira, F. and Vaughan, J.~W.},
    title = {A theory of learning from different domains},
    journal = {Machine Learning Journal},
    year = {2010},
    pages={151--175},
    volume={79},
    number={1--2}
}


@inproceedings{ben2010impossibility,
  author = {Ben-David, Shai and Lu, Tyler and Luu, Teresa and Pál, Dávid},
  booktitle = {AISTATS},
  title = {Impossibility Theorems for Domain Adaptation.},
  year = 2010
}


@inproceedings{tommasi2016learning,
  author    = {Tatiana Tommasi and
               Martina Lanzi and
               Paolo Russo and
               Barbara Caputo},
  title     = {Learning the Roots of Visual Domain Shift},
  booktitle = {Computer Vision - {European Conference on Computer Vision} 2016 Workshops - Amsterdam, The Netherlands,
               October 8-10 and 15-16, 2016, Proceedings, Part {III}},
  pages     = {475--482},
  year      = {2016},
  crossref  = {DBLP:conf/eccv/2016w3},
  timestamp = {Sun, 02 Jun 2019 21:17:49 +0200}
}
@proceedings{DBLP:conf/eccv/2016w3,
  editor    = {Gang Hua and
               Herv{\'{e}} J{\'{e}}gou},
  title     = {Computer Vision - {ECCV} 2016 Workshops - Amsterdam, The Netherlands,
               October 8-10 and 15-16, 2016, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9915},
  year      = {2016},
  isbn      = {978-3-319-49408-1},
  timestamp = {Sun, 02 Jun 2019 21:17:49 +0200}
}

@inproceedings{tommasi2014testbed,
  title={A testbed for cross-dataset analysis},
  author={Tommasi, Tatiana and Tuytelaars, Tinne},
  booktitle={European Conference on Computer Vision},
  year={2014}
}

@inproceedings{sun2016return,
  title={Return of Frustratingly Easy Domain Adaptation},
  author={Sun, Baochen and Feng, Jiashi and Saenko, Kate},
  booktitle={AAAI},
  year={2016}
}

@inproceedings{gong2012geodesic,
  title={Geodesic flow kernel for unsupervised domain adaptation},
  author={Gong, Boqing and Shi, Yuan and Sha, Fei and Grauman, Kristen},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2012}
}

@inproceedings{fernando2013unsupervised,
  title={Unsupervised visual domain adaptation using subspace alignment},
  author={Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  year={2013}
}

@inproceedings{russo17sbadagan,
  title={From source to target and back: symmetric bi-directional adaptive GAN},
  author={Russo, Paolo and Carlucci, Fabio Maria and Tommasi, Tatiana and Caputo, Barbara},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@inproceedings{pan2011domain,
  title={Domain adaptation via transfer component analysis},
  author={Pan, Sinno Jialin and Tsang, Ivor W and Kwok, James T and Yang, Qiang},
  journal={IEEE Transactions on Neural Networks},
  volume={22},
  number={2},
  pages={199--210},
  year={2011}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1097--1105},
  year={2012}
}

@inproceedings{saenko2010adapting,
author="Saenko, Kate
and Kulis, Brian
and Fritz, Mario
and Darrell, Trevor",

title="Adapting Visual Category Models to New Domains",
booktitle="Proceedings of the European Conference of Computer Vision (ECCV)",
year="2010",

pages="213--226",
abstract="Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions.",
isbn="978-3-642-15561-1"
}

@article{griffin2007caltech,
  title={Caltech-256 object category dataset},
  author={Griffin, Gregory and Holub, Alex and Perona, Pietro},
  year={2007},
  publisher={Technical report, California Institute of Technology}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2009}
}

@inproceedings{grandvalet2004semisupervised,
  author    = {Grandvalet, Y. and
               Bengio, Y.},
  title     = {Semi-supervised Learning by Entropy Minimization},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2004},
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@inproceedings{jia2014caffe,
  title={Caffe: Convolutional architecture for fast feature embedding},
  author={Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  pages={675--678},
  year={2014},
  organization={ACM}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={770--778},
  year={2016}
}

@inproceedings{long2017deep,
  title={Deep transfer learning with joint adaptation networks},
  author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
  booktitle={Proceedings of the 34th International Conference on Machine Learning (ICML) - Volume 70},
  pages={2208--2217},
  year={2017}
}

@inproceedings{ghifary2016deep,
  title={Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation},
  author={Ghifary, Muhammad and Kleijn, W Bastiaan and Zhang, Mengjie and Balduzzi, David and Li, Wen},
  booktitle={European Conference on Computer Vision},
  year={2016}
}

@InProceedings{haeusser17,
  author = 	 "P. Haeusser and T. Frerix and A. Mordvintsev and D. Cremers",
  title = 	 "Associative Domain Adaptation",
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  year = 	 "2017"
}

@incollection{TRUDA-NIPS16_savarese,
title = {Learning Transferrable Representations for Unsupervised Domain Adaptation},
author = {Sener, Ozan and Song, Hyun Oh and Saxena, Ashutosh and Savarese, Silvio},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{sankaranarayanan2017generate,
title={Generate to Adapt: Aligning Domains Using Generative Adversarial Networks},
author={Swami Sankaranarayanan and Yogesh Balaji and Carlos D. Castillo and Rama Chellappa},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2018},
pages={8503-8512}
}

@inproceedings{bousmalis2016domain,
  title={Domain separation networks},
  author={Bousmalis, Konstantinos and Trigeorgis, George and Silberman, Nathan and Krishnan, Dilip and Erhan, Dumitru},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2014}
}

@inproceedings{aljundi2016lightweight,
  author    = {Rahaf Aljundi and
               Tinne Tuytelaars},
  title     = {Lightweight Unsupervised Domain Adaptation by Convolutional Filter
               Reconstruction},
  booktitle = {Computer Vision - {European Conference on Computer Vision} 2016 Workshop - Amsterdam, The Netherlands,
               October 8-10 and 15-16, 2016, Proceedings, Part {III}},
  pages     = {508--515},
  year      = {2016},
  crossref  = {DBLP:conf/eccv/2016w3},
  timestamp = {Sun, 02 Jun 2019 21:17:49 +0200}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={59},
  pages={1--35},
  year={2016}
}

@inproceedings{saito2017asymmetric,
  title={Asymmetric tri-training for unsupervised domain adaptation},
  author={Saito, Kuniaki and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2988--2997},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems workshop on deep learning and unsupervised feature learning},
  pages={5},
  year={2011}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@inproceedings{carlucci2017just,
author="Carlucci, Fabio Maria
and Porzi, Lorenzo
and Caputo, Barbara
and Ricci, Elisa
and Bul{\`o}, Samuel Rota",

title="Just DIAL: DomaIn Alignment Layers for Unsupervised Domain Adaptation",
booktitle="Image Analysis and Processing - International Conference on 
Image Analysis And Processing (ICIAP) 2017          ",
year="2017",
pages="357--369",
abstract="The empirical fact that classifiers, trained on given data collections, perform poorly when tested on data acquired in different settings is theoretically explained in domain adaptation through a shift among distributions of the source and target domains. Alleviating the domain shift problem, especially in the challenging setting where no labeled data are available for the target domain, is paramount for having visual recognition systems working in the wild. As the problem stems from a shift among distributions, intuitively one should try to align them. In the literature, this has resulted in a stream of works attempting to align the feature representations learned from the source and target domains by introducing appropriate regularization terms in the objective function. In this work we propose a different strategy and we act directly at the distribution level by introducing DomaIn Alignment Layers (DIAL) which reduce the domain shift by matching the source and target feature distributions to a canonical one. Our experimental evaluation, conducted on a widely used public benchmark, demonstrates the advantages of the proposed domain adaptation strategy.",
isbn="978-3-319-68560-1"
}


@inproceedings{costante2013transfer,
  title={A transfer learning approach for multi-cue semantic place recognition},
  author={Costante, Gabriele and Ciarfuglia, Thomas A and Valigi, Paolo and Ricci, Elisa},
  booktitle={IROS},
  year={2013}
}

@article{rozantsev2018beyond,
  title={Beyond sharing weights for deep domain adaptation},
  author={Rozantsev, Artem and Salzmann, Mathieu and Fua, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={4},
  pages={801--814},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ren2016normalizing,
  author    = {Mengye Ren and
               Renjie Liao and
               Raquel Urtasun and
               Fabian H. Sinz and
               Richard S. Zemel},
  title     = {Normalizing the Normalizers: Comparing and Extending Network Normalization
               Schemes},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2017},
  crossref  = {DBLP:conf/iclr/2017},
  timestamp = {Thu, 04 Apr 2019 13:20:08 +0200}
}

@proceedings{DBLP:conf/iclr/2017,
  title     = {International Conference on Learning Representations (ICLR)},
  publisher = {OpenReview.net},
  year      = {2017},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200}
}

@inproceedings{mancini2018boosting,
  title={Boosting domain adaptation by discovering latent domains},
  author={Mancini, Massimiliano and Porzi, Lorenzo and Rota Bul{\`o}, Samuel and Caputo, Barbara and Ricci, Elisa},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3771--3780},
  year={2018}
}

@inproceedings{mancini2018kitting,
	author = {Mancini, Massimilano and Karaoguz, Hakan and Ricci, Elisa and Jensfelt, Patric and Caputo, Barbara},
	title  = {Kitting in the Wild through Online Domain Adaptation},
	booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	year      = {2018},
	month     = {October}
}

@inproceedings{carlucci2017autodial,
  title={AutoDIAL: Automatic Domain Alignment Layers.},
  author={Carlucci, Fabio Maria and Porzi, Lorenzo and Caputo, Barbara and Ricci, Elisa and Bul{\`o}, Samuel Rota},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={5077--5085},
  year={2017}
}

@inproceedings{gopalan2011domain,
  title={Domain adaptation for object recognition: An unsupervised approach},
  author={Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2011}
}

@article{xie2015learning,
  title={Learning sparse frame models for natural image patterns},
  author={Xie, Jianwen and Hu, Wenze and Zhu, Song-Chun and Wu, Ying Nian},
  journal={IJCV},
  volume={114},
  number={2-3},
  pages={91--112},
  year={2015},
  publisher={Springer}
}

@inproceedings{lucic2018gans,
  title={Are gans created equal? a large-scale study},
  author={Lucic, Mario and Kurach, Karol and Michalski, Marcin and Gelly, Sylvain and Bousquet, Olivier},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={700--709},
  year={2018}
}

@article{wang2019generative,
  title={Generative Adversarial Networks: A Survey and Taxonomy},
  author={Wang, Zhengwei and She, Qi and Ward, Tomas E},
  journal={arXiv preprint arXiv:1906.01529},
  year={2019}
}

@book{csurka2017domain,
  title={Domain adaptation in computer vision applications},
  author={Csurka, Gabriela},
  volume={2},
  year={2017},
  publisher={Springer}
}

@inproceedings{DBLP:conf/iclr/BrockDS19,
  author    = {Andrew Brock and
               Jeff Donahue and
               Karen Simonyan},
  title     = {Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2019},
  crossref  = {DBLP:conf/iclr/2019},
  timestamp = {Thu, 25 Jul 2019 13:03:18 +0200}
}

@proceedings{DBLP:conf/iclr/2019,
  title     = {International Conference on Learning Representations (ICLR)},
  publisher = {OpenReview.net},
  year      = {2019},
  timestamp = {Thu, 25 Jul 2019 13:03:15 +0200}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{DBLP:journals/corr/abs-1807-05520,
author="Caron, Mathilde
and Bojanowski, Piotr
and Joulin, Armand
and Douze, Matthijs",

title="Deep Clustering for Unsupervised Learning of Visual Features",
booktitle="Proceedings of the European Conference of Computer Vision (ECCV)",
year="2018",
pages="139--156",
abstract="Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large-scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks.",
isbn="978-3-030-01264-9"
}


@article{DBLP:journals/corr/abs-1807-06653,
	title={Invariant Information Clustering for Unsupervised Image Classification and Segmentation},
	author={Xu Ji and Andrea Vedaldi and Jo{\~a}o F. Henriques},
	journal={In Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
	year={2019},
	pages={9864-9873}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{long2015learning,
    author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
    title = {Learning Transferable Features with Deep Adaptation Networks},
    year = {2015},
    
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning (ICML) - Volume 37},
    pages = {97–105},
    numpages = {9},
}



@inproceedings{peng2018synthetic,
  author={X. {Peng} and K. {Saenko}},
booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
title={Synthetic to Real Adaptation with Generative Correlation Alignment Networks}, 
year={2018},
volume={},
number={},
pages={1982-1991},}


@inproceedings{liu2016coupled,
  title={Coupled generative adversarial networks},
  author={Liu, Ming-Yu and Tuzel, Oncel},
  booktitle={NIPS},
  year={2016}
}

@inproceedings{sankaranarayanan2018generate,
  title={Generate to adapt: Aligning domains using generative adversarial networks},
  author={Sankaranarayanan, Swami and Balaji, Yogesh and Castillo, Carlos D and Chellappa, Rama},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{yao2010boosting,
  title={Boosting for transfer learning with multiple sources},
  author={Yao, Yi and Doretto, Gianfranco},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2010}
}



@article{peng2018moment,
author = {Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
title = {Moment Matching for Multi-Source Domain Adaptation},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019},
pages={1406--1415},
volume={}
}

@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{choi2018stargan,
  title={Stargan: Unified generative adversarial networks for multi-domain image-to-image translation},
  author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{murez2018image,
author = {Murez, Zak and Kolouri, Soheil and Kriegman, David and Ramamoorthi, Ravi and Kim, Kyungnam},
title = {Image to Image Translation for Domain Adaptation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2018},
volume={},
number={},
pages={4500-4509}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={AAAI},
  year={2018}
}

@inproceedings{huang2018multimodal,
  title={Multimodal unsupervised image-to-image translation},
  author={Huang, Xun and Liu, Ming-Yu and Belongie, Serge and Kautz, Jan},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2018}
}

@inproceedings{anoosheh2018combogan,
  title={Combogan: Unrestrained scalability for image domain translation},
  author={Anoosheh, Asha and Agustsson, Eirikur and Timofte, Radu and Van Gool, Luc},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}


@ARTICLE{mancini2018robust,
author={M. Mancini and S. Rota Bul{\`o} and B. Caputo and E. Ricci},
journal={IEEE Robotics and Automation Letters},
title={Robust Place Categorization With Deep Domain Generalization},
year={2018},
volume={3},
number={3},
pages={2093-2100},
ISSN={},
month={July},}




@inproceedings{WenLi:ECCV2016,
author="Ghifary, Muhammad
and Kleijn, W. Bastiaan
and Zhang, Mengjie
and Balduzzi, David
and Li, Wen",
booktitle = {Proceedings of the European Conference of Computer Vision (ECCV)},
title="Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation",
year="2016"
}

@incollection{TRUDA-NIPS16_savarese,
title = {Learning Transferrable Representations for Unsupervised Domain Adaptation},
author = {Sener, Ozan and Song, Hyun Oh and Saxena, Ashutosh and Savarese, Silvio},
booktitle = {NIPS},
year = {2016},
}

@InProceedings{haeusser17,
  author = 	 "P. Haeusser and T. Frerix and A. Mordvintsev and D. Cremers",
  title = 	 "Associative Domain Adaptation",
  booktitle={ICCV},
  year = 	 "2017"
}

@inproceedings{sankaranarayanan2017generate,
  title={Generate To Adapt: Aligning Domains using Generative Adversarial Networks},
  author={Sankaranarayanan, Swami and Balaji, Yogesh and Castillo, Carlos D and Chellappa, Rama},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2018},
}


@inproceedings{MLDG_AAA18,
  author    = {Da Li and
               Yongxin Yang and
               Yi{-}Zhe Song and
               Timothy M. Hospedales},
  title     = {Learning to Generalize: Meta-Learning for Domain Generalization},
  booktitle = {Conference of the Association for the Advancement of Artificial Intelligence (AAAI)},
  year      = {2018}
}

% MULTISOURCE PRACTICE %%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Crammer_JMLR08,
 author = {Crammer, Koby and Kearns, Michael and Wortman, Jennifer},
 title = {Learning from Multiple Sources},
 journal = {JMLR},
 year = {2008}
} 




@inproceedings{LongZ0J17,
  author    = {Mingsheng Long and
               Han Zhu and
               Jianmin Wang and
               Michael I. Jordan},
  title     = {Deep Transfer Learning with Joint Adaptation Networks},
  booktitle = {ICML},
  year      = {2017}
}



@inproceedings{hoffman2012discovering,
  title={Discovering latent domains for multisource domain adaptation},
  author={Hoffman, Judy and Kulis, Brian and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2012}
}
@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  year={2001},
  publisher={Springer series in statistics New York}
}

@inproceedings{bousmalis2016unsupervised,
  title={Unsupervised pixel-level domain adaptation with generative adversarial networks},
  author={Bousmalis, Konstantinos and Silberman, Nathan and Dohan, David and Erhan, Dumitru and Krishnan, Dilip},
   booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}
@article{xie2015learning,
  title={Learning sparse frame models for natural image patterns},
  author={Xie, Jianwen and Hu, Wenze and Zhu, Song-Chun and Wu, Ying Nian},
  journal={IJCV},
  volume={114},
  number={2-3},
  pages={91--112},
  year={2015},
  publisher={Springer}
}
@inproceedings{gopalan2011domain,
  title={Domain adaptation for object recognition: An unsupervised approach},
  author={Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
  booktitle={ICCV},
  year={2011}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={NIPS-WS},
  year={2011}
}


@inproceedings{gong2013reshaping,
  title={Reshaping visual datasets for domain adaptation},
  author={Gong, Boqing and Grauman, Kristen and Sha, Fei},
  booktitle={NIPS},
  year={2013}
}
@article{nguyen2015dash,
  title={DASH-N: Joint hierarchical domain adaptation and feature learning},
  author={Nguyen, Hien V and Ho, Huy Tho and Patel, Vishal M and Chellappa, Rama},
  journal={IEEE T-IP},
  volume={24},
  number={12},
  pages={5479--5491},
  year={2015},
  publisher={IEEE}
}
@article{gopalan2014unsupervised,
  title={Unsupervised adaptation across domain shifts by generating intermediate data representations},
  author={Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
  journal={IEEE T-PAMI},
  volume={36},
  number={11},
  pages={2288--2302},
  year={2014},
  publisher={IEEE}
}

@inproceedings{jhuo2012robust,
  title={Robust visual domain adaptation with low-rank reconstruction},
  author={Jhuo, I-Hong and Liu, Dong and Lee, DT and Chang, Shih-Fu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2012}
}


@article{lin2017cross,
  title={Cross-Domain Recognition by Identifying Joint Subspaces of Source Domain and Target Domain},
  author={Lin, Yuewei and Chen, Jing and Cao, Yu and Zhou, Youjie and Zhang, Lingfeng and Tang, Yuan Yan and Wang, Song},
  journal={IEEE Transactions on Cybernetics},
  volume={47},
  number={4},
  pages={1090--1101},
  year={2017},
  publisher={IEEE}
}

@article{gopalan2017image,
  title={Image Clustering Under Domain Shift},
  author={Gopalan, Raghuraman},
  year={2017},
  publisher={IEEE}
}


@inproceedings{shekhar2013generalized,
  title={Generalized domain-adaptive dictionaries},
  author={Shekhar, Sumit and Patel, Vishal M and Nguyen, Hien V and Chellappa, Rama},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2013}
}

@article{li2017domain,
  title={Domain generalization and adaptation using low rank exemplar svms},
  author={Li, Wen and Xu, Zheng and Xu, Dong and Dai, Dengxin and Van Gool, Luc},
  journal={IEEE T-PAMI},
  year={2017},
  publisher={IEEE}
}


@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={IJCV},
  year={2015},
  publisher={Springer}
}
@article{arbelaez2011contour,
  title={Contour detection and hierarchical image segmentation},
  author={Arbelaez, Pablo and Maire, Michael and Fowlkes, Charless and Malik, Jitendra},
  journal={IEEE T-PAMI},
  volume={33},
  number={5},
  pages={898--916},
  year={2011},
  publisher={IEEE}
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting.},
  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}

@inproceedings{xiong2014latent,
  title={Latent Domains Modeling for Visual Domain Adaptation},
  author={Xiong, Caiming and McCloskey, Scott and Hsieh, Shao-Hang and Corso, Jason J},
  booktitle={AAAI},
  year={2014}
}

@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010}
}
@inproceedings{ghifary2016deep,
  title={Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation},
  author={Ghifary, Muhammad and Kleijn, W Bastiaan and Zhang, Mengjie and Balduzzi, David and Li, Wen},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{bousmalis2016domain,
  title={Domain separation networks},
  author={Bousmalis, Konstantinos and Trigeorgis, George and Silberman, Nathan and Krishnan, Dilip and Erhan, Dumitru},
  booktitle={NIPS},
  year={2016}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{aljundi2016lightweight,
  title={Lightweight Unsupervised Domain Adaptation by Convolutional Filter Reconstruction},
  author={Aljundi, Rahaf and Tuytelaars, Tinne},
  booktitle={European Conference of Computer Vision (ECCV) TASK-CV Workshops},
  year={2016}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={JMLR},
  year={2016}
}

@article{saito2017asymmetric,
  title={Asymmetric Tri-training for Unsupervised Domain Adaptation},
  author={Saito, Kuniaki and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={arXiv:1702.08400},
  year={2017}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  year={1998}
}




@inproceedings{yang2007adapting,
  title={Adapting SVM classifiers to data with shifted distributions},
  author={Yang, Jun and Yan, Rong and Hauptmann, Alexander G},
  booktitle={ICDM-WS 2007},
  year={2007}
}

@inproceedings{mansour2009domain,
  title={Domain adaptation with multiple sources},
  author={Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
  booktitle={NIPS},
  year={2009}
}

@inproceedings{duan2009domain,
  title={Domain adaptation from multiple sources via auxiliary classifiers},
  author={Duan, Lixin and Tsang, Ivor W and Xu, Dong and Chua, Tat-Seng},
  booktitle={ICML},
  year={2009}
}

@inproceedings{sun2011two,
  title={A two-stage weighting framework for multi-source domain adaptation},
  author={Sun, Qian and Chattopadhyay, Rita and Panchanathan, Sethuraman and Ye, Jieping},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{torralba2011unbiased,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2011}
}

@inproceedings{DBLP:journals/corr/DumoulinSK16,
  author    = {Vincent Dumoulin and
               Jonathon Shlens and
               Manjunath Kudlur},
  title     = {A Learned Representation For Artistic Style},
  booktitle   = {International Conference on Learning Representations (ICLR)},
  year      = {2016},
}


@article{siarohin2018whitening,
	title={Whitening and Coloring transform for {GAN}s},
	author={Aliaksandr Siarohin and Enver Sangineto and Nicu Sebe},
	booktitle={International Conference on Learning Representations (ICLR)},
	year={2019}
}

@inproceedings{miyato2018cgans,
  title={cGANs with projection discriminator},
  author={Miyato, Takeru and Koyama, Masanori},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2015},
  volume={abs/1412.6980}
}

@article{DBLP:journals/corr/UlyanovVL16,
  author    = {Dmitry Ulyanov and
               Andrea Vedaldi and
               Victor S. Lempitsky},
  title     = {Instance Normalization: The Missing Ingredient for Fast Stylization},
  journal   = {arXiv:1607.08022},
  year      = {2016},
}


@inproceedings{gatys2016image,
    author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    title={Image Style Transfer Using Convolutional Neural Networks},
    year={2016}
}

@inproceedings{jaderberg2015spatial,
  title={Spatial transformer networks},
  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},
  booktitle={NIPS},
  year={2015}
}

@inproceedings{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={NIPS},
  year={2017}
}

@article{yu2018multi,
  title={Multi-mapping image-to-image translation with central biasing normalization},
  author={Yu, Xiaoming and Ying, Zhenqiang and Li, Ge and Gao, Wen},
  journal={arXiv:1806.10050},
  year={2018}
}

@inproceedings{bousmalis2017unsupervised,
  title={Unsupervised pixel-level domain adaptation with generative adversarial networks},
  author={Bousmalis, Konstantinos and Silberman, Nathan and Dohan, David and Erhan, Dumitru and Krishnan, Dilip},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{liu2017unsupervised,
  title={Unsupervised image-to-image translation networks},
  author={Liu, Ming-Yu and Breuel, Thomas and Kautz, Jan},
  booktitle={NIPS},
  year={2017}
}

@inproceedings{larsson2016learning,
author="Larsson, Gustav
and Maire, Michael
and Shakhnarovich, Gregory",
title="Learning Representations for Automatic Colorization",
booktitle="Proceedings of the European Conference of Computer Vision (ECCV)",
year="2016",
pages="577--593",
abstract="We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.",
isbn="978-3-319-46493-0"
}


@inproceedings{zhao2019geometry,
  title={Geometry-aware symmetric domain adaptation for monocular depth estimation},
  author={Zhao, Shanshan and Fu, Huan and Gong, Mingming and Tao, Dacheng},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={9788--9798},
  volume={}
}

@inproceedings{haeusser,
  title={Associative deep clustering: Training a classification network with no labels},
  author={Haeusser, Philip and Plapp, Johannes and Golkov, Vladimir and Aljalbout, Elie and Cremers, Daniel.},
  booktitle={German Conference on Pattern Recognition},
  year={2018}
}

@inproceedings{liu2015deep,
  title={Deep learning face attributes in the wild},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2015}
}

@inproceedings{li2019episodic,
  title={Episodic training for domain generalization},
  author={Li, Da and Zhang, Jianshu and Yang, Yongxin and Liu, Cong and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={1446--1455},
  year={2019}
}

@inproceedings{mancini2019adagraph,
  title={Adagraph: Unifying predictive and continuous domain adaptation through graphs},
  author={Mancini, Massimiliano and Bulo, Samuel Rota and Caputo, Barbara and Ricci, Elisa},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6568--6577},
  year={2019}
}

@inproceedings{wang2017transitive,
author = {Wang, Xiaolong and He, Kaiming and Gupta, Abhinav},
year = {2017},
month = {10},
pages = {1338-1347},
title = {Transitive Invariance for Self-Supervised Visual Representation Learning}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  pages={69--84},
  year={2016},
}


@inproceedings{cho2019image,
  title={Image-to-image translation via group-wise deep whitening-and-coloring transformation},
  author={Cho, Wonwoong and Choi, Sungha and Park, David Keetae and Shin, Inkyu and Choo, Jaegul},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{hung2019scops,
  title={SCOPS: Self-Supervised Co-Part Segmentation},
  author={Hung, Wei-Chih and Jampani, Varun and Liu, Sifei and Molchanov, Pavlo and Yang, Ming-Hsuan and Kautz, Jan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{dereniowski2003cholesky,
  title={Cholesky factorization of matrices in parallel and ranking of graphs},
  author={Dereniowski, Dariusz and Kubale, Marek},
  booktitle={International Conference on Parallel Processing and Applied Mathematics},
  year={2003},
}

@misc{sohn2020fixmatch,
	title={FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence},
	author={Kihyuk Sohn and David Berthelot and Chun-Liang Li and Zizhao Zhang and Nicholas Carlini and Ekin D. Cubuk and Alex Kurakin and Han Zhang and Colin Raffel},
	year={2020},
	eprint={2001.07685},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}


@inproceedings{xie2015unsupervised,
author = {Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
title = {Unsupervised Deep Embedding for Clustering Analysis},
year = {2016},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning (ICML) - Volume 48},
pages = {478–487},
numpages = {10},
series = {ICML’16}
}

@inproceedings{chang2017dac,
  author={J. {Chang} and L. {Wang} and G. {Meng} and S. {Xiang} and C. {Pan}},
  booktitle={IEEE International Conference on Computer Vision (ICCV)}, 
  title={Deep Adaptive Image Clustering}, 
  year={2017},
  volume={},
  number={},
  pages={5880-5888},}
  
  
  @inproceedings{zen2014unsupervised,
  title={Unsupervised domain adaptation for personalized facial emotion recognition},
  author={Zen, Gloria and Sangineto, Enver and Ricci, Elisa and Sebe, Nicu},
  booktitle={Proceedings of the 16th international conference on multimodal interaction},
  year={2014}
}
  
@inproceedings{jang2017gumbel,
title	= {Categorical Reparameterization with Gumbel-Softmax},
author	= {Eric Jang and Shixiang Gu and Ben Poole},
year	= {2017}
}

@incollection{shi2015convlstm,
title = {Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting},
author = {SHI, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and WOO, Wang-chun},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},

pages = {802--810},
year = {2015},

}

@inproceedings{hessel2018rainbow,
  author={Matteo Hessel and Joseph Modayil and Hado van Hasselt and Tom Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and Mohammad Gheshlaghi Azar and David Silver},
  title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
  year={2018},
  cdate={1514764800000},
  pages={3215-3222},
  booktitle={AAAI}
}

@inproceedings{ebert2017selfsupervised,
  title={Self-Supervised Visual Planning with Temporal Skip Connections},
  author={Frederik Ebert and Chelsea Finn and Alex X. Lee and S. Levine},
  booktitle={CoRL},
  year={2017}
}

@InProceedings{Siarohin2019firstorder,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={First Order Motion Model for Image Animation},
  booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
  year = {2019}
}


@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and P. Abbeel and Chelsea Finn and S. Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.01523}
}

@InProceedings{tulyakov2018moco,
author = {Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
title = {MoCoGAN: Decomposing Motion and Content for Video Generation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2018}
}

@incollection{kim2019unsupervisedkeypointlearning,
title = {Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction},
author = {Kim, Yunji and Nam, Seonghyeon and Cho, In and Kim, Seon Joo},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2019},
}

@article{xu2020cideoprediction,
  title={Video Prediction via Example Guidance},
  author={J. Xu and Huazhe Xu and B. Ni and Xiaokang Yang and Trevor Darrell},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.01738}
}

@inproceedings{
weissenborn2020scaling,
title={Scaling Autoregressive Video Models},
author={Dirk Weissenborn and Oscar Täckström and Jakob Uszkoreit},
booktitle={International Conference on Learning Representations (ICLR)},
year={2020}
}

@article{clark2019dvdgan,
  author    = {Aidan Clark and
               Jeff Donahue and
               Karen Simonyan},
  title     = {Efficient Video Generation on Complex Datasets},
  journal   = {CoRR},
  volume    = {abs/1907.06571},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1907.06571},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200}
}

@article{franceschi2020stochastic,
  title={Stochastic Latent Residual Video Prediction},
  author={Jean-Yves Franceschi and Edouard Delasalles and Mickael Chen and Sylvain Lamprier and P. Gallinari},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.09219}
}

@InProceedings{denton2018svg, title = {Stochastic Video Generation with a Learned Prior}, author = {Denton, Emily and Fergus, Rob}, pages = {1174--1183}, year = {2018}, editor = {Jennifer Dy and Andreas Krause}, volume = {80}, series = {Proceedings of Machine Learning Research}, address = {Stockholmsmässan, Stockholm Sweden}, month = {10--15 Jul}, publisher = {PMLR}, abstract = {Generating video frames that accurately predict future world states is challenging. Existing approaches either fail to capture the full distribution of outcomes, or yield blurry generations, or both. In this paper we introduce a video generation model with a learned prior over stochastic latent variables at each time step. Video frames are generated by drawing samples from this prior and combining them with a deterministic estimate of the future frame. The approach is simple and easily trained end-to-end on a variety of datasets. Sample generations are both varied and sharp, even many frames into the future, and compare favorably to those from existing approaches.} }

@inproceedings{finn2016cdna,
 author = {Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},

 pages = {64--72},

 title = {Unsupervised Learning for Physical Interaction through Video Prediction},
 volume = {29},
 year = {2016}
}

@inproceedings{
babaeizadeh2018stochastic,
title={Stochastic Variational Video Prediction},
author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018}
}

@inproceedings{kumar2020videoflow,
title={VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation},
author={Manoj Kumar and Mohammad Babaeizadeh and Dumitru Erhan and Chelsea Finn and Sergey Levine and Laurent Dinh and Durk Kingma},
booktitle={International Conference on Learning Representations (ICLR)},
year={2020},
}


@article{luc2020trivdgan,
  title={Transformation-based Adversarial Video Prediction on Large-Scale Data},
  author={Pauline Luc and A. Clark and S. Dieleman and D. Casas and Yotam Doron and Albin Cassirer and K. Simonyan},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.04035}
}


@article{mathieu2015deep,
  title={Deep multi-scale video prediction beyond mean square error},
  author={Mathieu, Michael and Couprie, Camille and LeCun, Yann},
  journal={arXiv preprint arXiv:1511.05440},
  year={2015}
}

@inproceedings{srivastava2015unsupervised,
  title={Unsupervised learning of video representations using lstms},
  author={Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  booktitle={International conference on machine learning},
  pages={843--852},
  year={2015}
  
}Unsupervised learning of video
representations using lstms
@article{vondrick2015anticipating,
  title={Anticipating the future by watching unlabeled video},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal={arXiv preprint arXiv:1504.08023},
  volume={2},
  year={2015}
}
@inproceedings{kumar2019videoflow,
  title={VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation},
  author={Kumar, Manoj and Babaeizadeh, Mohammad and Erhan, Dumitru and Finn, Chelsea and Levine, Sergey and Dinh, Laurent and Kingma, Durk},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{kwon2019predicting,
  title={Predicting future frames using retrospective cycle gan},
  author={Kwon, Yong-Hoon and Park, Min-Gyu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1811--1820},
  year={2019}
}
@article{kingma2014auto,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={stat},
  volume={1050},
  pages={10},
  year={2014}
}

@article{saitotrain,
  title={Train Sparsely, Generate Densely: Memory-Efficient Unsupervised Training of High-Resolution Temporal GAN},
  author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
  journal={International Journal of Computer Vision (IJCV)},
  publisher={Springer}
}
@inproceedings{vondrick2016generating,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={613--621},
  year={2016}
}
@inproceedings{wang2018video,
  title={Video-to-Video Synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1144--1156},
  year={2018}
}
@inproceedings{chan2019everybody,
  title={Everybody dance now},
  author={Chan, Caroline and Ginosar, Shiry and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={5933--5942},
  year={2019}
}
@inproceedings{Kim2020_GameGan,
author = {Seung Wook Kim and Yuhao Zhou and Jonah Philion and Antonio Torralba and Sanja Fidler},
title = {{Learning to Simulate Dynamic Environments with GameGAN}},
year = {2020},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@inproceedings{rybkin2018learning,
  title={Learning what you can do before doing anything},
  author={Rybkin, Oleh and Pertsch, Karl and Derpanis, Konstantinos G and Daniilidis, Kostas and Jaegle, Andrew},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}
@inproceedings{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard L and Singh, Satinder},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={2863--2871},
  year={2015}
}
@inproceedings{nunes2020action,
  title={Action-conditioned Benchmarking of Robotic Video Prediction Models: a Comparative Study},
  author={Nunes, Manuel Serra and Dehban, Atabak and Moreno, Plinio and Santos-Victor, Jos{\'e}},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={8316--8322},
  year={2020},
}
@InProceedings{WANG_2020_WACV,
author = {Wand, Yaohui and Bilinski, Piotr and Bremond, Francois and Dantcheva, Antitza},
title = {ImaGINator: Conditional Spatio-Temporal GAN for Video Generation},
booktitle = {Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)},
month = {March},
year = {2020}
}

@inproceedings{ren2015faster,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 
 pages = {91--99},

 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 volume = {28},
 year = {2015}
}

@article{unterthiner2018towards,
  title={Towards Accurate Generative Models of Video: A New Metric \& Challenges},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}

@inproceedings{heusel2017advances,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},

 pages = {6626--6637},

 title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 volume = {30},
 year = {2017}
}
@article{fleiss1971measuring,
  title={Measuring nominal scale agreement among many raters.},
  author={Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={76},
  number={5},
  pages={378},
  year={1971},
  publisher={American Psychological Association}
}
@article{fleiss1981measurement,
  title={The measurement of interrater agreement},
  author={Fleiss, Joseph L and Levin, Bruce and Paik, Myunghee Cho and others},
  journal={Statistical methods for rates and proportions},
  volume={2},
  number={212-236},
  pages={22--23},
  year={1981},
  publisher={Citeseer}
}

@inproceedings{chen2016infogan,
 author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {2172--2180},
 title = {InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
 volume = {29},
 year = {2016}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2016}
}
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}
@article{chiappa2017recurrent,
  author    = {Silvia Chiappa and
               S{\'{e}}bastien Racani{\`{e}}re and
               Daan Wierstra and
               Shakir Mohamed},
  title     = {Recurrent Environment Simulators},
  journal   = {CoRR},
  volume    = {abs/1704.02254},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1704.02254},
  timestamp = {Mon, 13 Aug 2018 16:47:20 +0200},
}

@article{brockman2016gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  archivePrefix = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
}

@ARTICLE{peng2020unsupervised,
  author={B. {Peng} and J. {Lei} and H. {Fu} and C. {Zhang} and T. {Chua} and X. {Li}},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Unsupervised Video Action Clustering via Motion-Scene Interaction Constraint}, 
  year={2020},
  volume={30},
  number={1},
  pages={131-144}
}
  
@inproceedings{
gafni2020vid2game,
title={Vid2Game: Controllable Characters Extracted from Real-World Videos},
author={Oran Gafni and Lior Wolf and Yaniv Taigman},
booktitle={International Conference on Learning Representations (ICLR)},
year={2020}
}

@misc{zhang2020vid2player,
        Author = {Haotian Zhang and Cristobal Sciutto and Maneesh Agrawala and Kayvon Fatahalian},
        Title = {Vid2Player: Controllable Video Sprites that Behave and Appear like Professional Tennis Players},
        Year = {2020},
        Eprint = {arXiv:2008.04524},
      }
      
      @inproceedings{soomro2017unsupervised,
  title={Unsupervised action discovery and localization in videos},
  author={Soomro, Khurram and Shah, Mubarak},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={696--705},
  year={2017}
}
@inproceedings{luo2017unsupervised,
  title={Unsupervised learning of long-term motion dynamics for videos},
  author={Luo, Zelun and Peng, Boya and Huang, De-An and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2203--2212},
  year={2017}
}
@inproceedings{dwibedi2019temporal,
  title={Temporal cycle-consistency learning},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1801--1810},
  year={2019}
}

@InProceedings{siarohin2019monkeynet,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={Animating Arbitrary Objects via Deep Motion Transfer},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}
}

@inproceedings{siarohin2021motion,
        author={Siarohin, Aliaksandr and Woodford, Oliver and Ren, Jian and Chai, Menglei and Tulyakov, Sergey},
        title={Motion Representations for Articulated Animation},
        booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year = {2021}
}


@InProceedings{menapace2020acids,
author="Menapace, Willi
and Lathuili{\`e}re, St{\'e}phane
and Ricci, Elisa",
title="Learning to Cluster Under Domain Shift",
booktitle="Proceedings of the European Conference of Computer Vision (ECCV)",
year="2020",
address="Cham",
pages="736--752",
isbn="978-3-030-58604-1"
}


@InProceedings{Ost_2021_CVPR,
    author    = {Ost, Julian and Mannan, Fahim and Thuerey, Nils and Knodt, Julian and Heide, Felix},
    title     = {Neural Scene Graphs for Dynamic Scenes},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021},
    pages     = {2856-2865}
}

@InProceedings{menapace2021pvg,
    author    = {Menapace, Willi and Lathuiliere, Stephane and Tulyakov, Sergey and Siarohin, Aliaksandr and Ricci, Elisa},
    title     = {Playable Video Generation},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021},
    pages     = {10061-10070}
}

@InProceedings{niemeyer2021giraffe,
    author    = {Niemeyer, Michael and Geiger, Andreas},
    title     = {GIRAFFE: Representing Scenes As Compositional Generative Neural Feature Fields},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021},
    pages     = {11453-11464}
}

@inproceedings{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year={2020},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
}

@inproceedings{tretschk2021nonrigid,
    title = {Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video},
    author = {Tretschk, Edgar and Tewari, Ayush and Golyanik, Vladislav and Zollh\"{o}fer, Michael and Lassner, Christoph and Theobalt, Christian},
    booktitle = {Proceedings of the {IEEE} International Conference on Computer Vision ({ICCV})},
    year = {2021},
}

@inproceedings{huang2017adain,
  title={Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}


@inproceedings{hao2021GANcraft,
    title={{GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds}},
    author={Zekun Hao and Arun Mallya and Serge Belongie and Ming-Yu Liu},
    booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
    year={2021}
}

@inproceedings{yuan2021star,
    title={STaR: Self-supervised Tracking and Reconstruction of Rigid Objects in Motion with Neural Rendering},
    author={Yuan, Wentao and Lv, Zhaoyang and Schmidt, Tanner and Lovegrove, Steven},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2021}
} 

@article{kaizhang2020nerfplusplus,
    author    = {Kai Zhang and Gernot Riegler and Noah Snavely and Vladlen Koltun},
    title     = {NeRF++: Analyzing and Improving Neural Radiance Fields},
    journal   = {arXiv:2010.07492},
    year      = {2020},
}

@inproceedings{Niemeyer2021CAMPARI,
  author    = {Michael Niemeyer and
               Andreas Geiger},
  title     = {{CAMPARI:} Camera-Aware Decomposed Generative Neural Radiance Fields},
  booktitle={In Proceedings of the International Conference on 3D Vision (3DV)},
  year      = {2021},
}


@inproceedings{zhang2021stnerf,
               title={Editable Free-Viewpoint Video using a Layered Neural Representation},
                author={Jiakai, Zhang
                        and Xinhang, Liu
                        and Xinyi, Ye
                        and Fuqiang, Zhao
                        and Yanshun, Zhang
                        and Minye, Wu
                        and Yingliang, Zhang
                        and Lan, Xu
                        and Jingyi, Yu
                        },
         year={2021},
         booktitle={SIGGRAPH}
}


@Article{CDSD13,
  author       = {Chaurasia, Gaurav and Duch\^ene, Sylvain and Sorkine-Hornung, Olga and Drettakis, George},
  title        = {Depth Synthesis and Local Warps for Plausible Image-based Navigation},
  journal      = {ACM Transactions on Graphics},
  year         = {2013},
}

@article{Soft3DReconstruction,
  author    = {Eric Penner and Li Zhang},
  title     = {Soft 3D Reconstruction for View Synthesis},
  booktitle = {ACM Transactions on Graphics},
  publisher = {ACM},
  volume    = {36},
  number    = {6},
  year      = {2017}
}

@article{Kopf2013,
author = {Johannes Kopf and Fabian Langguth and Daniel Scharstein and Richard Szeliski and Michael Goesele},
title = {Image-Based Rendering in the Gradient Domain},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {0730-0301},
journal = {ACM Transactions on Graphics},
month = nov,
articleno = {199},
numpages = {9},
keywords = {image-based rendering, gradient domain processing}
}


@inproceedings{Seitz2006comparison,
  author={Steven M. Seitz and Brian Curless and James Diebel and Daniel Scharstein and Richard Szeliski},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms}, 
  year={2006},
  volume={1},
  number={},
  pages={519-528}
}
  
@InProceedings{pumarola2021dnerf,
    author    = {Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
    title     = {D-NeRF: Neural Radiance Fields for Dynamic Scenes},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021},
    pages     = {10318-10327}
}

@inproceedings{Zitnick2004HighqualityVV,
  title={High-quality video view interpolation using a layered representation},
  author={C. Lawrence Zitnick and Sing Bing Kang and Matthew Uyttendaele and Simon A. J. Winder and Richard Szeliski},
  booktitle={SIGGRAPH},
  year={2004}
}

@inproceedings{
kumar2020videoflow:,
title={VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation},
author={Manoj Kumar and Mohammad Babaeizadeh and Dumitru Erhan and Chelsea Finn and Sergey Levine and Laurent Dinh and Durk Kingma},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2021},
}

@misc{minecraft,
  title = {Minecraft},
  howpublished = {\url{https://www.minecraft.net}},
  note = {Accessed: 2021-11-12}
}

@misc{replaymod,
  title = {ReplayMod},
  author={ReplayMod},
  year={2022},
  howpublished = {\url{https://github.com/ReplayMod/ReplayMod}},
  note = {Accessed: 2021-11-12}
}

@inproceedings{farin2003robustcameracalibration,
  title={Robust camera calibration for sport videos using court models},
  author={Dirk Farin and Susanne Krabbe and Peter H. N. de With and Wolfgang Effelsberg},
  booktitle={IS\&T/SPIE Electronic Imaging},
  year={2003}
}

@misc{implementationfarin2003robustcameracalibration,
  title = {Implementation of: Robust camera calibration for sport videos using court models},
  howpublished = {\url{https://github.com/gchlebus/tennis-court-detection}},
  note = {Accessed: 2021-11-12}
}

@inproceedings{
    miyato2018spectral,
    title={Spectral Normalization for Generative Adversarial Networks},
    author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2018}
}

@InProceedings{Menapace2022PlayableEnvironments,
    author    = {Menapace, Willi and Lathuilière, Stéphane and Siarohin, Aliaksandr and Theobalt, Christian and Tulyakov, Sergey and Golyanik, Vladislav and Ricci, Elisa},
    title     = {Playable Environments: Video Manipulation in Space and Time},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022}
}

@inproceedings{koo2022partglot,
    title={PartGlot: Learning Shape Part Segmentation from Language Reference Games},
    author={
        Koo, Juil and
        Huang, Ian and
        Achlioptas, Panos and
        Guibas, Leonidas J and
        Sung, Minhyuk
    },
    booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}

@inproceedings{han2022show,
title={Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning},
author={Han, Ligong and Ren, Jian and Lee, Hsin-Ying and Barbieri, Francesco and Olszewski, Kyle and Minaee, Shervin and Metaxas, Dimitris and Tulyakov, Sergey},
booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2022}
}

@inproceedings{karras2019stylegan2,
  title     = {Analyzing and Improving the Image Quality of {StyleGAN}},
  author    = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2020}
}

@InProceedings{ronneberger2015unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@article{raffel2022exploring,
author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
year = {2022},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
journal = {J. Mach. Learn. Res.},
month = {jun},
articleno = {140},
numpages = {67},
keywords = {multi-task learning, deep learning, transfer learning, natural language processing, attention based models}
}

@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@inproceedings{shaw2018self,
    title = "Self-Attention with Relative Position Representations",
    author = "Shaw, Peter  and
      Uszkoreit, Jakob  and
      Vaswani, Ashish",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "464--468",
    abstract = "Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the WMT 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs.",
}

@inproceedings{ho2020ddpm,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6840--6851},
 publisher = {Curran Associates, Inc.},
 title = {Denoising Diffusion Probabilistic Models},
 volume = {33},
 year = {2020}
}

@article{girshick2013roipool,
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
year = {2013},
month = {11},
pages = {},
title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
journal = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@INPROCEEDINGS{fridovich2022plenoxels,
  author={Fridovich-Keil, Sara and Yu, Alex and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Plenoxels: Radiance Fields without Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={5491-5500}
}

@InProceedings{weng2022humannerf,
    title     = {Human{N}e{RF}: Free-Viewpoint Rendering of Moving People From Monocular Video},
    author    = {Weng, Chung-Yi and 
                 Curless, Brian and 
                 Srinivasan, Pratul P. and 
                 Barron, Jonathan T. and 
                 Kemelmacher-Shlizerman, Ira},
    booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16210-16220}
}

@inproceedings{lewis2000pose,
author = {Lewis, J. P. and Cordner, Matt and Fong, Nickson},
title = {Pose Space Deformation: A Unified Approach to Shape Interpolation and Skeleton-Driven Deformation},
year = {2000},
booktitle = SIGGRAPH,
}

@inproceedings{li2022tava,
  title={TAVA: Template-free animatable volumetric actors},
  author={Li, Ruilong and Tanke, Julian and Vo, Minh and Zollhofer, Michael and Gall, Jurgen and Kanazawa, Angjoo and Lassner, Christoph},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2022}
}

@article{loper2015smpl,
author = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
title = {SMPL: A Skinned Multi-Person Linear Model},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {6},
issn = {0730-0301},
abstract = {We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template, blend weights, pose-dependent blend shapes, identity-dependent blend shapes, and a regressor from vertices to joint locations. Unlike previous models, the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. We quantitatively evaluate variants of SMPL using linear or dual-quaternion blend skinning and show that both are more accurate than a Blend-SCAPE model trained on the same data. We also extend SMPL to realistically model dynamic soft-tissue deformations. Because it is based on blend skinning, SMPL is compatible with existing rendering engines and we make it available for research purposes.},
journal = {ACM Transactions on Graphics (TOG)},
month = {nov},
articleno = {248},
numpages = {16},
keywords = {blendshapes, soft-tissue, skinning, body shape}
}

@article{frechet1957distance,
  title={Sur la distance de deux lois de probabilit{\'e}},
  author={Fr{\'e}chet, Maurice},
  journal={Comptes Rendus Hebdomadaires des Seances de L Academie des Sciences},
  volume={244},
  number={6},
  pages={689--692},
  year={1957},
  publisher={GAUTHIER-VILLARS/EDITIONS ELSEVIER 23 RUE LINOIS, 75015 PARIS, FRANCE}
}

@InProceedings{bain2021webvid10m,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "Proceedings of the IEEE International Conference on Computer Vision (ICCV)",
  year         = "2021",
}

@inproceedings{miech19howto100m,
   title={How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
   author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
   booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
   year={2019},
}

@inproceedings{radford2021clip,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{saharia2022imagen,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily L. Denton and Seyed Kamyar Seyed Ghasemipour and Burcu Karagol Ayan and Seyedeh Sara Mahdavi and Raphael Gontijo Lopes and Tim Salimans and Jonathan Ho and David J. Fleet and Mohammad Norouzi},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.11487}
}

@inproceedings{zhou2019cvpr,
title={On the Continuity of Rotation Representations in Neural Networks},
author={Zhou, Yi and Barnes, Connelly and Jingwan, Lu and Jimei, Yang and Hao, Li},
booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month={June},
year={2019}
}

@InProceedings{zhao2018icnet,
author="Zhao, Hengshuang
and Qi, Xiaojuan
and Shen, Xiaoyong
and Shi, Jianping
and Jia, Jiaya",
editor="Ferrari, Vittorio
and Hebert, Martial
and Sminchisescu, Cristian
and Weiss, Yair",
title="ICNet for Real-Time Semantic Segmentation on High-Resolution Images",
booktitle={"Proceedings of the European Conference of Computer Vision (ECCV)"},
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="418--434",
abstract="We focus on the challenging task of real-time semantic segmentation in this paper. It finds many practical applications and yet is with fundamental difficulty of reducing a large portion of computation for pixel-wise label inference. We propose an image cascade network (ICNet) that incorporates multi-resolution branches under proper label guidance to address this challenge. We provide in-depth analysis of our framework and introduce the cascade feature fusion unit to quickly achieve high-quality segmentation. Our system yields real-time inference on a single GPU card with decent quality results evaluated on challenging datasets like Cityscapes, CamVid and COCO-Stuff.",
isbn="978-3-030-01219-9"
}

@InProceedings{choi2022learning,  
author = {Choi, Hongsuk and Moon, Gyeongsik and Park, JoonKyu and Lee, Kyoung Mu},  
title = {Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes},  
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2022}  
}  

@inproceedings{
  xu2022vitpose,
  title={Vi{TP}ose: Simple Vision Transformer Baselines for Human Pose Estimation},
  author={Yufei Xu and Jing Zhang and Qiming Zhang and Dacheng Tao},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
}

@article{EPnP,
author = {Lepetit, Vincent and Moreno-Noguer, Francesc and Fua, Pascal},
title = {EPnP: An Accurate O(n) Solution to the PnP Problem},
year = {2009},
journal = IJCV,
}

@inproceedings{
song2021denoising,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021}
}

@inproceedings{
salimans2022progressive,
title={Progressive Distillation for Fast Sampling of Diffusion Models},
author={Tim Salimans and Jonathan Ho},
booktitle={International Conference on Learning Representations (ICLR)},
year={2022}
}

@inproceedings{
meng2022on,
title={On Distillation of Guided Diffusion Models},
author={Chenlin Meng and Ruiqi Gao and Diederik P Kingma and Stefano Ermon and Jonathan Ho and Tim Salimans},
booktitle={NeurIPS 2022 Workshop on Score-Based Methods},
year={2022}
}

@inproceedings{mueller2022autorf,
  author    = {M{\"{u}}ller, Norman and Simonelli, Andrea and Porzi, Lorenzo and Bulò, Samuel Rota and Nie{\ss}ner, Matthias and Kontschieder, Peter},
  title     = {AutoRF: Learning 3D Object Radiance Fields from Single View Observations},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2022}
}

@article{xu2022discoscene,
    author  = {Xu, Yinghao and Chai, Menglei and Shi, Zifan and Peng, Sida and Skorokhodov Ivan and Siarohin Aliaksandr and Yang, Ceyuan and Shen, Yujun and Lee, Hsin-Ying and Zhou, Bolei and Tulyakov Sergy},
    title   = {DiscoScene: Spatially Disentangled Generative Radiance Field for Controllable 3D-aware Scene Synthesis},
    journal = {arxiv: 2212.11984},
    year    = {2022},
}

@inproceedings{10.1145/800031.808590,
author = {Cook, Robert L. and Porter, Thomas and Carpenter, Loren},
title = {Distributed Ray Tracing},
year = {1984},
isbn = {0897911385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Ray tracing is one of the most elegant techniques in computer graphics. Many phenomena that are difficult or impossible with other techniques are simple with ray tracing, including shadows, reflections, and refracted light. Ray directions, however, have been determined precisely, and this has limited the capabilities of ray tracing. By distributing the directions of the rays according to the analytic function they sample, ray tracing can incorporate fuzzy phenomena. This provides correct and easy solutions to some previously unsolved or partially solved problems, including motion blur, depth of field, penumbras, translucency, and fuzzy reflections. Motion blur and depth of field calculations can be integrated with the visible surface calculations, avoiding the problems found in previous methods.},
booktitle = {Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {137–145},
numpages = {9},
keywords = {Motion blur, Constructive solid geometry, Depth of field, Shadows, Focus, Penumbras, Camera, Gloss, Translucency, Transparency, Ray tracing},
series = {SIGGRAPH '84}
}


@article{cook1984distributed,
author = {Cook, Robert L. and Porter, Thomas and Carpenter, Loren},
title = {Distributed Ray Tracing},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {0097-8930},
abstract = {Ray tracing is one of the most elegant techniques in computer graphics. Many phenomena that are difficult or impossible with other techniques are simple with ray tracing, including shadows, reflections, and refracted light. Ray directions, however, have been determined precisely, and this has limited the capabilities of ray tracing. By distributing the directions of the rays according to the analytic function they sample, ray tracing can incorporate fuzzy phenomena. This provides correct and easy solutions to some previously unsolved or partially solved problems, including motion blur, depth of field, penumbras, translucency, and fuzzy reflections. Motion blur and depth of field calculations can be integrated with the visible surface calculations, avoiding the problems found in previous methods.},
journal = {SIGGRAPH Comput. Graph.},
month = {jan},
pages = {137–145},
numpages = {9},
keywords = {Shadows, Depth of field, Motion blur, Ray tracing, Gloss, Transparency, Constructive solid geometry, Camera, Focus, Translucency, Penumbras}
}

@misc{zhang2022motiondiffuse,
  author = {Zhang, Mingyuan and Cai, Zhongang and Pan, Liang and Hong, Fangzhou and Guo, Xinying and Yang, Lei and Liu, Ziwei},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{dabral2022mofusion,
  author = {Dabral, Rishabh and Mughal, Muhammad Hamza and Golyanik, Vladislav and Theobalt, Christian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{tashiro2021csdi,
  title={CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation},
  author={Tashiro, Yusuke and Song, Jiaming and Song, Yang and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ho2022imagenvideo,
  author = {Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P. and Poole, Ben and Norouzi, Mohammad and Fleet, David J. and Salimans, Tim},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Imagen Video: High Definition Video Generation with Diffusion Models},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
ho2022video,
title={Video Diffusion Models},
author={Jonathan Ho and Tim Salimans and Alexey A. Gritsenko and William Chan and Mohammad Norouzi and David J. Fleet},
booktitle={ICLR Workshop on Deep Generative Models for Highly Structured Data},
year={2022}
}

@inproceedings{kong2020diffwave,
  title={DiffWave: A Versatile Diffusion Model for Audio Synthesis},
  author={Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@misc{dieleman2022cdcd,
  author = {Dieleman, Sander and Sartran, Laurent and Roshannai, Arman and Savinov, Nikolay and Ganin, Yaroslav and Richemond, Pierre H. and Doucet, Arnaud and Strudel, Robin and Dyer, Chris and Durkan, Conor and Hawthorne, Curtis and Leblond, Rémi and Grathwohl, Will and Adler, Jonas},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Continuous diffusion for categorical data},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
@inproceedings{fortuin2020gp,
  title={Gp-vae: Deep probabilistic time series imputation},
  author={Fortuin, Vincent and Baranchuk, Dmitry and R{\"a}tsch, Gunnar and Mandt, Stephan},
  booktitle={International conference on artificial intelligence and statistics},
  pages={1651--1661},
  year={2020},
  organization={PMLR}
}
@inproceedings{kwon2019predicting,
  title={Predicting future frames using retrospective cycle gan},
  author={Kwon, Yong-Hoon and Park, Min-Gyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1811--1820},
  year={2019}
}

@inproceedings{babaeizadeh2018stochastic,
  title={Stochastic Variational Video Prediction},
  author={Babaeizadeh, Mohammad and Finn, Chelsea and Erhan, Dumitru and Campbell, Roy H and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@InProceedings{huang2022layered,
author="Huang, Jiahui
and Jin, Yuhe
and Yi, Kwang Moo
and Sigal, Leonid",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="Layered Controllable Video Generation",
booktitle={"Proceedings of the European Conference of Computer Vision (ECCV)"},
year="2022",
}

@article{starke2019neural, 
author = {Starke, Sebastian and Zhang, He and Komura, Taku and Saito, Jun}, 
title = {Neural State Machine for Character-Scene Interactions}, 
year = {2019}, 
volume = {38}, 
number = {6}, 
journal = {ACM Transactions on Graphics (TOG)} 
} 

@inproceedings {Stanton2016, 
booktitle = {Eurographics/ ACM SIGGRAPH Symposium on Computer Animation},  
title = {{Large-Scale Finite State Game Engines}}, 
author = {Stanton, Matt and Geddert, Sascha and Blumer, Adrian and Hormis, Paul and Nealen, Andy and Cooper, Seth and Treuille, Adrien}, 
year = {2016}, 
}


@inproceedings{Curtis2022, 
author = {Curtis, Cassidy and Adalgeirsson, Sigurdur Orn and Ciurdar, Horia Stefan and  McDermott, Peter and Vel\'{a}squez, JD and Knox, W. Bradley and Martinez, Alonso and  Gaztelumendi, Dei and Goussies, Norberto Adrian and Liu, Tianyu and Nandy, Palash}, 
title = {Toward Believable Acting for Autonomous Animated Characters}, 
year = {2022}, 
booktitle = {Proceedings of the 15th ACM SIGGRAPH Conference on Motion, Interaction and Games} 
} 

@inproceedings{davtyan2022glass,
  title={Controllable Video Generation through Global and Local Motion Dynamics},
  author={Aram Davtyan and Paolo Favaro},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{cao2020gtaim,
  author = {Zhe Cao and
    Hang Gao and
    Karttikeya Mangalam and
    Qizhi Cai and
    Minh Vo and
    Jitendra Malik},
  title = {Long-term human motion prediction with scene context},
  booktitle={Proceedings of the European Conference of Computer Vision (ECCV)},
  year = {2020},
  }

@inproceedings{
lam2022bddm,
title={{BDDM}: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis},
author={Max W. Y. Lam and Jun Wang and Dan Su and Dong Yu},
booktitle={International Conference on Learning Representations (ICLR)},
year={2022}
}

@inproceedings{
chen2021wavegrad,
title={WaveGrad: Estimating Gradients for Waveform Generation},
author={Nanxin Chen and Yu Zhang and Heiga Zen and Ron J Weiss and Mohammad Norouzi and William Chan},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021}
}

@inproceedings{
leng2022binauralgrad,
title={BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis},
author={Yichong Leng and Zehua Chen and Junliang Guo and Haohe Liu and Jiawei Chen and Xu Tan and Danilo Mandic and Lei He and Xiangyang Li and Tao Qin and sheng zhao and Tie-Yan Liu},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}

@misc{singer2022makeavideo,
  
  author = {Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Make-A-Video: Text-to-Video Generation without Text-Video Data},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  year={2022}
}

@misc{lin2022magic3d,
  
  author = {Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Magic3D: High-Resolution Text-to-3D Content Creation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{poole2022dreamfusion,
  
  author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DreamFusion: Text-to-3D using 2D Diffusion},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{jain2021dreamfields,
  author = {Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T. and Abbeel, Pieter and Poole, Ben},
  title = {Zero-Shot Text-Guided Object Generation with Dream Fields},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2022},
}


@InProceedings{ramesh2021zeroshot,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  abstract = 	 {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.}
}

@article{ramesh2022hierarchical,
  title={Hierarchical Text-Conditional Image Generation with CLIP Latents},
  author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.06125}
}

@inproceedings{guy2022motionclip,
  author    = {Guy Tevet and
               Brian Gordon and
               Amir Hertz and
               Amit H. Bermano and
               Daniel Cohen{-}Or},
  editor    = {Shai Avidan and
               Gabriel J. Brostow and
               Moustapha Ciss{\'{e}} and
               Giovanni Maria Farinella and
               Tal Hassner},
  title     = {MotionCLIP: Exposing Human Motion Generation to {CLIP} Space},
  booktitle = {Proceedings of the European Conference of Computer Vision (ECCV)},
  series    = {Lecture Notes in Computer Science},
  volume    = {13682},
  pages     = {358--374},
  publisher = {Springer},
  year      = {2022},
  timestamp = {Wed, 26 Oct 2022 09:56:23 +0200}
}

@inproceedings{
liu2020roberta,
title={Ro{\{}BERT{\}}a: A Robustly Optimized {\{}BERT{\}} Pretraining Approach},
author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
year={2020},
booktitle={International Conference on Learning Representations (ICLR)}
}

@misc{fu2022tellmewhathappened,
  
  author = {Fu, Tsu-Jui and Yu, Licheng and Zhang, Ning and Fu, Cheng-Yang and Su, Jong-Chyi and Wang, William Yang and Bell, Sean},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Tell Me What Happened: Unifying Text-guided Video Completion via Multimodal Masked Video Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{barron2021mipnerf360,
  title={Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
  author={Jonathan T. Barron and Ben Mildenhall and Dor Verbin and Pratul P. Srinivasan and Peter Hedman},
  journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={5460-5469}
}

@article{park2021hypernerf,
  author = {Park, Keunhong and Sinha, Utkarsh and Hedman, Peter and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Martin-Brualla, Ricardo and Seitz, Steven M.},
  title = {HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields},
  journal = {ACM Transactions on Graphics (TOG)},
  issue_date = {December 2021},
  publisher = {ACM},
  volume = {40},
  number = {6},
  month = {dec},
  year = {2021},
  articleno = {238},
}

@inproceedings{peng2021neural,
  title={Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans},
  author={Peng, Sida and Zhang, Yuanqing and Xu, Yinghao and Wang, Qianqian and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{kundu2022panoptic,
  title={Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation},
  author={Abhijit Kundu and Kyle Genova and Xiaoqi Yin and Alireza Fathi and Caroline Pantofaru and Leonidas J. Guibas and Andrea Tagliasacchi and Frank Dellaert and Thomas A. Funkhouser},
  journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  pages={12861-12871}
}

@inproceedings{
wu2022dnerf,
title={D{\textasciicircum}2Ne{RF}: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video},
author={Tianhao Walter Wu and Fangcheng Zhong and Andrea Tagliasacchi and Forrester Cole and Cengiz Oztireli},
booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}

@inproceedings{yu2021plenoctrees,
      title={{PlenOctrees} for Real-time Rendering of Neural Radiance Fields},
      author={Alex Yu and Ruilong Li and Matthew Tancik and Hao Li and Ren Ng and Angjoo Kanazawa},
      year={2021},
      booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
}

@inproceedings{chan2022eg3d,
  author = {Eric R. Chan and Connor Z. Lin and Matthew A. Chan and Koki Nagano and Boxiao Pan and Shalini De Mello and Orazio Gallo and Leonidas Guibas and Jonathan Tremblay and Sameh Khamis and Tero Karras and Gordon Wetzstein},
  title = {Efficient Geometry-aware {3D} Generative Adversarial Networks},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2022}
}

@INPROCEEDINGS{chen2022tensorf,
  author = {Anpei Chen and Zexiang Xu and Andreas Geiger and Jingyi Yu and Hao Su},
  title = {TensoRF: Tensorial Radiance Fields},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2022}
}

@article{mueller2022instant,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Transactions on Graphics (TOG)},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    publisher = {ACM},
    address = {New York, NY, USA},
}


@inproceedings{TEACH,
  title={TEACH: Temporal Action Compositions for 3D Humans},
  author={Athanasiou, Nikos and Petrovich, Mathis and Black, Michael J. and Varol, G\"{u}l },
  booktitle = {International Conference on 3D Vision (3DV)},
  month = {September},
  year = {2022}
}

@article{holden2020learned,
author = {Holden, Daniel and Kanoun, Oussama and Perepichka, Maksym and Popa, Tiberiu},
title = {Learned Motion Matching},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
abstract = {In this paper we present a learned alternative to the Motion Matching algorithm which retains the positive properties of Motion Matching but additionally achieves the scalability of neural-network-based generative models. Although neural-network-based generative models for character animation are capable of learning expressive, compact controllers from vast amounts of animation data, methods such as Motion Matching still remain a popular choice in the games industry due to their flexibility, predictability, low preprocessing time, and visual quality - all properties which can sometimes be difficult to achieve with neural-network-based methods. Yet, unlike neural networks, the memory usage of such methods generally scales linearly with the amount of data used, resulting in a constant trade-off between the diversity of animation which can be produced and real world production budgets. In this work we combine the benefits of both approaches and, by breaking down the Motion Matching algorithm into its individual steps, show how learned, scalable alternatives can be used to replace each operation in turn. Our final model has no need to store animation data or additional matching meta-data in memory, meaning it scales as well as existing generative models. At the same time, we preserve the behavior of Motion Matching, retaining the quality, control, and quick iteration time which are so important in the industry.},
journal = {ACM Transactions on Graphics (TOG)},
month = {aug},
articleno = {53},
numpages = {13},
keywords = {neural networks, generative models, animation, motion matching, character animation}
}

@article{starke2020local,
author = {Starke, Sebastian and Zhao, Yiwei and Komura, Taku and Zaman, Kazi},
title = {Local Motion Phases for Learning Multi-Contact Character Movements},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
abstract = {Training a bipedal character to play basketball and interact with objects, or a quadruped character to move in various locomotion modes, are difficult tasks due to the fast and complex contacts happening during the motion. In this paper, we propose a novel framework to learn fast and dynamic character interactions that involve multiple contacts between the body and an object, another character and the environment, from a rich, unstructured motion capture database. We use one-on-one basketball play and character interactions with the environment as examples. To achieve this task, we propose a novel feature called local motion phase, that can help neural networks to learn asynchronous movements of each bone and its interaction with external objects such as a ball or an environment. We also propose a novel generative scheme to reproduce a wide variation of movements from abstract control signals given by a gamepad, which can be useful for changing the style of the motion under the same context. Our scheme is useful for animating contact-rich, complex interactions for real-time applications such as computer games.},
journal = {ACM Transactions on Graphics (TOG)},
month = {aug},
articleno = {54},
numpages = {14},
keywords = {character interactions, deep learning, human motion, character animation, neural networks, character control}
}

@inproceedings {buttner2019motion, 
booktitle = {In Proc. of Nucl.ai 2015},  
title = {Motion Matching - The Road to Next Gen Animation}, 
author = {Büttner, Michael and Clavet, Simon}, 
year = {2015}, 
}

@article{lee2018interactive,
author = {Lee, Kyungho and Lee, Seyoung and Lee, Jehee},
title = {Interactive Character Animation by Learning Multi-Objective Control},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {6},
issn = {0730-0301},
abstract = {We present an approach that learns to act from raw motion data for interactive character animation. Our motion generator takes a continuous stream of control inputs and generates the character's motion in an online manner. The key insight is modeling rich connections between a multitude of control objectives and a large repertoire of actions. The model is trained using Recurrent Neural Network conditioned to deal with spatiotemporal constraints and structural variabilities in human motion. We also present a new data augmentation method that allows the model to be learned even from a small to moderate amount of training data. The learning process is fully automatic if it learns the motion of a single character, and requires minimal user intervention if it deals with props and interaction between multiple characters.},
journal = {ACM Transactions on Graphics (TOG)},
month = {dec},
articleno = {180},
numpages = {10},
keywords = {character animation, multi-objective control, interactive motion control, motion grammar, recurrent neural network, deep learning}
}

@article{holden2017phase,
  title={Phase-functioned neural networks for character control},
  author={Daniel Holden and Taku Komura and Jun Saito},
  journal={ACM Transactions on Graphics (TOG)},
  year={2017},
  volume={36},
  pages={1 - 13}
}

@article{kuang2022neroic,
author = {Kuang, Zhengfei and Olszewski, Kyle and Chai, Menglei and Huang, Zeng and Achlioptas, Panos and Tulyakov, Sergey},
title = {NeROIC: Neural Rendering of Objects from Online Image Collections},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
abstract = {We present a novel method to acquire object representations from online image collections, capturing high-quality geometry and material properties of arbitrary objects from photographs with varying cameras, illumination, and backgrounds. This enables various object-centric rendering applications such as novel-view synthesis, relighting, and harmonized background composition from challenging in-the-wild input. Using a multi-stage approach extending neural radiance fields, we first infer the surface geometry and refine the coarsely estimated initial camera parameters, while leveraging coarse foreground object masks to improve the training efficiency and geometry quality. We also introduce a robust normal estimation technique which eliminates the effect of geometric noise while retaining crucial details. Lastly, we extract surface material properties and ambient illumination, represented in spherical harmonics with extensions that handle transient elements, e.g. sharp shadows. The union of these components results in a highly modular and efficient object acquisition framework. Extensive evaluations and comparisons demonstrate the advantages of our approach in capturing high-quality geometry and appearance properties useful for rendering applications.},
journal = {ACM Transactions on Graphics (TOG)},
month = {jul},
articleno = {56},
numpages = {12},
keywords = {neural rendering, reflectance & shading models, multi-view & 3D}
}

@article{liu2021neural,
author = {Liu, Lingjie and Habermann, Marc and Rudnev, Viktor and Sarkar, Kripasindhu and Gu, Jiatao and Theobalt, Christian},
title = {Neural Actor: Neural Free-View Synthesis of Human Actors with Pose Control},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {6},
issn = {0730-0301},
abstract = {We propose Neural Actor (NA), a new method for high-quality synthesis of humans from arbitrary viewpoints and under arbitrary controllable poses. Our method is developed upon recent neural scene representation and rendering works which learn representations of geometry and appearance from only 2D images. While existing works demonstrated compelling rendering of static scenes and playback of dynamic scenes, photo-realistic reconstruction and rendering of humans with neural implicit methods, in particular under user-controlled novel poses, is still difficult. To address this problem, we utilize a coarse body model as a proxy to unwarp the surrounding 3D space into a canonical pose. A neural radiance field learns pose-dependent geometric deformations and pose- and view-dependent appearance effects in the canonical space from multi-view video input. To synthesize novel views of high-fidelity dynamic geometry and appearance, NA leverages 2D texture maps defined on the body model as latent variables for predicting residual deformations and the dynamic appearance. Experiments demonstrate that our method achieves better quality than the state-of-the-arts on playback as well as novel pose synthesis, and can even generalize well to new poses that starkly differ from the training poses. Furthermore, our method also supports shape control on the free-view synthesis of human actors.},
journal = {ACM Transactions on Graphics (TOG)},
month = {dec},
articleno = {219},
numpages = {16},
keywords = {photo-realistic character synthesis, neural rendering}
}


@inproceedings{achlioptas2023shapetalk,
  title={{ShapeTalk}: A Language Dataset and Framework for 3D Shape Edits and Deformations},
  author={Achlioptas, Panos and Huang, Ian and Sung, Minhyuk and Tulyakov, Sergey and Guibas, Leonidas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},  
  year={2023}
}