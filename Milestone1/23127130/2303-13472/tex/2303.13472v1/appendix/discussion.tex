\section{Discussion}

\subsection{Cost-Quality Tradeoff and Game Developers Validation}
\label{ap:cost_quality}

Building videogames is an extremely expensive process. We propose a \emph{fully learnable} solution, requiring only annotated monocular videos and supporting the core set of game functions. 

This research direction is a step towards creating games and editing videos without expensive equipment, data, 3D assets, sophisticated software and manual labor of trained experts. We do not aim to surpass the quality of high-cost techniques (\$100k-\$1M, see below) that require such resources.

Evaluation of such a method necessarily needs to be performed under the light of a Pareto curve representing the tradeoff between development cost and output quality. 
We analyze three points on this curve for tennis:
\begin{itemize}
\item \emph{Traditional game development} (1M\$ cost range, high quality). We interviewed three game development experts with backgrounds in real-time graphics, 3D models and animation, and game development management with 45 years of combined experience. We invited the experts to discuss the recent “AO Tennis 2” game and compare it with our method. Their cost estimate for building AO Tennis 2 using existing game engines were respectively of \$100k-500k (in the US), \$600k (45-person-years in Ukraine), and of \$1M (3-person-years in the US), including software licenses, equipment and assets. They noted that ``[our model’s] game AI is very valuable and it's going to be the hardest part of developing tennis'' and that our model's game AI has the potential to be ``game changer'' for tasks such as realistically modeling the behavior of animals inserted in a game. With regards to graphics, they noted that ``[our model’s graphics] is more realistic'' and that ``[our model’s output] looks like a real video'' when not zoomed in, but commented that users may be prefer a less-realistic game-like graphics because they are more accustomed to its look. The users highlighted the value of the generated animated 3D assets, remarking that high-quality 3D assets of real players are expensive. When asked about possible immediate uses of the model in game production they reported that while the model is ``impressive'' it is not yet ``mind-blowing'' when speaking about building products using our method. In particular, the model's output may present artifacts that would require correction, preventing direct use of the model in a production environment. An interviewee highlighted that the framework could be called a ``limited game engine'' and would be ``awesome'' to use to create a new type of ``promo games'' such as Superbowl or Nascar games that can be released at low cost immediately after the sport season, leveraging the captured footage. Given the significantly lower cost of our method and the rapid evolution in neural rendering and diffusion models on which our framework is based, we consider these comments an encouraging validation of this research direction.
\item \emph{Specialized CG techniques} (100k\$ cost range, high quality). Specialized character animation techniques \cite{starke2019neural,starke2020local,holden2020learned} produce high-quality animations. However, they come at higher cost. The sole requirement of motion capture data entails a professional multicamera system (1k-10k\$ per camera * 10s of cameras), motion capture software licenses (1k-10k\$/year), an HPC system with TBs of storage (>>10k\$), dedicated engineers (10k-100k\$/year), studio space, inviting professional actors or players (10-100\$/h). In addition, they do not model the complete game’s logic and only learn basic game AI elements, making their integration into a unified, learnable framework nontrivial.
\end{itemize}

\subsection{Limitations}

Since the model is trained on a dataset showing only plausible actions, the model's behavior is not defined when an \emph{implausible} action is specified, such as hitting a ball when it is too far from the player or jumping on a platform that is out of reach. In these cases we find the model to produce outcomes such as running too fast or producing implausibly long jumps. In addition, the model does not generate plausible results in the case of actions extremely out of distribution such as performing a backflip or doing a push-up.

While our Tennis dataset contains varied text annotations that allow the model to generalize to text inputs with varied structure, our Minecraft dataset's synthetic text annotations are less varied and the fixed synthetic structure of sentences tends to be memorized, making the model less effective if a different syntax is used (see Sec.~\ref{ap:language_robustness}). To address this issue, a more sophisticated algorithm can be employed to generate action annotation on the Minecraft dataset.

Our model learns to associate referential language to scene coordinates rather than the appearance of the referred object, and the model memorizes the position of contact surfaces. While tennis scenes always have the same structure, for Minecraft the model cannot generalize to different scenes. This concern can be addressed by conditioning the animation model on the scene's geometry, which we leave as future work.

Our animation model outperforms baselines that operate under the same data assumptions \cite{Menapace2022PlayableEnvironments} in terms of animation quality. With respect to recent character animation methods \cite{starke2019neural,starke2020local,holden2020learned} making use of richly annotated motion capture data and dataset-specific handcrafted optimizations (see Sec.~\ref{sec:character_animation}), our method demonstrates more advanced game logic and game AI modeling capabilities, but produces foot sliding artifacts. We expect continuous improvements in diffusion models to alleviate such artifacts and expect further improvements by considering different parametrizations of pose parameters taking into consideration the distance of limbs from the terrain, which we will explore in future work.

Lastly, our animation model does not yet produce results in real-time. We discuss inference speed and strategies to make the model real-time in \apref{ap:inference_speed}. Improving the sampling speed of diffusion models is an actively investigated problem \cite{salimans2022progressive,meng2022on,song2021denoising} that is orthogonal to ours.

\subsection{Ethics}

The techniques described in this work fall in the category of video editing methods and could potentially be used to nefariously alter existing videos. The design of our method assumes multiple camera-calibrated observations of a single scene to be available for training, and that the desired edit is shown at least once in the training data. This provides protection towards applying the method to tamper a single video, for which the quantity of data would not be sufficient and the desired edit would likely not be shown. 