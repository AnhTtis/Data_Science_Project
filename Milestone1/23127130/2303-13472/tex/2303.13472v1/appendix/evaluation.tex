\section{Additional Evaluation}
\label{ap:evaluation}

\subsection{Robustness to prompt variations}
\label{ap:language_robustness}
We perform a study on the Tennis dataset to evaluate the capability of our animation model to support diverse language prompts. We randomly sampled 50 prompts from our tennis dataset and asked \emph{ChatGPT to ``Produce a semantically equivalent reformulation of the prompt ‘<prompt>’''}. The sentence similarity between original and reformulated prompts measured by Jaccard similarity on their 3-grams is 0.390, while it is 0.203 for random dataset prompt pairs, indicating high diversity. As an example, the prompt \emph{``the player stops and quickly runs to the right and hits the ball with a backhand towards the center of no man's land''} is reformulated to \emph{``The player comes to a stop and rapidly sprints towards the right before executing a backhand stroke that directs the ball towards the center of no man's land''}, and prompt \emph{``the player prepares to hit the ball but stops, returning ball hits the net''} is transformed to \emph{``The player readies themselves to strike the ball, but abruptly halts and as a result, the returned ball collides with the net''}.

Successively, we run an AMT user study. Users are shown a video and two prompts (the true prompt used to produce the video, and a random negative prompt) and they are asked to recognize which of two prompts is the one used to produce a certain video. The average accuracy over 500 responses is $74.4\%$ and $77.1\%$ for videos produced using reformulated and dataset prompts respectively, indicating capability of the model to generate videos matching prompts independently from the form of used language.

The model trained on Minecraft allows for limited prompt variation due to the synthetic nature of the training language whose limited variation does not enable the model to learn generalization capabilities to different sentence structures as the ones acquired for Tennis. This limitation could be addressed by improving the synthetic language generation process, which we leave as future work.


\subsection{Animation Model Evaluation}
\label{ap:animation_evaluation}
In Tab.~\ref{table:animation_tennis} and Tab.~\ref{table:animation_minecraft} we show evaluation results for each inference task respectively on the Tennis and Minecraft datasets. In Fig.~\ref{fig:animation_ablation_qualitatives_minecraft} we show qualitative results on the Minecraft dataset.

\input{tables/table_animation_tennis}
\input{tables/table_animation_minecraft}

\begin{figure}
\includegraphics{resources/animation_ablation_qualitatives_minecraft}
  \caption{Qualitatives results on the Minecraft dataset. Sequences are produced in a video prediction setting that uses the first frame object properties and all actions as conditioning. Additional samples are shown in the \website.}
  \label{fig:animation_ablation_qualitatives_minecraft}
\end{figure}

\subsection{Alternative Samplers}
\begin{figure}
\includegraphics[width=\columnwidth]{resources/ddim_sampling_plot}
  \caption{Evaluation results for our method on the Tennis dataset using DDIM sampler with a varying number of sampling steps.}
  \label{fig:ddim_sampling_plot}
\end{figure}

In this section, we evaluate our animation model using the DDIM \cite{song2021denoising} sampler with a varying number of timesteps and show results in Fig.~\ref{fig:ddim_sampling_plot}. The DDIM sampler produces samples with a lower number of sampling timesteps with respect to the DDPM \cite{ho2020ddpm} sampler at the cost of higher FD scores, thus providing a tradeoff between inference speed and sample quality. We note that several techniques exist that speed up diffusion model sampling \cite{salimans2022progressive,meng2022on} and that these efforts are orthogonal to our work.
