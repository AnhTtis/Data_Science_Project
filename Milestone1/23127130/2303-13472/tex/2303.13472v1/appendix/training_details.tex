\section{Training Details}

\subsection{Synthesis Model}
\label{ap:training_details_synthesis}
We employ a reduced learning rate of $1e-5$ for the 3D CNNs that model the canonical radiance field voxels $\tensvoxel$ and blending weights $\tensblendweights$ that we find important to improve the learned geometry and avoid artifacts such as holes.

We train our full model on 8 A100 40GB GPUs for 4 days and 2 days respectively on the tennis and Minecraft datasets. We train the reduced version of our model (Ours Small) on 4 A100 40GB GPUs for 3 days and 2 days respectively for the Tennis and Minecraft datasets.

\subsection{Animation Model}
\label{ap:training_details_animation}
We create masks $\vecmask$ and $\vecmaskaction$ by randomly selecting one of the following masking strategies:
\begin{enumerate}[label=\roman*]
\item randomly mask each sequence element with a probability 0.25
\item randomly mask each sequence element with a probability 0.5
\item mask all sequence elements corresponding to a block of consecutive timesteps of random length
\item the complement of (iii)
\item mask all sequence elements corresponding to the last timesteps of the sequence
\item mask all sequence elements corresponding to a randomly chosen set of object properties
\end{enumerate}

With probability 0.5, we set $\vecmaskaction=1$, excluding actions from the masking operation, so that the model can learn to solve (ii), (iii), (iv) also in the scenario where text guidance is provided. We design the masking strategies to mimic masking configurations that are relevant to inference problems such as autoregressive generation (v), unconditional generation (vi), generating opponent responses to user actions (vi), sequence inpainting (iii), sequence outpainting (iv) and framerate increase (iii).

We train our full model on 8 A100 40GB GPUs for 15 days and 10 days respectively on the tennis and Minecraft datasets. We train the reduced version of our model (Ours Small) on 2 A100 40GB GPUs for 6 days and 4 days respectively for the Tennis and Minecraft datasets.