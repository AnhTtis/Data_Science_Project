\section{Introduction}

% 
% 


Advancements in graphics brought new capabilities to game engines. Their primary purpose was to democratize game development but due to the supported features and quality, their impact quickly reached a variety of creative applications spanning AR, VR, data generation~\cite{cao2020gtaim, hoffman2017cycada}, and, most recently, virtual film production\footnote{\href{https://www.unrealengine.com/en-US/solutions/film-television}{Unreal} and \href{https://unity.com/solutions/film-animation-cinematics}{Unity} engines are used to photorealistically render environments for film production.}. 
Building the vast software ecosystem of a game engine is an enormously challenging task and, despite the sophistication reached by such systems, making video games still requires specialized equipment, acquisition of expensive data and 3D assets, and labor of trained experts. There are, however, thousands of videos with games already played and real-world matches spectated.
% \steph{not clear: real or video game, if it's video game why do we want to train a network to do the same job}. 
\emph{Would it be possible to learn a game engine using this data?}  

Many learnable methods focus on reducing the need for manual labor and 3D assets in computer graphics \cite{starke2019neural,starke2020local,holden2017phase,kuang2022neroic,liu2021neural}, but only provide narrow video game functions. % and may require data, such as motion capture, that can only be gathered with specialized equipment.
%Broadly speaking, given a large collection of data, numerous 2D observations of agents interacting with their environments can be obtained.
More related to our work, neural video game simulation methods show that annotated videos can be used to learn to generate videos interactively \cite{Kim2020_GameGan,kim2021drivegan,menapace2021pvg,huang2022layered,davtyan2022glass} and build 3D environments where agents can be controlled through a set of discrete actions \cite{Menapace2022PlayableEnvironments}. While bringing us closer to \emph{learnable game engines}, when applied to complex or real-world environments, these works have several limitations: do not accurately model game logic, do not model physical interactions of objects in 3D space, do not learn fine-grained controls, do not allow for high-level goal-driven control of the game flow, and, finally, do not model game AI.

In this work, we present a framework for building game-engine-like models by observing a handful of annotated videos. Our framework supports a complete set of core game engine functions including rendering from a controllable viewpoint, modeling of game logic and physics, fine-grained character control, and game AI. Due to the versatility of the supported applications (see Sec.~\ref{sec:applications}), we call our framework Learnable Game Engines (LGEs).

To overcome the limitations of \cite{Kim2020_GameGan,kim2021drivegan,huang2022layered,davtyan2022glass,menapace2021pvg, Menapace2022PlayableEnvironments}, %Playable Video Generation \cite{menapace2021pvg} and Playable Environments \cite{Menapace2022PlayableEnvironments} 
not only we model the \emph{states} of an environment, but we also consider detailed textual representations of the actions taking place in it.  We argue that training on user commentaries describing detailed actions of a game greatly facilitates learning the game's logic and game AI---important parts of our LGEs---and that such commentaries are a key component in enabling a series of important model capabilities related to fine-grained character control and high-level goal-driven control of the game flow.

%Such information is key for the model to gain an understanding of the dynamics of the environment \willi{make stronger} and to enable many significant capabilities.

%and enables our LGE to perform high-level game-specific scenarios or scripts, specified by means of \emph{natural language} and \emph{desired states of the environment}, as in Fig.~\ref{fig:teaser}.

 In its simplest form, for games like
 %Minecraft, this allows the user to instruct the player to perform sequences of actions such as \emph{``Jump onto a birch pole and run through the stairs''}, while for
 tennis, this enables controlling each player in a fine-grained manner with instructions such as \emph{``hit the ball with a backhand and send it to the right service box''}.
%Training with language enables our model to deeply understand semantic parts of the environment in which the game is played. For example, the model learns the locations of certain \textit{parts} of the environment, as well as the sequence of actions necessary to end up in these locations. In tennis, our LGE understands the locations of the left \& right service boxes, no-man's land, and so on. %Interestingly, these inferences are made from language and language alone---a remarkable finding also highlighted in PartGlot \cite{koo2022partglot}.
Moreover, language enables users to take the \emph{director's mode} and perform high-level game-specific scenarios or scripts, specified by means of \emph{natural language} and \emph{desired states of the environment}. As an example, given desired starting and ending states, our learned game engines can devise in-between scenarios that led to the observed outcome. Most interestingly, as shown in Fig.~\ref{fig:teaser}, given the initial states of a real tennis video in which a player lost a point, our LGE prompted by the command \emph{“the [other] player does not catch the ball”} can perform the necessary action to win the point.

% \steph{To overcome the poor expressiveness of control based on discrete actions, we instruct our} learned game engine to perform high-level game-specific scenarios or scripts \willi{specified by means of \emph{natural language} and \emph{desired states of the environment}, as in Fig.~\ref{fig:teaser}}. \willi{In its simplest form,} for games like Minecraft, this allows the user to instruct the player to perform sequences of actions such as “Jump onto a birch pole and run through the stairs”. For tennis, this would mean providing a high-level goal to a player to hit or miss a score, or requesting a player to send the ball into a specific part of the field. \willi{However, more complex applications are unlocked. As an example,} given desired starting and ending states, learned game engines can \steph{sample} in-between scenarios that led to the observed outcome. Besides these generation tasks, they can semantically manipulate the actions of a player in \emph{existing videos}. Most interestingly, as shown in Fig.~\ref{fig:teaser}, \willi{given the initial states of} a real tennis video in which a player lost a point, our LGE prompted by the command “the other player does not catch the ball” can perform the necessary action to win the point.


%Given starting and ending frames, LGEs can in-between scenarios that led to the observed outcome. Besides these generation tasks, LGEs can semantically manipulate actions of a player in \emph{existing videos}. Most interestingly, as shown in Fig.~\ref{fig:teaser}, given a real tennis video in which a player lost a point, our method prompted by a command “the other player does not catch the ball” can perform the necessary action to win the point.

%Real-world data of matches can reveal the dynamics and semantics of an underlying game. Differently from previous work, our LGEs can efficiently discover and learn such dynamics and semantics. While the task is challenging for a machine learning system, an experienced spectator can explain the strategy selected by a particular player with ease and sometimes even propose an advantageous course of actions. We argue that training on user commentaries, describing detailed actions of a game greatly facilitates learning game AI---an important part of our LGEs. Most captivating, game AI brings interesting creative capabilities at inference time. Not only does it allow the user to play a game by providing commands, moving the camera, and changing the style, but it also unlocks the “director's mode” where the observer can “plot behind the scenes” by providing high-level, goal-driven instructions to the player. The game engine then leverages its knowledge of the learned physics and semantics of the game to perform action reasoning in time and generate videos that satisfy the director's instructions.
%\panos{again, does experimentally doing this with more than one possible actions? if so state/imply it}.
%This makes our framework capable of generating complex sequences of actions.
%actions in time.\panos{in time for what?}
%Besides that, training with language enables our model to deeply understand semantic parts of the environment in which the game is played. For example, the model learns the locations of certain \textit{parts} of the environment, as well as the sequence of actions necessary to end up in these locations. In tennis, our LGE understands the locations of the left \& right service boxes, no-man's land, and so on. Similarly in Minecraft, the locations of gold, birch, and decorated poles are known to the model. Interestingly, these inferences are made from language and language alone---a remarkable finding also highlighted in PartGlot \cite{koo2022partglot}.

Broadly speaking, a game maintains states of its environments \cite{Stanton2016,starke2019neural,Curtis2022}, renders them using a controllable camera, and evolves them according to user commands, actions of non-playable characters controlled by the game AI, and the game's logic. 
Our Learnable Game Engines follow this high-level structure highlighted in Fig.~\ref{fig:teaser}. Our synthesis model maintains a state for every object and agent included in the game and renders them in the image space using the compositional NeRF~\cite{mildenhall2020nerf} of~\cite{Menapace2022PlayableEnvironments} followed by a learnable enhancer for superior rendering quality. 
To model the logic of games and game AI that determine the evolution of the environment states, we introduce an animation model. Specifically, inspired by~\cite{han2022show}, we train a \emph{non-autoregressive} \emph{text-conditioned} diffusion model which leverages masked sequence modeling to enable the fine-grained conditioning capabilities on which the above-mentioned applications are based. In particular, we show that using text labels describing actions happening in a game is instrumental in learning such capabilities.  While certain prior work~\cite{Kim2020_GameGan,kim2021drivegan,menapace2021pvg,Menapace2022PlayableEnvironments} explored maintaining and rendering states of games, we are not aware of any generative method that attempts enabling fine-grained control, modeling sophisticated goal-driven game logic, and learning game AI to the extent explored in this paper.

%Learning such an "AI" is challenging as there exists no data with the desired, or "right" actions in a game, as many strategies can lead to a successful outcome.
%\willi{Slightly unclear. When observing tennis videos we have expert trajectories and we may consider them "right (although unlabeled) actions". The main problem is how to create from them a model where we can express interesting conditioning on such data and text is the tool to solve it.}
%We show that such a sophisticated game AI can be efficiently learned by using text labels describing actions happening in a game.
%To this end, we collect two large monocular video datasets annotated with a diverse corpus of text descriptions.
%Specifically, inspired by~\cite{han2022show}, we train a \emph{non-autoregressive} \emph{text-conditioned} diffusion model using masking, called the animation model. Our animation model successfully learns game AI and, at inference time, is capable of performing exciting tasks discussed above. 

The task of playing games and manipulating videos in the \emph{director's mode} has not been previously introduced in the literature. With this work, we attempt to introduce the task and set up a solid framework for future research. To do that, first and crucially, we collected two monocular video datasets. The first one is the Minecraft dataset containing 1.2 hours of videos, depicting a player moving in a complex environment.  %We provide camera calibration, 3D player poses, and a text caption for each frame describing whether the player is walking, running, jumping over platforms and walls, falling or climbing ladders, and using referential language to indicate the different parts of the environment.
%In addition, we will release the code to automatically extract such annotations from Minecraft.
The second one is a large-scale real-world dataset with 15.5 hours of high-resolution professional tennis matches. For each frame in these datasets, we provide accurate camera calibration, 3D player poses, ball localization and, most importantly, diverse and rich text descriptions of the actions performed by each player in each frame. %The dataset contains 1.12M frames for which we obtain accurate camera calibration, SMPL~\cite{loper2015smpl} body parameters for each player, 3D ball localization, and, most importantly, 84.1k diverse and rich manually-annotated text descriptions of the actions performed by each player in each frame. Such captions make use of %We manually \panos{further?} annotate such \panos{natural?} captions using
%technical language that describes where and how each player moves, how the ball is hit, and where it is sent. 
%\willi{tennis high resolution with professional matches from main tournaments 15hours 9.7M frames aligned captions and specific technical terms} dataset, for which we obtained accurate camera calibration and, most importantly, diverse and rich text descriptions of actions happening in videos. \sergey{some info here}.

%In terms of rendering quality, our framework outperforms prior works by a large margin, producing videos at the original frame rate and doubling the output resolution with respect to \cite{Menapace2022PlayableEnvironments}. In terms of game AI, our work is the first that unlocks goal-driven game playing and sets an important stepping stone towards learning game engines and AI for diverse real-world videos. 

In summary, our work brings the following contributions:
\begin{itemize}
\item A novel framework to build Learnable Game Engines from annotated monocular videos. It supports detailed rendering of high-resolution, high-frame rate videos of scenes with articulated objects from arbitrary viewpoints. It can generate fine-grained actions specified by text prompts, model opponents, and perform goal-driven generation of complex action sequences. As far as we are aware, no existing work provides this set of capabilities under comparable data assumptions.
\item A synthesis model, based on a compositional NeRF, producing videos at the original frame rate and doubling the output resolution with respect to \cite{Menapace2022PlayableEnvironments}.
\item An animation model, based on a text-conditioned diffusion model with a masked training procedure, which is key to support complex game logic, object interactions, game AI, and understanding fine-grained actions. It unlocks applications currently out of reach of state-of-the-art neural video game simulators (see Sec.~\ref{sec:applications}). 
\item A large-scale 15h Tennis and a 1h Minecraft video datasets with camera calibration, 3D player poses, 3D ball localization, and detailed text captions.
\end{itemize}

%In summary, we propose the following contributions:
%\begin{itemize}
%\item A novel framework for the construction of Learnable Game Engines from annotated videos that supports detailed rendering of high-resolution, high-framerate videos of scenes with articulated objects and scene-specific elements such as blurred balls and rackets from a controllable viewpoint, fine-grained control over the generation using textual actions, modeling of opponents, and goal-driven generation of complex sequences.
%\item A compositional NeRF-based synthesis model outperforming state-of-the-art in terms of synthesis quality
%\item A text-conditioned diffusion model a with masked training procedure that is key to support modeling of complex game logic and object interactions and to enable complex applications (See Sec.~\ref{XXXXXX}) currently out of reach of state-of-the-art neural video game simulators.
%\item A large-scale 15h Tennis and a 1h Minecraft video dataset with camera calibration, 3D player poses, 3D ball localization, and detailed text captions describing the action performed by each player in each frame.
%\end{itemize}