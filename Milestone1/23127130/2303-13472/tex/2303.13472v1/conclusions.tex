
\section{Conclusions}

In this paper, we demonstrate the feasibility of learning game engines solely from annotated data and show that textual action representations are critical for unlocking high-level and fine-grained control over the generation process, and enabling compelling constraint- and goal-driven generation applications. These results, jointly with two richly-annotated text-video datasets, pave the way towards learning game engines for complex, real-world scenes.

\section{Acknowledgements}
We would like to thank Denys Poluyanov, Eugene Shevchuk and Oleksandr Pyshchenko for the useful discussion and validation of the use cases of the LGE framework, Maryna Diakonova for her support in data labeling, and Anton Kuzmenko and Vadym Hrebennyk for their assistance in creating the accompanying video.
