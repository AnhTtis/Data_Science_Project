\section{Additional Evaluation}
\label{ap:evaluation}

\subsection{Robustness to prompt variations}
\label{ap:language_robustness}
We perform a study on the Tennis dataset to evaluate the capability of our animation model to support diverse language prompts. We randomly sampled 50 prompts from our tennis dataset and asked \emph{ChatGPT to ``Produce a semantically equivalent reformulation of the prompt ‘<prompt>’''}. The sentence similarity between original and reformulated prompts measured by Jaccard similarity on their 3-grams is 0.390, while it is 0.203 for random dataset prompt pairs, indicating high diversity. As an example, the prompt \emph{``the player stops and quickly runs to the right and hits the ball with a backhand towards the center of no man's land''} is reformulated to \emph{``The player comes to a stop and rapidly sprints towards the right before executing a backhand stroke that directs the ball towards the center of no man's land''}, and prompt \emph{``the player prepares to hit the ball but stops, returning ball hits the net''} is transformed to \emph{``The player readies themselves to strike the ball, but abruptly halts and as a result, the returned ball collides with the net''}.

Successively, we run an AMT user study. Users are shown a video and two prompts (the true prompt used to produce the video, and a random negative prompt) and they are asked to recognize which of two prompts is the one used to produce a certain video. The average accuracy over 500 responses is $74.4\%$ and $77.1\%$ for videos produced using reformulated and dataset prompts respectively, indicating capability of the model to generate videos matching prompts independently from the form of the used language.

The model trained on Minecraft allows for limited prompt variation due to the synthetic nature of the training language whose limited variation does not enable the model to learn generalization capabilities to different sentence structures as the ones acquired for Tennis. This limitation could be addressed by improving the synthetic language generation process, which we leave as future work.


\subsection{Animation Model Evaluation}
\label{ap:animation_evaluation}
In Tab.~\ref{table:animation_tennis} and Tab.~\ref{table:animation_minecraft} we show evaluation results for each inference task respectively on the Tennis and Minecraft datasets. In Fig.~\ref{fig:animation_ablation_qualitatives_minecraft} we show qualitative results on the Minecraft dataset.

\input{tables/table_animation_tennis}
\input{tables/table_animation_minecraft}

\begin{figure}
\includegraphics{resources/animation_ablation_qualitatives_minecraft}
  \caption{Qualitatives results on the Minecraft dataset. Sequences are produced in a video prediction setting that uses the first frame object properties and all actions as conditioning.}
  \label{fig:animation_ablation_qualitatives_minecraft}
\end{figure}

\subsection{Animation Model Masking Strategies Ablation}
\label{ap:animation_model_masking_strategies_ablation}

\change{In Tab.~\ref{table:animation_tennis_masking_ablation}, we ablate the contribution of the animation model training masking strategies (see Sec.~\ref{ap:training_details_animation}) on the Tennis dataset. We group the masking strategies in four groups of semantically-related strategies: ``Random'' (i + ii) which masks random sequence elements, ``Block'' (iii + iv) which masks blocks of contiguous timesteps, ``Last'' (v) which masks the last timesteps of the sequence, ``Opponent'' (vi) that masks a randomly chosen set of properties in the whole sequence.}

\change{The use of only the ``Random'' masking strategy results in the worst performance as the model only learns to interpolate between adjacent values and fails on tasks requiring long predictions. Adding the ``Block'' strategy enables the model to learn how to interpolate between values separated by larger gaps, producing good results in the sequence completion task. The addition of the ``Last'' training strategy enables the model to learn how to produce future states from a given initial one, improving the results on both video prediction tasks. The ``Opponent'' masking strategy enables the model to recover properties that are missing in the whole sequence, enabling best performance on the opponent modeling task. Finally, combining all masking strategies enables the model to jointly learn these capabilities, producing the best results.}

\input{tables/table_animation_tennis_masking_ablation}

\subsection{Animation Model Dataset Size Ablation}
\label{ap:animation_model_dataset_size_ablation}

\change{In Tab.~\ref{table:animation_data_ablation_tennis}, we analyze the performance of the animation model as a function of the available portion of the training data on the Tennis dataset. The model performance gradually reduces as the amount of training data shrinks. When the amount of available training data falls below $60\%$ of the original dataset size, the model overfits to the training data, yielding poor performance.}

\input{tables/table_animation_data_ablation_tennis}


\subsection{Alternative Samplers}
\begin{figure}
\includegraphics[width=\columnwidth]{resources/ddim_sampling_plot}
  \caption{Evaluation results for our method on the Tennis dataset using DDIM sampler with a varying number of sampling steps.}
  \label{fig:ddim_sampling_plot}
\end{figure}

In this section, we evaluate our animation model using the DDIM \cite{song2021denoising} sampler with a varying number of timesteps and show results in Fig.~\ref{fig:ddim_sampling_plot}. The DDIM sampler produces samples with a lower number of sampling timesteps with respect to the DDPM \cite{ho2020ddpm} sampler at the cost of higher FD scores, thus providing a tradeoff between inference speed and sample quality. We note that several techniques exist that speed up diffusion model sampling \cite{salimans2022progressive,meng2022on} and that these efforts are orthogonal to our work.
