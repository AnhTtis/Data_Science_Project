\section{Applications}
\label{ap:applications}

\begin{figure*}
\includegraphics[width=\textwidth]{resources/style_swap}
  \caption{Style swap results on the Tennis and Minecraft datasets. We produce the central image by swapping the style code $\vecstyle$ for the players on the leftmost image with the ones from the rightmost image. Minecraft results are cropped for better visualization.}
  \label{fig:style_swap}
\end{figure*}

\begin{figure*}
\includegraphics[width=\textwidth]{resources/camera_manipulation_qualitatives.pdf}
  \caption{Camera manipulation results on the Tennis and Minecraft datasets. The lack of camera translation on the Tennis dataset does not allow to capture the 3D geometry of static objects, which is replaced by a prior \cite{Menapace2022PlayableEnvironments}. Minecraft results are cropped for better visualization.}
  \label{fig:camera_manipulation_qualitatives}
\end{figure*}

To demonstrate style swapping capabilities, in Fig.~\ref{fig:style_swap} we swap the style of the player $\vecstyle$ in the original image with the one from a target image. In addition, our synthesis model renders the current state of the environment from a user-defined perspective, similarly to the rendering component of a game engine. This enables our QGE to perform novel view synthesis as shown in Fig.~\ref{fig:camera_manipulation_qualitatives}.