\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{natbib} 
\usepackage{url} 
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{float}
\RequirePackage[dvipsnames]{xcolor}
\usepackage{mathptmx}
\usepackage{breqn}

\renewcommand{\thesection}{\Alph{section}}

\setcounter{table}{0}
\renewcommand{\thetable}{S\arabic{table}}%
\setcounter{figure}{0}
\renewcommand{\thefigure}{S\arabic{figure}}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%\\
\addtolength{\topmargin}{-1in}%

\bibliographystyle{apalike}

\numberwithin{equation}{section}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
% \newcommand{\Pr}{\text{Pr}}

\newcommand{\RC}[2]{\mathrm{RC}_{#2}(#1)}
\def\CB#1{{\textcolor{Green}{[CB: #1]}}}
\def\CBnew#1{{\textcolor{Cyan}{ #1}}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{property}{Property}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


\title{\bf Supplementary Material for ``Improving estimation for asymptotically independent bivariate extremes via global estimators for the angular dependence function"}
\author{C. J. R. Murphy-Barltrop$^{1*}$, J. L. Wadsworth$^2$ and E. F. Eastoe$^2$\\
\small $^1$STOR-i Centre for Doctoral Training, Lancaster University LA1 4YR, United Kingdom \\
\small $^2$Department of Mathematics and Statistics, Lancaster University LA1 4YF, United Kingdom \\
\small $^*$Correspondence to: c.barltrop@lancaster.ac.uk}
\date{\today}

\maketitle



\bigskip

\spacingset{1.8}

% \section{Constrained polynomial coefficients to satisfy the ADF lower bound}
% The family of polynomials presented in Section 2 of the main article can be adapted to ensure the resulting estimates of the ADF satisfy the theoretical lower bound: $\lambda(w) \geq \max(w,1-w)$ for all $w \in [0,1]$. This is done by considering the following family of functions:
% \begin{equation} \label{eqn:constr_BP}
%     \mathcal{B}^{\wedge}_k = \left\{ f \in \mathcal{B}^{*}_k :  f(w) \geq \max(w,1-w) \; \text{for all} \; w \in [0,1] \right\}.
% \end{equation}
% Functions in this family will satisfy all theoretical constraints for the ADF, and can be used for estimating the coefficient vector $\pmb{\beta}$ using the techniques introduced in Section 2.2 of the main article. However, we have found that in practice, they perform than the corresponding estimates from the unconstrained counterparts. This is likely due to the higher degree of variability within the latter, allowing one to capture a wider range of dependence structures. 

% However, in practice, we found ADF estimates from a constrained approach to perform worse than the unconstrained counterpart, owing to the reduced flexibility in parameter estimation; see the Supplementary Material for further details. 

% This finding is illustrated for three copula examples in the Figure below. One can observe in every case, the ISE values for the unconstrained polynomials are lower than the constrained versions, implying lower bias for the former for these particular examples. 

\section{Example ADF estimates}
Examples of ADF estimates obtained using each of the estimators discussed in the main article are given in Figure \ref{fig:ADF_estimates_examples} for a bivariate Gaussian copula with $\rho = 0.5$. The different estimates are in good agreement, and one can observe the roughness in estimates obtained via the Hill estimator. 
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.6\textwidth]{Supplementary/ADF_estimates_example.pdf}
    \caption{ADF estimates from each of the estimators discussed in the main article. Red represents the true ADF, with the theoretical lower bound given by the dotted black lines.}
    \label{fig:ADF_estimates_examples}
\end{figure}


\section{Example boundary set estimates}

Figure \ref{fig:gauge_estimates} illustrates estimates of the boundary set $G$ obtained using the technique proposed in \citet{Simpson2022} for three copula examples. 

% Figure \ref{fig:gauge_estimates} illustrates estimates of the boundary set $G$ obtained using the techniques proposed in \citet{Simpson2022} and \citet{Wadsworth2022} for three copula examples. 
% One can observe that for the logistic copula, which exhibits asymptotic dependence, neither estimation procedure appears flexible enough to accurately capture the true underlying dependence structure. In the other two copula examples, the estimates appear similar to the true limit sets. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/example_gauge_estimates.pdf}
    \caption{The boundary set $G$ (given in red) for three copula examples, with estimates from \citet{Simpson2022} given in green. Left: bivariate Gaussian copula with correlation coefficient $\rho = 0.5$. Centre: inverted logistic copula with dependence parameter $r = 0.8$. Right: logistic copula with dependence parameter $r = 0.8$. In each plot, the coordinate limits of $G$ are denoted by the black dotted lines.}
    \label{fig:gauge_estimates}
\end{figure}

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\textwidth]{Supplementary/example_gauge_estimates.pdf}
%     \caption{The boundary set $G$ (given in red) for three copula examples, with estimates from \citet{Simpson2022} and \citet{Wadsworth2022} given in green and blue, respectively. Left: bivariate Gaussian copula with correlation coefficient $\rho = 0.5$. Centre: inverted logistic copula with dependence parameter $r = 0.8$. Right: logistic copula with dependence parameter $r = 0.8$. In each plot, the theoretical boundary of the limit set $G$ is denoted by the black dotted lines.}
%     \label{fig:gauge_estimates}
% \end{figure}


\section{Tuning parameter selection}
Figures \ref{fig:rmise_est_cl} and \ref{fig:rmise_est_pr} illustrate plots of scaled RMISE estimates against the polynomial degree $k$ for the estimators $\hat{\lambda}_{CL}$ and $\hat{\lambda}_{PR}$, respectively. RMISE was estimated using Monte-Carlo techniques: first, for each $j = 1, 2, \hdots, N$, where $N=200$ denotes the number of samples, the ISE was estimated via the trapezium rule, i.e.,
\begin{equation*}
    \widehat{\text{ISE}}\left(\hat{\lambda}_j\right) = \frac{0.001}{2} \left( (\hat{\lambda}_j(0) - \lambda(0))^2 + \sum_{w \in \mathcal{W}\setminus\{0,1\}}2(\hat{\lambda}_j(w) - \lambda(w))^2 + (\hat{\lambda}_j(1) - \lambda(1))^2 \right),
\end{equation*}
where $\hat{\lambda}_j$ denotes the ADF estimate for sample $j$ and $\mathcal{W}$ denotes the set of rays spanning the interval $[0,1]$, as defined in Section 3.4 the main article. An estimate of the RMISE is then given by
\begin{equation*}
    \widehat{\text{RMISE}} = \sqrt{\frac{1}{N}\sum_{j=1}^N\widehat{\text{ISE}}\left(\hat{\lambda}_j\right)}.
\end{equation*}
For the polynomial degree, we considered $k \in \{2,3,\hdots,11\}$; higher values of $k$ were not considered due to computational complexity. The left and right panels of Figures \ref{fig:rmise_est_cl} and \ref{fig:rmise_est_pr} correspond to Gaussian copulas exhibiting strong ($\rho = 0.9$) and weak ($\rho=0.1$) positive dependence, respectively.   

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/rmise_cl_plots.pdf}
    \caption{RMISE estimates (multiplied by 100) over $k$ obtained for $\hat{\lambda}_{CL}$ using $N=200$ from Gaussian copulas with strong (left, $\rho=0.9$) and weak (right, $\rho=0.1$) positive dependence.}
    \label{fig:rmise_est_cl}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/rmise_pr_plots.pdf}
    \caption{RMISE estimates (multiplied by 100) over $k$ obtained for $\hat{\lambda}_{PR}$ using $N=200$ from Gaussian copulas with strong (left, $\rho=0.9$) and weak (right, $\rho=0.1$) positive dependence.}
    \label{fig:rmise_est_pr}
\end{figure}

One can observe that, for the strongly dependent example, the RMISE estimates tend to decrease as the value of $k$ increases. This is in agreement with findings for the PDF \citep[e.g.,][]{Marcon2017a,Vettori2018}; strongly dependent copulas require a higher degree of flexibility to capture the triangle-like shapes of the resulting dependence functions. 

On the other hand, for the weakly dependent Gaussian copula, the value of $k$ made little difference to the resulting RMISE estimates. There is even a slight increase in RMISE estimates for higher values of $k$; this suggests that having a higher polynomial degrees for such data structures may lead to over-fitting. 

In practice, we set $k=7$; this value is sufficient for obtaining low RMISE estimates under both copula examples. Furthermore, for the strongly dependent Gaussian copula, the reduction in RMISE values above this value of $k$ are very marginal. This polynomial degree therefore appears to offer sufficient flexibility without high computational burden and/or parameter variability.  


% In this section, we present our methodology for selecting the tuning parameters of the estimators described in Sections 2.2.1 and 2.2.2. For both estimators, we consider polynomial degrees $k \in \{3,5,7,9,11\}$, corresponding to functions with varying degrees of flexibility. 

% For the estimator $\hat{\lambda}_{CL}$, we consider probabilities $q \in \{0.71,0.73,\hdots,0.85\}$, while for the estimator $\hat{\lambda}_{PR}$, we consider the probability sets of the form:
% \begin{equation} \label{eqn:prob_set}
%     \{q_{j}\}^m_{j = 1} \subset [r,r+0.04], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.05, j = 1, \ldots, m\}, 
% \end{equation} 
% with $m=30$ and $\{q_{j}\}^m_{j = 1}$ denoting subsets of equally spaced points within the interval $[r,r+0.04]$, with $r \in \{0.75, 0.77, \hdots, 0.89\}$. This results in eight different choices of probabilities for both estimators. Higher probability values were also considered but did not give any improvement in terms of bias or variance. The same conclusion was true when different gaps between the quantile sets $\{q_{j}\}^m_{j = 1}$ and $\{p_{j}\}^m_{j = 1}$, along with different values for $m$, were considered for the estimator $\hat{\lambda}_{PR}$. 

% Figures \ref{fig:ise_est_cl} and \ref{fig:ise_est_pr} illustrate scaled ISE estimates for each tuning parameter combination as a function of the polynomial degree $k$. For both estimators, one can observe that for the copula with strong positive dependence, higher $k$ values are preferable, whereas the opposite appears to be true in the case of weak positive dependence. Setting $k=7$ appears to be a reasonable choice to account for this trade-off, and in the strongly dependent example, improvements in the ISE above this value appear to be very marginal. Moreover, there was a significantly higher computational burden for $k=9$ and $k=11$, further justifying this choice. 

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\textwidth]{Supplementary/ise_cl_plots.pdf}
%     \caption{ISE estimates of $\hat{\lambda}_{CL}$ (scaled by 1000) for both Gaussian copulas as a function of the Bernstein-B\'ezier polynomial degree $k$. The different colours of lines represent the varying probability values, with blue and red giving the lowest and highest considered probability values, respectively.}
%     \label{fig:ise_est_cl}
% \end{figure}

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\textwidth]{Supplementary/ise_pr_plots.pdf}
%     \caption{ISE estimates of $\hat{\lambda}_{PR}$ (scaled by 1000) for both Gaussian copulas as a function of the Bernstein-B\'ezier polynomial degree $k$. The different colours of lines represent the varying probability values, with blue and red giving the lowest and highest considered probability values, respectively.}
%     \label{fig:ise_est_pr}
% \end{figure}

% Fixing $k=7$, we consider the selection of the probabilities $q$ and $r$. Figures \ref{fig:rmse_est_cl} and \ref{fig:rmse_est_pr} display plots of scaled RMSE estimates for the estimators $\hat{\lambda}_{CL}$ and $\hat{\lambda}_{PR}$, respectively, for both Gaussian copulas at each ray $w \in \{0.1,0.3,0.5,0.7,0.9\}$ as a function of probability values. For the $\hat{\lambda}_{CL}$ estimator, higher probabilities tended to give higher RMSE values; however, this was not the case for all of the considered rays. Furthermore, the RMSE estimates appear close for the majority of probabilities and rays considered. We therefore set $q=0.79$, since this value appears to give consistently low RMSE estimates (relative to the other probabilities) across each of the considered rays.

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\textwidth]{Supplementary/rmse_cl_individual_plots.pdf}
%     \caption{RMSE estimates of $\hat{\lambda}_{PR}$ (scaled by 100) for both Gaussian copulas as a function of the probability level $q$. The different colours of points represent the varying probability values, with blue and red giving the lowest and highest considered probability values, respectively.}
%     \label{fig:rmse_est_cl}
% \end{figure}

% For the $\hat{\lambda}_{PR}$ estimator, no obvious trends can be observed in the RMSE estimate. Reassuringly, the estimates appear similar across each of the angles and copula pairings. We therefore set $r = 0.83$, with the corresponding probability set given by equation \eqref{eqn:prob_set}, as our default suggestion, .   

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=\textwidth]{Supplementary/rmse_pr_individual_plots.pdf}
%     \caption{RMSE estimates of $\hat{\lambda}_{PR}$ (scaled by 100) for both Gaussian copulas as a function of the probability level $r$. The different colours of points represent the varying probability values, with blue and red giving the lowest and highest considered probability values, respectively.}
%     \label{fig:rmse_est_pr}
% \end{figure}

% The selected tuning parameters estimates appear to appropriately account for both of the aforementioned trade-offs, whilst also being able to capture both strong and weak positive extremal dependence. The selected values should therefore be able to capture the range of extremal dependence structures consider in Section 3.4 of the main article. 

\section{Additional simulation study results}

The ISB and IV estimates for each estimator are given in Tables \ref{table:ISB_values} and \ref{table:IV_values}. One can observe that, while the $\hat{\lambda}_{ST}$ appears to perform best in terms of ISB, the estimators derived using the composite likelihood function ($\hat{\lambda}_{CL}$ and $\hat{\lambda}_{CL2}$) exhibit the least IV for eight out of the nine copula examples. For the most part, one can observe similar ISB and IV values across the different estimators. 

\renewcommand{\arraystretch}{1.5}
\begin{table}[!h]

\caption{ISB values (multiplied by 1,000) for each estimator and copula combination. Smallest ISB values in each row are highlighted in bold, with values reported to 3 significant figures.
\label{table:ISB_values}}
\centering
\begin{tabular}[t]{c|c|c|c|c|c|c|c}
\hline
Copula & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$\\
\hline
Copula 1 & \textbf{371} & 374 & 436 & 374 & 380 & 442 & 402\\
\hline
Copula 2 & 0.361 & 0.378 & 0.468 & 0.34 & 0.338 & 0.416 & \textbf{0.00815}\\
\hline
Copula 3 & 0.779 & 0.883 & 1.07 & 0.762 & 0.771 & 0.946 & \textbf{0.0181}\\
\hline
Copula 4 & 1.74 & 1.95 & 4.25 & 1.5 & 1.49 & 3.22 & \textbf{0.299}\\
\hline
Copula 5 & 19.2 & 19.3 & 28.4 & 19.1 & 19.1 & 28.1 & \textbf{13.6}\\
\hline
Copula 6 & 0.0012 & 0.0526 & 0.0683 & \textbf{0.000954} & 0.00324 & 0.00531 & 0.0045\\
\hline
Copula 7 & \textbf{0.000917} & 0.00709 & 0.0131 & 0.00161 & 0.00276 & 0.00467 & 0.55\\
\hline
Copula 8 & 0.047 & 0.622 & 0.664 & \textbf{0.00728} & 0.00903 & 0.0186 & 0.0755\\
\hline
Copula 9 & 13.8 & 13.8 & 21.3 & 13.7 & 13.7 & 21.1 & \textbf{10.9}\\
\hline
\end{tabular}
\end{table}

\begin{table}[!h]

\caption{IV values (multiplied by 1,000) for each estimator and copula combination. Smallest IV values in each row are highlighted in bold, with values reported to 3 significant figures.
\label{table:IV_values}}
\centering
\begin{tabular}[t]{c|c|c|c|c|c|c|c}
\hline
Copula & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$\\
\hline
Copula 1 & 2.6 & \textbf{2.02} & 2.11 & 3.51 & 3.29 & 3.18 & 4.7\\
\hline
Copula 2 & 0.9 & \textbf{0.732} & 0.859 & 0.889 & 0.769 & 0.904 & 0.863\\
\hline
Copula 3 & 0.652 & 0.328 & 0.401 & 0.311 & 0.267 & 0.33 & \textbf{0.1}\\
\hline
Copula 4 & 0.657 & 0.352 & 0.536 & 0.324 & \textbf{0.315} & 0.588 & 0.468\\
\hline
Copula 5 & 0.808 & \textbf{0.651} & 0.841 & 0.793 & 0.707 & 0.933 & 1.07\\
\hline
Copula 6 & 0.628 & 0.337 & 0.395 & 0.4 & \textbf{0.299} & 0.356 & 0.445\\
\hline
Copula 7 & 0.855 & \textbf{0.692} & 0.817 & 0.821 & 0.702 & 0.831 & 1.02\\
\hline
Copula 8 & 0.571 & 0.119 & 0.206 & 0.0363 & \textbf{0.0269} & 0.0437 & 0.273\\
\hline
Copula 9 & 0.799 & \textbf{0.696} & 0.895 & 0.839 & 0.761 & 0.98 & 1.28\\
\hline
\end{tabular}
\end{table}

% \begin{table}[!h]

% \caption{ISB values (scaled by 1,000) for each estimator and copula combination. Smallest ISB values in each row are highlighted in bold, with values reported to 3 significant figures.
% \label{table:ISB_values}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Copula & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% Copula 1 & 371 & 374 & 436 & 374 & 380 & 442 & 402 & \textbf{333}\\
% \hline
% Copula 2 & 0.361 & 0.378 & 0.468 & 0.34 & 0.338 & 0.416 & \textbf{0.00815} & 0.208\\
% \hline
% Copula 3 & 0.779 & 0.883 & 1.07 & 0.762 & 0.771 & 0.946 & \textbf{0.0181} & 0.0461\\
% \hline
% Copula 4 & 1.74 & 1.95 & 4.25 & 1.5 & 1.49 & 3.22 & \textbf{0.299} & 0.567\\
% \hline
% Copula 5 & 19.2 & 19.3 & 28.4 & 19.1 & 19.1 & 28.1 & \textbf{13.6} & 27.8\\
% \hline
% Copula 6 & 0.0012 & 0.0526 & 0.0683 & \textbf{0.000954} & 0.00324 & 0.00531 & 0.0045 & 0.541\\
% \hline
% Copula 7 & \textbf{0.000917} & 0.00709 & 0.0131 & 0.00161 & 0.00276 & 0.00467 & 0.55 & 2.42\\
% \hline
% Copula 8 & 0.047 & 0.622 & 0.664 & \textbf{0.00728} & 0.00903 & 0.0186 & 0.0755 & 69.9\\
% \hline
% Copula 9 & 13.8 & 13.8 & 21.3 & 13.7 & 13.7 & 21.1 & \textbf{10.9} & 89.6\\
% \hline
% \end{tabular}
% \end{table}

% \begin{table}[!h]

% \caption{IV values (scaled by 1,000) for each estimator and copula combination. Smallest IV values in each row are highlighted in bold, with values reported to 3 significant figures.
% \label{table:IV_values}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Copula & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% Copula 1 & 2.6 & \textbf{2.02} & 2.11 & 3.51 & 3.29 & 3.18 & 4.7 & 4.59\\
% \hline
% Copula 2 & 0.9 & \textbf{0.732} & 0.859 & 0.889 & 0.769 & 0.904 & 0.863 & 0.924\\
% \hline
% Copula 3 & 0.652 & 0.328 & 0.401 & 0.311 & 0.267 & 0.33 & 0.1 & \textbf{0.0536}\\
% \hline
% Copula 4 & 0.657 & 0.352 & 0.536 & 0.324 & \textbf{0.315} & 0.588 & 0.468 & 0.669\\
% \hline
% Copula 5 & 0.808 & \textbf{0.651} & 0.841 & 0.793 & 0.707 & 0.933 & 1.07 & 1.52\\
% \hline
% Copula 6 & 0.628 & 0.337 & 0.395 & 0.4 & \textbf{0.299} & 0.356 & 0.445 & 1.49\\
% \hline
% Copula 7 & 0.855 & \textbf{0.692} & 0.817 & 0.821 & 0.702 & 0.831 & 1.02 & 0.937\\
% \hline
% Copula 8 & 0.571 & 0.119 & 0.206 & 0.0363 & \textbf{0.0269} & 0.0437 & 0.273 & 9.26\\
% \hline
% Copula 9 & 0.799 & \textbf{0.696} & 0.895 & 0.839 & 0.761 & 0.98 & 1.28 & 3.22\\
% \hline
% \end{tabular}
% \end{table}
 
\section{Additional case study figures}

This section contains additional figures for the case study detailed in Section 4 of the main article. Figure \ref{fig:river_flow_time_series} illustrates daily river flow time series for each of the six gauges in the north of England, UK. These series suggest a stationarity assumption is reasonable for the extremes of each data set. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/time_series.pdf}
    \caption{Daily river flow time series for the six gauges in the north of England, UK.}
    \label{fig:river_flow_time_series}
\end{figure}

Figure \ref{fig:qq_plots} illustrates the QQ plots from the fitted GPDs at each of the six gauges. One can observe that, in each case, the majority of points lie close to the $y=x$ line, indicating the fitted models capture the upper tails well. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/qq_plots_uncertainty.pdf}
    \caption{QQ plots for each of the fitted GPDs at each of the six gauges. Estimates are given in black, with 95\% pointwise confidence intervals represented by the grey shaded regions. The red line corresponds to the $y=x$ line. The corresponding threshold quantile levels are given in the subtitle of each plot.}
    \label{fig:qq_plots}
\end{figure}

Figures \ref{fig:adf_diag2} and \ref{fig:adf_diag3} illustrate the ADF QQ plots for the first pair of gauges using the estimates obtained via $\hat{\lambda}_{ST}$ and $\hat{\lambda}_{H}$, respectively. The estimated and observed quantiles appear in good agreement at each of the considered rays. 

% Note that the estimated confidence intervals for the deviance metric need not contain the estimates obtained using the original sample. This is due to the fact these confidence bounds are obtained using block bootstrapping with the ADF estimates obtained from the original sample. Naturally, one would expect generally lower values for the deviance metric using the original sample rather that a bootstrapped sample.   

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/adf_diag_plots2.pdf}
    \caption{Individual ADF QQ plots for $w \in \{0.1,0.3,0.5,0.7,0.9\}$ for first pair of gauges, using the ADF estimate obtained via $\hat{\lambda}_{ST}$. Estimates are given in black, with 95\% pointwise confidence intervals represented by the grey shaded regions. The red line corresponds to the $y=x$ line.}
    \label{fig:adf_diag2}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/adf_diag_plots3.pdf}
    \caption{Individual ADF QQ plots for $w \in \{0.1,0.3,0.5,0.7,0.9\}$ for first pair of gauges, using the ADF estimate obtained via $\hat{\lambda}_{H}$. Estimates are given in black, with 95\% pointwise confidence intervals represented by the grey shaded regions. The red line corresponds to the $y=x$ line.}
    \label{fig:adf_diag3}
\end{figure}

Figures \ref{fig:diag_st} and \ref{fig:diag_cl2} illustrate the return curve diagnostic of \citet{Murphy‐Barltrop2023} for the estimators $\hat{\lambda}_{ST}$ and $\hat{\lambda}_{CL2}$, respectively. For this diagnostic, a subset of points are selected on a return curve estimate; these points correspond to a set of $m=150$ equally spaced angles $\theta$ in the interval $[0,\pi/2]$, i.e., given $(x,y) \in \RC{p}{}$, we have $\theta = \tan^{-1}(y/x)$. Empirical estimates of the joint survival function are computed for each point and bootstrapping is used to evaluate uncertainty. Finally, the median empirical estimates, alongside 95\% pointwise confidence intervals, are plotted against the angle index and compared to the true probability; see \citet{Murphy‐Barltrop2023} for further details. 

Both estimators appear to give a similar level of accuracy, though for the fifth gauge site pairing, both $\hat{\lambda}_{ST}$ and $\hat{\lambda}_{CL2}$ fail to capture the true probability at all angles. 
% The $\hat{\lambda}_{CL2}$ estimator on the other hand captures the true probability at all angles, indicating a marginally better model fit. 
% , indicating the return curve estimates from this estimator better captures the extremal dependence structure for this example.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/diagnostic_plots2.pdf}
    \caption{Diagnostic plots of the return curve estimates from the $\hat{\lambda}_{ST}$ estimator for the first and fifth gauge site pairings. The black and red lines indicate the empirical median and true survival probabilities, respectively, with 95\% bootstrapped confidence intervals denoted by the shaded regions.}
    \label{fig:diag_st}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/diagnostic_plots.pdf}
    \caption{Diagnostic plots of the return curve estimates from the $\hat{\lambda}_{CL2}$ estimator for the first and fifth examples. The black and red lines indicate the empirical median and true survival probabilities, respectively, with 95\% bootstrapped confidence intervals denoted by the shaded regions}
    \label{fig:diag_cl2}
\end{figure}

Finally, Figures \ref{fig:uncert_rc2} and \ref{fig:uncert_rc} illustrate estimated return curve uncertainty intervals obtained using the $\hat{\lambda}_{ST}$ and $\hat{\lambda}_{CL2}$ estimators, respectively, for the first and fifth gauge site pairings. In both figures, one can observe the contrast in shapes of the uncertainty regions between the two site pairings. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/uncertainty_plots2.pdf}
    \caption{Median and mean return curve estimates in orange and brown, respectively, obtained using the $\hat{\lambda}_{ST}$ estimator for the first and fifth examples. The black dotted lines indicate 95\% confidence intervals.}
    \label{fig:uncert_rc2}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Supplementary/uncertainty_plots.pdf}
    \caption{Median and mean return curve estimates in orange and brown, respectively, obtained using the $\hat{\lambda}_{CL2}$ estimator for the first and fifth examples. The black dotted lines indicate 95\% confidence intervals.}
    \label{fig:uncert_rc}
\end{figure}

\bibliography{library}

\end{document}
\begin{align} 
    &\{q_{j}\}^m_{j = 1} \subset [r,r+], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.01, j = 1, \ldots, m\}, \label{eqn:set1}\\
    &\{q_{j}\}^m_{j = 1} \subset [0.93,0.97], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.02, j = 1, \ldots, m\}, \label{eqn:set2}\\
    &\{q_{j}\}^m_{j = 1} \subset [0.92,0.96], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.03, j = 1, \ldots, m\}, \label{eqn:set3}\\
    &\{q_{j}\}^m_{j = 1} \subset [0.91,0.95], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.04, j = 1, \ldots, m\}, \label{eqn:set4}\\
    &\{q_{j}\}^m_{j = 1} \subset [0.90,0.94], \{p_{j}\}^m_{j = 1} = \{q_{j} + 0.05, j = 1, \ldots, m\}, \label{eqn:set5}
\end{align}


\begin{table}[!h]

\caption{Sum of MISE values of Gaussian copulas with strong and weak positive dependencies (scaled by 1,000) for $\hat{\lambda}_{CL}$. All values reported to 3 significant figures, with smallest value highlighted in bold.
\label{table:tun_param_cl}}
\centering
\begin{tabular}[t]{c|c|c|c|c|c}
\hline
Polynomial Degree & q = 0.91 & q = 0.93 & q = 0.95 & q = 0.97 & q = 0.99\\
\hline
k = 3 & 13 & 13.2 & 13.4 & 13.9 & 16.5\\
\hline
k = 5 & 2.09 & 2.35 & 2.89 & 4.15 & 11.4\\
\hline
k = 7 & 1.88 & 2.15 & 2.76 & 4.2 & 12.3\\
\hline
k = 9 & 1.78 & 2.09 & 2.72 & 4.23 & 12.7\\
\hline
k = 11 & 1.75 & 2.06 & 2.73 & 4.26 & 13.1\\
\hline
\end{tabular}
\end{table}

\begin{table}[!h]

\caption{Sum of MISE values of Gaussian copulas with strong and weak positive dependence (scaled by 1,000) for for $\hat{\lambda}_{PR}$. All values reported to 3 significant figures, with smallest value highlighted in bold.
\label{table:tun_param_pr}}
\centering
\begin{tabular}[t]{c|c|c|c|c|c}
\hline
Polynomial Degree & B.1 & B.2 & B.3 & B.4 & B.5\\
\hline
k = 3 & 13.3 & 13.3 & 13.3 & 13.2 & 13.2\\
\hline
k = 5 & 2.97 & 2.88 & 2.83 & 2.59 & 2.47\\
\hline
k = 7 & 2.95 & 2.84 & 2.65 & 2.49 & 2.31\\
\hline
k = 9 & 2.95 & 2.84 & 2.68 & 2.48 & 2.3\\
\hline
k = 11 & 2.97 & 2.85 & 2.69 & 2.48 & 2.28\\
\hline
\end{tabular}
\end{table}
% \begin{table}[!h]

% \caption{MISE values (scaled by 1,000) for each estimator and copula combination. Smallest MISE values in each row are highlighted in bold, with values reported to 3 significant figures.
% \label{table:MISE_values}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Copula & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% Copula 1 & 300 & 310 & 359 & 304 & 318 & 367 & 406 & 337\\
% \hline
% Copula 2 & 2.18 & 1.74 & 1.76 & 2.07 & 1.69 & 1.72 & 0.871 & 1.13\\
% \hline
% Copula 3 & 1.96 & 1.72 & 1.88 & 1.27 & 1.18 & 1.33 & 0.118 & 0.0997\\
% \hline
% Copula 4 & 1.7 & 1.65 & 2.62 & 0.726 & 0.685 & 1.33 & 0.767 & 1.24\\
% \hline
% Copula 5 & 13.6 & 13.4 & 20.6 & 13.1 & 12.9 & 19.7 & 14.6 & 29.3\\
% \hline
% Copula 6 & 1.28 & 1.07 & 1.13 & 0.889 & 0.767 & 0.788 & 0.45 & 2.03\\
% \hline
% Copula 7 & 1.66 & 1.3 & 1.36 & 1.59 & 1.29 & 1.36 & 1.57 & 3.36\\
% \hline
% Copula 8 & 1.24 & 1.52 & 1.58 & 0.129 & 0.12 & 0.13 & 0.348 & 79.2\\
% \hline
% Copula 9 & 9.49 & 9.07 & 14.2 & 9.19 & 8.83 & 13.8 & 12.2 & 92.8\\
% \hline
% \end{tabular}
% \end{table}


% The RMSE values for the first, sixth, and eighth copula examples are given in Tables \ref{table:rmse_cop_1}, \ref{table:rmse_cop_6}, and \ref{table:rmse_cop_8}, respectively, while the results for the remaining copulas can be found in the Supplementary Material. On average, similar values were obtained across many of the estimators. Again, no estimator consistently outperforms the others, though the estimator $\hat{\lambda}_{ST}$ had the best performance in many cases. These results again demonstrate the inability of these approaches to capture negative extremal dependence, as evidenced by the significantly higher RMSE values for the first copula. Furthermore, on average, the composite likelihood estimator $\hat{\lambda}_{CL2}$ appeared to give the best performance for copula exhibiting asymptotic dependence, while $\hat{\lambda}_{ST}$ appears preferable for asymptotically independent examples. Moreover, the `combined' estimators again outperform their non-combined counterparts in the majority of cases, suggesting the additional steps also reduce variability in estimates. 

% \begin{table}[!h]

% \caption{RMSE values (scaled by 100) for copula 1 \label{table:rmse_cop_1}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Ray & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% $w = $0.1 & \textbf{53.7} & 55.1 & 59.6 & 54.7 & 57.2 & 61.6 & 61.8 & 55.1\\
% \hline
% $w = $0.3 & 54.8 & \textbf{51.8} & 56.9 & 55.1 & \textbf{51.8} & 56.9 & 63.8 & 57.7\\
% \hline
% $w = $0.5 & \textbf{55.5} & 60.1 & 63.9 & \textbf{55.5} & 60.4 & 64 & 63.9 & 56.4\\
% \hline
% $w = $0.7 & 55.4 & 52.4 & 57.3 & 55.4 & \textbf{52.1} & 57.1 & 63.8 & 57.9\\
% \hline
% $w = $0.9 & \textbf{53.8} & 55.2 & 59.7 & 54.1 & 56.9 & 61.3 & 61.7 & 54.9\\
% \hline
% \end{tabular}
% \end{table}

% \begin{table}[!h]

% \caption{RMSE values (scaled by 100) for copula 6 \label{table:rmse_cop_6}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Ray & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% $w = $0.1 & 4.05 & 3.94 & 4.15 & 2.7 & 2.61 & 2.58 & \textbf{0.175} & 2.32\\
% \hline
% $w = $0.3 & 3.29 & 3.3 & 3.34 & 3.27 & 3.22 & 3.33 & \textbf{2.67} & 5.52\\
% \hline
% $w = $0.5 & 2.87 & 2.3 & \textbf{2.27} & 2.87 & 2.57 & 2.58 & 2.67 & 5.36\\
% \hline
% $w = $0.7 & 3.26 & 3.26 & 3.27 & 3.25 & 3.25 & 3.33 & \textbf{2.72} & 5.63\\
% \hline
% $w = $0.9 & 4.13 & 4.04 & 4.23 & 2.79 & 2.55 & 2.55 & \textbf{0.183} & 2.31\\
% \hline
% \end{tabular}
% \end{table}

% \begin{table}[!h]

% \caption{RMSE values (scaled by 100) for copula 8 \label{table:rmse_cop_8}}
% \centering
% \begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
% \hline
% Ray & $\hat{\lambda}_{H}$ & $\hat{\lambda}_{CL}$ & $\hat{\lambda}_{PR}$ & $\hat{\lambda}_{H2}$ & $\hat{\lambda}_{CL2}$ & $\hat{\lambda}_{PR2}$ & $\hat{\lambda}_{ST}$ & $\hat{\lambda}_{WC}$\\
% \hline
% $w = $0.1 & 4.1 & 4.8 & 5.11 & \textbf{0.817} & 0.889 & 0.89 & 2.42 & 35.4\\
% \hline
% $w = $0.3 & 3.16 & 4.27 & 4.11 & 0.761 & \textbf{0.673} & 0.818 & 1.88 & 27.8\\
% \hline
% $w = $0.5 & 2.63 & 4.98 & 5.3 & 2.51 & 1.95 & 2.05 & \textbf{1.8} & 23.7\\
% \hline
% $w = $0.7 & 3.19 & 4.22 & 4.1 & 1.15 & \textbf{1.04} & 1.15 & 1.85 & 28.6\\
% \hline
% $w = $0.9 & 4.21 & 4.98 & 5.21 & \textbf{1.19} & 1.32 & 1.24 & 2.38 & 36.3\\
% \hline
% \end{tabular}
% \end{table}


% each ray $w \in \{0.1,0.3,0.5,0.7,0.9\}$ and copula can be found in the Supplementary Material, with the lowest value in each case highlighted in black. We find that for copula examples ... , the estimator proposed in \citet{Simpson2022} gives the lowest RMSE values, while for the remaining copula examples, the lowest values are given by one of the `combined' estimators proposed in Section \ref{Subsec2.2}. This suggests the `combined' approaches produce the least bias and variance for examples exhibiting a high degree of positive extremal dependence. 

% To test this hypothesis, first observe that for the correlation coefficient $\rho \in [-1,1]$, we have $\eta = (1 + \rho)/2$, as derived in \citet{Ledford1996}. Our aim is to discover which $\eta$ values do the combined estimators give a superior performance to the technique proposed in \citet{Simpson2022}. Therefore, we simulate $N=1,000$ samples from Gaussian copulas with $\rho \in \{ 2\eta - 1 \mid \eta \in \mathcal{N}\}$, where $\mathcal{N}:=\{0.1,0.2,\hdots,0.9,1\}$: this corresponds to a range of extremal dependence structures, from weak to strong positive dependence. We then plotted the resulting MISE and RMSE estimates (for each ray $w \in \{0.1,0.3,0.5,0.7,0.9\}$) for each copula against the corresponding $\eta$ values; these results can be found in the Supplementary Material. They suggest that, for $\eta > 0.65$, the combined estimators have less bias and variance, on average, compared to $\hat{\lambda}_{ST}$. From these results, we suggest that the combined estimation techniques are preferable in cases where there is a reasonable degree of positive extremal dependence ($\eta > 0.65$), while the estimator of \citet{Simpson2022} is preferable in all other cases. 