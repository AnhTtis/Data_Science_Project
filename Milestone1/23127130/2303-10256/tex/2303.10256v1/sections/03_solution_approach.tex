We approach the solution of \labelcref{eq:AE_power,eq:DE_power} by finding an explicit expression for $\Bar{\bm{V}}(t)$ for $t\in[t_0, t_0+\Delta t]$. Given $\Bar{\bm{V}}(t)$, the solution of \labelcref{eq:DE_power_f} can be computed quickly, as we now only need to solve $m$ much smaller and simpler problems instead of a single large and difficult one. We start by initially estimating the temporal evolution of the algebraic variables $\hat{\Bar{\bm{V}}}(t)$ (\cref{subsec:voltage_guess}). Using this estimate, we employ a \gls{NN} for each component $i$ to predict the trajectory $\hat{\bm{x}}_i(t)(t, \bm{x}_0, \hat{\Bar{\bm{V}}}(t))$ (\cref{subsec:NN_approximation}). We then can evaluate \labelcref{eq:AE_power} to assess the quality of the guess $\hat{\Bar{\bm{V}}}(t)$ and update it iteratively based on the mismatch of the currents in \labelcref{eq:AE_power} (\cref{subsec:voltage_update}). As soon as this update scheme converged, we \say{solved} the problem for the present time-step and can  repeat the procedure for the next time-step. We are thereby able to simulate trajectories of arbitrary length (\cref{subsec:simulator}).
% For the estimate of the current injections $\hat{\Bar{\bm{I}}}(\hat{\bm{x}}(t), \hat{\Bar{\bm{V}}}(t))$, we furthermore require an explicit approximator for the evolution of the dynamic variable $\hat{\bm{x}}(t)$. By iteratively updating the guess for $\hat{\Bar{\bm{V}}}(t)$ until we minimized the current balance error $\bm{\varepsilon}_I \in \mathbb{C}^{n}$
% \begin{align}
%     \bm{\varepsilon}_I(\hat{\bm{x}}(t), \hat{\Bar{\bm{V}}}(t)) := \Bar{Y}_N \hat{\Bar{\bm{V}}}(t)) - \Bar{\bm{I}}(\hat{\bm{x}}(t), \hat{\Bar{\bm{V}}}(t)),
% \end{align}
% we \say{solve} the system of \glspl{DAE} and obtain the solutions $\hat{\bm{x}}(t)$ and $\hat{\Bar{\bm{V}}}(t)$ for the time interval $[t_0, t_0 + \Delta t]$. By 

This approach allows us, firstly, to incorporate \glspl{NN}, which are a powerful explicit function approximator, into solution algorithms for \glspl{DAE}. \glspl{NN} can approximate $\hat{\bm{x}}(t)$ well for large time-steps of complicated functions, they do not experience numerical instability, and they are fast to evaluate. The second benefit relates to the fact, that the proposed solution algorithm is indifferent to the dimensionality of the differential variable vector, i.e., $\dim(\bm{x})$. This addresses a major challenge for solving \glspl{DAE} in very large power systems as $\dim(\bm{x})$ rapidly grows when many complicated components are present.
% \bz{stress this more, i.e., say that it can scale to very large networks. Echo back to say that this solves one of the main challenges with DAEs in power systems.}

\subsection{Parametrization of the voltage estimate $\hat{\Bar{\bm{V}}}(t)$}\label{subsec:voltage_guess}

Based on the initial state $\bm{x}_0$, we can compute the initial voltages $\Bar{\bm{V}}$ that satisfy the current balance. We now take an initial estimate for the evolution of the complex voltage in its polar form at each bus for the time interval $[t_0, t_0 + \Delta t]$. We express this estimate as a power-series with respect to time for the voltage magnitude $V_i$ and the voltage angle $\theta_i$
\begin{align}
     \Bar{V}_i(t) &= V_{i}(t) e^{j\theta_i(t)} \\
     &\approx \left(\sum_{k=0}^{r} V_{k, i} (t-t_0)^k \right) e^{j\left(\sum_{k=0}^{r} \theta_{k, i} (t-t_0)^k \right)}\label{eq:voltage_parametrisation}
\end{align}
up to power $r$. The coefficients $V_{0, i}, V_{1, i}, \dots, V_{r, i}$ and $\theta_{0, i}, \theta_{1, i}, \dots, \theta_{r, i}$ form the parameters which we will later on update to improve the initial estimate. We subsequently refer to this estimate as $\hat{\Bar{V}}_i(t, \yparams{}_i)$. The vector $\yparams{}_i$ collects all parameters at bus $i$
\begin{align}
    \yparams{}_i = \begin{bmatrix}
      V_{0, i} & \theta_{0, i} & \hdots & V_{r, i}, \theta_{r, i}
    \end{bmatrix} \in \mathbb{R}^{1\times2r}.
\end{align}
This parametization is repeated for all $n$ buses in the system. We collect all $\yparams{}_i$ in the vector $\yparams{} \in \mathbb{R}^{2 r n}$.

\subsection{Explicit approximation of $\hat{\bm{x}}_i(t)$ by a Neural Network (NN)}\label{subsec:NN_approximation}

The exact solution for the evolution of the differential variables $\bm{x}_i(t)$ of machine $i$ can be obtained by integration of \labelcref{eq:DE_power_f}
\begin{align}
    \bm{x}_i(t) &= \bm{x}_{0, i} + \int_{t_0}^{t} \bm{f}_i\left(\bm{x}_i(\tau), \Bar{V}_i(\tau), \bm{u}_i\right) d\tau. \label{eq:x_integral}
\end{align}
As there usually exists no explicit analytical solution to \labelcref{eq:x_integral}, we seek to approximate the solution. In a first step, we replace $\Bar{V}_i(\tau)$ by the estimate for the bus voltage $\hat{\Bar{V}}_i(\tau)$
\begin{align}
    \bm{x}_i(t) &\approx \bm{x}_{0, i} + \int_{t_0}^{t} \bm{f}_i\left(\bm{x}_i(\tau), \hat{\Bar{V}}_i(\tau), \bm{u}_i\right) d\tau.\label{eq:x_integral_V_guess}
\end{align}
Because an explicit analytical solution is usually still not attainable, we now approximate \labelcref{eq:x_integral_V_guess} by a \gls{NN} to obtain
\begin{align}
    \hat{\bm{x}}^{NN}_i(t) = NN(t, \bm{x}_{0, i}, \hat{\Bar{V}}_i(t), \bm{u}_i).
\end{align}
As we have parameterized the estimate $\hat{\Bar{V}}_i(t)$ in terms of the parameters $\yparams{}_i$, the input $\bm{z}_0$ to the \gls{NN} becomes
\begin{align}
    \bm{z}_0 &= [t, \bm{x}_{0,i}, \yparams{}_i, \bm{u}_i], \quad \bm{z}_0 \in \mathbb{R}^{1+p+2r+q} \label{eq:NN_input}
\end{align}
We use a multi-layer perceptron \gls{NN} which is a sequence of linear transformations parameterized by weight matrices $\bm{W}_k$ and bias vectors $\bm{b}_k$ and the application of a non-linear function $\sigma$ in each of the $K$ hidden layers
\begin{subequations}
\begin{align}
    \bm{z}_{k+1} &= \sigma\left(\bm{W}_{k+1} \bm{z}_{k} + \bm{b}_{k+1}\right), \,\forall k = 0, 1, \ldots, K-1\label{eq:NN_hidden_layers}\\
    \hat{\bm{x}}_i^{NN} &= \bm{x}_{0,i} + (\bm{W}_{K} \bm{z}_K + \bm{b}_{K}). \label{eq:NN_output}
\end{align}
\end{subequations}
In our simulation, we use $\sigma(\cdot) = \tanh(\cdot)$ and three layers, i.e., $K=3$.
 As a baseline, we consider an explicit \gls{RK}-based approximation scheme for \labelcref{eq:x_integral_V_guess}
\begin{align}
    &\hat{\bm{x}}_i^{RK}(\Delta t, \bm{x}_{0,i}, \yparams{}_i) = \bm{x}_{0, i} + \Delta t \sum_{j=1}^\nu b_j \bm{k}^{(j)}\\
    &\bm{k}^{(j)} = \bm{f}\left(t_0 + c_j \Delta t, \bm{x}_{0, i} + \Delta t \sum_{l=1}^\nu a_{jl} \bm{k}^{(l)}, \yparams{}_i, \bm{u}_i \right),
\end{align}
where $a_{jl}$ is strictly lower triangular. Other choices such as time-power series \cite{wang_timepower_2019} or Adomian decomposition methods \cite{gurrala_large_2017} are equally possible. In either case the state evaluation is explicitly dependent on $\yparams{}_i$ which together with $t$ accounts for the evolution of the network algebraic variables. 

\subsection{Update scheme for voltage parametrization}\label{subsec:voltage_update}
Independent of the approximation method used for $\xhat{}_i$, we can now compute each component's current injection $\hat{\Bar{I}}_i(\hat{\bm{x}}_i, \hat{\Bar{V}}_i)$. We then define the current mismatch $\bm{\varepsilon}_I^{(k)} \in \mathbb{R}^{2n}$ in iteration $k$
\begin{align}
    \bm{\varepsilon}_I^{(k)} := \begin{bmatrix}
        \Re\left(\Bar{Y}_N \hat{\Bar{\bm{V}}}(t, \yparams{}^{(k)}) - \hat{\Bar{\bm{I}}}(t, \bm{x}_0,  \yparams{}^{(k)})\right)\\
        \Im\left(\Bar{Y}_N \hat{\Bar{\bm{V}}}(t, \yparams{}^{(k)}) - \hat{\Bar{\bm{I}}}(t, \bm{x}_0,  \yparams{}^{(k)})\right)
    \end{bmatrix}.\label{eq:current_mismatch}
\end{align}
We deliberately used the notation $\hat{\Bar{\bm{V}}}(t, \yparams{}^{(k)})$ and $\hat{\Bar{\bm{I}}}(t, \bm{x}_0,  \yparams{}^{(k)})$ to make clear that $\bm{\varepsilon}_I^{(k)}$ is a function dependent only on $t$, $\bm{x}_{0}$, and $\yparams{}_i^{(k)}$. 
\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures_pdf/voltage_parametrisation_update.pdf}
    \caption{Current with $s$ collocation points at iteration 0 and 5.}
    \label{fig:lstsq_voltage_parametrisation}
\end{figure}
\Cref{fig:lstsq_voltage_parametrisation} illustrates the real part of the current injection of the component $\Bar{I}_1$ and the respective network current $(\Bar{Y}_N \hat{\Bar{\bm{V}}})_1$ at bus 1. The current mismatch $\Re(\bm{\varepsilon}_{I,1}^{(k)})$ corresponds to area between the two curves. By updating the parameters \yparams{} we reduce the mismatch as seen in each of the columns in \cref{fig:lstsq_voltage_parametrisation}. If $\bm{\varepsilon}_I = \bm{0}$ across the entire time-step $[t_0, t_0 + \Delta t]$ and $\hat{\bm{x}}$ accurately solves \labelcref{eq:DE_power_f}, then we found a solution to the system of \glspl{DAE}. In practice, we evaluate \labelcref{eq:current_mismatch} on $s$ collocation points within the time interval, $\bm{T} = [t_1, \dots, t_s]$, which we can freely choose. The two columns in \cref{fig:lstsq_voltage_parametrisation} show two possible choices for $s=2$ and $s=5$. Formally, the objective in order to solve the system of \glspl{DAE} becomes
\begin{align}
    \min_{\yparams{}} \left\|\begin{bmatrix}  \bm{\varepsilon}_I(t_1, \bm{x}_0,  \yparams{}) \\ \vdots \\  \bm{\varepsilon}_I(t_s, \bm{x}_0,  \yparams{})
    \end{bmatrix}\right\|_2
\end{align}
and we solve this optimization problem by applying an iterative procedure, summarized by \cref{algo:parameter_update}, to determine \yparams{} based on the Newton-Raphson algorithm.
% and subsequently the real and imaginary component of the current mismatch  which forms \labelcref{eq:g_desired} in this setup's context:
% \begin{equation}\label{eq:current_error_optimisation}
% \begin{split}
%     \bm{0} &\overset{!}{=} \bm{\varepsilon}_I(t,\bm{x}_{0}, \bm{\Theta}^{(k)}))\\
%     &= \begin{bmatrix} \Re\left(\Bar{\bm{Y}} \hat{\Bar{\bm{V}}}(t, \bm{\Theta}^{(k)}) - \hat{\Bar{\bm{I}}}_c(t, \bm{x}_{0}, \bm{\Theta}^{(k)}) \right) \\ \Im\left(\Bar{\bm{Y}} \hat{\Bar{\bm{V}}}(t, \bm{\Theta}^{(k)}) - \hat{\Bar{\bm{I}}}_c(t, \bm{x}_{0}, \bm{\Theta}^{(k)}) \right) \end{bmatrix}.
% \end{split}
% \end{equation}
% The superscript $k$ on the voltage parameters indicates the iteration as we will
% \begin{align}
%    \frac{\partial \bm{\varepsilon}_I}{\partial \bm{\Theta}^{(k)}} \Delta \bm{\Theta}^{(k)} &= -\bm{\varepsilon}_I(\bm{\Theta}^{(k)})\\
%    \bm{\Theta}^{(k+1)} &= \bm{\Theta}^{(k)} + \Delta \bm{\Theta}
% \end{align}
The update value $\Delta \yparams{}^{(k)}$ in Step 8 of \cref{algo:parameter_update} is determined by the least square problem
% \begin{subequations}\label{eq:lstsq_delta_theta}
% \begin{alignat}{2}
%     \min_{\Delta \yparams{}^{(k)}}& \;&&\left\| A \Delta \yparams{}^{(k)} - B\right\|_2\\
%     A &= &&\begin{bmatrix} \nicefrac{\partial \bm{\varepsilon}_I(t_1, \bm{x}_{0},\yparams{}^{(k)})}{\partial \yparams{}^{(k)}} \\ \vdots \\ \nicefrac{\partial \bm{\varepsilon}_I(t_s, \bm{x}_{0},\yparams{}^{(k)})}{\partial \yparams{}^{(k)}} \end{bmatrix}\\
%     B &= &&\begin{bmatrix} \bm{\varepsilon}_I(t_1, \bm{x}_{0}, \yparams{}^{(k)}) \\ \vdots \\ \bm{\varepsilon}_I(t_s,\bm{x}_{0}, \yparams{}^{(k)}) \end{bmatrix}
% \end{alignat}
% \end{subequations}
\begin{subequations}\label{eq:lstsq_delta_theta}
\begin{align}
    &\hspace{-1.7cm}\min_{\Delta \yparams{}^{(k)}} \;\left\| A \Delta \yparams{}^{(k)} - B\right\|_2\\[8pt]
    A = \begin{bmatrix} \nicefrac{\partial \bm{\varepsilon}_I(t_1, \bm{x}_{0},\yparams{}^{(k)})}{\partial \yparams{}^{(k)}} \\ \vdots \\ \nicefrac{\partial \bm{\varepsilon}_I(t_s, \bm{x}_{0},\yparams{}^{(k)})}{\partial \yparams{}^{(k)}}\end{bmatrix}&\,
    B = \begin{bmatrix} \bm{\varepsilon}_I(t_1, \bm{x}_{0}, \yparams{}^{(k)}) \\ \vdots \\ \bm{\varepsilon}_I(t_s,\bm{x}_{0}, \yparams{}^{(k)}) \end{bmatrix}
\end{align}
\end{subequations}
which we solve for repeatedly until we reach the defined tolerance $\Delta \yparams{}^{\max}$ or the maximum number of iterations $k^{\max}$. The problem in \labelcref{eq:lstsq_delta_theta} can be under-determined, over-determined, or unique, primarily depending on $s$ and the number of voltage parameters \yparams{}. As we are free to choose the number of collocation points, we impose $ 2 \cdot n \cdot s \geq |\yparams{}|$ which rules out under-determined settings unless the Jacobian matrices are not full rank\footnote{The Jacobian of the network current $\Bar{Y} \hat{\Bar{\bm{V}}}$ is actually deficient by 1 rank due to the symmetry around the voltage angles, however, as long as the Jacobian of the component's current injection matrix is non-zero, i.e., there is some dependency of the voltage parameters, the problem is well posed.}.
\input{algorithms/voltage_parametrisation_update.tex}

Usually, $\nicefrac{\partial \hat{\Bar{\bm{I}}}}{\partial \yparams{}^{(k)}}$ is not straightforward to derive, however, the use of \gls{AD} allows an efficient computation of the derivatives~\cite{griewank1989automatic}. \Gls{AD} constructs a computational graph for the calculation of $\hat{\bm{x}}$ and $\hat{\Bar{\bm{I}}}$ and then applies the chain rule to obtain the the derivatives $\nicefrac{\partial\hat{\bm{x}}}{\partial\yparams{}^{(k)}}$ and $\nicefrac{\partial \hat{\Bar{\bm{I}}}}{\partial \yparams{}^{(k)}}$. As we restricted $\hat{\bm{x}}(t, \bm{x}_0, \yparams{})$ to be an explicit integration scheme for \labelcref{eq:x_integral_V_guess}, the associated computational graph is automatically constructed and of relatively small size which results in fast calculations. The calculation furthermore does not directly depend on the dimension of $\bm{x}$.\footnote{$\dim(\bm{x})$ might affect the necessary size of the computational graph.}

\subsection{Multi-step simulator for power system dynamics}\label{subsec:simulator}

The sections above yield a state trajectory for a single time-step and its accuracy is dependent on the approximation quality of $\hat{\bm{x}}(t)$ and $\hat{\Bar{\bm{V}}}(t)$. Requirements on the resulting tolerance therefore limit the suitable time-step size $\Delta t$. By repeatedly applying the above algorithm, we obtain a multi-step scheme that then allows the simulation of dynamics beyond $\Delta t$. \Cref{algo:simulator} summarizes the simplest form of such a multi-step simulator in which we evaluate the trajectory on the points $T_{\text{eval}}$. 
We show in \cref{sec:results} that \cref{algo:simulator} yields accurate trajectories and that the use of \glspl{NN} allows larger time-steps, hence faster simulations, while being more accurate than the \gls{RK}-based approximators.
\input{algorithms/multi_step_simulator.tex}

% \bz{You don't want to end a section with an algorithm. Saying something like "As we show in the simulations, Algorithm 2 is x times faster than the iterative schemes..." would be helpful}

