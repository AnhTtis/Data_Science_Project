\documentclass[9pt]{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{amssymb,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,sectsty,comment,footmisc,caption,pdflscape,subfigure,array,hyperref}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{multirow}
\usepackage{mathtools}
\normalem
\newcommand{\mR}{\mathbb{R}}
\newcommand{\mC}{\mathbb{C}}
\newcommand{\mP}{\mathbb{P}}
\newcommand{\mf}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\mG}{\mathcal{G}}
\newcommand{\mA}{\mathcal{A}}
\newcommand{\mE}{\mathbb{E}}
\newcommand{\ul}{\underline}
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\Tha}{\Theta}
\newcommand{\tha}{\theta}
\newcommand{\lam}{\lambda}
\newcommand{\Lam}{\Lambda}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\mathtoolsset{showonlyrefs}


\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{eufrak}

\newtheorem{theo}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{prop}{Proposition}
\newtheorem{Def}{Definition}
\newtheorem{assume}{Assumption}
\newtheorem{coro}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{rk}{Remark}

\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\eps}{\epsilon}
\DeclareMathOperator{\vor}{Vor}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\spt}{supp}

\newcommand{\mge}{\succcurlyeq}		% matrix greater than or equal to
\newcommand{\mgt}{\succ}			% matrix greater than
\newcommand{\mle}{\preccurlyeq}		% matrix less than or equal to
\newcommand{\mlt}{\prec}			% matrix less than
\newcommand{\note}{\textbf{Notation:}}
\newcommand{\eg}{\textbf{Example:}}

\newcommand{\ketzero}{|\varphi_0\rangle}
\newcommand{\ketone}{|\varphi_1\rangle}
\newcommand{\ket}{|\varphi\rangle}
\newcommand{\bra}{\langle\varphi|}
\newcommand{\Ket}{|\Phi\rangle}
\newcommand{\Bra}{\langle \Phi |}

\newcommand{\ketkk}{|\varphi_k\rangle}
\newcommand{\brakk}{\langle\varphi_k|}
\newcommand{\brazero}{\langle\varphi_0|}
\newcommand{\braone}{\langle\varphi_1|}

\newcommand{\ketpsi}{|\psi\rangle}
\newcommand{\brapsi}{\langle\psi|}
\newcommand{\keteta}{|\eta_i\rangle}
\newcommand{\ketetaa}{|\eta_j\rangle}
\newcommand{\ketetaaa}{|\eta_k\rangle}
\newcommand{\braeta}{\langle\eta_i|}
\newcommand{\braetaa}{\langle\eta_j|}
\newcommand{\braetaaa}{\langle\eta_k|}

\newcommand{\ketm}{|m\rangle}
\newcommand{\bram}{\langle m|}
\newcommand{\ketmzero}{|m^0\rangle}
\newcommand{\ketmone}{|m^1\rangle}
\newcommand{\bramzero}{\langle m^0|}
\newcommand{\bramone}{\langle m^1|}

\newcommand{\kets}{|s\rangle}
\newcommand{\bras}{\langle s|}
\newcommand{\ketszero}{|s^0\rangle}
\newcommand{\ketsone}{|s^1\rangle}
\newcommand{\braszero}{\langle s^0|}
\newcommand{\brasone}{\langle s^1|}

\newcommand{\kett}{|\phi'\rangle}
\newcommand{\braa}{\langle\phi'|}
\newcommand{\keti}{|\varphi_i\rangle}
\newcommand{\brai}{\langle\varphi_i|}
\newcommand{\ketk}{|k\rangle}
\newcommand{\brak}{\langle k|}

\newcommand{\ketip}{|\varphi_{i'}\rangle}% p stands for 'prime'
\newcommand{\braip}{\langle\varphi_{i'}|}


\newcommand{\ketpsij}{|\psi_j\rangle} 
\newcommand{\brapsij}{\langle\psi_j|}
\newcommand{\ketjp}{|\psi_{j'}\rangle}
\newcommand{\brajp}{\langle\psi_{j'}|}

\newcommand{\spinup}{|\uparrow\rangle}
\newcommand{\spinupbra}{\langle \uparrow |}
\newcommand{\spindown}{|\downarrow\rangle}
\newcommand{\spindownbra}{\langle \downarrow |}
\newcommand{\tr}{\text{Tr}}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}
\begin{document}
\title{Detection in human-sensor systems under quantum prospect theory using Bayesian persuasion frameworks}
\name{Yinan Hu and Quanyan Zhu\address{Tandon School of Engineering, New York University, Brooklyn, NY, USA}}

\maketitle
\begin{abstract}
    %Human-sensor systems has a variety of applications in robotics, healthcare and finance. Sensors observe the true state of nature and produce strategically designed signals to help human arrive at more accurate decisions of the state of nature.  
    Human-sensor systems have a wide range of applications in fields such as robotics, healthcare, and finance. These systems utilize sensors to observe the true state of nature and generate strategically designed signals, aiding humans in making more accurate decisions regarding the state of nature. We adopt a Bayesian persuasion framework that is integrated with quantum prospect theories. In this framework, we develop a detection scheme where humans aim to determine the true state by observing the realization of quantum states from the sensor. We derive the optimal signaling rule for the sensor and the optimal decision rule for humans. We discover that this scenario violates the total law of probability. Furthermore, we examine how the concepts of rationality can influence the human detection performance and the signaling rules employed by the sensor.
    %We formulate the human-sensor systems into a Bayesian persuasion framework consolidated into prospect theories and construct a detection scheme where human wants to find out the true state by observing the realization of the quantum states from the sensor. We obtain the optimal signaling rule for the sensor and optimal decision rule and verify that the total law of probability is violated in this scenario. We also illustrate how the concept of rationality and influence human's detection performance and also the sender's signaling rules. 
\end{abstract}
\begin{keywords}
Quantum Detection, Quantum Signal Processing, game theory, Bayesian Persuasion
\end{keywords}



\section{Introduction}
%Detection methods play an essential role in statistical signal processing. It has many applications in studying sensor-attacks \cite{meira2020synthesis_sensor_attack}, internet traffic, etc. Detection frameworks in human-sensor systems have played an important role in robotics \cite{amini2013quantum_robotics}, healthcare systems, as well as recommend systems \cite{lu2012recommender}. One important topic is how a sensor can guide human's decision making process by carefully designing signals delivered to human beings.

Detection methods play a vital role in statistical signal processing, encompassing a wide range of applications, such as studying sensor attacks \cite{meira2020synthesis_sensor_attack}, analyzing internet traffic, and more. Within the realm of human-sensor systems, detection frameworks have emerged as essential components in domains like robotics \cite{amini2013quantum_robotics}, healthcare systems, and recommendation systems \cite{lu2012recommender}. An essential aspect of research within this field centers on the influence of sensors in guiding human decision-making processes through the meticulous design of signals intended for individuals.

Recent studies have embraced quantum decision theories \cite{busemeyer2012quantum_cognition} to interpret various phenomena in human cognitive science such as order effect \cite{trueblood2017quantum_inference} and violation of sure-thing-principle \cite{busemeyer2009quantum_violation_sure_thing_principple} that cannot be adequately explained using classical theories.  which refers to the violation of the total probability law when probabilities represent human perception in the decision-making process. In \cite{snow2022quickest_detection_QDT}, researchers have developed quickest detection frameworks by integrating quantum decision models, aiming to capture bounded rationalities observed in human decision-making. However, it is essential to consider risk preference \cite{tversky1992advances_prospect_theory} as a crucial factor in human decision-making. Humans may not assign equal weight to gains and losses, and risk-averse individuals may be unwilling to trade the possibility of a loss for the chance of a gain when selecting lotteries. Theories on risk measures \cite{artzner1999coherent_risk} have been developed to provide a more sophisticated characterization of human risk preferences.

%Recently, several studies have adopted quantum decision theories \cite{busemeyer2012quantum_cognition} to interpret  a variety of phenomena in human cognitive science that cannot be interpreted using classical counterparts. One phenomenon of such kind is order effect \cite{trueblood2017quantum_inference}, which means that human's posterior belief on perception is impacted by the order at which the classical information is provided;  Another phenomenon is violation of sure-thing principle \cite{busemeyer2009quantum_violation_sure_thing_principple}, which refers to the violation of total probability law when the probabilities represent human perception in decision making process. 



%Recently, authors in \cite{snow2022quickest_detection_QDT} have developed quickest detection frameworks consolidated quantum decision models to capture bounded rationalities in human decision making. However, risk-preference \cite{tversky1992advances_prospect_theory} also plays an important role in human's decision making process as humans may not value gains and losses at the same weight. Risk-averse humans may not be willing to sacrifice the chance of a loss in exchange for the chance of a gain when selecting lotteries. There are also theories on risk measures \cite{artzner1999coherent_risk} to characterize human's risk preferences in a more sophisticated way. 

To this end, we formulate the detection of sensor-human systems to using quantum decision theory \cite{sornette2020quantum_propsect_theory}. This decision model integrates classical outcomes and the psychological state to capture human's bounded rationality, including risk-preference, in the decision-making process. %Such a decision model incorporates exogenous classical outcome with psychological state to capture human's bounded rationality including the risk-preference in decision making. We have following contributions: 
Our contributions can be summarized as follows.
First, we develop a comprehensive detection framework for human-sensor systems that takes into account risk-preference and incorporates interference effects,  thereby capturing the inherent bounded rationality of humans. 
%we develop a detection framework in human-sensor system where risk-preference, combined with interference to constitute the human's bounded rationality.
Second, we establish the existence of an optimal policy resembling a likelihood-ratio test for the human receiver within the detection framework. This finding sheds light on the optimal decision-making strategy for the human component of the system, enhancing our understanding of their behavior. %we show the existence of an optimal likelihood-ratio-test-like policy for the human receiver;
%Lastly, we demonstrate the violation of the sure-thing principle and investigate the relationships between the optimal threshold, prior beliefs, and risk-preference parameter. %third, we illustrate the violation of sure-thing-principle as well as the relationships between the optimal threshold and prior beliefs and risk-preference parameter.

The rest of the paper is organized as follows: Section \ref{sec:formulation} presents the formulation of the relationship between the sensor and the human receiver, along with the protocol for communication between them regarding the true state of nature. In Section \ref{sec:sol_concept}, we discuss the optimal decision policies for the human receivers and the optimal signaling rules for the sensors. Section \ref{sec:numerical_results} is dedicated to the numerical simulation of the proposed solution concepts. Specifically, we verify the violation of the sure-thing principle and illustrate the optimal thresholding based on different prior beliefs about the true hypothesis. Finally, Section \ref{sec:conclusion} concludes the paper. %in section \ref{sec:formulation} we formulate the relationship between the sensor and the human receiver and characterize the protocol that the sensor communicates with human regarding the true state of nature. In section \ref{sec:sol_concept} we the optimal decision policies for the human receivers and optimal signaling rules for sensors. In section \ref{sec:numerical_results} we simulate the solution concepts numerically. In particular, we verify the violation of sure-thing-principle and depict the optimal thresholding regarding the prior upon the true hypothesis. Finally, we conclude in section \ref{sec:conclusion}. 

\textbf{Related work:} This work builds upon previous research such as \cite{gezici2018_likelihood_ratio_test_prospect_hypo} and \cite{nadendla2016human_agent_hypo_testing}, but introduces a novel perspective by incorporating quantum decision theory into the human decision-making process. In addition, we employ the Bayesian persuasion model \cite{kamenica2019bayesian_persuasion} to formulate the behaviors of the sensor. By integrating these frameworks, we aim to capture the complex dynamics within the sensor-human system.
%This work serves as a variation of the work \cite{gezici2018_likelihood_ratio_test_prospect_hypo} and \cite{nadendla2016human_agent_hypo_testing} by adopting quantum decision theory in human's decision making process. We here adopt Bayesian persuasion \cite{kamenica2019bayesian_persuasion} model to formulate sensor's behaviors. There are numerous game-theoretic frameworks to formulate the relationship between strategic agents.     

%\textcolor{red}{(for long paper only)}

\textbf{Notation:}
$\mc{H}$: the Hilbert space (over the set of real numbers $\mR$); $\mc{H}^*$: the dual space of $\mc{H}$; $\langle \Phi|\in\mc{H}^*$: the left state vector; $|\Phi\rangle\in\mc{H}$: the right state vector;
$B(\mc{H})$: the space of all positive, Hermitian and bounded operators from $\mc{H}$ to itself; 
$\mc{S}$: the subset of $B(\mc{H})$ such as trace of its operators is $1$; $\mc{V}$: the space of projection-valued measurements \cite{von2018mathematical_QM};
$S$: the space of signals; $\Delta(\cdot)$: the set of probability measures over the given space;
$\mathbf{1}\in B(\mc{H})$: the identity operator; $\Om=\{H_0,H_1\}$: the space of states.


\section{Problem Formulation} 
\label{sec:formulation}
In this section, we develop the framework of detection in human-sensor systems where human adopts quantum decision theory \cite{sornette2020quantum_propsect_theory}. We assume that there are two underlying states of the system:  normal state $\om = H_0$  and abnormal state $\om = H_1$. Under each hypothesis, the observations generated $s'\in S$ obey different distributions:
\begin{equation}
    H_0: s'\sim  f_0(s),\;\;H_1: s'\sim f_1(s),\;
    \label{hypo_rho1_rho0} 
\end{equation}
where $f_0,f_1$ are probability density functions.  We associate a common prior $p(H_1),p(H_0)$, with $p(H_1)+p(H_0)=1$ with the true hypothesis. 
\begin{figure}
    \centering
    \includegraphics[scale=0.24]{QDT_Sensor.png}
    \caption{The human-sensor interaction scheme. Before the game starts the sender (sensor) commits to a type-dependent signaling devices $\rho_0,\rho_1\in \mc{S}$. The sender is a sensor/machine that obtains the true state. }
    \label{fig:quantum_prospect_theory}
\end{figure}
\begin{comment}
    It is understood that the quantum decision theory is a generalization of classical prospect theory \cite{tversky1992advances_prospect_theory} where the classical probability is generalized into quantum probability. Such generalization, assumes the validity of the quantum-classical correspondence principle \cite{bohr1976correspondence_principle} that was initiated by Bohr for analyzing spectral structures for atom spectra. 
\end{comment}
%The key feature of quantum decision theory is the entanglement of quantum states that corresponds to a classical, exogenous outcome with the quantum states associated with endogenous psychological mind state of humans. Mathematically, for every classical observation of the signal $s'\in S$, the human receiver associates a composite state of mind to produce a prospect state $|\Phi\rangle \in \mc{H}= \mc{H}_C\otimes \mc{H}_I, \;|\psi^s\rangle \in \mc{H}_C,\;\ket\in\mc{H}_I$. 

The key feature of quantum decision theory lies in the entanglement of quantum states, which connects classical, exogenous outcomes with the quantum states associated with the endogenous psychological mind state of humans. This connection is achieved by mathematically associating a composite state of mind, represented as $|\Phi\rangle \in \mathcal{H} = \mathcal{H}_C \otimes \mathcal{H}_I$, with each classical observation of the signal, denoted as $s' \in S$. The composite state consists of a quantum state $|\psi^{s'}\rangle \in \mathcal{H}_C$ representing the cognitive aspect of the human's mind and a quantum state $|\chi\rangle \in \mathcal{H}_I$ representing the subjective interpretation or perception associated with the signal. The human receiver produces a `prospect state'
$ |\Phi\rangle = |\psi^s\rangle \otimes \sum_{k}{a_{sk}\ketkk}= \sum_{k}{a_{sk}|\psi^s\varphi_k\rangle}$ (with  $\sum_{k=1}{|a_{sk}|^2} = 1$), where $\{\ketkk\}$  is  a set of orthonormal basis spanning $\mc{H}_I$ as the space of perception states. 
%For decision problems between completely exclusive events, such as distinguishing between the outcome $s$ and the outcome $s\neq s'$ with $\langle s | s'\rangle = 0$. To identify the prospect state suggests the outcome $s$, the human decision maker can construct the following operator 
% %\begin{equation}
%     P_{s} = \Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_k'|}}\Big).
% \end{equation}
% For $s'\neq s$, we can construct the operator $P_{s'}$ in a similar way as before. Notice for any possible prospect state $\Phi$, either $\Bra P_s\Ket= 0$  or $\Bra P_{s'}\Ket= 0$, suggesting that the corresponding classical outcome is not $s$ ($s'$). Observing  $\Bra P_s\Ket= 1$ suggests the underyling outcome is $s$ for certainty. 
%What is discussed before is situations when the observations of signals are deterministic.  
When the realization of signals $s$ is stochastic, obeying distributions $f_1,f_0$ as in \eqref{hypo_rho1_rho0} and depending on the true state of nature, the sensor (sender) generates two possible ``mixed prospect states" $\tilde{\rho}_1$ and $\tilde{\rho}_0$ from the set $\mathcal{S}$ as follows:  %the sensor/sender equivalently, generates two possible \textit{`mixed prospect states $\tilde{\rho}_1,\tilde{\rho}_0\in \mc{S}$'} as follows: 
 \begin{align}
        \tilde{\rho}_1 & = \sum_{s}{f_1(s)\Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_{k'}|}}\Big)},  
        \label{eq:rho1_prospect_state}
        \\
        \tilde{\rho}_0 & =  \sum_{s}{f_0(s)\Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_{k'}|}\Big)}}, 
       \label{eq:rho0_prospect_state}
    \end{align}
%To identify which distribution of signals is the true one ($f_1,f_0$), the human receiver cannot simply construct operators as before as any propspect state will produce a positive probability. The human receiver needs to strategically design an decision operator that minimizes her weighted risk. 
%The sensor does not have access to the eigenvalues $r=(r_1,\dots,r_d)\in \mR^d$ of the human's mindset $\rho\in \mc{S}$, but knows the eigenvectors and thus $\rho$ can be expressed in the following form:
%\begin{equation}
 %   \rho = \sum_{j=1}^d{r_j\ketpsij\brapsij},\;\ketpsij\in\mc{H},
%\end{equation}
%The sender does not knows the exact value of $r = (r_1,\dots,r_d)\in\mR^d$ (so treat it as a random variable $\hat{r}$) but knows they obeys some distribution $r\sim \Delta(\Delta(\mR^d))$.  

\textbf{The protocol:} We adopt a sender-receiver framework to model the relationship between a sensor and a human being, as illustrated in Figure \ref{fig:quantum_prospect_theory}. The system consists of an underlying state that satisfies the requirements described in \eqref{hypo_rho1_rho0}. We apply the following decision-making protocol for human-sensor system.  The sender(sensor) first commits to a type-dependent signal devices: $\rho_1,\rho_0\in \mc{S}$ based on the `vanilla prospect states' $\tilde{\rho}_1,\tilde{\rho}_0$. The sender observes the realization of the true state $\om\in \Om$. The sender delivers randomized signal to the receiver(human). The receiver  observes the realization of the signal $\Phi\in \mc{H}$. The receiver takes an action $a = \delta(\Phi)\in\{0,1\}$ suggesting that the human thinks the hypothesis $H_a$ holds true. The sender and the receiver both obtain reward/cost based on the true state and their actions.  

\textbf{Sender's utility function:} 
We denote $v:\Om\times \mc{S}\times \mc{S}\times B(\mc{H}) \rightarrow \mR$ be the sender's utility function.  The sender aims at seeking optimal signaling devices $\rho^*_1,\rho^*_0$ by solving the following optimization problem:
\begin{equation}
\begin{aligned}
    &\underset{\rho_1,\rho_0\in \mc{S}}{\max}\Big\{\mE_{\substack{\Phi_0\sim\rho_0 \\ \Phi_1\sim\rho_1}}[v(\om,\Phi_1,\Phi_0, P^*)]\Big\},\\
    &\text{s.t.}\;P^*\in \arg\underset{P\in B(\mc{H})}{\min}\;u(\rho^*_1,\rho_0^*,P),
\end{aligned}
\label{eq:Bayesian_Persusasion_sender}
\end{equation}
\begin{comment}
    \begin{equation}    \underset{\sigma_1,\sigma_0\in\Delta(S)}{\max}\;\mE_{\hat{r}\sim \mu }\;\Big\{\mE_{\substack{s_0\sim\sigma_0 \\ s_1\sim\sigma_1}}[v(s_1,s_0, \delta^*(s_1;\rho),\delta^*(s_0;\rho))]\Big\},
\label{eq:Bayesian_Persusasion_sender}
\end{equation}
\end{comment}
where $P^*\in B(\mc{H})$ and $u: \mc{S}\times \mc{S} \times B(\mc{H})\rightarrow \mR$ are the optimal decision rule and the utility function of the human receiver, respectively,  which we will specify later. 
%We could construct three categories for the sender: 1) helper, where ; 2) neutral; 3) destroyer; For helpful sensors 

\textbf{Human's decision model:}
Upon receiving the signal $s\in S$ from the sensor, the human receiver first construct a prospect state $\Phi$ based on $s$ as mentioned before. Then the human receiver updates the common prior belief $p(H_0),p(H_1)$ on the true hypothesis into posterior belief based on Bayes' rule:
\begin{equation}
    p(H_j|\Phi) = \frac{p(H_j)\Bra \rho_j \Ket}{p(H_0)\Bra \rho_0 \Ket + p(H_1)\Bra \rho_1 \Ket},\;\;j=0,1.
\end{equation}

The human arrives at a decision rule $\delta^*$ through projective positive-valued measurements (POVM) \cite{von2018mathematical_QM}: $P(\cdot) = \sum_{j}{\ketetaa\braetaa}$,
 where $\{\ketetaa\}_j\subset \mc{H}$ forms a set of orthonormal base vectors for the decision maker to find out.  Given any realization of the prospect state $\Ket \in \mc{H}$, we can form that the human receiver makes a probabilistic decision $a_1=\delta(\Phi) = 1$ (i.e., considering that $H_1$ holds true) with probability
$\mathbb{P}(a_1=1|\Phi) = \Bra P \Ket \equiv g + q$, where $g,q$ represent the \textit{utility factor} and the \textit{attraction factor} respectively \cite{sornette2020quantum_propsect_theory}.

Motivated by the frameworks in \cite{gezici2018_likelihood_ratio_test_prospect_hypo}, we let the probability $P_F = \tr(P\rho_0)$ denote the false alarm rate, and the probability $P_D = \tr(P\rho_1)$  the detection rate. They are used to characterize receiver's risk function due to errors. We now formulate human's problem as an optimization problem where we construct the human receiver's weighted risk function $u$ that takes into account the probabilities $P_F,P_D$ in a way similar to \cite{gezici2018_likelihood_ratio_test_prospect_hypo} based on sensor's equivalent signaling rules $\rho_1,\rho_0$ as follows:
\begin{equation}
\begin{aligned}
  &\underset{P\in B(\mc{H})}{\min }u(\rho_1,\rho_0,P,\Phi)  \\
  &={ w(p(H_0|\Phi)\tr(P \rho_0))}u_{01}+ w(p(H_1|\Phi)\tr(P\rho_1))u_{11} \\
  &+ w(p(H_0|\Phi)(1-\tr(P \rho_0)))u_{00}\\
     &+w(p(H_1|\Phi)(1-\tr (P\rho_1)))u_{10},
\end{aligned} 
    \label{eq:util_detector_proactive}
\end{equation}
where for convenience we assume $u_{11},u_{00}<0,u_{01},u_{10}>0$. The weight function $w:[0,1]\rightarrow [0,1]$ in \eqref{eq:util_detector_proactive} is selected the same as in \cite{nadendla2016human_agent_hypo_testing}:
\begin{equation}
    w(z;\eps) = {z^{\eps}},\;\;z\in[0,1],\;\eps>0,
    \label{eq:weight_function}
\end{equation}
 where $0<\eps<1$ corresponds to a pessimistic agent, while $\eps>1$ an optimistic agent \cite{nadendla2016human_agent_hypo_testing}. 

\begin{comment}
     \begin{assume}
    We assume that the human receiver earns positive reward under correction predictions and incurs cost under incorrect ones: that is, $u_{11},u_{00}>0,\; u_{01},u_{10}<0$.
    \label{assume:positive_rewards}
\end{assume}
\end{comment}








\section{Theoretical Results}
\label{sec:sol_concept}
In this section, we solve the optimization problems \eqref{eq:util_detector_proactive} and \eqref{eq:Bayesian_Persusasion_sender}. Notice the sender's utility function $v$  in \eqref{eq:Bayesian_Persusasion_sender} characterizes sender's type-dependent strategies of changing the original prospect states. We assume that the sensor construct mixed prospect states with the same form but with different `perception coefficients' $a^1_{sk}\in\mR,a^0_{sk}, s\in S,k=1,2,\dots, d$. Below, we demonstrate that the human agent's optimal decision rule corresponds to the Quantum Likelihood Ratio Test (QLRT), which bears resemblance to the approach outlined in \cite{helstrom1976quantum_estimation_detection}. % We derive below that the human agent will adopt quantum likelihood ratio test (QLRT) similar to \cite{helstrom1976quantum_estimation_detection} as his optimal decision rule below.  
\begin{prop}[QLRT as human's optimal strategy]
\label{prop:human_decision_rule}
Let $\rho_1,\rho_0\in B(\mc{H})$ be the sender's signaling devices and let $\Phi\in\mc{H}$ be the prospect state. Let the problem \eqref{eq:util_detector_proactive} be the human's receiver's optimization problem, where the receiver aims at developing optimal measurements $P^*\in B(\mc{H})$. Suppose that the weight function $w$ defined in \eqref{eq:weight_function} is monotonically increasing. Then, we arrive at the following conclusion: 
\begin{equation}
    P^* =  \sum_{\eta_j>0}{\ketetaa\braetaa},
    \label{eq:optimal_decision_rule_prospect}
\end{equation}
where $\ketetaa$ are the eigenvectors of $\rho_1-\tau \rho_0$ with eigenvalues $\eta_j,\;j=1,2,\dots$ i.e.,$(\rho_1-\tau \rho_0) \ketetaa = \eta_j \ketetaa$ for some $\tau\geq 0$.  
\end{prop}
\begin{proof}
We adopt the proof similar to the one for proposition 1 in \cite{gezici2018_likelihood_ratio_test_prospect_hypo}. We know that the human receiver aims to distinguish between two states $H_1,H_0$ corresponding to two mixed states $\rho_1,\rho_0$, respectively as in \eqref{eq:rho0_prospect_state} and \eqref{eq:rho1_prospect_state}.  Denote $y^*= \tr(P^*\rho_1)$ as the detection rate and $x^*=\tr(P^*\rho_0)$ as the false alarm rate. 
We construct the projective measurement $P^*$ for binary hypothesis testing as \eqref{eq:optimal_decision_rule_prospect}. 
Now we claim the decision rule $\delta^*:\mc{H}\rightarrow [0,1]$ is constructed as $\delta^*(\Phi) = \Bra P^*\Ket$ is optimal. To see this,
first notice via \cite{helstrom1976quantum_estimation_detection} that $P^*$ minimizes the Bayes risk for quantum detection:
\begin{equation}
    P^*\in\arg\underset{P\in B(\mc{H})}{\min}\; \tau\tr(P\rho_0) + \tr((\mathbf{1}-P)\rho_1).
\end{equation} 
Thus if we pick another arbitrary projective operator-valued measurement $P'\in B(\mc{H})$ leading to another detection rate $x'=\tr(P'\rho_1)$ and false alarm rate $y' = \tr(P'\rho_0)$,
similar to the proof of Neyman-Pearson lemma \cite{neyman_pearson1933}, we can derive
for any $P'\in B(\mc{H})$,$\tau(x^*-x')\leq y^*-y'$, where $x^*,y^*$ are the false alarm rate and detection rate of $P^*$, respectively. Since we set $y^*=y'$, we conclude $x^*\leq x'$. 
Since $w$ is monotone increasing and that the left hand side is $0$, we have 
\begin{equation}
    w(\tr((1-P^*)\rho_1))\geq w(\tr ((1- P')\rho_1)).
\end{equation}
As a result, for any measurement $P'$ leading to a certain detection rate $y'$, we can always construct a corresponding $P^*$ of the form \eqref{prop:human_decision_rule} achieving a lower false positive rate than the one of $P'$ under the same detection rate. Thus using $P^*$ of the form \eqref{eq:optimal_decision_rule_prospect} we can lower the second term without changing the first term in \eqref{eq:util_detector_proactive}. 
Thus a generic human's optimal decision rule $P^*$ minimizing the utility function $u$ must be of the form given in \eqref{eq:optimal_decision_rule_prospect}. 
\end{proof} 


% The conclusion in proposition \ref{appd:proof_human_decision_rule} states that the human decision rule under prospect theory is nothing but a likelihood ratio test in quantum hypothesis testing formulation \cite{helstrom1976quantum_estimation_detection} if assumption \ref{assume:positive_rewards} holds. 




\section{Numerical results} 
\label{sec:numerical_results}
%In this section, we illustrate the optimal detection policy for the human and the optimal signaling rule for the sensor as characterized in Section \ref{sec:sol_concept}. The first numerical example originates from a cognitive case study named Prisoner's dilemma in \cite{busemeyer2006quantum_disjunct}, in which there are two parties: a human and her opponent.

In this section, we present the numerical illustration of the optimal detection policy for the human agent and the optimal signaling rule for the sensor, as discussed in Section \ref{sec:sol_concept}. To demonstrate these concepts, we utilize a cognitive case study known as the Prisoner's Dilemma, as described in \cite{busemeyer2006quantum_disjunct}. In this scenario, there are two parties involved: a human agent and her opponent.
%Neither player knows the other's choice before receiving the outcome, which depends on both of their choices. 
\begin{comment}
    If both defect, they will receive a high reward (say $(25,25)$) as police cannot convict them without confessions. If they both confess, they will receive a low reward (say $(10,10)$) as they are convicted but the sentence is mitigated. If one cooperates while the other does not, then the one cooperating receives highest reward (say $30$) as she is not found guilty due to lack of sneaking, yet has credit for turning up the opponent.  The other party, unfortunately, receives the worst outcome (say $0$) as he is found guilty without mitigating circumstances. 
\end{comment}
signaling rules according to $\rho_1,\rho_0$.
The human decision maker faces a binary choice: defection $(a=1)$ or cooperation $(a=0)$. Simultaneously, the opponent's choices, represented by the true state of nature, consist of defection $H_1$ or cooperation $H_0$. Notably, the human agent is unaware of the opponent's action until after she has made her own decision.
The human agent's objective is to maximize her reward, which is higher when her action aligns with that of her opponent. Human makes a decision based on \eqref{eq:util_detector_proactive} while the sensor (interpreted as a message passer) producing signaling rules according to $\rho_1,\rho_0$. % To inform her decision-making process, the human agent relies on \eqref{eq:util_detector_proactive}, which provides a utility function guiding her choice. On the other hand, the sensor in our framework plays the role of a message passer. It generates signaling rules, denoted as $\rho_1$ and $\rho_0$, which determine the information communicated to the human agent regarding the opponent's action. These signaling rules are strategically designed by the sensor to effectively influence the human agent's decision-making process.

%The decision-making process of the human agent in our framework involves two possible choices: defection ($a=1$) or cooperation ($a=0$). Meanwhile, the opponent's choices, represented by the true state of nature, can either be defection ($H_1$) or cooperation ($H_0$). Importantly, the human agent is unaware of the opponent's action until after making her own decision.

%The human agent's objective is to maximize her reward, which is higher when her action aligns with that of her opponent. To achieve this, the human agent employs a decision rule based on  \eqref{eq:util_detector_proactive}.

%On the other hand, the sensor in our framework plays the role of a message passer. It generates signaling rules, denoted as $\rho_1$ and $\rho_0$, which determine the information passed to the human agent regarding the opponent's action. These signaling rules are designed strategically to guide the human agent's decision-making process effectively.

\textbf{Violation of sure-thing-principle:}
The sure-thing-principle (STP), or total probability law,  can be interpreted in decision theory as a phenomenon that if under two states $H_1,H_0$, an action $a$ is preferred to $a'$, then such preference is carried over to the scenario where the state is unknown. 
%Authors in \cite{tversky1992disjunction_effect_empirical} first observed that in the game of prisoner's dilemma empirically the defect rate of the agent is lower when the opponent's action is unknown ($66\%$) than the counterparts when the opponent either defects ($91\%$) or cooperates ($84\%$).   
Authors in \cite{busemeyer2006quantum_disjunct} have used quantum probabilistic models to justify such violations under investigations of the case of Prisoner's dilemma. 
We assume $d=2$ and $K=5$ and fix the realization of the state $\Ket$. We apply the same payoff matrix as in \cite{busemeyer2006quantum_disjunct} and set the reward values as $u_{00} = 20, u_{01} = 5, u_{10} = 10, u_{11} = 25$. Using different values of the attraction factor from $0$ to $1$, we demonstrate the violation in \cite{tversky1992disjunction_effect_empirical} in Figure \ref{fig:violation_of_sure_thing_principle}. 
\begin{figure}
    \centering
    \includegraphics[scale=0.28]{Archived/STP_violation_9450.png}
    \caption{Demonstration of violation of sure-thing-principle with $\eps = 1$:   The probability of defection for the human receiver when the opponent is known to defect and cooperate is $0.39$ and $0.26$, respectively. The probability of defection when the action of the opponent is unknown depends on the attraction factor as illustrated in the dashed curve. We observe a violation of the total law of probability in our framework. Specifically, when the attraction factor exceeds $0.001$ (indicated by the purple region), the probability of defection for the human receiver is no longer a convex combination of the probabilities associated with the opponent's certain defection or cooperation.}
\label{fig:violation_of_sure_thing_principle}
\end{figure}

%Furthermore, in Figure \ref{fig:threshold_prior}, we plot the optimal threshold as a function of $p(H_1)$.

In addition, we plot in Figure \ref{fig:threshold_prior} the human detector's optimal decision rule, characterized by the threshold,  given the prior that the opponent chooses to defect $p(H_1)$. We observe that as $p(H_1)$ increases from $0$ to $1$, the optimal detecting threshold initially increases slowly, but later drastically after a certain point, indicating that the probability that human cooperates decreases slowly when the prior $p(H_1)$ is not too large, but switch to defect very quickly after a certain point. 
\begin{figure}
    \centering
    \includegraphics[scale=0.23]{ROC_gaussian_lrtest_quantum.png}
    \caption{The ROC curves of the human agent's optimal decision rules using our framework and a previous prospect-theory-based hypothesis testing framework \cite{nadendla2016human_agent_hypo_testing}.    }
    \label{fig:threshold_prior}
\end{figure}

\textbf{The human agent's detection performance:}
% We plot the receiver-operational characteristic (ROC) curve of the human agent  human detector's optimal decision rule, characterized by the threshold.
We plot the receiver operating characteristic (ROC) curve of the human detector's optimal decision rule, which is determined by the threshold.
 Assume that the two underlying distributions $f_1,f_0$ are both Gaussian with mean $0$ and mean $1$ and with the same variance of $1$. We choose randomly the coefficients $a_{sk}$ in \eqref{eq:rho0_prospect_state} and \eqref{eq:rho1_prospect_state}.
% We can observe from Figure \ref{fig:threshold_prior} that the quantum human agent leads to a different as the attraction factor, which results from quantum interference of human's mind, influences the detection performance.  
Figure \ref{fig:threshold_prior} illustrates the observed ROC curve, highlighting the impact of the attraction factor on the human agent's detection performance. Notably, the quantum human agent exhibits a distinct behavior due to the influence of the attraction factor, which arises from the quantum interference of the human mind. This interference phenomenon leads to an intriguing deviation in the detection performance.

\section{Conclusion}
\label{sec:conclusion}

In this paper, we have proposed a novel detection framework for human-sensor systems based on quantum decision theory, which effectively captures the bounded rationality of human agents, including their risk preferences, in the decision-making process. We have specifically focused on deriving the optimal decision rule for human agents under a particular case. Additionally, we conduct an analysis to highlight the impact of the attraction factor on the detecting performance of human agents. To achieve this, we have compared the receiver operating characteristic (ROC) curves obtained using quantum decision models with those obtained using prospect-theory-based models.

Our framework possesses the flexibility to be extended to cases where the sender exhibits different preferences, which can be characterized by specifying distinct utility functions. For instance, the sender may be adversarial towards the human receiver and aim to employ persuasive strategies that lead the human agent to higher error rates. Such conflicting relationships often arise in network security detection problems and are frequently studied using game theory (see \cite{manshaei2013game_network_security}).
%In this paper we formulate a detection framework applicable in human-sensor system using quantum decision theory, capturing bounded rationality including human's risk preference for the decision making processing of human agents. Under a special case we derive the optimal decision rule for human agents. We also illustrate the impact of attraction factor upon the human agent's detecting performance via comparing ROC curves of human agents using quantum decision models and using prospect-theory-based models.

%Our framework can be generalized to the cases where the sender has various preferences, which can be characterized by specifying different utility functions. For instance, the sender could be antagonistic to the human receiver and may aim to adopt persuading strategies leading human agent's to higher error rates. Such a conflicting relationship is often seen in detection problems in network security and is frequently characterized by game theory \cite{manshaei2013game_network_security}. 
\newpage
\bibliographystyle{IEEEbib}
\bibliography{thesis}
\newpage



\end{document}
