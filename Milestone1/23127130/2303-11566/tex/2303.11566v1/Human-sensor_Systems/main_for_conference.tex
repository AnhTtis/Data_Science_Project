\documentclass[9pt]{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{amssymb,amsfonts,eurosym,geometry,ulem,graphicx,caption,color,setspace,sectsty,comment,footmisc,caption,pdflscape,subfigure,array,hyperref}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{multirow}
\usepackage{mathtools}
\normalem
\newcommand{\mR}{\mathbb{R}}
\newcommand{\mC}{\mathbb{C}}
\newcommand{\mP}{\mathbb{P}}
\newcommand{\mf}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\mG}{\mathcal{G}}
\newcommand{\mA}{\mathcal{A}}
\newcommand{\mE}{\mathbb{E}}
\newcommand{\ul}{\underline}
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\Tha}{\Theta}
\newcommand{\tha}{\theta}
\newcommand{\lam}{\lambda}
\newcommand{\Lam}{\Lambda}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\mathtoolsset{showonlyrefs}


\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{eufrak}

\newtheorem{theo}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{prop}{Proposition}
\newtheorem{Def}{Definition}
\newtheorem{assume}{Assumption}
\newtheorem{coro}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{rk}{Remark}

\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\eps}{\epsilon}
\DeclareMathOperator{\vor}{Vor}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\spt}{supp}

\newcommand{\mge}{\succcurlyeq}		% matrix greater than or equal to
\newcommand{\mgt}{\succ}			% matrix greater than
\newcommand{\mle}{\preccurlyeq}		% matrix less than or equal to
\newcommand{\mlt}{\prec}			% matrix less than
\newcommand{\note}{\textbf{Notation:}}
\newcommand{\eg}{\textbf{Example:}}

\newcommand{\ketzero}{|\varphi_0\rangle}
\newcommand{\ketone}{|\varphi_1\rangle}
\newcommand{\ket}{|\varphi\rangle}
\newcommand{\bra}{\langle\varphi|}
\newcommand{\Ket}{|\Phi\rangle}
\newcommand{\Bra}{\langle \Phi |}

\newcommand{\ketkk}{|\varphi_k\rangle}
\newcommand{\brakk}{\langle\varphi_k|}
\newcommand{\brazero}{\langle\varphi_0|}
\newcommand{\braone}{\langle\varphi_1|}

\newcommand{\ketpsi}{|\psi\rangle}
\newcommand{\brapsi}{\langle\psi|}
\newcommand{\keteta}{|\eta_i\rangle}
\newcommand{\ketetaa}{|\eta_j\rangle}
\newcommand{\ketetaaa}{|\eta_k\rangle}
\newcommand{\braeta}{\langle\eta_i|}
\newcommand{\braetaa}{\langle\eta_j|}
\newcommand{\braetaaa}{\langle\eta_k|}

\newcommand{\ketm}{|m\rangle}
\newcommand{\bram}{\langle m|}
\newcommand{\ketmzero}{|m^0\rangle}
\newcommand{\ketmone}{|m^1\rangle}
\newcommand{\bramzero}{\langle m^0|}
\newcommand{\bramone}{\langle m^1|}

\newcommand{\kets}{|s\rangle}
\newcommand{\bras}{\langle s|}
\newcommand{\ketszero}{|s^0\rangle}
\newcommand{\ketsone}{|s^1\rangle}
\newcommand{\braszero}{\langle s^0|}
\newcommand{\brasone}{\langle s^1|}

\newcommand{\kett}{|\phi'\rangle}
\newcommand{\braa}{\langle\phi'|}
\newcommand{\keti}{|\varphi_i\rangle}
\newcommand{\brai}{\langle\varphi_i|}
\newcommand{\ketk}{|k\rangle}
\newcommand{\brak}{\langle k|}

\newcommand{\ketip}{|\varphi_{i'}\rangle}% p stands for 'prime'
\newcommand{\braip}{\langle\varphi_{i'}|}


\newcommand{\ketpsij}{|\psi_j\rangle} 
\newcommand{\brapsij}{\langle\psi_j|}
\newcommand{\ketjp}{|\psi_{j'}\rangle}
\newcommand{\brajp}{\langle\psi_{j'}|}

\newcommand{\spinup}{|\uparrow\rangle}
\newcommand{\spinupbra}{\langle \uparrow |}
\newcommand{\spindown}{|\downarrow\rangle}
\newcommand{\spindownbra}{\langle \downarrow |}
\newcommand{\tr}{\text{Tr}}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}{Proposition}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\newtheorem{hyp}{Hypothesis}
\newtheorem{subhyp}{Hypothesis}[hyp]
\renewcommand{\thesubhyp}{\thehyp\alph{subhyp}}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\arraybackslash\hspace{0pt}}m{#1}}
\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}
\begin{document}
\title{Detection in human-sensor systems under quantum prospect theory using Bayesian Persuasion Frameworks}
\name{Yinan Hu and Quanyan Zhu\address{Tandon School of Engineering, New York University, Brooklyn, NY, USA}}

\maketitle
\begin{abstract}
    Human-sensor systems has a variety of applications in robotics, healthcare and finance. Sensors observe the true state of nature and produce strategically designed signals to help human arrive at more accurate decisions of the state of nature. We formulate the human-sensor system into Bayesian persuasion framework consolidated into prospect theories and construct a detection scheme where human wants to find out the true state by observing the realization of the quantum states from the sensor. We obtain the optimal signaling rule for the sensor and optimal decision rule and verify that the total law of probability is violated in this scenario. We also illustrate how the concept of rationality and influence human's detection performance and also the sender's signaling rules. 
\end{abstract}
\begin{keywords}
Quantum detection, quantum signal processing
\end{keywords}



\section{Introduction}
Detection methods play an essetnial role in statisitical signal processing. It has many applications in studying sensor-attacks \cite{meira2020synthesis_sensor_attack}, internet traffic, etc. Detection frameworks in human-sensor systems have played an important role in robotics \cite{amini2013quantum_robotics}, healthcare systems, as well as recommender systems \cite{lu2012recommender}. One important topic is how a sensor can guide human's decision making process by carefully designing signals delivered to human beings.
%There have been theories on quantum cognition that formulate human's decision making process so as to capture human's bounded rationalities. However, such models are inaccurate in the sense that human beings present bounded rationality in a variety of ways, one of which arises from the fact that human makes decisions based on their current mindsets or psychological state.
%Also, humans may have different risk preferences: some may be risk-averse and are more sensitive to losses than gains, others may feel the other way around. It is therefore crucial to take into consideration human's risk preference as well as psychological state when formulating decision making process for humans. A good candidate is quantum prospect theory \cite{sornette2020quantum_propsect_theory}.
Recently studies have adopted quantum decision theories to interpret \cite{busemeyer2012quantum_cognition} a variety of phenomena in human cognitive science that cannot be interpret using classical counterparts.
One phenomenon of such kind is order effect \cite{trueblood2017quantum_inference}, which means that human's posterior belief on perception is impacted by the order at which the classical information is provided; 
Another phenomenon is violation of sure-thing principle \cite{busemeyer2009quantum_violation_sure_thing_principple}, which refers to the violation of total probability law when the probabilities represent human perception in decision making process. 
Recently, authors in \cite{snow2022quickest_detection_QDT} have developed quickest detection frameworks consolidated quantum decision models to capture bounded rationalities in human decision making. However, risk-preference \cite{tversky1992advances_prospect_theory} also plays an important role in human's decision making process as humans may not value gains and losses at the same weight. Risk-averse humans may not be willing to sacrifice the chance of a loss in exchange for the chance of a gain when selecting lotteries. There are also theories on risk measures \cite{artzner1999coherent_risk} to characterize human's risk preferences in a more sophisticated way. 

To this end, we formulate the detection of sensor-human systems to using quantum prospect theory \cite{sornette2020quantum_propsect_theory}. Such a decision model incorporates exogenous classical outcome with psychological state to capture human's bounded rationality including the risk-preference in decision making. We have following contributions: 
first we develop a detection framework in human-sensor system where risk-preference, combined with interference to constitute the human's bounded rationality; 
second, we show the existence of an optimal likelihood-ratio-test-like policy for the human receiver;
third, we illustrate the violation of sure-thing-principle as well as the relationships between the optimal threshold and prior beliefs and risk-preference parameter.

The rest of the paper is organized as follows: in section \ref{sec:formulation} we formulate the relationship between the sensor and the human receiver and characterize the protocol that the sensor communicates with human regarding the true state of nature. In section \ref{sec:sol_concept} we the optimal decision policies for the human receivers and optimal signaling rules for sensors. In section \ref{sec:numerical_results} we simulate the solution concepts numerically. In particular, we verify the violation of sure-thing-principle and depict the optimal thresholding regarding the prior upon the true hypothesis. Finally, we conlcude in section \ref{sec:conclusion}. 

\textbf{Related work:} This work serves as a variation of the work \cite{snow2022quickest_detection_QDT} by taking into consideration of risk-preferences in human's decision making process. We here adopt Bayesian persuasion \cite{kamenica2019bayesian_persuasion} model to formulate sensor's behaviors. There are numereous game-theoretic frameworks to formulate the relationship between strategic agents.     

%\textcolor{red}{(for long paper only)}

\textbf{Notation:}
$\mc{H}$: the Hilbert space (over the set of real numbers $\mR$); $\mc{H}^*$: the dual space of $\mc{H}$; $\langle \Phi|\in\mc{H}^*$: the left state vector; $|\Phi\rangle\in\mc{H}$: the right state vector;
$B(\mc{H})$: the space of all positive, Hermitian and bounded operators from $\mc{H}$ to itself; 
$\mc{S}$: the subset of $B(\mc{H})$ such as trace of its operators is $1$; $\mc{V}$: the space of projection-valued measurements \cite{von2018mathematical_QM};
$S$: the space of signals; $\Delta(\cdot)$: the set of probability measures over the given space;
$\mathbf{1}\in B(\mc{H})$: the identity operator; $\Om=\{H_0,H_1\}$: the space of states.


\section{Formulation} 
\label{sec:formulation}
In this section we develop the framework of detection in human-sensor systems where human adopts quantum prospect theory \cite{sornette2020quantum_propsect_theory}. We assume that there are two underlying state of the system: normal $H_0$ and abnormal $H_1$, under each hypothesis the observations generated $s'\in S$ obeying different distributions:
\begin{equation}
    H_0: s'\sim  f_0(s),\;\;H_1: s'\sim f_1(s),\;
    \label{hypo_rho1_rho0} 
\end{equation}
where $f_0,f_1$ are probability density functions.  We associate a common prior $p(H_1),p(H_0)$, with $p(H_1)+p(H_0)=1$ with the true hypothesis. 
\begin{figure}
    \centering
    \includegraphics[scale=0.24]{QDT_Sensor.png}
    \caption{The human-sensor interaction scheme. Before the game starts the sender (sensor) commits to a type-dependent signaling devices $\rho_0,\rho_1\in \mc{S}$. The sender is a sensor/machine that obtains the true state. }
    \label{fig:quantum_prospect_theory}
\end{figure}
\begin{comment}
    It is understood that the quantum prospect theory is a generalization of classical prospect theory \cite{tversky1992advances_prospect_theory} where the classical probability is generalized into quantum probability. Such generalization, assumes the validity of the quantum-classical correspondence principle \cite{bohr1976correspondence_principle} that was initiated by Bohr for analyzing spectral structures for atom spectra. 
\end{comment}
The key feature of quantum prospect theory is the entanglement of quantum states that corresponds to a classical, exogenous outcome with the quantum states associated with endogenous psychological mind state of humans. Mathematically, for every classical observation of the signal $s'\in S$, the human receiver associates a composite state of mind to produce a prospect state $|\Phi\rangle \in \mc{H}= \mc{H}_C\otimes \mc{H}_I, \;|\psi^s\rangle \in \mc{H}_C,\;\ket\in\mc{H}_I$. 
%We stress that $\ket$  is essentially a superposition of basis mind states as $$|\varphi\rangle = \sum_{k}{a_{sk}\ketkk}.$$ 
%The expression above means that for every classical outcome, the human produces a superposition of basis psychological states. One key feature that distinguishes between a quantum state corresponding to a classical outcome (such as $|\psi^s\rangle$) and the psychological state (such as $\ket$) is that the former is fully testable and measurable classically. 
%For every event, there is only one quantum state of such kind associated and there is no superposition involved. The psychological states, however, are not fully testable due superposition and even for identical copies of the psychological states, identical measurement may lead to different classical results. 
The human receiver produces a `prospect state'
$ |\Phi\rangle = |\psi^s\rangle \otimes \sum_{k}{a_{sk}\ketkk}= \sum_{k}{a_{sk}|\psi^s\varphi_k\rangle},$ where $\{\ketkk\}$  is  a set of orthonormal basis spanning $\mc{H}_I$ as  with the normalization condition $\sum_{k=1}^K{|a_{sk}|^2} = 1$. 
%For decision problems between completely exclusive events, such as distinguishing between the outcome $s$ and the outcome $s\neq s'$ with $\langle s | s'\rangle = 0$. To identify the prospect state suggests the outcome $s$, the human decision maker can construct the following operator 
% %\begin{equation}
%     P_{s} = \Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_k'|}}\Big).
% \end{equation}
% For $s'\neq s$, we can construct the operator $P_{s'}$ in a similar way as before. Notice for any possible prospect state $\Phi$, either $\Bra P_s\Ket= 0$  or $\Bra P_{s'}\Ket= 0$, suggesting that the corresponding classical outcome is not $s$ ($s'$). Observing  $\Bra P_s\Ket= 1$ suggests the underyling outcome is $s$ for certainty. 
%What is discussed before is situations when the observations of signals are deterministic.  
When the realization of signals $s$ is stochastic obeying distributions $f_1,f_0$ as in \eqref{hypo_rho1_rho0}, depending on the true state of nature, the sensor/sender equivalently, generates two possible \textit{`mixed prospect states $\tilde{\rho}_1,\tilde{\rho}_0\in \mc{S}$'} as follows: 
 \begin{align}
        \tilde{\rho}_1 & = \sum_{s}{f_1(s)\Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_k'|}}\Big)},  
        \label{eq:rho1_prospect_state}
        \\
        \tilde{\rho}_0 & =  \sum_{s}{f_0(s)\Big(\sum_{k}{a_{sk}|\psi^s\varphi_k\rangle\Big)\Big(\sum_{k'}{a_{sk'}\langle \psi^s\varphi_k'|}\Big)}}, 
       \label{eq:rho0_prospect_state}
    \end{align}
%To identify which distribution of signals is the true one ($f_1,f_0$), the human receiver cannot simply construct operators as before as any propspect state will produce a positive probability. The human receiver needs to strategically design an decision operator that minimizes her weighted risk. 
%The sensor does not have access to the eigenvalues $r=(r_1,\dots,r_d)\in \mR^d$ of the human's mindset $\rho\in \mc{S}$, but knows the eigenvectors and thus $\rho$ can be expressed in the following form:
%\begin{equation}
 %   \rho = \sum_{j=1}^d{r_j\ketpsij\brapsij},\;\ketpsij\in\mc{H},
%\end{equation}
%The sender does not knows the exact value of $r = (r_1,\dots,r_d)\in\mR^d$ (so treat it as a random variable $\hat{r}$) but knows they obeys some distribution $r\sim \Delta(\Delta(\mR^d))$.  

\textbf{The protocol} We adopt a framework of sender-receiver to formulate the relationship between a sensor and a human being as depicted in figure \ref{fig:quantum_prospect_theory}. There is a system with underlying state satisfying the requirement in \eqref{hypo_rho1_rho0}. We apply the following decision-making protocol for human-sensor system: the sender(sensor) first commits to a type-dependent signal devices: $\rho_1,\rho_0\in \mc{S}$ based on the `vanilla prospect states' $\tilde{\rho}_1,\tilde{\rho}_0$; the sender observes the realization of the true state $\om\in \Om$; sender delivers randomized signal to the receiver(human); receiver  observes the realization of the signal $\Phi\in \mc{H}$; the receiver takes an action $a = \delta(\Phi)\in\{0,1\}$ suggesting that the human thinks the hypothesis $H_a$ holds true; the sender and the receiver both obtain reward/cost based on the true state and their actions.  

\textbf{Sender's utility function} 
We denote $v:\mc{S}\times \mc{S}\times B(\mc{H}) \rightarrow \mR$ be the sender's utility function.  The sender aims at seeking optimal signaling devices $\rho^*_1,\rho^*_0$ by solving the following optimization problem:
\begin{equation}
\begin{aligned}
    &\underset{\rho_1,\rho_0\in \mc{S}}{\max}\Big\{\mE_{\substack{\Phi_0\sim\rho_0 \\ \Phi_1\sim\rho_1}}[v(\Phi_1,\Phi_0, \Gamma)]\Big\},\\
    &\text{s.t.}\;P^*\in \arg\underset{P\in B(\mc{H})}{\min}\;u(\rho^*_1,\rho_0^*,P,\Phi)
\end{aligned}
\label{eq:Bayesian_Persusasion_sender}
\end{equation}
\begin{comment}
    \begin{equation}    \underset{\sigma_1,\sigma_0\in\Delta(S)}{\max}\;\mE_{\hat{r}\sim \mu }\;\Big\{\mE_{\substack{s_0\sim\sigma_0 \\ s_1\sim\sigma_1}}[v(s_1,s_0, \delta^*(s_1;\rho),\delta^*(s_0;\rho))]\Big\},
\label{eq:Bayesian_Persusasion_sender}
\end{equation}
\end{comment}
where $P^*$ and $u$ refer to the optimal decision rule and utility function of the human receiver, which we specify later. 

\textbf{Human's decision model:}
Upon receiving the signal $s\in S$ from the sensor, the human receiver first construct a prospect state $\Phi$ based on $s$ as mentioned before. Then the human receiver updates the common prior belief $p(H_0),p(H_1)$ on the true hypothesis into posterior belief based on Bayes' rule:
\begin{equation}
    p(H_j|\Phi) = \frac{p(H_j)\Bra \rho_j \Ket}{p(H_0)\Bra \rho_0 \Ket + p(H_1)\Bra \rho_1 \Ket},\;\;j=0,1.
\end{equation}

The human arrives at a decision rule $\delta^*$ through projective positive-valued measurements (POVM) \cite{von2018mathematical_QM}: $P(\cdot) = \sum_{j}{\ketetaa\braetaa}$,
 where $\{\ketetaa\}_j\subset \mc{H}$ forms a set of orthonormal base vectors for the decision maker to find out.  Given any realization of the prospect state $\Ket \in \mc{H}$, we can form that the human receiver makes a probabilistic decision $a_1=\delta(\Phi) = 1$ (i.e. considering that $H_1$ holds true) with
$\Gamma(1) = \mathbb{P}(a_1=1|\Phi) = \Bra P \Ket. $
\begin{comment}
    Then human arrives at a decision rule $\delta$ through measurement:  the goal of the human decision maker is to design projective measurement operators $P\in B(\mc{H})$ as 
\begin{equation}
    \delta(s;\rho) = \sum_{j}{\langle \eta_j(s)|{\rho}|\eta_j(s)\rangle}.
\end{equation}
\end{comment}
The probability 
\begin{equation}
\begin{aligned}
     &\Bra P \Ket= \sum_{s,s'}\sum_{k,k'}{c_{sk}c_{s'k'}\Bra s\varphi_k\rangle \langle s'\varphi_{k'}\Ket} \\
     & =\sum_{s,s'}\sum_{k}{c_{sk}c_{s'k}|\Bra s\varphi_k\rangle|^2 } \\
     &+ \sum_{s,s'}\sum_{k\neq k'}{c_{sk}c_{s'k'}\Bra s\varphi_k\rangle \langle s'\varphi_{k'}\Ket} \\ 
     & \equiv g(P;\Phi) + q(P;\Phi), 
\end{aligned}
\label{attaction_factor_util_factor}
\end{equation}
where $g(P;\Phi)$ and $q(P;\Phi)$ are named \textit{utility factor} and \textit{attraction factor} regarding the prospect state $\Phi$ upon human's decision making rule $P$. 
\begin{comment}
    \textbf{The attraction factor} 
Let $\{\ketkk\}_k\subset \mc{H}$ be the set of vectors for every vector $\ketetaa_j\in\mc{H}$, we can expand it into outcome-based vectors as 
\begin{equation}
    \ketetaa = \sum_{k=1}{b_{jk}\ketkk}.\;
\end{equation}
Therefore the prospect probabilities can be divided into two terms named \textit{attraction factor} and the \textit{utility factor}:
\begin{align}
\tr_{\mc{H}}(\rho P) &= \sum_{k_1,k_2}\sum_{j}{{b_{jk_1}b_{jk_2}\langle\varphi_{k_1}|\rho|\varphi_{k_2}\rangle}} \\
& = \sum_{k_1=k_2=k}\sum_{j}{|b_{jk}|^2\langle\varphi_{k}|\rho|\varphi_{k}\rangle} + \sum_{k_1\neq k_2}\sum_{j}{{b_{jk_1}b_{jk_2}\langle\varphi_{k_1}|\rho|\varphi_{k_2}\rangle}} \\
& \equiv \sum_{j}{g({\eta_j}) + q({\eta_j})}, 
\label{attaction_factor_util_factor}
\end{align}
where $g$ is the \textit{utility factor} and $q$ is the \textit{attraction factor}\cite{sornette2020quantum_propsect_theory}, characterizing the interference of the prospect and the state of mind and the human receiver. Meanwhile, $\tr_{\mc{H}}$ means taking trace over the whole Hilbert space $\mc{H}$ (so it is not a partial trace).  It embodies the deviations from utility-based rationality caused by interference in quantum states. 

For simplicity, we extend the definition of attraction factors so that they apply to a set of prospect states instead of a single one. With a little abuse of notation we denoted the extended attraction factor as $\bar{q}$.

\begin{Def}[Extended attraction factor]
Let $\{\ketjp\}^n_1$ be the set of vectors in $\mc{H}$. Let $\Ket \in \mc{H}$ be an arbitrary given prospect state.   We define the extended attraction factor $\bar{q}:\mc{H}^n\rightarrow \mR$ as 
\begin{equation}
    \bar{q}(\psi_1,\psi_2,\dots,\psi_n;\Ket) = \sum_{j=1}^n{q(\psi_j)},
\end{equation}
where $q$ is the attraction factor mentioned in \eqref{attaction_factor_util_factor}.
\end{Def}
%We denote $1/\bar{q}$ as the `\textit{rationality}' of human receiver. 
\end{comment}

Similar to the frameworks raised in \cite{gezici2018_likelihood_ratio_test_prospect_hypo}, we associate the probability $P_F = \tr(P\rho_0)$ means the false alarm rate, and the probability $P_D = \tr(P\rho_1)$ meaning the detection rate, to characterize receiver's risk function. We now formulate human's problem as an optimization problem where we construct the human receiver's weighted risk function $u:\mc{S}\times \mc{S} \times B(\mc{H})\times \mc{H}\rightarrow \mR$ that takes into account the probabilities $P_F,P_D$ in a way similar to \cite{gezici2018_likelihood_ratio_test_prospect_hypo} based on sensor's equivalent signaling rules $\rho_1,\rho_0$ as follows:
\begin{equation}
\begin{aligned}
  &\underset{P\in B(\mc{H})}{\min }u(\rho_1,\rho_0,P,\Phi)  \\
  &={ w(p(H_0|\Phi)\tr_{\mc{H}}(P \rho_0))}u_{01}+ w(p(H_1|\Phi)\tr_{\mc{H}} (P\rho_1))u_{11} \\
  &+ w(p(H_0|\Phi)(1-\tr_{\mc{H}}(P \rho_0)))u_{00}\\
     &+w(p(H_1|\Phi)(1-\tr_{\mc{H}} (P\rho_1)))u_{10},
\end{aligned} 
    \label{eq:util_detector_proactive}
\end{equation}
where the function $w:[0,1]\rightarrow [0,1]$ in \eqref{eq:util_detector_proactive} is a weight function of the following form (the parameter $\eps$ characterizes the decision maker's risk preference):
\begin{equation}
    w(z;\eps) = \frac{z^{\eps}}{(z^{\eps} + (1-z)^{\eps})^{1/\eps}},\;\;z\in[0,1],\;\eps>0
    \label{eq:weight_function}
\end{equation}
We notice when $\eps = 1$, the weight function reduces to a risk-neutral preference $w(z;1)= z$. 
For convenience in deriving the human's optimal decision rules, we assume the following on payoff values under different state-action pairs.
\begin{assume}
    We assume that the human receiver earns positive reward under correction predictions and incurs cost under incorrect ones: that is, $u_{11},u_{00}>0,\; u_{01},u_{10}<0$.
    \label{assume:positive_rewards}
\end{assume}





\begin{comment}
    The sensor's strategy space is 
\begin{equation}
\begin{aligned}
 \bar{A}_S := &\{({\sigma}_0,{\sigma}_1)\in [L^1(S)]^{\otimes 2}: \forall i\in\{0,1\},\;\int_{M}{{\sigma}_i(s)ds} = 1;\\
    &\;\forall s\in S, \;{\sigma}_i(s)\geq 0\}.
\end{aligned}
\label{eq:strategy_space_sender}
\end{equation}
\end{comment}


\section{Theoretical Results}
\label{sec:sol_concept}
In this section we solve the optimization problems \eqref{eq:util_detector_proactive} and \eqref{eq:Bayesian_Persusasion_sender}. We first show that there is an optimal decision policy for the human receiver and an optimal signaling policy for the sender. Then we analyze the solution. 
\subsection{Obtaining the results}

\begin{comment}
 \begin{assume}
\label{Assume:PBNE}
We make the following assumption of the sender's utility function $v$ and the human receiver's utility function $u$ for the prospect theory:
\end{assume}   
\end{comment}

\begin{prop}[LRT as human's optimal decision rule]
\label{prop:human_decision_rule}
Let $\rho_1,\rho_0\in B(\mc{H})$ be the sender's signaling devices. Let the problem \eqref{eq:util_detector_proactive} be the human's receiver's optimization problem, where the receiver aims at developing optimal measurements $P^*\in B(\mc{H})$. Suppose the weight function $w$ defined in \eqref{eq:weight_function} is monotonically increasing. and the assumption \ref{assume:positive_rewards} holds. Then we have the following conclusion: 
\begin{equation}
    P^* =  \sum_{\eta_j>0}{\ketetaa\braetaa},
    \label{eq:optimal_decision_rule_prospect}
\end{equation}
where $\ketetaa$ are eigenvectors of $\rho_1-\tau \rho_0$ with eigenvalues $\eta_j,\;j=1,2,\dots$
\begin{equation}
    (\rho_1-\tau \rho_0) \ketetaa = \eta_j \ketetaa.
\end{equation}
for some $\tau\geq 0$.  
\end{prop}
\begin{proof}
    See the appendix \ref{appd:proof_human_decision_rule}
\end{proof}

The conclusion in proposition \ref{appd:proof_human_decision_rule} states that the human decision rule under prospect theory is nothing but a likelihood ratio test in quantum hypothesis testing formulation \cite{helstrom1976quantum_estimation_detection} if assumption \ref{assume:positive_rewards} holds. 
\begin{comment}
    \begin{prop}[Sender's optimal persuading strategies]
Let $P^*$ be the optimal decision rule derived in proposition \ref{prop:human_decision_rule}. Let $\rho_1,\rho_0\in B(\mc{H})$ be generic sender's type-dependent commitment. Let $v:{B}(\mc{H})\times {B}(\mc{H})\times {B}(\mc{H})\rightarrow \mR$ be the sender's objective utility function defined in \eqref{eq:BP_QDT_sender_util}  we arrive at the sender's optimal decision rule as follows:

\begin{equation}
    \begin{aligned}
        \rho^*_1 & = \begin{cases} 
        c_1{\exp(\ln\tilde{\rho}_1 + \frac{1}{\lam})},  \\
        c_1{\exp(\ln\tilde{\rho}_1 + \frac{x}{\lam})}, \\
        \rho_1
        \end{cases} 
        \label{eq:sol_human_receiver_prospect_theory_rho1}
    \end{aligned},
\end{equation}
where 
\begin{equation}
\begin{aligned}
     \mc{M}_1 &= \{|\varphi\rangle \in \mc{H}:\bra \tilde{\rho}_1 - \tau\tilde{\rho}_0 \ket >0\}  , \\
     \mc{M}_{*} &= \{|\varphi\rangle\in \mc{H}:\bra \tilde{\rho}_1 - \tau\tilde{\rho}_0 \ket=0\},\; \\
     \mc{M}_0 &=\{|\varphi\rangle\in \mc{H}:\bra \tilde{\rho}_1 - \tau\tilde{\rho}_0 \ket <0\}.
\end{aligned}
\end{equation}
In the meantime, the normalization factors $c_0,c_1$ satisfy the following requirements:
\begin{equation}
\begin{aligned}
    c_0 &=
    c_1 &= 
\end{aligned}
\end{equation}
\label{prop:sender_perusasion_strategy}
\end{prop}

\begin{proof}
    See the appendix.
\end{proof}
\end{comment}




\begin{comment}
    \begin{Def}[Definition of PBNE]
We define the perfect Bayesian Nash equilibrium for the signaling game $\mc{G}_1$ mentioned in definition \eqref{Def:signalling_game} as a strategy profile and a belief system $(\sigma^*_1,\sigma^*_0,\delta^*,p)$ satisfying the requirements:    
\end{Def}
\begin{prop}[Existence of PBNE]
    Let $\mc{G}$ be the signaling game discussed in definition \eqref{Def:signalling_game}. With the assumption of the utility functions as indicated in assumption \ref{Assume:PBNE} 
\end{prop}

\begin{prop}[Analytical/algorithmic results for PBNE]

\end{prop}
\end{comment}

\begin{comment}
  \begin{prop}[Relevation principle does not hold]
    
\end{prop}


\begin{prop}[Existence of human's optimal decision rule]
    
\end{prop}

\begin{prop}[Computation of human's optimal decision rule]
    
\end{prop}
\end{comment}

\subsection{Analysis of the result}
We would show that under mild assumptions, when the attraction factor $q$ vanishes for some prospect state $\Ket$, the human receiver's decision rule reduces to one equivalent to likelihood ratio test \cite{levy2008principles_signal_detection} in classical hypothesis testing. %We attempt to prove bounds, inequalities regarding the utility function for human receiver's prospect decision rules. We will show that adopting classical prospect theory leads to a better utility.
\begin{prop} Let $\rho_1,\rho_0\in B(\mc{H})$ be the sender's signaling rule as indicated before with the vector of eigenvalues $\sigma_1,\sigma_0\in \Delta(\mR^d)$. Let $P^*$ be the optimal detecting policy for the human-receiver as mentioned in proposition \ref{prop:human_decision_rule}. Let ${q}(P_1;\Phi)$ be the attraction factor for the operator $P_1$ regarding the realization of the quantum state $\ket\in\mc{H}$. Construct the diagonal operator $\Lambda \in \mR^{dK\times dK}$ as follows:
\begin{equation}
    \Lambda  = \begin{bmatrix}
\Lambda_1 & \cdots & \cdots & \cdots \\
    \vdots & \Lambda_2 & \vdots & \vdots \\
    \vdots & \vdots & \ddots & \vdots \\
     \cdots & \cdots & \cdots & \Lambda_d     
     \end{bmatrix},
     \label{eq:diag_Lambda}
\end{equation}
where every $\Lambda_s \in \mR^{K\times K},\;s=1,2,\dots d$ is also a diagonal matrix:
\begin{equation}
    \Lambda_s = 
        \begin{bmatrix}
    a_{s1}\gamma_{\tau}(s) & \cdots & \cdots & \cdots \\
    \vdots & a_{s2}\gamma_{\tau}(s)  & \vdots & \vdots \\
    \vdots & \vdots & \ddots & \vdots \\
     \cdots & \cdots & \cdots &a_{sk}\gamma_{\tau}(s)
    \end{bmatrix},
\end{equation}
where $\gamma_{\tau}(s) = \sigma_1(s)- \tau\sigma_0(s)$.
If the attraction factor ${q}(P;\Phi) = 0$ for some $\Phi\in\mc{H}$, then $\langle \Phi |P^*\Ket = \Bra\Lambda\Ket$.
\label{prop:reducing_to_classical}
\end{prop}

\begin{proof}
    See the appendix on the arxiv paper.
\end{proof}

\begin{comment}
 \begin{Def}[Rationality]
Let $\rho\in \mc{S}$ be the state of mind for the human receiver. Let $\{\eta_j\}_j$ be the set of base vectors consituting the human's projection operator for decision. We denote  $1/q(\eta_j)$, where $q$ is given in \eqref{attaction_factor_util_factor}, the attraction factor, as a measurement for human's rationality. 
\end{Def}   
\end{comment}

\section{Numerical results} 
\label{sec:numerical_results}
In this section we illustrate the optimal detection policy for the human and the optimal signaling rule for the sensor as characterized in Section \ref{sec:sol_concept}. The first numerical example originates from a cognitive case study named Prisoner's dilemma in \cite{busemeyer2006quantum_disjunct}, in which there are two parties: a human and her opponent. 
%Neither player knows the other's choice before receiving the outcome, which depends on both of their choices. 
\begin{comment}
    If both defect, they will receive a high reward (say $(25,25)$) as police cannot convict them without confessions. If they both confess, they will receive a low reward (say $(10,10)$) as they are convicted but the sentence is mitigated. If one cooperates while the other does not, then the one cooperating receives highest reward (say $30$) as she is not found guilty due to lack of sneaking, yet has credit for turning up the opponent.  The other party, unfortunately, receives the worst outcome (say $0$) as he is found guilty without mitigating circumstances. 
\end{comment}
%The optimal solution for Prisoner's dilemma without no prior knowledge is that both parties confess. But if there is a sequential order of taking actions the optimal strategies may vary. For instance, if human knows her opponent cooperates, then most likely she has to cooperate and vice versa. Such phenomenon has been verified by psychological experiments \cite{busemeyer2006quantum_disjunct}. 
The human decision maker has two choices: to defect $(a=1)$ and cooperate $(a=0)$, while her opponent's choices, characterized by the true state of nature, are to defect $H_1$ or to cooperate $H_0$. The human does not know the opponent's action until after she takes an action. The human receives higher reward if her action and her opponent's coincide. We adopt hu
Human here makes a decision based on \eqref{eq:util_detector_proactive} while sensor (interpreted as a message passer)producing signaling rules according to $\rho_1,\rho_0$.

\textbf{Violation of sure-thing-principle:}
The sure-thing-principle (STP), or total probability law,  can be interpreted in decision theory as a phenomenon that if under two states $H_1,H_0$, an action $a$ is preferred to $a'$, then such preference is carried over to the scenario where the state is unknown. 
%Authors in \cite{tversky1992disjunction_effect_empirical} first observed that in the game of prisoner's dilemma empirically the defect rate of the agent is lower when the opponent's action is unknown ($66\%$) than the counterparts when the opponent either defects ($91\%$) or cooperates ($84\%$).   
Authors in \cite{busemeyer2006quantum_disjunct} adopts quantum probabilistic models to justify such violations under investigations of the case of Prisoner's dilemma. 
We assume $d=2$ and $K=5$ and fix the realization of the state $\Ket$. We apply the same payoff matrix as in \cite{busemeyer2006quantum_disjunct} and set the reward values as $u_{00} = 20, u_{01} = 5, u_{10} = 10, u_{11} = 25$. Using different values of the attraction factor from $0$ to $1$, we construct the violation in \cite{tversky1992disjunction_effect_empirical} in the following figure \ref{fig:violation_of_sure_thing_principle}. 
\begin{figure}
    \centering
    \includegraphics[scale=0.3]{STP_violation.png}
    \caption{Demonstration of violation of sure-thing-principle. We here choose $\eps = 1$.  The probability of defection for the human receiver when the opponent is known to defect and cooperate is $0.39,0.26$, respectively The probability of defection when the action of the opponent is unknown depends on attraction factor as illustrated in the dashed curve. Observing that when the attraction factor is larger than $0.001$ (the green region), the chance of defection is not a convex combination of the counterparts when the opponent's defection or cooperation is certain. Thus the total law of probability is violated.}
    \label{fig:violation_of_sure_thing_principle}
\end{figure}
In addition, we plot in Figure \ref{fig:threshold_prior} the human detector's optimal decision rule, characterized by the threshold,  given the prior that the opponent chooses to defect $p(H_1)$. We observe that as $p(H_1)$ increases from $0$ to $1$, the optimal detecting threshold initially increases slowly, but later drastically after a certain point, indicating that the probability that human cooperates decreases slowly when the prior $p(H_1)$ is not too large, but switch to defect very quickly after a certain point. 
\begin{figure}
    \centering
    \includegraphics[scale=0.25]{threshold_prior.png}
    \caption{The optimal threshold $\tau$ in terms of the prior $p(H_1)$. We pick $\eps=1$ as parameterization of the risk-preference.    }
    \label{fig:threshold_prior}
\end{figure}
\begin{figure}
    \centering
\includegraphics[scale=0.25]{risk_threshold.png}
    \caption{Optimal threshold in in terms of the risk-preference parameter $\eps$.}
    \label{fig:risk_threshold}
\end{figure}

\textbf{Risk preference and threshold}
In Figure \ref{fig:risk_threshold}, we illustrate the human receiver's optimal threshold in terms of the risk-preference parameter. We observe that when $\eps<1$, the human is risk-averse in some regions so that she tends to defect. As $\eps$ grows larger, human tends to be more risk-seeking and are more likely to cooperate.  

\section{Conclusion}
\label{sec:conclusion}
We formulate the human-sensor system using quantum prospect theory, capturing bounded rationality that also includes human's risk preference. We illustrate the violation of total probability law, which serves an important feature of quantum decision models. We also characterize the receiver's strategy as an optimal threshold policy and studies its dependence in terms of risk preference.  

One aspect that we have not addressed is the dynamical scenario where the human receiver's psychological states evolve through time while the sensor can controls the evolution by adjusting Linbladian parameters \cite{martinez2016quantum_stochastic_walk}. It is also worthwhile investigating the quantitative improvement of performance for human under the sensor's influence.
\newpage
\bibliographystyle{IEEEbib}
\bibliography{thesis}
\newpage
\section{Appendix}

\subsection{Proof of proposition \ref{prop:human_decision_rule}}
\label{appd:proof_human_decision_rule}
\begin{proof}
We adopt the proof similar to the one for proposition 1 in \cite{gezici2018_likelihood_ratio_test_prospect_hypo}. We know that the human receiver aims to distinguish between two states $H_1,H_0$ where the underlying target mixed prospect states are  $\rho_1,\rho_0$, respectively as in \eqref{eq:rho0_prospect_state} and \eqref{eq:rho1_prospect_state}.

Denote $y= \tr(P\rho_1)$ as the detection rate and $x=\tr(P\rho_0)$ as the false alarm rate. 

Thus  we could construct decision rule $P^*$ for binary hypothesis testing as \eqref{eq:optimal_decision_rule_prospect}. 

Then we prove it is the optimal decision rule. 
Consider another arbitrary projective operator-valued measurement $P'\in B(\mc{H})$ leading to detection rate $x'$ and false alarm rate $y'$. We construct the decision rule $\delta^*:\mc{H}\rightarrow [0,1]$ as 
\begin{equation}
    \delta^*(\Phi) = \Bra P^*\Ket, 
\end{equation}
where the operator $P^*$ is as follows:
\begin{equation}
    P^* =  \sum_{\eta_j>0}{\ketetaa\braetaa},
    \label{eq:optimal_decision_rule_prospect1}
\end{equation}
where $\ketetaa$ are eigenvectors of $\rho_1-\tau \rho_0$ with eigenvalues $\eta_j,\;j=1,2,\dots$
\begin{equation}
    (\rho_1-\tau \rho_0) \ketetaa = \eta_j \ketetaa.
\end{equation}
for some $\tau\geq 0$ chosen so the detection rate is $y'$. According to \cite{helstrom1976quantum_estimation_detection} we know  that $P^*$ minimizes the Bayes risk for quantum detection:
\begin{equation}
    P^*\in\arg\underset{P\in B(\mc{H})}{\min}\; \tau\tr(P\rho_0) + \tr((\mathbf{1}-P)\rho_1)
\end{equation} 
Similar to the proof of Neyman-Pearson lemma \cite{neyman_pearson1933}, we can derive
for any $P'\in B(\mc{H})$,
\begin{equation}
\begin{aligned}
    &\tau(\tr(P'\rho_0)- \tr(P^*\rho_0)) \\ 
    &\leq   \tr((1-P^*)\rho_1) - \tr ((1- P')\rho_1) \\ 
    &= \tr(P'\rho_1) - \tr (P^*\rho_1).
\end{aligned}
\end{equation}
That is, $\tau(x^*-x')\leq y^*-y'$, where $x^*,y^*$ are false alarm rate and detection rate of $P^*$, respectively. Since we set $y^*=y'$, we conclude $x^*\leq x'$. 
Since $w$ is monotone increasing and that the left hand side is $0$, we have 
\begin{equation}
    w(\tr((1-P^*)\rho_1))\geq w(\tr ((1- P')\rho_1)).
\end{equation}
As a result, for any decision rule $P'$ leading to a certain detection rate $y'$, we can always construct a corresponding $P^*$ of the form \eqref{prop:human_decision_rule} achieving a lower false positive rate than the one of $P'$ under the same detection rate. Thus using $P^*$ of the form \eqref{eq:optimal_decision_rule_prospect1} we can always lower the second term without changing the first term in \eqref{eq:util_detector_proactive}. 
Thus a generic human's optimal decision rule $P^*$ minimizing the utility function $u$ must be of the form given in \eqref{eq:optimal_decision_rule_prospect}. 
\end{proof} 

\subsection{Proof of proposition \ref{prop:reducing_to_classical}}
\label{appd:proof_reducing_to_classical}
\begin{proof}
    For a given prospect state $\Phi\in \mc{H}$, knowing the human receiver's decision $P^*$, we first write out the prospect probability $p(P^*;\Phi)$ as a sum of attraction factor and utility factor as follows:
\begin{align}
   {q}(P^*;\Phi) &=  \sum_{s}{(\sigma_1(s)-\tau\sigma_0(s))}\sum_{\substack{k,k'\\ k'\neq k}}{a_{sk}a_{sk'}\Bra s\varphi_{k'}\rangle\langle s{\varphi}_{k}\Ket}, \\
   {g}(P^*;\Phi) &=  \sum_{s}{(\sigma_1(s)-\tau\sigma_0(s))}\sum_{\substack{k}}{|a_{sk}|^2|\Bra s\varphi_{k}\rangle|^2},
\end{align}

Since we assume all coefficients are real and non-negative in \eqref{hypo_rho1_rho0}, we get that when $\bar{q}(P^*;\Phi)\rightarrow 0$, $\bar{p}(P^*;\Phi)\rightarrow \bar{f}(P^*;\Phi)$ for the given $\Ket$. Then we know that 
$\langle s'\varphi_{k'}|P^*|s\varphi_k\rangle = 0$ for all $s\neq s'$ or $k\neq k'$, that is, any non-diagonal entry of the operator $P^*$ is zero under the basis $\{|s\varphi_k\rangle\}_{\substack{s=1,2\dots,d \\ k=1,2,\dots, K}}$. But we know the diagonal elements of the operator $P^*$ is given as in \eqref{eq:diag_Lambda}, which concludes the proof. 
\end{proof}


\begin{comment}
    \subsection{Proof of proposition \ref{prop:sender_perusasion_strategy} }
\begin{proof}
    We list the generalized KKT conditions \cite{luenberger1984nonlinear} with respect to the density operators $\rho_1,\rho_0$ as follows:
    \begin{equation}
    \begin{aligned}
        0&\equiv \frac{\partial v}{\partial \rho_1} = P^* - \lambda(\ln\tilde{\rho}_1 - \ln\rho_1 + 1), \\
        0&\equiv \frac{\partial v}{\partial \rho_0} = - \lambda(\ln\tilde{\rho}_0 - \ln\rho_0 + 1),\\
        1 &= \tr(\rho_1) \\
        1 &= \tr(\rho_0) \\
    \end{aligned}
    \end{equation}
    Solving the two equations lead to 
    \begin{equation}
       {\rho}_1 = {\exp\left(\ln\tilde{\rho}_1 + \frac{1}{\lam}P\right)},\;\;\;\tilde{\rho}_0 = \rho_0.
    \end{equation}
    There are natural requirements for the density operators $\rho_1,\rho_0$ such that $\rho_1 = \rho^T_1,\;\rho_0 = \rho^T_0$ and $\tr(\rho_1) = 1,\;\tr(\rho_0) = 1$. We apply the concept of proximal method \cite{beck2017first_order_optimization} and project $\rho_1,\rho_0$ onto the boundary of the $B(\mc{H})$ and obtain the results in \eqref{eq:sol_human_receiver_prospect_theory}.
\end{proof}
\end{comment}



\end{document}
