%\newcommand{\algheur}{{\tt DEP-HACT}}
\begin{figure*}[thpb]
\vspace{0.1in}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq1.pdf}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq2.pdf}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq3.pdf}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq4.pdf}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq5.pdf}
\includegraphics[width=0.162\linewidth,trim={0 0 0 0},clip]{figures/real_exp/seq6.pdf}
\caption{Execution on the real robot %and integration with perception
: (a) Initial scene where the red bottle is hidden. (b) The robot moves the yellow bottle, which occludes the most space. (c) The robot moves the second yellow bottle, revealing the red bottle.
%, which is blocked by the green and blue bottles and not graspable,
(d and e) The robot moves the green and the blue bottles to reach the red bottle. (f) Target is now reachable.}
\label{fig:exp-real-data}
\vspace{-0.28in}
\end{figure*}

Simulated experiments and the real demonstrations are performed with the Yaskawa Motoman sda10f, with a robotiq 85 gripper attached on the right arm.

The simulated trials are randomly generated by picking random objects, dimensions, and collision-free placements within the specified workspace. 20 scenes with each of 6, 8, 10, 12, and 14 objects were used, all of which contain objects occluded from the camera. Each of the 100 trials is a unique scene. The target object in each scene was selected to be the hidden object with the most objects above it, if any.

All tested algorithms were given 20 minutes to run before being terminated. A trial run is considered successful only if the target object was retrieved within the time limit. Discovering but failing to pick up the object was still considered a failure. 

Comparisons of the success rate, number of actions for solved trials,
total run-time for solved trials,
and number of timed out trials
%and time till termination for unsolved trials
are shown in \autoref{fig:exp-data} for 3 algorithms.
The algorithms compared are the baseline random action approach (blue in figure), the proposed resolution complete pipeline without the object ranking heuristic (orange) and with it (green).
For the resolution complete approaches timing-out is not the only failure mode since they could detect certain infeasible problems (\autoref{sec:completeness}: Failure Detection)
%The system is robust to tackle hard instances as shown in Figure \ref{fig:exp-real-data}

The success rate of the resolution complete approaches is higher than that of the random baseline. 
Although its not directly apparent from the plotted results in \autoref{fig:exp-data}, the resolution complete approaches (as expected) always found a solution when the random baseline found a solution; however in one such trial the resolution complete approach without heuristic exceeded the 20 min time-limit.
It is also clear that the heuristic approach has better success than the non heuristic approach even though they are both complete. Looking at the data for timed-out experiments, it becomes clear that the increased success of the heuristic approach is due to timing out less frequently. This also coincides with the data showing that the heuristic approach overwhelmingly finds solutions faster and with fewer object manipulations. In fact, while the non-heuristic {\tt RC} approach started timing out linearly with increase in the number of objects, the heuristic approach had virtually no issue until the scenes got very cluttered with 14 objects.

It is clear that for all methods, success rate starts dropping off significantly at around 14 objects.
This marks the difficulty level for the given industrial Motoman robot and the workspace.
%This may not seem like too heavy a clutter but, if once observes the the size of the arm and the gripper in \autoref{fig:dep_graph}, it becomes clear that the industrial Motoman robot used for the simulated experiments and practical demonstration faced a more challenging task than the pristine, spacious, and structured environments it was designed for. 
A more compact robot with a streamlined end-effector (such as the ``bluction'' tool \cite{huang2022mechanical}) could scale to more cluttered scenes.%with the same pipeline.

\begin{figure}[thpb]
    \centering
    %\includegraphics[width=.49\linewidth]{figures/success_rate3.png}
    %\includegraphics[width=.49\linewidth]{figures/timed_out3.png}
    %\includegraphics[width=.49\linewidth]{figures/num_actions3.png}
    %\includegraphics[width=.49\linewidth]{figures/times3.png}
    \includegraphics[width=.99\linewidth]{figures/trial_results_succ.png}
    \caption{On top are shown the graphs of the: success rate (left) and number of timed out trials (right). On the bottom are the number of actions and the total runtime for the subset of trials in which all algorithms were successful.}
    \label{fig:exp-data}
    \vspace{-0.25in}
\end{figure}

\subsection{Integration with Perception \& Real Robot Demonstration}

The pipeline is directly transferable to scenarios on the real robot to retrieve a target red bottle from a cluttered shelf. Due to time constraints, a simple implementation of a perception system is used which only segments and detects colored cylinders without stacking. Despite the simplifications, a scene with significant object occlusion is still demonstrated with a successful retrieval.
The proposed pipeline (with heuristic) is run online and communicates with the robot controller and the RGBD camera for execution and sensing.
The camera extrinsic matrix is estimated by a classical robot-camera calibration procedure using ArUco markers \cite{tsai1989new}.
For object recognition, the perception component is implemented via plane fitting, DBSCAN segmentation \cite{ester1996density}, and cylinder fitting using Open3D \cite{zhou2018open3d}. 
The plane fitting algorithm extracts the boundaries of the workspace, which is used to construct the collision geometries in MoveIt \cite{chitta2016moveit}.
The inliers of each segmented cylinder are used to produce the segmentation mask for the RGBD image, which is used to label occlusion correspondence for each object.
To ensure safety, additional cubic collision geometries are added to the planning scene to avoid collisions between the robot and the camera.
\footnote{Videos can be found at \url{https://sites.google.com/scarletmail.rutgers.edu/occluded-obj-retrieval}}.
Extensive experiments of the proposed pipeline were not performed on the real robot but the demonstration presented was performed a few times and the pipeline was observed to have qualitatively similar performance as in simulated experiments; however, calibration and perception issues were observed to lead to pipeline failure.