{\bf Objective:} The goal of this project is to study 
%which modes of human-robot communication are most effective for task specification and 
how to best utilize task specification strategies in a task and motion planner. Specifically, the focus will be on combining voice and gesture communication to simply describe a rearrangement/assembly task. Additionally, since many tasks will initially be under-specified, it will be necessary to include two-way communication so that the robot can query for missing details in the task (e.g. final orientation of objects). Thus, task planning will involve balancing verbal query and object manipulation so as to discover and execute a task.

%\kostas{I think the first question is great but it is probably too large of a scope for one person and you will need to work with others on this aspect. My suggestion is to focus on the 2nd question. Lets pick a setup of task specification that we believe is natural for a non-expert and deal with how task and motion planning can effective achieve this specification given ambiguity and dynamic changes in the specification. Notice that I changed the title.}

%\kostas{So, key question here that needs to be answered in your following paragraph: How does the non-expert specify a task?}

{\bf Task Environment:} The task environment will feature one human agent and one robot agent (with multiple arms) surrounding a table. Within this environment the mobility and reachability of the robot can be varied. For simplicity of modeling physical human-robot interaction, it will be assumed that the robot and human are restricted to opposite sides of the table but that both can reach across the table to touch objects placed in front of one or the other. This environment allows for easy verbal and gesture based interaction while including a basic safety barrier (the table) to minimize human-robot collision.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/task_environment.png}
    \caption{A simulated scene of the task environment. In this example, Baxter observes a human pointing at a cup.}
    \label{fig:task_environment}
\end{figure}

%\kostas{I like the setup of 1 person, 1 dual-arm robot and a tabletop, where the person and the robot are on opposite sides. It is rather and clear straightforward. It allows for interaction but it also introduces a safety barrier. You may want to introduce some of this justification in the text above.}

%\kostas{What robot in the lab do you want to use for this task? This will affect whether we are talking about a mobile manipulator or a static one. Lets make the setup concrete given our lab resources, e.g., Baxter at the front desk or Motoman inside the lab in front of a table. This will help to clarify what is the next step here and you can expand upon this document with an actual image of the setup. }

{\bf Challenges:}
Besides the classic challenges of rearrangement planning, the introduction of human interaction introduces both task and motion planning challenges. In terms of motion planning, the robot must not collide with the human; this requires online collision checking and replanning. In fact, replanning the motion is not the only possible resolution to an imminent collision with the human; alternatively the robot can halt and communicate to the human that they are in the way and resume motion once they move away. This example begins to highlight the task planning challenges introduces by the human agent. Normally task planning only needs to answer ``when do I do?'' and ``when do I sense?'', but with the human involved, task planning needs to additionally answer ``what do I do?'', ``what do I say?'', ``when do I say and when do I do?''.

In addition to planning challenges, there are challenges of basic natural language processing/generation and perception/interpretation of human actions (pointing, touching, grasping).

\kostas{Lets not emphasize first tasks where the robot and the human are solving them together, where collision avoidance of the human motion is important. We can get into that incrementally.}

\kostas{Lets focus first on setups where the person is just specifying a task (e.g., through pointing, talking, etc.). The need for replanning may still arise but not because of safety considerations and collisions between the robot and the person. It will arise because of ambiguous specification of the task and the need for the robot to understand better the true objective of the person.}

\kostas{You should also be thinking of a very specific problem, such as setting up a dinner table. What are the objects involved? What will the person have to specify? What will the robot have to infer from the specification?}

\kostas{Not sure whether we should consider dialog from scratch or not. Should the robot ask every time that there is ambiguity for clarification? Or should our first attempt be: execute something given the best inference from what it has been specified and then the person can intervene and correct what is happening?}

\kostas{You cannot solve all of the problems related to this problem, i.e., planning + perception + language processing. Initially, you should try to solve the problem in simulation, where the language will be text provided by a human in a very limited vocabulary. If you want to introduce pointing, the user should be able to click in the simulation environment in order to point. When we move to the real setup, you can replace these components. Bowen or someone else may be able to help with understanding pointing. And we will need Matthew or someone else to contribute on the NLP side of things. Your focus should be on the decision making side of things.}

{\bf Related Work:} Recently pre-determined human-robot collaborative tasks has been tackled by answer-set programming paradigms mixed with hierarchical planning techniques \cite{rizwan2020human, faroni2020layered}. Such approaches require ``atoms'' that are somewhat specialized for the predefined task. Focusing more on the communication side, \cite{unhelkar2020decision} and similar works use a partially observable Markov decision process (POMDP) to model human-robot interaction. The POMDP in such approaches factor the action space and transition function into movement actions and communication actions (usually verbal). Such models also require task specific defined states/actions in order to be computationally tractable.
In \cite{raessa2020human}, a human robot assembly system is proposed that efficiently distributes sub-tasks between the human and robot; the capabilities of each are known before hand. 

\kostas{Thanks for the references. I took a quick look in them.}

\kostas{Volkan and Esra sure like "answer set programming"... it is their favorite tool! Their overall setup is interesting as it includes sensing and communication actions. The tree of conditional actions is a useful representation of the problem. We can adopt the hybrid conditional planning framework but perhaps allow ourselves to pick alternative methods for planning.}

\kostas{The two layer approach of Faroni et al. is reasonable. The focus here is more on the replanning aspects and the execution in the context of a collaborative task. Given what I mentioned above, I would like us to first see the case where the human specifies the task and the robot executes it. Some of the ideas here are still useful and the mosaic challenge is interesting. }

\kostas{Julie Sha's group is definitely one we should be paying attention to in this line of work. For sure, all of these problems can be modeled as POMDPs. But given the computational complexity of such problems, the critical issue is indeed how to factor the space so as to bring down the complexity. The focus in ref. 3 seems to be on the bidirectional communication, which again I am not sure whether this should be our starting point.}

\kostas{Kensuke Harada also has a long history in manipulation and assembly tasks. His group tends to use tools that are much closer to the ones we have been using, e.g., sampling-based planning for the low level motion planning and then some form of search or automaton for the high-level planning. The focus here is on how to distribute the tasks between the robot and the human for a collaborative problem. See what you can learn from this work in terms of a task that is executed by the robot given an ambiguous human specification.}

In \cite{wang2019symbiotic}, a taxonomy of human robot collaboration (HRC) is described and future research directions suggested. The directions that this work will focus on primarily is programming-free robot control. It is noted in \cite{wang2019symbiotic} that using gesture and voice commands alone are not practical for successful HRC especially in a noisy work environment. Rather it could be fruitful to combine learned human behavior intent models with a variety of event triggers such as voice, gaze, gestures, brain-waves, and haptic control.

\kostas{Thanks as well for the survey. I encourage you to share it with others in the emailing list and give some context of why you looked into it. For the "dinner table setup problem" as ambiguously specified by a human, are we in the "interaction" or "cooperation" area?  It was interesting to read the point from this survey that you brought up (i.e., gesture+voice not being good in noisy environments). I think we can also skip such considerations as noisy environments for now. Was this in the context of a collaborative task? The following sentence in your document talking about "learned human behavior intent models" made me believe so.}

\kostas{Make sure that you keep track of an active bibliography in this domain - this will be very useful for any paper submission as well as a quick reference as we may want to consider how to approach different challenges in this domain. The best way forward is to identify one state-of-the-art paper that we believe deals with the setup closest to the one we want to address. Then, see what are the gaps in that solution that we can improve upon. As you do an additional round of literature search, think of this objective and let me know 1-3 directions that we could consider.}

{\bf Misc. Ideas:}

Experiments/Tasks in consideration
\begin{itemize}
    \item Mosaic/Puzzle: similar to \cite{faroni2020layered} but with the user showing a picture of complete puzzle to the robot camera. Human can correct misplaced pieces or verbally communicate mistakes. Robot needs to communicate confidence of piece placement and ask for help when not confident.
    
    \item Setting a table: Human can specify one persons plate/utensils with picture or by demonstration. Robot replicates for N people. Human can communicate when robot messed up or directly fix a robots mistake and the robot would need to react to these passive or active directives.
    
\end{itemize}

\kostas{I tend to prefer the "setting a table" because it gets closer to a real application. But I am not sure about the specification of the problem via a picture or via demonstration for now. }

Methods of Communication to consider:
\begin{itemize}
    \item Verbal
    \item Gesture
    \item Haptic
    \item Gaze (to what precision?)
    \item Photographs
    \item Facial expressions?
\end{itemize}

\kostas{Let me know what you think about the following given what you have read and what you would like to do. I am thinking of this in a simulation environment first. As input we can have: a) a set of objects and their current locations, b) a semantic label for each object (e.g., "plate", "fork", etc.) - note that we can have multiple instances of the same object category - c) a text description provided by a non-expert that specifies how to setup a table with these objects and a limited vocabulary of words (such as "pick", "place", "left/right", etc.) d) optionally: the user can also point by clicking on specific objects and associate words in the text description with clicks. You could first try to setup a planning and execution framework that does its best with the specification. Then, we can look into additional communication by the user during or after the execution of the plan by the robot, where through additional verbal/text descriptions and pointing actions, the person is trying to correct the placement of objects.}

How to extend previous approaches?:

\kostas{This is key. We should find the most relevant work and build on top of that.}

I think extending the grammar based approaches to reason about goal states differently could work. Keeping some model of current human satisfaction could be used to guide the robot to plan to make actions that progress towards the goal. The general question is how to model when the robot should be learning what the goal is and when it should be acting to achieve it. Based on \cite{wang2019symbiotic} it seems that the approach to try is to have pre-programmed triggers (in the form of verbal,gesture,etc.) to tell the robot to stop and then collect an aggregate of data during this observation mode to feed into a more complex model designed to determine the goal. What I still don't know is what this goal determining model should be; could I come up with a metric on the human-robot state space or perhaps a reinforcement learning model with a reward for successful completion (e.g. thumbs up from the human). Or, should I start with more explicit models: initialize goal belief from a photograph and then refine based on human communicated corrections.

\kostas{These sounded like important questions but I am not sure I followed everything here. Perhaps iterate given the above feedback and we discuss about these questions online.}