\section{Method}

We first give an overall introduction for the task of scribble-based interactive segmentation and survey the current status of the community in Sec.~\ref{overall}. Then, we elaborate on the detailed model structure of ScribbleSeg in Sec.~\ref{framework}. Afterward, we introduce the training protocol in Sec.~\ref{sec:train}. In Sec.~\ref{val_protocol}, we describe the evaluation method and our constructed benchmark for evaluation.  

\subsection{Task Overview}
\label{overall}
\paragraph{Task definition.}
To extract a target mask, the user sequentially draws positive/negative scribbles to add/remove mask regions, and the model returns the predicted mask after receiving new interactions. For each interaction period, only one additional scribble could be provided. 

\vspace{-3mm}
\paragraph{Exisiting works.}
We survey the  scribble-based interactive segmentation methods in Tab.~\ref{tab:survey}. Most of the existing works use different protocols~(domain, data, metrics), which makes it hard to make comparisons and hinders the development of the community. However, as scribbles contain more information than clicks, it has the potential to be a more promising choice for interactive segmentation.  Thus, the community needs a standard framework to unleash the potential of scribble-based interactive segmentation. 


\begin{table}[h]
\small
\begin{center}
\scalebox{0.7}{
\begin{threeparttable}
\begin{tabular}{l|c|c|c|c|c }
\toprule[1pt]
    &  Train Data  & Train Scribbles &  Test Data & Test Scribbles  & Metrics  \\
\hline
\cite{IFIS} & COCO & Linked points  & COCO & Linked points & IoU per Scribble    \\
\cite{appearancesimilarity} & COCO & None & COCO & Human Drawn   & Annotation Time  \\
\cite{bai2014error} & None  & None & GrabCut & Random Pixels & Label Accuracy   \\
\cite{DeepIGeoS} & Medical & None & Medical & Random Pixels & Dice Score  \\

\bottomrule[1pt]
\end{tabular}
\end{threeparttable}
}
\end{center}
\vspace{-2mm}
\caption{ Survey for existing works of scribble-based interactive segmentation. Their configurations differ from each other.
}
\label{tab:survey}%添加标题 设置标签
\end{table}



\subsection{Framework for ScribbleSeg}
\label{framework}
As shown in Fig.~\ref{fig:pipeline}, we first feed the image and interaction maps into a
segmentation model. This is a commonly used baseline solution transferred from click-based methods~\cite{sofiiuk2021ritm}. To improve its performance, we analyze the characteristics of using scribbles as interactions to design novel components. Accordingly, we develop two modules: 

\vspace{-4mm}
\paragraph{Prototype Adaption.} 
Scribbles often cover more pixels than clicks, thus besides providing position/shape priors like clicks, the scribble-covered regions could better indicate the target appearance and semantics. According to this property, we propose to use the scribble-covered regions to enhance the target extraction procedure.     

Masks extraction could be understood as a correlation between the projected features and  learned prototypes~(the last FC layer for the segmentation model).  Traditional semantic segmentation models learn fixed prototypes for each category. However, interactive segmentation models learn only one prototype for the universal targets.  As the segmentation target could be any object, stuff, or part, it is challenging to use a single prototype to represent the diverse target.


We propose the Prototype Adaption Module~(PAM), which dynamically adapts the universal prototype~(the last projection kernel) by interacting with the scribble-covered features. Thus, the parameters of the segmentation model become image-specific and scribble-specific. 


As shown in the left bottom part of Fig.~\ref{fig:pipeline}, we first use the universal prototype as the convolution kernel to generate a primitive mask $\mathbf{M}_{prim}$ via dot production with the final feature map. This prototype is  initialized with learnable parameters. Afterward, we use the two user-provided scribble maps, and the primitive mask prediction to pool the feature map into three embeddings. Then, we project those embeddings using MLP layers and add them to the original prototype. As the labels of the scribble-marked regions are known, they contain more cues that indicate the user's intentions. The primitive mask could also give a global representation for the segmentation target, which helps construct a dynamic prototype with high-consistency representations.  Finally, we use this adapted prototype to predict the adapted mask, and note it as $\mathbf{M}_{ada}$.

\vspace{-2mm}
\paragraph{Corrective Refine.}
The scribbles could also provide indications for refining the segmentation details.
We propose Corrective Refine Module~(CRM) to make modifications on the $\mathbf{M}_{ada}$ predicted by PAM. As demonstrated in the right bottom of Fig.~\ref{fig:pipeline}, the first branch of CRM concatenates the predicted mask with the scribble maps and the original image to extract the features with fine details. The second branch fuses the detached features from the segmentation model. The features in CRM are kept at the resolution of stride-2 to preserve the fine details. Afterwards, we predict an error map $\mathbf{M}_{error}$ and a correction map $\mathbf{M}_{corr}$. The error map is supervised with the difference between the ground truth and the $\mathbf{M}_{ada}$. 
The final prediction is a combination of the $\mathbf{M}_{ada}$ and $\mathbf{M}_{corr}$ in the predicted error region $\mathbf{M}_{error}$. The structure of CRM is inspired by the refiner of FocalClick~\cite{focalclick}. The core differences are, we detach the feature of the segmentation model, and we use the error map to guide the detail correction process. The effectiveness of these modifications would be verified in the experiments. 

\vspace{-2mm}
\paragraph{Training losses.} The principle supervision is for the final refined prediction, for which we use normalized focal loss~(NFL)~\cite{sofiiuk2021ritm}, and note it as $\mathcal{L}_{ref}$. Besides, we also use NFL to supervise the primitive and adapted masks produced by KAM, and note them as $\mathcal{L}_{prim}$, and $\mathcal{L}_{ada}$. In addition, the error map of CRM is supervised with binary cross-entropy loss, $\mathcal{L}_{error}$. The total loss is a combination of these losses, where $\alpha, \beta, \gamma$ all equal 0.4.
\begin{equation}
    \mathcal{L}_{total} = \mathcal{L}_{ref} +  \alpha \mathcal{L}_{prim} + \beta \mathcal{L}_{ada} + \gamma \mathcal{L}_{error}
\label{equ:loss}
\end{equation}


\begin{figure}[t]
\newcommand{\image}{\includegraphics[width=0.32\columnwidth]}
\centering 
\tabcolsep=0.04cm
\renewcommand{\arraystretch}{0.06}
\begin{tabular}{ccc}
\vspace{3pt}
\image{Figures/Scribbles_train/1.png} &
\image{Figures/Scribbles_train/2.png} &
\image{Figures/Scribbles_train/3.png} \\
\vspace{3pt}
{\footnotesize (a)~Bezier Scribble } & {\footnotesize (b)~Axial Scribble} & {\footnotesize (c)~Boundary Scribble} \\

\vspace{3pt}
\image{Figures/train/4.png} &
\image{Figures/train/5.png} &
\image{Figures/train/6.png} \\
\multicolumn{3}{c}{ \footnotesize{(d)~Random compositions of scribbles during training.}} \\
\end{tabular}
\vspace{0mm}
\caption{Demonstrations of the meta scribble simulators. We combine these strategies to generate  scribbles during training. }
\vspace{-2mm}
\label{fig:scribbles_train}
\end{figure}


\subsection{Training Scribble Simulation}
\label{sec:train}

\paragraph{Meta-simulators.} The naive methods~\cite{IFIS,bai2014error,DeepIGeoS} use random dilated points to simulate scribbles, which could not satisfy the diversity. Additionally, we 
develop multiple meta-simulators to generate various scribbles.  As demonstrated in Fig.~\ref{fig:scribbles_train}, the bezier scribble uses bezier function to draw curves within the mask regions; the axial scribble calculates the media axis of the given mask; the boundary scribble draws lines along with the mask boundary. For the stroke thickness, we randomly choose values from 3 to 7.

\vspace{-4mm}
\paragraph{Scribble composition.} We combine these four strategies to generate diversified scribbles during training with carefully tuned ratios, some of the results could be found in Fig.~\ref{fig:scribbles_train} (d). When starting from a void previous mask, we generate positive scribbles in the foreground regions, and negative scribbles in the background.  

\vspace{-4mm}
\paragraph{Iterative sampling.} To better simulate the practical usage, we add scribbles iteratively. When starting from a previous mask, we first calculate the False Positive~(FP) and False Negative~(FN) regions and generate negative and positive scribbles accordingly. 
We develop two strategies to simulate the flawed masks. The first one is applying the iterative training schema~\cite{mahadevan2018iteratively}. 
Another strategy is to exert random perturbations on the ground truth masks, where we use random dilation, erosion, translation, and local erasing.  We combine these two strategies during training and make experiments to find the best combination ratio.


\begin{figure}[t]
\newcommand{\image}{\includegraphics[width=1\columnwidth]}
\centering 
\image{Figures/Paper-Diagram.pdf}
\vspace{-4mm}
\caption{The procedure of deterministic scribble generation. The true positives, false negatives, and false positives of the segmentation result are marked in red, green, and blue respectively. }
\label{fig:scribble_protocol}
\vspace{-4mm}
\end{figure}

\begin{algorithm}[t] 
\caption{Deterministic Scribble Simulator}
\label{code}
\begin{algorithmic}[1]
    \small
    \State $max\_mask = \max(error\_mask)$
    \State $skel\_mask = \hspace{0.1cm} $ \Call{MedialAxis}{$max\_mask$}
    \State $Graph = \hspace{0.1cm} $\Call{RadiusNeighbourGraph}{$skel\_mask$}
    \For {$subgraph \in \hspace{0.1cm} $\Call{Connected}{$Graph$}}
        \While {true}
            \State $cycle = \hspace{0.1cm} $\Call{FindCycle}{$subgraph$}
            \If {$cycle == \text{None}$} $\text{break}$
            \Else \hspace{0.1cm}$ 
            $\Call{RemoveCycle}{$subgraph$, $cycle$}
            \EndIf

        \EndWhile
    \EndFor
    
    \State $distance = [~]$
    \For {$v \in Graph$.$nodes$()}
        \State $max\_path = \hspace{0.1cm} $\Call{ShortestPath}{$Graph$, $v$}
        \State $distance$.append($max\_path)$
    
    \EndFor
    \State $longest\_path = \max(distance)$
    \State $scribble = \hspace{0.1cm} $\Call{BezierCurve}{$longest\_path$}
\end{algorithmic}
\end{algorithm}


\subsection{Evaluation Method}
\vspace{-5pt}
\label{val_protocol}
In this section, we introduce our evaluation protocol that could compare different methods fairly and automatically.

\vspace{-4mm}
\paragraph{Revisiting click-based evaluation.}
DIOS~\cite{DIOS} proposes the evaluation methods that followed by almost all previous click segmentation works~\cite{fbrs,jang2019brs,firstclick,sofiiuk2021ritm,sofiiuk2021ritm,chen2021cdnet,focalclick}. In this setting, the simulated clicks are added sequentially on the center of the maximum error regions for the previous prediction. For example, the first positive click is added at the center of the ground truth mask. Then, we calculate the error regions of the prediction and extract the maximum connected area. Afterwards, an additional positive/negative click would be placed at the center of this maximum connected area. Thus, clicks would be added automatically until the prediction reaches the target IOU, or when the number of clicks reaches the limitation. In this way, we could report NoC85/90~(the average Number of Clicks required to reach the IOU 85/90\% ), and NoF$^{20}$85/90~(the Numbers of Failures to reach IOU 85/90\% within 20 clicks).     

\vspace{-4mm}
\paragraph{Deterministic scribble-simulator.} We attempt to extend the click-based protocol into a more general form for scribbles. The challenge is that clicks could simply be added at the center of the error region, but not for scribbles, as they have various shapes, which introduces randomness. 

Accordingly, We develop a \textbf{deterministic} scribble simulator that could simulate human-like scribbles according to the shape and size of the given mask.
The pseudo-code for the scribble generation process is shown in Alg.~\ref{code}, and the demonstration is given in Fig.~\ref{fig:scribble_protocol}.
Similar to the click-based protocol, we first calculate the max error regions.  Then, we compute the medial axis for the largest error mask to obtain the skeleton of the objects. Afterwards, we transform the skeleton mask into a radius neighbor graph, where the neighborhood of a vertex is points at a distance less than the radius from it. Then we divide the graph into connected components sub-graphs and remove its cycles. Finally, we will create a Bezier curve with the points in the graph's longest path. The thickness of the stroke is set to a fixed value~(3 as default).

With this deterministic scribble simulator, we could iteratively add scribbles on the FP or FN regions. Thus, we generalize the NoC metric for clicks to NoI~(Number of Interactions), and report NoI85/90, NoF$^{20}$85/90.



\vspace{-4mm}
\paragraph{Evaluation benchmark.}
To perform comparisons with previous methods, we first evaluate ScribbleSeg on the benchmarks~\cite{rother2004grabcut,berkeley,SBD,davis} used by click-based models. However, they have the following disadvantages:
GrabCut~\cite{rother2004grabcut} and Berkeley~\cite{berkeley} only have 50 and 100 test images respectively, which could not provide convincing results.
SBD~\cite{SBD} contains 2802 samples, but the mask annotations are coarse, thus often causing inconsistent results, which has been discussed in ~\cite{chen2021cdnet,focalclick}.   
DAVIS~\cite{davis} contains 345 annotations, but the targets are all saliency objects. 

In general, the benchmark above only contains relatively easy cases for the salient object.
However, a good annotation tool should be able to deal with large-scope categories in complex scenes. Therefore, we additionally use ADE20K~\cite{ade20k} to evaluate our model, which covers both things and stuff for 150 categories. We use the panoptic format annotation for the ADE20K validation split. For each category, we randomly pick 5 samples~(we take the max number if there are fewer than 5 samples) and we have obtained 246 samples for stuff and 499 samples for things.


