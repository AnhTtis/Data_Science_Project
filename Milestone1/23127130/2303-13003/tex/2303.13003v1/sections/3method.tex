\section{Exploring Reliability of PTQ}
% In this section, we first decompose the Post-Training Quantization (PTQ) process into individual steps, followed by the proposal of a framework for exploring the reliability of each step. 
% The objective of this framework is to systematically evaluate each step in the PTQ process in order to expose the reliability issues.

In this section, we will initially introduce the generic workflow of the Post-Training Quantization (PTQ). 
Subsequently, we will define the PTQ reliability and propose an approach to examine the reliability of PTQ.


\subsection{PTQ Workflow}

PTQ is an effective method for compressing neural networks and accelerating their inference.
The workflow of PTQ involves three key steps, namely collecting a calibration dataset, assigning quantization settings, and optimizing quantization parameters. 
While it is worth noting that not all prior work can be neatly subsumed under these three steps, these stages are consistently found in the majority of PTQ methodologies.
% It can be break down into three steps: collecting calibration dataset, choosing quantization settings, and optimizing quantization parameters.
% Although not all previous work can be unified into these three steps, they are present in most PTQ methods.

\textbf{Collecting Calibration Dataset}: PTQ requires a calibration dataset, which is a number of input samples, to compute the activations of each layer, $\{X^1,...,X^L\}$.
The majority of academic papers typically obtain their calibration dataset through random sampling from the training dataset. 
In contrast, industrial applications involve the user collecting a specific amount of real-world data to serve as the calibration dataset.

% The reliability of this step depends on the representativeness and quality of the calibration dataset. 
% If the calibration dataset is not representative of the data that the network will encounter during inference, or if it contains outliers or biases, this can lead to inaccurate quantization parameters and reduced performance of the quantized network. 
% It is important to ensure that the calibration dataset is diverse, covers a range of inputs that the network is likely to encounter, and is free from biases or outliers.

\textbf{Assigning Quantization Settings}: The next step is to choose the quantization settings, which specify the bit-width and the quantization function. 
The quantization bit-width refers to the number of bits used to represent a numerical value in a quantized representation.
% While smaller bit-widths can reduce memory requirements and computation time, they may also lead to a loss of prediction accuracy.
% The reliability of quantized neural networks can be affected by different bit-widths. 
% Lower bit-widths can reduce the precision and dynamic range of the network's representations, leading to potential information loss and decreased accuracy. 
% Different sample categories or difficulty levels have different sensitivity to the information loss, with some categories or levels being more impacted by the reduced precision and dynamic range. 
The quantization function determines how the continuous values of weights and activations are mapped to discrete values, such as uniform quantization~\cite{krishnamoorthi2018quantizing_whitepaper} and non-uniform quantization~\cite{miyashita2016conv_logarithmic_data,yuahngli2020apot}. 
% There are several types of quantization functions $f$, including uniform, non-uniform, symmetric, and asymmetric functions.
Taking the symmetric uniform quantization function as an example, float value $x$ is quantized to $k$ bits integer $x_q$:
\begin{equation}
    x_q = clamp(round(\frac{x}{s}),-2^{k-1},2^{k-1}-1),
\label{quantization_function}
\end{equation}
where $s$ is the scaling factor, $clamp$ function limits the value into the range of k bit integer $[-2^{k-1},2^{k-1}-1]$.
For 8 bit integer, the range is [-128,127].
$x_q$ can be de-quantized as $\hat{x}=sx_q\approx x$.
% The choice of quantization function can affect the performance and reliability of the quantized neural network, as different functions may be more or less suitable for different types of datasets and architectures.
% Thus, it is important to careful evaluate the effects of different quantization settings on the network's reliability, particularly in terms of its ability to handle samples from different categories and difficulty levels.


\textbf{Optimize Quantization Parameters}: 
The final step searches for the best quantization parameters to minimize the quantization error. 
This error is typically evaluated using a metric, such as MSE~\cite{choukroun2019lowbit_for_efficient_inference}, cosine distance~\cite{wu2020easyquant}, KL distance~\cite{migacz2017tensorrt}.
The optimization can be layer-wise~\cite{migacz2017tensorrt,yuan2022ptq4vit}, block-wise~\cite{nagel2020adaround,wei2022qdrop}, or network-wise~\cite{wang2022leveraging}.
For example, we can layer-wisely optimize the scaling factors $s^l$ in Eq~\ref{quantization_function} by minimize the MSE of de-quantized activation $\hat{X^l}$ and original activation $X^l$:
\begin{equation}
    \arg\min_{s^l_x}MSE(\hat{X^l},X^l).
\end{equation}
We can use various methods, such as grid search or gradient-based methods to solve the optimization problem.
The grid search method is a commonly used approach, which tests a range of candidate values for the quantization parameters and selects the parameters that minimize the quantization error.

% The optimizing process involves feeding a representative dataset through the network and observing the activations and weights at various layers.
% A calibrator is a function that takes as input a tensor with floating-point values and returns the scaling factor and zero point that minimize the quantization error for a given bit-width. 
% The calibrator can use various optimization techniques, such as minimizing the mean squarer error (MSE) or cosine distance between the quantized and full-precision network output, to find the optimal quantization parameters.
% The choice of calibrator can affect the reliability of the quantized network, as different calibrators may have varying degrees of sensitivity to different calibration data. 
% For example, some calibrators may be more sensitive to certain types of samples, such as those from different categories or with varying levels of difficulty, leading to differences in the optimized quantization parameters.
% This step involves selecting the algorithm or method used to calibrate the quantization parameters based on the calibration dataset. 
% The reliability of this step depends on the accuracy and effectiveness of the calibrator. 
% If the calibrator is not able to accurately optimize the quantization parameters based on the calibration dataset, this can lead to reduced accuracy and performance of the final quantized network. 
% It is important to choose a reliable and effective calibrator that is appropriate for the chosen quantization settings and the architecture of the network.

\subsection{PTQ Reliability Evaluation Method}
\label{sec_evaluation_method}

The reliability of deep models is often measured through different dimensions, some commonly used dimensions include (1) model performance in various situations (including performance on the existing worst categories, noise samples, and out-of-distribution samples, etc.), (2) model robustness against test-time attacks such as adversarial attacks, and (3) the quality of the model's confidence. In this paper, we mainly focus on evaluating the reliability of existing PTQ methods based on the first dimension. Specifically, we measure its reliability by observing the accuracy changes of different categories under different quantization settings. Exploration of other dimensions will be addressed in future work.

%Reliability refers to the consistency and dependability of a test in measuring a particular characteristic or construct across different contexts, conditions, and time points. It involves the extent to which the test yields consistent and stable results across repeated trials.We define PTQ reliability as the degree to which the quantization for a neural network consistently measures its prediction accuracy across multiple trials. The variability in results arises due to the randomness in collecting the calibration dataset, which affects the quantization parameters and hence, the prediction accuracy. 

To this end, we assess the prediction accuracy on different categories\footnote{Different categories can refer not only to different class labels in classification tasks but also to grouping of object detection bounding boxes based on their sizes, shapes, or other properties, as well as to grouping of samples based on their difficulty level. } to evaluate the reliability of PTQ. 
By analyzing the prediction accuracy across multiple categories, we can gain a more comprehensive understanding of the PTQ reliability and its ability to generalize across different types of inputs. 
This approach can provide additional insights into the performance of the quantized network and help identify any potential biases or limitations that may affect its overall reliability. 

% The reliability of PTQ can be assessed using statistical measures such as the intraclass correlation coefficient (ICC), which quantifies the degree of agreement among multiple measurements of the same characteristic. Achieving high PTQ reliability requires careful selection of the calibration dataset, use of appropriate optimization algorithms, and sufficient training iterations to obtain stable quantization parameters. Overall, the assessment and improvement of PTQ reliability are critical for the reliable and accurate deployment of quantized neural networks in various applications.

To demonstrate the necessity of assessing on different categories, we experiment three representative networks, ResNet~\cite{he2016resnet} for CIFAR-10~\cite{CIFAR2009} classification task, MobileNetV2~\cite{sandler2018mobilenetv2} for ImageNet~\cite{Deng_ImageNet_CVPR2009} classification task, and YOLOv5~\cite{jocher2022yolov5} for MS COCO~\cite{lin2014mscoco} object detection task.
We performed multiple trials of network quantization with different random seeds.
In each trial, we randomly sampled a calibration dataset from the training dataset and performed PTQ quantization. 
We evaluated the performance of the quantized neural network in terms of both the average accuracy and the accuracy of each category.

% We evaluate the influence of intra-class variance, we can randomly sample multiple subsets of samples within each class. 
% We then use these subsets to construct different calibration datasets, each with a different combination of samples from each class.
% Each class has the same number of samples to avoid inter-class bias.
% After quantizing the neural network using these different calibration datasets, we test the accuracy drop of each class.

\begin{figure}[tbp] % h:here 当前位置 % b bottom % t top % p 浮动
    \centering
    \includegraphics[width=0.45\textwidth]{ims/data_intra_var.pdf} %ims/xx.png
    \caption{The box plot of accuracy drop on different classes over 50 trials with different random seeds. We only plot 10 classes of ImageNet and COCO for demonstration. "mAP" refers to mean average precision. "Small", "Medium", and "Large" refer to the precision for small, medium, and large objects.}
    \label{im_data_intra_var}
\end{figure}

Figure~\ref{im_data_intra_var} illustrates the accuracy drop from the original network, with the box spanning from the first quartile (Q1) to the third quartile (Q3) of the data, while a red horizontal line depicts the median.
Notably, the accuracy drop exhibits significant difference across categories and average values.
Firstly, we observe that different categories display varying degrees of sensitivity to quantization. 
While some categories maintain their prediction accuracy after quantization, others experience a substantial decline in accuracy.
For instance, the accuracy drop of large objects is much larger than small and medium objects, indicating large objects are more vulnerable to quantization.
Secondly, we find that the variation in accuracy drop differs significantly across categories. 
For instance, the variation in Class 4 of COCO is much larger than that of other classes. 
Thirdly, we observe that the variance of accuracy drop across most individual categories is substantially higher than the average value. 
In conclusion, the reliability of individual categories is lower than anticipated.

% The variance of accuracy drop from the original network is depicted in Figure~\ref{im_data_intra_var}, revealing significant differences between individual classes and the average value. The mean accuracy drop over different trials, as indicated by the horizontal red line, exhibits substantial variation across different classes. While some classes demonstrate minimal decline in accuracy, others experience a dramatic drop. Moreover, the variance of accuracy drop across individual classes is considerably higher than the average value, as depicted by the height of the boxes in the figure.

% Figure~\ref{im_data_intra_var} shows variance of accuracy drop from original network.
% We observe that the intra-class variance had a significant effect on individual classes. 
% For instance, some classes have an 2 points of difference.
% We think this is because that different classes may require different quantization parameters to achieve the same level of accuracy. 
% Therefore, if the calibration dataset for a specific class has a high intra-class variance, it may not accurately represent the distribution of that class, leading to sub-optimal quantization parameters for that class and a decrease in accuracy. 
% On the other hand, if the intra-class variance is low, the calibration dataset can more accurately represent the class distribution, resulting in better quantization parameters and higher accuracy.
% We also observe that intra-class variance had a small impact on the average prediction accuracy.
% This implies that a particular quantization parameter may be suitable for some classes, leading to their high prediction accuracy, while it may not be suitable for other classes, resulting in low accuracy. 
% The trade-off between these classes leads to a small change in the average accuracy.

Drawing on the above findings, we indicate that the low reliability of individual categories poses a risk in practical applications.
In many real-world scenarios, the accuracy of predictions for specific categories may be of critical importance, and any decrease in reliability for these categories can lead to serious consequences. 
For example, in medical diagnosis, the accuracy of predicting a disease may be more important than the overall accuracy of the model. 
Overall, this evaluation method can enhance the assessment of PTQ reliability and facilitate the deployment of PTQ in various real-world applications.

