\subsection{Optimization of Quantization Parameters }
\label{sec_optimization}

The final step of PTQ is to search for the optimal quantization parameters.
The goal of this step is to minimize the quantization error, which is typically evaluated using a calibration metric, such as mean squared error (MSE)~\cite{choukroun2019lowbit_for_efficient_inference}, cosine distance~\cite{wu2020easyquant}, Kullback-Leibler (KL) divergence~\cite{migacz2017tensorrt}, or MinMax~\cite{nagel2021white}.

\begin{table}[tb]
\centering
\caption{The influence of calibration metric. We report mean±std over 50 runs with different random seeds.}
\label{table_optimization}
\resizebox{\linewidth}{!}{
\begin{tabular}{ccccc}
\hline
Metric  & MSE       & Cosine    & KL        & MinMax    \\ \hline
\multicolumn{5}{c}{CIFAR-10 ResNet20 W4A4}              \\ \hline
Average & 88.1±0.19 & 88.3±0.17 & 87.0±0.29 & 79.6±1.06 \\
Class 0 & 92.3±0.37 & 92.3±0.42 & 92.6±0.49 & 88.7±1.64 \\
Class 1 & 93.1±0.42 & 91.9±0.50 & 94.0±0.40 & 88.4±1.08 \\
Class 2 & 84.6±0.46 & 83.5±0.59 & 83.8±0.68 & 71.1±1.89 \\
Class 3 & 76.5±0.71 & 79.2±0.65 & 73.9±0.80 & 73.6±1.24 \\
Class 4 & 86.7±0.64 & 86.8±0.42 & 84.4±0.81 & 71.1±2.67 \\
Class 5 & 81.6±0.62 & 81.8±0.55 & 81.0±0.82 & 72.2±1.80 \\
Class 6 & 94.2±0.40 & 94.3±0.37 & 93.7±0.43 & 89.4±1.05 \\
Class 7 & 89.8±0.49 & 90.1±0.47 & 88.4±0.61 & 86.3±0.85 \\
Class 8 & 88.8±0.74 & 89.6±0.42 & 86.1±0.87 & 64.9±3.05 \\
Class 9 & 93.4±0.45 & 93.5±0.34 & 92.5±0.56 & 90.0±0.65 \\ \hline
\multicolumn{5}{c}{ImageNet MobilenetV2 W6A6}           \\ \hline
Average & 70.2±0.07 & 70.1±0.07 & 69.9±0.06 & 69.7±0.07 \\
Class 0 & 82.8±1.27 & 82.1±0.69 & 82.8±1.21 & 83.7±1.62 \\
Class 1 & 70.6±1.13 & 69.1±1.61 & 70.2±1.38 & 70.4±1.56 \\
Class 2 & 74.3±2.53 & 71.3±2.65 & 76.1±2.56 & 74.3±3.43 \\
Class 3 & 74.7±1.82 & 74.2±2.26 & 75.6±2.91 & 75.1±2.47 \\
Class 4 & 60.6±1.89 & 61.0±1.80 & 60.2±1.46 & 61.4±2.31 \\
Class 5 & 95.2±1.38 & 95.4±1.00 & 94.7±1.18 & 93.7±1.96 \\
Class 6 & 85.6±1.56 & 82.7±2.02 & 85.1±1.80 & 83.5±2.25 \\
Class 7 & 65.7±2.09 & 62.8±1.96 & 64.7±2.18 & 64.0±1.94 \\
Class 8 & 79.9±1.60 & 79.4±1.15 & 81.1±1.56 & 81.8±2.09 \\
Class 9 & 91.4±1.56 & 92.0±1.52 & 91.4±1.67 & 91.1±1.75 \\ \hline
\end{tabular}
}
\end{table}

We conduct experiments to assess the reliability of PTQ using different calibration metrics.
Table~\ref{table_optimization} shows the results. 
% For average prediction accuracy, we observe that different metrics perform differently on different tasks. 
% Specifically, 
For CIFAR-10, the mean prediction accuracy achieved by KL and MinMax algorithms is inferior to that of MSE and Cosine, with correspondingly higher standard deviation. 
However, in the case of average prediction accuracy of ImageNet, all four metrics display comparable accuracy and standard deviation.
For individual class, variations in performance can be observed across different metrics. 
To illustrate, when considering ImageNet, the MinMax metric exhibits higher prediction accuracy for Class 0, while MSE outperforms the other metrics for Class 1, and KL yields better results for Class 2, and Cosine performs better for Class 9. 
A high standard deviation on individual classes is observed across all four metrics. 
Additionally, it is noted that the variances obtained using the KL and MinMax metrics are greater than those obtained using other metrics.

% For instance, on ImageNet, MinMax has higher prediction accuracy on Class 0, MSE is better on Class 1, KL has better prediction accuracy on Class 2, Cosine is better on Class 9.
% The high standard deviation on individual classes is observed on all of the four metrics.
% Furthermore, we observe that the variances using KL metric and MinMax metric are larger than other metrics.


% Each metric has its own strengths and weaknesses, and may be better suited for certain types of data or tasks. 
% KL divergence, for instance, is known to be effective for comparing probability distributions, while cosine distance is sensitive to the angle between two vectors.
% In addition to the characteristics of each metric, the observed differences may also be attributed to the nature of the specific task.
% For example, the CIFAR-10 dataset contains small but simple images, while ImageNet contains images of much larger and more complex scenes.
% It is possible that certain metrics may be better suited for certain types of images or datasets.

The observed differences in performance among different calibration metrics could be attributed to the characteristics of each metric. 
One possible reason for the larger variance of the KL could be the existence of long tailed samples. 
KL divergence is a measure of the difference between two probability distributions, and is particularly sensitive to differences in tail behavior. 
This means that even small differences in the tails of the distributions can result in a large divergence value. 
The MinMax metric determines the quantization parameters based on the maximum value of the data in the calibration activation.
As a result, the MinMax metric may be more sensitive to outliers or extreme values in the calibration dataset, leading to a larger variance in the quantization error. 
In contrast, other metrics such as MSE and cosine distance may be more robust to outliers and therefore have a smaller variance. 
Further research is needed to fully understand the reasons behind these observations.

% Another factor that can affect the reliability of optimization is the complexity of the search space.
% If the search space is too large, the optimization process may become computationally intractable and require significant resources. 
% On the other hand, if the search space is too small or restrictive, the optimization may not find the optimal quantization parameters and lead to decreased reliability.

% Table~\ref{} shows the results.

Another factor that can affect the reliability is the optimization algorithm.
In our study, we assessed four different optimization algorithms, including the grid search method~\cite{nagel2021white}, as well as three gradient-based approaches\footnote{These gradient based methods will optimize the scaling factors for quantizing activation and the rounding for quantizing weight.}, namely Adaround~\cite{nagel2020adaround}, BRECQ~\cite{li2021brecq}, and QDrop~\cite{wei2022qdrop}.
The results, as shown in Table~\ref{table_optimization_algorithm}, demonstrate that gradient-based methods can substantially enhance the overall prediction accuracy. 
For instance, the average accuracy on ImageNet using QDrop is 72.1\%, which is almost comparable to full-precision. 
However, our analysis reveals that the accuracy of individual classes varied considerably. 
For instance, using QDrop, Class 1 of ImageNet achieves a mean accuracy of only 68.6\%, whereas this is 70.6\% using the grid search algorithm. 
Additionally, our observation reveals that the standard deviations of individual classes are relatively high.
Therefore, we indicate that gradient-based PTQ methods may have relatively lower reliability, despite achieving better overall prediction accuracy.

% For example, the Class 1 of ImageNet only achieves 68.6\% mean accuracy using QDrop, while this is 70.6\% using the grid search algorithm.
% In addition, we also note that the variance of individual classes is very high.
% Therefore, we indicate that the gradient-based PTQ methods have relatively lower reliability although it achieves better average prediction accuracy.

\begin{table}[tb]
\centering
\caption{The influence of optimization algorithm. We report mean±std over 50 runs with different random seeds.}
\label{table_optimization_algorithm}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Algorithm & Grid Search & Adaround  & BRECQ     & QDrop     \\ \midrule
\multicolumn{5}{c}{CIFAR10 ResNet20 W4A4}                   \\ \midrule
Average   & 88.0±0.21   & 89.8±0.14 & 90.0±0.14 & 89.3±0.22 \\
Class 0   & 92.2±0.43   & 93.1±0.41 & 91.4±0.54 & 90.1±0.88 \\
Class 1   & 93.2±0.45   & 95.5±0.28 & 95.3±0.41 & 96.3±0.47 \\
Class 2   & 84.6±0.61   & 87.9±0.50 & 87.2±0.61 & 88.0±0.79 \\
Class 3   & 76.4±0.69   & 82.0±0.76 & 78.8±0.78 & 79.6±1.21 \\
Class 4   & 86.6±0.61   & 90.1±0.62 & 89.7±0.50 & 88.0±0.88 \\
Class 5   & 81.4±0.67   & 81.8±0.78 & 83.4±0.65 & 81.0±1.13 \\
Class 6   & 94.2±0.45   & 91.3±0.45 & 92.9±0.48 & 90.5±0.81 \\
Class 7   & 89.5±0.46   & 92.0±0.46 & 92.9±0.38 & 93.1±0.53 \\
Class 8   & 88.8±0.70   & 92.5±0.41 & 93.6±0.43 & 92.6±0.57 \\
Class 9   & 93.2±0.43   & 93.4±0.42 & 94.5±0.34 & 93.4±0.61 \\ \midrule
\multicolumn{5}{c}{ImageNet MobileNetV2 W6A6}               \\ \midrule
Average   & 70.2±0.07   & 72.0±0.06 & 72.1±0.06 & 72.1±0.06 \\
Class 0   & 82.8±1.27   & 82.3±1.05 & 81.7±0.98 & 82.1±1.01 \\
Class 1   & 70.6±1.13   & 67.2±2.77 & 69.2±2.27 & 68.8±2.33 \\
Class 2   & 74.3±2.53   & 81.9±2.51 & 79.7±2.37 & 80.6±2.95 \\
Class 3   & 74.7±1.82   & 76.4±2.52 & 77.0±2.01 & 78.0±2.73 \\
Class 4   & 60.6±1.89   & 63.8±2.56 & 61.1±2.34 & 60.6±2.51 \\
Class 5   & 95.2±1.38   & 95.2±0.99 & 95.4±0.98 & 95.4±1.09 \\
Class 6   & 85.6±1.56   & 92.3±1.61 & 90.7±1.43 & 89.7±2.26 \\
Class 7   & 65.7±2.09   & 64.0±1.95 & 62.8±1.65 & 63.0±1.61 \\
Class 8   & 79.9±1.60   & 80.4±1.33 & 80.8±1.38 & 78.4±0.80 \\
Class 9   & 91.4±1.56   & 93.3±1.42 & 93.5±1.25 & 91.0±1.66 \\ \bottomrule
\end{tabular}
}
\end{table}