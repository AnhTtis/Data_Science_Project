% \documentclass[10pt,twocolumn,letterpaper]{article}

% \usepackage{iccv}
% \usepackage{times}
% \usepackage{epsfig}
% \usepackage{graphicx}
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{booktabs}
% \graphicspath{ {supp_imgs} }
% \usepackage{float}
% % Include other packages here, before hyperref.

% % If you comment hyperref and then uncomment it, you should delete
% % egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% % run, let it finish, and you should be clear).
% \usepackage[breaklinks=true,bookmarks=false]{hyperref}

% \iccvfinalcopy % *** Uncomment this line for the final submission

% \def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
% \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% % Pages are numbered in submission mode, and unnumbered in camera-ready
% \ificcvfinal\pagestyle{empty}\fi

% \begin{document}

% %%%%%%%%% TITLE
% \title{}

% \author{First Author\\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% }

% % \maketitle
% % Remove page # from the first page of camera-ready.
% \ificcvfinal\thispagestyle{empty}\fi

% %-------------------------------------------------------------------------
\begin{appendices}

\section{Quantization Models}
We have quantized various CNN architectures for the ImageNet dataset, such as ResNet-18, ResNet-50, RegNetX-600m, RegNetX-3200m, MobileNetV2, and MNasNet. 
Additionally, for the CIFAR-10 dataset, we considered ResNet models with different depths, including ResNet-20, ResNet-32, ResNet-44, and ResNet-56.
In our benchmark, we conducted thorough experiments on all the mentioned models to determine that quantization reliability issues exist in various networks.

\section{Benchmark}
\subsection{Evaluation on accuracy drop}
We quantize each model 50 times, selecting different random calibration data each time, and investigate the change in quantized model's accuracy for each class compared to the accuracy of the full-precision model.
The box plot of accuracy drop on different classes over 50 trials with different random seeds is shown as follows. 
We only plot 10 classes of ImageNet.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W4A4_cifar10_resnet20_amode_mse_num_samples_64_random.pdf} 
\end{figure}
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W4A4_cifar10_resnet32_amode_mse_num_samples_64_random.pdf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W4A4_cifar10_resnet44_amode_mse_num_samples_64_random.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W4A4_cifar10_resnet56_amode_mse_num_samples_64_random.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_mnasnet_amode_mse_num_samples_64_random.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_resnet18_num_amode_mse_samples_64_random.pdf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_resnet50_amode_mse_num_samples_64_random.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_mobilenetv2_amode_mse_num_samples_64_random.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_regnetx_3200m_amode_mse_num_samples_64_random.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{supp_imgs/W6A6_imagenet_regnetx_600m_amode_mse_num_samples_64_random.pdf}
\end{figure}

\subsection{Evaluation on calibration numbers}
We tested the performance of PTQ at calibration set sizes of 1, 32, 64, and 256 separately, and the experimental results of different models are as follows:


\begin{table}[tb]
\centering
\caption{The influence of different numbers of calibration samples. We report the mean±std over 50 runs on CIFAR-10 dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Dataset Size & 1         & 32        & 256       & 1024      \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet20 W4A4}                   \\ \midrule
Average & 88.0±0.53 & 88.0±0.30 & 88.0±0.21 & 88.1±0.18 \\ 
Class 0 & 92.6±0.81 & 92.3±0.41 & 92.2±0.44 & 92.1±0.52 \\ 
Class 1 & 92.3±0.80 & 93.0±0.52 & 93.2±0.46 & 93.1±0.33 \\ 
Class 2 & 83.2±1.09 & 84.4±0.75 & 84.6±0.62 & 84.7±0.57 \\ 
Class 3 & 77.8±1.70 & 76.6±0.87 & 76.4±0.70 & 76.3±0.69 \\ 
Class 4 & 86.5±1.22 & 86.7±0.58 & 86.6±0.61 & 86.8±0.47 \\ 
Class 5 & 81.7±1.65 & 81.5±0.71 & 81.4±0.67 & 81.6±0.50 \\ 
Class 6 & 94.1±0.50 & 94.2±0.42 & 94.2±0.45 & 94.1±0.45 \\ 
Class 7 & 89.4±0.69 & 89.4±0.57 & 89.5±0.47 & 89.7±0.53 \\ 
Class 8 & 88.9±1.23 & 88.9±0.99 & 88.8±0.71 & 88.7±0.58 \\ 
Class 9 & 93.5±0.50 & 93.5±0.47 & 93.2±0.43 & 93.3±0.41 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet32 W4A4}                \\ \midrule
        Average & 87.8±0.62 & 87.8±0.29 & 87.7±0.21 & 87.7±0.24 \\ 
        Class 0 & 91.5±0.88 & 91.7±0.64 & 91.8±0.54 & 91.7±0.55 \\ 
        Class 1 & 93.5±0.71 & 93.8±0.39 & 93.8±0.36 & 94.0±0.46 \\ 
        Class 2 & 84.9±1.24 & 86.0±0.52 & 86.1±0.63 & 86.0±0.58 \\ 
        Class 3 & 69.8±2.39 & 68.1±1.06 & 67.4±1.02 & 67.3±0.85 \\ 
        Class 4 & 90.5±1.08 & 90.4±0.63 & 90.3±0.49 & 90.3±0.67 \\ 
        Class 5 & 81.7±1.80 & 81.4±0.86 & 81.4±0.77 & 81.1±0.60 \\ 
        Class 6 & 91.9±0.91 & 92.2±0.55 & 92.3±0.54 & 92.4±0.58 \\ 
        Class 7 & 88.8±0.77 & 89.4±0.55 & 89.4±0.45 & 89.3±0.47 \\ 
        Class 8 & 93.5±0.90 & 93.2±0.60 & 93.2±0.52 & 93.1±0.44 \\ 
        Class 9 & 92.0±0.67 & 91.5±0.50 & 91.5±0.40 & 91.5±0.38 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet44 W4A4}                \\ \midrule
        Average & 87.5±1.10 & 87.4±0.47 & 87.3±0.39 & 87.2±0.17 \\ 
        Class 0 & 77.5±3.07 & 77.6±1.63 & 77.4±1.13 & 77.1±0.79 \\ 
        Class 1 & 90.5±1.34 & 90.7±0.57 & 90.9±0.52 & 90.8±0.50 \\ 
        Class 2 & 84.1±2.14 & 84.0±1.00 & 83.9±0.97 & 83.6±0.68 \\ 
        Class 3 & 87.2±1.35 & 88.3±0.94 & 88.3±0.80 & 88.8±0.56 \\ 
        Class 4 & 91.7±0.88 & 91.2±0.61 & 91.2±0.55 & 91.3±0.51 \\ 
        Class 5 & 79.0±1.90 & 78.4±0.76 & 78.2±0.79 & 77.7±0.51 \\ 
        Class 6 & 89.4±2.36 & 88.0±1.55 & 87.7±1.16 & 87.2±0.57 \\ 
        Class 7 & 88.1±1.25 & 87.8±0.73 & 87.5±0.73 & 87.5±0.50 \\ 
        Class 8 & 94.0±1.16 & 94.1±0.59 & 94.2±0.52 & 94.2±0.38 \\ 
        Class 9 & 94.1±0.71 & 94.0±0.42 & 94.1±0.42 & 94.2±0.27 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet56 W4A4}                \\ \midrule
        Average & 89.3±0.80 & 89.4±0.19 & 89.4±0.19 & 89.3±0.16 \\ 
        Class 0 & 86.6±2.03 & 86.8±1.00 & 86.8±0.82 & 86.7±1.00 \\ 
        Class 1 & 90.9±1.55 & 91.3±0.44 & 91.2±0.58 & 91.0±0.54 \\ 
        Class 2 & 84.2±1.53 & 85.2±0.78 & 85.2±0.68 & 85.5±0.58 \\ 
        Class 3 & 85.1±1.53 & 84.6±0.96 & 84.8±0.84 & 84.8±0.71 \\ 
        Class 4 & 91.5±0.96 & 91.6±0.72 & 91.6±0.61 & 91.6±0.67 \\ 
        Class 5 & 78.2±1.94 & 78.0±1.10 & 77.9±1.13 & 77.4±0.92 \\ 
        Class 6 & 94.8±0.63 & 94.6±0.44 & 94.7±0.52 & 94.7±0.36 \\ 
        Class 7 & 91.7±1.33 & 92.3±0.49 & 92.1±0.51 & 92.0±0.46 \\ 
        Class 8 & 96.3±0.49 & 96.4±0.31 & 96.4±0.31 & 96.5±0.33 \\ 
        Class 9 & 93.6±0.68 & 93.5±0.51 & 93.4±0.43 & 93.4±0.42 \\ \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of different numbers of calibration samples. We report the mean±std over 50 runs on ImageNet dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}

\toprule
Dataset Size & 1         & 32        & 256       & 1024      \\ \midrule
\multicolumn{5}{c}{ImageNet ResNet18 W6A6}                   \\ \midrule
        Average & 70.0±0.29 & 70.3±0.07 & 70.3±0.06 & 70.3±0.05 \\ 
        Class 0 & 85.0±1.08 & 84.2±0.65 & 84.3±0.69 & 84.3±0.73 \\ 
        Class 1 & 89.2±1.39 & 89.6±0.83 & 89.5±0.85 & 89.4±0.93 \\ 
        Class 2 & 83.9±0.84 & 83.4±0.98 & 83.6±1.0 & 83.3±1.18 \\ 
        Class 3 & 68.6±2.02 & 68.4±1.46 & 68.6±1.85 & 68.4±1.71 \\ 
        Class 4 & 90.8±1.44 & 90.4±1.73 & 90.0±1.85 & 89.9±1.7 \\ 
        Class 5 & 70.0±1.52 & 70.8±1.26 & 70.9±1.14 & 70.7±1.11 \\ 
        Class 6 & 79.0±1.97 & 79.3±1.48 & 79.2±1.64 & 78.8±1.39 \\ 
        Class 7 & 69.4±1.39 & 68.5±1.9 & 68.5±2.26 & 68.9±1.97 \\ 
        Class 8 & 86.4±2.34 & 87.9±1.72 & 88.1±1.76 & 88.5±1.54 \\ 
        Class 9 & 98.5±1.17 & 99.9±0.39 & 100.0±0.0 & 100.0±0.0 \\ \midrule
\multicolumn{5}{c}{ImageNet ResNet50 W6A6}                \\ \midrule
        Average & 76.2±0.3 & 76.3±0.05 & 76.3±0.04 & 76.3±0.05 \\ 
        Class 0 & 94.2±0.86 & 94.7±1.04 & 95.0±1.08 & 95.0±1.15 \\ 
        Class 1 & 89.8±2.21 & 93.1±1.15 & 93.2±1.12 & 93.5±1.17 \\ 
        Class 2 & 81.7±1.22 & 81.6±1.06 & 81.7±0.9 & 81.7±0.9 \\ 
        Class 3 & 83.8±1.77 & 83.8±1.94 & 84.2±1.51 & 84.3±1.5 \\ 
        Class 4 & 87.0±1.08 & 86.5±1.24 & 86.3±1.44 & 86.0±1.41 \\ 
        Class 5 & 75.1±2.27 & 75.8±2.29 & 75.6±2.37 & 75.2±1.96 \\ 
        Class 6 & 81.5±1.91 & 81.8±1.53 & 82.0±1.83 & 81.5±1.73 \\ 
        Class 7 & 71.8±2.71 & 72.4±2.36 & 72.8±2.0 & 73.1±2.2 \\ 
        Class 8 & 84.3±1.06 & 83.6±1.08 & 84.0±0.94 & 83.2±1.32 \\ 
        Class 9 & 99.9±0.62 & 100.0±0.28 & 100.0±0.28 & 100.0±0.28 \\ \midrule
\multicolumn{5}{c}{ImageNet MobileNetV2 W6A6}                \\ \midrule
        Average & 70.0±0.37 & 70.2±0.06 & 70.2±0.06 & 70.2±0.05 \\ 
        Class 0 & 90.5±1.1 & 91.0±1.08 & 91.0±1.08 & 91.0±1.08 \\ 
        Class 1 & 83.2±2.91 & 85.2±1.13 & 85.3±0.95 & 85.3±1.03 \\ 
        Class 2 & 74.4±2.34 & 74.2±2.46 & 74.0±2.38 & 73.3±2.18 \\ 
        Class 3 & 78.2±1.78 & 78.5±1.82 & 78.0±1.83 & 78.1±1.76 \\ 
        Class 4 & 79.0±1.8 & 78.1±1.92 & 78.2±1.87 & 77.9±1.92 \\ 
        Class 5 & 67.9±2.53 & 68.3±2.15 & 68.4±2.01 & 67.9±1.7 \\ 
        Class 6 & 69.4±2.54 & 69.2±2.66 & 69.9±2.31 & 69.8±2.01 \\ 
        Class 7 & 73.4±1.27 & 73.5±1.42 & 73.1±1.39 & 73.2±1.33 \\ 
        Class 8 & 88.1±2.43 & 88.5±1.59 & 87.9±2.09 & 88.6±1.67 \\ 
        Class 9 & 97.8±0.65 & 97.3±1.03 & 97.3±1.03 & 97.3±1.24 \\ \midrule
\multicolumn{5}{c}{ImageNet MNasNet W6A6}                \\ \midrule
        Average & 74.9±0.2 & 74.8±0.22 & 74.8±0.19 & 74.8±0.14 \\ 
        Class 0 & 95.5±1.19 & 96.0±1.44 & 96.0±1.41 & 95.9±1.2 \\ 
        Class 1 & 91.0±1.56 & 91.0±1.66 & 91.2±1.59 & 91.0±1.66 \\ 
        Class 2 & 81.2±2.66 & 80.3±2.05 & 79.5±2.87 & 79.6±2.7 \\ 
        Class 3 & 83.1±2.86 & 82.6±2.77 & 82.4±2.95 & 82.1±2.5 \\ 
        Class 4 & 80.8±2.62 & 82.0±2.91 & 82.0±2.21 & 82.0±2.21 \\ 
        Class 5 & 79.2±2.23 & 78.2±2.58 & 79.1±2.01 & 79.2±2.65 \\ 
        Class 6 & 79.0±3.28 & 79.5±2.29 & 79.9±2.65 & 80.2±2.46 \\ 
        Class 7 & 65.4±3.5 & 66.8±3.73 & 67.7±3.5 & 69.2±2.53 \\ 
        Class 8 & 90.0±2.19 & 89.0±2.31 & 88.9±2.3 & 88.5±2.49 \\ 
        Class 9 & 97.9±1.41 & 97.9±1.09 & 97.6±1.13 & 97.5±1.1 \\ 
        \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of different numbers of calibration samples. We report the mean±std over 50 runs on ImageNet dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}

\toprule
Dataset Size & 1         & 32        & 256       & 1024      \\ \midrule
\multicolumn{5}{c}{ImageNet RegNetx600M W6A6}                   \\ \midrule
        Average & 72.7±0.44 & 73.0±0.07 & 73.0±0.08 & 73.0±0.06 \\ 
        Class 0 & 90.4±1.4 & 90.7±1.04 & 90.4±0.77 & 90.3±0.93 \\ 
        Class 1 & 89.3±1.24 & 89.4±1.16 & 89.3±1.11 & 89.7±0.84 \\ 
        Class 2 & 75.2±1.49 & 75.9±2.09 & 75.8±1.86 & 76.6±1.57 \\ 
        Class 3 & 76.0±1.79 & 77.1±1.61 & 77.0±1.84 & 77.1±1.84 \\ 
        Class 4 & 90.0±1.79 & 89.1±1.84 & 89.9±1.49 & 89.9±1.85 \\ 
        Class 5 & 77.1±1.92 & 75.6±1.89 & 75.8±1.99 & 75.3±1.54 \\ 
        Class 6 & 76.2±2.55 & 76.9±2.72 & 77.0±2.37 & 77.5±2.55 \\ 
        Class 7 & 73.8±2.55 & 75.0±2.37 & 75.0±2.01 & 76.2±1.91 \\ 
        Class 8 & 83.0±2.44 & 83.8±1.64 & 83.4±1.79 & 83.3±1.86 \\ 
        Class 9 & 96.0±0.28 & 96.0±0.0 & 96.0±0.28 & 96.0±0.0 \\ \midrule
\multicolumn{5}{c}{ImageNet RegNetx3200M W6A6}                \\ \midrule
        Average & 77.8±0.21 & 77.9±0.07 & 77.9±0.07 & 77.9±0.06 \\ 
        Class 0 & 94.1±0.39 & 94.0±0.28 & 94.0±0.28 & 94.0±0.0 \\ 
        Class 1 & 90.9±1.07 & 91.8±0.6 & 91.8±0.65 & 91.9±0.39 \\ 
        Class 2 & 84.6±1.33 & 84.3±1.13 & 84.5±1.19 & 84.6±1.08 \\ 
        Class 3 & 84.6±1.28 & 85.9±0.93 & 85.9±1.01 & 86.0±0.63 \\ 
        Class 4 & 92.2±0.92 & 92.2±0.78 & 92.1±0.62 & 92.0±0.4 \\ 
        Class 5 & 87.7±1.7 & 87.3±1.94 & 87.6±1.63 & 87.5±1.69 \\ 
        Class 6 & 82.5±1.37 & 82.6±1.5 & 82.2±1.48 & 82.6±1.7 \\ 
        Class 7 & 72.4±1.99 & 72.4±1.39 & 72.5±1.73 & 73.2±1.6 \\ 
        Class 8 & 85.5±1.99 & 85.9±1.98 & 86.0±1.92 & 85.6±2.0 \\ 
        Class 9 & 99.4±0.98 & 99.5±0.88 & 99.4±0.93 & 99.3±0.95 \\ \bottomrule

\end{tabular}
}
\end{table}

\subsection{Evaluation on calibration metrics}
We have studied a total of four calibration metrics, including MinMax, Cosine, KL and MSE.
Results of different models on different datasets for different metrics are as follows:

\noindent\textbf{MinMax calibration.} Quantization scaling factors are computed based on the range directly determined by the maximum and minimum values of the feature map. 
The equation for calculating the scaling factors is as follows:
\begin{equation}
    s = \frac{max(x)-min(x)}{2^n-1}.
\end{equation}

\noindent\textbf{Cosine calibration.} 
Quantization range is determined based on the cosine distance between features before and after quantization.
Here we consider asymmetric quantization, where the minimum value after quantization is set to 0. 
Therefore, we only need to find the maximum value of the quantization range.
Search 100 times uniformly within the range of the maximum value of the feature to find the maximum value that minimizes cosine distance.
The equation is as follows:
\begin{equation}
    \min_sD_{cos}(x, x^q).
\end{equation}

\begin{table}[tb]
\centering
\caption{The influence of different metrics. We report the mean±std over 50 runs on CIFAR-10 dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Dataset Size & Cosine         & KL        & MSE       & MinMax      \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet20 W4A4}                   \\ \midrule
        Average & 88.3±0.14 & 87.1±0.28 & 88.0±0.21 & 79.4±1.18 \\ 
        Class 0 & 92.4±0.54 & 92.9±0.54 & 92.2±0.44 & 88.3±1.46 \\ 
        Class 1 & 92.0±0.36 & 94.0±0.45 & 93.2±0.46 & 88.4±1.27 \\ 
        Class 2 & 83.5±0.65 & 83.6±0.62 & 84.6±0.62 & 70.7±1.94 \\ 
        Class 3 & 79.2±0.51 & 73.8±0.85 & 76.4±0.7 & 73.2±1.78 \\ 
        Class 4 & 86.9±0.48 & 84.5±0.77 & 86.6±0.61 & 71.0±2.99 \\ 
        Class 5 & 81.7±0.54 & 81.1±0.79 & 81.4±0.67 & 72.1±1.71 \\ 
        Class 6 & 94.3±0.33 & 93.8±0.46 & 94.2±0.45 & 89.4±1.06 \\ 
        Class 7 & 90.1±0.48 & 88.5±0.57 & 89.5±0.47 & 86.3±0.7 \\ 
        Class 8 & 89.6±0.48 & 85.9±0.87 & 88.8±0.71 & 64.9±3.47 \\ 
        Class 9 & 93.7±0.33 & 92.7±0.42 & 93.2±0.43 & 90.0±0.66 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet32 W4A4}                \\ \midrule
        Average & 88.1±0.19 & 86.4±0.48 & 87.7±0.21 & 73.9±1.42 \\ 
        Class 0 & 92.0±0.48 & 90.9±1.0 & 91.8±0.54 & 85.9±2.42 \\ 
        Class 1 & 92.9±0.37 & 94.3±0.45 & 93.8±0.36 & 88.6±1.02 \\ 
        Class 2 & 85.2±0.58 & 85.3±0.85 & 86.1±0.63 & 72.2±2.55 \\ 
        Class 3 & 70.2±0.87 & 64.9±1.69 & 67.4±1.02 & 45.1±2.62 \\ 
        Class 4 & 91.6±0.48 & 86.7±1.24 & 90.3±0.49 & 72.5±2.3 \\ 
        Class 5 & 81.8±0.61 & 82.3±1.67 & 81.4±0.77 & 62.0±3.35 \\ 
        Class 6 & 92.1±0.45 & 89.0±1.16 & 92.3±0.54 & 88.8±2.23 \\ 
        Class 7 & 88.6±0.46 & 89.9±0.67 & 89.4±0.45 & 78.7±3.01 \\ 
        Class 8 & 94.2±0.28 & 90.1±1.63 & 93.2±0.52 & 63.5±4.22 \\ 
        Class 9 & 92.1±0.37 & 90.3±0.84 & 91.5±0.4 & 81.5±2.97 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet44 W4A4}                \\ \midrule
        Average & 87.9±0.31 & 85.1±0.51 & 87.3±0.39 & 62.6±5.08 \\ 
        Class 0 & 78.5±1.09 & 83.2±1.51 & 77.4±1.13 & 27.3±8.72 \\ 
        Class 1 & 89.8±0.48 & 91.2±0.87 & 90.9±0.52 & 68.2±7.1 \\ 
        Class 2 & 84.6±0.86 & 80.4±1.32 & 83.9±0.97 & 56.3±6.9 \\ 
        Class 3 & 87.6±0.68 & 87.7±0.88 & 88.3±0.8 & 88.2±1.43 \\ 
        Class 4 & 91.8±0.44 & 87.9±1.21 & 91.2±0.55 & 73.4±5.74 \\ 
        Class 5 & 79.6±0.77 & 70.0±1.79 & 78.2±0.79 & 64.8±3.74 \\ 
        Class 6 & 90.6±0.83 & 85.5±1.73 & 87.7±1.16 & 61.2±11.26 \\ 
        Class 7 & 88.1±0.61 & 83.0±1.23 & 87.5±0.73 & 56.6±6.58 \\ 
        Class 8 & 94.4±0.51 & 91.4±0.82 & 94.2±0.52 & 54.2±10.08 \\ 
        Class 9 & 94.2±0.41 & 90.3±0.88 & 94.1±0.42 & 76.2±4.44 \\ \midrule
\multicolumn{5}{c}{CIFAR-10 ResNet56 W4A4}                \\ \midrule
        Average & 89.1±0.17 & 85.7±0.69 & 89.4±0.19 & 72.7±3.12 \\ 
        Class 0 & 84.9±0.54 & 88.5±1.09 & 86.8±0.82 & 72.6±8.02 \\ 
        Class 1 & 89.7±0.52 & 94.3±0.7 & 91.2±0.58 & 78.9±6.8 \\ 
        Class 2 & 84.1±0.57 & 84.3±1.12 & 85.2±0.68 & 59.5±6.61 \\ 
        Class 3 & 85.6±0.69 & 77.5±2.2 & 84.8±0.84 & 81.5±4.02 \\ 
        Class 4 & 92.0±0.48 & 73.7±3.08 & 91.6±0.61 & 51.5±8.77 \\ 
        Class 5 & 77.8±0.63 & 78.7±2.03 & 77.9±1.13 & 65.3±4.89 \\ 
        Class 6 & 94.8±0.33 & 90.8±1.08 & 94.7±0.52 & 80.0±4.4 \\ 
        Class 7 & 91.7±0.46 & 87.0±1.45 & 92.1±0.51 & 76.1±3.69 \\ 
        Class 8 & 96.9±0.24 & 90.4±1.36 & 96.4±0.31 & 75.4±6.05 \\ 
        Class 9 & 93.9±0.36 & 91.7±0.63 & 93.4±0.43 & 86.0±3.56 \\ \bottomrule
\end{tabular}
}
\end{table}
\begin{table}[htb]
\centering
\caption{The influence of different metrics. We report the mean±std over 50 runs on ImageNet dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}

\toprule
Dataset Size & Cosine         & KL        & MSE       & MinMax      \\ \midrule
\multicolumn{5}{c}{ImageNet ResNet18 W6A6}                   \\ \midrule
        Average & 70.2±0.05 & 70.3±0.04 & 70.3±0.06 & 69.8±0.15 \\ 
        Class 0 & 84.7±0.95 & 84.5±0.88 & 84.3±0.69 & 84.8±0.98 \\ 
        Class 1 & 89.6±0.83 & 89.3±0.96 & 89.5±0.85 & 89.6±1.42 \\ 
        Class 2 & 83.2±1.12 & 83.6±1.31 & 83.6±1.0 & 84.9±1.51 \\ 
        Class 3 & 68.2±2.33 & 68.9±2.05 & 68.6±1.85 & 65.8±3.65 \\ 
        Class 4 & 91.1±1.07 & 91.0±1.34 & 90.0±1.85 & 86.6±2.41 \\ 
        Class 5 & 70.4±1.4 & 69.9±0.69 & 70.9±1.14 & 70.4±1.92 \\ 
        Class 6 & 79.4±1.65 & 78.8±1.2 & 79.2±1.64 & 79.8±2.25 \\ 
        Class 7 & 69.4±1.34 & 68.8±2.15 & 68.5±2.26 & 68.4±2.2 \\ 
        Class 8 & 88.0±1.47 & 87.8±1.9 & 88.1±1.76 & 87.2±1.96 \\ 
        Class 9 & 98.7±0.95 & 100.0±0.0 & 100.0±0.0 & 99.6±0.8 \\ \midrule
\multicolumn{5}{c}{ImageNet ResNet50 W6A6}                \\ \midrule
        Average & 76.3±0.05 & 76.3±0.06 & 76.3±0.04 & 75.7±0.29 \\ 
        Class 0 & 94.2±0.6 & 94.3±0.8 & 95.0±1.08 & 93.6±1.91 \\ 
        Class 1 & 91.4±1.0 & 92.9±0.99 & 93.2±1.12 & 94.8±1.14 \\ 
        Class 2 & 81.9±0.56 & 81.4±0.9 & 81.7±0.9 & 82.9±2.12 \\ 
        Class 3 & 84.8±1.5 & 84.4±1.73 & 84.2±1.51 & 83.5±3.01 \\ 
        Class 4 & 87.7±0.73 & 87.5±0.88 & 86.3±1.44 & 83.4±2.67 \\ 
        Class 5 & 75.6±2.15 & 76.9±2.23 & 75.6±2.37 & 78.2±2.22 \\ 
        Class 6 & 81.8±1.73 & 80.8±1.69 & 82.0±1.83 & 79.2±2.85 \\ 
        Class 7 & 70.7±2.1 & 70.1±2.51 & 72.8±2.0 & 74.4±2.65 \\ 
        Class 8 & 84.0±0.85 & 84.1±1.35 & 84.0±0.94 & 83.3±2.55 \\ 
        Class 9 & 100.0±0.0 & 100.0±0.28 & 100.0±0.28 & 99.1±0.99 \\ \midrule
\multicolumn{5}{c}{ImageNet MobileNetV2 W6A6}                \\ \midrule
        Average & 70.1±0.06 & 69.9±0.07 & 70.2±0.06 & 69.7±0.07 \\ 
        Class 0 & 90.6±0.9 & 91.2±0.97 & 91.0±1.08 & 90.7±1.1 \\ 
        Class 1 & 85.2±1.14 & 85.2±1.05 & 85.3±0.95 & 86.6±1.22 \\ 
        Class 2 & 75.5±2.61 & 73.3±2.45 & 74.0±2.38 & 68.4±2.1 \\ 
        Class 3 & 78.2±1.94 & 78.8±1.92 & 78.0±1.83 & 79.2±2.0 \\ 
        Class 4 & 79.9±1.13 & 78.0±1.81 & 78.2±1.87 & 77.0±2.41 \\ 
        Class 5 & 70.0±2.4 & 65.9±1.76 & 68.4±2.01 & 67.5±2.82 \\ 
        Class 6 & 69.8±2.03 & 70.2±2.51 & 69.9±2.31 & 70.7±3.29 \\ 
        Class 7 & 73.8±1.28 & 73.3±1.48 & 73.1±1.39 & 73.7±1.62 \\ 
        Class 8 & 88.6±1.89 & 89.9±1.67 & 87.9±2.09 & 88.4±2.33 \\ 
        Class 9 & 97.8±0.65 & 97.7±0.69 & 97.3±1.03 & 97.4±0.93 \\ \midrule
\multicolumn{5}{c}{ImageNet MNasNet W6A6}                \\ \midrule
        Average & 74.9±0.09 & 74.9±0.26 & 74.8±0.19 & 72.9±1.41 \\ 
        Class 0 & 95.0±1.08 & 95.9±1.35 & 96.0±1.41 & 95.9±1.62 \\ 
        Class 1 & 91.2±1.26 & 91.0±1.56 & 91.2±1.59 & 90.6±2.53 \\ 
        Class 2 & 82.2±2.16 & 81.8±2.15 & 79.5±2.87 & 74.6±5.24 \\ 
        Class 3 & 81.5±2.76 & 82.8±2.49 & 82.4±2.95 & 79.2±5.04 \\ 
        Class 4 & 81.4±2.33 & 81.0±1.84 & 82.0±2.21 & 75.8±4.79 \\ 
        Class 5 & 78.6±2.23 & 76.8±2.27 & 79.1±2.01 & 72.1±3.45 \\ 
        Class 6 & 80.3±2.15 & 82.6±1.92 & 79.9±2.65 & 77.9±3.33 \\ 
        Class 7 & 65.6±2.65 & 66.4±1.7 & 67.7±3.5 & 63.2±6.37 \\ 
        Class 8 & 88.5±1.72 & 90.1±1.83 & 88.9±2.3 & 89.2±3.92 \\ 
        Class 9 & 97.1±1.27 & 97.6±1.34 & 97.6±1.13 & 97.1±1.39 \\ 
        \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of different metrics. We report the mean±std over 50 runs on ImageNet dataset.}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}

\toprule
Dataset Size & Cosine         & KL        & MSE       & MinMax      \\ \midrule
\multicolumn{5}{c}{ImageNet RegNetx600M W6A6}                   \\ \midrule
        Average & 72.9±0.06 & 73.0±0.06 & 73.0±0.08 & 72.4±0.11 \\ 
        Class 0 & 90.2±0.72 & 90.6±1.16 & 90.4±0.77 & 90.3±1.46 \\ 
        Class 1 & 89.6±0.8 & 89.5±0.88 & 89.3±1.11 & 89.4±1.7 \\ 
        Class 2 & 76.2±1.59 & 75.8±1.54 & 75.8±1.86 & 76.0±2.56 \\ 
        Class 3 & 76.5±2.11 & 75.9±1.46 & 77.0±1.84 & 76.5±2.45 \\ 
        Class 4 & 90.8±1.64 & 90.3±1.74 & 89.9±1.49 & 88.2±2.67 \\ 
        Class 5 & 77.1±1.66 & 76.2±1.91 & 75.8±1.99 & 75.0±2.27 \\ 
        Class 6 & 75.6±2.63 & 77.4±2.31 & 77.0±2.37 & 76.7±2.67 \\ 
        Class 7 & 75.2±1.79 & 75.2±2.37 & 75.0±2.01 & 74.3±2.33 \\ 
        Class 8 & 83.0±1.84 & 83.9±1.32 & 83.4±1.79 & 82.3±2.28 \\ 
        Class 9 & 96.0±0.0 & 95.9±0.47 & 96.0±0.28 & 95.8±0.78 \\ \midrule
\multicolumn{5}{c}{ImageNet RegNetx3200M W6A6}                \\ \midrule
        Average & 77.9±0.04 & 77.9±0.06 & 77.9±0.07 & 77.1±0.14 \\ 
        Class 0 & 94.0±0.28 & 94.0±0.0 & 94.0±0.28 & 95.0±1.15 \\ 
        Class 1 & 90.8±1.2 & 91.4±1.02 & 91.8±0.65 & 92.4±1.74 \\ 
        Class 2 & 85.1±0.99 & 84.3±0.98 & 84.5±1.19 & 82.0±1.65 \\ 
        Class 3 & 84.6±1.29 & 85.4±0.93 & 85.9±1.01 & 85.0±2.09 \\ 
        Class 4 & 92.4±0.77 & 92.3±1.2 & 92.1±0.62 & 91.5±1.32 \\ 
        Class 5 & 87.7±0.93 & 89.1±1.34 & 87.6±1.63 & 86.9±2.08 \\ 
        Class 6 & 82.9±1.34 & 82.9±1.45 & 82.2±1.48 & 79.2±3.73 \\ 
        Class 7 & 74.0±1.52 & 70.8±1.6 & 72.5±1.73 & 73.0±1.84 \\ 
        Class 8 & 84.8±1.75 & 85.1±1.84 & 86.0±1.92 & 85.4±1.98 \\ 
        Class 9 & 100.0±0.0 & 100.0±0.28 & 99.4±0.93 & 97.8±0.67 \\ \bottomrule

\end{tabular}
}
\end{table}
\noindent\textbf{KL calibration.} 
Minimizing the KL divergence between the distributions before and after quantization to find the range for quantization. Specifically, the distribution is divided into a histogram of 2048 bins, and the difference between the distributions before and after quantization is compared. The equation is as follows:
\begin{equation}
    \min_sD_{cos}(hist(x), hist(x^q)).
\end{equation}

\noindent\textbf{MSE calibration.} 
Similar to KL calibration, the quantization range is determined based on the difference between the pre- and post-quantization distributions using MSE distance instead of KL divergence. Similarly, search 100 times to find the optimal maximum value. The equation is as follows:
\begin{equation}
    \min_s\|x - x^q\|^2.
\end{equation}

\subsection{Evaluation on bitwidth}
We evaluated the performance of multiple models under 6-bit and 8-bit quantization for the ImageNet dataset, and under 4-bit and 6-bit quantization for the CIFAR-10 dataset.
The experimental results are shown as follows:

\begin{table}[htb]
\centering
\caption{The influence of quantization settings on CIFAR-10 dataset.}
\label{table_quantization_settings}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Task     & \multicolumn{2}{c}{CIFAR-10 ResNet20} & \multicolumn{2}{c}{CIFAR-10 ResNet32} \\
bit-width & W6A6              & W4A4              & W6A6              & W4A4               \\ \midrule
        Average & 90.7±0.08 & 88.0±0.21 & 90.4±0.1 & 87.7±0.21 \\ 
        Class 0 & 90.1±0.27 & 92.2±0.44 & 93.5±0.3 & 91.8±0.54 \\ 
        Class 1 & 95.8±0.19 & 93.2±0.46 & 95.8±0.22 & 93.8±0.36 \\ 
        Class 2 & 88.5±0.3 & 84.6±0.62 & 90.8±0.3 & 86.1±0.63 \\ 
        Class 3 & 82.6±0.51 & 76.4±0.7 & 77.4±0.41 & 67.4±1.02 \\ 
        Class 4 & 90.8±0.27 & 86.6±0.61 & 90.0±0.35 & 90.3±0.49 \\ 
        Class 5 & 85.5±0.33 & 81.4±0.67 & 84.4±0.35 & 81.4±0.77 \\ 
        Class 6 & 92.1±0.28 & 94.2±0.45 & 94.6±0.3 & 92.3±0.54 \\ 
        Class 7 & 93.2±0.29 & 89.5±0.47 & 89.5±0.26 & 89.4±0.45 \\ 
        Class 8 & 93.1±0.21 & 88.8±0.71 & 94.3±0.29 & 93.2±0.52 \\ 
        Class 9 & 94.8±0.21 & 93.2±0.43 & 93.6±0.2 & 91.5±0.4 \\ \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of quantization settings on CIFAR-10 dataset.}
\label{table_quantization_settings}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Task     & \multicolumn{2}{c}{CIFAR-10 ResNet44} & \multicolumn{2}{c}{CIFAR-10 ResNet56} \\
bit-width & W6A6              & W4A4              & W6A6              & W4A4               \\ \midrule
        Average & 92.1±0.1 & 87.3±0.39 & 92.9±0.11 & 89.4±0.19 \\ 
        Class 0 & 92.0±0.28 & 77.4±1.13 & 93.1±0.28 & 86.8±0.82 \\ 
        Class 1 & 96.7±0.2 & 90.9±0.52 & 96.6±0.22 & 91.2±0.58 \\ 
        Class 2 & 90.8±0.31 & 83.9±0.97 & 90.6±0.39 & 85.2±0.68 \\ 
        Class 3 & 86.4±0.35 & 88.3±0.8 & 86.5±0.36 & 84.8±0.84 \\ 
        Class 4 & 92.5±0.25 & 91.2±0.55 & 94.2±0.33 & 91.6±0.61 \\ 
        Class 5 & 86.9±0.35 & 78.2±0.79 & 87.9±0.42 & 77.9±1.13 \\ 
        Class 6 & 92.0±0.36 & 87.7±1.16 & 94.8±0.21 & 94.7±0.52 \\ 
        Class 7 & 93.9±0.26 & 87.5±0.73 & 94.1±0.31 & 92.1±0.51 \\ 
        Class 8 & 95.3±0.26 & 94.2±0.52 & 95.5±0.22 & 96.4±0.31 \\ 
        Class 9 & 94.6±0.26 & 94.1±0.42 & 95.7±0.21 & 93.4±0.43 \\ \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of quantization settings on Imagenet dataset.}
\label{table_quantization_settings}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Task     & \multicolumn{2}{c}{ImageNet ResNet18} & \multicolumn{2}{c}{Imagenet ResNet50} \\
bit-width & W8A8                & W6A6              & W8A8                & W6A6               \\ \midrule
        Average & 70.9±0.03 & 70.3±0.06 & 76.6±0.03 & 76.3±0.04 \\ 
        Class 0 & 86.0±0.0 & 84.3±0.69 & 93.4±1.47 & 95.0±1.08 \\ 
        Class 1 & 86.8±0.97 & 89.5±0.85 & 93.8±0.54 & 93.2±1.12 \\ 
        Class 2 & 78.6±1.29 & 83.6±1.0 & 82.0±0.0 & 81.7±0.9 \\ 
        Class 3 & 69.1±1.07 & 68.6±1.85 & 83.8±0.65 & 84.2±1.51 \\ 
        Class 4 & 88.0±0.0 & 90.0±1.85 & 85.0±1.08 & 86.3±1.44 \\ 
        Class 5 & 72.0±0.0 & 70.9±1.14 & 78.8±1.39 & 75.6±2.37 \\ 
        Class 6 & 74.6±1.23 & 79.2±1.64 & 75.2±1.45 & 82.0±1.83 \\ 
        Class 7 & 68.1±0.39 & 68.5±2.26 & 71.5±1.99 & 72.8±2.0 \\ 
        Class 8 & 86.8±1.05 & 88.1±1.76 & 82.9±1.21 & 84.0±0.94 \\ 
        Class 9 & 100.0±0.0 & 100.0±0.0 & 100.0±0.0 & 100.0±0.28 \\ \midrule
Task     & \multicolumn{2}{c}{ImageNet MobilenetV2} & \multicolumn{2}{c}{Imagenet MNasNet} \\
bit-width & W8A8                & W6A6              & W8A8                & W6A6               \\ \midrule
        Average & 72.0±0.03 & 70.2±0.06 & 76.4±0.04 & 74.8±0.19 \\ 
        Class 0 & 91.9±0.47 & 91.0±1.08 & 97.0±1.0 & 96.0±1.41 \\ 
        Class 1 & 92.0±0.0 & 85.3±0.95 & 89.6±0.87 & 91.2±1.59 \\ 
        Class 2 & 88.8±1.07 & 74.0±2.38 & 86.9±1.39 & 79.5±2.87 \\ 
        Class 3 & 79.2±1.05 & 78.0±1.83 & 81.5±2.02 & 82.4±2.95 \\ 
        Class 4 & 83.0±1.0 & 78.2±1.87 & 84.4±1.68 & 82.0±2.21 \\ 
        Class 5 & 68.6±1.66 & 68.4±2.01 & 76.3±1.27 & 79.1±2.01 \\ 
        Class 6 & 78.8±1.27 & 69.9±2.31 & 75.9±1.67 & 79.9±2.65 \\ 
        Class 7 & 77.0±1.22 & 73.1±1.39 & 70.8±1.33 & 67.7±3.5 \\ 
        Class 8 & 86.0±0.0 & 87.9±2.09 & 90.0±0.0 & 88.9±2.3 \\ 
        Class 9 & 96.1±0.39 & 97.3±1.03 & 96.0±0.0 & 97.6±1.13 \\ \bottomrule
\end{tabular}
}
\end{table}

\begin{table}[htb]
\centering
\caption{The influence of quantization settings on Imagenet dataset.}
\label{table_quantization_settings}
\resizebox{\linewidth}{!}{
\begin{tabular}{@{}ccccc@{}}
\toprule
Task     & \multicolumn{2}{c}{ImageNet RegNet600} & \multicolumn{2}{c}{ImageNet RegNet3200} \\
bit-width & W8A8                & W6A6              & W8A8                & W6A6               \\ \midrule
        Average & 73.5±0.04 & 73.0±0.08 & 78.5±0.03 & 77.9±0.07 \\ 
        Class 0 & 92.0±0.0 & 90.4±0.77 & 94.0±0.0 & 94.0±0.28 \\ 
        Class 1 & 88.0±0.85 & 89.3±1.11 & 90.0±0.28 & 91.8±0.65 \\ 
        Class 2 & 76.9±1.15 & 75.8±1.86 & 85.8±0.65 & 84.5±1.19 \\ 
        Class 3 & 78.1±0.84 & 77.0±1.84 & 84.0±0.28 & 85.9±1.01 \\ 
        Class 4 & 85.2±1.74 & 89.9±1.49 & 92.0±0.28 & 92.1±0.62 \\ 
        Class 5 & 75.5±0.94 & 75.8±1.99 & 85.5±1.25 & 87.6±1.63 \\ 
        Class 6 & 79.6±1.25 & 77.0±2.37 & 84.8±0.98 & 82.2±1.48 \\ 
        Class 7 & 71.7±1.55 & 75.0±2.01 & 72.9±1.0 & 72.5±1.73 \\ 
        Class 8 & 88.0±0.0 & 83.4±1.79 & 86.1±1.6 & 86.0±1.92 \\ 
        Class 9 & 96.0±0.0 & 96.0±0.28 & 100.0±0.0 & 99.4±0.93 \\ \bottomrule
\end{tabular}
}
\end{table}

\subsection{Evaluation on noise data}
We investigated the performance of quantized models when introducing noise data similar to the actual calibration set during calibration. 
Specifically, we conducted experiments on the performance of quantized models when the calibration set contains 1\%, 5\%, 10\%, and 50\% noise data. 
The results of the experiments on multiple models are as follows, we only plot 10 classes of ImageNet.
The figures below are the relative performance change to the clean case with varying datanoise amounts.
The change values are demonstrated in different colors.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet20.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet32.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet44.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet56.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet18.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet50.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/mobilenetv2.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/mnasnet.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/regnetx_600m.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/regnetx_3200m.pdf}
\end{figure}


\subsection{Evaluation on class bias}
We conducted experiments on unbalanced calibration datasets to explore how class imbalance affects model quantization. 
Specifically, we set one category in the calibration dataset to represent 50\% of the total samples and tested four different categories across multiple models.
The experimental results of top-1 accuracy is averaged over 50 runs with different random seeds. The prediction accuracy change is demonstrated in different colors (red means increment and blue means decrement).
We only plot 10 classes of ImageNet.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet20_cls_bias.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet32_cls_bias.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet44_cls_bias.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet56_cls_bias.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet18_cls_bias.pdf} 
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/resnet50_cls_bias.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/mobilenetv2_cls_bias.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/mnasnet_cls_bias.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/regnetx_600m_cls_bias.pdf}
\end{figure}
\vspace{-1cm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{supp_imgs/regnetx_3200m_cls_bias.pdf}
\end{figure}

\end{appendices}
% \end{document}
