@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
  CTLuse_url               = "yes",
  CTLdash_repeated_names   = "yes",
  CTLuse_forced_etal       = "yes",
  CTLmax_names_forced_etal = "2",
  CTLnames_show_etal       = "3"
}


string{icassp = "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}
@string{interspeech = "Proc. ISCA Interspeech"}
string{asru = "Proc. IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)"}
@string{lrec = "Proc. International Conference on Language Resources and Evaluation (LREC)"}
string{ieee-taslp = "IEEE Transactions on Audio, Speech, and Language Processing"}
string{ieee-acm-taslp = "IEEE/ACM Transactions on Audio, Speech and Language Processing"}
string{icml = "Proc. International Conference on Machine Learning (ICML)"}
@string{mlsp = "Proc. International Workshop on Machine Learning for Signal Processing (MLSP)"}
string{nips = "Proc. Conference on Neural Information Processing Systems (NIPS)"}
@string{csl = "Computer speech \& language"}
string{slt = "Proc. IEEE Spoken Language Technology Workshop (SLT)"}
string{acl = "Proc. Annual Meeting of the Association for Computational Linguistics (ACL)"}
string{naacl = "Proc. Conference of the North {A}merican Chapter of the Association for Computational Linguistics (NAACL)"}
string{emnlp = "Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP)"}
@string{icassp = "Proc. IEEE ICASSP"}
string{interspeech = "Proc. ISCA Interspeech"}
@string{asru = "Proc. IEEE ASRU"}
@string{waspaa = "Proc. IEEE WASPAA"}
string{lrec = "Proc. LREC"}
@string{ieee-taslp = "IEEE Trans. Audio, Speech, Language Process."}
@string{ieee-acm-taslp = "IEEE/ACM Trans. ASLP."}
@string{icml = "Proc. ICML"}
@string{mlsp = "Proc. MLSP"}
@string{nips = "Proc. NIPS"}
string{csl = "Comput. Speech Lang."}
@string{slt = "Proc. IEEE SLT"}
@string{acl = "Proc. ACL"}
@string{naacl = "Proc. NAACL"}
@string{emnlp = "Proc. EMNLP"}



@inproceedings{kongSourceSeparationWeakly2020,
	title = {Source {Separation} with {Weakly} {Labelled} {Data}: an {Approach} to {Computational} {Auditory} {Scene} {Analysis}},
	shorttitle = {Source {Separation} with {Weakly} {Labelled} {Data}},
	doi = {10.1109/ICASSP40776.2020.9053396},
	booktitle = icassp,
	author = {Kong, Qiuqiang and Wang, Yuxuan and Song, Xuchen and Cao, Yin and Wang, Wenwu and Plumbley, Mark D.},
	month = may,
	year = {2020},
	pages = {101--105},
}



@inproceedings{huDCCRNDeepComplex2020,
	title = {{DCCRN}: {Deep} {Complex} {Convolution} {Recurrent} {Network} for {Phase}-{Aware} {Speech} {Enhancement}},
	shorttitle = {{DCCRN}},
	doi = {10.21437/Interspeech.2020-2537},
	language = {en},
	urldate = {2022-01-26},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Hu, Yanxin and Liu, Yun and Lv, Shubo and Xing, Mengtao and Zhang, Shimin and Fu, Yihui and Wu, Jian and Zhang, Bihong and Xie, Lei},
	month = oct,
	year = {2020},
	pages = {2472--2476},
}


@inproceedings{stollerWaveUNetMultiScaleNeural2018,
	title = {Wave-{U}-{Net}: {A} {Multi}-{Scale} {Neural} {Network} for {End}-to-{End} {Audio} {Source} {Separation}},
	shorttitle = {Wave-{U}-{Net}},
	booktitle = {Proceedings of the 19th {ISMIR} 2018},
	author = {Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
	year = {2018},
	pages = {334--340},
}



@inproceedings{ronnebergerUNetConvolutionalNetworks2015,
	address = {Cham},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year = {2015},
	keywords = {Convolutional Layer, Data Augmentation, Deep Network, Ground Truth Segmentation, Training Image},
	pages = {234--241},
}



@inproceedings{liCategoryAdaptedSoundEvent2022,
	title = {Category-{Adapted} {Sound} {Event} {Enhancement} with {Weakly} {Labeled} {Data}},
	doi = {10.1109/ICASSP43922.2022.9747722},
	booktitle = icassp,
	author = {Li, Guangwei and Xu, Xuenan and Dinkel, Heinrich and Wu, Mengyue and Yu, Kai},
	month = may,
	year = {2022},
	pages = {851--855},
}

@INPROCEEDINGS{9746962,
  author={Eskimez, Sefik Emre and Yoshioka, Takuya and Wang, Huaming and Wang, Xiaofei and Chen, Zhuo and Huang, Xuedong},
  booktitle = icassp,
  title={Personalized speech enhancement: new models and Comprehensive evaluation}, 
  month = may,
  year={2022},
  pages={356--360}
}
  

@article{kongPANNsLargeScalePretrained2020,
	title = {{PANNs}: {Large}-{Scale} {Pretrained} {Audio} {Neural} {Networks} for {Audio} {Pattern} {Recognition}},
	volume = {28},
	issn = {2329-9304},
	shorttitle = {{PANNs}},
	doi = {10.1109/TASLP.2020.3030497},
	journal = ieee-acm-taslp,
	author = {Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and Wang, Wenwu and Plumbley, Mark D.},
	year = {2020},
	keywords = {Acoustics, Audio tagging, Convolution, Neural networks, Pattern recognition, pretrained audio neural networks, Tagging, Task analysis, Training, transfer learning},
	pages = {2880--2894},
}


@article{vaswaniAttentionAllYou2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	language = {en},
	journal = {Advances in Neural Information Processing Systems},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
}




@article{sanhDistilBERTDistilledVersion2019,
	title = {{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
	volume = {abs/1910.01108},
	shorttitle = {{DistilBERT}, a distilled version of {BERT}},
	urldate = {2022-10-10},
	journal = {CoRR},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	year = {2019},
}



@inproceedings{liuSwinTransformerHierarchical2021,
	title = {Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}},
	shorttitle = {Swin {Transformer}},
	doi = {10.1109/ICCV48922.2021.00986},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	month = oct,
	year = {2021},
	keywords = {Computational modeling, Computer architecture, Computer vision, Detection and localization in 2D and 3D, grouping and shape, Image segmentation, Object detection, Recognition and classification, Representation learning, Segmentation, Semantics, Visualization},
	pages = {9992--10002},
}



@inproceedings{rahimiReadingListenCocktail2022,
	title = {Reading {To} {Listen} at the {Cocktail} {Party}: {Multi}-{Modal} {Speech} {Separation}},
	shorttitle = {Reading {To} {Listen} at the {Cocktail} {Party}},
	language = {en},
	urldate = {2022-07-13},
	author = {Rahimi, Akam and Afouras, Triantafyllos and Zisserman, Andrew},
	year = {2022},
	pages = {10493--10502},
}



@inproceedings{gemmekeAudioSetOntology2017,
	title = {Audio {Set}: {An} ontology and human-labeled dataset for audio events},
	shorttitle = {Audio {Set}},
	doi = {10.1109/ICASSP.2017.7952261},
	booktitle = icassp,
	month = mar,
	year = {2017},
	keywords = {audio databases, Audio event detection, Birds, data collection, Labeling, Music, Ontologies, sound ontology, Taxonomy},
	pages = {776--780},
 	author = {Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},

}



@inproceedings{kimAudioCapsGeneratingCaptions2019,
	address = {Minneapolis, Minnesota},
	title = {{AudioCaps}: {Generating} {Captions} for {Audios} in {The} {Wild}},
	shorttitle = {{AudioCaps}},
	doi = {10.18653/v1/N19-1011},
	urldate = {2022-10-12},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
	month = jun,
	year = {2019},
	pages = {119--132},
}








@inproceedings{wuAudioCaptionListen2019,
	title = {Audio {Caption}: {Listen} and {Tell}},
	shorttitle = {Audio {Caption}},
	doi = {10.1109/ICASSP.2019.8682377},
	booktitle = icassp,
	author = {Wu, Mengyue and Dinkel, Heinrich and Yu, Kai},
	month = may,
	year = {2019},
	keywords = {Audio Caption, Audio Databases, Feature extraction, Hospitals, Mathematical model, Music, Natural Language Generation, Recurrent Neural Networks, Task analysis, Training, Videos},
	pages = {830--834},
	file = {Submitted Version:/Users/chenda/Zotero/storage/6WSCC2BN/Wu et al. - 2019 - Audio Caption Listen and Tell.pdf:application/pdf},
}



@article{cherryExperimentsRecognitionSpeech1953,
	title = {Some experiments on the recognition of speech, with one and with two ears},
	volume = {25},
	number = {5},
	journal = {The Journal of the acoustical society of America},
	author = {Cherry, E Colin},
	year = {1953},
	pages = {975--979},
}



@article{kolbaekMultitalkerSpeechSeparation2017,
	title = {Multitalker {Speech} {Separation} {With} {Utterance}-{Level} {Permutation} {Invariant} {Training} of {Deep} {Recurrent} {Neural} {Networks}},
	volume = {25},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2017.2726762},
	number = {10},
	journal = ieee-acm-taslp,
	author = {Kolbæk, M. and Yu, D. and Tan, Z. and Jensen, J.},
	month = oct,
	year = {2017},
	pages = {1901--1913},
}



@inproceedings{hersheyDeepClusteringDiscriminative2016,
	title = {Deep clustering: {Discriminative} embeddings for segmentation and separation},
	shorttitle = {Deep clustering},
	doi = {10.1109/ICASSP.2016.7471631},
	booktitle = icassp,
	author = {Hershey, J. R. and Chen, Z. and Roux, J. Le and Watanabe, S.},
	month = mar,
	year = {2016},
	pages = {31--35},
}



@misc{liuVoiceAccompanimentSeparation2020,
	title = {Voice and accompaniment separation in music using self-attention convolutional neural network},
	doi = {10.48550/arXiv.2003.08954},
	urldate = {2022-10-17},
	publisher = {arXiv},
	author = {Liu, Yuzhou and Thoshkahna, Balaji and Milani, Ali and Kristjansson, Trausti},
	month = mar,
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Statistics - Machine Learning},
}



@inproceedings{liuChannelWiseSubbandInput2020,
	title = {Channel-{Wise} {Subband} {Input} for {Better} {Voice} and {Accompaniment} {Separation} on {High} {Resolution} {Music}},
	doi = {10.21437/Interspeech.2020-2555},
	language = {en},
	urldate = {2022-10-17},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Liu, Haohe and Xie, Lei and Wu, Jian and Yang, Geng},
	month = oct,
	year = {2020},
	pages = {1241--1245},
}


@misc{defossezMusicSourceSeparation2021,
	title = {Music {Source} {Separation} in the {Waveform} {Domain}},
	doi = {10.48550/arXiv.1911.13254},
	urldate = {2022-10-17},
	publisher = {arXiv},
	author = {Défossez, Alexandre and Usunier, Nicolas and Bottou, Léon and Bach, Francis},
	month = apr,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Statistics - Machine Learning},
}


@article{luoConvTasNetSurpassingIdeal2019,
	title = {Conv-{TasNet}: {Surpassing} {Ideal} {Time}–{Frequency} {Magnitude} {Masking} for {Speech} {Separation}},
	volume = {27},
	issn = {2329-9304},
	shorttitle = {Conv-{TasNet}},
	doi = {10.1109/TASLP.2019.2915167},
	number = {8},
	journal = ieee-acm-taslp,
	author = {Luo, Y. and Mesgarani, N.},
	month = aug,
	year = {2019},
	pages = {1256--1266},
}



@inproceedings{tzinisImprovingUniversalSound2020,
	title = {Improving {Universal} {Sound} {Separation} {Using} {Sound} {Classification}},
	doi = {10.1109/ICASSP40776.2020.9053921},
	booktitle = icassp,
	author = {Tzinis, Efthymios and Wisdom, Scott and Hershey, John R. and Jansen, Aren and Ellis, Daniel P. W.},
	month = may,
	year = {2020},
	pages = {96--100},
}



@inproceedings{kavalerovUniversalSoundSeparation2019,
	title = {Universal {Sound} {Separation}},
	doi = {10.1109/WASPAA.2019.8937253},
	booktitle = icassp,
	author = {Kavalerov, Ilya and Wisdom, Scott and Erdogan, Hakan and Patton, Brian and Wilson, Kevin and Le Roux, Jonathan and Hershey, John R.},
	month = oct,
	year = {2019},
	keywords = {Convolution, deep learning, Source separation, Task analysis, Training, Speech enhancement, Transforms, Microsoft Windows, Network architecture, non-speech audio},
	pages = {175--179},
}



@inproceedings{wangVoiceFilterTargetedVoice2019,
	title = {{VoiceFilter}: {Targeted} {Voice} {Separation} by {Speaker}-{Conditioned} {Spectrogram} {Masking}},
	shorttitle = {{VoiceFilter}},
	doi = {10.21437/Interspeech.2019-1101},
	language = {en},
	urldate = {2021-04-15},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Wang, Quan and Muckenhirn, Hannah and Wilson, Kevin and Sridhar, Prashant and Wu, Zelin and Hershey, John R. and Saurous, Rif A. and Weiss, Ron J. and Jia, Ye and Moreno, Ignacio Lopez},
	month = sep,
	year = {2019},
	pages = {2728--2732},
}



@inproceedings{delcroixSingleChannelTarget2018,
	title = {Single {Channel} {Target} {Speaker} {Extraction} and {Recognition} with {Speaker} {Beam}},
	doi = {10.1109/ICASSP.2018.8462661},
	booktitle = icassp,
	author = {Delcroix, M. and Zmolikova, K. and Kinoshita, K. and Ogawa, A. and Nakatani, T.},
	month = apr,
	year = {2018},
	keywords = {Speech recognition, Training, Acoustics, Speech Recognition, Feature extraction, Microphones, Adaptation, Adaptation models, Robust ASR, Speaker extraction, Speech mixtures, Target recognition},
	pages = {5554--5558},
}



@article{xuSpExMultiScaleTime2020,
	title = {{SpEx}: {Multi}-{Scale} {Time} {Domain} {Speaker} {Extraction} {Network}},
	volume = {28},
	issn = {2329-9304},
	shorttitle = {{SpEx}},
	doi = {10.1109/TASLP.2020.2987429},
	journal = ieee-acm-taslp,
	author = {Xu, Chenglin and Rao, Wei and Chng, Eng Siong and Li, Haizhou},
	year = {2020},
	keywords = {Decoding, Speech processing, Time-domain analysis, Training, multi-task learning, Feature extraction, Frequency-domain analysis, Data mining, depth-wise separable convolution, multi-scale, speaker extraction, Time-domain},
	pages = {1370--1384},
}


@inproceedings{delcroixImprovingSpeakerDiscrimination2020,
	title = {Improving {Speaker} {Discrimination} of {Target} {Speech} {Extraction} {With} {Time}-{Domain} {Speakerbeam}},
	doi = {10.1109/ICASSP40776.2020.9054683},
	booktitle = icassp,
	author = {Delcroix, Marc and Ochiai, Tsubasa and Zmolikova, Katerina and Kinoshita, Keisuke and Tawara, Naohiro and Nakatani, Tomohiro and Araki, Shoko},
	month = may,
	year = {2020},
	pages = {691--695},
}



@inproceedings{wangSpeechSeparationUsing2019,
	title = {Speech {Separation} {Using} {Speaker} {Inventory}},
	doi = {10.1109/ASRU46091.2019.9003884},
	booktitle = asru,
	author = {Wang, Peidong and Chen, Zhuo and Xiao, Xiong and Meng, Zhong and Yoshioka, Takuya and Zhou, Tianyan and Lu, Liang and Li, Jinyu},
	month = dec,
	year = {2019},
	keywords = {Feature extraction, LibriSpeech, Loss measurement, Mathematical model, PIT, speaker inventory, speech extraction, Speech processing, speech separation, Task analysis, Training, Weight measurement},
	pages = {230--236},
}



@misc{tzinisAudioScopeV2AudioVisualAttention2022a,
	title = {{AudioScopeV2}: {Audio}-{Visual} {Attention} {Architectures} for {Calibrated} {Open}-{Domain} {On}-{Screen} {Sound} {Separation}},
	shorttitle = {{AudioScopeV2}},
	urldate = {2022-07-26},
	publisher = {arXiv},
	author = {Tzinis, Efthymios and Wisdom, Scott and Remez, Tal and Hershey, John R.},
	month = jul,
	year = {2022},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Computer Vision and Pattern Recognition},
}


@inproceedings{afourasConversationDeepAudioVisual2018,
	title = {The {Conversation}: {Deep} {Audio}-{Visual} {Speech} {Enhancement}},
	shorttitle = {The {Conversation}},
	doi = {10.21437/Interspeech.2018-1400},
	language = {en},
	urldate = {2021-03-31},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
	month = sep,
	year = {2018},
	pages = {3244--3248},
}



@inproceedings{gaoVisualVoiceAudioVisualSpeech2021,
	title = {{VisualVoice}: {Audio}-{Visual} {Speech} {Separation} with {Cross}-{Modal} {Consistency}},
	shorttitle = {{VisualVoice}},
	doi = {10.1109/CVPR46437.2021.01524},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Gao, Ruohan and Grauman, Kristen},
	month = jun,
	year = {2021},
	keywords = {Computational modeling, Speech recognition, Speech enhancement, Lips, Computer vision, Face recognition, Location awareness},
	pages = {15490--15500},
}



@inproceedings{liListenWatchUnderstand2020,
	title = {Listen, {Watch} and {Understand} at the {Cocktail} {Party}: {Audio}-{Visual}-{Contextual} {Speech} {Separation}},
	shorttitle = {Listen, {Watch} and {Understand} at the {Cocktail} {Party}},
	doi = {10.21437/Interspeech.2020-2028},
	language = {en},
	urldate = {2021-03-23},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Li, Chenda and Qian, Yanmin},
	month = oct,
	year = {2020},
	pages = {1426--1430},
}



@misc{kilgourTextDrivenSeparationArbitrary2022,
	title = {Text-{Driven} {Separation} of {Arbitrary} {Sounds}},
	doi = {10.48550/arXiv.2204.05738},
	urldate = {2022-09-26},
	publisher = {arXiv},
	author = {Kilgour, Kevin and Gfeller, Beat and Huang, Qingqing and Jansen, Aren and Wisdom, Scott and Tagliasacchi, Marco},
	month = apr,
	year = {2022},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}



@misc{liuSeparateWhatYou2022b,
	title = {Separate {What} {You} {Describe}: {Language}-{Queried} {Audio} {Source} {Separation}},
	shorttitle = {Separate {What} {You} {Describe}},
	doi = {10.48550/arXiv.2203.15147},
	urldate = {2022-09-22},
	publisher = {arXiv},
	author = {Liu, Xubo and Liu, Haohe and Kong, Qiuqiang and Mei, Xinhao and Zhao, Jinzheng and Huang, Qiushi and Plumbley, Mark D. and Wang, Wenwu},
	month = mar,
	year = {2022},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Electrical Engineering and Systems Science - Signal Processing},
}


@inproceedings{kinoshitaTextinformedSpeechEnhancement2015,
	title = {Text-informed speech enhancement with deep neural networks},
	urldate = {2022-10-17},
	booktitle = {{INTERSPEECH} 2015, 16th {Annual} {Conference} of the {International} {Speech} {Communication} {Association}, {Dresden}, {Germany}, {September} 6-10, 2015},
	publisher = {ISCA},
	author = {Kinoshita, Keisuke and Delcroix, Marc and Ogawa, Atsunori and Nakatani, Tomohiro},
	year = {2015},
	pages = {1760--1764},
}





@misc{ohishiConceptBeamConceptDriven2022a,
	title = {{ConceptBeam}: {Concept} {Driven} {Target} {Speech} {Extraction}},
	shorttitle = {{ConceptBeam}},
	doi = {10.1145/3503161.3548397},
	urldate = {2022-08-15},
	author = {Ohishi, Yasunori and Delcroix, Marc and Ochiai, Tsubasa and Araki, Shoko and Takeuchi, Daiki and Niizumi, Daisuke and Kimura, Akisato and Harada, Noboru and Kashino, Kunio},
	month = jul,
	year = {2022},
}





@inproceedings{liESPnetSEEndToEndSpeech2021,
	title = {{ESPnet}-{SE}: {End}-{To}-{End} {Speech} {Enhancement} and {Separation} {Toolkit} {Designed} for {ASR} {Integration}},
	shorttitle = {{ESPnet}-{SE}},
	doi = {10.1109/SLT48900.2021.9383615},
	booktitle = slt,
	author = {Li, Chenda and Shi, Jing and Zhang, Wangyou and Subramanian, Aswin Shanmugam and Chang, Xuankai and Kamo, Naoyuki and Hira, Moto and Hayashi, Tomoki and Boeddeker, Christoph and Chen, Zhuo and Watanabe, Shinji},
	month = jan,
	year = {2021},
	pages = {785--792},
}


@article{tanAudioVisualSpeechSeparation2020,
	title = {Audio-{Visual} {Speech} {Separation} and {Dereverberation} {With} a {Two}-{Stage} {Multimodal} {Network}},
	volume = {14},
	issn = {1941-0484},
	doi = {10.1109/JSTSP.2020.2987209},
	number = {3},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Tan, Ke and Xu, Yong and Zhang, Shi-Xiong and Yu, Meng and Yu, Dong},
	month = mar,
	year = {2020},
	pages = {542--553},
}


@inproceedings{liVCSETimeDomainVisualContextual2022,
	title = {{VCSE}: {Time}-{Domain} {Visual}-{Contextual} {Speaker} {Extraction} {Network}},
	shorttitle = {{VCSE}},
	doi = {10.21437/Interspeech.2022-11183},
	booktitle = interspeech,
	publisher = {ISCA},
	author = {Li, Junjie and Ge, Meng and Pan, Zexu and Wang, Longbiao and Dang, Jianwu},
	editor = {Ko, Hanseok and Hansen, John H. L.},
	year = {2022},
	pages = {906--910},
}
