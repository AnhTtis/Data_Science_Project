@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zhang2021pointclip,
  title={PointCLIP: Point Cloud Understanding by CLIP},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2112.02413},
  year={2021}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}
@inproceedings{zhang2019making,
  title={Making convolutional networks shift-invariant again},
  author={Zhang, Richard},
  booktitle={International conference on machine learning},
  pages={7324--7334},
  year={2019},
  organization={PMLR}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@article{muzahid2020curvenet,
  title={CurveNet: Curvature-based multitask learning deep networks for 3D object recognition},
  author={Muzahid, AAM and Wan, Wanggen and Sohel, Ferdous and Wu, Lianyao and Hou, Li},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={8},
  number={6},
  pages={1177--1187},
  year={2020},
  publisher={IEEE}
}



@article{mandikal20183d,
  title={3D-LMNet: Latent embedding matching for accurate and diverse 3D point cloud reconstruction from a single image},
  author={Mandikal, Priyanka and Navaneet, KL and Agarwal, Mayank and Babu, R Venkatesh},
  journal={arXiv preprint arXiv:1807.07796},
  year={2018}
}
@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}


@article{phan2018dgcnn,
  title={Dgcnn: A convolutional neural network over large-scale labeled graphs},
  author={Phan, Anh Viet and Le Nguyen, Minh and Nguyen, Yen Lam Hoang and Bui, Lam Thu},
  journal={Neural Networks},
  volume={108},
  pages={533--543},
  year={2018},
  publisher={Elsevier}
}

@article{muzahid2020curvenet,
  title={CurveNet: Curvature-based multitask learning deep networks for 3D object recognition},
  author={Muzahid, AAM and Wan, Wanggen and Sohel, Ferdous and Wu, Lianyao and Hou, Li},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={8},
  number={6},
  pages={1177--1187},
  year={2020},
  publisher={IEEE}
}

@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}


@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}


@article{ma2022rethinking,
  title={Rethinking network design and local geometry in point cloud: A simple residual mlp framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  journal={arXiv preprint arXiv:2202.07123},
  year={2022}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
} 

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year = {2017}
}
@ARTICLE{2017arXiv170201105A,
   author = {{Armeni}, I. and {Sax}, A. and {Zamir}, A.~R. and {Savarese}, S.
	},
    title = "{Joint 2D-3D-Semantic Data for Indoor Scene Understanding}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.01105},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170201105A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{zhao2021point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={16259--16268},
  year={2021}
}



@article{declip,
  title={Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  journal={arXiv preprint arXiv:2110.05208},
  year={2021}
}


@inproceedings{mu2022slip,
  title={Slip: Self-supervision meets language-image pre-training},
  author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={529--544},
  year={2022},
  organization={Springer}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@article{hess2022masked,
  title={Masked Autoencoders for Self-Supervised Learning on Automotive Point Clouds},
  author={Hess, Georg and Jaxing, Johan and Svensson, Elias and Hagerman, David and Petersson, Christoffer and Svensson, Lennart},
  journal={arXiv preprint arXiv:2207.00531},
  year={2022}
}


@article{min2022voxel,
  title={Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds},
  author={Min, Chen and Zhao, Dawei and Xiao, Liang and Nie, Yiming and Dai, Bin},
  journal={arXiv preprint arXiv:2206.09900},
  year={2022}
}


@article{liu2022masked,
  title={Masked Discrimination for Self-Supervised Learning on Point Clouds},
  author={Liu, Haotian and Cai, Mu and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2203.11183},
  year={2022}
}


@inproceedings{yu2022point,
  title={Point-bert: Pre-training 3d point cloud transformers with masked point modeling},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19313--19322},
  year={2022}
}


@article{pang2022masked,
  title={Masked autoencoders for point cloud self-supervised learning},
  author={Pang, Yatian and Wang, Wenxiao and Tay, Francis EH and Liu, Wei and Tian, Yonghong and Yuan, Li},
  journal={arXiv preprint arXiv:2203.06604},
  year={2022}
}


@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}



@techreport{shapenet2015,
  title       = {{ShapeNet: An Information-Rich 3D Model Repository}},
  author      = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
  number      = {arXiv:1512.03012 [cs.GR]},
  institution = {Stanford University --- Princeton University --- Toyota Technological Institute at Chicago},
  year        = {2015}
}

@inproceedings{scanobjectnn,
      title = {Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data},
      author = {Mikaela Angelina Uy and Quang-Hieu Pham and Binh-Son Hua and Duc Thanh Nguyen and Sai-Kit Yeung},
      booktitle = {International Conference on Computer Vision (ICCV)},
      year = {2019}
  }


@inproceedings{fan2017point,
  title={A point set generation network for 3d object reconstruction from a single image},
  author={Fan, Haoqiang and Su, Hao and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={605--613},
  year={2017}
}



@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}


@article{jing2020self,
  title={Self-supervised visual feature learning with deep neural networks: A survey},
  author={Jing, Longlong and Tian, Yingli},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4037--4058},
  year={2020},
  publisher={IEEE}
}



@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9912--9924},
  year={2020}
}



@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}


@inproceedings{pix3d,
  title={Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling},
  author={Sun, Xingyuan and Wu, Jiajun and Zhang, Xiuming and Zhang, Zhoutong and Zhang, Chengkai and Xue, Tianfan and Tenenbaum, Joshua B and Freeman, William T},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@article{fu20213d,
  title={3d-future: 3d furniture shape with texture},
  author={Fu, Huan and Jia, Rongfei and Gao, Lin and Gong, Mingming and Zhao, Binqiang and Maybank, Steve and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  pages={1--25},
  year={2021},
  publisher={Springer}
}


@article{text2shape,
  title={Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings},
  author={Chen, Kevin and Choy, Christopher B and Savva, Manolis and Chang, Angel X and Funkhouser, Thomas and Savarese, Silvio},
  journal={arXiv preprint arXiv:1803.08495},
  year={2018}
}

@inproceedings{wu2019pointconv,
  title={Pointconv: Deep convolutional networks on 3d point clouds},
  author={Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9621--9630},
  year={2019}
}
@article{xu2021image2point,
  title={Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models},
  author={Xu, Chenfeng and Yang, Shijia and Zhai, Bohan and Wu, Bichen and Yue, Xiangyu and Zhan, Wei and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi},
  year={2021}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{xiang2021walk,
  title={Walk in the cloud: Learning curves for point clouds shape analysis},
  author={Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={915--924},
  year={2021}
}

@article{wang2022OFA,
  title={Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  journal={arXiv preprint arXiv:2202.03052},
  year={2022}
}

@article{midas,
	author    = {Ren\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},
	title     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},
	journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
	year      = {2020},
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@inproceedings{simpleview,
  title={Revisiting point cloud shape classification with a simple and effective baseline},
  author={Goyal, Ankit and Law, Hei and Liu, Bowei and Newell, Alejandro and Deng, Jia},
  booktitle={International Conference on Machine Learning},
  pages={3809--3820},
  year={2021},
  organization={PMLR}
}
@inproceedings{achlioptas2020referit3d,
  title={Referit3d: Neural listeners for fine-grained 3d object identification in real-world scenes},
  author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas},
  booktitle={European Conference on Computer Vision},
  pages={422--440},
  year={2020},
  organization={Springer}
}


@article{Xu2021Image2Point3P,
  title={Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets},
  author={Chenfeng Xu and Shijia Yang and Bohan Zhai and Bichen Wu and Xiangyu Yue and Wei Zhan and P{\'e}ter Vajda and Kurt Keutzer and Masayoshi Tomizuka},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.04180}
}
@inproceedings{chen2020scanrefer,
  title={Scanrefer: 3d object localization in rgb-d scans using natural language},
  author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={202--221},
  year={2020},
  organization={Springer}
}


@article{cheraghian2022zero,
  title={Zero-shot learning on 3d point cloud objects and beyond},
  author={Cheraghian, Ali and Rahman, Shafin and Chowdhury, Townim F and Campbell, Dylan and Petersson, Lars},
  journal={International Journal of Computer Vision},
  volume={130},
  number={10},
  pages={2364--2384},
  year={2022},
  publisher={Springer}
}



@inproceedings{gao2021utnet,
  title={UTNet: a hybrid transformer architecture for medical image segmentation},
  author={Gao, Yunhe and Zhou, Mu and Metaxas, Dimitris N},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={61--71},
  year={2021},
  organization={Springer}
}
@inproceedings{xu2021co,
  title={Co-scale conv-attentional image transformers},
  author={Xu, Weijian and Xu, Yifan and Chang, Tyler and Tu, Zhuowen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9981--9990},
  year={2021}
}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{liu20213d,
  title={3d-to-2d distillation for indoor scene parsing},
  author={Liu, Zhengzhe and Qi, Xiaojuan and Fu, Chi-Wing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4464--4474},
  year={2021}
}
@inproceedings{xie2020pointcontrast,
  title={Pointcontrast: Unsupervised pre-training for 3d point cloud understanding},
  author={Xie, Saining and Gu, Jiatao and Guo, Demi and Qi, Charles R and Guibas, Leonidas and Litany, Or},
  booktitle={European conference on computer vision},
  pages={574--591},
  year={2020},
  organization={Springer}
}


@inproceedings{zhang2021cross,
  title={Cross-modal contrastive learning for text-to-image generation},
  author={Zhang, Han and Koh, Jing Yu and Baldridge, Jason and Lee, Honglak and Yang, Yinfei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={833--842},
  year={2021}
}


@inproceedings{afham2022crosspoint,
  title={Crosspoint: Self-supervised cross-modal contrastive learning for 3d point cloud understanding},
  author={Afham, Mohamed and Dissanayake, Isuru and Dissanayake, Dinithi and Dharmasiri, Amaya and Thilakarathna, Kanchana and Rodrigo, Ranga},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9902--9912},
  year={2022}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}



@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{cong2022satmae,
  title={SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery},
  author={Cong, Yezhen and Khanna, Samar and Meng, Chenlin and Liu, Patrick and Rozi, Erik and He, Yutong and Burke, Marshall and Lobell, David B and Ermon, Stefano},
  journal={arXiv preprint arXiv:2207.08051},
  year={2022}
}

@article{zhou2022self,
  title={Self pre-training with masked autoencoders for medical image analysis},
  author={Zhou, Lei and Liu, Huidong and Bae, Joseph and He, Junjun and Samaras, Dimitris and Prasanna, Prateek},
  journal={arXiv preprint arXiv:2203.05573},
  year={2022}
}
@article{gidaris2018unsupervised,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1803.07728},
  year={2018}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}
@article{yan2022implicit,
  title={Implicit autoencoder for point cloud self-supervised representation learning},
  author={Yan, Siming and Yang, Zhenpei and Li, Haoxiang and Guan, Li and Kang, Hao and Hua, Gang and Huang, Qixing},
  journal={arXiv preprint arXiv:2201.00785},
  year={2022}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European conference on computer vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@inproceedings{tang2022self,
  title={Self-supervised pre-training of swin transformers for 3d medical image analysis},
  author={Tang, Yucheng and Yang, Dong and Li, Wenqi and Roth, Holger R and Landman, Bennett and Xu, Daguang and Nath, Vishwesh and Hatamizadeh, Ali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20730--20740},
  year={2022}
}

@inproceedings{li2021imbalance,
  title={Imbalance-aware self-supervised learning for 3d radiomic representations},
  author={Li, Hongwei and Xue, Fei-Fei and Chaitanya, Krishna and Luo, Shengda and Ezhov, Ivan and Wiestler, Benedikt and Zhang, Jianguo and Menze, Bjoern},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={36--46},
  year={2021},
  organization={Springer}
}
@inproceedings{liu2019align,
  title={Align, attend and locate: Chest x-ray diagnosis via contrast induced attention network with limited supervision},
  author={Liu, Jingyu and Zhao, Gangming and Fei, Yu and Zhang, Ming and Wang, Yizhou and Yu, Yizhou},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10632--10641},
  year={2019}
}
@article{he2020sample,
  title={Sample-efficient deep learning for COVID-19 diagnosis based on CT scans},
  author={He, Xuehai and Yang, Xingyi and Zhang, Shanghang and Zhao, Jinyu and Zhang, Yichen and Xing, Eric and Xie, Pengtao},
  journal={medrxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory Press}
}
@article{kalapos2022self,
  title={Self-Supervised Pretraining for 2D Medical Image Segmentation},
  author={Kalapos, Andr{\'a}s and Gyires-T{\'o}th, B{\'a}lint},
  journal={arXiv preprint arXiv:2209.00314},
  year={2022}
}
@article{jiang2022self,
  title={Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)},
  author={Jiang, Jue and Tyagi, Neelam and Tringale, Kathryn and Crane, Christopher and Veeraraghavan, Harini},
  journal={arXiv preprint arXiv:2205.10342},
  year={2022}
}
@article{min2022voxel,
  title={Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds},
  author={Min, Chen and Zhao, Dawei and Xiao, Liang and Nie, Yiming and Dai, Bin},
  journal={arXiv preprint arXiv:2206.09900},
  year={2022}
}
@article{dong2022maskclip,
  title={MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining},
  author={Dong, Xiaoyi and Zheng, Yinglin and Bao, Jianmin and Zhang, Ting and Chen, Dongdong and Yang, Hao and Zeng, Ming and Zhang, Weiming and Yuan, Lu and Chen, Dong and others},
  journal={arXiv preprint arXiv:2208.12262},
  year={2022}
}
@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}
@article{girdhar2022omnimae,
  title={OmniMAE: Single Model Masked Pretraining on Images and Videos},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  journal={arXiv preprint arXiv:2206.08356},
  year={2022}
}
@article{lyu2022maskocr,
  title={MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining},
  author={Lyu, Pengyuan and Zhang, Chengquan and Liu, Shanshan and Qiao, Meina and Xu, Yangliu and Wu, Liang and Yao, Kun and Han, Junyu and Ding, Errui and Wang, Jingdong},
  journal={arXiv preprint arXiv:2206.00311},
  year={2022}
}
@article{wang2022facemae,
  title={FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders},
  author={Wang, Kai and Zhao, Bo and Peng, Xiangyu and Zhu, Zheng and Deng, Jiankang and Wang, Xinchao and Bilen, Hakan and You, Yang},
  journal={arXiv preprint arXiv:2205.11090},
  year={2022}
}
@article{arici2021mlim,
  title={MLIM: Vision-and-Language Model Pre-training with Masked Language and Image Modeling},
  author={Arici, Tarik and Seyfioglu, Mehmet Saygin and Neiman, Tal and Xu, Yi and Train, Son and Chilimbi, Trishul and Zeng, Belinda and Tutar, Ismail},
  journal={arXiv preprint arXiv:2109.12178},
  year={2021}
}
@article{feichtenhofer2022masked,
  title={Masked Autoencoders As Spatiotemporal Learners},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Li, Yanghao and He, Kaiming},
  journal={arXiv preprint arXiv:2205.09113},
  year={2022}
}

@inproceedings{dwibedi2021little,
  title={With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9588--9597},
  year={2021}
}
@inproceedings{qian2021spatiotemporal,
  title={Spatiotemporal contrastive video representation learning},
  author={Qian, Rui and Meng, Tianjian and Gong, Boqing and Yang, Ming-Hsuan and Wang, Huisheng and Belongie, Serge and Cui, Yin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6964--6974},
  year={2021}
}
@inproceedings{pan2021videomoco,
  title={Videomoco: Contrastive video representation learning with temporally adversarial examples},
  author={Pan, Tian and Song, Yibing and Yang, Tianyu and Jiang, Wenhao and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11205--11214},
  year={2021}
}
@article{fang2021seed,
  title={Seed: Self-supervised distillation for visual representation},
  author={Fang, Zhiyuan and Wang, Jianfeng and Wang, Lijuan and Zhang, Lei and Yang, Yezhou and Liu, Zicheng},
  journal={arXiv preprint arXiv:2101.04731},
  year={2021}
}
@article{ma2020active,
  title={Active contrastive learning of audio-visual video representations},
  author={Ma, Shuang and Zeng, Zhaoyang and McDuff, Daniel and Song, Yale},
  journal={arXiv preprint arXiv:2009.09805},
  year={2020}
}
@article{kumar2017weight,
  title={On weight initialization in deep neural networks},
  author={Kumar, Siddharth Krishna},
  journal={arXiv preprint arXiv:1704.08863},
  year={2017}
}
@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}
		  
	@article{liu2020ms,
			title={Ms-net: Multi-site network for improving prostate segmentation with heterogeneous mri data},
			author={Liu, Quande and Dou, Qi and Yu, Lequan and Heng, Pheng Ann},
			journal={IEEE Transactions on Medical Imaging},
			year={2020},
			publisher={IEEE}
	}
			  
	@inproceedings{liu2020saml,
			title={Shape-aware Meta-learning for Generalizing Prostate MRI Segmentation to Unseen Domains},
			author={Liu, Quande and Dou, Qi and Heng, Pheng Ann},
			booktitle={International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)},
			year={2020}
	}
@inproceedings{dwibedi2021little,
  title={With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9588--9597},
  year={2021}
}

@inproceedings{wei2022masked,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14668--14678},
  year={2022}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={arXiv preprint arXiv:2203.12602},
  year={2022}
}

@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}

@article{guo2021efficient,
  title={Efficient center voting for object detection and 6D pose estimation in 3D point cloud},
  author={Guo, Jianwei and Xing, Xuejun and Quan, Weize and Yan, Dong-Ming and Gu, Qingyi and Liu, Yang and Zhang, Xiaopeng},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={5072--5084},
  year={2021},
  publisher={IEEE}
}

@article{simon2018complex,
  title={Complex-yolo: Real-time 3d object detection on point clouds},
  author={Simon, Martin and Milz, Stefan and Amende, Karl and Gross, Horst-Michael},
  journal={arXiv preprint arXiv:1803.06199},
  year={2018}
}

@inproceedings{milioto2019rangenet++,
  title={Rangenet++: Fast and accurate lidar semantic segmentation},
  author={Milioto, Andres and Vizzo, Ignacio and Behley, Jens and Stachniss, Cyrill},
  booktitle={2019 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={4213--4220},
  year={2019},
  organization={IEEE}
}

@inproceedings{shi2019pointrcnn,
  title={Pointrcnn: 3d object proposal generation and detection from point cloud},
  author={Shi, Shaoshuai and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={770--779},
  year={2019}
}

@inproceedings{qi2018frustum,
  title={Frustum pointnets for 3d object detection from rgb-d data},
  author={Qi, Charles R and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={918--927},
  year={2018}
}


@inproceedings{kastner20203d,
  title={A 3d-deep-learning-based augmented reality calibration method for robotic environments using depth sensor data},
  author={K{\"a}stner, Linh and Frasineanu, Vlad Catalin and Lambrecht, Jens},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1135--1141},
  year={2020},
  organization={IEEE}
}

@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={arXiv preprint arXiv:2204.14198},
  year={2022}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIII},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@article{xing2022class,
  title={Class-aware visual prompt tuning for vision-language pre-trained model},
  author={Xing, Yinghui and Wu, Qirui and Cheng, De and Zhang, Shizhou and Liang, Guoqiang and Zhang, Yanning},
  journal={arXiv preprint arXiv:2208.08340},
  year={2022}
}

@article{sohn2022visual,
  title={Visual Prompt Tuning for Generative Transfer Learning},
  author={Sohn, Kihyuk and Hao, Yuan and Lezama, Jos{\'e} and Polania, Luisa and Chang, Huiwen and Zhang, Han and Essa, Irfan and Jiang, Lu},
  journal={arXiv preprint arXiv:2210.00990},
  year={2022}
}

@article{zang2022unified,
  title={Unified vision and language prompt learning},
  author={Zang, Yuhang and Li, Wei and Zhou, Kaiyang and Huang, Chen and Loy, Chen Change},
  journal={arXiv preprint arXiv:2210.07225},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{maturana2015voxnet,
  title={Voxnet: A 3d convolutional neural network for real-time object recognition},
  author={Maturana, Daniel and Scherer, Sebastian},
  booktitle={2015 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={922--928},
  year={2015},
  organization={IEEE}
}

@inproceedings{shi2020pv,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10529--10538},
  year={2020}
}

@inproceedings{you2018pvnet,
  title={Pvnet: A joint convolutional network of point cloud and multi-view for 3d shape recognition},
  author={You, Haoxuan and Feng, Yifan and Ji, Rongrong and Gao, Yue},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={1310--1318},
  year={2018}
}

@inproceedings{li2020end,
  title={End-to-end learning local multi-view descriptors for 3d point clouds},
  author={Li, Lei and Zhu, Siyu and Fu, Hongbo and Tan, Ping and Tai, Chiew-Lan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1919--1928},
  year={2020}
}
@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{fan2021scf,
  title={SCF-Net: Learning spatial contextual features for large-scale point cloud segmentation},
  author={Fan, Siqi and Dong, Qiulei and Zhu, Fenghua and Lv, Yisheng and Ye, Peijun and Wang, Fei-Yue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14504--14513},
  year={2021}
}

@inproceedings{xu2021paconv,
  title={Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds},
  author={Xu, Mutian and Ding, Runyu and Zhao, Hengshuang and Qi, Xiaojuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3173--3182},
  year={2021}
}
@InProceedings{VS_2022_WACV,
    author    = {VS, Vibashan and Poster, Domenick and You, Suya and Hu, Shuowen and Patel, Vishal M.},
    title     = {Meta-UDA: Unsupervised Domain Adaptive Thermal Object Detection Using Meta-Learning},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2022},
    pages     = {1412-1423}
}
@article{wang2018deep,
  title={Deep visual domain adaptation: A survey},
  author={Wang, Mei and Deng, Weihong},
  journal={Neurocomputing},
  volume={312},
  pages={135--153},
  year={2018},
  publisher={Elsevier}
}
@article{csurka2017domain,
  title={Domain adaptation for visual applications: A comprehensive survey},
  author={Csurka, Gabriela},
  journal={arXiv preprint arXiv:1702.05374},
  year={2017}
}
@InProceedings{VS_2021_CVPR,
    author    = {VS, Vibashan and Gupta, Vikram and Oza, Poojan and Sindagi, Vishwanath A. and Patel, Vishal M.},
    title     = {MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {4516-4526}
}

@article{vs2022target,
  title={Target and task specific source-free domain adaptive image segmentation},
  author={VS, Vibashan and Valanarasu, Jeya Maria Jose and Patel, Vishal M},
  journal={arXiv preprint arXiv:2203.15792},
  year={2022}
}

@article{guo2021pct,
  title={Pct: Point cloud transformer},
  author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R and Hu, Shi-Min},
  journal={Computational Visual Media},
  volume={7},
  pages={187--199},
  year={2021},
  publisher={Springer}
}



@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}


@article{goel2022cyclip,
  title={CyCLIP: Cyclic Contrastive Language-Image Pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan A and Vinay, Vishwa and Grover, Aditya},
  journal={arXiv preprint arXiv:2205.14459},
  year={2022}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7331--7341},
  year={2021}
}

@article{luo2022clip4clip,
  title={CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  volume={508},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{cho2022fine,
  title={Fine-grained image captioning with clip reward},
  author={Cho, Jaemin and Yoon, Seunghyun and Kale, Ajinkya and Dernoncourt, Franck and Bui, Trung and Bansal, Mohit},
  journal={arXiv preprint arXiv:2205.13115},
  year={2022}
}
@inproceedings{xie2022clims,
  title={CLIMS: cross language image matching for weakly supervised semantic segmentation},
  author={Xie, Jinheng and Hou, Xianxu and Ye, Kai and Shen, Linlin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4483--4492},
  year={2022}
}

@article{liang2022open,
  title={Open-vocabulary semantic segmentation with mask-adapted clip},
  author={Liang, Feng and Wu, Bichen and Dai, Xiaoliang and Li, Kunpeng and Zhao, Yinan and Zhang, Hang and Zhang, Peizhao and Vajda, Peter and Marculescu, Diana},
  journal={arXiv preprint arXiv:2210.04150},
  year={2022}
}

@article{zhou2021denseclip,
  title={Denseclip: Extract free dense labels from clip},
  author={Zhou, Chong and Loy, Chen Change and Dai, Bo},
  journal={arXiv preprint arXiv:2112.01071},
  year={2021}
}

@inproceedings{tevet2022motionclip,
  title={Motionclip: Exposing human motion generation to clip space},
  author={Tevet, Guy and Gordon, Brian and Hertz, Amir and Bermano, Amit H and Cohen-Or, Daniel},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXII},
  pages={358--374},
  year={2022},
  organization={Springer}
}

@misc{guzero,
  title={Zero-shot detection via vision and language knowledge distillation. CoRR abs/2104.13921 (2021)},
  author={Gu, X and Lin, T and Kuo, W and Cui, Y}
}

@inproceedings{zhou2022detecting,
  title={Detecting twenty-thousand classes using image-level supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Philipp and Misra, Ishan},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IX},
  pages={350--368},
  year={2022},
  organization={Springer}
}

@inproceedings{koniarski2022feature,
  title={Feature Point Cloud Based Registration in Augmented Reality},
  author={Koniarski, Konrad and My{\'s}li{\'n}ski, Andrzej},
  booktitle={Advances in Systems Engineering: Proceedings of the 28th International Conference on Systems Engineering, ICSEng 2021, December 14-16, Wroc{\l}aw, Poland 28},
  pages={418--427},
  year={2022},
  organization={Springer}
}

@article{you2022robot,
  title={Robot-Based Real-Time Point Cloud Digital Twin Modeling in Augmented Reality},
  author={You, Hengxu and Xu, Fang and Du, Eric},
  journal={Transforming Construction with Reality Capture Technologies},
  year={2022}
}

@article{wang2023pointshopar,
  title={PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality},
  author={Wang, Zeyu and Nguyen, Cuong and Asente, Paul and Dorsey, Julie},
  year={2023}
}

@article{zhou2021path,
  title={Path planning with automatic seam extraction over point cloud models for robotic arc welding},
  author={Zhou, Peng and Peng, Rui and Xu, Maggie and Wu, Victor and Navarro-Alarcon, David},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={5002--5009},
  year={2021},
  publisher={IEEE}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{chen2022adaprompt,
  title={Adaprompt: Adaptive model training for prompt-based nlp},
  author={Chen, Yulong and Liu, Yang and Dong, Li and Wang, Shuohang and Zhu, Chenguang and Zeng, Michael and Zhang, Yue},
  journal={arXiv preprint arXiv:2202.04824},
  year={2022}
}

@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@article{li2018pointcnn,
  title={Pointcnn: Convolution on x-transformed points},
  author={Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{gao2022get3d,
  title={Get3d: A generative model of high quality 3d textured shapes learned from images},
  author={Gao, Jun and Shen, Tianchang and Wang, Zian and Chen, Wenzheng and Yin, Kangxue and Li, Daiqing and Litany, Or and Gojcic, Zan and Fidler, Sanja},
  booktitle={Advances In Neural Information Processing Systems},
  year={2022}
}