\section{Future Directions}\label{sec:future}
% \begin{itemize}
%     \item large-scale data
%     \begin{itemize}
%         \item integrate multiple small datasets into large one
%         \item federated learning to decentralize the training of LAMs on various private sources of data to make use of private dataset.
%         \item create new dataset
%     \end{itemize}
%     \item model
%     \begin{itemize}
%         \item adapted to exclusive modality in medical data, and how to fuse them
%         \item prompt engineering to prompt versatile, downstream, applications.
%         \item efficiency regarding training and inference
%         \item duo mo xing hui zhen
%     \end{itemize}
%     \item societal concerns
%     \begin{itemize}
%         \item right reasoning for right output
%         \item adversarial vulnerability
%         \item security
%         \item norms
%     \end{itemize}
% \end{itemize}

% \textbf{application: long term health monitoring}

As research continues to progress and advance the development of LAMs as well as further our understanding of their strengths and weaknesses, in this section, we discuss some potential research directions of LAMs and their future outlook in the field of biomedical and health informatics.

Currently, a large portion of medical LAM research is focused on language and vision. Other pervasive modalities such as many tabular and time-series data including EEG and ECG are less explored. Speech is also an important avenue to explore, e.g., developing a medical LAudiM that can summarize recorded conversations into medical notes, which can save huge amounts of time in outpatient clinics. It is also worth future investigation on a wider range of medical and healthcare data modalities to potentially create a holistic LAM that can serve as the foundation for tackling various downstream tasks in this field. 


% In addition, a multi-modal medical LAM may potentially show more compassion and care while engaging with patients, e.g., a better understanding of a patient's sentiment from his/her tones and faces~\cite{stypulkowski2023diffused} while responding in a conversational dialogue with the patient. 

Compared to data from the general domain, massive amounts can be aggregated to a central repository for LAM development. In biomedical, clinical, and health domains, data are often decentralized, and possessed by individual institutions and hospitals due to privacy and ethical issues. In light of this, future work can investigate the use of blockchain technologies and federated learning~\cite{dou2021federated} to decentralize the development and deployment of LAMs for healthcare-related applications. 

Inference budget becomes practical and more important for end users such as hospitals when it comes to the deployment of medical LAMs. Touvron et al.~\cite{touvron2023llama} recently suggested that it is possible to train smaller LAMs that retain competitive accuracy. Another potential way worth investigating is to use knowledge distillation~\cite{qin2021efficient} to transfer the capabilities of LAMs to smaller models. 

Apart from accuracy, defining explicit evaluation metrics that can better measure the social and ethical compliance, and scientific and factual grounding of LAMs can advance and accelerate their practical applications in medical and health domains. For example, a clear passing threshold can be defined, and if LAMs are able to exceed the passing threshold, their strong reasoning and generative capabilities can potentially be leveraged to generate more medical data to either augment model training or further the understanding of, e.g., a particular disease.  

The recent GeneTuring test~\cite{hou2023geneturing} revealed that it is not uncommon for LLMs exhibiting AI hallucinations and the unawareness of its incapacity. RLHF might be a solution to strengthen the medical and factual grounding of biomedical and health LAMs. However, the current optimal policy of RLHF may lack security evaluation, which can not be directly applied to clinical experiments~\cite{yu2021reinforcement}. The use of RLHF also requires professional medical experts to curate the human preference dataset. For future work in this direction, joint efforts from clinical and RL experts are needed. 

Prompt engineering which involves crafting effective prompts or inputs to guide a LAM's behavior has emerged as a key research direction for advancing LAMs. Similarly, prompt engineering in health informatics should involve the use of domain-specific prompts that reflect the relevant clinical or medical knowledge. These prompts should be carefully crafted to reflect the nuances of the healthcare domain, and should be designed to guide a LAM toward accurate and clinically relevant predictions. 
% Interactive prompts can be used to allow healthcare providers to interact with the model and guide its behavior in real time. This can be particularly useful in clinical settings, where healthcare providers may need to adjust the model's behavior based on patient-specific information. 
Multi-modal prompts can be used to combine multiple sources of data, such as medical images and patient records, to guide a LAM's behavior. 
% These prompts can help to ensure that the outputs of the LAM are, even when working with complex and heterogeneous data.
% Overall, prompt engineering is an important aspect of LAMs in health informatics, as it can help to ensure that the model is making accurate and clinically relevant predictions. 
By using domain-specific, dataset-specific, interactive, and multi-modal prompts, healthcare providers can develop LAMs that are optimized for healthcare applications.

% \textcolor{red}{Efficient computing is becoming increasingly important for LAMs in health informatics, particularly as these models become more complex and require more computational resources. Efficient computing enabling LAMs to be trained and deployed more quickly and effectively. By optimizing model architecture, using parallel processing, and leveraging techniques such as model compression, pruning, or quantization, healthcare providers can develop more accurate, efficient, and effective AI models for a wide range of health informatics applications.}

% \textcolor{red}{Privacy computing is an important consideration for LAMs in health informatics, as these models often process sensitive patient data. Differential privacy is a technique that adds noise to data to protect individual privacy while still allowing for useful insights to be extracted. This technique can be applied to large AI models to ensure that patient data remains private, even when the model is trained on sensitive data. Overall, privacy computing is essential for LAMs in health informatics, as it allows sensitive patient data to be protected while still enabling models to be trained and deployed effectively. Techniques such as differential privacy, federated learning, homomorphic encryption, and secure enclaves can all be used to protect patient privacy in large AI models.}

As discussed in Section~\ref{sec:challenges}, current LAMs still show different levels of vulnerability to adversarial attacks, how to increase their robustness and increase the interpretability and explainability~\cite{carusi2023medical} of their outputs remains an open question for future research.






% \begin{enumerate}
  




%     \item large graph models (LGMs)? to model structural clinical data. GreaseLM~\cite{zhang2022greaselm} \textcolor{red}{(double check if it is a LGM)}
%     \item key take away from Stanford - Improving Transparency in AI Language Models: A Holistic Evaluation: 1) they found that fine-tuning language models with human feedback can improve accuracy, robustness, and fairness. Also such fine-tuning sometimes could enable smaller language models to yield comparable performance to those of models that are 10 times the size; 2) of course we should improve transparency of LAMs, as they will have immense societal impact
%     % \item clinical and medical data is also long-tailed. e.g., some rare diseases are only detected in a few people, whereas some are widespread. although LAMs especially LLMs have demonstrated impressive few-shot learning capability, it still needs to be validated on clinical and medical domain


% \end{enumerate}