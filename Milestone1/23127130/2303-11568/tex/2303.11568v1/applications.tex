\section{Applications of Large AI Models in Health Informatics}\label{sec:applications}


\begin{figure*}[!t]
\centerline{\includegraphics[width=\textwidth]{figures/lams_per_application.pdf}}
\caption{A summary of current large AI models (LAMs) in biomedical and health informatics.}
\label{fig:lams_per_application}
\end{figure*}


In this section, we identify seven key sectors in which LAMs will have substantial influence and bring new paradigm shifts for tackling the problems and challenges in health informatics. The seven key sectors include 1) molecular biology and drug discovery; 2) medical diagnosis and decision-making; 3) medical imaging and vision; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We summarize in Fig.~\ref{fig:lams_per_application} those LAMs that are identified in or can be applied to each corresponding sector, and illustrate in Fig.~\ref{fig:LAM_application_in_HI} various downstream applications and tasks in health informatics in which LAMs can play an important role.













































\subsection{Molecular Biology and Drug Discovery}\label{subsec:mole_bio_drug_disconvery}

\subsubsection{Molecular Biology}
% \textcolor{red}{what is molecular biology; why LAMs will impact this field; a summary of the current LAM development in this field (few sentences or 1 paragraph); go to details of current LAMs; discussion}

Molecular biology studies the roles of biological macromolecules (e.g., DNA, RNA, protein) in life processes and describes various life activities and phenomena including the structure, function, and synthesis of molecules. Although many experimental attempts have been made on this topic over decades~\cite{bai2015cryo,wuthrich2001way,grimes2018crystallography}, they are still of high cost, long experiment cycle, and high production difficulty. For example, the number of experimentally determined protein structures stored in the protein data bank (PDB) hardly rivals that of known protein sequences. Efficient and accurate computational methods are therefore needed and can be used to accelerate the determination process. Due to the huge number of parameters and learning capacity, LAMs endow us with prospects to approach such a Herculean task. Especially, LLMs' outstanding representation learning ability has been employed to implicitly model the biological properties hidden in large-scale unlabeled data including RNA and protein sequences. 

%To this end, deep learning methods, with their superior capability of feature learning and predicting, have been employed to revolutionize the field of protein structure prediction. Instead of directly predicting 3-Dimensional topology from input sequences, several early works\cite{senior2020improved}\cite{yang2020improved}\cite{wang2017accurate}\cite{li2019respre}\cite{li2021deducing}\cite{shen2021homologous} reformulate the problem as the computer vision task. Concretely, sequences and features computed from multiple sequence alignment (MSA) are input into deep residual network\cite{he2016deep} to predict a set of structural features including distance histogram, contact map, and inter-residue torsion angles. These predicted features are then converted into differentiable constraints to produce optimized 3D coordinate predictions. 


When it comes to the field of protein, starting from amino acid sequences, we can analyze the spatial structure of proteins and furthermore understand their functions, and mutual interactions. AlphaFold2~\cite{jumper2021highly} pioneered leveraging the attention-based Transformer model~\cite{vaswani2017attention} to predict protein structures. Specifically, they treated structure prediction as a 3D graph inference problem, where the network's inputs are pairwise features between residues, available templates, and multi-sequence alignment (MSA) embeddings. Especially, embeddings extracted from MSA can infer the evolutionary information between aligned sequences. Evoformer and structure modules were proposed to update the input representation and predict the final 3D structure, the whole process of which was recycled several times. Additionally, self-distillation and self-estimation were utilized on unlabeled data to improve prediction accuracy.
Also based on MSA, RoseTTAfold\cite{baek2021accurate} devised a 3-track neural network to exploit the interactions between sequence, distance map, and 3D coordinates concurrently. While previous works are well-established for single-chain protein prediction, AlphaFold-Multimer\cite{evans2021protein} extended AlphaFold to enable precise multi-chain protein complex prediction. Specifically, positional encoding was improved to encode chains, and multi-chain MSAs were paired based on species annotations and target sequence similarity.

Meanwhile, prohibitive computational resources (e.g., AlphaFold2 requires 128 TPU v3 for training) required for model training are barely accessible to many research communities. To reconcile this issue, Cheng et al.\cite{cheng2022fastfold} reduced training and inference time and mitigated the severe memory consumption by scaling the model training on GPUs. HelixFold\cite{wang2022helixfold} reimplemented AlphaFold2 in a more efficient way using PaddlePaddle. On top of that, extensive efforts have been put into building open-source platforms and libraries, enabling protein structure prediction software more accessible to the public~\cite{li2022uni,ahdritz2022openfold,villegas2023manyfold,mirdita2022colabfold}.

In spite of the groundbreaking endeavors aforementioned works have contributed, to achieving optimal prediction, they still heavily rely on MSAs and templates searched from genetic and structure databases, which is time-consuming. Instead, researchers managed to employ large-scale protein language models (PLMs) to learn co-evolution information in a self-supervised manner. PLMs learned the global relation and long-range dependencies of unaligned and unlabelled protein sequences and the learned representations can be transferred to benefit the downstream tasks (e.g., protein structure prediction). Rives et al.\cite{rives2021biological} proposed ESM-1b transformer (650M) which is trained on UniParc database\cite{uniprot2007universal} that comprises 86 billion amino acids. By studying representation space learned under self-supervision, they found the model learned to encode biochemical properties, biological variations, and remote homology of proteins. ProGen (1.2B)\cite{madani2020progen} utilized a conditional language model to provide controllable generation of protein sequences. By inputting desired tags (e.g., function, organism), ProGen can generate corresponding proteins such as enzymes with good functional activity. Elnaggar et al.\cite{article} devised ProtT5-XXL (11B) which was first trained on BFD\cite{steinegger2018clustering} and then fine-tuned on UniRef50\cite{suzek2015uniref} to predict the secondary structure. ESMfold\cite{lin2022language} scaled the number of model parameters up to 15B and observed a significant prediction improvement over AlphaFold2 and RoseTTAfold with considerably higher inference speed when MSAs and templates are unavailable. Similarly, from only the primary sequence input, OmegaFold\cite{wu2022high} and RGN2\cite{chowdhury2022single} can outperform MSA-based methods~\cite{jumper2021highly,baek2021accurate}, especially when predicting orphan proteins which are characterized by the paucity of homologous structure.

% The conspicuousness of utilizing LLMs for self-supervised representation learning also reflects in various other applications. 
Moving beyond single-chain protein structure prediction, Chen et al.\cite{chen2022improved} utilized PLMs to enhance MSA-pairing and hence improve the accuracy of protein complex prediction. Instead of using single sequence input, MSA transformer\cite{rao2021msa} takes as input MSAs, which exploits the co-evolutionary signal across the protein family. In so doing, the model is capable of leveraging both covariance information and biological patterns of sequences learned during training. Some studies specialize in pre-trained antibody language models and elucidate that the learned embeddings can reveal antibody-specific information including immunogenicity, binding sites, structure, and function~\cite{ruffolo2021deciphering,wang2022xtrimoabfold}. Similarly, Yang et al.\cite{yang2022scbert} applied the large-scale language model on single-cell RNA-seq data to capture mutual interactions between genes and facilitate downstream cell-type tasks (e.g., new cell type discovery).

In the context of RNA structure prediction, the number of nonredundant 3D RNA structures stored in PDB is significantly less than that of protein structures, which hinders the accurate and generalizable prediction of RNA structure from sequence information using deep learning. To mitigate the severe unavailability of labeled RNA data, Chen et al. \cite{chen2022interpretable} proposed the RNA foundation model (RNA-FM), which learns evolutionary information implicitly from 23 million unlabeled ncRNA sequences\cite{rnacentral2021rnacentral}, to facilitate multiple downstream tasks including RNA secondary structure prediction and 3D closeness prediction. Concretely, the model is enforced to predict the original nucleotide tokens from the masked ones and hence learn useful RNA representations. Furthermore, based on RNA-FM, Shen et al.\cite{shen2022e2efold} pioneered predicting 3D RNA structure directly.

% Undoubtedly, these models are transformational and have reduced the time and cost of molecule structure prediction by a large margin. Thereby, this raises the question of whether AI can completely replace experimental methods such as Cryo-EM\cite{bai2015cryo}? We deem that it still falls short from that point. Specifically, the advance of LAMs builds upon big data and large model capacity, which means they are still data-driven in nature. Their ability in predicting unseen types of data could be problematic. For instance, in terms of protein structure prediction, \cite{buel2022can} stated that AlphaFold can barely handle missense mutation on protein structure due to the lack of a corresponding dataset. Meanwhile, deep learning models are able to perform end-to-end prediction of 3D structures but predominantly skip the process of protein folding, which means existing deep learning methods could miss crucial information such as some physical properties of molecules or chemical information. 


% Furthermore, competitions such as Critical Assessment of techniques for protein Structure Prediction (CASP) evaluate the accuracy of model prediction based on protein structures obtained by experimental methods, which means that the evaluation metrics are based on known structures. So how can we judge the quality of model prediction for unknown protein structures still remains unclear. This is also reflected in the fact that the protein database constructed from the model predictions has low-quality parts that we are unable to clearly identify at the moment. Consequently, these low-quality or unverified protein structures cannot be applied to, for example, drug discovery. Therefore, protocols and metrics need to be established to assess their potential impact and to perform the quality assessment.


Undoubtedly, these models are seminal and have reduced the time and cost of molecule structure prediction by a large margin. Thereby, this raises the question of whether AI can completely replace experimental methods such as Cryo-EM\cite{bai2015cryo}. We deem that it still falls short from that point. Specifically, the advance of LAMs builds upon big data and large model capacity, which means their ability to predict unseen types of data could be problematic. For instance, \cite{buel2022can} stated that AlphaFold can barely handle missense mutation on protein structure due to the lack of a corresponding dataset. Furthermore, how can we assess the quality of model prediction for unknown protein structures still remains unclear. In turn, these unverified protein structures cannot be applied to, for example, drug discovery. Therefore, protocols and metrics need to be established to assess their quality and potential impacts. There are mutual and complementary benefits between LAMs and conventional experimental techniques. LAMs can be re-designed to predict the process of protein folding and reveal their mutual interactions so as to facilitate experimental methods. On the other hand, experimental information, such as some physical properties of molecules, can be leveraged by LAMs to further improve prediction performance, especially when dealing with rare data (e.g., orphan protein).





\subsubsection{Drug Discovery}

Novel drug discovery requires numerous iterative cycles of design, validation, screening, and optimization until a compound is found to be effective at the target site while meeting safety standards for humans~\cite{burki2020newdrugdesign}. Such complex, costly, and time-consuming flows may be accelerated by using LAMs. Recently, various transformer-based molecular property prediction techniques for drug discovery have been proposed including SMILES-BERT~\cite{wang2019smilesBERT}, SMILES Transformer~\cite{honda2019smilesTRANS}, MolBERT~\cite{fabian2020molecularBERT} and AGBT~\cite{chen2021AGBT} as the most popular representation of molecules is regarded as SMILES strings. Molecular Graphs are another representation of molecular property prediction introduced in GROVER~\cite{rong2020GROVER}. With over 100 million parameters trained on 10 million unlabelled molecules data, GROVER is capable of acquiring abundant structural and semantic information about molecules for drug discovery. Apart from molecular property prediction, molecule generation is another fundamental task for drug discovery. Both MolGPT~\cite{bagal2021molgpt} and the accelerated Generative Model proposed by Yang et al.~\cite{yang2021transformermolegeneration} used SMILES strings~\cite{honda2019smiles} as input for generation tasks. Treating molecular graph as input for molecule generation has been achieved in Molecule Chef\cite{bradshaw2019MoleculeChef} and de novo drug design~\cite{grechishnikova2021transformerdonovo}. Moreover, drug-target interaction (DTI) prediction, as an important component of drug discovery, has also benefited from LAMs~\cite{lee2019deepconv,nguyen2021graphdta,huang2021moltrans}. Previous research has mainly made contributions to drug discovery partially, thus the unified LAMs with whole-process optimization capabilities in drug discovery have started to be developed.

% make it natural to think of dealing drug discovery with LAMs. Benefits from the fortissimo representative learning ability of LLMs, billions of atomic permutations can be analyzed efficiently. Moreover, solubility, intrinsic permeability, etc. other characteristics~\cite{paul2021artificialdrug} of novel life-saving drugs that can be accurately predicted by LAMs. 

% \textbf{Drug Discovery is another process now accelerated by LAMs, built on the top of successful molecular analysis for reducing the excessiveness and costly experiments during the development of novel medicines~\cite{stark2022equibind}. Pharmaceutical molecules whose efficacy depends on their affinity for target proteins or receptors. The solubility, intrinsic permeability, etc. other characteristics of the drug will indirectly affect its efficacy~\cite{paul2021artificialdrug}. So leveraging the fortissimo representative learning ability of LAMs for drug discovery has attracted much attention recently. }

% A new drug candidate compound developed by AI to enter the world's first phase of clinical trials~\cite{mak2022success}.

% \textbf{Since deep learning-based approaches on large-scale molecular data have shown competitive results on molecular design~\cite{chen2018rise}, the traditional resource-intensive guesswork of drug development has become a relatively simple process. 
% }

% Specifically, Zhang et al.~\cite{zhang2022canpretrained} explored the relationship between pre-trained models and drug discovery effectiveness and proposed a novel algorithm to evaluate the quality of the representations extracted. Moreover, drug-target interaction (DTI) prediction, an important component of drug discovery, also benefits from LAMs~\cite{lee2019deepconv,nguyen2021graphdta,huang2021moltrans}. However, previous research mainly made contributions to whole drug discovery partially, the unified LAMs with whole-process optimization capabilities in drug discovery are supposed to be developed.

% \textcolor{red}{LAM}
A typical representation learning framework that was trained on more than 700 million unlabeled molecules has been introduced by Chen et al.~\cite{chen2021extracting}, which has the ability to automatically select the best model for a given task. 
In addition to this, Tencent iDrug~\cite{xiong2021admetlab} has developed an integrated AI platform for multi-functions including protein structure prediction, virtual screening, molecular generation as well as ADMET (absorption, distribution, metabolism, excretion, and toxicity) prediction. MolGNet~\cite{li2020mpgnet}, as a pre-trained model with 53 million parameters, has been integrated into the platform MPG~\cite{li2021mpg} as a base module, which can be leveraged for multiple tasks, including molecular properties prediction, drug-drug interaction, and drug-target interaction. 
Zhang et al.~\cite{zhang2021mgbert} also proposed MG-BERT which was trained on sources from over 700 million unlabeled molecules. This method leveraged the advantages of self-supervised representation learning from LLMs where the local message-passing mechanism of GNN has been incorporated with a BERT model for precise and reliable prediction of drug features. The recent PanGu Drug Model~\cite{lin2022pangu}, with a novel graph-to-sequence asymmetric structure, was trained on 1.7 billion data to learn the relationship between chemical structures and formula strings, similar to human cognitive transformation.
Novel text-based representations instead of SMILES have been proposed so that the model was able to benefit from the structure of LLMs. DrugBAN~\cite{bai2023interpretable} described the causality of the discoverable drugs and the initial one for accurate prediction and designed a solution to achieve generalization for drug-target pair discovery.  


% Chembeta-2~\cite{ahmad2022chemberta2}
% Claiming to be a foundation model in arxiv with 5 pages, but Jiachuan thought the chembeta1.0 is too small to regard as a LAM. So we ignore the chembera2.0





% which provides an automated dataset manager with custom scripts, rich domain annotation consistent with biochemical knowledge, and realistic noise annotation. 
% The following approach for drug target binding affinity prediction achieved SOTA as well, 


Although LAMs have shown competitive predictions for drug discovery, the current heterogeneous sources of data still lack the capacity to fulfill the emergency and rare requirements for clinical translation. 
% Drug discovery is the cornerstone of the entire drug development process and the most promising breakthrough for drug innovation. 
% To date, there has not been a single drug, primarily screened by LAMs, approved by the Food and Drug Administration (FDA) for marketing. So LAMs are expected to be involved in more, including drug synthesis, efficacy validation, and participation in the completion of clinical studies. 
The first yet comprehensive dataset (96 realized exemplar datasets) for AI drug discovery and corresponding benchmarks has been introduced recently~\cite{2022drugood}, which may encourage more joint research from the medicine, chemistry and computer science communities to advance AI-based drug discovery. NVIDIA BioNeMo Service~\cite{nvidia} has also recently released a highly integrated cloud service and framework to advance molecular biology and drug discovery.


% The bioactivity or toxicity of potential drugs is supposed to be predicted accurately by the DL models~\cite{zhavoronkov2019DDR1}. 








\subsection{Medical Diagnosis and Decision-making}

As research has been carried out to improve the safety and strengthen the factual grounding of LAMs, it is foreseeable that LAMs will play a significant role in medical diagnosis and decision-making. A pilot study conducted by Kung et al.~\cite{kung2023performance} revealed that ChatGPT was able to approach the passing performance of the US Medical Licensing Exam (USMLE), demonstrating sound knowledge spectrum and reasonable capabilities in bioethics, clinical reasoning, and medical management. 


Medical diagnosis can also be automated and enhanced by LVMs, and other LMMs that incorporate visual modality to offer more precise localization, recognition, detection, and segmentation of medical images, leading to better interpretation for diagnostic outcomes. For example, CheXzero~\cite{tiu2022expert}, a zero-shot chest X-ray classifier, has recently demonstrated radiologist-level performance in classifying multiple pathologies which it never saw in its self-supervised learning process. An LMM that jointly learns from medical images and medical corpora can also provide medical diagnosis support by interpreting medical images for the clinicians~\cite{chen2022multi}.


Recently, ChatCAD~\cite{wang2023chatcad}, a framework that integrates multiple diagnostic networks with ChatGPT, demonstrated a potential use case of applying LLMs in computer-aided diagnosis (CAD) for medical images. By stratifying the decision-making process with specialized medical networks, and followed by an iteration of prompts based on the outcomes of those networks as the queries to an LLM for medical recommendations, the workflow of ChatCAD offers an insight into the integration of the LLMs that were pre-trained using a massive corpus, with the upstream specialized diagnostic networks for supporting medical diagnosis and decision-making.  


Medical LAMs may also potentially produce a more reliable forecast of treatment outcomes and the future development of diseases using their strong reasoning capability. For example, Li et al.~\cite{li2020behrt} proposed BEHRT, which is able to predict the most likely disease of a patient in his/her next visit by learning from a large archive of EHRs. Rasmy et al.~\cite{rasmy2021medbert} recently proposed Med-BERT, which was able to predict the heart failure of diabetic patients. The accurate prediction ability of these LLMs could benefit precision decision-making, provide clinical decision support, and better treatment recommendations for doctors in the future. 


With the ubiquity of internet, medical LAMs can also offer remote diagnosis and medical consultation for people at home, providing people in need with more flexibility of medical consultation and diagnosis. 


However, as Wang et al.~\cite{wang2023robustness} revealed, despite being informative, general LLMs such as ChatGPT actually are not definitive while responding to medical-related questions. This is also aligned with Jeblick et al.'s findings~\cite{jeblick2022chatgpt}, which revealed that while asked to simplify radiological reports so that non-experts could also understand, ChatGPT sometimes would produce incorrect statements. Recently, Antaki et al.~\cite{antaki2023evaluating} also suggested that while the answers to general medical questions are generally sound, for specialized areas, such as neuro-ophthalmology and ophthalmic pathology, ChatGPT actually cannot produce reliable answers. As previously Gu et al.~\cite{gu2021domain} indicated that LLMs pre-trained with medical corpora from scratch can exhibit better performance on medical tasks, for future development, it is promising to design a medical and clinical knowledgeable LAM with large amounts of unlabelled medical data so that the properly trained medical LAM can accurately interpret the current medical status and recall the medical history of a patient to automatically generate diagnostic report~\cite{ramesh2022improving} for the patient, or generate more clinically sound responses for medical queries. We also envision that future diagnosis of complex diseases may also be conducted or assisted by a panel of clinical LAMs. 




% triage
 


% radiology, pathology, histology, \textbf{ophthalmology}, precision diagnosis, treatment recommendation, computer-aided diagnosis, clinical decision support, previous clinical decisions and outcomes, the proliferation of medical data, medical and health data are heterogeneous.




% histology slides (here or in medical imaging and vision)


% Robust medical diagnosis and decision-making; 

% The increasing common use of medical imaging in diagnosis of diseases has produced abundant medical images for the development of LVMs, LLVMs, and other LAMs that incorporate visual modality. 

% \begin{enumerate}
%     \item CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning~\cite{rajpurkar2017chexnet}
%     \item CheXzero: using the radiology reports to provide self-supervsion for chest x ray classification. based on ViT-B/32 
%     \item Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction.\cite{rasmy2021medbert}
%     % \item ChatCAD~\cite{wang2023chatcad}: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models
%     % \item Performance of ChatGPT on USMLE~\cite{kung2023performance}: USMLE (United States Medical Licensing Exam). As it passes this exam, it can potential assist decision-making.
%     % \item Large Language Models are Few-Shot Clinical Information Extractors~\cite{agrawal2022large}
 
% \end{enumerate}















\subsection{Medical Imaging and Vision}
% \textcolor{blue}{PL:(a) fall detection (b) action and activity monitoring (c) sleep monitoring (d) respiration and apnea monitoring (e) epilepsy monitoring (f) vital signs monitoring and (g) facial expression monitoring. WILL DO THAT}





The adoption of medical imaging and vision techniques has vastly influenced the process of diagnosis and treatment of a patient. The wide use of magnetic resonance imaging (MRI), computed tomography (CT), positron emission tomography (PET), optical coherence tomography (OCT), and ultrasound also has produced a vast amount of multi-modal, multi-source, and multi-organ medical vision data to foster the development of medical vision LAMs.



Med3D~\cite{chen2019med3d}, a heterogeneous 3D framework that enables pretraining on multi-domain medical vision datasets, shows strong generalization capabilities in downstream tasks, such as lung segmentation and pulmonary nodule classification. Models Genesis~\cite{zhou2019models} has recently been proposed to boost 3D medical imaging with self-supervised learning, and yielded state-of-the-art performance on different 3D downstream applications. Google recently proposed MICLe~\cite{azizi2021big}, which utilizes self-supervised learning and shows robustness to distribution shift that is inherent in medical data. Contrastive learning has been a common choice in using self-supervised learning. Zhou et al.~\cite{zhou2020C2L} proposed C2L, a self-supervised method that contrastively learns from 700k unlabelled radiographs for effective chest X-ray classification. ConVIRT~\cite{zhang2022convirt}, a domain-agnostic approach that learns medical visual representations with paired diagnostic text, shows its contrastively learned visual representations lead to improved classification and retrieval accuracy. Similarly, GLoRIA~\cite{huang2021gloria} further adds the attention mechanism for contrastive learning of medical image and text pairs. MoCo-CXR~\cite{sowrirajan2021moco} shows Momentum Contrast~\cite{he2020momentum} pre-trained medical image representations can lead to better accuracy such as more accurate pleural effusion detection in many chest X-ray datasets. Many efforts have also been made to integrate the Transformer-based structure into models designed for medical vision, e.g., TransUNet~\cite{chen2021transunet}, TransFuse~\cite{zhang2021transfuse}, MedT~\cite{valanarasu2021medT}, CoTr~\cite{xie2021cotr}, and UNETR~\cite{hatamizadeh2022unetr}. Swin-Unet~\cite{cao2023swinunet} uses the hierarchical Swin Transformer~\cite{liu2021swin} to construct a U-Net~\cite{ronneberger2015u} structure for multi-organ and cardiac segmentation tasks, in which it outperforms the previous state-of-the-arts. Similarly, Swin UNETR~\cite{tang2022self} also leverages Swin Transformer for encoding features, and has validated the effectiveness of self-supervised pretraining of 3D medical images to tackle 3D medical segmentation challenges. UNETR++~\cite{shaker2022unetrplus} has recently been proposed, which balances the accuracy and efficiency of transformer-based structures for 3D medical segmentation. Sharing a similar paradigm of pre-training with self-supervision or basic architecture such as vision transformer, the above methods lay the foundation for fostering medical vision LAMs.   


With the success of generative LAMs such as Stable Diffusion~\cite{rombach2021highresolution} in the general domain, which can generate realistic high-fidelity images with text descriptions, Chambon et al.~\cite{chambon2022adapting} recently fine-tuned Stable Diffusion on medical data to generate synthetic chest X-ray images based on clinical descriptions. The encouraging generative capability of Stable Diffusion in the medical domain may inspire more future research on using generative LAMs to augment medical data that are conventionally hard to obtain.

MedCLIP~\cite{wang2022medclip} has recently been proposed, a contrastive learning framework for decoupled medical images and text, which demonstrated impressive zero-shot medical image classification accuracy. In particular, it yielded over 80\% accuracy in detecting Covid-19 infection in a zero-shot setting.


Nevertheless, some compromises are also evident in medical vision LAMs. For example, the currently common practice of training LVMs and LMMs often limits the size of the medical images to shorten the training time and reduce the computational costs. The reduced size inevitably causes information loss, e.g., some small lesions that are critical for accurate recognition might be removed in a compressed downsampled medical image, whereas doctors could examine the original high-resolution image and spot these early-stage tumors. This may cause performance discrepancies between current medical vision LAMs and well-trained doctors.


LAMs are also transforming medical vision beyond clinical settings. For example, the recent GPT-4~\cite{gpt4openai2023} has been integrated to empower visual assistance, providing image-to-text interpretation for people with visual impairment~\cite{bemyeyes2023}.

% Tiu et al.~\cite{tiu2022expert} proposed CheXzero, which successfully detected pathologies from unannotated chest X-ray datasets at an expert level. 







% To address the limitation of only being able to train using paired data, zhang et al.~\cite{wang2022medclip} proposed the MedCLIP, decoupling the pairing of images and text and instead using a manually constructed weak tagging system as a tool for matching information. Tailoring diverse but limited medical imaging data with pre-trained models meets given clinical requirements before medical LAMs arise~\cite{taleb20203d,zhang2021dodnet,sowrirajan2021moco}.


% Additionally, a novel self-supervised pre-training model for 3D CT analysis has achieved state-of-the-art performance by incorporating feature maps at a multi-scale level~\cite{tang2022self}. 

% It is undeniable that the above methods continue to explore the extension of the understanding and generalization of the DL models based on limited medical datasets, and that the use of multimodal information is an apparent trend, which lays the foundation for subsequent unified LAMs for medical image analysis~\cite{chambon2022adapting}.




% Since the GPT shows electrifying performance under the self-supervised pre-training paradigm. The models which leverage the Vision Transformer (ViT) into the large-scale medical dataset could be regarded as the herald of \textbf{medical vision LAMs}~\cite{chen2021transunet,zhang2021transfuse,valanarasu2021medT,xie2021cotr}. 




% Computer-aided medical image analysis is essentially learning image representations, in which the spaces of feature embedding are constructed via pre-text tasks\cite{noroozi2016unsupervised} or regarded as memorizing spatial context\cite{azizi2021big} \cite{chen2019self7}. 

%  \textcolor{red}{(it seems the mention of LAMs start here??? The above background and the current limitations of deep learning in medical imaging are still too much. They could actually be briefly discussed after the main body of medical vision LAMs, as some of them may also be the issues that LAMs need to tackle)}




% In brief, deep learning-based medical AI models are moving towards targeting modality-oriented or disease-aware services. To a certain extent, this is also in line with the logic of training a medical expert as an optometrist or cardiologist is not able to shine in each other's niches. People all receive a comprehensive fundamental knowledge of medicine, including internal medicine, surgery, and pediatrics
% before obtaining a Doctorate of Medicine and of Philosophy (M.D.). The LAMs in the medical field do not ingest medical a priori knowledge while the medical image and text are sheerly input. This may also explain the weak generalization of the medical pre-trained model as well as diagnoses from doctors are more convincing to patients. Moreover, the same publicly available datasets across the medical AI models development frequently reuse increases the likelihood of developing a model that performs excellently in a particular domain by chance~\cite{thompson2020dataset}. It is also recommended that better assessment indicators for medical LAMs be taken into consideration like learned perceptual image path similarity (LPIPS)~\cite{zhang2018unreasonableLPIPS}. Future AGI models have the benefit of continuous learning from an expert and patient feedback or anatomical patterns from more elementary models ~\cite{haghighi2021transvw}. Lastly, RTP-Net~\cite{shi2022rtpnet} presents people with another possibility for future medical imaging, in which initialization of whole-body organs-at-risk (OARS) and tumors could be one-off, swift, and pinpoint generated.



% LAMs of medicine are eventually expected to deal with clinical problems regarded as multifarious downstream tasks~\cite{varoquaux2022npjsurvey,zendel2017good} while the performance of LVMs is conceivably affected by the volume of training data~\cite{Sun_2017_ICCV}. By lucky coincidence, generative deep learning models achieved image synthesizing at unprecedented levels for dealing with medical image scarcity~\cite{yi2019ganmedsurvey,kim2022diffusion4dsurvey,dalmaz2022resvit,ghorbani2020dermgan,deshpande2022safron}, which makes extremely large-scale medical training data input for LAMs possible. Generalization has always been a dilemma for previous medical AI models~\cite{li2020domain}, that the distribution of data generated based on specific domains can exacerbate the imbalance in the global medical community information. Specifically, data on rare diseases that are difficult to collect often suffer from a lack of medical resources \cite{ferreira2019rareburden}, making it even more difficult to improve the quality of the data generated. Clinically-relevant predictions required very high reliability and interpretability for matching the actual target sufferer \cite{larrazabal2020gender,tasdizen2018improving,wachinger2021detect}. So LAMs are expected to draw from those increased steadily multi-modal, multi-source, and multi-organ data until handled with ease.


% which have occupied most modalities for early detection and medical pre-diagnosis under the standard of DICOM (Digital Imaging and Communications in Medicine) \cite{national1997dicom}. 
% The accuracy and reliability of diagnostics from the region of interest (ROI) often required the cooperation of multiple dimensions of multi modalities information. 
% Medical LAMs are supposed to draw from those increased steadily multi-modal, multi-source, and multi-organ data until performing as a doctor, which achieves inter-operable on top of generalizability and reliability, not limited to deal with basic tasks such as calibration, detection or segmentation, etc. Vision-based health monitoring in both surgery and recovery also performed an influential role for achieving better rehabilitation~\cite{srivastav2018mvor}~\cite{rodas2016xawAR16}. As extremely strong learners, LAMs are expected to predict and analysis on emergencies. However, under the shortage of heterogeneous medical data with a high professional threshold of labeling, a uniform LAM with generalization for medical image analysis still struggling with many problems. Unlike the properties of natural images, medical image analysis suffers from a high professional threshold of labeling and assessment, while ethical norms and patient privacy are also involved \cite{litjens2017medicalsurvey}. Another typical 
% characteristic different from natural images is that the majority of medical images are in 3D structural form. Fortunately, the available multimodal data with the advancing normative diagnostic information has been the basis for the development of LAMs.

% \textcolor{red}{JQ: Medical imaging and vision cover what sectors, e.g., MRI and CT data, vision-based monitoring, etc; why will medical imaging and vision be affected by LAMs; current situations of LAMs in this field (a brief summary here and say we will go into details in the following)}

% Pre-trained models based on large-scale natural image datasets have driven advances in downstream tasks of computer vision  applications~\cite{deng2009imagenet}~\cite{Sun_2017_ICCV}, which leads to widespread hope naturally to think of the medical image analysis field. 


% Synthetic data have been explored in various medical modalities~\cite{yi2019ganmedsurvey} ~\cite{kim2022diffusion4dsurvey} ~\cite{dalmaz2022resvit}~\cite{ghorbani2020dermgan}~\cite{deshpande2022safron}. However, 




% Even though images make up the majority of information in clinical diagnoses, researchers have not disregarded the information contained in written diagnosis letters or annotations of anatomy \cite{miura2020improving}. The LAMs with powerful learning abilities with global datasets are supposed to take more demographic cases into consideration\cite{abbasi2020risk} for mitigating medical resource imbalances.


% However, larger datasets in the medical field do not always lead to the same expectation we hoped for~\cite{mueller2005AD}. The pursuit of solely quantitative data augmentation will not benefit medical diagnosis under typical circumstances such as multi-organ, multi-modality and multi-disease \cite{zendel2017good}. 

% Proficiency of operators directly affects the qualities of a label \cite{oakden2020exploring} \cite{joskowicz2019inter} while economically developed regions tend to have better imaging equipment and more professional evaluation systems is another factor\cite{emanuel2020fair}. 


% A previous clinical experience with Alzheimerâ€™s disease (AD)~\cite{mueller2005AD}, supported by adequate long-term clinical data (over a thousand subjects),  has not shown more desirable diagnostic accuracy. Conversely, studies with larger input cases tend to report poorer predictive accuracy from a meta-analysis containing 478 studies of AD and mild cognitive impairment. While the minor enhancement of deep learning model performance has been taken on in later studies\cite{liu2019comparison} \cite{dallora2017machine} \cite{arbabshirani2017single} \cite{sakai2019machine} \cite{wen2020convolutional} \cite{ansart2021predicting}. Both the quality and quantity of medical image are increasing together with innovative imaging devices. While domain shift of medical data always appears because of different scanner vendors, and the status of equipment, also leading out of distribution\cite{zhou2022domainDG}. 


% Most previous works focus on leveraging the pre-trained model in both natural image datasets or larger medical image datasets with transfer learning in medical image analysis. While the effectiveness of
% supervised pre-training in medical imaging has been demonstrated in different applications~\cite{raghu2019transfusion} ~\cite{alzubaidi2020towards} ~\cite{cheplygina2019not}~\cite{tiu2022expert}~\cite{vu2021medaug}. 

\begin{figure*}[!t]
\centerline{\includegraphics[width=\textwidth]{figures/LAM_applications.pdf}}
\caption{Overview of the downstream applications and tasks of different large AI models (LAMs) in biomedical and health informatics.}
\label{fig:LAM_application_in_HI}
\end{figure*}




\subsection{Medical Informatics}

In medical informatics, it has been a topic of long-standing interest to leverage large-scale medical information and signals to create AI models that can recognize, summarize, and generate medical and clinical content. 

Over the past few years, with advances in the development of LLMs~\cite{devlin2018bert, brown2020language, chowdhery2022palm}, and the abundance of EHRs as well as public medical text outlets such as PubMed\footnote{\url{https://pubmed.ncbi.nlm.nih.gov/}}, research has been carried out to design and propose BioLLMs. Since the introduction of BioBERT~\cite{lee2020biobert}, a seminal BioLLM which outperformed previous state-of-the-art on various biomedical text mining tasks such as biomedical named entity recognition, many different BioLLMs that stem from their general LLM counterparts have been proposed, including ClinicalBERT~\cite{alsentzer2019publicly}, BioMegatron~\cite{shin2020biomegatron}, BioMedRoBERTa~\cite{gururangan2020don}, Med-BERT~\cite{rasmy2021med}, BioELECTRA~\cite{raj2021bioelectra}, PubMedBERT~\cite{gu2021domain}, BioLinkBERT~\cite{yasunaga2022linkbert}, BioGPT~\cite{luo2022biogpt}, and Med-PaLM~\cite{singhal2022large}. 

The recent GatorTron~\cite{yang2022large} model (8.9 billion parameters) pre-trained with de-identified clinical text (82 billion words) revealed that scaling up the size of clinical LLMs leads to improvements on different medical language tasks, and the improvements are more substantial for complex ones, such as medical question answering and inference. Previously, the PubMedBERT work~\cite{gu2021domain} also revealed that instead of conducting continual pretraining from the checkpoint of an LLM pre-trained on the general-domain corpora, it is more favorable to conduct domain-specific pretraining from scratch (i.e., pretraining LLMs with biomedical corpora from scratch), which leads to remarkable improvements on medical language tasks. As LLMs start to show emergent abilities~\cite{wei2022emergent} with their size scaled up increasingly, Agrawal et al.~\cite{agrawal2022large} revealed that recent LLMs such as InstructGPT~\cite{ouyang2022training} and GPT-3~\cite{brown2020language} can well extract clinical information in a few-shot setting despite being not explicitly trained for the clinical domain. Med-PaLM~\cite{singhal2022large}, a BioLLM with 540 billion parameters generated by applying instruction prompt tuning on Flan-PaLM~\cite{chung2022scaling} (which exhibited state-of-the-art accuracy on MultiMedQA~\cite{singhal2022large}), demonstrated the ability to answer consumer medical questions that are comparable to the performance of clinicians.  As prompt engineering has become a key technique for investigating and improving LLMs, Li{\'e}vin et al.~\cite{lievin2022can} have also applied various prompt engineering on recent GPT-3.5 series such as InstructGPT~\cite{ouyang2022training} to understand their abilities on medical question answering, and their results suggested that increasing Chain-of-Thoughts (CoTs)~\cite{wei2022chain} per question can deliver better and more interpretable medical question responses. 




The impressive performance of BioLLMs on medical language tasks shows their potential to be used to assist clinicians to process, interpret, and analyze clinical and medical data more efficiently, and also to vastly reduce the time that clinicians have to spend on documenting EHRs. BioLLMs can also assist the writing of prior authorizations for insurance purposes, accelerating treatment authorizations~\cite{priorauth2023}. On the patient side, the zero-, one-, and few-shot learning capability of LLMs may enable them to provide personalized medical assistance based on the medical history of each individual patient. In addition, LLMs may also find them applicable in clinical trial matching. Based on candidates' demographics and medical history, a BioLLM may effectively generate eligible matching, which accelerates clinical trial recruitment and initiation. Patel and Lam~\cite{patel2023chatgpt} recently shed insight on the use of ChatGPT~\cite{chatgpt2022} to generate discharge summaries, which could potentially relieve doctors from laborious writing and improve their clinical productivity. 



% \textcolor{red}{Multi-modal Masked Autoencoders for Medical Vision-and-Language
% Pre-training}


% \subsubsection{E-Health}

% \begin{enumerate}
%     % \item ChatGPT Is Shaping the Future of Medical Writing but Still Requires Human Judgment~\cite{kitamura2023chatgpt}
%     % \item Large Language Models are Few-Shot Clinical Information Extractors~\cite{agrawal2022large}
    
% \end{enumerate}








% \subsubsection{Clinical Trial Matching}

% \begin{enumerate}
%     \item CTMatch \url{https://www.quantumleaphealth.org/portfolio/ctmatch}
%     \item A short explanation of how clinical trial matching software works \url{https://www.antidote.me/blog/how-clinical-trial-matching-software-can-amp-up-your-recruitment}
% \end{enumerate}



% \subsubsection{Clinical Workflow Optimization}




% \textcolor{blue}{reducing routine workload of clinicians on paperwork~\cite{korngiebel2021considering}. This can be referred to processing EHR}















\subsection{Medical Education}



It is likely that future medical education will also be influenced by LAMs, as research continues to strengthen their scientific grounding, sound reasoning, and creative generation.


The generative capability of ChatGPT may augment medical student learning and help them gain additional insights from AI-generated content as recently pointed out in~\cite{kung2023performance}. A LAM with wide knowledge and social compliance can act as a companion learning assistant, answering medical questions promptly and explaining intricate terms and practices in simple sentences. For example, the recent GPT-4 model~\cite{gpt4openai2023} can act as a Socratic tutor, leading a student step-by-step to find the answers by themselves, which is an important step towards practical adoption of LAMs in education as they can be steered to teach/assist students in a desired manner. The OPTICAL model proposed by Shue et al.~\cite{shue2023empowering} recently shows the feasibility of using LLMs to guide beginners to analyze bioinformatics data. The sentence paraphrasing abilities of LLMs such as ChatGPT may also help students with dyslexia~\cite{dai2023chataug} in their learning. However, concerns about the illegitimate uses of LAMs such as plagiarism are practical and should raise awareness. A pilot study conducted by Mitchell et al.~\cite{mitchell2023detectgpt} proposed a zero-shot detector named DetectGPT, which is able to distinguish human-written or LLM-generated text. This attempt may lead to more research into developing reliable tools for verifying the content source and potentially countering the side effects of LAMs in education. 

For medical education givers, LAMs can potentially create novel teaching and exam contents, and diversify the teaching formats and their presentation. Based on the history of medical study and outcomes, LAMs may also help design personalized and precise course materials for students in need. In addition, LAMs may also help deliver remote medical education, providing engaging learning experiences and opportunities for students living in resource-poor areas or from underprivileged families. In addition, LAMs can also serve as a grading and scoring system in medical education, e.g., grading the surgical skill of a surgeon operating a surgical robot. 



In medical and clinical training such as nurse training, one can imagine a domain-knowledgeable LAM can act as an assistant or a trainer to supervise the training. For certain frequent and tedious routine medical training courses, human trainers tend to become less productive as training keeps repeating, and the quality of training delivery also varies among different human trainers. With a wide knowledge spectrum and responsive interactions, training delivered by a LAM can potentially be more engaging, productive, and the standard of training can be maintained as equal and of high quality. 











\subsection{Public Health}



As the American epidemiologist Larry Brilliant said \textit{``outbreaks are inevitable, but pandemics are optional"}, with the world gradually returning to normal after the Covid-19 pandemic, if there is one thing that the world has to reflect on, it is how we become prepared to prevent the next pandemic.


Based on past public policy and interventions to contain the spread of infectious diseases and the specific current situation, LLMs may help epidemiologists and policymakers to draft targeted public policies and recommend effective interventions. LLMs and other LAMs are also likely to be used to monitor, track, forecast, and analyze the progress of new outbreaks. As discussed in Section~\ref{subsec:mole_bio_drug_disconvery}, as LAMs have been actively researched in molecular biology and for drug discovery, they can potentially be used for the design of vaccine and drugs to treat and save people from new outbreaks. Furthermore, another potential usage of LAMs, as pointed out in~\cite{korngiebel2021considering}, can be in precision triage and diagnosis, in which they could play a pivotal role as medical care workforce might be stretched when encountering a new outbreak. An important aspect of tackling an outbreak/epidemic is to handle misinformation. The study conducted by Chen et al.~\cite{chen2020tracking} revealed that from 21 January 2020 to 21 March 2020, Twitter produced over 72 million COVID-19-related tweets. If unverified media information proliferates at scale, it inevitably causes complications in tackling the outbreak. Although LAMs could be double-edged swords when it comes to misinformation, with gradually complete regulations and strengthened factual grounding of LAMs, they can be used to effectively identify misinformation and tackle public health infodemic. 



Beyond their promising usage in preventing pandemics, LAMs are also an effective tool for solving other public health challenges, for example, providing large-scale dietary monitoring and assessment~\cite{peng2022clustering,qiu2023egocentric} to tackle the growing \textit{double burden of malnutrition}~\cite{popkin2019dynamics} in many low- and middle-income countries, and demystifying and proposing new solutions for mental illnesses that are common in populations. Researchers have recently proposed ClimaX~\cite{nguyen2023climax}, a foundation model for forecasting weather and climate change. With its remarkable forecasting capability, LAMs such as ClimaX can advance our understanding of climate change and provide solutions to better address the global health issues posed by climate change.






% During Current Covid-19 pandemic era, artificial intelligence models can help people monitor the spread of the virus, track the source of infection as well as predict the risk of death of patients based on a database \cite{vaishya2020artificial}. In addition, it can assist in the development and decision-making of public health policies based on public health databases \cite{budd2020digital}. In the last two decades, many monitoring networks based on big data and natural language processing have been established, such as MedISys, SENTINEL, etc \cite{zeng2021artificial}.


% PAPERs:
% \begin{enumerate}
%     \item ChatGPT and the Rise of Large Language Models: The New AI-Driven Infodemic Threat in Public Health~\cite{de2023chatgpt}



%     \item DeepScaffold: A Comprehensive Tool for Scaffold-Based De Novo Drug Discovery Using Deep Learning.
%     \item Deep Morphology Learning Enhances Ex Vivo Drug Profiling-Based Precision Medicine.(Drug test)
%     \item NERDD: New E-Resource for Drug Discovery-Improved Method of Structure-Based Virtual Screening via Interaction-Energy-Based Learning \cite{yasuo2019improved}
% \end{enumerate}
















% \subsection{Lin's comment}
% \begin{itemize}
%     \item application and challenges in healthcare and medicine.\cite{bommasani_opportunities_2022} \textcolor{blue}{JQ: I have gone through this paper few days ago. Their chapters related to healthcare are not in depth, very general. This is our chance.}
% \end{itemize}




\subsection{Medical Robotics}


% The robotics community has actively researched the use of LAMs in various robotic tasks and settings. Some works apply Transformer architecture and associated advances in language modeling such as GPT~\cite{brown2020language} and BERT~\cite{devlin2018bert}  to reinforcement learning, as shown in Decision Transformer~\cite{chen2021decision,sun2021adversarial}. 
% Some recent research explores the application of large model representation capabilities to robotics. For example, MVP~\cite{Radosavovic2022} explores self-supervised visual pre-training on images from the Internet and egocentric videos for real-world robotic tasks. They trained a 307M parameter vision transformer on a massive collection of 4.5M images, and demonstrated evidently the benefits of scaling visual pre-training for robot learning. Similarly, R3M~\cite{nair2022r3m} shows visual representations pre-trained on diverse egocentric video data (Ego4D~\cite{grauman2022ego4d}) using video-language alignment can enable data-efficient learning of downstream robotic manipulation tasks. MimicPlay~\cite{wang2023mimicplay} demonstrates that human-play data can enable data-efficient learning of downstream visuomotor control and help in learning latent plans. (SL)$^3$~\cite{sharma2021skill} simultaneously finetunes two LLMs, a high-level planning network, and a low-level policy network for actions selection. Pre-trained language models can be further leveraged for more general decision-making problems~\cite{li2022pre,licomposing}.
% % Recently, ChatGPT for Robotics~\cite{vemprala2023chatgpt} develops PromptCraft, a platform that outlines a strategy to combine design principles for prompt engineering and the creation of a high-level function library, allowing ChatGPT to adapt to different robotics tasks, simulators, and form factors. 

% With scaled-up capability, many work has proposed to use only one single LAM to conduct a diverse range of robotic tasks, demonstrating impressive adaptability and generalization skills.
% Gato~\cite{reed2022generalist}, with 1.2 billion parameters and trained on 604 unique tasks, is a generalist agent that utilizes one single large neural model to conduct various downstream robotic tasks. Other studies, such as CLIPort~\cite{shridhar2022cliport} and PerAct~\cite{shridhar2022perceiver}, use multi-task Transformer to learn a single language-conditioned policy for various tasks.
% LLMs contain a wealth of semantic knowledge about the world~\cite{sun2022plate}, which in principle might be useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. PaLM-SayCan~\cite{saycan2022arxiv} % tackles
% and PaLM-E~\cite{driess2023palme} tackle
% language grounding in robotic affordances with Pathways Language Model (PaLM)~\cite{chowdhery2022palm}. Jiang et al.~\cite{jiang2022vima} proposed VIMA, also a generalist robot agent that leverages multimodal prompts to conduct diverse manipulation tasks. Robotics Transformer 1 (RT-1)~\cite{brohan2022rt} trains a multi-task transformer model on 130k tele-operation demonstrations over 13 robots and 744 tasks. \textbf{Microsoft has utilized ChatGPT to generate execution codes for robots based on natural language instructions, with an aim to transform robotic pipelines from the current \textit{engineer in the loop} to the potential \textit{user in the loop}, which can use high-level language commands to control and fulfill robotic tasks~\cite{vemprala2023chatgpt}.} \textbf{They also proposed AirSim-ChatGPT~\cite{vemprala2023chatgpt}, which combines AirSim~\cite{shah2018airsim} with ChatGPT to serve as a platform to investigate future research on drone navigation using ChatGPT.} Furthermore, Sun et al.~\cite{sun2023smart} recently proposed SMART, which pretrains a versatile, generalizable, and resilient model for a wide range of control tasks and shows that the efficacy of self-supervised pretraining seen in vision and language can be extended to control tasks. These studies highlight the potential of LAMs and large model representation capabilities to improve robot learning and performance in various tasks and settings. 






% \textcolor{red}{JQ: also surgical robots are just a type of medical robots. Medical robots also include rehabilitation robots, biorobots, \textbf{companion robots}, etc. We can possibly provide some examples other than surgical robots. ALSO, LAMs may provide or inspire future design of medical robots, e.g., using the generative capability of LAMs to simulate, and learn from the nature to inspire the future design of bionic robots. ALSO, LAMs can potentially be used to control and schedule a medical robot swarm, e.g., a team of disinfection robots to disinfect an virus outbreak area.}


From surgical robots that allow surgeons to perform precision minimally invasive surgery, to wearable robots that assist patients with health monitoring and rehabilitation, medical robotics has seen rapid growth and advances over the past few decades. Although the use of LAMs in medical robotics is nascent, it is foreseeable that they will have a significant impact on improving the vision, interaction, and autonomy of medical robotics at large. 


% The use of robots in surgery, rehabilitation and detection of disease has been prevalent for over twenty years, and they have been implemented in a variety of medical fields in recent years \cite{ozmen2021artificial}\cite{qassim2020review}\cite{ghosh2022biorobots}. Current commercial medical robots can provide a surgeon with high precision control, outstanding ergonomics as well as 3D vision \cite{kwartowitz2006toward} \cite{wee2020systematic}. The implementation of robotic technology to facilitate movement restoration by guiding the patient's limbs along a predetermined trajectory \cite{glowinski2019exoskeleton}. Over the past few years, large models have been rapidly developed, enabling healthcare to become more intelligent. 

% However, in terms of the application in medical robotics, only a paucity of research studies have used large models. The following are some of the reasons: 
% \begin{itemize}
% \item The majority of commercial medical robots do not provide the capability of recording kinematic data, such as the da Vinci surgical system, which must use a dVRK kit modified for scientific use only to achieve similar functionality \cite{kazanzides2014open}. Kinematic data mostly records the trajectory of the surgeon operating the robot in a non-surgical environment to perform some simple training tasks \cite{hwang2020superhuman}\cite{grannen2020untangling}\cite{nisky2015teleoperated}.
% \item There may be concerns about the ethical use of patient data \cite{chiruvella2021ethical}. It may cause serious ethical problems that sharing surgical data without patient's consent \cite{haynes2007legal}.
% \item The utilization of medical robots in healthcare institutions is limited due to their high cost and maintenance expenses. For instance, the average cost of rehabilitation robots is approximately 0.33M euros \cite{carpino2018assessing}, making them financially inaccessible to many healthcare institutions. As a result, the acquisition of significant amounts of surgical data is hindered by the limited availability of medical robots.\cite{amodeo2009robotic}.
% \end{itemize}

% The application of LAMs in medical robotics is still in infancy \cite{bhandari2020artificial}. However, in recent years, there has been a growing trend towards the sharing of surgical datasets \cite{quellec2014real}\cite{twinanda2016single}. The following three sectors in medical robotics have shown some potentials of using LAMs. 



% With the availability of large amount of data, these three sub-fields can benefit from the large amount of data and have the potential to produce a generalizable model for new tasks. 

\subsubsection{Enhance Vision}


The integration of LAMs into surgical robots has the potential to enhance both the 2D and 3D vision of these systems in surgery, e.g., improved segmentation of anatomical structures, and better 3D navigation to the targeted surgical site in neuro- and brain surgery\cite{secoli2022modular}. In addition to online vision enhancement, LAMs can also potentially improve the offline workflow analysis of robotic surgery, and more accurately and objectively predict the likelihood of complications or successful outcomes, which help surgeons better plan and execute surgeries in the future. Furthermore, with their strong generative capabilities, LAMs can be used to generate and simulate surgical procedures, allowing surgeons to practice and refine their techniques before operating on a patient with real surgical robots. Beyond surgical robots, the perception of many companion and assistive robots can also be enhanced by LAMs, e.g., enabling a companion robot to better understand the patient's emotion through accurate recognition of facial expressions~\cite{d2022emotion}, and enabling an assistive robot to offer safer and more natural blind navigation for visually impaired people~\cite{qiu2022egocentric}. 

% LAMs can also be used to predict surgical outcomes. By analyzing large datasets of surgical procedures, LAMs can identify patterns and predict the likelihood of complications or successful outcomes. This can help surgeons better plan and execute surgeries, leading to better patient outcomes ~\cite{hashimoto2018artificial, ren2022performance}. 
% Another application scenario is the identification of areas for optimization in the surgical workflow. LAMs can analyze the surgical workflow, identify bottlenecks, and suggest improvements to increase efficiency and reduce the likelihood of errors~\cite{garrow2021machine,linardatos2020explainable}. 

% They can significantly improve the vision of surgical robots in both 2D and 3D modes, providing precise and efficient surgical operations. 
% In 2D vision, LAMs can enhance the segmentation of anatomical structures in surgical images, enabling surgical robots to isolate and identify specific structures with high accuracy. This is useful in a variety of applications, such as neurosurgery, orthopedics, and urology. For instance, in urology, AI-assisted surgical robots can distinguish between cancerous and healthy tissues in real-time, facilitating precise and minimally invasive surgeries~\cite{rossin2023artificial}. LAMs can also potentially enable surgical robots to generate detailed 3D models of the patient's anatomy in real-time, which can be used for preoperative planning and intraoperative guidance. 3D vision technology has been particularly beneficial in complex procedures such as spine surgeries and cardiac surgeries, where it helps to identify the critical structures and avoid damage to surrounding tissues. In cardiac surgery, AI-powered surgical robots can generate real-time 3D images of the heart, providing surgeons with detailed information on the anatomy and facilitating precise surgical procedures~\cite{qian2019review,dewitz2022real}

% In addition to the above applications, AI-powered surgical robots have shown remarkable progress in other specialties as well. For example, LAMs can analyze real-time images captured by high-resolution cameras installed on the surgical robot. This analysis helps the surgical robot to accurately identify and navigate around obstacles in the surgical site, providing a safe and effective path for the surgeon to perform the operation. One application of this technology is in brain surgery, where the surgical robot can accurately navigate through the delicate structures of the brain to reach the desired target area \cite{secoli2022modular}. Another application is in laparoscopic surgery, where the surgical robot can provide a clear view of the surgical site, reducing the risk of accidental damage to surrounding organs \cite{daneshgar2021visual}. Furthermore, real-time gesture analysis can provide immediate feedback to the surgeon during the procedure~\cite{wang2018deep,kasa2022multi},\cite{8512575} enabling them to make adjustments and corrections as needed. These advancements have the potential to improve surgical outcomes and patient safety, highlighting the significant contributions that LAMs can make for enhancing medical robotic vision.

% One key application of large AI models is in the field of 3D reconstruction, where the models can provide detailed and accurate representations of the patient's anatomy~\cite{penza2016dense,wang2022neural}, enabling surgeons to visualize the surgical site and identify critical structures with greater precision. In addition, AI-based surgical path planning algorithms can leverage these 3D models to optimize the surgical path and minimize risk to the patient~\cite{8441801,bucker2022reshaping,bonatti2022pact}.   


% \textcolor{red}{Offline}
% surgern's robotic surgery skill analysis
% Robotic surgery has gained popularity due to its precision, minimally invasive nature, and faster recovery time compared to traditional open surgery. One critical aspect of robotic surgery is the ability to analyze the offline workflow and optimize it for better performance. 

% Apart from online vision enhancement, LAMs can also potentially improve the offline workflow analysis of robotic surgery. LAMs can also be used to predict surgical outcomes. By analyzing large datasets of surgical procedures, LAMs can identify patterns and predict the likelihood of complications or successful outcomes. This can help surgeons better plan and execute surgeries, leading to better patient outcomes ~\cite{hashimoto2018artificial, ren2022performance}. Another application scenario is the identification of areas for optimization in the surgical workflow. LAMs can analyze the surgical workflow, identify bottlenecks, and suggest improvements to increase efficiency and reduce the likelihood of errors~\cite{garrow2021machine,linardatos2020explainable}. In addition to surgical outcome prediction and workflow optimization, with their strong generative capabilities, LAMs can be used to generate and simulate surgical procedures, allowing surgeons to practice and refine their techniques before operating on a patient~\cite{pakkasjarvi2023artificial}. 

% Finally, LAMs can also be used to analyze the data from the robotic surgery system, including the position and movement of the instruments and the physiological data of the patient. This data can be used to generate insights that aid in diagnosis, treatment planning, and postoperative care ~\cite{randell2015impact,zhang2020symmetric,khanagar2022performance}.

% Beyond surgical robots, the perception of many companion and assistive robots can also be enhanced by LAMs, e.g., enabling a companion robot to better understand the patient's emotion through accurate recognition of facial expressions~\cite{d2022emotion}, and enabling a assistive robot to offer safer and more natural blind navigation for visually impaired people by better understanding the surroundings and human social conventions~\cite{qiu2022egocentric}.

\subsubsection{Improve Interaction}
LAMs may significantly improve the interactive capabilities of many rehabilitation and companion robots, by enabling them to recognize human emotions, gestures~\cite{sun2022locate}, and speech, and respond to high-level human language commands. This will be easier for patients undergoing rehabilitation to communicate and engage with their robotic assistants, improving their overall recovery experience. More intelligent LAMs may also better understand human intentions and create more human-like companionship, which could improve the overall quality of care for the elderly~\cite{asgharian2022review}.
% Similarly, companion robots equipped with LAMs can interact with humans in a more natural way, improving their social and emotional well-being. 
% For example, in the rehabilitation of stroke patients, a LAM-empowered robot can use sensors to monitor the patient's movement and adjust the difficulty level of the exercises accordingly~\cite{bonkhoff2022precision,yan2019detection}. Furthermore, LAMs can analyze the patient's emotional state and provide feedback that encourages and motivates them to continue with their exercises ~\cite{abdulghafor2022analysis,gual2022using}. 
% Another scenario is in the care of elderly people. Companion robots empowered by LAMs can recognize and respond to high-level language commands~\cite{vemprala2023chatgpt} and engage in conversational interactions~\cite{Zhou2021}. 
% Additionally, these robots can monitor the user's health and provide reminders for medications and appointments. This creates a sense of companionship for the elderly and reduces their feelings of loneliness, thus improving the overall quality of care~\cite{asgharian2022review}.

% With LAMs, rehabilitation robots can better understand and interact with patients, leading to improved outcomes. Meanwhile, large AI models also increase the autonomy of medical robots, allowing for more efficient and accurate medical procedures. Ultimately, the use of large AI models in both rehabilitation and medical robots has the potential to greatly benefit patients and improve the overall quality of care.


\subsubsection{Increase Autonomy}
In general robotic domains, Transformer architecture and associated advances in LAMs such as GPT~\cite{brown2020language} and BERT~\cite{devlin2018bert} have been applied to increase robotic autonomy~\cite{chen2021decision}. Some recent research explores the application of LAM representation capabilities to robotics. For example, R3M~\cite{nair2022r3m} shows that visual representations derived from a large set of pretraining egocentric video data (Ego4D~\cite{grauman2022ego4d}) through video-language alignment can facilitate the learning of skills for robotic manipulation tasks. MimicPlay~\cite{wang2023mimicplay} demonstrates that human-play data can enable data-efficient learning and help in learning latent plans. LLMs contain a wealth of semantic knowledge about the world~\cite{sun2022plate}, which in principle might be useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. ChatGPT recently has been used to generate execution codes for robots based on natural language instructions, with an aim to transform robotic pipelines from the current \textit{engineer in the loop} to the potential \textit{user in the loop}, which can use high-level language commands to control and carry out robotic tasks~\cite{vemprala2023chatgpt}. With scaled-up capability, much work has proposed to use only one single LAM to conduct a diverse range of robotic tasks, demonstrating impressive adaptability and generalization skills~\cite{reed2022a,shridhar2022cliport,shridhar2022perceiver,saycan2022arxiv,driess2023palme,jiang2022vima,brohan2022rt}. The progress made by these LAMs in general-purpose robotics may inspire the development of medical robotics towards higher autonomy.

Surgical robots with high levels of autonomy are capable to perform surgical tasks with little or even without human supervision, reducing the cognitive load of a surgeon during the operation~\cite{yang2017medical}. To attain a high level of autonomy, a surgical robot must exhibit the ability to proficiently execute various surgical procedures while adapting to different operating environments~\cite{yip2019robot}. Currently, there is an evident trend in medical research to pursue the augmentation of surgical robot autonomy with AI models~\cite{9341382,8794159},\cite{saeidi2022autonomous}. 

However, most of the current research on surgical robot autonomy remains in level two, which only focuses on specific tasks instead of the whole procedure ~\cite{dupont2021decade, 10065461}.
% , and none of the existing medical robots intended for commercial use can execute surgical procedures without human intervention~\cite{attanasio2021autonomy}. 
The current trend in surgical robotics is to provide surgical strategies with preoperative data and adjust instrument movements based on real-time sensor feedback~\cite{dupont2021decade}. 
% Some studies have utilized pretrained models to facilitate the motion planning of robots and their perception of the environment~\cite{bucker2022reshaping,sun2022nerf,bonatti2022pact}, which can potentially be further improved with LAMs. 
% Reinforcement Learning (RL) has also attracted significant attention in the realm of medical robotic autonomy, such as controlling laparoscope to obtain optimal camera views~\cite{li20223d}, and precisely cutting soft tissues~\cite{8836924}. 
LAMs may help robots consistently maintain their performance while facing environmental changes or unexpected events with their strong adaptability and generalization capabilities. For example, in some abdominal surgeries, a LAM-based system can potentially better detect human respiratory motion, and adjust the instrument trajectory to avoid collision with organs, thereby minimizing the potential harm to patients. Additionally, this system may be utilized to transfer surgical proficiency across various surgical procedures, such as appendectomy and cholecystectomy, among others, with the ultimate objective of improving the overall surgical outcomes. 
% The integration of LAMs can aid in the execution of intricate surgical procedures that demand meticulous management of instrument orientation and manipulation, such as tumor ablation, incision suturing, and other related tasks. 

% In summary, the integration of large AI models into medical robots has the potential to revolutionize healthcare and improve patient outcomes by increasing the autonomy and efficiency of these devices.



% \textbf{Additionally, LAMs can expedite the analysis of robotic surgery data and facilitate the generation of large datasets. The analysis of surgical skills using these datasets can provide valuable insights into a surgeon's aptitude, enabling real-time adaptation of intraoperative methodologies and maneuvers. (repetitive)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% One of the first fields that may benefit from the development of LAMs is robotic surgery workflow analysis, which also is an important part for medical robots to achieve high level intelligence and autonomy \cite{nagy2019dvrk} \cite{maier2017surgical}. By feeding massive surgical data, the robot is able to identify the surgery phrase in real time, monitor the surgical process and adjust staff scheduling during the whole operation \cite{7519080}. Furthermore, after the operation, it can help release the burden of manually labeling surgery videos \cite{zhao2020learning}, which helps enlarge the data base \cite{9336292}.

% Skill analysis in robotic surgery also has high demand on surgical data, especially on surgical videos \cite{kutana2022objective}. Currently, most of surgeons still follow relatively rigid metrics to assess the performance and they usually not sufficient in providing a comprehensive evaluation of the performance of a surgeon in the operating room \cite{lam2022machine}. LAMs can learn from a large number of robotic surgery review cases, rapid identification of segmented surgical stages and evaluation and feedback \cite{garrow2021machine}. 

% Robots with high level antonomy are capable to perform surgical task with weak human supervision or without supervision,  reducing the workload of a surgeon during the operation \cite{yang2017medical}. Additionally, assistive robots, such as robotic wheelchairs, are capable of traversing doorways and docking automatically for patients with cognitive impairments \cite{simpson2005smart}. In order for medical robots to operate autonomously, it is imperative that they acquire knowledge from human sources. This necessitates the accumulation of substantial amounts of data obtained from patients or surgical procedures \cite{si2021review} \cite{hussein2017imitation}. LAMs has the potential to facilitate the generalization of surgical skills and strategies derived from human performance, such as executing suturing and knot tying procedures that necessitate repetitive motion from the surgeon. Moreover, owing to the remarkable generalization prowess exhibited by LAMs, assistant robot can effectively conform to diverse patient profiles, thereby minimizing training expenses. 

% \subsubsection{Robotic Workflow Analysis}
% JIGSAWS is one of the most commonly used public surgical robot datasets for robotic surgery workflow analysis, which contains 95 surgical task demonstration videos performed on da Vinci surgical system \cite{gao2014jhu}\cite{ahmidi2017dataset}. Despite its relatively small size, the dataset made a significant contribution to the promotion of robotic surgical procedures recognition and shows the potential of applying LAMs in robotic surgery workflow analysis. In terms of the temporal modelling, a self-temporal attention mechanism has been developed and validated on the JIGSAWS \cite{zhang2020symmetric}. For gesture and movement recognition, a novel CNN-biLSTM-CRF architecture has been developed and has good performance on JIGSAWS dataset \cite{yu2018learning}. An unsupervised deep learning network has been developed and achieved 68\% accuracy on needle passing on the JIGSAWS dataset \cite{8476566}. Increasingly diverse data types and their abundance have made it possible to analyse robotic surgery workflows using multi-modal data integration. Combining kinematics and vision for complementary information allows for more efficient recognition and segmentation \cite{van2022gesture}. A surgical procedure recognition model has been proposed that achieves about 90\% accuracy on JIGSAWS by parameters such as kinematics, vision and system events during surgery \cite{qin2020temporal}. An unsupervised deep learning network was used for robotic surgical trajectory segmentation, significantly reducing time costs on JIGSAWS \cite{krishnan2017transition}. 

% Some other surgical robot datasets for gesture and phrase recognition have also been proposed in recent year. A set of robotic surgery videos that contain various instruments was provided in a Sub-Challenge of MICCAI 2017 \cite{allan20192017}. A dataset for transfering surgical skills between different medical robots has been published in 2019 \cite{8967760}. A labeled 3D pose estimation of instruments in robotic surgery has been published in 2021 \cite{HASAN2021101994}. Advancements in the acquisition of datasets within the field of robotic surgery have opened up new prospects for the utilization of LAMs in the analysis of robotic surgery workflows. As a consequence, LAMs are likely to exhibit increasing potential for contributing to various sub-disciplines within the realm of medical robotics.


% \subsubsection{Skill Analysis in Robotic Surgery}
% The current availability of datasets for the purpose of skill analysis in robotic surgery remains limited, most researchers rely heavily on their own proprietary data sources. By collecting motion data from fourteen subjects, a sparse coding framework has been developed for evaluating the movement style of users \cite{ershad2019automatic}. After being trained on twenty-three videos of robotic urethrovesical anastomosis, a multi-task convolutional neural network has been proposed to predict proficiency of surgeon by GEARS scoring \cite{gahan2020mp34}. A transfer learning scheme was used to assess the performance on microsurgery based on 24 robot-assisted microsurgery trails completed by eight subjects. None of those data is open sourced and does not provide a positive linkage and facilitation between different studies. 

% Notwithstanding, there are certain investigations that continue to depend on open-source datasets. An end-to-end framework for motion analysis has been proposed for surgeon skill and movement assessment, and validated on the public dataset JIGSAWS \cite{8512575}. with data augmentation on the JIGSAWS dataset, a deep learning network based on multivariate time series has achieved more than 90\% accuracy on standard robotic surgical training tasks \cite{wang2018deep}. Through the assessment of eight distinct global movement features derived from the movement trajectories recorded in JIGSAWS, an automated objective skill assessment method has demonstrated its ability to distinguish the performance levels of surgeons \cite{fard2018automated}. Over the course of the previous decade, there has been a significant upsurge in the utilization of neural networks for the analysis of robotic surgical skills \cite{kasa2022multi}. Now, with the trend of open-source robotic surgery data, LAMs will gradually show its potential in the robotic surgery skill analysis. For instance,  during a robot-assisted minimally invasive surgery, system can monitor surgeon's action and give some warnings when action may causing excessive bleeding or push too much pressure on the organs. Also, system can given an optimal angle for needle incision for better stitching outcome. For instance, during a robot-assisted minimally invasive surgical procedure, an LAM based system can effectively monitor the actions of the surgeon and provide real-time feedback. Specifically, the system can provide warnings to the surgeon when their actions may result in excessive bleeding or cause undue pressure on the patient's organs. Furthermore, the AI system can offer guidance to the surgeon by suggesting an optimal angle for the needle incision to achieve a more favorable stitching outcome.

% providing optimal trajectories of instruments in a dynamic vivo environment.
% offering the capability of providing real-time feedback to surgeons during operations and predicting surgical outcomes.

% \subsubsection{Robotics Autonomy}
% To attain a high level of autonomy, a medical robot must exhibit the ability to proficiently execute various surgical procedures while adapting to differing operating environments \cite{yip2019robot}. Currently, there is a prevalent inclination within medical research to pursue the augmentation of surgical robot autonomy with AI models \cite{9341382}\cite{8794159} \cite{saeidi2022autonomous}, while there is a dearth of research on rehabilitation robot autonomy.

% % In order to perceive the environment and deduce a surgical task execution plan, a framework has been used to complete standard peg and ring task \cite{9341382}. A prediction model based on learning from demonstration has been proposed for manipulating soft tissue autonomously \cite{8794159}. An autonomous strategy for intestinal anastomosis has been proposed and validated on both phantom and in vivo intestinal tissues \cite{saeidi2022autonomous}.

% However, most of current research on surgical robot autonomous is still under Level of Autonomy(LoA) three and none of the existing medical robots intended for commercial use can execute surgical procedures without human intervention \cite{han2022systematic}\cite{attanasio2021autonomy}. The advancement of autonomous medical robots to the subsequent stage necessitates the incorporation of a capacity to generate and modify plans and movements in response to real-time sensor data \cite{dupont2021decade}. Some studies have utilized pre-trained models to facilitate the motion planning of robots and their perception of the environment \cite{bucker2022reshaping} \cite{bonatti2022pact}. Reinforcement Learning (RL) has also garnered significant attention in the realm of robotic autonomy, owing to its successful application in various domains such as laparoscope control to obtain optimal camera views \cite{li20223d}, and soft tissue cutting \cite{8836924}. The application of LAMs may help robots maintain their performance in the face of environmental changes or unexpected events, adapt to new environment and learn from experience. For instance, in some abdominal surgeries, LAM base system is capable of executing human respiratory motion compensation to minimise the harm to patients. Additionally, this system may be utilized to transfer surgical proficiencies across various surgical procedures, such as appendectomy and cholecystectomy, among others, with the ultimate objective of improving the overall surgical outcome. The integration of reinforcement learning can aid in the execution of intricate surgical procedures that demand meticulous management of instrument orientation and manipulation, such as tumor ablation, incision suturing, and other related tasks. Additionally, LAMs can expedite the analysis of robotic surgery data and facilitate the generation of large datasets. The analysis of surgical skills using these datasets can provide valuable insights into a surgeon's aptitude, enabling real-time adaptation of intraoperative methodologies and maneuvers.

% In terms of rehabilitation robot, current research are mainly focus on the mobile robot (Robotics wheelchair, Mobile gait training Robot etc.). For those people with severe motor impairment, consistent and accurate input is difficult for them \cite{argall2018autonomy}. One current approach entails relinquishing the control of the wheelchair's direction and path to a robotic system, with the patient only responsible for adjusting the linear velocity \cite{6610332}. The orthopedic rehabilitation robot can autonomously track and monitor the post-operative walking posture of implanted patients and provide real-time corrective feedback \cite{9223482}. LAM-based rehabilitation robots can provide personalized treatment plans and real-time feedback, making the rehabilitation process more effective and efficient. With the ability to collect and analyze large amounts of data, rehabilitation robots can identify trends and improve the overall rehabilitation process, making it more accessible for patients.

% \subsubsection{Discussion}
% Beyond the sub-fields discussed earlier, LAMs may contribute to the advancement of medical robotics by aiding not only in the completion of medical tasks but also in the development of next-generation medical robots. With LAMs, robots are capable of comprehending and executing instructions provided by human operators, enabling them to collaborate effectively. For instance, in the context of surgical procedures, a robot empowered by a LAM can identify infected tissue through the description provided by the surgeon or switch instruments according to their instructions. LAMs also have the potential to enhance collaboration between robots, for example, upper and lower extremity rehabilitation robots that can work in tandem to support patients with complex movements, such as lifting and balance training. LAMs may also be applied to schedule medical robot swarms, e.g., for fast disinfecting an outbreak.


% Video recordings of robotic surgical procedures can provide a detailed and comprehensive view for offline analysis. This is particularly important for LAMs, which require large amounts of data to analysis the surgical workflow. JIGSAWS is one of the most commonly used public surgical robot datasets for robotic surgery workflow analysis, which contains 95 surgical task demonstration videos performed on da Vinci surgical system~\cite{gao2014jhu,ahmidi2017dataset}. Despite its relatively small size, the dataset made a significant contribution to the promotion of robotic surgical procedures recognition and shows the potential of applying LAMs in robotic surgery workflow analysis. New models have been developed for temporal modelling and gesture recognition on the JIGSAWS dataset, while an unsupervised deep learning network achieved good accuracy on needle passing~\cite{zhang2020symmetric,yu2018learning}. A surgical procedure recognition model achieves high accuracy on JIGSAWS, and an unsupervised deep learning network significantly reduces time costs for robotic surgical trajectory segmentation~\cite{qin2020temporal,krishnan2017transition}.

% Some other surgical robot datasets for gesture and phrase recognition have also been proposed in recent year. A set of robotic surgery videos that contain various instruments was provided in a Sub-Challenge of MICCAI 2017 \cite{allan20192017}. A dataset for transferring surgical skills between different medical robots has been published in 2019 \cite{8967760}. A labeled 3D pose estimation of instruments in robotic surgery has been published in 2021 \cite{HASAN2021101994}. Advancements in the acquisition of datasets within the field of robotic surgery have opened up new prospects for the utilization of LAMs in the analysis of robotic surgery workflows. As a consequence, In the field of medical robotics, LAM may z in the offline analysis of surgical dl processes show increasing potential to contribute to various sub-disciplines.






