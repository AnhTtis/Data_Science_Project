\section{Introduction}\label{sec:introduction}




\begin{figure}[!t]
\centerline{\includegraphics[width=\linewidth]{figures/chatgpt_sam_publications.eps}}
\caption{Number of publications related to ChatGPT and SAM in medical and health areas. Statistics were queried from Google Scholar with the keywords ``Medical ChatGPT" or ``Medical Segment Anything", and the last entry was 31-th Aug. 2023. From April to August, each month, there were over 200 publications about ChatGPT in medicine and healthcare.}
\label{fig:chatgpt_sam_publications}
\vspace{-0.5cm}
\end{figure}








\begin{figure*}[!t]
\centerline{\includegraphics[width=\textwidth]{figures/LAM_key_feature_summary.eps}}
\caption{The key features of large AI models lie in the following four aspects: 1) increased size (e.g., for large language models (LLMs), the number of parameters is often billions); 2) trained with large-scale data (e.g., for LLMs, the data can contain trillions of tokens; and for large vision models (LVMs), the data can contain billions of images); 3) able to process data of multiple modalities; and 4) can perform well across multiple downstream tasks, especially on zero-, one-, and few-shot tasks.}
\label{fig:LAM_key_feature_summary}
\vspace{-0.5cm}
\end{figure*}








\IEEEPARstart{T}{he} introduction of ChatGPT~\cite{chatgpt2022} has triggered a new wave of development and deployment of Large AI Models (LAMs) recently. As shown in Fig.~\ref{fig:chatgpt_sam_publications}, ChatGPT and the phenomenal Segment Anything Model (SAM)~\cite{kirillov2023segment} have sparked active research in medical and health sectors since their initial launch. Although groundbreaking, the AI community has in fact started creating LAMs much earlier, and it was the seminal work introducing the Transformer model~\cite{vaswani2017attention} back in 2017 that accelerated the creation of LAMs.

The recent advances in data science and AI algorithms have endowed LAMs with strengthened \textit{generative} and \textit{reasoning} capabilities, as well as \textit{generalist intelligence} across multiple tasks with impressive zero- and few-shot performance, significantly distinguishing them from early deep models. For example, when asked for medical advice, ChatGPT, based on GPT-4~\cite{gpt4openai2023}, demonstrates the capability of recalling prior conversation and being able to contextualize the user's past medical history before answering, showing a new level of intelligence way beyond that of a simple symptom checker~\cite{lee2023ai}. 




 




One notable bottleneck of developing supervised medical and clinical AI models is that they require annotated data at scale for training a well-functioning model. However, such annotations have to be conducted by domain experts, which is often expensive and time-consuming. This causes the curation of large-scale medical and clinical data with high-quality annotations to be challenging. However, this may no longer be a bottleneck for LAMs, as they can leverage self-supervision and reinforcement learning in training, relieving the annotation burden and workload of curating large-scale annotated datasets~\cite{gulshan2016development}. With the ever-increasing proliferation of medical Internet of things such as pervasive wearable sensors, medical and clinical history such as electronic health records (EHRs), prevalent medical imaging for diagnosis such as computed-tomography (CT) scans, the growing genomic sequence discovery, and more, the abundance of biomedical, clinical, and health data fosters the development of the next generation of AI models in the field, which are expected to have a large capacity for modeling the complexity and magnitude of health-related data, and generalize to multiple unseen scenarios to actively assist and engage in clinical and medical decision-making.    


Despite the homogeneity of the model architecture (current LAMs are primarily based on Transformer~\cite{vaswani2017attention}), LAMs inherently are strong learners of heterogeneous data due to their large capacity, unified input modeling of different modalities, and improved multi-modal learning techniques. Multi-modality is common in biomedical and health settings, and the multi-modal nature of health data provides the natural and promising ground for developing and evaluating LAMs.


The LAMs that this article discusses are mainly foundation models~\cite{bommasani_opportunities_2022}. However, this article also provides a retrospective of the recent LAMs that are not necessarily considered foundational at their current stage, but are seminal in advancing the future development of LAMs in the fields of biomedicine and health informatics. Fig.~\ref{fig:LAM_key_feature_summary} summarizes the key features of LAMs, and highlights the paradigm shift it is introducing, i.e., 1) large-scale model size; 2) large-scale training/pre-training; and 3) large generalization.
 

Albeit inspirational, LAMs still face challenges and limitations, and the rapid rise of LAMs brings new opportunities as well as potential pitfalls. This article aims to provide a comprehensive review of the recent developments of LAMs, with a particular focus on their impacts on the biomedical and health informatics communities. The remainder of this article is organized as follows: Section~\ref{sec:background_large_ai_model} describes the background of LAMs in general domains, such as natural language processing (NLP) and computer vision (CV); Section~\ref{sec:applications} discusses current progress and possible applications of LAMs in key sectors of health informatics; Section~\ref{sec:challenges} discusses challenges, limitations and risks of LAMs; Section~\ref{sec:future} points out some potential future directions of advancing LAMs in health informatics, and Section~\ref{sec:conclusions} concludes.  

As this field progresses very rapidly, and also due to the page limit, there are a lot of works that this paper cannot cover. It is our hope that the community can be updated with the latest advances, so we refer readers to our website \footnote{https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models} for the latest progress about LAMs.











