\section{Applications of Large AI Models in Health Informatics}\label{sec:applications}





In this section, we identify seven key sectors in which LAMs will have substantial influence and bring a new paradigm for tackling the problems and challenges in health informatics. The seven key sectors include 1) bioinformatics; 2) medical diagnosis; 3) medical imaging; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. Table~\ref{tab:LAM_sota} compares current LAMs with previous SOTA methods in these seven sectors.































\begin{figure*}[!t]
\centering
\captionof{table}{Comparison between state-of-the-art LAMs (second row) and prior arts (first row) in typical tasks of seven biomedical and health sectors. ``$-$'' denotes not applicable. ``N/R" denotes not released in the original literature. For zero-shot medical segmentation task, we tested the off-the-shelf Mask RCNN model to compare with SAM.}
\centerline{\includegraphics[width=\textwidth]{figures/LAM_sota.eps}}
\label{tab:LAM_sota}
\vspace{-0.5cm}
\end{figure*}











\subsection{Bioinformatics}\label{subsec:mole_bio_drug_disconvery}


Molecular biology studies the roles of biological macromolecules (e.g., DNA, RNA, protein) in life processes and describes various life activities and phenomena including the structure, function, and synthesis of molecules. Although many experimental attempts have been made on this topic over decades~\cite{bai2015cryo,wuthrich2001way,grimes2018crystallography}, they are still of high cost, long experiment cycle, and high production difficulty. For example, the number of experimentally determined protein structures stored in the protein data bank (PDB) hardly rivals the number of protein sequences that have been generated. Efficient and accurate computational methods are therefore needed and can be used to accelerate the protein structure determination process. Due to the huge number of parameters and learning capacity, LAMs endow us with prospects to approach such a Herculean task. Especially, LLMs' outstanding representation learning ability has been employed to implicitly model the biological properties hidden in large-scale unlabeled data including RNA and protein sequences. 




When it comes to the field of protein, starting from amino acid sequences, we can analyze the spatial structure of proteins and furthermore understand their functions, and mutual interactions. AlphaFold2~\cite{jumper2021highly} pioneered leveraging the attention-based Transformer model~\cite{vaswani2017attention} to predict protein structures. Specifically, they treated structure prediction as a 3D graph inference problem, where the network's inputs are pairwise features between residues, available templates, and multi-sequence alignment (MSA) embeddings. Especially, embeddings extracted from MSA can infer the evolutionary information between aligned sequences. Evoformer and structure modules were proposed to update the input representation and predict the final 3D structure, the whole process of which was recycled several times. Meanwhile, despite being trained on single-protein chains, AlphaFold2 exhibits the ability to predict multimers. To further enable multimeric inputs for training, DeepMind proposed AlphaFold-Multimer\cite{evans2021protein}, achieving impressive performance, especially in heteromeric protein complexes structure prediction.  Specifically, positional encoding was improved to encode chains, and multi-chain MSAs were paired based on species annotations and target sequence similarity.



In spite of the groundbreaking endeavors aforementioned works have contributed, to achieving optimal prediction, they still heavily rely on MSAs and templates searched from genetic and structure databases, which is time-consuming. Analogous to mining semantic information in natural language, researchers managed to explore co-evolution information in protein sequences in a self-supervised manner by employing large-scale protein language models (PLMs), which learn the global relation and long-range dependencies of unaligned and unlabelled protein sequences. ProGen (1.2B)\cite{madani2020progen} utilized a conditional language model to provide controllable generation of protein sequences. By inputting desired tags (e.g., function, organism), ProGen can generate corresponding proteins such as enzymes with good functional activity. Elnaggar et al.\cite{article} devised ProtT5-XXL (11B) which was first trained on BFD\cite{steinegger2018clustering} and then fine-tuned on UniRef50\cite{suzek2015uniref} to predict the secondary structure. ESMfold\cite{lin2023evolutionary} scaled the number of model parameters up to 15B and observed a significant prediction improvement over AlphaFold2 (0.68 vs 0.38 for TM-score on CASP14) with considerably faster inference speed when MSAs and templates are unavailable. Similarly, from only the primary sequence input, OmegaFold\cite{wu2022high} can outperform MSA-based methods~\cite{jumper2021highly,baek2021accurate}, especially when predicting orphan proteins that are characterized by the paucity of homologous structure. xTrimoPGLM\cite{Chen2023.07.05.547496} proposed a unified pre-training strategy that integrates the protein understanding and generation by optimizing masked language modelling and general language modelling concurrently and achieved remarkable performance over 13 diverse protein tasks with its 100B parameters. For instance, for GB1 fitness prediction in protein function task, xTrimoPGLM outperforms the previous SOTA method: Ankh\cite{elnaggar2023ankh}, with an 11\% performance increase. Moreover, for antibody structure prediction, xTrimoPGLM outperformed AlphaFold2 (TM-score: 0.951) and achieved SOTA performance (TM-score: 0.961) with significantly faster inference speed. We underscore that in the presence of MSA, although the performance of PLMs is hardly on par with Alphfold2, PLMs can make predictions several orders of magnitude faster, which speeds up the process of related applications such as drug discovery. In addition, because PLMs implicitly understand the deep information implied in protein sequences, they are promising to predict mutations in protein structures and their potential impact to help guide the design of next-generation vaccines.



In the context of RNA structure prediction, the number of nonredundant 3D RNA structures stored in PDB is significantly less than that of protein structures, which hinders the accurate and generalizable prediction of RNA structure from sequence information using deep learning. To mitigate the severe unavailability of labeled RNA data, Chen et al.\cite{chen2022interpretable} proposed the RNA foundation model (RNA-FM), which learns evolutionary information implicitly from 23 million unlabeled ncRNA sequences\cite{rnacentral2021rnacentral} by recovering masked nucleotide tokens, to facilitate multiple downstream tasks including RNA secondary structure prediction and 3D closeness prediction. Especially, for secondary structure prediction, RNA-FM achieves 3-5\% performance increase among three metrics (i.e., Precision, Recall, and F1-score), compared to UFold\cite{fu2022ufold} which utilizes U-Net as the backbone. Furthermore, based on RNA-FM, Shen et al.\cite{shen2022e2efold} pioneered predicting 3D RNA structure directly.



Undoubtedly, these models are seminal and have reduced the time and cost of molecule structure prediction by a large margin. Thereby, this raises the question of whether LAMs can completely replace experimental methods such as Cryo-EM\cite{bai2015cryo}. We deem that it still falls short from that point. Specifically, the advance of LAMs builds upon big data and large model capacity, which means they are still data-driven, and hence their ability to predict unseen types of data could sometimes be problematic. For instance, \cite{buel2022can} stated that AlphaFold can barely handle missense mutation on protein structure due to the lack of a corresponding dataset. Furthermore, how we can assess the quality of model prediction for unknown protein structures remains unclear. In turn, these unverified protein structures cannot be applied to, for example, drug discovery. Therefore, protocols and metrics need to be established to assess their quality and potential impacts. There are mutual and complementary benefits between LAMs and conventional experimental techniques. LAMs can be re-designed to predict the process of protein folding and reveal their mutual interactions so as to facilitate experimental methods. On the other hand, experimental information, such as some physical properties of molecules, can be leveraged by LAMs to further improve prediction performance, especially when dealing with rare data (e.g., orphan protein).
























\subsection{Medical Diagnosis}

As research has been carried out to improve the safety and strengthen the factual grounding of LAMs, it is foreseeable that LAMs will play a significant role in medical diagnosis and decision-making.



CheXzero~\cite{tiu2022expert}, a zero-shot chest X-ray classifier, has demonstrated radiologist-level performance in classifying multiple pathologies which it never saw in its self-supervised learning process. Recently, ChatCAD~\cite{wang2023chatcad}, a framework that integrates multiple diagnostic networks with ChatGPT, demonstrated a potential use case for applying LLMs in computer-aided diagnosis (CAD) for medical images. By stratifying the decision-making process with specialized medical networks, and followed by an iteration of prompts based on the outcomes of those networks as the queries to an LLM for medical recommendations, the workflow of ChatCAD offers an insight into the integration of the LLMs that were pre-trained using a massive corpus, with the upstream specialized diagnostic networks for supporting medical diagnosis and decision-making. Its follow-up work ChatCAD+~\cite{zhao2023chatcad+}, shows improved quality of generating diagnostic reports with the incorporation of a retrieval system. Using external knowledge and information retrieval can potentially enable the resulting diagnostics more factually-grounded, and such a design has also been favoured and implemented in the ChatDoctor model~\cite{li2023chatdoctor}. By leveraging a linear transformation layer to align two medical LAMs, XrayGPT~\cite{thawkar2023xraygpt}, a conversational chest X-ray diagnostic tool, shows decent accuracy in responding to diagnostic summary. While most LLMs are based on English, researchers have also managed to fine-tune LLaMa~\cite{touvron2023llama}, an LLM, with Chinese medical knowledge, and the resulting model shows improved medical expertise in Chinese~\cite{wang2023huatuo}. 




Apart from chest X-ray diagnostics and medical question answering, LAMs have also been applied to other diagnostic scenarios. HeartBEiT~\cite{vaid2023foundational}, a foundation model pre-trained using 8.5 million electrocardiograms (ECGs), shows that large-scale ECG pre-training could produce accurate cardiac diagnosis and improved explainability of the diagnostic outcome, and the amount of annotated data for downstream fine-tuning could be reduced. Medical LAMs may also potentially produce a more reliable forecast of treatment outcomes and the future development of diseases using their strong reasoning capability. For example, Li et al.~\cite{li2020behrt} proposed BEHRT, which is able to predict the most likely disease of a patient in his/her next visit by learning from a large archive of EHRs. Rasmy et al.~\cite{rasmy2021medbert} proposed Med-BERT, which is able to predict the heart failure of diabetic patients. 




With the ubiquity of internet, medical LAMs can also offer remote diagnosis and medical consultation for people at home, providing people in need with more flexibility. We also envision that future diagnosis of complex diseases may also be conducted or assisted by a panel of clinical LAMs.






























\subsection{Medical Imaging}



The adoption of medical imaging and vision techniques has vastly influenced the process of diagnosis and treatment of a patient. The wide use of medical imaging, such as CT and MRI, has produced a vast amount of multi-modal, multi-source, and multi-organ medical vision data to accelerate the development of medical vision LAMs.

The recent success of SAM~\cite{kirillov2023segment} has drawn much attention within the medical imaging community. SAM has been extensively examined in medical imaging, especially on its zero-shot segmentation ability. While research revealed that for certain medical imaging modalities and targets, the zero-shot performance of SAM is impressive (e.g., on endoscopic and dermoscopic images, as these are essentially RGB images, which are the same type as that of SAM's pre-training images), for imaging modalities that are medicine-specific such as MRI and OCT (optical coherence tomograpy), SAM often fails to segment targets in a zero-shot way~\cite{shi2023generalist}, mainly because the topology and presentation of a target in those imaging modalities are much different from what SAM has seen during pre-training. Nevertheless, after adaptation and fine-tuning, the medical segmentation accuracy of SAM can surpass current SOTA with a clear margin~\cite{wu2023medical}, showing the potential of extending versatility of general LVMs to medical imaging with parameter-efficient adaptation. Apart from zero-shot segmentation, MedCLIP~\cite{wang2022medclip} was proposed, a contrastive learning framework for decoupled medical images and text, which demonstrated impressive zero-shot medical image classification accuracy. In particular, it yielded over 80\% accuracy in detecting Covid-19 infection in a zero-shot setting. The recent PLIP model~\cite{huang2023visual}, built using image-text pairs curated from medical Twitter, enables both image-based and text-based pathology image retrieval, as well as enhanced zero-shot pathology image classification compared to CLIP~\cite{radford2021learning}.

Many medical imaging modalities are 3-dimensional (3D), and thus developing 3D medical LVMs are crucial. Med3D~\cite{chen2019med3d}, a heterogeneous 3D framework that enables pre-training on multi-domain medical vision datasets, shows strong generalization capabilities in downstream tasks, such as lung segmentation and pulmonary nodule classification. 






With the success of generative LAMs such as Stable Diffusion~\cite{rombach2021highresolution} in the general domain, which can generate realistic high-fidelity images with text descriptions, Chambon et al.~\cite{chambon2022adapting} recently fine-tuned Stable Diffusion on medical data to generate synthetic chest X-ray images based on clinical descriptions. The encouraging generative capability of Stable Diffusion in the medical domain may inspire more future research on using generative LAMs to augment medical data that are conventionally hard to obtain, and expensive to annotate.




Nevertheless, some compromises are also evident in medical vision LAMs. For example, the currently common practice of training LVMs and LMMs often limits the size of the medical images to shorten the training time and reduce the computational costs. The reduced size inevitably causes information loss, e.g., some small lesions that are critical for accurate recognition might be removed in a compressed downsampled medical image, whereas doctors could examine the original high-resolution image and spot these early-stage tumors. This may cause performance discrepancies between current medical vision LAMs and well-trained doctors. In addition, although research has shown that increasing medical LAM size and data size could improve medical domain performance of the model, e.g., STU-Net~\cite{huang2023stu}, a medical segmentation model with 1.4 billion parameters, the best practice of model-data scaling is yet to be conclusive in medical imaging and vision. 










\subsection{Medical Informatics}



In medical informatics, it has been a topic of long-standing interest to leverage large-scale medical information and signals to create AI models that can recognize, summarize, and generate medical and clinical content. 

Over the past few years, with advances in the development of LLMs~\cite{devlin2018bert, brown2020language, chowdhery2022palm}, and the abundance of EHRs as well as public medical text outlets such as PubMed~\cite{pubmedabstract2023,pubmedcentral2023}, research has been carried out to design and propose Biomedical LLMs. Since the introduction of BioBERT~\cite{lee2020biobert}, a seminal Biomedical LLM which outperformed previous SOTA methods on various biomedical text mining tasks such as biomedical named entity recognition, many different Biomedical LLMs that stem from their general LLM counterparts have been proposed, including ClinicalBERT~\cite{alsentzer2019publicly}, BioMegatron~\cite{shin2020biomegatron}, BioMedRoBERTa~\cite{gururangan2020don}, Med-BERT~\cite{rasmy2021med}, BioELECTRA~\cite{raj2021bioelectra}, PubMedBERT~\cite{gu2021domain}, BioLinkBERT~\cite{yasunaga2022linkbert}, BioGPT~\cite{luo2022biogpt}, and Med-PaLM~\cite{singhal2022large}. 

The recent GatorTron~\cite{yang2022large} model (8.9 billion parameters) pre-trained with de-identified clinical text (82 billion words) revealed that scaling up the size of clinical LLMs leads to improvements on different medical language tasks, and the improvements are more substantial for complex ones, such as medical question answering and inference. Previously, the PubMedBERT work~\cite{gu2021domain} also suggested that pre-training an LLM with biomedical corpora from scratch can lead to better results than continually training an LLM that has been pre-trained on the general-domain corpora. While training large number of parameters may seem daunting, parameter-efficient adaptation techniques such as low-rank adaptation (LoRA)~\cite{hu2021lora} have enabled researchers to efficiently adapt a 13 billion LLaMa model to produce decent US Medical Licensing Exam (USMLE) answers, and the performance of a collection of such fine-tuned models, called MedAlpaca~\cite{han2023medalpaca} also reveals that increasing model size and quality of data can improve model's medical domain expertise. As LLMs start to show emergent abilities~\cite{wei2022emergent} with their size scaled up increasingly, Agrawal et al.~\cite{agrawal2022large} revealed that recent LLMs such as InstructGPT~\cite{ouyang2022training} and GPT-3~\cite{brown2020language} can well extract clinical information in a few-shot setting despite being not explicitly trained for the clinical domain. Med-PaLM~\cite{singhal2022large}, a Biomedical LLM with 540 billion parameters generated by applying instruction prompt tuning on Flan-PaLM~\cite{chung2022scaling} (which exhibited SOTA accuracy on MultiMedQA~\cite{singhal2022large}), demonstrated the ability to answer consumer medical questions that are comparable to the performance of clinicians. Its follow-up work, Med-PaLM 2~\cite{singhal2023towards}, further strengthens medical reasoning, and as shown in Table~\ref{tab:LAM_sota}, it has reached an accuracy of 86.5\% on the MedQA benchmark. As prompt engineering has become a key technique for investigating and improving LLMs, Li{\'e}vin et al.~\cite{lievin2022can} have also applied various prompt engineering on the GPT-3.5 series such as InstructGPT~\cite{ouyang2022training} to understand their abilities on medical question answering, and their results suggested that increasing Chain-of-Thoughts (CoTs)~\cite{wei2022chain} per question can deliver better, more interpretable medical question responses. 



The impressive performance of Biomedical LLMs on medical language tasks shows their potential to be used to assist clinicians in processing, interpreting, and analyzing clinical and medical data more efficiently, and also to vastly reduce the time that clinicians have to spend on documenting EHRs.  Patel and Lam~\cite{patel2023chatgpt} recently shed insight on using ChatGPT~\cite{chatgpt2022} to generate discharge summaries, which could potentially relieve doctors from laborious writing and improve their clinical productivity. Biomedical LLMs can also assist in the writing of prior authorizations for insurance purposes, accelerating treatment authorizations~\cite{priorauth2023}. On the patient side, the zero-, one-, and few-shot learning capability of LLMs may enable them to provide personalized medical assistance based on the medical history of each individual patient. In addition, LLMs may also find them applicable in clinical trial matching. Based on candidates' demographics and medical history, a Biomedical LLM may effectively generate eligible matching, which accelerates clinical trial recruitment and initiation.


















\subsection{Medical Education}



It is likely that future medical education will also be influenced by LAMs, as research continues to strengthen their scientific grounding and creative generation. Many LAMs, such as GPT-4~\cite{gpt4openai2023} and Med PaLM 2~\cite{singhal2023towards}, have already passed USMLE with a score of over 86\%, demonstrating sound knowledge spectrum and reasonable capabilities in bioethics, clinical reasoning, and medical management. 



The generative capability of such LAMs may augment medical student learning and help them gain additional insights from AI-generated content as recently pointed out in~\cite{kung2023performance}. A LAM with wide knowledge and social compliance can act as a companion learning assistant, answering medical questions promptly and explaining intricate terms and practices in simple sentences. For example, the recent GPT-4 model~\cite{gpt4openai2023} can act as a Socratic tutor, leading a student step-by-step to find the answers by themselves, which is an important step towards practical adoption of LAMs in education as they can be steered to teach/assist students in a desired manner. The OPTICAL model proposed by Shue et al.~\cite{shue2023empowering} recently shows the feasibility of using LLMs to guide beginners in analyzing bioinformatics data. The sentence paraphrasing abilities of LLMs~\cite{dai2023chataug} such as ChatGPT may also help students with dyslexia in their learning. However, concerns about the illegitimate uses of LAMs such as plagiarism are practical and should raise awareness. A pilot study conducted by Mitchell et al.~\cite{mitchell2023detectgpt} proposed a zero-shot detector named DetectGPT, which is able to distinguish human-written or LLM-generated text. This attempt may lead to more research into developing reliable tools for verifying the content source and potentially countering the side effects of LAMs in education. 

For medical education givers, LAMs can potentially create novel teaching and exam contents, and diversify the teaching formats and their presentation. Based on the history of medical study and outcomes, LAMs may also help design personalized and precise course materials for students in need. In addition, LAMs may also help deliver remote medical education, providing engaging learning experiences and opportunities for students living in resource-poor areas or from underprivileged families. LAMs can also serve as a grading and scoring system in medical education, e.g., grading the surgical skill of a surgeon operating a surgical robot. 



In medical and clinical training such as nurse training, one can imagine a domain-knowledgeable LAM can act as an assistant or a trainer to supervise the training. For certain frequent and tedious routine medical training courses, human trainers tend to become less productive as training keeps repeating, and the quality of training delivery also varies among different human trainers. With a wide knowledge spectrum and responsive interactions, training delivered by a LAM can potentially be more engaging and productive, and the standard of training can be maintained as equal and of high quality. 



\begin{figure*}[!t]
\centering
\captionof{table}{Large-scale datasets in biomedical and health informatics}
\centerline{\includegraphics[width=\textwidth]{figures/LAM_dataset.eps}}
\label{tab:LAM_dataset}
\vspace{-0.5cm}
\end{figure*}







\subsection{Public Health}



As the American epidemiologist Larry Brilliant said \textit{``outbreaks are inevitable, but pandemics are optional"}, with the world gradually returning to normal after the Covid-19 pandemic, if there is one thing that the world has to reflect on, it is how we become prepared to prevent the next pandemic.


Based on past public policy and interventions to contain the spread of infectious diseases and the specific current situation, LLMs may help epidemiologists and policymakers to draft targeted public policies and recommend effective interventions. LLMs and other LAMs are also likely to be used to monitor, track, forecast, and analyze the progress of new outbreaks. LAMs have been actively researched for drug discovery, e.g., the Pangu Drug model~\cite{lin2022pangu}, and they can potentially be used for the design of vaccine and drugs to treat and save people from new outbreaks. Furthermore, another potential usage of LAMs, as pointed out in~\cite{korngiebel2021considering}, can be in precision triage and diagnosis, in which they could play a pivotal role as medical care workforce might be stretched when encountering a new outbreak. An important aspect of tackling an outbreak/epidemic is to handle misinformation. The study conducted by Chen et al.~\cite{chen2020tracking} revealed that from 21 January 2020 to 21 March 2020, Twitter produced over 72 million Covid-19-related tweets. If unverified media information proliferates at scale, it inevitably causes complications in tackling the outbreak. Although LAMs could be double-edged swords when it comes to misinformation, with gradually complete regulations and strengthened factual grounding of LAMs, they can be used to effectively identify misinformation and tackle public health infodemic. 



Beyond their promising usage in preventing pandemics, LAMs are also an effective tool for solving other public health challenges, for example, providing large-scale dietary monitoring and assessment~\cite{peng2022clustering,qiu2023egocentric} to tackle the growing \textit{double burden of malnutrition}~\cite{popkin2019dynamics} in many low- and middle-income countries, and demystifying and proposing new solutions for mental illnesses that are common in populations. Researchers have recently proposed ClimaX~\cite{nguyen2023climax}, a foundation model for forecasting weather and climate change. With their remarkable forecasting capability, LAMs like ClimaX and Pangu-Weather~\cite{bi2023accurate} can advance our understanding of climate change and provide solutions to better address the global health issues posed by climate change.





















\subsection{Medical Robotics}




From surgical robots that allow surgeons to perform precision minimally invasive surgery, to wearable robots that assist patients with health monitoring and rehabilitation, medical robotics has seen rapid growth and advances over the past few decades. LAMs have begun to show exciting prospects in enhancing medical robotic vision, interaction, and autonomy. 




\subsubsection{Enhance Vision}


The integration of LAMs into surgical robots has the potential to enhance the vision of these systems in surgery. Endo-FM~\cite{wang2023foundation}, a foundation model with high precision for endoscopic video classification, segmentation, and detection, could be one of these LAMs to provide robotic surgery systems with enhanced vision.
In addition to online vision enhancement, LAMs can also potentially improve the offline workflow analysis of robotic surgery, and more accurately and objectively predict the likelihood of complications and successful outcomes, which help surgeons better plan and execute surgeries in the future. Furthermore, with their strong generative capabilities, LAMs can be used to generate and simulate surgical procedures, allowing surgeons to practice and refine their techniques before operating on a patient with real surgical robots. Beyond surgical robots, the perception of many companion and assistive robots can also be enhanced by LAMs, e.g., enabling a companion robot to better understand a patient's emotion through accurate recognition of facial expressions~\cite{d2022emotion}, and enabling an assistive robot to offer safer, more natural navigation for visually impaired people~\cite{qiu2022egocentric}. 


\subsubsection{Improve Interaction}
LAMs may significantly improve the interactive capabilities of many medical robots, by enabling them to recognize human emotions, gestures, and speech, and respond to high-level human language commands. For example, this will be easier for patients undergoing rehabilitation to communicate and engage with their robotic assistants, improving their overall recovery experience. More intelligent LAMs may also better understand human intentions and create more human-like companionship, which could improve the overall quality of care for the elderly~\cite{asgharian2022review}. Recently, SurgicalGPT~\cite{seenivasan2023surgicalgpt}, a visual question answering model for surgery, has shown great promise that future robotic surgery could become more interactive between surgeons and the surgical robots.




\subsubsection{Increase Autonomy}

LAMs have the potential to turn robotic pipelines from the current \textit{engineer in the loop} to \textit{user in the loop} using high-level language commands~\cite{vemprala2023chatgpt}, which could enable surgeons with less programming proficiency to easily adapt robotic manipulations to their target tasks. Studies have proposed to use a single LAM to conduct diverse robotic tasks, demonstrating impressive adaptability and generalization skills~\cite{reed2022a, shridhar2022cliport, shridhar2022perceiver, saycan2022arxiv, driess2023palme, jiang2022vima, brohan2022rt}. These advancements can potentially inspire the development of more autonomous medical robots.








