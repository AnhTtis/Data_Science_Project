\section{Introduction}
\label{sec:intro}

Speech coding, which consists of compressing speech signals to a limited number of bits with minimal distortion, is at the core of communication technologies such as mobile telephony or Voice over IP (VoIP). Opus~\cite{valin2012opus} and EVS~\cite{dietz2015evs} are state-of-the-art speech coding techniques that combine traditional coding tools, such as Linear Predictive Coding (LPC), Code Excited Linear Prediction (CELP), and Modified Discrete Cosine Transformation (MDCT) to achieve high coding efficiency over different content types and bitrates. These waveform and parametric codecs rely on psychoacoustics expertise to design signal processing pipelines with maximal coding efficiency. Yet, while fast and interpretable, such handcrafted pipelines \linebreak only represent a fraction of the potential models for a speech codec.

This has motivated data-driven approaches to train neural networks to perform speech coding. These networks leverage large amounts of training data while relaxing the assumptions made on the type of transformations applied by the system \cite{morishima1990speechcoding, kankanahalli2018speechdnn, valin2019lpcnet, garbacea2019vqvae, polyak2021speech, zhen2019cascaded, petermann2021harp, zeghidour2021soundstream}. In particular, the SoundStream neural codec combines a causal convolutional architecture with a residual vector quantizer. This quantization method produces a hierarchy of coarse-to-fine codes, and allows for efficient compression while providing bitrate scalability. As a result, SoundStream at \SI{3}{~}kbps matches the quality Opus at \SI{12}{~}kbps. However, the quality of most codecs, be they handcrafted or trained, degrades significantly at bitrates lower than \SI{3}{~}kbps.

In this work, we introduce LMCodec, a low bitrate speech codec that combines recent advances in neural audio coding and audio generative modeling. LMCodec uses autoregressive Transformers \cite{attentionvaswani} on SoundStream tokens to (i) model the entropy of the distribution of coarse tokens and (ii) predict fine tokens from the coarse ones. At inference, LMCodec extracts the codes of a  SoundStream model from the input waveform. However, instead of sending all codes to the receiver like a SoundStream codec would do, LMCodec only transmits entropy-coded coarse tokens. On the receiver side, a generative language model is used to predict fine tokens from the coarse ones, and a SoundStream decoder then reconstructs audio from the complete token sequence.

LMCodec takes inspiration from the AudioLM \cite{borsos2022audiolm} generative model, which also predicts fine SoundStream tokens from coarse ones. However, unlike AudioLM, LMCodec does low bitrate compression rather than generative modeling, and to do so leverages AudioLM both as a generative model and an entropy model. Other Transformer-based models for low bitrate coding have been proposed ~\cite{siahkoohi2022ultra, polyak2021speech}. The codec in~\cite{siahkoohi2022ultra} enriches SoundStream with embeddings extracted from a self-supervised speech representation model \cite{conformer} and achieves speech compression at a rate of \SI{600}{~}bps. \cite{polyak2021speech} synthesizes speech from a combination of phonetic, pitch and speaker representations to achieve 365 bps. Unlike these models, LMCodec is a fully causal model, which is thus amenable to online encoding and decoding. Our primary contribution is the design of a new neural speech codec, which achieves state-of-the-art results  outperforming many previous codecs operating at three to four times the rates according to subjective human evaluation metrics.

Subjective evaluations demonstrate how LMCodec allows for low bitrate speech coding with minimal distortion, with LMCodec at approximately \SI{1}{}-\SI{1.5}{~}kbps matching the performance of Opus at \SI{12}{~}kbps. We furthermore analyze the failure modes of our system, as well as the discrepancies in bit allocations between speech and non-speech sections of an audio signal.

\begin{figure}
    \centering
    \captionsetup{belowskip=-20pt}
    \centerline{\includegraphics[trim={0 3cm 0 1cm},clip,width=8.5cm]{diagrams/overall.pdf}}
    \caption{Overall pipeline of the proposed codec.}
    \label{fig:overall}
\end{figure}


\begin{figure}
    \captionsetup{belowskip=-10pt}
    \centering
    \begin{subfigure}[b]{0.245\textwidth}
         \centering
         \includegraphics[clip, trim=0.5cm 0.5cm 1.3cm 1.7cm, height=3.9cm]{diagrams/mushra.pdf}
         \label{fig:a}
    \end{subfigure}
    \kern-1em
    \begin{subfigure}[b]{0.245\textwidth}
        \centering
         \includegraphics[clip, trim=0.5cm 0.5cm 1.3cm 1.7cm, height=3.9cm]{diagrams/mushra_new.pdf}
         \label{fig:b}
    \end{subfigure}
    \caption{MUHSRA-like subjective evaluation from state-of-the-art codecs with medium and low bitrates. LMCodec-$x/y$ refers to our model with $N_\mathcal{C}=x$ and $N_\mathcal{C} + N_\mathcal{F}=y$. wav2vec \cite{siahkoohi2022ultra} is a recent neural codec based on SoundStream and Transformer.}
    \label{fig:mushra} \label{fig:mushra_new}
\end{figure}

