
IEEEexample.bib 
V1.12 (2007/01/11)
Copyright (c) 2002-2007 by Michael Shell
See: http://www.michaelshell.org/
for current contact information.

This is an example BibTeX database for the official IEEEtran.bst
BibTeX style file.

Some entries call strings that are defined in the IEEEabrv.bib file.
Therefore, IEEEabrv.bib should be loaded prior to this file. 
Usage: 

\bibliographystyle{./IEEEtran}
\bibliography{./IEEEabrv,./IEEEexample}


Support sites:
http://www.michaelshell.org/tex/ieeetran/
http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
and/or
http://www.ieee.org/

*************************************************************************
Legal Notice:
This code is offered as-is without any warranty either expressed or
implied; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE! 
User assumes all risk.
In no event shall IEEE or any contributor to this code be liable for
any damages or losses, including, but not limited to, incidental,
consequential, or any other damages, resulting from the use or misuse
of any information contained here.

All comments are the opinions of their respective authors and are not
necessarily endorsed by the IEEE.

This work is distributed under the LaTeX Project Public License (LPPL)
( http://www.latex-project.org/ ) version 1.3, and may be freely used,
distributed and modified. A copy of the LPPL, version 1.3, is included
in the base LaTeX documentation of all distributions of LaTeX released
2003/12/01 or later.
Retain all contribution notices and credits.
** Modified files should be clearly indicated as such, including  **
** renaming them and changing author support contact information. **

File list of work: IEEEabrv.bib, IEEEfull.bib, IEEEexample.bib,
                   IEEEtran.bst, IEEEtranS.bst, IEEEtranSA.bst,
                   IEEEtranN.bst, IEEEtranSN.bst, IEEEtran_bst_HOWTO.pdf
*************************************************************************


Note that, because the example references were taken from actual IEEE
publications, these examples do not always contain the full amount
of information that may be desirable (for use with other BibTeX styles).
In particular, full names (not abbreviated with initials) should be
entered whenever possible as some (non-IEEE) bibliography styles use
full names. IEEEtran.bst will automatically abbreviate when it encounters
full names.
 
 
@inproceedings{liu2016quantitative,
  title={Quantitative workload analysis and prediction using Google cluster traces},
  author={Liu, Bingwei and Lin, Yinan and Chen, Yu},
  booktitle={2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  pages={935--940},
  year={2016},
  organization={IEEE}
}

@article{calheiros2014workload,
  title={Workload prediction using ARIMA model and its impact on cloud applications’ QoS},
  author={Calheiros, Rodrigo N and Masoumi, Enayat and Ranjan, Rajiv and Buyya, Rajkumar},
  journal={IEEE transactions on cloud computing},
  volume={3},
  number={4},
  pages={449--458},
  year={2014},
  publisher={IEEE}
}

@inproceedings{kumar2016forecasting,
  title={Forecasting HPC workload using ARMA models and SSA},
  author={Kumar, Anoop S and Mazumdar, Somnath},
  booktitle={2016 International Conference on Information Technology (ICIT)},
  pages={294--297},
  year={2016},
  organization={IEEE}
} 
 
@article{zhong2018load,
  title={A load prediction model for cloud computing using PSO-based weighted wavelet support vector machine},
  author={Zhong, Wei and Zhuang, Yi and Sun, Jian and Gu, Jingjing},
  journal={Applied Intelligence},
  volume={48},
  number={11},
  pages={4072--4083},
  year={2018},
  publisher={Springer}
} 

@inproceedings{nikravesh2015towards,
  title={Towards an autonomic auto-scaling prediction system for cloud resource provisioning},
  author={Nikravesh, Ali Yadavar and Ajila, Samuel A and Lung, Chung-Horng},
  booktitle={2015 IEEE/ACM 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  pages={35--45},
  year={2015},
  organization={IEEE}
}

@inproceedings{marcus2016workload,
  title={Workload management for cloud databases via machine learning},
  author={Marcus, Ryan and Papaemmanouil, Olga},
  booktitle={2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW)},
  pages={27--30},
  year={2016},
  organization={IEEE}
} 

@inproceedings{yang2018intelligent,
  title={Intelligent resource scheduling at scale: a machine learning perspective},
  author={Yang, Renyu and Ouyang, Xue and Chen, Yaofeng and Townend, Paul and Xu, Jie},
  booktitle={2018 IEEE symposium on service-oriented system engineering (SOSE)},
  pages={132--141},
  year={2018},
  organization={IEEE}
} 

@inproceedings{gupta2017online,
  title={Online adaptation models for resource usage prediction in cloud network},
  author={Gupta, Shaifu and Dinesh, Dileep Aroor},
  booktitle={2017 Twenty-third National Conference on Communications (NCC)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}



@article{farrokh2022sp,
  title={SP-ant: An ant colony optimization based operator scheduler for high performance distributed stream processing on heterogeneous clusters},
  author={Farrokh, Mohammadreza and Hadian, Hamid and Sharifi, Mohsen and Jafari, Ali},
  journal={Expert Systems with Applications},
  volume={191},
  pages={116322},
  year={2022},
  publisher={Elsevier}
}



@article{hadian2023elastic,
  title={An elastic and traffic-aware scheduler for distributed data stream processing in heterogeneous clusters},
  author={Hadian, Hamid and Farrokh, Mohammadreza and Sharifi, Mohsen and Jafari, Ali},
  journal={The Journal of Supercomputing},
  volume={79},
  number={1},
  pages={461--498},
  year={2023},
  publisher={Springer}
}

@inproceedings{validi2022hybrid,
  title={Hybrid On/Off Blockchain Approach for Vehicle Data Management, Processing and Visualization Exemplified by the ADAPT Platform},
  author={Validi, Aso and Kashansky, Vladislav and Khiari, Jihed and Hadian, Hamid and Prodan, Radu and Li, Juanjuan and Wang, Fei-Yue and Olaverri-Monreal, Cristina},
  booktitle={2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC)},
  pages={3152--3158},
  year={2022},
  organization={IEEE}
}


@inproceedings{gupta2017resource,
  title={Resource usage prediction of cloud workloads using deep bidirectional long short term memory networks},
  author={Gupta, Shaifu and Dinesh, Dileep Aroor},
  booktitle={2017 IEEE international conference on advanced networks and telecommunications systems (ANTS)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}


@inproceedings{cheng2019gru,
  title={Gru-es: Resource usage prediction of cloud workloads using a novel hybrid method},
  author={Cheng, Yuming and Wang, Chao and Yu, Huihuang and Hu, Yahui and Zhou, Xuehai},
  booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)},
  pages={1249--1256},
  year={2019},
  organization={IEEE}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@article{gupta2020online,
  title={Online sparse blstm models for resource usage prediction in cloud datacentres},
  author={Gupta, Shaifu and Dileep, Aroor Dinesh and Gonsalves, Timothy A},
  journal={IEEE Transactions on Network and Service Management},
  volume={17},
  number={4},
  pages={2335--2349},
  year={2020},
  publisher={IEEE}
}

@article{surya2021prediction,
  title={Prediction of resource contention in cloud using second order Markov model},
  author={Surya, K and Rajam, V},
  journal={Computing},
  volume={103},
  number={10},
  pages={2339--2360},
  year={2021},
  publisher={Springer}
}

@article{xu2022esdnn,
  title={esDNN: Deep Neural Network based Multivariate Workload Prediction in Cloud Computing Environments},
  author={Xu, Minxian and Song, Chenghao and Wu, Huaming and Gill, Sukhpal Singh and Ye, Kejiang and Xu, Chengzhong},
  journal={ACM Transactions on Internet Technology (TOIT)},
  year={2022},
  publisher={ACM New York, NY}
}




@article{messias2016combining,
  title={Combining time series prediction models using genetic algorithm to autoscaling web applications hosted in the cloud infrastructure},
  author={Messias, Valter Rog{\'e}rio and Estrella, Julio Cezar and Ehlers, Ricardo and Santana, Marcos Jos{\'e} and Santana, Regina Carlucci and Reiff-Marganiec, Stephan},
  journal={Neural Computing and Applications},
  volume={27},
  number={8},
  pages={2383--2406},
  year={2016},
  publisher={Springer}
}

@article{kaur2015energy,
  title={Energy efficiency techniques in cloud computing: A survey and taxonomy},
  author={Kaur, Tarandeep and Chana, Inderveer},
  journal={ACM computing surveys (CSUR)},
  volume={48},
  number={2},
  pages={1--46},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@inproceedings{sudhakar2018workload,
  title={Workload prediction using ARIMA statistical model and long short-term memory recurrent neural networks},
  author={Sudhakar, Chapram and Kumar, A Revanth and Siddartha, Nupa and Reddy, S Vishal},
  booktitle={2018 International Conference on Computing, Power and Communication Technologies (GUCON)},
  pages={600--604},
  year={2018},
  organization={IEEE}
}






@article{gupta2018joint,
  title={A joint feature selection framework for multivariate resource usage prediction in cloud servers using stability and prediction performance},
  author={Gupta, Shaifu and Dileep, Aroor Dinesh and Gonsalves, Timothy A},
  journal={The Journal of Supercomputing},
  volume={74},
  number={11},
  pages={6033--6068},
  year={2018},
  publisher={Springer}
}


@article{cetinski2015ame,
  title={AME-WPC: Advanced model for efficient workload prediction in the cloud},
  author={Cetinski, Katja and Juric, Matjaz B},
  journal={Journal of Network and Computer Applications},
  volume={55},
  pages={191--201},
  year={2015},
  publisher={Elsevier}
} 

@article{song2018host,
  title={Host load prediction with long short-term memory in cloud computing},
  author={Song, Binbin and Yu, Yao and Zhou, Yu and Wang, Ziqiang and Du, Sidan},
  journal={The Journal of Supercomputing},
  volume={74},
  number={12},
  pages={6554--6568},
  year={2018},
  publisher={Springer}
}

@article{KUMAR2018676,
title = {Long Short Term Memory Recurrent Neural Network (LSTM-RNN) Based Workload Forecasting Model For Cloud Datacenters},
journal = {Procedia Computer Science},
volume = {125},
pages = {676-682},
year = {2018},
note = {The 6th International Conference on Smart Computing and Communications},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.12.087},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917328557},
author = {Jitendra Kumar and Rimsha Goomer and Ashutosh Kumar Singh},
keywords = {Cloud Computing, Resource Scaling, Forecasting, Deep Learning},
abstract = {In spite of various gains, cloud computing has got few challenges and issues including dynamic resource scaling and power consumption. Such affairs cause a cloud system to be fragile and expensive. In this paper we address both issues in cloud datacenter through workload prediction. The workload prediction model is developed using long short term memory (LSTM) networks. The proposed model is tested on three benchmark datasets of web server logs. The empirical results show that the proposed method achieved high accuracy in predictions by reducing the mean squared error up to 3.17 x 10-3.}
}

@article{ouhame2021efficient,
  title={An efficient forecasting approach for resource utilization in cloud data center using CNN-LSTM model},
  author={Ouhame, Soukaina and Hadi, Youssef and Ullah, Arif},
  journal={Neural Computing and Applications},
  volume={33},
  number={16},
  pages={10043--10055},
  year={2021},
  publisher={Springer}
}

@article{dang2022efficient,
  title={An Efficient Multivariate Autoscaling Framework Using Bi-LSTM for Cloud Computing},
  author={Dang-Quang, Nhat-Minh and Yoo, Myungsik},
  journal={Applied Sciences},
  volume={12},
  number={7},
  pages={3523},
  year={2022},
  publisher={MDPI}
}

@article{kumar2021self,
  title={Self directed learning based workload forecasting model for cloud resource management},
  author={Kumar, Jitendra and Singh, Ashutosh Kumar and Buyya, Rajkumar},
  journal={Information Sciences},
  volume={543},
  pages={345--366},
  year={2021},
  publisher={Elsevier}
}

@article{amiri2018online,
  title={An online learning model based on episode mining for workload prediction in cloud},
  author={Amiri, Maryam and Mohammad-Khanli, Leyli and Mirandola, Raffaela},
  journal={Future Generation Computer Systems},
  volume={87},
  pages={83--101},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{liu2016online,
  title={Online arima algorithms for time series prediction},
  author={Liu, Chenghao and Hoi, Steven CH and Zhao, Peilin and Sun, Jianling},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@article{cho2014properties,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@article{reiss2011google,
  title={Google cluster-usage traces: format+ schema},
  author={Reiss, Charles and Wilkes, John and Hellerstein, Joseph L},
  journal={Google Inc., White Paper},
  volume={1},
  year={2011}
}

@article{JMLR:v23:21-1177,
  author  = {Julien Herzen and Francesco LÃ¤ssig and Samuele Giuliano Piazzetta and Thomas Neuer and LÃ©o Tafti and Guillaume Raille and Tomas Van Pottelbergh and Marek Pasieka and Andrzej Skrodzki and Nicolas Huguenin and Maxime Dumonal and Jan KoÅcisz and Dennis Bader and FrÃ©dÃ©rick Gusset and Mounir Benheddi and Camila Williamson and Michal Kosinski and Matej Petrik and GaÃ«l Grosch},
  title   = {Darts: User-Friendly Modern Machine Learning for Time Series},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {124},
  pages   = {1-6},
  url     = {http://jmlr.org/papers/v23/21-1177.html}
}

@article{falcon2020pytorchlightning,
  title={PyTorchLightning/pytorch-lightning: 0.7. 6 release},
  author={Falcon, William and Borovec, Jirka and W{\"a}lchli, Adrian and Eggert, N and Schock, J and Jordan, J and Skafte, N and Bereznyuk, V and Harris, E and Murrell, T and others},
  journal={Zenodo: Geneva, Switzerland},
  year={2020}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@misc{vaquero2008break,
  title={A break in the clouds: towards a cloud definition},
  author={Vaquero, Luis M and Rodero-Merino, Luis and Caceres, Juan and Lindner, Maik},
  journal={ACM sigcomm computer communication review},
  volume={39},
  number={1},
  pages={50--55},
  year={2008},
  publisher={ACM New York, NY, USA}
}

 @misc{fact.mr, title={Fact.MR – cloud computing market analysis by deployment (public, private, Hybrid Cloud Computing), by service (infrastructure as a service (iaas), Platform as a Service (paas), software as a service (SAAS)), by Enterprise Size, by end use \&amp; regional forecast 2022-2032}, url={https://bit.ly/3Tk58Oz}, journal={Fact.MR, Market Research Company}} 

@article{lstm,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

Those fields that are not to be changed can be left out.
@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
  CTLuse_article_number     = "yes",
  CTLuse_paper              = "yes",
  CTLuse_forced_etal        = "no",
  CTLmax_names_forced_etal  = "10",
  CTLnames_show_etal        = "1",
  CTLuse_alt_spacing        = "yes",
  CTLalt_stretch_factor     = "4",
  CTLdash_repeated_names    = "yes",
  CTLname_format_string     = "{f.~}{vv~}{ll}{, jj}",
  CTLname_latex_cmd         = "",
  CTLname_url_prefix        = "[Online]. Available:"
}


