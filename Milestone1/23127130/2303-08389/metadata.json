{
    "arxiv_id": "2303.08389",
    "paper_title": "PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning",
    "authors": [
        "Yongil Kim",
        "Yerin Hwang",
        "Hyeongu Yun",
        "Seunghyun Yoon",
        "Trung Bui",
        "Kyomin Jung"
    ],
    "submission_date": "2023-03-15",
    "revised_dates": [
        "2023-03-16"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL"
    ],
    "abstract": "Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning. This paper proposes Perturbation Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages. To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text. To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for 3, 000 images in five languages. In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, proving that PR-MCS is highly robust to lexical perturbations.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08389v1"
    ],
    "publication_venue": null
}