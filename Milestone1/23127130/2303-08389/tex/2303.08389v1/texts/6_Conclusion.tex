In this paper, we propose PR-MCS, a perturbation-robust metric for multilingual image captioning using language-agnostic fine-tuning. PR-MCS, developed by fine-tuning the text encoder of CLIP, can distinguish lexically perturbed text from original text. We also propose a new fine-grained multilingual evaluation set, \dataset, for use in perturbation robustness evaluation. Experimental results for existing datasets and our new dataset show that PR-MCS detects perturbation well and is robust to perturbation in multiple languages.  

\iffalse
In this paper, we propose PR-MCS, perturbation robust metric in multi-lingual image captioning by using language-agnostic fine-tuning method.
By fine-tuning the text encoder of CLIP,~\ours~is able to distinguish the lexical noised text to the original text.
Also, we propose new fine-grained multi-lingual evaluation set~\dataset~for perturbation robustness.
Experimental results on existing dataset and our new dataset show that PR-MCS detects perturbation well and is robust to perturbation in all languages.
We also believe that~\dataset~can be used in various multi-lingual tasks.
\fi

\iffalse

In this paper, we propose \textbf{P}erturbation \textbf{R}obust \textbf{M}ulti-Lingual \textbf{C}LIP\textbf{S}core(\textbf{PR-MCS}) which shows robustness to such perturbations as a novel reference-free image captioning metric in multiple languages.
To allow perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to be able to distinguish the perturbed text from the original text.
Additionally, to verify PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for $3,000$ images in five languages.
In our experiments, PR-MCS significantly outperforms its baselines in capturing lexical noises of all various perturbation types in all five languages, proving that PR-MCS is strongly robust to lexical perturbations.
\fi