Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning.
%The vulnerability to lexical perturbation is spotted as a critical weakness of automatic evaluation metrics for Image Captioning.
This paper proposes \textbf{P}erturbation \textbf{R}obust \textbf{M}ulti-Lingual \textbf{C}LIP\textbf{S}core(\textbf{PR-MCS}), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages.
%This paper proposes \textbf{P}erturbation \textbf{R}obust \textbf{M}ulti-Lingual \textbf{C}LIP\textbf{S}core(\textbf{PR-MCS}), which shows robustness to such perturbations as a novel reference-free image captioning metric in multiple languages.
To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text.
%To allow perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text.
To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for $3,000$ images in five languages\footnote{All the datasets and code will be available here. Our dataset is distributed under the CC-BY-NC 4.0 license.}.
%Additionally, to verify PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for $3,000$ images in five languages\footnote{All the datasets and code will be available here. Our dataset is distributed under the CC-BY-NC 4.0 license.}.
In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, proving that PR-MCS is highly robust to lexical perturbations.
%In our experiments, PR-MCS significantly outperforms its baselines in capturing lexical noises of all various perturbation types in all five languages, proving that PR-MCS is strongly robust to lexical perturbations.

\iffalse
Despite the advance of recent image captioning metrics for evaluating generated captions such as CLIPScore, many metrics including CLIPScore are vulnerable to perturbation such as lexcial noise.
In this paper, we propose a novel methodology to give perturbation robustness to CLIPScore. 
We trains the text encoder so that the original caption embedding becomes similar to the image embedding of CLIPSCore and the perturbed caption embedding becomes dissimilar.
Moreover, we extend CLIPScore into multilingul setting, and create \textbf{P}erturbation \textbf{R}obust \textbf{M}ultiLingual \textbf{C}LIP\textbf{S}core(\textbf{PR-MCS}) by using proposed methodology.
In addition, to prove the perturbation robustness and language-agnostic characteristics of PR-MCS, we introduce new fine-grained evaluation dataset of five languages.
In experimental results, PR-CMS shows overwhelming performance for detecting perturbation in all five languages, proving that PR-MCS is strongly robust to perturbation.
\fi

\iffalse
In recent years, Image Captioning models have shown great performance, and many metrics have been presented to evaluate the models.
However, there is no metric that catches robustness of a model as for perturbation with changes in inputs.
%Existing metrics show weaknesses for perturbations with changes in inputs.
Even when perturbations change captions to make it difficult for humans to describe images well, existing image caption metrics fail to distinguish them and still predict scores similar to original captions.
In this paper, we propose a novel methodology to produce Image Captioning metric which is robust to perturbation of input.
%To compare our metric with existing metrics, 
In experiments, our metric shows overwhelming performance for detecting perturbations of captions than existing metrics.
Moreover, we extend our method to multilingual environments and we present new evaluation sets for perturbation robustness in multilingual setting. %, which is very helpful in the multi-lingual image captioning environment where the current dataset is much lacking.
In the multilingual setting, our metric shows outstanding performance than existing metrics in all the five languages. %much better
\fi