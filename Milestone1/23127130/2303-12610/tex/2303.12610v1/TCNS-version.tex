\documentclass[10pt,twocolumn,twoside]{IEEEtran}
\usepackage{generic}
\usepackage{cite}
\expandafter\let\csname proof\endcsname\relax
\expandafter\let\csname endproof\endcsname\relax
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithmic}
% \usepackage{romannum}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{textcomp}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{bbding}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{bm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
  T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}
\newtheorem{problem}{Problem}
\newtheorem*{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\usepackage{threeparttable}
\allowdisplaybreaks
%\markboth{\journalname, VOL. XX, NO. XX, XXXX 2017}
%{Author \MakeLowercase{\textit{et al.}}: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS (February 2017)}
\begin{document}
\title{Distributed Control Design and Safety Verification for Multi-Agent Systems}
\author{Han Wang, Antonis Papachristodoulou, Kostas Margellos
\thanks{ For
the purpose of Open Access, the authors have applied a CC BY public
copyright licence to any Author Accepted Manuscript (AAM) version
arising from this submission.

The authors are with the Department of Engineering Science, University of Oxford, Oxford, United Kingdom. E-mails: \{han.wang, antonis, kostas.margellos\}@eng.ox.ac.uk
}
\thanks{
% The next few paragraphs should contain 
% the authors' current affiliations, including current address and e-mail. For 
% example, F. A. Author is with the National Institute of Standards and 
% Technology, Boulder, CO 80305 USA (e-mail: author@boulder.nist.gov). 
}
\thanks{
% S. B. Author, Jr., was with Rice University, Houston, TX 77005 USA. He is 
% now with the Department of Physics, Colorado State University, Fort Collins, 
% CO 80523 USA (e-mail: author@lamar.colostate.edu).
}
\thanks{
% T. C. Author is with 
% the Electrical Engineering Department, University of Colorado, Boulder, CO 
% 80309 USA, on leave from the National Research Institute for Metals, 
% Tsukuba, Japan (e-mail: author@nrim.go.jp).
}}

\maketitle

\begin{abstract}
We propose distributed iterative algorithms for safe control design and safety verification for networked multi-agent systems. These algorithms rely on distributing a control barrier function (CBF) related quadratic programming (QP) problem. The proposed distributed algorithm addresses infeasibility issues of existing schemes by dynamically allocating auxiliary variables across iterations. The resulting control input is guaranteed to be optimal, and renders the system safe. Furthermore, a truncated algorithm is proposed to facilitate computational implementation, with probabilistically guaranteed constraint satisfication, while generating a Lipschitz continuous control input. We further develop a distributed safety verification algorithm to quantify safety for a multi-agent system by means of CBFs in probability. Both upper and lower bounds on the probability of safety are obtained using the so called scenario approach. Both the scenario sampling and safety verification procedures are fully distributed. The efficacy of our algorithms is demonstrated by an example on multi-robot collision avoidance.
\end{abstract}

\begin{IEEEkeywords}
Distributed Optimisation, Scenario Approach, Safe Control, Multi-Agent Systems, Nonlinear Systems
\end{IEEEkeywords}


\section{Introduction}
\label{sec:intro}
\IEEEPARstart{S}{afety} of a dynamical system requires the system state to remain in a safe set for all time. This property is important in many applications such as collision avoidance  \cite{ding2022configuration,wang2019moving}, vehicle platooning \cite{axelsson2016safety,alam2014guaranteeing}, vehicle merging control \cite{xiao2021decentralized}, etc. For a single agent system, safety is usually captured by introducing constraints on the state of the agent and the environment. For a multi-agent system, the meaning of safety extends to capture the interactions among agents. In this case, safety is encoded by coupling constraints over the states of a group of agents. For a networked multi-agent system, where agents cooperate to satisfy safety constraints, we consider designing distributed algorithms to ensure safety for all agents. 

Another problem of interest is to validate the proposed control law. For a single agent system, an agent can evaluate the system behaviour to characterize its risk of being unsafe under the employed control input. Similarly, for a multi-agent safety verification problem, cooperation among agents is necessary since safety involves multiple agents. In summary, this paper focuses on designing a distributed protocol for safe control input design and developing a distributed safety verification algorithm.

\subsection{Related Work}
Safety in control systems is often certified by control barrier functions (CBF), which is a type of control Lyapunov-like functions \cite{ames2016control,sontag1989universal,primbs1999nonlinear}. By enforcing the inner product of the CBF derivative and vector field of the controlled system to be bounded, safety is rigorously guaranteed at any time. CBF is shown to be powerful and scalable in control input design for control-affine systems, as this condition can be encoded as a linear constraint in a quadratic programming (QP) problem \cite{ames2016control}. By solving online QP problems for every state, the system can be guaranteed to be safe  \cite{hsu2015control,ames2014control}. Higher-order derivative based methods for high relative degree systems are proposed in \cite{xiao2019control,nguyen2016exponential,tan2021high}. In \cite{xiao2021adaptive}, adaptive coefficients are introduced to improve the feasibility of the CBF-QP. For the case where multiple CBFs exist, an optimal decay based method is proposed to tune the CBF constraints \cite{zeng2021safety}. CBFs for discrete time systems are proposed in \cite{agrawal2017discrete}. For the case where model uncertainty and system noise are added, robust CBF with worst case analysis \cite{nguyen2021robust, jankovic2018robust} can be considered. Most of the existing results in this direction involve a centralized approach; however, multi-agent considerations call for distributed solution regimes. In this paper we address the distributed safety problem for multi-agent systems.

Related to the problem considered in this paper, CBFs for multi-robot systems were studied in \cite{chen2020guaranteed,wang2017safety,borrmann2015control}. These works propose to split the CBF constraints into two components for neighbouring agents: the computation is therefore distributed as every agent solves a local optimisation problem. An improved constraint sharing mechanism is developed in \cite{xu2018constrained}, where the CBF constraints are dynamically tuned for compatibility. Optimality is further considered in \cite{tan2021distributed}, and a dynamical constraint allocation scheme among agents based on a consensus protocol is proposed. In our work, we aim at dealing with the problem of feasibility and optimality simultaneously, as well as considering multiple CBF constraints for safety. In essence, the distributed CBF-based safe control design problem can be seen under the lens of distributed optimisation. 

Distributed optimisation for a multi-agent system aims to design a distributed protocol that involves solving an optimisation problem locally for every agent. Algorithms can be divided into two types, dual decomposition based \cite{falsone2017dual,falsone2020tracking,shi2014linear,duchi2011dual} and primal decomposition based ones \cite{margellos2017distributed,camisa2021distributed,notarnicola2019constraint,li2020distributed,nedic2010constrained}. Dual decomposition methods consider the dual problem, where each agent maintains a local copy of the dual variables. Constraint satisfication is achieved by consensus over the dual variables. Primal decomposition methods directly decompose the primal problem into local problems. By local projection \cite{margellos2017distributed,li2020distributed,nedic2010constrained} or updating auxiliary variables \cite{camisa2021distributed,notarnicola2019constraint}, algorithms converge to  centralized optimum under convexity assumptions. Such methods guarantee near feasibility as far as the constraints of the primal problem are concerned. As our problem has the same structure with the one considered in \cite{camisa2021distributed,notarnicola2019constraint}, primal decomposition methods are leveraged. 

Another problem of interest in this work is safety verification. For a dynamical system, safety requires the trajectory to be within a safe set. Given the vector field, a target set and an unsafe set, solving a reach-avoid game \cite{margellos2011hamilton,lygeros2004reachability} yields a set from which all trajectories start can reach the target set without entering the unsafe set. In this sense, safety verification lies in the scope of reachability analysis. The main challenge here is how to solve the underlying Hamilton Jacobi partial differential equation. To bypass this difficulty, the barrier certificates method was proposed in a convex programming framework~\cite{prajna2004safety,prajna2007framework}. A barrier certificate identifies an invariant set inside the safe set. System trajectories cannot escape from the underlying invariant set, and this directly leads to safety. Numerical methods for verifying safety using barrier certificates with convex programs entails sum-of-squares (SOS) programs~\cite{prajna2002introducing,prajna2004sostools}, which are equivalent to semi-definite programs. In real applications, the system model and control input are usually not precisely known, or are even unknown. In this setup, another type of verification method \cite{akella2022barrier} using sampled data was proposed recently. Probabilistically guaranteed safety is ensured using the so called scenario approach \cite{campi2008exact,campi2018wait,calafiore2005uncertain,calafiore2006scenario,garatti2019risk}. 

% The scenario approach is a data-driven methodology for uncertain optimisation problems. By sampling independent scenarios from the uncertain set, the uncertain problem transforms into a certain one. The probability of violating the uncertain constraints can be characterized \cite{calafiore2005uncertain}. 

\subsection{Contributions}
Our first contribution is to provide a method for constructing a distributed, safe controller. The proposed algorithm offers a distributed implementation of solving a quadratic programming problem with CBF-based affine constraints \cite{ames2016control}. To parallelize the computation, we leverage the primal decomposition method presented in \cite{notarnicola2019constraint} to
decompose the coupling constraints via the introduction of auxiliary variables. In this way, each agent can solve a local optimisation problem with auxiliary variables iteratively, while the auxiliary variables are dynamically updated using the dual variables associated with the constraints. We also introduce additional relaxation variables for every CBF constraint to overcome incompatibility issues of multiple safety certificates, and avoid compromising the control ability. Compared with other methods in the literature, our approach offers feasibility and optimality guarantees.

In the original framework \cite{notarnicola2019constraint,camisa2021distributed}, asymptotic convergence is achieved for primal variables. Our method exhibits a linear convergence rate for the control input. This is realized by a properly determined quadratic term in every local cost function to enhance convexity and smoothness. The term is designed based only on a local tolerance parameter and local control ability for distributed computation. Moreover, the relaxation variables decrease monotonically across iterations until they reach the certain tolerance threshold. At a given state, the minimal number of iterations for reaching a given threshold can be calculated. The monotonicity and linear convergence results are rigorously analyzed. 

To reduce the communication and computation burden, an truncation mechanism is proposed to allow us to terminate the algorithm prior to convergence. The main challenge here is to determine the truncation parameter under the promise of safety. Using the obtained monotonicity result, the upper bound of the truncation parameter can be calculated by solving an uncertain optimisation problem. Such a problem poses difficulties in computation, and parallelization. To address these issues, we leverage the so called scenario approach \cite{campi2008exact,campi2018wait,calafiore2005uncertain,calafiore2006scenario,garatti2019risk}, which samples a number of independent states from the state space and enforces the constraint only at these realizations. The original program is therefore approximated by a certain convex optimisation problem. We show that the obtained upper bound is also feasible for unrealized states with certain probabilistic guarantees.

A further contribution is that of constructing a distributed safety verification algorithm. Here we address the problem of certifying safety for a multi-agent system. We propose to quantify safety by means of CBFs. At a given state, if the CBF constraints are violated, then the system is under the risk of being unsafe. Following this principle, we propose a scenario-based verification algorithm for a probabilistic quantification of safety. The scenarios, however, are hard to be sampled independently for a multi-agent system, due to the large cardinality of the uncertain set and the high coupling on each dimension. A sequential sampling algorithm is proposed to sample scenarios efficiently in a distributed fashion. For the probabilistic result, we extend the state-of-the-art result \cite[Theorem 1]{garatti2019risk} to a multi-agent setting. Both lower and upper bounds on the probability of being unsafe are established, while the safety verification program is also shown to be amenable to parallelization.

\subsection{Organization}
Section \ref{sec:dscl} proposes our distributed safe control design algorithm, including a truncated version and the associated mathematical analysis. Section \ref{sec:safetyverification} provides the distributed safety verification scheme, and the distributed scenario sampling algorithm. Section \ref{sec:simulation} demonstrates the control design and safety verification algorithms on a multi-robot system collision avoidance case study. Section \ref{sec:conc} concludes the paper and provides some directions for future research.

\subsection{Notation}
\label{sec:nota}
We use $\mathbb{R}$, $\mathbb{R}^N$, $\mathbb{R}_+$ to represent the space of one-dimensional, $N$-dimensional and nonnegative real numbers, respectively. $\mathbb{N}$ is the set of natural numbers. For matrices $A$ and $B$, $A\preceq B$ implies $B-A$ is positive semi-definite.
A continuous function $\alpha(\cdot):(-b,a)\to (-\infty,+\infty)$ is said to be an extended class-$\mathcal{K}$ function for positive $a$ and $b$, if it is strictly increasing and $\alpha(0)=0$. $\mathcal{G}=(\mathcal{V},\mathcal{E})$ denotes a graph with nodes set $\mathcal{V}$ and edge set $\mathcal{E}$. Throughout the paper $\mathcal{S}$ is used for a safe set, $\mathcal{X}$, $\mathcal{U}$ are used for general constraint sets over state and input, and $\mathcal{B}$ is used for an invariant set. Boldface symbols are used as stacked vectors for scalar or vector elements, e.g., $\boldsymbol{x}=[x_1^\top,\ldots,x_N^\top]^\top$. Specifically, $\boldsymbol{0}$ is vector whose elements are all zero, and $I$ is an identity matrix, with their dimensions being clear from the context. For a set $\mathcal{K}$, $|\mathcal{K}|$ denotes its cardinality. For a function $s(x):\mathbb{R}^n\to\mathbb{R}$, we use the calligraphic font to represent the corresponding zero-supper level set, i.e., $\mathcal{S}:=\{\boldsymbol{x}|s(\boldsymbol{x})\ge 0\}$.

% \subsection{Control Barrier Functions}
% Consider a nonlinear control-affine system
% \begin{equation}\label{eq:nonlnsys}
%     \dot x = f(x)+g(x)u,
% \end{equation}
% with $x(t) \in\mathbb{R}^n$, $u(t) \in\mathcal{U}\subset \mathbb{R}^m$, $f(x):\mathbb{R}^n\to\mathbb{R}^m,$ and $g(x):\mathbb{R}^n\to \mathbb{R}^{n\times m}$. Both $f$ and $g$ are further assumed to be Lipschitz continuous. Defining the solution of \eqref{eq:nonlnsys} to be $\psi(u,t,x_0)$, where $x_0$ represents the initial condition and $t$ denotes time, our goal is to design a state feedback control input $u(x)$ so that $\psi(u(x),t,x_0)$ stays within a given safe set $\mathcal{S}$ for any $t$. The existence and uniqueness of solutions $\psi(u(x),t,x_0)$ is assumed.  

% The safe set $\mathcal{S}$ is represented by the zero-super level set of a continuously differentiable function $s(x)$. Dually, the unsafe set $\bar{\mathcal{S}}$ can be defined as the complementary set. To ease the explanation we give the algebraic expressions of safe set $\mathcal{S}$, boundary of the safe set $\partial{\mathcal{S}}$, interior of the safe set $\mathrm{Int}(\mathcal{S})$ and unsafe set $\bar{\mathcal{S}}$:
% \begin{subequations}\label{eq:safe}
% \begin{align}
%     \mathcal{S}&:=\{x\in\mathbb{R}^N|s(x)\ge0\},\\
%     \partial{\mathcal{S}}&:=\{x\in\mathbb{R}^N|s(x)=0\},\\
%     \mathrm{Int}(\mathcal{S})&:=\{x\in\mathbb{R}^N|s(x)>0\},\\
%     \bar{\mathcal{S}}&:=\{x\in\mathbb{R}^N|s(x)<0\}.
% \end{align}
% \end{subequations}

% With this formulation, the safe control design problem boils down to finding $u(x)\in\mathcal{U}$, such that $s(\psi(u(x),t,x_0))\ge 0$ for any $t$. To achieve this, a control barrier function-based quadratic programming approach was proposed \cite{ames2016control}.

% Control Barrier functions are an extension to Barrier certificates \cite{prajna2004safety} for safety verification. It has been revealed in these papers that safety is closely related to the notion of \textit{forward invariance}.
% \begin{definition}\label{def:invariance}
% A set $\mathcal{B} \subset \mathbb{R}^n$ is said to be forward invariant with respect to vector field \eqref{eq:nonlnsys}, if for any $x_0\in\mathcal{B}$, there exists $u\in\mathcal{U}$ such that $\psi(u,t,x_0)\in\mathcal{B}$.
% \end{definition}
% The relationship between safety and forward invariance is demonstrated in the following equivalence lemma.
% \begin{lemma}\label{lem:safetyinvariance}
% System \eqref{eq:nonlnsys} is able to maintain safety under $\mathcal{S}$, if and only if there exists a forward invariant set $\mathcal{B}\subseteq\mathcal{S}$. 
% \end{lemma}
% Clearly, given a forward invariant set $\mathcal{B}$, a safe control input $u(x)$ always exists for any $x\in\mathcal{B}$. The control Barrier function approach answers the question of how to design a closed loop safe control input $u(x)$ inside $\mathcal{B}$, and how to guarantee the resulting safe control input is Lipschitz continuous. The notion of control barrier functions is related to  the notion of extended class-$\mathcal{K}$ functions.

% \begin{definition}
% For the control-affine dynamical system \eqref{eq:nonlnsys}, a continuously differentiable function $b(\cdot):\mathbb{R}^n\to \mathbb{R}$ is said to be a control Barrier function for the set $\mathcal{B}$, if there exists an extended class-$\mathcal{K}$ function $\alpha(\cdot)$ and a set $\mathcal{C}$, where $\mathcal{B}\subseteq\mathcal{C}\subset \mathbb{R}^n$, such that for any $x\in\mathcal{C}$,
% \begin{equation}\label{eq:cbf}
%   \mathop{\sup\limits_{u\in\mathcal{U}}}[\mathcal{L}_fb(x)+\mathcal{L}_gb(x)u+\alpha(b(x))]\ge0.
% \end{equation}
% Here $\mathcal{L}_fb(x)$ and $\mathcal{L}_gb(x)$ are Lie derivatives, which are defined by $\mathcal{L}_fb(x):=\frac{\partial b(x)}{\partial x}f(x)$ and $\mathcal{L}_gb(x):=\frac{\partial b(x)}{\partial x}g(x)$, respectively.
% \end{definition}
% Given a control barrier function $b(x)$, the control admissible set corresponding to \eqref{eq:cbf} is defined by
% \begin{equation}\label{eq:cbfset}
%     K_{cbf}(x):=\{u\in\mathcal{U}:\mathcal{L}_fb(x)+\mathcal{L}_gb(x)u+\alpha(b(x))\ge0\}.
% \end{equation}
% \begin{theorem}{\cite{ames2016control}}\label{th:theo1}
% Consider a control Barrier function $b(x)$ defined on $\mathcal{C}$. Then for any $x\in\mathcal{C}$, any $u(x)\in K_{cbf}(x)$ will render the set $\mathcal{B}$ forward invariant.
% \end{theorem}

% We note that the control barrier function $b(x)$ need generally not be the same function as $s(x)$, the synthesis problem is beyond the scope of this paper, readers are referred to \cite{wang2022safety} for details.

% \subsection{Multi-agent Optimisation Problem}
% A local distributed optimisation problem is the problem of finding a global optimum for an optimisation problem over a network of agents, where every agent has access to a local decision variable, and agents are coupled through the constraints.
% Unlike the usual setting, our problem involves two types of coupled constraints, i.e. \emph{pair-wise constraints} and \emph{group constraints}.

% Consider a networked system of $N$ agents communicating over a connected and undirected graph $\mathcal{G}$, with nodes set $\mathcal{V}=\{1,\ldots,N\}$, and edge set $\mathcal{E}$ such that $\{i,j\}\in\mathcal{E}$ if agent $j$ communicates with agent $i$. In addition to the pair-wise interaction relationship, agents are also grouped in $E$ sub-networks. For each sub-network $\mathcal{G}_e$, $e=1,\ldots,E$, the set of grouped agents is $\mathcal{V}_e \subseteq \mathcal{V}$. The multi-agent distributed optimisation problem that needs to be solved in a distributed manner can then be defined as
% \begin{equation}\label{eq:ldop}
%     \begin{split}
%         \min_{\boldsymbol{x}}&\sum_{i=1}^NJ_i(x_i)\\
%         \mathrm{subject~to}~&x_i\in\mathcal{X}_i,\forall i=1,\ldots,N,\\
%         &\sum_{k\in\mathcal{V}_e} h_{ke}(x_k)\le0,\forall e=1,\ldots,E,
%     \end{split}
% \end{equation}
% where for all $i=1,\ldots,N$, $x_i\in\mathbb{R}^{d_i}$ for some $d_i\in\mathbb{N}$. Also, $J_i(x_i):\mathbb{R}^{d_i}\to \mathbb{R}$. For all $k\in\mathcal{V}_e$, $h_{ke}:\mathbb{R}^{d_k}\mapsto \mathbb{R}$ stand for the group constraints that agents $k$ decisions need to satisfy. Variables $\mu_e\ge 0$ denotes the Lagrange multiplier associated with the inequality constraint $\sum_{k\in\mathcal{V}_e}h_{ke}(x_k)\le 0$. The function $h_{ke}(x_k)$ is not necessarily the same for every $k$ in the same sub-network. Our goal is to split \eqref{eq:ldop} into $N$ sub-problems of which the decision variables are only the local variables of each agent, thus enabling paralleled computation. 


% Agent $k$ may have no prior knowledge of function $h_{ke}(x_k)$, of which the expression is partially parameterized and determined by other agents in the group. This is because in our problem functions $h_{ke}(x_k)$ are determined by every agent in group $e$. To address this issue, we first \emph{assume} that agent $k$ has full knowledge of $h_{ke}(x_k)$. This assumption can be removed by transmitting some information other than the whole function expression in Section \ref{sec:dscl}.

% \subsection{Scenario Optimisation}
% Scenario optimisation is a data-driven robust optimisation methodology where one aims at searching for an optimum over uncertain sets. For the case where the uncertain sets are continuous, and possibly nonconvex or unknown, this kind of optimisation problem is usually hard to solve with guaranteed robustness. The scenario approach, on the other hand, proposes to solve the problem over finite empirical records, named \emph{scenarios} for a certain confidence of feasibility of the optimal solution. An uncertain optimisation problem is formulated as
% \begin{equation}\label{eq:uncertain}
% \begin{split}
%     \min_{x\in\mathcal{X}}~&c^\top x\\
%     \mathrm{subject~to}~&x\in\mathcal{X}_{\delta},~\text{for all}~\delta\in\Delta,
% \end{split} 
% \end{equation}
% where $x\in\mathbb{R}^n$ is a decision variable constrained by a convex set $\mathcal{X}\subseteq\mathbb{R}^n$, $c\in\mathbb{R}^n$ is a constant vector. The convex uncertain constraint set $\mathcal{X}_{\delta}$ is parameterized by an uncertain parameter $\delta$, which is a random variable defined on a probability space $(\Delta,\mathcal{F},\mathbb{P})$. As discussed above, directly solving the problem \eqref{eq:uncertain} involves addressing infinite constraints for continuous set $\Delta$. Alternatively, the scenario approach proposes to solve the problem by encoding the constraint only on scenarios.

% The corresponding prototype convex scenario optimisation problem is formulated as

% \begin{equation}\label{eq:scenario}
% \begin{split}
%     \min_{x\in\mathcal{X}}~&c^\top x\\
%     \mathrm{subject~to}~&x\in\bigcap_{i=1,\ldots,N}\mathcal{X}_{\delta_i},
% \end{split} 
% \end{equation}
% where $\delta_i$, $i=1,\ldots,N$ are \emph{scenarios} sampled independently from the uncertain set $\Delta$. The scenario optimisation \eqref{eq:scenario} is a convex optimisation problem which can be solved efficiently. Clearly, the optimal solution $x_N^*\in\bigcap_{i=1,\ldots,N}\mathcal{X}_{\delta_i}$, but is not necessarily within $\mathcal{X}_\delta$ for an arbitrary new $\delta\in\Delta$. The following definition of violation probability comes along with the result.
% \begin{definition}[violation probability]
%     The violation probability of a a given $x\in\mathcal{X}$ is defined as $V(x)=\mathbb{P}\{\delta\in\Delta:x\notin\mathcal{X}_\delta\}$.
% \end{definition}




% \section{Distributed Optimisation Protocol}
% \label{sec:dop}
% In this section we show how to split \eqref{eq:ldop} into $N$ sub-problems which only require local computation for each agent. Problem \eqref{eq:ldop} has a separable structure but coupling constraints are also presented. For the purposes of distributed computation, one idea is to substitute the neighbours' contributions to the coupling constraints by dynamically allocated resources, which are auxiliary variables in the computation.

% \begin{algorithm}[h]
%   \caption{Local Constrained Relaxation Splitting (LCRS) Algorithm for agent $i$}
%   \hspace*{\algorithmicindent} \textbf{Initialization} Predefined $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$.\\
%  \hspace*{\algorithmicindent} \textbf{Output:} Optimal solution $x_i^*$.\\
%  \vspace{-3ex}
%   \begin{algorithmic}[1]\label{al:dcbf}
%   \WHILE{Not reaching convergence}
%   \STATE \textbf{Receive} \label{step:firstcommunication} $\lambda_{il}^k$ from $\forall l\in\mathcal{N}_i\cap \mathcal{V}_e,\forall e\in\mathcal{C}_i$.
%   \STATE \label{step:firstcomputation} \textbf{Compute} $((x_i^{k+1},\boldsymbol{\rho}^{k+1}_i),\boldsymbol{\mu}^{k+1}_i)$ as a primal-dual solution of the following optimisation problem.
%   \begin{equation}\label{eq:problem}
%       \begin{split}
%           \min_{x_i,\boldsymbol{\rho}_i}~&J_i(x_i) +\sum_{e\in\mathcal{C}_i} M_{i}\rho_{ie}\\
%           \mathrm{subject~to}~&x_i\in\mathcal{X}_i,\boldsymbol{\rho}_i\ge0,\\
%           &h_{ie}(x_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie},\forall e\in\mathcal{C}_i.
%       \end{split}
%   \end{equation}
%   \STATE \textbf{Receive} \label{step:secondcommunication} $\mu_{le}^{k+1}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$.
%   \STATE \textbf{Update} \label{step:secondcomputation} $\lambda_{il}$ by 
%   \begin{align}\label{eq:subupdate}
%       &\lambda_{il}^{k+1}=\lambda_{il}^k-\gamma^k(\mu_{ie}^{k+1}-\mu_{le}^{k+1}).
%   \end{align}
%   \ENDWHILE
%   \end{algorithmic}
% \end{algorithm}

% \begin{proposition}[Adapted from \cite{notarnicola2019constraint}]\label{pro:lowerbound}
% Consider \eqref{eq:ldop} and denotes its minimizer by $\boldsymbol{x}^*_{\mathrm{cen}}$. The optimal solution returned by Algorithm \ref{al:dcbf} for agents $1,\ldots,N$ is denoted by $\boldsymbol{x}^*_{\mathrm{dis}}$. Then $\boldsymbol{x}^*_{\mathrm{dis}}=\boldsymbol{x}^*_{\mathrm{cen}}$ if $M_{i}\ge \mu_e$, for any $e=1,\ldots,E$, and $i\in\mathcal{V}_e$.
% \end{proposition}


\section{Distributed Safe Control Law}
\label{sec:dscl}
% After proposing \eqref{eq:ldop} and its distributed solution, we are now in a position to use the proposed algorithm for \emph{distributed safe control input design}. 

Consider an $N$-agent system with the dynamics of the $i$-th agent described by
\begin{equation}\label{eq:dynamics}
    \dot x_i=f_i(x_i)+g_i(x_i)u_i,
\end{equation}
where $x_i(t)\in\mathcal{X}_i\subset\mathbb{R}^{n_i}$ denotes its state, $u_i\in\mathcal{U}_i\subset\mathbb{R}^{m_i}$ denotes its control input, while $\mathcal{X}_i$ and $\mathcal{U}_i$ are the state space and control admissible set, respectively. The dynamics $f_i(x_i):\mathbb{R}^{n_i}\to\mathbb{R}^{n_i}$ and $g_i(x_i):\mathbb{R}^{n_i}\to\mathbb{R}^{n_i}\times\mathbb{R}^{m_i}$ are both locally Lipchistz-continuous. Vector $\boldsymbol{x}=[x_1^\top,\ldots,x_N^\top]^\top$ stacks the states of all systems, $\boldsymbol{u}=[u_1^\top,\ldots,u_N^\top]^\top$ stacks the control inputs, while $f(\boldsymbol{x})$, $g(\boldsymbol{x})$ stack the dynamics for each agent. In this way, the system dynamics of the whole multi-agent system can be compactly modelled by $\dot{\boldsymbol{x}}=f(\boldsymbol{x})+g(\boldsymbol{x})\boldsymbol{u}$.

The networked system is described by an undirected graph $\mathcal{G}$, with nodes set $\mathcal{V}=\{1,\ldots,N\}$, and edges set $\mathcal{E}$ such that $\{i,j\}\in\mathcal{E}$ if agent $j$ communicates with agent $i$. Agents are grouped in $E$ sub-networks with specific safety requirement. For each sub-network $\mathcal{G}_e$, $e=1,\ldots,E$, the set of grouped agents is $\mathcal{V}_e \subseteq \mathcal{V}$. Each agent $i$ can communicate and cooperate with its neighbour $j\in\mathcal{N}_i$ to stay safe inside group $e$ by ensuring $s_e(\boldsymbol{x}_e)\ge 0$, where $s_e(\cdot)\in\mathbb{R}$. We let $\mathcal{C}_i$ to be the set of group constraints agent $i$ participates in; then we have $\mathcal{V}_e=\{i|e\in\mathcal{C}_i\}$. 

\begin{assumption}[Connectivity]
For each $e=1,\ldots,E$, sub-network $\mathcal{G}_e$ is connected and undirected.
\end{assumption}

% i) \emph{Pair-wise safe}: For the sub-network $\mathcal{G}_e$ that has only pair-wise  neighbourhood agents inside, take agent $i$ and one of its neighbours $j\in\mathcal{N}_i$ for example. Such safety is captured by a safe function $s_{ij}(x_i,x_j)$, and a corresponding pre-synthesized CBFs $b_{ij}(x_i,x_j)$. Here we have that $s_{ij}(x_i,x_j)\ne s_{ji}(x_j,x_i)$, but $b_{ij}(x_i,x_j)=b_{ji}(x_j,x_i)$. This assumption is reasonable even for heterogeneous multi-agent system, where each agent can have different dynamics, control ability and safety requirement. Take the mobile robotics applications for example, the safety requirement is described by different safe distances. For example, the safe functions $s_{ij}(x_i,x_j)=||x_i-x_j||_2^2-\mathrm{dist}_i$ and $s_{ji}(x_j,x_i)=||x_j-x_i||_2^2-\mathrm{dist}_j$, and $\mathrm{dist}_i\ne\mathrm{dist}_j$. Correspondingly, the safe set is defined by $\mathcal{S}_{ij}:=\{x|s_{ij}(x)\ge 0\}$, and $\mathcal{S}_{ji}:=\{x|s_{ji}(x)\ge 0\}$. The barrier function, on the other hand captured the characteristic of both the two functions and agents. In practice, the barrier function $b_{e}(x_i,x_j)$ is synthesized by the two agents cooperatively. The invariant sets $\mathcal{B}_{e}$ is then defined correspondingly.
% The type of safety considered in this paper is inner safety, which is commonly seen in connected vehicle systems and robotic manipulators. Take three connected vehicles as an example, we have three vehicles $i,j,l$ in a sub-network $\mathcal{G}_e$, where vehicle $j$ and $l$ are connected to maintain a constant distance. The safety for this group is that vehicle $i$ needs to stay away from the centroid of the segment connecting $j$ and $l$. Clearly, the corresponding safe function has the form of $s_e(x_i,x_j,x_l)=||x_i-(x_j+x_l)/2||_2^2-D_e$, where $D_e$ is a constant. The safe set is therefore defined by $\mathcal{S}_{e}:=\{x|s_{e}(x_i,x_j,x_l)\ge 0\}$. The safety related CBF is denoted by $b_{e}(x_i,x_j,x_l)$, and encode an invariant set $\mathcal{B}_{e}$. A uniform representation for the group CBF is $b_{e}(\boldsymbol{x})$.

The overall invariant (safe) set is defined by the Cartesian intersection of all the individual safe (invariant) sets 
\begin{subequations}\label{eq:invariantset}
\begin{equation}\label{eq:invariantset1}
    \mathcal{B}=\bigcap_{e=1}^E\mathcal{B}_{e}.
\end{equation}
\begin{equation}\label{eq:invariantset2}
    \mathcal{S}=\bigcap_{e=1}^E\mathcal{S}_{e}.
\end{equation}
\end{subequations}

% \begin{assumption}\label{ass:direvative}
% For any $\boldsymbol{x}\in\mathcal{B}$ $e=1,\ldots,E$, and $i\in\mathcal{V}_e$ the CBFs $b_e(\boldsymbol{x})$ satisfy
% \begin{equation}\label{eq:bound}
%   G_{\min}I\preceq\frac{\partial b_e(\boldsymbol{x})}{\partial x_i}g_i(x_i)^\top\left(\frac{\partial b_e(\boldsymbol{x})}{\partial x_i}g_i(x_i)\right)\preceq G_{\max}I,
% \end{equation}
% \end{assumption}
% where $G_{\min}$ and $G_{\max}$ are positive numbers. The lower bound $G_{\min}I$ guarantees that the CBFs are all of relative degree one, and there is no singular point exist in the invariant set $\mathcal{B}$. Cases of high degree and singular points \cite{xiao2019control,tan2021high} are omitted in this paper, but our result can be easily extended. The upper bound $G_{\max}I$ is a reasonable assumption such that the derivative $\frac{\partial b_e}{\partial x_i}$, and dynamics $g_i(x_i)$ are both bounded for any $i=1,\ldots,N$ and $e=1,\ldots,E$.

% \begin{assumption}\label{ass:safety}
% The networked system \eqref{eq:dynamics} is able to maintain safety in safe set $\mathcal{S}$ \eqref{eq:invariantset2}.
% \end{assumption}

The following proposition guarantees the existence of the invariant set $\mathcal{B}$ retrieved from $\mathcal{S}$ by the way in \eqref{eq:invariantset1}.

\begin{proposition}\label{prop:existenceofinvariant}
For the networked system \eqref{eq:dynamics} and the safe set \eqref{eq:invariantset2}, there exists an invariant set $\mathcal{B}\subseteq\mathcal{S}$. Furthermore, for any invariant set $\mathcal{B}\subseteq{\mathcal{S}}$, there exists a series of invariants set $\mathcal{B}_e\in\mathcal{S}_e$, for $e=1,\ldots,E$, such that \eqref{eq:invariantset1} holds.
\end{proposition}
\begin{proof}
From \cite[Lemma 1]{wang2022safety}, there always exists a invariant set ${\mathcal{B}}\subseteq\mathcal{S}$. From the definition of $\mathcal{S}$ in \eqref{eq:invariantset2}, we have that ${\mathcal{B}}\subseteq\mathcal{S}_{e}$, for any $e=1,\ldots,E$. Using \cite[Lemma 1]{wang2022safety} again, it is always possible to retrieve a maximal invariant set $\mathcal{B}_{e}$, from $\mathcal{S}_{e}$, with $\mathcal{B}_{e}\subseteq\mathcal{S}_{e}$ for any $e=1,\ldots,E$. Suppose there exists an invariant set ${\mathcal{B}}\not\subseteq \mathcal{B}_{e}$. This establishes a contradiction as in this case ${\mathcal{B}}\cup\mathcal{B}_{e} \supset \mathcal{B}_e$ would also be invariant, contradicting the assumption that $\mathcal{B}_{e}$ is the maximal invariant set. Then we conclude that $\forall e=1,\ldots,E$, $\mathcal{ B}\subseteq\mathcal{B}_{e}$, thus establishing \eqref{eq:invariantset1}.
\end{proof}

% which is calculated by solving a local optimal control problem:
% \begin{align}\label{eq:optimalcontrol}
%       u_i^{\mathrm{des}}(x_i)=\mathop{\arg\min}_{u_i\in\mathcal{U}_i}&\int_0^\infty (e_i^\top Qe_i+u_i^\top Ru_i)dt\nonumber\\
%       \mathrm{s.t.}~&\dot x_i=f_i(x_i)+g_i(x_i)u_i,\nonumber\\
%       &e_i=x_i-x_i^{\mathrm{des}},
% \end{align}
% where we assume that the minimizer is unique. Here $x_i^{\mathrm{des}}$ is a predefined destination for agent $i$. 

Following \cite[Proposition 3]{ames2016control}, safety constraints can be incorporated in the CBF-QP formulation given by
\begin{equation}\label{eq:centralizedqp}
    \begin{split}
        \min_{u_i\in\mathcal{U}_i}&\sum_{i=1}^N ||u_i-u_i^{\mathrm{des}}(x_i)||_2^2\\
                \text{s.t.} &\sum_{k\in\mathcal{V}_e}\left\{\frac{\partial b_{e}}{\partial x_k}(f_k(x_k)+g_k(x_k)u_k)+\alpha_{ke}(b_{e})\right\}\ge 0,\\
        &\forall e=1,\ldots,E,
    \end{split}
\end{equation}
where $\alpha_{ke}(\cdot)$ (and hence also $\sum_{k\in\mathcal{V}_e}\alpha_{ke}(\cdot)$ is also a class-$\mathcal{K}$) are class-$\mathcal{K}$ functions, while $u_i^{\mathrm{des}}(x_i)$ is a nominal stabilizing control input. Let
\begin{equation}\label{eq:substi}
    \begin{split}
       J_i(u_i)&=||u_i-u_i^{\mathrm{des}}(x_i)||_2^2, \\
       h_{ie}(u_i)&=-\left(\frac{\partial b_{e}}{\partial x_i}(f_i(x_i)+g_i(x_i)u_i)+\alpha_{ie}(b_{e})\right).\\
    \end{split}
\end{equation}
Notice that, even not shown explicitly, $h_{ie}(u_i)$ depends on $x_i,i\in\mathcal{V}_e$. Communication between neighbouring agents is thus necessary for constructing $h_{ie}(u_i)$ in the optimisation problem. We also highlight that \eqref{eq:centralizedqp} is parameterized in $\boldsymbol{x}$, which can be thought of as constant as for the optimisation in \eqref{eq:centralizedqp} is concerned. For any $e=1,\ldots,E$, and $i\in\mathcal{V}_e$, there exists class-$\mathcal{K}$ functions $\alpha_{ie}(\cdot)$ such that the CBF-QP problem \eqref{eq:centralizedqp} is feasible for any $\boldsymbol{x}\in\mathcal{B}$ \cite[Proposition 3]{ames2016control}. 

\subsection{Full Control Law}
We now design an algorithm to solve the centralized CBF-QP problem \eqref{eq:centralizedqp} in a distributed manner; see Algorithm \ref{al:dcbf}.
\begin{algorithm}[h]
  \caption{Distributed Safe Control Design Algorithm for agent $i$ at $x_i$}
   \hspace*{\algorithmicindent} \textbf{Initialization} $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$ pre-defined.\\
   \hspace*{\algorithmicindent} \textbf{Receive} $x_k$ for any $k\in\mathcal{V}_e\backslash i$ from $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
    \hspace*{\algorithmicindent} \textbf{Send} $x_i$ to any $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$.\\
 \hspace*{\algorithmicindent} \textbf{Output:} Optimal control input $u_i^*$\\
 \vspace{-3ex}
  \begin{algorithmic}[1]\label{al:dcbf}
  \WHILE{Not reaching convergence}
  \STATE \textbf{Receive} \label{step:firstcommunication} $\lambda_{il}^k$ from $\forall l\in\mathcal{N}_i\cap \mathcal{V}_e,\forall e\in\mathcal{C}_i$.
  \STATE \label{step:firstcomputation} \textbf{Solve} $((u_i^{k+1},\boldsymbol{\rho}_i^{k+1}),\boldsymbol{\mu}_i^{k+1})$ as a primal-dual solution of the following optimisation problem
  \begin{equation}\label{eq:dcbf}
      \begin{split}
          \min_{u_i,\boldsymbol{\rho}_i}~&J_i(u_i) +\sum_{e\in\mathcal{C}_i}(\rho_{ie}^2+ M_{i}\rho_{ie})\\
          \mathrm{s.t.}~&u_i\in\mathcal{U}_i,\rho_{ie}\ge0,\\
          &h_{ie}(u_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie},\forall e\in\mathcal{C}_i.
      \end{split}
  \end{equation}
  \STATE \textbf{Receive} \label{step:secondcommunication} $\mu_{le}^{k+1}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$.
  \STATE \textbf{Update} \label{step:secondcomputation} $\lambda_{il}$ by   
  \begin{align}\label{eq:trunsubupdate}
      &\lambda_{il}^{k+1}=\lambda_{il}^k-\gamma(\mu_{ie}^{k+1}-\mu_{le}^{k+1}).
  \end{align}
  \ENDWHILE
  \end{algorithmic}
\end{algorithm}
Since $h_{ie}(u_i)$ also depends on $x_k$ for $k\in\mathcal{V}_e\backslash \{i\}$, an additional communication round at the beginning of the algorithm is designed. For all $i=1,\ldots,N$, and $e\in\mathcal{C}_i$, agent $i$ is to receive $x_k$ for any $k\in\mathcal{V}_e\backslash \{i\}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$. Within a finite number of communication rounds, agent $i$ can gather all the other agents' states in sub-networks $e\in\mathcal{C}_i$. Then, for any $e\in\mathcal{C}_i$, functions $h_{ie}(u_i)$ can be constructed as in \eqref{eq:substi}.

There are two main computation and two communication steps in the algorithm. In the first computation step (Step \ref{step:firstcomputation}), agent $i$ solves the optimisation problem \eqref{eq:dcbf} to obtain the optimal primal-dual solution $((x_i^{k+1},\boldsymbol{\rho}^{k+1}_i),\boldsymbol{\mu}^{k+1}_i)$, where $\boldsymbol{\rho}_i$ includes relaxation variables denoted by $\rho_{ie}$ (penalized in the cost by $M_{i}>0$), and $\boldsymbol{\mu}_i$ includes the dual variables $\mu_{ie}$, for all $e\in\mathcal{C}_i$ and $l\in\mathcal{N}_i\cap\mathcal{V}_e$. In practice, $\mu_{ie}$ corresponds to the group constraints allocated to agent $i$, i.e. $h_{ie}(x_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie}$. Moreover, the group constraints in the distributed problem \eqref{eq:dcbf} are relaxed by an additional nonnegative relaxation variable $\rho_{ie}$. This guarantees the feasibility of the local optimisation problem by loosing the restriction of the original constraints. The possible infeasibility without relaxations happens if $\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)>\sup_{x_i\in\mathcal{X}_i}-h_{ie}(x_i)$, the constraint $h_{ie}(x_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le 0$ might not be satisfied. The interpretation of this kind of infeasibility in CBF-QP application is that, there is no admissible control input that renders the system safe with the CBFs and auxiliary variables.

The first computation step uses auxiliary variables $\lambda_{il}^k$ and $\lambda_{li}^k$ which constitute estimates of the neighbouring terms $h_{le}(x_l)$. Among all these variables, $\lambda_{le}^k$ for $l\in\mathcal{N}_i\cap\mathcal{V}_e$ are updated and stored by neighbours. They are available by agent $i$ via communication in Step \ref{step:firstcommunication}. We note here that for all $l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\lambda_{il}$ and $\lambda_{li}$ are all scalars, hence the communication burden will not be high. 
The second computation step is to update the local auxiliary variables by means of \eqref{step:secondcomputation}. Part of the dual variables used in the update are received from the neighbours in the second communication round, i.e. Step \ref{step:secondcommunication}. Here the update is a gradient-like procedure, with stepsize $\gamma>0$. The dual variables will be bounded provided that the auxiliary variables are also bounded. 
%This is evident by evaluating the KKT equations, and analyzing the activeness of the constraints around the optimal solution.

Algorithm \ref{al:dcbf} is fully distributed, where the two computation and communication steps can be carried out locally by each agent. Differently from the setting in \cite[Algorithm RSDD]{notarnicola2019constraint}, the relaxation penalty in the cost includes now a quadratic term. This renders the cost function strongly convex, allowing for superior convergence properties and ensuring the minimizer $u_i^*$ is unchanged. These properties are illustrated in the following lemma.

\begin{lemma}\label{lem:newproperty}
Consider problem \eqref{eq:centralizedqp} and denote its minimizer by $\boldsymbol{u}_{\mathrm{cen}}^*(\boldsymbol{x})$. The optimal control input returned by Algorithm \ref{al:dcbf} is denoted by $\boldsymbol{u}_{\mathrm{dis}}^*(\boldsymbol{x})$. Then $\boldsymbol{u}_{\mathrm{dis}}^*(\boldsymbol{x})=\boldsymbol{u}_{\mathrm{cen}}^*(\boldsymbol{x})$ if
\begin{equation}\label{eq:lem2eq1}
    M_{i}\ge\mu_{e},\forall i\in\mathcal{V}_e, \forall e=1,\ldots,E.
\end{equation}
Besides, the overall cost function $J(\boldsymbol{u},\boldsymbol{\rho})=\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}(\rho^2_{ie}+M_{i}\rho_{ie})\right\}$ is strongly convex and has a Lipschitz continuous gradient.
\end{lemma}

We directly have the following \emph{optimality} and \emph{safety} results; the proof follows from Proposition \ref{prop:existenceofinvariant}.
\begin{theorem}\label{th:safety}
For every $\boldsymbol{x}\in\mathcal{B}$, the optimal distributed control input $\boldsymbol{u}^*(\boldsymbol{x})$ returned by Algorithm \ref{al:dcbf} coincides with the optimal centralized control input solved using \eqref{eq:centralizedqp}. Besides, the optimal distributed control input renders $\mathcal{B}$ invariant.
\end{theorem}

Among different types of distributed optimisation algorithms, \cite[Algorithm RSDD]{notarnicola2019constraint} is selected here for its ability to guarantee almost-safety in iterations. This is realized by allocating the auxiliary variables $\boldsymbol{\lambda}$, while balancing the safety requirement to every agent. We say ``almost" here since additional relaxation variables are introduced in every local optimisation problem for feasibility. In high-frequency applications, the algorithm may stop before reaching convergence. When the relaxation variables $\boldsymbol{\rho}^k=0$ for a $k>0$, then for any $e=1,\ldots,E$ we have that
\begin{equation*}
\begin{split}
    &\sum_{i\in\mathcal{V}_e}h_{ie}(u_i^k)=\sum_{i\in\mathcal{V}_e}\underbrace {\left\{h_{ie}(u_i^k)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\right\}}_{ \le 0}\le 0,
\end{split}
\end{equation*}
which implies that the CBF constraints are satisfied with any control input solving \eqref{eq:dcbf} at iteration $k$.

For each state $\boldsymbol{x}$, let
\begin{subequations}\label{eq:quantities}
\begin{align}
    \rho_{\mathrm{sum}}^k&=\sum_{i=1}^N\sum_{e\in\mathcal{C}_i}\left((\rho_{ie}^k)^2+M_i\rho_{ie}^k\right),\label{eq:quan2}\\
    P_i&=\sup_{u_i\in\mathcal{U}_i}||u_i-u_i^{\mathrm{des}}(\boldsymbol{x})||^2.\label{eq:quan3}
\end{align}
\end{subequations}
The next theorem gives the convergence result, and further points out a monotonicity property of the relaxation variables. 

\begin{theorem}\label{th:speed}
Consider Algorithm \ref{al:dcbf}. There exists $\theta\in(0,1)$, such that for any $\epsilon_1,\ldots,\epsilon_N>0$, and $k\in\mathbb{N}$, if
\begin{subequations}\label{eq:parameterselection}
\begin{align}
    \sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^k)^2}{M_i}+\rho_{ie}^k)>\epsilon_i,\forall i=1,\ldots,N,\label{eq:para1}\\
    \frac{P_i}{M_i}<\frac{1-\theta}{\theta}\epsilon_i,\forall i=1,\ldots,N,\label{eq:para2}
\end{align}
\end{subequations}
then $0\le\rho_{\mathrm{sum}}^{k+1}<\rho_{\mathrm{sum}}^k$.
\end{theorem}

Note that $\theta,\rho_{\mathrm{sum}}^k$, $\rho_{\mathrm{sum}}^{k+1}$, $u_i^k$, $u_i^{k+1}$ are functions of $\boldsymbol{x}$. We drop the arguments for simplicity.  
Theorem \ref{th:speed} establishes that under tolerance $\epsilon_1,\ldots,\epsilon_N$, $\rho_{\mathrm{sum}}$ decreases monotonically when parameters $M_i$, $i=1,\ldots,N$ satisfy \eqref{eq:parameterselection}. The requirement of $M_i$ in Lemma \ref{lem:newproperty} is consistent with that of \eqref{eq:parameterselection}. With large enough $M_i$, \eqref{eq:para1} is approximated by $\sum_{e\in\mathcal{C}_i}\rho_{ie}^k>\epsilon_i$, which represents the case that the local control law $u_i$ violates the CBF constraint by at least $\epsilon_i$, while \eqref{eq:para2} and \eqref{eq:lem2eq1} hold. 

%We note here that it is $\rho_{\mathrm{sum}}$ but not every $\rho_{ie}$ that is necessary to decrease in every iteration. However, for any $e=1,\ldots,E$, for all $i\in\mathcal{V}_e$, $\nabla_{\rho_{ie}}\rho_{\mathrm{sum}}>0$, and $\lim_{\boldsymbol{\rho}\to 0}\rho_{\mathrm{sum}}= 0$, which indicates that the solution $\boldsymbol{u}^k$ can become feasible across iterations. 

For a general strongly convex and smooth cost function, Algorithm \ref{al:dcbf} only guarantees asymptotic convergence \cite{notarnicola2019constraint}. However, our problem is a strictly convex quadratic program, where the dual function, and the dual of the dual function are both strongly convex and smooth. Thus, the cost $\sum_{i=1}^NJ_i(x_i) +\sum_{e\in\mathcal{C}_i} (M_i\rho_{ie}+\rho_{ie}^2)$ converges to the optimum $\sum_{i=1}^NJ_i(u_i^*) +\sum_{e\in\mathcal{C}_i}( M_i\rho_{ie}^*+(\rho_{ie}^*)^2)=\sum_{i=1}^NJ_i(u_i^*)$ with linear convergence rate. However, this does not necessarily lead to a decrease of the relaxation variables across iterations, since $J_i(u_i^k)$ also appears in the cost. The following corollary further investigates the evolution of $\rho_{\mathrm{sum}}^k$.

\begin{corollary}\label{co:convergence}
Assume \eqref{eq:para2} holds for $\epsilon_1,\ldots,\epsilon_N >0 $, and $M_1,\ldots,M_N>0$ and in addition:
\emph{Case I}:
\begin{equation}\label{eq:coro2assum1}
    \sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^0)^2}{M_i}+\rho_{ie}^0)>\epsilon_i,\forall i=1,\ldots,N.
\end{equation}
Then, for all $k\in\mathbb{N}$, $\rho_{\mathrm{sum}}^k$ satisfies
\begin{equation}\label{eq:coro2eq1}
    \rho_{\mathrm{sum}}^k\le\mathrm{max}\left\{\sum_{i=1}^NM_i\epsilon_i,\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i\right\}.
\end{equation}
Moreover, $\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^N P_i$ decreases monotonically and 
\begin{equation}\label{eq:coro2eq2}
    \lim_{k\to\infty}\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i<\sum_{i=1}^NM_i\epsilon_i.
\end{equation}

\emph{Case II}:
\begin{equation}\label{eq:coro2assum2}
    0\le\sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^0)^2}{M_i}+\rho_{ie}^0)\le \epsilon_i,\forall i=1,\ldots,N.
\end{equation}
Then for all $k\in\mathbb{N}$,  $\rho_{\mathrm{sum}}^k$ satisfies
\begin{equation}\label{eq:coro2eq3}
    \rho_{\mathrm{sum}}^k\le \sum_{i=1}^NM_i\epsilon_i.
\end{equation}
\end{corollary}


Conditions \eqref{eq:parameterselection}, \eqref{eq:coro2assum1}, \eqref{eq:coro2assum2} are all distributed, hence $M_i$, $i=1,\ldots,N$ can be designed by agents locally. 



\subsection{Truncated Control Law}
Algorithm \ref{al:dcbf} can be implemented in a distributed fashion with ensured safety and optimality properties, however, it may not be suitable for control tasks that require high actuation frequency, i.e. multi-robot system control, as its theoretical properties are established in an asymptotic manner. This motivates the use of a \emph{truncated algorithm}, Algorithm \ref{al:truncated}, where the algorithm is interrupted after a finite number of iterations, denoted by $\eta$.

\begin{algorithm}[h]
  \caption{Truncated Distributed Safe Control Design Algorithm for agent $i$}
   \hspace*{\algorithmicindent} \textbf{Initialization} Predefined $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$, truncated parameter $\eta\in\mathbb{N}$\\   \hspace*{\algorithmicindent} \textbf{Receive} $x_k$ for any $k\in\mathcal{V}_e\backslash i$ from $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
    \hspace*{\algorithmicindent} \textbf{Send} $x_i$ to any $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
 \hspace*{\algorithmicindent} \textbf{Output:} Optimal control input $u_i^*$\\
 \vspace{-3ex}
  \begin{algorithmic}[1]\label{al:truncated}
  \WHILE{$k\le \eta$}
  \STATE steps 2, 3, 4 in Algorithm \ref{al:dcbf}
  \ENDWHILE
  \STATE step 5 in Algorithm \ref{al:dcbf}
  \end{algorithmic}
\end{algorithm}
The following theorem shows how to decide on a value for $\eta$ to meet the desired tolerances $\epsilon_1,\ldots,\epsilon_N$. To reduce conservatism we do this in a probabilistic manner, where we sample scenarios $\boldsymbol{x}^{(r)},r=1,\ldots,\bar N$, independently from some distribution $\mathbb{P}$ and choose $\eta$ on the basis of these samples. Moreover, we support this choice with a probabilistic certificate on its effect on $\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})$.

\begin{theorem}\label{th:confidence}
Consider $\bar N$ i.i.d. samples $\boldsymbol{x}^{(r)}\in\mathcal{B}$, $r=1\ldots,\bar N$, extracted from some probability distribution $\mathbb{P}$, and let $\bar X = \{\boldsymbol{x}^{(1)},\ldots,\boldsymbol{x}^{(r)}\}$. For all $i=1,\ldots,N$, let
\begin{equation}\label{eq:localupperbound}
    \tilde{\epsilon_i}=\sup_{r=1,\ldots,\bar N}\sum_{e\in\mathcal{C}_i}\left(\frac{(\rho_{ie}^0(\boldsymbol{x}^{(r)}))^2}{M_i}+\rho_{ie}^0(\boldsymbol{x}^{(r)})\right).
\end{equation}
For $\epsilon_1,\ldots,\epsilon_N$ with $\epsilon=\sum_{i=1}^NM_i\epsilon_i$, choose $K_1,\ldots,K_N$ such that \eqref{eq:parameterselection} holds. For each $r=1,\ldots,\bar{N}$, $i=1,\ldots,r$  select
\begin{equation}\label{eq:localtruncation}
    \eta_i(x_i^{(r)}) \in \mathop{\arg\min}\limits_{\eta_i\in\mathbb{N}}\left\{\theta^{\eta_i}M_i \tilde{\epsilon_i}+\frac{\theta-\theta^{\eta_i+1}}{1-\theta}P_i\le M_i\epsilon_i\right\},
\end{equation}
where $\theta$ is a function of $\boldsymbol{x}$. Let $\eta = \max\limits_{\boldsymbol{x}^{(r)}\in\bar X}\{\eta_1,\ldots,\eta_N\}$. Fix confidence parameters $\beta_1,\ldots,\beta_N\in(0,1)$ with $\sum_{i=1}^N\beta_i= 1$. Then we have:
\begin{equation}\label{eq:trunprobability}
\begin{split}
    &\mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})>\epsilon\right\}\ge 1-\sum_{i=1}^N\sqrt[\bar N-1]{1-\beta_i}\right\}\\
    &\ge 1-\sum_{i=1}^N\beta_i.
\end{split}
\end{equation}
\end{theorem}

% \begin{solution}[Deterministic Solution]\label{sol:certain}
% To satisfy \eqref{eq:inequality} for any $\boldsymbol{x}\in\mathcal{B}$, from the monotonicity results in Theorem \ref{th:speed} and Corollary \ref{co:convergence}, it is directly necessary to find $\tilde\epsilon$ such that
% \begin{equation}\label{eq:inequality2}
%         \rho_{\mathrm{sum}}^{0}(\boldsymbol{x})\le \tilde \epsilon.
% \end{equation}
% for any $\boldsymbol{x}\in\mathcal{B}$. Upon determining the upper bound $\sup_{\boldsymbol{x}\in\mathcal{B}}\rho_{\mathrm{sum}}^{0}(\boldsymbol{x})$, select $\tilde \epsilon>\sup_{\boldsymbol{x}\in\mathcal{B}}\rho_{\mathrm{sum}}^{0}(\boldsymbol{x})$, pick $\delta\in(0,{\epsilon})$ and $K_1,\ldots,K_N$ such that $\sum_{i=1}^N\frac{P_i}{M_i}<\frac{1-\theta}{\theta}(\epsilon-\delta)$. Using Corollary \ref{co:convergence}, we conclude that if $\eta$ satisfies
% \begin{equation}\label{eq:tolerancesetting}
%     \theta^\eta \tilde{\epsilon}+\frac{\theta-\theta^{\eta+1}}{1-\theta}\sum_{i=1}^NP_i\le \epsilon,
% \end{equation}
% then that $\eta$ and the coefficients $K_1,\ldots,K_N$ solve the Problem \ref{prob:upperbound}. The trivial case that $\epsilon\le\tilde \epsilon$ is omitted here.
% \QED
% \end{solution}

% There are issues hampering its use. i) The expression of function $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ is unknown to every agent. For any agent $i=1,\ldots,N$, given \{$\lambda_{il}^0,\lambda_{li}^0\}$, it can evaluate the expression of $(\rho_{\mathrm{sum}}^0(\boldsymbol{x}))_i=\sum_{e\in\mathcal{C}_i}(\rho_{ie}^2(\boldsymbol{x})+\rho_{ie}(\boldsymbol{x}))$ with local information \footnote{The expression can be evaluated by regarding $\boldsymbol{x}$ as parameter in the optimisation problem, and exploring the sensitivity of the minimizer. The reader is referred to \cite{bemporad2002explicit} for more information}. Transmitting the expressions among agents is arduous, as they are not in perfectly parameterized forms such as polynomials with certain basis. ii) $\rho_{ie}(\boldsymbol{x})$ is a piece-wise nonlinear and nonconvex function defined on several critical regions \cite{bemporad2002explicit}.%iii) The set $\mathcal{B}$ is also not necessary to be convex, especially as it is an intersection of several sets.%
% To address these difficulties, we propose another solution based on certified sampling from the invariant set $\mathcal{B}$, and accompany it with a probabilistic guarantee.

% \begin{solution}[Stochastic Solution]\label{sol:uncertain}
% Sampling $\bar N$ independent vectors $\boldsymbol{x}^{(r)}\in\mathcal{B}$, for $r=1,\ldots,\bar N$. Solving the multi-agent CBF-QP problem with Algorithm \ref{al:truncated} at every $\boldsymbol{x}=\boldsymbol{x}^{(r)}$, then collecting $\rho_{\mathrm{sum}}^0(\boldsymbol{x}^{(r)})$ for $r=1,\ldots,\bar N$ in a distributed fashion. Choosing $\tilde \epsilon\ge \sup_{r=1,\ldots,\bar N}\rho_{\mathrm{sum}}^0(\boldsymbol{x}^{(r)})$, and following the parameters calculation criterion in Solution \ref{sol:certain}. Then $\eta$ and the coefficients $K_1,\ldots,K_N$ solve the Problem \ref{prob:upperbound} with a probabilistic guarantee which is shown in Theorem \ref{th:confidence}.
% \QED
% \end{solution}

% Solution \ref{sol:uncertain} is a data-driven method. The only difference between Solution \ref{sol:certain} and \ref{sol:uncertain} is the calculation of the upper bound $\tilde \epsilon$. By sampling data from the invariant set $\mathcal{B}$, we cross the requirement of the accurate expression $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$, and avoid solving a non-convex optimisation problem. 

Scenarios $\boldsymbol{x}^{(r)},r=1,\ldots,\bar N$ can be sampled in a distributed manner; this is shown in Algorithm \ref{al:sampling} in the next section.
Another property of interest is whether the control input $\boldsymbol{u}^{\eta}(\boldsymbol{x})$ is Lipschitz continuous in $\boldsymbol{x}$. The continuity of the control input is important both from view of theory and application. A Lipschitz continuous control input $\boldsymbol{u}^\eta(\boldsymbol{x})$ together with Lipschitz continuous $f(\boldsymbol{x})$ and $g(\boldsymbol{x})$ in \eqref{eq:dynamics} guarantees the Lipschitz continuity of the whole vector field $f(\boldsymbol{x})+g(\boldsymbol{x})\boldsymbol{u}(\boldsymbol{x})$. From Peano's Uniqueness Theorem, the solution of $\dot{\boldsymbol{x}}=f(\boldsymbol{x})+g(\boldsymbol{x})\boldsymbol{u}(\boldsymbol{x})$ is then unique locally. In applications, continuous control input avoids system chattering, and guarantees steady motion performance for kinetic systems.

\begin{proposition}\label{pro:continuity}
For system \eqref{eq:dynamics}, fix $\eta$ and let  $\boldsymbol{u}^{\eta}(\boldsymbol{x})$ be the truncated control input solved by Algorithm \ref{al:truncated} for the CBF-QP problem \eqref{eq:centralizedqp}. Then $\boldsymbol{u}^\eta(\boldsymbol{x})$ is locally Lipschitz continuous in $\boldsymbol{x}$.
\end{proposition}
\begin{proof}
We will show this by means of induction. For agent $i$, consider the first iteration with $k=1$ in Algorithm \ref{al:truncated}. From \cite[Theorem 2]{wang2022explicit} we have that $u_i^1$ and $\mu_{ie}^1$ are functions in the form of
\begin{subequations}\label{eq:pro3eq1}
\begin{align}
        u_i^1&= u_i(\boldsymbol{x},\{\lambda_{il}^0,\lambda_{li}^0\}_{l\in\mathcal{N}_i\cap\mathcal{V}_e,e\in\mathcal{C}_i}),\\
        \mu_{ie}^1&= \mu_{ie}(\boldsymbol{x},\{\lambda_{il}^0,\lambda_{li}^0\}_{l\in\mathcal{N}_i\cap\mathcal{V}_e}),\forall e\in\mathcal{C}_i,
\end{align}
\end{subequations}
where $\{\lambda_{il}^0,\lambda_{li}^0\}_{l\in\mathcal{N}_i\cap\mathcal{V}_e,e\in\mathcal{C}_i}$ represents all the auxiliary variables in the sub-problem \eqref{eq:dcbf}. In the sequel, we will use $\boldsymbol{\lambda}$ in stead of  $\{\lambda_{il},\lambda_{li}\}$ for simplicity. By regarding the state $\boldsymbol{x}$ and the auxiliary variable $\boldsymbol{\lambda}$ as parameters, we obtain that $u_i(\boldsymbol{x},\boldsymbol{\lambda})$, and $\mu_{ie}(\boldsymbol{x},\boldsymbol{\lambda})$ are both piece-wise locally Lipschitz continuous functions over $\boldsymbol{x}$ and $\boldsymbol{\lambda}$ \cite[Section III A]{wang2022explicit}. Following this result, we have the expression for $\lambda_{il}^1$ from the update \eqref{eq:trunsubupdate}
\begin{equation}\label{eq:pro3eq2}
\begin{split}
    \lambda_{il}^1&=\lambda_{il}^0-\gamma(\mu_{ie}^1-\mu_{le}^1),\\
    &=\lambda_{il}(\boldsymbol{x},\boldsymbol{\lambda}^0).
\end{split}
\end{equation}
Clearly, $\lambda_{il}(\boldsymbol{x},\boldsymbol{\lambda}^0)$ is Lipschitz continuous in the first argument $\boldsymbol{x}$, and the second argument $\boldsymbol{\lambda}^0$.
Recursively repeating the explicit update procedure \eqref{eq:pro3eq1} and \eqref{eq:pro3eq2} for the auxiliary variables until $k\in\mathbb{N}<\eta$, we obtain that
\begin{equation}\label{eq:induction}
\begin{split}
    u_i^{k+1}&=u_i(\boldsymbol{x},\boldsymbol{\lambda}^k),
    \mu_{ie}^{k+1}=\mu_{ie}(\boldsymbol{x},\boldsymbol{\lambda}^k),
    \lambda_{il}^{k+1}=\lambda_{il}(\boldsymbol{x},\boldsymbol{\lambda}^k).
\end{split}
\end{equation} 
For the induction hypothesis assume that $\boldsymbol{\lambda}^k$ is a Lipschitz continuous in $\boldsymbol{x}$. By \eqref{eq:induction} then $\boldsymbol{ \lambda}^{k+1}$ is also a Lipschitz continuous function in $\boldsymbol{x}$. Together with $\boldsymbol{\lambda}^1$ being Lipschitz continuous, we conclude that $\boldsymbol{\lambda}^{\eta-1}$ is Lipschitz continuous in $\boldsymbol{x}$, and hence also $\boldsymbol{u}^{\eta}$.
\end{proof}

\section{Distributed Safety Verification}
\label{sec:safetyverification}
%In the previous sections, two distributed safe control input design algorithms are presented with additional relaxations to guarantee feasibility of the optimisation problems across iterations. The algorithm may terminate before reaching the optimal control input $\boldsymbol{u}^*(\boldsymbol{x})$ which certainly renders the system safe. Moreover, if for some $\boldsymbol{x}$, the leveraged $\boldsymbol{u}(\boldsymbol{x})$ corresponds to a non-zero $\boldsymbol{\rho}^k$, the CBF constraints are violated. We point out here that constraint violation is not equivalent to becoming unsafe at the current state, but describes the \emph{risk} of becoming unsafe along the current trajectories by means of the CBFs. 

In this section we show how to verify safety by checking the \emph{risk} of becoming unsafe along the current trajectories by means of the CBFs using the so called scenario approach. The verification method proposed in this section can be used with any type of time-invariant control inputs; CBF is only regarded as a verification criteria but not necessarily as a control design principle.

%The rest of this section is organized in three parts: Section \ref{subsec:5a} proposes the scenario-based verification program, and compares them with the other programs; ii) Section \ref{subsec:5b} develops a distributed scenario sampling scheme, and gives a formal independency guarantee; iii) Section \ref{subsec:5c} shows the distributed implementation of the verification program, and gives probabilistic results. 

\subsection{Scenario Based Safety Verification}\label{subsec:5a}

Consider an $N$-agent system \eqref{eq:dynamics} and a safe invariant set $\mathcal{B}$. Our objective is to verify whether for the designed $\boldsymbol{u}(\boldsymbol{x}(t))$,  $\boldsymbol{x}(t)\in\mathcal{S}$ for any $\boldsymbol{x}(0)\in\mathcal{B}$ and $t>0$. 

We propose a scenario-based safety verification program as follows.

\begin{align}\label{eq:dscenvarification}\tag{SC-Verification}
        \min_{\boldsymbol{z}\le 0,\boldsymbol{\zeta}\ge 0}~&\sum_{i=1}^N\sum_{e\in\mathcal{C}_i} \left(z_{ie}^2+M\sum_{r=1}^{\bar N}\zeta_{ie}^{(r)}\right)\nonumber\\
        \mathrm{s.t.}~
        &\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))\le \sum_{i\in\mathcal{V}_e}(z_{ie}+\zeta_{ie}^{(r)}),\nonumber\\
        &\forall e=1,\ldots,E, \forall r=1,\ldots,\bar{N},
\end{align}
% \begin{equation}\label{eq:scenvarification}\tag{SC-Verification}
%         \begin{split}
%         \min_{\boldsymbol{\rho}\le 0,\boldsymbol{\zeta}\ge 0}~&\sum_{e=1}^E\left( \rho_e^2+M\sum_{r=1}^{\bar N}\zeta_e^{(r)}\right)\\
%         \mathrm{subject~to~}
%         &\sum_{l\in\mathcal{V}_e}h_{le}(u_l(\boldsymbol{x}^{(r)}))\le \rho_e+\zeta_e^{(r)},\\
%         &\forall e=1,\ldots,E, \forall r=1,\ldots,\bar N,
%     \end{split}
% \end{equation}
where scenarios $\boldsymbol{x}^{(r)}\in\mathcal{B}$ for any $r=1,\ldots,\bar N$ are extracted according to some probability distribution to be clarified in the sequel. 
Throughout the section $\bar X=\{\boldsymbol{x}^{(1)},\ldots,\boldsymbol{x}^{(\bar N)}\}$ denotes the set of scenarios, where $\boldsymbol{x}^{(r)}=[(x^{(r)}_1)^\top,\ldots,(x^{(r)}_N)^\top]^\top\in\mathbb{R}^{\sum_{i=1}^Nn_i}$, for $r=1,\ldots,\bar N$. Relaxation variables $\boldsymbol{\zeta}$ are introduced to ensure feasibility, while $M>0$ is a large enough penalty coefficient.

Program \eqref{eq:dscenvarification} is a data-driven QP, where all the constraints are linear based on the samples. Roughly speaking, if for any $\boldsymbol{x}\in\mathcal{B}$ and corresponding control input $\boldsymbol{u}(\boldsymbol{x})$, all the CBF constraints are satisfied, then $\boldsymbol{\zeta}^*=0$. Conversely, $\boldsymbol{\zeta}^*\ne0$ represents a CBF constraint violation, and indicates the risk of being unsafe by means of CBF. A new set $\mathcal{Z}(\mathcal{B})$ for optimal solution $\boldsymbol{z}^*$ is defined as follow
\begin{equation}
    \begin{split}
        &\boldsymbol{z}^*\in\mathcal{Z}(\mathcal{B})\Longleftrightarrow\\
        & \sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}))\le  \sum_{i\in\mathcal{V}_e}z^*_{ie},\forall e=1,\ldots,E, \forall \boldsymbol{x}\in\mathcal{B}.
    \end{split}
\end{equation}
Then $\mathcal{Z}(\mathcal{B})$ is constituted of $N$ individual set $\mathcal{Z}_i(\mathcal{B})$ as
\begin{equation}\label{eq:constraints}
    \mathcal{Z}(\mathcal{B})=\bigcap_{i=1}^N\mathcal{Z}_i(\mathcal{B}).
\end{equation}
The argument of $\mathcal{Z}$ and $\mathcal{Z}_i$ is dropped in the sequel for simplicity.

% When the number of samples is large enough, i.e. $\bar N\to \infty$, the safety verification result is obtained by the following Proposition.

% \begin{proposition}\label{th:inisafetyresult}
% Consider the verification program \eqref{eq:scenvarification} with $\bar N\to\infty$. If the minimizer $\boldsymbol{\rho}^*=0$, with relaxation variable $\boldsymbol{\zeta}^*=0$, the multi-agent system \eqref{eq:dynamics} is safe with control input $\boldsymbol{u}(\boldsymbol{x})$.
% \end{proposition}

% \begin{proof}
% If $\boldsymbol{\rho}^*=0$ and $\boldsymbol{\zeta}^*=0$, we have 
% \begin{equation}
%     \sum_{l\in\mathcal{V}_e}h_{le}(u_l(\boldsymbol{x}))\le 0,\forall e=1,\ldots,E,\forall x\in\mathcal{B}.
% \end{equation}
% By Theorem \ref{th:theo1}, we directly have that the set $\mathcal{B}$ is forward-invariant with control input $\boldsymbol{u}(\boldsymbol{x})$.
% \end{proof}


% The reason why we use finte samples instead of optimizing over the whole set $\mathcal{B}$ is to avoid solving an uncertain optimisation problem
% \begin{equation}\label{eq:verification}
%     \begin{split}
%         \min_{\boldsymbol{\rho}}~&\sum_{e=1}^E \rho_e^2\\
%         \mathrm{subject~to~}
%         &\sum_{l\in\mathcal{V}_e} h_{le}(u_l(\boldsymbol{x}))\le \rho_e,\forall e=1,\ldots,E,\\
%         &\forall \boldsymbol{x}\in\mathcal{B}, u_i(\boldsymbol{x})\in\mathcal{U}_i,\forall i=1,\ldots,N.
%     \end{split}
% \end{equation}
% Here $u_i(\boldsymbol{x})$ with $i=1,\ldots,N$ is a function of $\boldsymbol{x}$. The verification program \eqref{eq:verification} is an uncertain problem parameterized by $\boldsymbol{x}$ in an uncertain set $\mathcal{B}$. Although mathematically sound, \eqref{eq:verification} is hard to solve in practice due to the uncertain set constraint $\forall \boldsymbol{x}\in\mathcal{B}$. In this sense, with a compact set $\mathcal{B}$, \eqref{eq:verification} is an infinitely constrained problem. Moreover, the form of  $\boldsymbol{u}(\boldsymbol{x})$ is possibly unknown.

% Another deterministic verification program can be obtained by assuming the map from $\boldsymbol{x}$ to $\boldsymbol{u}(\boldsymbol{x})$ is known as a \emph{priori}. Under this assumption, the verification program \eqref{eq:verification} can actually be solved exactly. For example, the control input designed by solving the CBF-QP \eqref{eq:centralizedqp} can be explicit. Although the optimisation only gives an implicit expression, i.e. $u_i(\boldsymbol{x})$ for $i=1,\ldots,N$ are solved point-wisely at given $\boldsymbol{x}$, the explicit form of $u_i(\boldsymbol{x})$ can be evaluated exactly as a piece-wise Lipschitz continuous function \cite{wang2022explicit}. The alternative equivalent deterministic formulation of the problem \eqref{eq:verification} follows as
% \begin{equation}\label{eq:equivalentverification}
%     \begin{split}
%         \max_{\boldsymbol{x}\in\mathcal{B}}~&H(\boldsymbol{x})\\
%         \mathrm{subject~to~}&H(\boldsymbol{x})=\mathrm{max}
%         \left\{\vphantom{sum_{i=1}^N\sum_{l\in\mathcal{V}_e\cap\mathcal{N}_i}\tilde h_{l,\mathcal{C}_1}(u_l(\boldsymbol{x}))}\sum_{i\in\mathcal{C}_1} h_{i1}(u_i(\boldsymbol{x}))\right.\\
%         &,\ldots,\left.\sum_{i\in\mathcal{V}_e} h_{iE}(u_i(\boldsymbol{x}))\right\},\\
%     \end{split}
% \end{equation}

% If the problem \eqref{eq:verification} has a minimizer of $\boldsymbol{\rho}=0$, then $H(\boldsymbol{x}^*)\le 0$ for $\boldsymbol{x}^*$ as the minimizer to \eqref{eq:equivalentverification}. Though now the uncertain program \eqref{eq:verification} is equivalently formulated as a certain program \eqref{eq:equivalentverification}, solving \eqref{eq:equivalentverification} is still non-trivial since the functions $h_{ie}(u_i(\boldsymbol{x}))$ for $e=1,\ldots,E$ are all non-linear. Besides, in real applications the form of $u_i(x)$ is \emph{a priori}, at least not circulated across the whole system. To this end, the benefit of \eqref{eq:scenvarification} is clear: it is a finite convex optimisation problem.

\subsection{Sampling the Scenarios}
\label{subsec:5b}
The scenarios are sampled independently from the uncertain set $\mathcal{B}$. For sampling we define a probability density $\pi(\boldsymbol{x})$ associated with set $\mathcal{B}$ that satisfies:
\begin{equation*}
    \int_{\mathcal{B}}\pi(\boldsymbol{x})d\boldsymbol{x}=1.
\end{equation*}
One typical choice of $\pi(\boldsymbol{x})$ is to set it according to the density of the uniform distribution, i.e., $\pi(x)=\pi^{\mathrm{uni}}(\boldsymbol{x})=\frac{1}{\int_\mathcal{B}d\boldsymbol{x}}$. \begin{assumption}\label{ass:nonzero}
The safe invariant set $\mathcal{B}$ constructed from \eqref{eq:invariantset1} has non-zero Lebesgue measure.
\end{assumption}

Assumption \ref{ass:nonzero} is not a strong assumption since there always exists non-empty $\mathcal{B}$ as $\mathcal{S}$ is assumed to be non-empty. We only omit the case where $\mathcal{B}$ is a single-point set, or a countable number of points set. This guarantees the existence of $\pi^{\mathrm{uni}}(\boldsymbol{x})$. Then, $\boldsymbol{x}$ can be sampled for $\bar N$ times independently from the distribution $\pi^{\mathrm{uni}}(\boldsymbol{x})$. We note here that different probability distributions have minor impact on the final violation results, interested readers are referred to \cite[Section 3.1]{garatti2019risk}. Although the uniform distribution here is well-defined, the uncertain set $\mathcal{B}$ is defined implicitly as an intersection of multiple sets \eqref{eq:invariantset1}. Sampling a point from the proposed uniform distribution is rather arduous in practice, and agents may not have access to $\mathcal{B}$. Here, we provide a sequential algorithm to sample scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar{N}$. 

\begin{algorithm}[h]
  \caption{Scenarios Sampling Algorithm}
   \hspace*{\algorithmicindent} \textbf{Initialization} Uncertain set $\mathcal{B}$ constructed by \eqref{eq:invariantset1}, failed times $F=0$.\\
 \hspace*{\algorithmicindent} \textbf{Output:} Scenario $\boldsymbol{x}^{(r)}$.\\
 \vspace{-3ex}
  \begin{algorithmic}[1]\label{al:sampling}
  \STATE Sample $x_1^{(r)}$ from $\pi_1(x_1)$.
  \FOR{$i=2,\ldots,N$}
    \STATE Construct a distribution $\pi_{i}(\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\};x_{i})$ following \eqref{eq:fixedinvariant} \eqref{eq:distribution}.
  \IF {$\pi_{i}=0$}
  \STATE $F \leftarrow F+1$.
  \STATE go to $i=i-F$ ($i=1$ is step $1$).
  \ENDIF
    \STATE Sample $x_i^{r}$ from $\pi_i(\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\};x_i)$.
  \ENDFOR
  
  \end{algorithmic}
\end{algorithm}
The algorithm constructs the densities from which samples are extracted sequentially for each agent.
We first show the construction of $\pi_i(\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\};x_{i})$. Here $\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\}$ are sampled according to the $i$-th density, $\pi_i$. To determine this, we first define the uncertain sets from which samples are extracted for agent $i$ with part of the states of agents in the same sub-network $\mathcal{G}_e$ fixed.
\begin{align}\label{eq:fixedinvariant}
    \tilde{\mathcal{B}}_{ie}&=\left\{ \begin{array}{l}
\mathcal{X}_i,~\mathrm{if}~\exists l\in\mathcal{V}_e,\mathrm{such}~\mathrm{that}~l> i\\
\{x_i\in\mathbb{R}^{n_i}|b_{ie}(x_i,\{x_l^{(r)}\})\ge0)\},~\mathrm{otherwise}
\end{array} \right.
\end{align}
We then have that $\tilde{\mathcal{B}}_i = \bigcap\limits_{e\in\mathcal{C}_i}  {{\tilde{{\cal B}}_{i{e}}}}$. The parameters in \eqref{eq:fixedinvariant} can all be collected by local communication, since only states of agents in the same sub-network are required. Note here $\tilde{\mathcal{B}}_i$ is possibly empty with some parameters $\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\}$. The distribution $\pi_i(\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\};x_{i})$ used in the step $3$ of Algorithm \ref{al:sampling} is a uniform distribution over $\tilde{\mathcal{B}}_i$, i.e.,
\begin{equation}\label{eq:distribution}
    \pi_i(\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\};x_{i})=\left\{
    \begin{array}{l}
    \frac{1}{\int_{\tilde{\mathcal{B}}_i}dx_i},~\mathrm{if}~\tilde{\mathcal{B}}_i\ne\emptyset\\
    0,~\mathrm{otherwise}
    \end{array}
    \right.
\end{equation}

In step $1$, the first scenario $x_1^{(r)}$ associated with agent $1$ is sampled from distribution $\pi_1(x_1)=\frac{1}{\int_{\mathcal{X}_1}dx}$, since now there are no other agents involved to restrict the uncertain set for agent $1$. Then, the sampling-construction procedures repeat sequentially from agent $2$ to agent $N$. One case needs additional attention, where $\pi_i=0$. This implies that $\tilde{\mathcal{B}}_i=\emptyset$. By Assumption \ref{ass:nonzero}, there exists $\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\}$ such that $\tilde{\mathcal{B}}_i\ne \emptyset$. Therefore, if $\pi_i=0$ (Step 5), then go back to the sampling-construction of agent $i-F$, $F\ne 1$ is to avoid a deadlock on step $i$. The deadlock happens when for given scenarios $x_1^{(r)},\ldots,x_{i-2}^{(r)}$, the uncertain set $\tilde{\mathcal{B}}_{i-1}$ and distribution $\pi_{i-1}$ is such that for any $ x_{i-1}^{(r)}\in\tilde{\mathcal{B}}_{i-1}$, $\tilde{\mathcal{B}}_i=\emptyset$. It is guaranteed that $F\le i-1$ for $i\ge 2$, since $\tilde{\mathcal{B}}_1=\mathcal{X}_1\ne\emptyset$. 

\begin{proposition}\label{pro:independency}
The scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$, are feasible, i.e. $\boldsymbol{x}^{(r)}\in\mathcal{B}$, and independent.
\end{proposition}
\begin{proof}
The feasibility result holds directly from the definition of every uncertain set $\tilde{\mathcal{B}}_i$ in \eqref{eq:fixedinvariant} that $x_i^{(r)}$ is sampled from. As a result, we have  $b_{ie}(x_i^{(r)},\{x_k^{(r)}\})\ge 0$ for any $i=1,\ldots,N$, $e\in\mathcal{C}_i$, and $k\in\mathcal{V}_e$. Therefore, $\boldsymbol{x}^{(r)}\in\mathcal{B}$. $\boldsymbol{x}^{(r)}$ for $r=1,\ldots,\bar N$ are independent since for $r=1,\ldots,\bar N$, $x_1^{(r)}$ are independently sampled from distribution $\pi_1$.
\end{proof}

We note here that the elements in $\boldsymbol{x}^{(r)}$ are correlated, but this will not influence the independence results in Proposition \ref{pro:independency} since we seek independence across $r$.



\subsection{Distributed Safety Verification}
\label{subsec:5c}
%After sampling every scenario $\boldsymbol{x}^{(r)}$, the scenario represents the states to the networked system \eqref{eq:dynamics}. Agents then design their control law $\boldsymbol{u}(\boldsymbol{x}^{(r)})$ with their methods. As we have stated in the beginning of this section, the control law $\boldsymbol{u}(\boldsymbol{x})$ is not necessarily designed via solving the CBF-QP \eqref{eq:centralizedqp}, but can also be synthesized by other methods. The only requirement is that every agent has access to its control input. Without additional communication, $x_i^{(r)}$ and $u_i(\boldsymbol{x}^{(r)})$ are private resources to agent $i$. Although $u_i(\boldsymbol{x}^{(r)})$ may be designed on the scenarios (states) of other agents, in the verification step we still assume the scenarios are private since the design of control input is not \textit{a priori}. 

% The verification program \eqref{eq:scenvarification} is well-defined, however it can not be directly solved locally with Algorithm \ref{al:dcbf} since the problem is still coupled across agents as the decision variables $\rho_e$ is common variable for all agents in the sub-network $\mathcal{G}_e$. A commonly used approach to split the problem is to decompose the ``edge" variables into several ``node" variables, entailing additional consensus constraints. Following this idea, a decoupled version is proposed as
After sampling scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$ using Algorithm \ref{al:sampling}, we are at the stage of solving the safety verification program \eqref{eq:dscenvarification}.

Letting the local cost function $J_i(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)$, and constraint function $\hat{h}_{ie}(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)$ be
\begin{equation}\label{eq:scenariodistributed}
    \begin{aligned}
        &J_i(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)&&=\sum_{e\in\mathcal{C}_i} \left(z_{ie}^2+\sum_{r=1}^{\bar N}\zeta_{ie}^{(r)}\right),\\
        &\hat{h}_{ie}^{(r)}(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)&&={h}_{ie}(u_i(\boldsymbol{x}^{(r)}))-z_{ie}-\zeta_{ie}^{(r)},r=1,\ldots,\bar N,
    \end{aligned}
\end{equation}
Algorithm \ref{al:dcbf} can be applied to solve the distributed scenario optimisation problem \eqref{eq:dscenvarification}. The relaxation variables in Algorithm \ref{al:dcbf} are unnecessary, since every optimisation sub-problem in iteration is solvable. In the sequel, we use $\boldsymbol{z}^*$ and $\boldsymbol{\zeta}^*$ to represent the optimal solution to \eqref{eq:dscenvarification}, with scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$. We then have the following theorem as the main result on probabilistic safety.

\begin{theorem}\label{th:probability} Choose $\beta_i \in (0,1),i=1,\ldots,N$, and set $\beta=\sum_{i=1}^N \beta_i$. For $i=1,\ldots,N$, and $0\le s_i^*\le \bar N-1$, consider the polynomial equation in $t_i$
\begin{equation}\label{eq:scenariopolynomial}
\begin{split}
        &\left(\begin{array}{l}
{\bar N}\\
{s^*_i}
\end{array}\right)t_i^{\bar N-s^*_i}-\frac{\beta_i}{2\bar N}\sum_{j=s^*_i}^{\bar N-1}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-s^*_i}\\
&-\frac{\beta_i}{6\bar N}\sum_{j=\bar N+1}^{4\bar N}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-s^*_i}=0,
\end{split}
\end{equation}
while for $s_i^*=\bar N$ consider the polynomial equation
\begin{equation}\label{eq:scenariopolynomial2}
    1-\frac{\beta}{6N}\sum_{j=\bar N+1}^{4\bar N}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-\bar N}=0.
\end{equation}
For any $i=1,\ldots,N$, this equation has exactly two solutions in $[0,+\infty)$ denoted by $\underline t_i(s^*_i)$ and $\bar t_i(s^*_i)$, where $\underline t_i(s^*_i)\le \bar t(s^*_i)$. Let $\underline\epsilon_i(s^*_i):=\max\{0,1-\bar t_i(s^*_i)\}$, $\bar \epsilon_i(s^*_i):=1-\underline t_i(s^*_i)$, and $\underline \epsilon(s^*)=\sum_{i=1}^N\underline\epsilon_i(s_i^*)$, $\bar \epsilon(s^*)=\min\{\sum_{i=1}^N\bar\epsilon_i(s_i^*),1\}$. We then have that
\begin{equation}\label{eq:violation}
    \mathbb{P}^{\bar N}\left\{\frac{\underline\epsilon(s^*)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:0\notin\mathcal{Z} \right\}\le\bar\epsilon(s^*)
    \right\}\ge 1-\beta,
\end{equation}
where $s_i^*$ is the number of non-zero $\zeta_{ie}^{(r)*}$, $e\in\mathcal{C}_i$.
\end{theorem}

% The following corollary is a direct result from Lemma \ref{lem:uniqueness}.
% \begin{corollary}\label{coro:violation}
% For state $\boldsymbol{x}\in\mathcal{B}$, if $\boldsymbol{z}^*\ne \boldsymbol{0}$, then at least one CBF constraint is violated for system \eqref{eq:dynamics} at $\boldsymbol{x}$, using control input $\boldsymbol{u}(\boldsymbol{x})$. 
% \end{corollary}

% Under the assumption of Lemma \ref{lem:uniqueness}, the violation probability $V(\boldsymbol{z}^*)=\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\bigcap_{i=1}^N\mathcal{Z}_i  \}$ shows the probability that at least one CBF constraint is violated. From Lemma \ref{lem:uniqueness}, the scenario program is guaranteed to have a unique solution, therefore the $V(\boldsymbol{z}^*)$ can be evaluated through scenario approach theory \cite{campi2018wait}, which points out that $V(\boldsymbol{z}^*)$ is with a quantifiable level $\bar \epsilon$ under confidence probability $\beta$. The relationship is built on the notion of \emph{support constraint}. For an optimisation problem, a constraint is called a support constraint if its removal (with all the other constraints remained) changes the solution of the problem. The \emph{support set} is a corresponding notion. A subset with minimal cardinality of constraints is called a support set if solving the optimisation problem with only these constraints considered returns the same solution as the nominal problem. If the support set is identified, the original optimisation problem can be simplified to be solved with removing all the other redundant constraints. 

% Let $s^*(\boldsymbol{x}^{(r)})$ to be the upper bound of cardinality of the support set. By \cite{calafiore2005uncertain}, $s^*(\boldsymbol{x}^{(r)})$ is less smaller to the dimension of the decision variables, which is $\sum_{i=1}^E|\mathcal{V}_e|$. In the sequel, $s^*(\boldsymbol{x}^{(r)})$ is substituted by $s^*$ for simplicity. Using $s_i^*$ to denote the number of support constraints belong to the constraints of agent $i$, then $s_i^*\le|\mathcal{C}_i|$, which is the dimension of decision variables for agent $i$. Directly, suppose the number of scenarios for agent $i$ is $\tilde N_i$. Adopting the scenario approach theory from \cite{garatti2019risk}, we have the following theorem as the main results of this section.

Note that Theorem \ref{th:probability} constitutes a generalization of \cite[Theorem 2]{garatti2019risk} to a multi-agent setting. It also extends \cite{margellos2017distributed} by determining the lower bound $\frac{\underline\epsilon(s^*)}{N}$.
Theorem \ref{th:probability} states that with confidence $1-\beta$, the system tends to be unsafe by means of the CBFs with probability within the interval $[\frac{\underline\epsilon(s^*)}{N}$, $\bar \epsilon(s^*)]$. 
%Note here that unlike the upper bound, the lower bound is divided by the amount of agents $N$. This is because in the extreme case where all the events $\boldsymbol{z}^*\notin\mathcal{Z}_i$ for $i=1,\ldots,N$ happen simultaneously, such that $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\{\boldsymbol{z}^*\notin\mathcal{Z}_i  \}\right\}=$ $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_1  \right\}$ $=\ldots=\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_N  \right\}$, then $\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}$ $\le N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\{\boldsymbol{z}^*\notin\mathcal{Z}_i  \}\right\}$. 

% \begin{proposition}
% For the scenario program \eqref{eq:dscenvarification} with level $Q$. Then $s^*(\boldsymbol{x}^{(r)})=I_{=0}(\boldsymbol{z}^*(\boldsymbol{x}^{(r)}))$ if $\forall \boldsymbol{x}^{(r)}\in\bar X$, and corresponding control input $\boldsymbol{u}(\boldsymbol{x}^{(r)})$, all the CBF constraints are satisfied with level $Q$.
% \end{proposition}
% \begin{proof}
% For the case where all the CBF constraints are satisfied with level $Q$, we have $\boldsymbol{z}^*(\boldsymbol{x}^{(r)})=-\varepsilon$ or $0$ from Lemma \ref{lem:uniqueness}. For $i$ and $e$ such that $z_{ie}^*(\boldsymbol{x}^{(r)})=0$, there must exist at least one $r$ such that $\sum_{k\in\mathcal{V}_e}h_{ke}(u_k(\boldsymbol{x}^{(r)}))\le\sum_{k\in\mathcal{V}_e}z_{ke}+Q$ supports the problem. Besides, the number of support constraints is not bigger than the dimension of decision variables \cite{calafiore2005uncertain}. Hence, $s^*(\boldsymbol{x}^{(r)})$ equals to the number of zeros in $\boldsymbol{z}^*(\boldsymbol{x}^{(r)})$. We conclude the proof.
% \end{proof}

% The following lemma characterizes the distribution of violation probability $V(\boldsymbol{z}^*)$, which indicates the \emph{risk} of the system \eqref{eq:dynamics} by means of the CBFs.
% \begin{lemma}\label{lem:safetyprobability}
% For the multi-agent system \eqref{eq:dynamics} and the CBFs, we have that
% \begin{equation}\label{eq:safetyprobability}
%     \mathbb{P}\left\{\frac{\underline\epsilon(0)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\ne\boldsymbol{0}\right\}\le\bar\epsilon(0)
%     \right\}\ge 1-\beta,
% \end{equation}
% where $\beta$, $\underline\epsilon$, $\bar\epsilon(0)$ follows Theorem \ref{th:probability} and Equation \eqref{eq:scenariopolynomial} by letting $s_i^*=0$ for any $i=1,\ldots,N$.
% \end{lemma}

% Lemma \ref{lem:safetyprobability} shows the probability measure about the risk of the multi-agent system \eqref{eq:dynamics} under confidence $1-\beta$. Here $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\bigcap_{i=1}^N\mathcal{Z}_i\right\}$ has been substituted by $\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\ne 0\}$ as they are equivalent at $\boldsymbol{z}^*=0$.
Furthermore, for a given $r$, \eqref{eq:dscenvarification} can be split into $\sum_{i=1}^E|\mathcal{V}_e|$ sub-problems, each one with its own CBF constraint. Each sub-problem is solved at the agent level and has only $\bar N$ constraints. Then, the probability that one of the CBF constraints is violated can be bounded as shown in the following corollary.

\begin{corollary}\label{coro:sconecbf}
Consider the multi-agent system \eqref{eq:dynamics}, and let  $\underline\epsilon_i(s_i^*)$, $\bar\epsilon_i(s_i^*)$, and $\beta_i$ as in Theorem \ref{th:probability}. We then have that
\begin{equation}
\begin{split}
     &\mathbb{P}^{\bar N}\left\{\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))>0\right\}\le\bar\epsilon_i(s_i^*)
    \right\}\\
    &\ge 1-\beta_i.
\end{split}
\end{equation}

\end{corollary}




\section{Simulations Results}
\label{sec:simulation}
The distributed safe control input design and safety verification algorithms are numerically validated on a multi-robot positions swapping problem. To facilitate comparison, we adopt a similar setup as in \cite{wang2017safety}. 
\subsection{Multi-Robot Position Swapping}
Robots are assigned different initial positions and are required to navigate towards target locations. In a distributed framework, robots are equipped with sensing and communication modules for collision detection and information sharing. A group of ten robots, indexed by $i=1,\ldots,10$ are considered, with double integrator dynamics
\begin{equation}\label{eq:robotdynamics}
    \begin{bmatrix}
    \dot{\boldsymbol{p}_i}\\\dot{\boldsymbol{v}_i}
    \end{bmatrix}=
    \begin{bmatrix}
    0&I_{2\times 2}\\
    0&0
    \end{bmatrix}
    \begin{bmatrix}
    \boldsymbol{p}_i\\
    \boldsymbol{v}_i
    \end{bmatrix}+
    \begin{bmatrix}
    0\\
    I_{2\times 2}
    \end{bmatrix}\boldsymbol{a}_i,
\end{equation}
where $\boldsymbol{p}_i\in\mathbb{R}^2$, $\boldsymbol{v}_i\in\mathbb{R}^2$ represent positions and velocities, and $\boldsymbol{a}_i\in\mathbb{R}^2$ is the control input, representing accelerations. The working space is restricted to be $||\boldsymbol{p}_i||_\infty\le x^{\max}$, $||\boldsymbol{v}_i||_\infty\le v_i^{\max}$,  $||\boldsymbol{a}_i||_\infty\le a_i^{\max}$. Each robot is regarded as a disk centered at $\boldsymbol{p}_i$ with radius $D_i\in\mathbb{R}_+$. The safety certificate $s_{ij}(\boldsymbol{p},\boldsymbol{v})$ for collision avoidance between robot $i$ and $j$ is defined by
\begin{equation}\label{eq:robotsafety}
    s_{ij}(\boldsymbol{p},\boldsymbol{v}) = ||\Delta\boldsymbol{p}_{ij}||_2^2-D_{ij},
\end{equation}
where $\Delta\boldsymbol{p}_{ij}=\boldsymbol{p}_i-\boldsymbol{p}_j$, $D_{ij}=D_i+D_j$.
Note here that the system is heterogeneous as different robots have different mobility. The control barrier function for invariance certificates is then defined pair-wisely, as
\begin{align}
    b_{ij}(\boldsymbol{p},\boldsymbol{v}) &= \sqrt{2(a_i^{\max}+a_j^{\max})(||\Delta\boldsymbol{p}_{ij}||_2^2-D_{ij})}\nonumber \\&+\frac{\Delta\boldsymbol{p}_{ij}^\top}{||\Delta\boldsymbol{p}_{ij}||_2^2}\Delta\boldsymbol{v}_{ij}, \label{eq:robotbarrierfunction}
\end{align}
where $\Delta\boldsymbol{v}_{ij}=\boldsymbol{v}_i-\boldsymbol{v}_j$. The function $b_{ij}(\boldsymbol{p},\boldsymbol{v})$ is guaranteed to be a CBF since when $b_{ij}(\boldsymbol{p},\boldsymbol{v})>0$, collision can be avoided with maximum braking acceleration $\boldsymbol{a}^{\max}_i+\boldsymbol{a}^{\max}_j$ applied to robots $i$ and $j$. For $i=1,\ldots,5$, $\boldsymbol{a}_i^{\max}=1$, while for $i=6,\ldots,10$, $\boldsymbol{a}_i^{\max}=10$. Note that although $b_{ij}(\boldsymbol{p},\boldsymbol{v})$ is guaranteed to be a CBF for safety certificate $s_{ij}(\boldsymbol{p},\boldsymbol{v})$, the corresponding invariant set $\mathcal{B}=\mathop{\bigcap}\limits_{\{i,j\}\in\mathcal{E}}\mathcal{B}_{ij}$ is possibly empty. Intuitively, this is since robots cannot utilize maximum braking force to avoid collision with multiple other robots simultaneously. This problem is beyond the scope of this paper, and we still adopt the CBF as in \eqref{eq:robotbarrierfunction}.

\subsection{Distributed Control: Asymptotic Algorithm}
The distributed safe control design procedure of Algorithm \ref{al:dcbf} that exhibits asymptotic convergence and optimality guarantees is implemented for robots to swap positions with the opposite robots while avoiding collision. The resulting simulation results are shown in Figure \ref{fig:fullcontrol}.

\begin{figure}[h]
     \centering

     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter1.eps}
         \caption{Iteration 1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter100.eps}
         \caption{Iteration 100}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter200.eps}
         \caption{Iteration 200}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter300.eps}
         \caption{Iteration 300}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter400.eps}
         \caption{Iteration 400}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/ceniter500.eps}
         \caption{Iteration 500}
     \end{subfigure}
         \caption{Trajectory of ten robots swapping positions according to Algorithm \ref{al:dcbf}. Robots with the same color are swapping positions, and avoiding collision with the others.}
         \label{fig:fullcontrol}
\end{figure}


\subsection{Distributed Control: Truncated Algorithm}
The truncated Algorithm \ref{al:truncated} is then implemented for the same setting. Here we consider the problem  in a working space with boundary $x^{\mathrm{\max}}=4$, $v^{\mathrm{\max}}=3$. To employ Theorem 3 we used $50$ samples related to the truncation parameter, and set $\beta_1,\ldots,\beta_{10}=0.01$, $\epsilon_1,\ldots,\epsilon_{10}=0.001$, obtaining 
\begin{equation*}
    \mathbb{P}^{50}\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\rho_{\mathrm{sum}}^{79}(\boldsymbol{x})>10^{-3}\right\}\le 0.088\right\}\ge 0.9.
\end{equation*}

\begin{figure}[h]
     \centering

     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter1.eps}
         \caption{Iteration 1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter100.eps}
         \caption{Iteration 100}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter200.eps}
         \caption{Iteration 200}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter300.eps}
         \caption{Iteration 300}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter400.eps}
         \caption{Iteration 400}
     \end{subfigure}
          \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/deciter500.eps}
         \caption{Iteration 500}
     \end{subfigure}
         \caption{Trajectory of ten robots swapping positions while avoiding collision by means of Algorithm \ref{al:truncated}, with $\eta=30$.}
         \label{fig:truncontrol}
\end{figure}
For a practical implementation $\eta$ could be much smaller, as its theoretical value is calculated by considering the most ill-conditioned matrix \eqref{eq:quadraticmatrix} for $r=1,\ldots,\bar{N}$. To this end, we numerically investigated the performance of the algorithm with $\eta=30$; the resulting swapping trajectories are shown in Figure \ref{fig:truncontrol}. The evolution of the relaxation parameters $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ and $\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})$ across algorithm iterations, is shown in Figures \ref{fig:rho0} and \ref{fig:rho30}.

\begin{figure}[h]
     \centering

     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/toler0.eps}
         \caption{$\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ along the trajectory}
         \label{fig:rho0}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.23\textwidth}
         \centering
         \includegraphics[width=\textwidth]{pic/toler30.eps}
         \caption{$\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})$ along the trajectory}
         \label{fig:rho30}
     \end{subfigure}
     \caption{Evolution of the relaxation parameters $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ and $\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})$ evaluated at the state trajectory, across algorithm iterations.}
\end{figure}

\subsection{Distributed Safety Verification}
Safety verification is performed for a four-robot system, within working space $x^{\max}=4$, $v^{\max}=3$. Each robot is using Algorithm \ref{al:truncated} to safely move towards the origin. 
We sample $200$ scenarios via Algorithm \ref{al:sampling}.
Theorem \ref{th:probability} yields then that with confidence at least $0.9$, 
$\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:0\notin\mathcal{Z} \right\}\in [0,0.146]$.
We repeat this procedure $300$ times, each time using $300$ scenarios, and construct the empirical cumulative distribution function of $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:0\notin\mathcal{Z} \right\}$.
This is shown in Figure \ref{fig:distribution};
it can be observed that the empirical probability that $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:0\notin\mathcal{Z} \right\} \in [0,0.146] \approx 1$, thus satisfying the theoretical confidence lower bound of $0.9$.
\begin{figure}[h]
     \centering

    %  \begin{subfigure}[b]{0.23\textwidth}
    %      \centering
    %      \includegraphics[width=\textwidth]{pic/pdf.eps}
    %      \caption{PDF for safety violation}
    %  \end{subfigure}
    %  \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         \includegraphics[width=0.8\textwidth]{pic/cfg.eps}
        %  \caption{CDF for safety violation}
         \label{fig:4cdf}
     \end{subfigure}
     \caption{Cumulative distribution function for safety violation.}
          \label{fig:distribution}
\end{figure}


\section{Conclusion}
\label{sec:conc}
In this paper we presented distributed safe control design and safety verification algorithms for multi-agent systems. The proposed control algorithms introduce auxiliary and relaxation variables to allow feasibility across iterations. We guaranteed convergence to an optimal solution and establish a linear convergence rate. Furthermore, the relaxation variables are guaranteed to decrease until below a certain level by setting the penalty coefficients locally. This level can be determined by each agent, and can be reached in a finite number of iterations; the latter is determined in a probabilistic way. We also addressed the problem of distributed safety verification for given control inputs. A scenario-based verification program is formulated and can be solved locally by each agent. The scenarios are sampled independently by a sequential algorithm from the controlled invariant set. The distributed scenario program characterizes the probability of being unsafe, with both lower and upper bounds  being determined. Simulation on a multi-robot swapping position problem determines the efficacy of our result. Current work concentrates in accounting for communication delays and model uncertainty in real systems.
\appendix
\begin{proof}[Proof of Lemma \ref{lem:newproperty}]
Combining the optimisation problems \eqref{eq:dcbf} in Step 3 of Algorithm \ref{al:dcbf} for all agents, we have
\begin{equation}\label{eq:globalrelaxedcbf}
    \begin{split}
        \min_{\boldsymbol{u},\boldsymbol{\rho}}&~J(\boldsymbol{u},\boldsymbol{\rho})\\
        \mathrm{subject~to}~&u_i\in\mathcal{U}_i,\forall i=1,\ldots,N,\boldsymbol{\rho}\ge 0\\
        &\sum_{k\in\mathcal{V}_e} h_{ke}(u_k)\le\sum_{k\in\mathcal{V}_e}\rho_{ke},\forall e=1,\ldots,E,
    \end{split}
\end{equation}
where for each $e=1,\ldots,E$, $\mu_e$ is the dual variable associated with the last constraint in \eqref{eq:globalrelaxedcbf}.
The dual function of \eqref{eq:globalrelaxedcbf} is given by
\begin{align*}\label{eq:dual}
        q_{R}(\boldsymbol{\mu})&=\inf_{\{u_i\in\mathcal{U}_i\},\boldsymbol{\rho}\ge 0}\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}(\rho^2_{ie}+M_{i}\rho_{ie})\right\}\\
        &+\sum_{e=1}^E\mu_e\left\{\sum_{k\in\mathcal{V}_e} h_{ke}(u_k)-\sum_{k\in\mathcal{V}_e}\rho_{ke}\right\}\nonumber\\
        &=\inf_{\{u_i\in\mathcal{U}_i\},\boldsymbol{\rho}\ge 0}\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}\mu_eh_{ke}(u_k)\right\}\nonumber\\
        &+\sum_{e=1}^E\sum_{k\in\mathcal{V}_e}\left\{\rho_{ke}^2+(M_{k}-\mu_e)\rho_{ke}\right\}\nonumber\\
        &=\left\{ \begin{array}{l}
- \infty,~\text{if}~M_{k}-\mu_e<0,\forall e=1,\ldots,E,k\in\mathcal{V}_e \nonumber\\
\mathop {\inf }\limits_{\{{u_i} \in {{\cal U}_i}\}} \sum\limits_{i = 1}^N {\left\{ {{J_i}({u_i}) + \sum\limits_{e \in {{\cal G}_i}} {{\mu _e}} {h_{ke}}({u_k})} \right\}},~\text{else}.
\end{array} \right.
\end{align*}

From the dual function we obtain that if $M_{k}-\mu_e\ge0$ for any $e=1,\ldots,E$ and $k\in\mathcal{V}_e$, then the minimization of the relaxed dual function is equivalent to the minimization of the dual function of problem \eqref{eq:centralizedqp} that does not include any relaxation. Besides, the optimisation problems \eqref{eq:globalrelaxedcbf} and \eqref{eq:centralizedqp} both have zero duality gap since they are convex QPs. We conclude that solving the relaxed problem \eqref{eq:globalrelaxedcbf} yields the same minimizer as the original unrelaxed problem \eqref{eq:centralizedqp}, i.e. $\boldsymbol{u}_{\mathrm{dis}}^*=\boldsymbol{u}_{\mathrm{cen}}^*$. The cost function $J(\boldsymbol{u},\boldsymbol{\rho})$ is strongly convex with Lipschitz continuous gradient since it is a strict convex quadratic function over both $\boldsymbol{u}$ and $\boldsymbol{\rho}$.
\end{proof}

\begin{proof}[Proof of Theorem \ref{th:speed}]
Following the convergence analysis in \cite[Section III]{notarnicola2019constraint}, \eqref{eq:dcbf} and \eqref{eq:trunsubupdate} are doing gradient ascent over the dual problem
\begin{equation}\label{eq:dualproblem}
    \begin{split}
        \max_{}~& q_R(\boldsymbol{\mu})\\
        \mathrm{subject~to}~&\mu_{ie}=\mu_{ke},\forall i,k\in\mathcal{V}_e,e=1,\ldots,E.
    \end{split}
\end{equation}
Following the example \cite[Section 5.2.4, Eq. 5.28]{boyd2004convex}, the dual function $q_R(\boldsymbol{\mu})$ is a quadratic function with the quadratic part as
\begin{equation}\label{eq:quadraticmatrix}
    \boldsymbol{\mu}^\top\left[ {\begin{array}{*{20}{c}}
{{L_{{g_1}}}{b_{11}}^ \top }\\
 \vdots \\
{{L_{{g_N}}}{b_{NE}}^ \top }
\end{array}} \right]
\left[ {\begin{array}{*{20}{c}}
{{L_{{g_1}}}{b_{11}}^ \top }\\
 \vdots \\
{{L_{{g_N}}}{b_{NE}}^ \top }
\end{array}} \right]^\top\boldsymbol{\mu},
\end{equation}
Therefore, $q_{R}(\boldsymbol{\mu})$ is a $2\sigma_{\min}(\boldsymbol{x})$-strongly convex, and $2\sigma_{\max}(\boldsymbol{x})$-smooth function, where $\sigma_{\min}(\boldsymbol{x})$ and $\sigma_{\max}(\boldsymbol{x})$ are the minimal and maximal eigenvalues for the square matrix in \eqref{eq:quadraticmatrix}. By selecting stepsize $0\le\gamma\le1/(\sigma_{\min}(\boldsymbol{x})+\sigma_{\max}(\boldsymbol{x}))$, and leveraging dual ascent steps for \eqref{eq:dualproblem}, the $q_R(\boldsymbol{\mu}^k)$ converges to $q_R(\boldsymbol{\mu}^*)$ with linear convergence rate $\theta=1-\frac{\sigma_{\min}(\boldsymbol{x})}{\sigma_{\max}(\boldsymbol{x})}$ \cite{luenberger1984linear}. From the argument in \cite[Lemma 5.1]{camisa2021distributed},for any $k>0$, $q_R(\boldsymbol{\mu}^k)=\left(\sum_{i=1}^N||u_i^{k}-u^{\mathrm{des}}||^2+\rho_{\mathrm{sum}}^{k}\right)$, we obtain
\begin{equation}\label{eq:th3eq1}
\begin{split}
        &\sum_{i=1}^N ||u_i^{k+1}-u^{\mathrm{des}}||^2+\rho_{\mathrm{sum}}^{k+1}
        \\
        &\le\theta\left(\sum_{i=1}^N||u_i^{k}-u^{\mathrm{des}}||^2+\rho_{\mathrm{sum}}^{k}\right).
\end{split}
\end{equation}
Using the fact that $0\le||u^{k+1}-u^{\mathrm{des}}||^2\le P_i$, hence it can be dropped from \eqref{eq:th3eq1}, and $0\le||u^{k}-u^{\mathrm{des}}||^2\le P_i$, and combining this with \eqref{eq:th3eq1} we obtain
\begin{align}\label{eq:th3eq2}
        &\rho_{\mathrm{sum}}^{k+1}\le\theta\left(\sum_{i=1}^NP_i+\rho_{\mathrm{sum}}^k\right)\nonumber\\
        \Rightarrow &\rho_{\mathrm{sum}}^{k}-(\rho_{\mathrm{sum}}^k-\rho_{\mathrm{sum}}^{k+1})\le\theta\left(\sum_{i=1}^NP_i+\rho_{\mathrm{sum}}^k\right)\nonumber\\
        \Rightarrow&\rho_{\mathrm{sum}}^k-\rho_{\mathrm{sum}}^{k+1}\ge (1-\theta)\rho_{\mathrm{sum}}^k-\theta\sum_{i=1}^NP_i.\nonumber\\
\end{align} 
Combining \eqref{eq:th3eq2} with \eqref{eq:parameterselection}, we have
\begin{equation}\label{eq:th3eq3}
\begin{split}
    &\rho_{\mathrm{sum}}^k-\rho_{\mathrm{sum}}^{k+1}>(1-\theta)\sum_{i=1}^NM_i\epsilon_i-\theta\sum_{i}^N\frac{1-\theta}{\theta}M_i\epsilon_i\\
    \Rightarrow&\rho_{\mathrm{sum}}^k-\rho_{\mathrm{sum}}^{k+1}>0,
\end{split}
\end{equation}
where the inequality is strict due to the strict inequalities in \eqref{eq:parameterselection}.
Hence, we conclude the proof.
\end{proof}

\begin{proof}[Proof of Corollary \ref{co:convergence}]
Equation \eqref{eq:coro2eq1} in \emph{Case I}. The proof is conducted by considering two scenarios. For the ease of illustration, let $\epsilon=\sum_{i=1}^NM_i\epsilon_i$.

Firstly, consider the scenario where $\rho^0_{\mathrm{sum}}>\ldots>\rho_{\mathrm{sum}}^{k-1}>\rho_{\mathrm{sum}}^k>\epsilon$, and use the inequality $\rho_{\mathrm{sum}}^{k+1}\le\theta\left(\sum_{i=1}^NP_i+\rho_{\mathrm{sum}}^k\right)$ from \eqref{eq:th3eq2}. A proportional sequence $\{a^0,\ldots,a^{k+1}\}$ is defined by $a^0=\rho_{\mathrm{sum}}^0$, and $a^{k+1}=\theta\left(\sum_{i=1}^NP_i+a^k\right)$. By comparing the sequences $\{a^0,\ldots,a^{k+1}\}$ and $\{\rho_{\mathrm{sum}}^0,\ldots,\rho_{\mathrm{sum}}^{k+1}\}$, we have $\rho_{\mathrm{sum}}^{i}\le a^i$, for every $i=0,\ldots,k+1$. Clearly, we also have $a^{k+1}=\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i$, which shows that $\rho_{\mathrm{sum}}^{k+1}\le \theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i$.

Secondly, we consider the scenario where $\rho_{\mathrm{sum}}^k<\epsilon$. Suppose $\rho_{\mathrm{sum}}^k=\epsilon-\delta$, where $\delta\in(0,\epsilon)$. From \eqref{eq:th3eq2} we have $\rho^{k}_{\mathrm{sum}}-\rho^{k+1}_{\mathrm{sum}}\ge (1-\theta)\rho_{\mathrm{sum}}^k-\theta\sum_{i=1}^NP_i$. Then
\begin{align}\label{eq:coro2prof1}
        \rho_{\mathrm{sum}}^{k+1}&\le \theta\left(\rho_{\mathrm{sum}}^k+\sum_{i=1}^NP_i\right)\nonumber= \theta\left(\epsilon-\delta+\sum_{i=1}^NP_i\right)\nonumber\\
        &\le \theta\left(\epsilon-\delta+\frac{1-\theta}{\theta}\epsilon\right)=\epsilon-\theta\delta<\epsilon.\nonumber
    \end{align}
These two scenarios cover every possibility since if $\rho_{\mathrm{sum}}^k>\epsilon$, from the arguments in the second case we conclude that $\rho_{\mathrm{sum}}^{k-1}>\epsilon$. Directly this corresponds to the first case. Hence, the two cases are complementary, and we conclude the proof for \eqref{eq:coro2eq1}. \eqref{eq:coro2eq2} is proved by $\lim_{k\to\infty}\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i=\frac{\theta}{1-\theta}\sum_{i=1}^NP_i<\epsilon$. 
Equation \eqref{eq:coro2eq3} in \emph{Case II} follows then directly by setting $k=0$ in the second scenario above.

\end{proof}
\begin{proof}[Proof of Theorem \ref{th:confidence}]
We begin with prove that \eqref{eq:localupperbound} and \eqref{eq:localtruncation}, together with other prior conditions are sufficient for
\begin{equation}\label{eq:globalupperbound}
    \rho_{\mathrm{sum}}^\eta(\boldsymbol{x}^{(r)})\le \epsilon,\forall r=1,\ldots,\bar N.
\end{equation}
Substituting $\eta_i$ with $\eta$ in \eqref{eq:localtruncation} yields
\begin{align*}
    &\theta^{\eta}M_i \tilde{\epsilon_i}+\frac{\theta-\theta^{\eta+1}}{1-\theta}P_i\le M_i\epsilon_i,\forall i=1,\ldots,N\\
    \Rightarrow&\theta^\eta\sum_{i=1}^NM_i\tilde{\epsilon_i}+\frac{\theta-\theta^{\eta+1}}{1-\eta}\sum_{i=1}^NP_i\le \sum_{i=1}^NM_i\epsilon_i=\epsilon.
\end{align*}
According to \eqref{eq:localupperbound}, $\sum_{i=1}^NM_i\tilde{\epsilon_i}\ge \rho_{\mathrm{sum}}^0(\boldsymbol{x}^{(r)})$, using this term to substitute the first term on the left hand side, and we obtain
\begin{equation*}
    \theta^\eta\rho_{\mathrm{sum}}^0(\boldsymbol{x}^{(r)})+ \frac{\theta-\theta^{\eta+1}}{1-\theta}P_i\le \epsilon, \forall r=1,\ldots,\bar N.
\end{equation*}
Hence, from Corollary \ref{co:convergence}, we have \eqref{eq:globalupperbound} holds.

We next characterize the distribution of $\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})> \epsilon\}$. First, consider the random variables
\begin{equation*}
    \mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\delta_i\right\}, i=1,\ldots,N,
\end{equation*}
where $\delta_i=\sum_{e\in\mathcal{C}_i}\left(\frac{(\rho_{ie}^\eta(\boldsymbol{x}))^2}{M_i}+\rho_{ie}^\eta(\boldsymbol{x})\right)>\epsilon_i$ represents an event. Recall that every $\tilde{\epsilon}_i$ is calculated by solving \eqref{eq:localupperbound}, which is a \emph{fully supported} problem \cite[Definition 3]{campi2008exact}. Therefore, $\delta_i$ is a Beta variable with parameters $(1,\bar N)$ \cite[Theorem 1]{campi2008exact}, the cumulative distribution is given by
\begin{equation*}
    \mathbb{P}^{\bar N}\left\{ \mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\delta_i\right\}\le 1-\tilde{\varepsilon_i}\right\}= \beta_i, i=1,\ldots,N,
\end{equation*}
where $\tilde{\varepsilon_i}=\sqrt[\bar N-1]{1-\beta_i}$. Equivalently, we have
\begin{equation}\label{eq:dontnohowtoname}
    \mathbb{P}^{\bar N}\left\{ \mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\ge\tilde{\varepsilon_i}\right\}=\beta_i, i=1,\ldots,N,
\end{equation}
where $\bar{\delta_i}$ is the event complementary to $\delta_i$. We first show that
\begin{equation}\label{eq:prior}
    \mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\ge1-\sum_{i=1}^N\beta_i.
\end{equation}
We have that
\begin{align*}
    \mathbb{P}^{\bar N}&\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
    =& \mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
    \ge & \mathbb{P}^{\bar N}\left\{\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
    \ge & \mathbb{P}^{\bar N}\left\{\bigcap_{i=1}^N\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}\right\}\right\}\\
    \ge & 1- \sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}>\tilde{\varepsilon_i}\right\}
    \ge 1-\sum_{i=1}^N\beta_i,
\end{align*}
where the first inequality is due to subbatitivity of $\mathbb{P}$. The second inequality is since an element in the intersection $\bigcap_{i=1}^N\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}\right\}$ will also be in the set of samples such that $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}$ for all $i=1,\ldots,N$, and hence also in the set of samples such that $\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}$.
The third inequality follows from the second one using the set complement and the subbatitivity of $\mathbb{P}^{\bar N}$, while the last inequality is due to \eqref{eq:dontnohowtoname}.
Using \eqref{eq:prior}, we have
\begin{align*}
    \mathbb{P}^{\bar N}&\left\{\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})>\epsilon\}\ge 1-\sum_{i=1}^N\tilde{\varepsilon_i} \right\}\\
    \ge&\mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcap_{i=1}^N\delta_i\right\}\ge1-\sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
    =&\mathbb{P}^{\bar N}\left\{1-\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\ge1-\sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
    \ge&1-\sum_{i=1}^N\beta_i,
\end{align*}
thus concluding the proof.
\end{proof}
\vspace{-0.2cm}
\begin{proof}[Proof of Theorem \ref{th:probability}]
We have that 
\begin{align}\label{eq:scinequality1}
      \mathbb{P}^{\bar N}&\left\{\frac{\sum_{i=1}^N\underline\epsilon_i(s_i^*)}{N} \le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}  \right\} \le \sum_{i=1}^N\bar\epsilon_i(s_i^*)
    \right\}\nonumber\\
    &=\mathbb{P}^{\bar N}\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\vphantom{\bigcap_{i=1}^N}\boldsymbol{x}\in\mathcal{B}: \right.\right.\nonumber\\
    &\hspace{0.1cm}\exists i\in\{1,\ldots,N\},\left.\left.\vphantom{\bigcap_{i=1}^N}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\nonumber\\
    &=\mathbb{P}^{\bar N}\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\left\{\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right\}\right.\nonumber\\
    &\bigcap\left.\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right.\}
    \end{align}
    We separately deal with the inner and upper bounds on the probability. For the upper bound we have
    \begin{align*}
      \mathbb{P}^{\bar N}&\left\{\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\\
      \ge &\mathbb{P}^{\bar N}\left\{\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}.
    \end{align*}
    The equality is achieved when for any $i\ne j$, $\boldsymbol{z}^*\notin\mathcal{Z}_i$ and $\boldsymbol{z}^*\notin\mathcal{Z}_j$ are mutually exclusive.
    For the lower bound we have
    \begin{align*}
        \mathbb{P}^{\bar N}&\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\left\{\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right\}\right\}\\
        \ge &\mathbb{P}^{\bar N}\left\{N\cdot\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right\}.
    \end{align*}
    The equality is achieved if for any $i\ne j$, $\boldsymbol{z}^*\ne \mathcal{Z}_i\Leftrightarrow\boldsymbol{z}\ne\mathcal{Z}_j$ and $\underline{\epsilon}_i(s_i^*)=\underline{\epsilon}_j(s_j^*)$. The right-hand side of \eqref{eq:scinequality1} can be then lower-bounded by
    \begin{align}
    &\mathbb{P}^{\bar N}\left\{N\cdot\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right.\nonumber\\&\bigcap
    \left.\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\nonumber\\
        &\ge \mathbb{P}^{\bar N}\left\{\bigcap_{i=1}^N\left\{\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\le\bar\epsilon_i(s_i^*)\right\}\right\}\nonumber\\
        &\ge
        1-\sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\bar\epsilon_i(s_i^*)<\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right.\nonumber\\
        &\bigcup\left.\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}<\underline\epsilon_i(s_i^*)\right\}.
\end{align}
By \cite[Theorem 1]{garatti2019risk} we have that for any $i=1,\ldots,N$
\begin{align}\label{eq:scinequality2}
      &\mathbb{P}^{\bar N}\left\{\boldsymbol{x}\in\mathcal{B}:\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\vphantom{\bigcup}\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\le\bar\epsilon_i(s_i^*)\right\}\nonumber\\
      &\ge 1-\beta_i\nonumber\\
      \Rightarrow&\sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\bar\epsilon_i(s_i^*)<\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}\right.\nonumber\\
        &\bigcup\left.\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i  \right\}<\underline\epsilon_i(s_i^*)\right\}<\sum_{i=1}^N\beta_i.
\end{align}
Since $\frac{\underline \epsilon(s^*)}{N}<\underline\epsilon(s^*)<\bar\epsilon(s^*)$,
substituting \eqref{eq:scinequality2} into \eqref{eq:scinequality1} with $i=1,\ldots,N$ we obtain 
\begin{equation}\label{eq:55}
    \mathbb{P}^{\bar N}\left\{\frac{\underline\epsilon(s^*)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}  \right\}\le\bar\epsilon(s^*)
    \right\}\ge 1-\beta.
\end{equation}
We then prove that $\boldsymbol{z}^*$ is unique, and $\boldsymbol{z}^*=0$. For the case where all the CBF constraints are satisfied, i.e. $\sum_{k\in\mathcal{V}_e} h_{ke}(u_k(\boldsymbol{x}^{(r)}))\le 0,\forall e=1,\ldots,E$, $r=1,\ldots,\bar N$, we have that $\boldsymbol{z}^*=0$ and $\boldsymbol{\zeta}^*= 0$. For the case where there exists violated CBF constraint, i.e. $\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))>0$, we have that $z_{ie}^*=0$ since $\boldsymbol{z}\le 0$, and $\zeta_{ie}^*>0$ for $i\in\mathcal{V}_e$. In summary, we always have $\boldsymbol{z}^*=0$ for any scenarios, thus \eqref{eq:55} is equivalent to \eqref{eq:violation}. In addition, we directly obtain that $\zeta_{ie}^*> 0$ shows that $\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))> z_{ie}^*=0$. Thus, for every agent, $s_i^*$ is the number of non-zero $\zeta_{ie}^*$, for $e\in\mathcal{C}_i$.

\end{proof}

\bibliographystyle{ieeetr}
\bibliography{article.bib} 
\end{document}
