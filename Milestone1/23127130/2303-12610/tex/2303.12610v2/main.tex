\documentclass[twocolumn]{autart} 
\usepackage{generic}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{subcaption}
\usepackage{algorithmic}
\let\classAND\AND
\let\AND\relax
% \usepackage{romannum}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{cite}
\usepackage{textcomp}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{bbding}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{bm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
 T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\newtheorem{problem}{Problem}
\usepackage{threeparttable}
\allowdisplaybreaks
%\markboth{\journalname, VOL. XX, NO. XX, XXXX 2017}
%{Author \MakeLowercase{\textit{et al.}}: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS (February 2017)}
\begin{document}
\begin{frontmatter}
\title{Distributed { Safe} Control Design and Safety Verification for Multi-Agent Systems\thanksref{footnoteinfo}} % Title, preferably not more   % than 10 words.
\thanks[footnoteinfo]{For the purpose of Open Access, the authors have applied a CC BY public copyright licence to any Author Accepted Manuscript (AAM) version
arising from this submission.
Part of the results of this manuscript has been presented in the IEEE Conference on Decision and Control 2023 \cite{cdcsubmit}. Here we significantly extend the conference version by additionally evaluating a lower bound on the probability of safety in Section \ref{sec:safetyverification}, proposing a distributed safe controller design algorithm, and a truncated algorithm with rigorous safety analysis in Section \ref{sec:dscl}.}

\author{Han Wang}\ead{han.wang@eng.ox.ac.uk},  % Add the 
\author{Antonis Papachristodoulou}\ead{antonis@eng.ox.ac.uk},        % e-mail address 
\author{Kostas Margellos}\ead{kostas.margellos@eng.ox.ac.uk} % (ead) as shown

\address{OX1 3PJ, Department of Engineering Science, University of Oxford, Oxford, United Kingdom.} % Please supply                 

     
\begin{keyword}              % Five to ten keywords, 
Neural Network Controller, Data-Driven Control, Stability, Safety, Sum-of-Squares Programming       % chosen from the IFAC 
\end{keyword} 

\maketitle

\begin{abstract}
We propose distributed iterative algorithms for safe control design and safety verification for networked multi-agent systems. These algorithms rely on distributing a control barrier function (CBF) related quadratic programming (QP) problem. The proposed distributed algorithm addresses infeasibility issues of existing schemes by dynamically allocating auxiliary variables across iterations. The resulting control input is guaranteed to be optimal, and renders the system safe. Furthermore, a truncated algorithm is proposed to facilitate computational implementation. {The performance of the truncated algorithm is evaluated using a distributed safety verification algorithm. The algorithm quantifies safety for a multi-agent system probabilistically, using a certain locally Lipschitz continuous feedback controller by means of CBFs.} Both upper and lower bounds on the probability of safety are obtained using the so called scenario approach. Both the scenario sampling and safety verification procedures are fully distributed. The efficacy of our algorithms is demonstrated by an example on multi-robot collision avoidance.
\end{abstract}

\begin{keyword}
Distributed Control, Safe Control, Multi-Agent Systems, Scenario Approach, Nonlinear Systems
\end{keyword}
\end{frontmatter}


\section{Introduction}
\label{sec:intro}
Safety of a dynamical system requires the system state to remain in a safe set for all time. This property is important in many applications such as collision avoidance \cite{ding2022configuration,wang2019moving}, vehicle platooning \cite{axelsson2016safety,alam2014guaranteeing}, vehicle merging control \cite{xiao2021decentralized}, etc. For a single agent system, safety is usually captured by introducing constraints on the state of the agent and the environment. For a multi-agent system, the meaning of safety extends to capture the interactions among agents. In this case, safety is encoded by coupling constraints over the states of a group of agents. For a networked multi-agent system, where agents cooperate to satisfy safety constraints, we consider designing distributed algorithms to ensure safety for all agents. 

Another problem of interest is to validate the proposed control law. For a single agent system, an agent can evaluate the system behaviour to characterize its risk of being unsafe under the employed control input. Similarly, for a multi-agent safety verification problem, cooperation among agents is necessary since safety involves multiple agents. In summary, this paper focuses on designing a distributed protocol for safe control input design and developing a distributed safety verification algorithm.

\subsection{Related Work}
Safety in control systems is often certified by control barrier functions (CBF), which is a type of control Lyapunov-like functions \cite{ames2016control,sontag1989universal,primbs1999nonlinear}. By enforcing the inner product of the CBF derivative and vector field of the controlled system to be bounded, safety is rigorously guaranteed at any time. CBF is shown to be powerful and scalable in control input design for control-affine systems, as this condition can be encoded as a linear constraint in a quadratic programming (QP) problem \cite{ames2016control}. By solving online QP problems for every state, the system can be guaranteed to be safe \cite{hsu2015control,ames2014control}. 
% Higher-order derivative based methods for high relative degree systems are proposed in \cite{xiao2019control,nguyen2016exponential,tan2021high}. In \cite{xiao2021adaptive}, adaptive coefficients are introduced to improve the feasibility of the CBF-QP. For the case where multiple CBFs exist, an optimal decay based method is proposed to tune the CBF constraints \cite{zeng2021safety}. CBFs for discrete time systems are proposed in \cite{agrawal2017discrete}. For the case where model uncertainty and system noise are added, robust CBF with worst case analysis \cite{nguyen2021robust, jankovic2018robust} can be considered. 
Most of the existing results in this direction involve a centralized approach; however, multi-agent considerations call for distributed solution regimes. In this paper we address the distributed safety problem for multi-agent systems.

Related to the problem considered in this paper, CBFs for multi-robot systems were studied in \cite{chen2020guaranteed,wang2017safety,borrmann2015control}. These works propose to split the CBF constraints into two components for neighbouring agents: the computation is therefore distributed as every agent solves a local optimisation problem. An improved constraint sharing mechanism is developed in \cite{xu2018constrained}, where the CBF constraints are dynamically tuned for compatibility. Optimality is further considered in \cite{tan2021distributed}, and a dynamical constraint allocation scheme among agents based on a consensus protocol is proposed. In our work, we aim at dealing with the problem of feasibility and optimality simultaneously, as well as considering multiple CBF constraints for safety. In essence, the distributed CBF-based safe control design problem can be seen under the lens of distributed optimisation. 

Distributed optimisation for a multi-agent system aims to design a distributed protocol that involves solving an optimisation problem locally for every agent. Algorithms can be divided into two types, dual decomposition \cite{falsone2017dual,falsone2020tracking,shi2014linear,duchi2011dual} and primal decomposition-based \cite{margellos2017distributed,camisa2021distributed,notarnicola2019constraint,li2020distributed,nedic2010constrained}. Dual decomposition methods consider the dual problem, where each agent maintains a local copy of the dual variables. Constraint satisfaction is achieved by consensus over the dual variables. Primal decomposition methods directly decompose the primal problem into local problems. By local projection \cite{margellos2017distributed,li2020distributed,nedic2010constrained} or updating auxiliary variables \cite{camisa2021distributed,notarnicola2019constraint}, algorithms converge to centralized optimum under convexity assumptions. Such methods guarantee near feasibility as far as the constraints of the primal problem are concerned. As our problem has the same structure with the one considered in \cite{camisa2021distributed,notarnicola2019constraint}, primal decomposition methods are leveraged. 

Our first contribution is to provide a method for constructing a distributed, safe controller. To parallelize the computation, we leverage the primal decomposition method presented in \cite{notarnicola2019constraint} to decompose the coupling constraints via the introduction of auxiliary variables. We also introduce additional relaxation variables for every CBF constraint to overcome incompatibility issues of multiple safety certificates, and avoid compromising the control ability. Compared with other methods in the literature, our approach offers feasibility and optimality guarantees, and exhibits a sublinear convergence rate. 

To reduce the communication and computation burden, a truncation mechanism is proposed to allow us to terminate the algorithm prior to convergence. To give a probabilistic guarantee for safety over the state space, we leverage scenario approach \cite{campi2008exact,campi2018wait,calafiore2005uncertain,calafiore2006scenario,garatti2019risk}, which samples a number of independent states from the state space and enforces the constraint only at these realizations.

Another problem of interest in this work is safety verification. For a dynamical system, safety requires the trajectory to be within a safe set. Given the vector field, a target set and an unsafe set, solving a reach-avoid game \cite{margellos2011hamilton,lygeros2004reachability} yields a set from which all trajectories start can reach the target set without entering the unsafe set. In this sense, safety verification lies in the scope of reachability analysis. The main challenge here is how to solve the underlying Hamilton Jacobi partial differential equation. To bypass this difficulty, the barrier certificates method was proposed in a convex programming framework~\cite{prajna2004safety,prajna2007framework}. A barrier certificate identifies an invariant set inside the safe set. System trajectories cannot escape from the underlying invariant set, and this directly leads to safety. Numerical methods for verifying safety using barrier certificates with convex programs entails sum-of-squares (SOS) programs~\cite{prajna2002introducing,prajna2004sostools}, which are equivalent to semi-definite programs. In real applications, the system model and control input are usually not precisely known, or are even unknown. In this setup, another type of verification method \cite{akella2022barrier} using sampled data was proposed recently. Probabilistically guaranteed safety is ensured using the so called scenario approach \cite{campi2008exact,campi2018wait,calafiore2005uncertain,calafiore2006scenario,garatti2019risk}. 

A further contribution is that of constructing a distributed safety verification algorithm. Here we address the problem of certifying safety for a multi-agent system. We propose a scenario-based verification algorithm for a probabilistic quantification of safety. A sequential sampling algorithm is proposed to sample scenarios efficiently in a distributed fashion. For the probabilistic result, we extend the state-of-the-art result \cite[Theorem 1]{garatti2019risk} to the multi-agent setting. Both lower and upper bounds on the probability of being unsafe are established, while the safety verification program is also shown to be amenable to parallelization.


\subsection{Organization}
Section \ref{sec:dscl} proposes our distributed safe control design algorithm, including a truncated version and the associated mathematical analysis. Section \ref{sec:safetyverification} provides the distributed safety verification scheme, and the distributed scenario sampling algorithm. Section \ref{sec:simulation} demonstrates the control design and safety verification algorithms on a multi-robot system collision avoidance case study. Section \ref{sec:conc} concludes the paper and provides some directions for future research.

\section{Preliminaries}
\subsection{Notation}
\label{sec:nota}
We use $\mathbb{R}$, $\mathbb{R}^N$, $\mathbb{R}_+$ to represent the set of one-dimensional, $N$-dimensional and nonnegative real numbers, respectively. $\mathbb{N}$ is the set of natural numbers. For matrices $A$ and $B$, $A\preceq B$ implies $B-A$ is positive semi-definite.
A continuous function $\alpha(\cdot):(-b,a)\to (-\infty,+\infty)$ is said to be an extended class-$\mathcal{K}$ function for positive $a$ and $b$, if it is strictly increasing and $\alpha(0)=0$. $\mathcal{G}=(\mathcal{V},\mathcal{E})$ denotes a graph with a nodes set $\mathcal{V}$ and an edge set $\mathcal{E}$. Throughout the paper $\mathcal{S}$ is used for a safe set, $\mathcal{B}$ is used for an invariant set. Boldface symbols are used as stacked vectors for scalar or vector elements, e.g., $\boldsymbol{x}=[x_1^\top,\ldots,x_N^\top]^\top$. Specifically, $\boldsymbol{0}$ is vector whose elements are all zero, and $I$ is an identity matrix, with their dimensions being clear from the context. For a set $\mathcal{K}$, $|\mathcal{K}|$ denotes its cardinality. For a function $s(x):\mathbb{R}^n\to\mathbb{R}$, we use the calligraphic font to represent the corresponding zero-super level set, i.e., $\mathcal{S}:=\{\boldsymbol{x}|s(\boldsymbol{x})\ge 0\}$.

\subsection{Control Barrier Functions}
Consider a nonlinear control-affine system
\begin{equation}\label{eq:nonlnsys}
  \dot x = f(x)+g(x)u,
\end{equation}
with $x(t) \in{ \mathcal{X}}\subset\mathbb{R}^n$, $u(t) \in\mathcal{U}\subset \mathbb{R}^m$, $f(x):{ \mathcal{X}}\to\mathbb{R}^n,$ and $g(x):{ \mathcal{X}}\to \mathbb{R}^{n\times m}$. Both $f$ and $g$ are further assumed to be { locally Lipschitz continuous on a compact set $\mathcal{X}\subset \mathbb{R}^n$.} The existence and uniqueness of solutions $x(u(\cdot),t,x_0)$ is assumed where $x_0$ is the initial state.

The safe set $\mathcal{S}$ is represented by the zero-super level set of a continuously differentiable function $s(x)$. Dually, the unsafe set $\bar{\mathcal{S}}$ can be defined as the complementary set. {We denote by $\mathcal{S}$ the safe set, by $\partial{\mathcal{S}}$ the boundary of the safe set, by $\mathrm{Int}(\mathcal{S})$ the interior of the safe set, and by $\bar{\mathcal{S}}$ the unsafe set, respectively.}
With this formulation, the safe control design problem boils down to finding $u(\cdot)\in\mathcal{U}$, such that { $s(x(u(\cdot),t,x_0))\ge 0$} for any $t$. To achieve this, a control barrier function-based quadratic programming approach was proposed \cite{ames2016control}.

Control barrier functions are an extension to barrier certificates \cite{prajna2004safety} for safety verification. It has been revealed in these papers that safety is closely related to the notion of \textit{control invariance}.
\begin{defn}\label{def:invariance}
A set $\mathcal{B} \subset \mathbb{R}^n$ is said to be control invariant with respect to \eqref{eq:nonlnsys}, if for any $x_0\in\mathcal{B}$, there exists $u\in\mathcal{U}$ such that $\psi(u,t,x_0)\in\mathcal{B}$.
\end{defn}
The relationship between safety and control invariance is demonstrated in the following equivalence lemma.
\begin{lem}[\protect{\cite{taly2009deductive}}]\label{lem:safetyinvariance}
System \eqref{eq:nonlnsys} is able to maintain safety under $\mathcal{S}$, if and only if there exists a control invariant set $\mathcal{B}\subseteq\mathcal{S}$. 
\end{lem}
Clearly, given a control invariant set $\mathcal{B}$, a safe control input $u(x)$ always exists for any $x\in\mathcal{B}$. The control barrier function approach answers the question of how to design a closed loop safe control input $u(x)$ inside $\mathcal{B}$. The notion of control barrier functions is related to the notion of extended class-$\mathcal{K}$ functions.
\begin{defn}
For the control-affine dynamical system \eqref{eq:nonlnsys}, a continuously differentiable function $b(\cdot):\mathbb{R}^n\to \mathbb{R}$ is said to be a control barrier function, if there exists an extended class-$\mathcal{K}$ function $\alpha(\cdot)$, such that for any $x\in\mathcal{B}$,
\begin{equation}\label{eq:cbf}
 \mathop{\sup\limits_{u\in\mathcal{U}}}[\mathcal{L}_fb(x)+\mathcal{L}_gb(x)u+\alpha(b(x))]\ge0.
\end{equation}
Here $\mathcal{L}_fb(x)$ and $\mathcal{L}_gb(x)$ are Lie derivatives, which are defined by $\mathcal{L}_fb(x):=\frac{\partial b(x)}{\partial x}f(x)$ and $\mathcal{L}_gb(x):=\frac{\partial b(x)}{\partial x}g(x)$, respectively.
\end{defn}
Given a control barrier function $b(x)$, the control admissible set corresponding to \eqref{eq:cbf} is defined by
\begin{equation}\label{eq:cbfset}
  K_{cbf}(x):=\{u\in\mathcal{U}:\mathcal{L}_fb(x)+\mathcal{L}_gb(x)u+\alpha(b(x))\ge0\}.
\end{equation}
\begin{thm}{\cite[Corollary 2]{ames2016control}}\label{th:theo1}
Consider a control barrier function $b(x)$. Then for any $x\in\mathcal{B}$, any locally Lipschitz continuous controller $u(x)$ such that $u(x)\in K_{cbf}(x)$ will render the set $\mathcal{B}$ control invariant.
\end{thm}

% \subsection{Multi-agent Optimisation Problem}
% A local distributed optimisation problem is the problem of finding a global optimum for an optimisation problem over a network of agents, where every agent has access to a local decision variable, and agents are coupled through the constraints.
% Unlike the usual setting, our problem involves two types of coupled constraints, i.e. \emph{pair-wise constraints} and \emph{group constraints}.

% Consider a networked system of $N$ agents communicating over a connected and undirected graph $\mathcal{G}$, with nodes set $\mathcal{V}=\{1,\ldots,N\}$, and edge set $\mathcal{E}$ such that $\{i,j\}\in\mathcal{E}$ if agent $j$ communicates with agent $i$. In addition to the pair-wise interaction relationship, agents are also grouped in $E$ sub-networks. For each sub-network $\mathcal{G}_e$, $e=1,\ldots,E$, the set of grouped agents is $\mathcal{V}_e \subseteq \mathcal{V}$. The multi-agent distributed optimisation problem that needs to be solved in a distributed manner can then be defined as
% \begin{equation}\label{eq:ldop}
%   \begin{split}
%     \min_{\boldsymbol{x}}&\sum_{i=1}^NJ_i(x_i)\\
%     \mathrm{subject~to}~&x_i\in\mathcal{X}_i,\forall i=1,\ldots,N,\\
%     &\sum_{k\in\mathcal{V}_e} h_{ke}(x_k)\le0,\forall e=1,\ldots,E,
%   \end{split}
% \end{equation}
% where for all $i=1,\ldots,N$, $x_i\in\mathbb{R}^{d_i}$ for some $d_i\in\mathbb{N}$. Also, $J_i(x_i):\mathbb{R}^{d_i}\to \mathbb{R}$. For all $k\in\mathcal{V}_e$, $h_{ke}:\mathbb{R}^{d_k}\mapsto \mathbb{R}$ stand for the group constraints that agents $k$ decisions need to satisfy. Variables $\mu_e\ge 0$ denotes the Lagrange multiplier associated with the inequality constraint $\sum_{k\in\mathcal{V}_e}h_{ke}(x_k)\le 0$. The function $h_{ke}(x_k)$ is not necessarily the same for every $k$ in the same sub-network. Our goal is to split \eqref{eq:ldop} into $N$ sub-problems of which the decision variables are only the local variables of each agent, thus enabling paralleled computation. 


% Agent $k$ may have no prior knowledge of function $h_{ke}(x_k)$, of which the expression is partially parameterized and determined by other agents in the group. This is because in our problem functions $h_{ke}(x_k)$ are determined by every agent in group $e$. To address this issue, we first \emph{assume} that agent $k$ has full knowledge of $h_{ke}(x_k)$. This assumption can be removed by transmitting some information other than the whole function expression in Section \ref{sec:dscl}.

% \subsection{Scenario Optimisation}
% Scenario optimisation is a data-driven robust optimisation methodology where one aims at searching for an optimum over sets. For the case where the sets are continuous, and possibly nonconvex or unknown, this kind of optimisation problem is usually hard to solve with guaranteed robustness. The scenario approach, on the other hand, proposes to solve the problem over finite empirical records, named \emph{scenarios} for a certain confidence of feasibility of the optimal solution. An uncertain optimisation problem is formulated as
% \begin{equation}\label{eq:uncertain}
% \begin{split}
%   \min_{x\in\mathcal{X}}~&c^\top x\\
%   \mathrm{subject~to}~&x\in\mathcal{X}_{\delta},~\text{for all}~\delta\in\Delta,
% \end{split} 
% \end{equation}
% where $x\in\mathbb{R}^n$ is a decision variable constrained by a convex set $\mathcal{X}\subseteq\mathbb{R}^n$, $c\in\mathbb{R}^n$ is a constant vector. The convex uncertain constraint set $\mathcal{X}_{\delta}$ is parameterized by an uncertain parameter $\delta$, which is a random variable defined on a probability space $(\Delta,\mathcal{F},\mathbb{P})$. As discussed above, directly solving the problem \eqref{eq:uncertain} involves addressing infinite constraints for continuous set $\Delta$. Alternatively, the scenario approach proposes to solve the problem by encoding the constraint only on scenarios.

% The corresponding prototype convex scenario optimisation problem is formulated as

% \begin{equation}\label{eq:scenario}
% \begin{split}
%   \min_{x\in\mathcal{X}}~&c^\top x\\
%   \mathrm{subject~to}~&x\in\bigcap_{i=1,\ldots,N}\mathcal{X}_{\delta_i},
% \end{split} 
% \end{equation}
% where $\delta_i$, $i=1,\ldots,N$ are \emph{scenarios} sampled independently from the set $\Delta$. The scenario optimisation \eqref{eq:scenario} is a convex optimisation problem which can be solved efficiently. Clearly, the optimal solution $x_N^*\in\bigcap_{i=1,\ldots,N}\mathcal{X}_{\delta_i}$, but is not necessarily within $\mathcal{X}_\delta$ for an arbitrary new $\delta\in\Delta$. The following definition of violation probability comes along with the result.
% \begin{defn}[violation probability]
%   The violation probability of a a given $x\in\mathcal{X}$ is defined as $V(x)=\mathbb{P}\{\delta\in\Delta:x\notin\mathcal{X}_\delta\}$.
% \end{defn}




% \section{Distributed Optimisation Protocol}
% \label{sec:dop}
% In this section we show how to split \eqref{eq:ldop} into $N$ sub-problems which only require local computation for each agent. Problem \eqref{eq:ldop} has a separable structure but coupling constraints are also presented. For the purposes of distributed computation, one idea is to substitute the neighbours' contributions to the coupling constraints by dynamically allocated resources, which are auxiliary variables in the computation.

% \begin{algorithm}[h]
%  \caption{Local Constrained Relaxation Splitting (LCRS) Algorithm for agent $i$}
%  \hspace*{\algorithmicindent} \textbf{Initialization} Predefined $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$.\\
% \hspace*{\algorithmicindent} \textbf{Output:} Optimal solution $x_i^*$.\\
% \vspace{-3ex}
%  \begin{algorithmic}[1]\label{al:dcbf}
%  \WHILE{Not reaching convergence}
%  \STATE \textbf{Receive} \label{step:firstcommunication} $\lambda_{il}^k$ from $\forall l\in\mathcal{N}_i\cap \mathcal{V}_e,\forall e\in\mathcal{C}_i$.
%  \STATE \label{step:firstcomputation} \textbf{Compute} $((x_i^{k+1},\boldsymbol{\rho}^{k+1}_i),\boldsymbol{\mu}^{k+1}_i)$ as a primal-dual solution of the following optimisation problem.
%  \begin{equation}\label{eq:problem}
%    \begin{split}
%      \min_{x_i,\boldsymbol{\rho}_i}~&J_i(x_i) +\sum_{e\in\mathcal{C}_i} M_{i}\rho_{ie}\\
%      \mathrm{subject~to}~&x_i\in\mathcal{X}_i,\boldsymbol{\rho}_i\ge0,\\
%      &h_{ie}(x_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie},\forall e\in\mathcal{C}_i.
%    \end{split}
%  \end{equation}
%  \STATE \textbf{Receive} \label{step:secondcommunication} $\mu_{le}^{k+1}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$.
%  \STATE \textbf{Update} \label{step:secondcomputation} $\lambda_{il}$ by 
%  \begin{align}\label{eq:subupdate}
%    &\lambda_{il}^{k+1}=\lambda_{il}^k-\gamma^k(\mu_{ie}^{k+1}-\mu_{le}^{k+1}).
%  \end{align}
%  \ENDWHILE
%  \end{algorithmic}
% \end{algorithm}

% \begin{prop}[Adapted from \cite{notarnicola2019constraint}]\label{pro:lowerbound}
% Consider \eqref{eq:ldop} and denotes its minimizer by $\boldsymbol{x}^*_{\mathrm{cen}}$. The optimal solution returned by Algorithm \ref{al:dcbf} for agents $1,\ldots,N$ is denoted by $\boldsymbol{x}^*_{\mathrm{dis}}$. Then $\boldsymbol{x}^*_{\mathrm{dis}}=\boldsymbol{x}^*_{\mathrm{cen}}$ if $M_{i}\ge \mu_e$, for any $e=1,\ldots,E$, and $i\in\mathcal{V}_e$.
% \end{prop}


\section{Distributed Safe Control Law}
\label{sec:dscl}
% After proposing \eqref{eq:ldop} and its distributed solution, we are now in a position to use the proposed algorithm for \emph{distributed safe control input design}. 

Consider an $N$-agent system with the dynamics of the $i$-th agent described by
\begin{equation}\label{eq:dynamics}
  \dot x_i=f_i(x_i)+g_i(x_i)u_i,
\end{equation}
where $x_i(t)\in{ \mathcal{X}_i\subset}\mathbb{R}^{n_i}$ denotes its state, $u_i\in\mathcal{U}_i\subseteq \mathbb{R}^{m_i}$ denotes its control input. The dynamics $f_i(x_i):{ \mathcal{X}_i}\to\mathbb{R}^{n_i}$ and $g_i(x_i):{ \mathcal{X}_i}\to\mathbb{R}^{n_i}\times\mathbb{R}^{m_i}$ are both locally Lipschitz-continuous { on a compact set $\mathcal{X}_i\subset\mathbb{R}^{n_i}$, which represents the domain of each agent.} Vector $\boldsymbol{x}=[x_1^\top,\ldots,x_N^\top]^\top$ stacks the states of all systems, $\boldsymbol{u}=[u_1^\top,\ldots,u_N^\top]^\top$ stacks the control inputs, while $f(\boldsymbol{x})$, $g(\boldsymbol{x})$ stack the dynamics for each agent. {The domain and control admissible set for the multi-agent system are then defined by
\begin{equation*}
  \mathcal{X}:=\prod_{i=1}^N\mathcal{X}_i, \mathcal{U}:=\prod_{i=1}^N\mathcal{U}_i,
\end{equation*}
where $\prod$ represents the Cartesian product for the state space of all the agents. Given that all $\mathcal{X}_i$, $i=1,\ldots,N$, are assumed to be compact, compactness of $\mathcal{X}$ is assured using Tychonoff's theorem \cite{wright1994tychonoff}.} In this way, the system dynamics of the whole multi-agent system can be compactly modelled by $\dot{\boldsymbol{x}}=f(\boldsymbol{x})+g(\boldsymbol{x})\boldsymbol{u}$.

The networked system is described by an undirected graph $\mathcal{G}$, with nodes set $\mathcal{V}=\{1,\ldots,N\}$, and edges set $\mathcal{E}$ such that $\{i,j\}\in\mathcal{E}$ if agent $j$ communicates with agent $i$. Agents are grouped in $E$ sub-networks with specific safety requirement. For each sub-network $\mathcal{G}_e$, $e=1,\ldots,E$, the set of grouped agents is $\mathcal{V}_e \subseteq \mathcal{V}$. Let $\boldsymbol{x}_e=[x_i^\top]^\top_{i\in\mathcal{V}_e}$ be the stacked states in group $e$. Each agent $i$ can communicate and cooperate with its neighbour $j\in\mathcal{N}_i$ to stay safe inside group $e$ by ensuring 
\begin{equation}
\boldsymbol{x}_e\in\mathcal{S}_e:=\{\boldsymbol{x}_e:s_e(\boldsymbol{x}_e)\ge 0\},
\end{equation}
where $s_e(\cdot)\in\mathbb{R}$. We let $\mathcal{C}_i$ be the set of constraints agent $i$ participates in; then we have $\mathcal{V}_e=\{i|e\in\mathcal{C}_i\}$. 

\begin{assum}[Connectivity]
For each $e=1,\ldots,E$, sub-network $\mathcal{G}_e$ is connected and undirected.
\end{assum}

\begin{assum}\label{ass:barrier}
Suppose $\mathcal{S}=\bigcap_{e=1}^E\mathcal{S}_e\ne\emptyset$. There exists $E$ control barrier functions $b_e(\cdot)$, such that $\mathcal{B}_e:=\{\boldsymbol{x}_e:b_e(\boldsymbol{x}_e)\ge 0\}\subseteq \mathcal{S}_e$, and $\mathcal{B}=\bigcap_{e=1}^E\mathcal{B}_e\ne\emptyset$. { Moreover, $\mathcal{H}:=\mathcal{B}\cap\mathcal{X}\ne \emptyset$.}
\end{assum}
% 
\begin{assum}
  For the multi-agent system \eqref{eq:dynamics} and CBFs $b_e(\boldsymbol{x}_e)$, $e=1,\ldots,E$. For every $\boldsymbol{x}\in{\mathcal{B}}$, there exists $\boldsymbol{u}=[u_1^\top\in\mathcal{U}_1,\ldots,u_N^\top\in\mathcal{U}_N]^\top\in\mathcal{U}$, such that for any $e=1,\ldots,E$:
  \begin{equation}
    \sum_{k\in\mathcal{V}_e}\left(\frac{\partial b_e}{\partial x_k}(f_k(x_k)+g_k(x_k)u_k)+\alpha_{ke}(b_e)\right)\ge 0.
  \end{equation}
\end{assum}

Following \cite[Theorem 3]{ames2016control}, safety constraints can be incorporated in the CBF-QP formulation given by
\begin{align}\label{eq:centralizedqp}
J^*=\min_{\boldsymbol{u}\in\mathcal{U}}&\sum_{i=1}^N ||u_i-u_i^{\mathrm{des}}(x_i)||_2^2\nonumber\\
        \text{s.t.} &\sum_{k\in\mathcal{V}_e}\left(\frac{\partial b_{e}}{\partial x_k}(f_k(x_k)+g_k(x_k)u_k)+\alpha_{ke}(b_{e})\right)\ge 0,\nonumber\\
    &\forall e=1,\ldots,E,
\end{align}
where $\alpha_{ke}(\cdot)$ (and hence also $\sum_{k\in\mathcal{V}_e}\alpha_{ke}(\cdot)$ is also a class-$\mathcal{K}$) are class-$\mathcal{K}$ functions, while $u_i^{\mathrm{des}}(x_i)$ is a nominal stabilizing control input. Let
\begin{equation}\label{eq:substi}
  \begin{split}
    J_i(u_i)&=||u_i-u_i^{\mathrm{des}}(x_i)||_2^2, \\
    h_{ie}(u_i)&=-\left(\frac{\partial b_{e}}{\partial x_i}(f_i(x_i)+g_i(x_i)u_i)+\alpha_{ie}(b_{e})\right).
  \end{split}
\end{equation}

\begin{assum}\label{ass:slater}
  For every $\boldsymbol{x}\in\mathcal{B}$, there exists $\boldsymbol{u}(\boldsymbol{x}){ \in\mathcal{U}}$, such that $h_{ie}<0$ for all $e=1,\ldots,E$, $i\in\mathcal{V}_e$. 
\end{assum} 

Notice that, even not shown explicitly, $h_{ie}(u_i)$ depends on $x_i,i\in\mathcal{V}_e$. We also highlight that \eqref{eq:centralizedqp} is parameterized in $\boldsymbol{x}$, which can be thought of as constant as for the optimisation problem in \eqref{eq:centralizedqp} is concerned. {Under Assumption \ref{ass:slater}, problem \eqref{eq:centralizedqp} is always feasible for all $x\in\mathcal{B}$.}
To begin with our analysis, we propose a relaxed version of \eqref{eq:centralizedqp} {to guarantee feasibility of the local problems in the proposed distributed algorithm. This will be clarified in the sequel}.
\begin{align}\label{eq:relaxedqp}
    H^*=\min_{\boldsymbol{u}\in\mathcal{U},\boldsymbol{\rho}\ge 0}H(\boldsymbol{u},\boldsymbol{\rho}):=\nonumber\\
    \sum_{i=1}^N&\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}(\rho^2_{ie}+M_{i}\rho_{ie})\right\}\nonumber\\
\mathrm{subject~to~}\sum_{i\in\mathcal{V}_e}&h_{ie}(u_i) \le\rho_{ie}, e=1,\ldots,E.
\end{align}
Let $\mu_e$ be the optimal dual solution for the constraint $\sum_{i\in\mathcal{V}_e}h_{ie}(u_i)\le \rho_{ie}$. 
Feasibility of problem \eqref{eq:relaxedqp} is clear, as the positive variable $\boldsymbol{\rho}$ relaxes the linear constraints. Optimality is analyzed in the following lemma. 
\begin{lem}\label{lem:newproperty}
Denote the minimizer of problem \eqref{eq:centralizedqp} by $\boldsymbol{u}_{\mathrm{nom}}^*(\boldsymbol{x})$, and the minimizer of problem \eqref{eq:relaxedqp} by $\boldsymbol{u}_{\mathrm{rel}}^*(\boldsymbol{x})$. Then $\boldsymbol{u}_{\mathrm{rel}}^*(\boldsymbol{x})=\boldsymbol{u}_{\mathrm{nom}}^*(\boldsymbol{x})$, and $\boldsymbol{\rho}^*=0$ if
\begin{equation}\label{eq:lem2eq1}
  M_{i}\ge\mu_{e},\forall i\in\mathcal{V}_e, \forall e=1,\ldots,E.
\end{equation}
Besides, the cost function $H(\boldsymbol{u},\boldsymbol{\rho})$ is strongly convex and has a Lipschitz continuous gradient.
\end{lem}
{ 
\begin{pf}
  See Appendix.
\end{pf}
}
\subsection{Full Control Law}
We now design an algorithm to solve the centralized CBF-QP problem \eqref{eq:centralizedqp} in a distributed manner; see Algorithm \ref{al:dcbf}.
\begin{algorithm}[h]
 \caption{Distributed Safe Control Design Algorithm for agent $i$ at $x_i$}
  \hspace*{\algorithmicindent} \textbf{Initialization} Arbitrary $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$.\\
  \hspace*{\algorithmicindent} \textbf{Receive} $x_k$ for any $k\in\mathcal{V}_e\backslash i$ from $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
  \hspace*{\algorithmicindent} \textbf{Send} $x_i$ to any $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$.\\
 \hspace*{\algorithmicindent} \textbf{Output:} Optimal control input $u_i^*$\\
 \vspace{-3ex}
 \begin{algorithmic}[1]\label{al:dcbf}
 \WHILE{Not reaching convergence}
 \STATE \textbf{Receive} \label{step:firstcommunication} $\lambda_{il}^k$ from $\forall l\in\mathcal{N}_i\cap \mathcal{V}_e,\forall e\in\mathcal{C}_i$.
 \STATE \label{step:firstcomputation} \textbf{Solve} $((u_i^{k+1},\boldsymbol{\rho}_i^{k+1}),\boldsymbol{\mu}_i^{k+1})$ as a primal-dual solution of the following optimisation problem
 \begin{equation}\label{eq:dcbf}
   \begin{split}
     \min_{u_i,\boldsymbol{\rho}_i}~&J_i(u_i) +\sum_{e\in\mathcal{C}_i}(\rho_{ie}^2+ M_{i}\rho_{ie})\\
     \mathrm{s.t.}~&u_i\in\mathcal{U}_i,\rho_{ie}\ge0,\\
     &h_{ie}(u_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie},\forall e\in\mathcal{C}_i.
   \end{split}
 \end{equation}
 \STATE \textbf{Receive} \label{step:secondcommunication} $\mu_{le}^{k+1}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$.
 \STATE \textbf{Update} \label{step:secondcomputation} $\lambda_{il}$ by  
 \begin{align}\label{eq:trunsubupdate}
   &\lambda_{il}^{k+1}=\lambda_{il}^k-\gamma^k(\mu_{ie}^{k+1}-\mu_{le}^{k+1}).
 \end{align}
 \ENDWHILE
 \end{algorithmic}
\end{algorithm}
Since $h_{ie}(u_i)$ also depends on $x_k$ for $k\in\mathcal{V}_e\backslash \{i\}$, an additional communication round at the beginning of the algorithm is designed. For all $i=1,\ldots,N$, and $e\in\mathcal{C}_i$, agent $i$ is to receive $x_k$ for any $k\in\mathcal{V}_e\backslash \{i\}$ from agent $l\in\mathcal{N}_i\cap\mathcal{V}_e$. Within a finite number of communication rounds, agent $i$ can gather all the other agents' states in sub-networks $e\in\mathcal{C}_i$. Then, for any $e\in\mathcal{C}_i$, functions $h_{ie}(u_i)$ can be constructed as in \eqref{eq:substi}.

There are two main computation and two communication steps in the algorithm. In the first computation step (Step \ref{step:firstcomputation}), agent $i$ solves the optimisation problem \eqref{eq:dcbf} to obtain the optimal primal-dual solution $((u_i^{k+1},\boldsymbol{\rho}^{k+1}_i),\boldsymbol{\mu}^{k+1}_i)$, where $\boldsymbol{\rho}_i$ includes relaxation variables denoted by $\rho_{ie}$ (penalized in the cost by $M_{i}$), and $\boldsymbol{\mu}_i$ includes the dual variables $\mu_{ie}$, for all $e\in\mathcal{C}_i$ and $l\in\mathcal{N}_i\cap\mathcal{V}_e$. In practice, $\mu_{ie}$ corresponds to the constraints allocated to agent $i$, i.e. $h_{ie}(x_i)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\le \rho_{ie}$. Moreover, the constraints in the distributed problem \eqref{eq:dcbf} are relaxed by an additional non-negative relaxation variable $\rho_{ie}$. This guarantees the feasibility of the local optimisation problem by loosing the restriction of the original constraints. However, this does not necessarily imply satisfaction of the CBF constraints in \eqref{eq:centralizedqp} by using $\boldsymbol{u}^{k+1}$. The interpretation of this kind of infeasibility in CBF-QP application is that, there is no admissible control input that renders the agent system safe with the CBFs and given auxiliary variables. 

The first computation step uses auxiliary variables $\lambda_{il}^k$ and $\lambda_{li}^k$. The difference $\lambda_{il}^k-\lambda_{li}^k$ constitutes estimates of the neighbouring terms $h_{le}(u_l)$. $\lambda_{il}^0$ is initialized arbitrarily. As we will show in Theorem \ref{th:speed}, the initialization will not influence convergence to the optimizer. Among all these variables, $\lambda_{le}^k$ for $l\in\mathcal{N}_i\cap\mathcal{V}_e$ are updated and stored by neighbours. They are available by agent $i$ via communication in Step \ref{step:firstcommunication}. We note here that for all $l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\lambda_{il}$ and $\lambda_{li}$ are all scalars, hence the communication burden will not be high. 
The second computation step is to update the local auxiliary variables by means of \eqref{step:secondcomputation}. Part of the dual variables used in the update are received from the neighbours in the second communication round, i.e. Step \ref{step:secondcommunication}. Here the update is a gradient-like procedure, with stepsize $\gamma>0$. The dual variables will be bounded provided that the auxiliary variables are also bounded. 
%This is evident by evaluating the KKT equations, and analyzing the activeness of the constraints around the optimal solution.

Algorithm \ref{al:dcbf} is fully distributed, where the two computation and communication steps can be carried out locally by each agent. Differently from the setting in \cite[Algorithm RSDD]{notarnicola2019constraint}, the relaxation penalty in the cost includes now a quadratic term. This renders the cost function strongly convex, allowing for superior convergence properties and ensuring the minimizer $u_i^*$ is unchanged. 

We directly have the following \emph{optimality} and \emph{safety} results.
\begin{thm}\label{th:safety}
For every $\boldsymbol{x}\in\mathcal{B}$, the optimal distributed control input $\boldsymbol{u}^*(\boldsymbol{x})$ returned by Algorithm \ref{al:dcbf} coincides with the optimal centralized control input solved using \eqref{eq:centralizedqp}. Besides, the optimal distributed control input renders $\mathcal{B}$ invariant.
\end{thm}

Among different types of distributed optimisation algorithms, \cite[Algorithm RSDD]{notarnicola2019constraint} is selected here for its ability to guarantee almost-safety in iterations. This is realized by allocating the auxiliary variables $\boldsymbol{\lambda}$, while balancing the safety requirement to every agent. We say ``almost" here since additional relaxation variables are introduced in every local optimisation problem for feasibility. In high-frequency applications, the algorithm may stop before reaching convergence. When the relaxation variables $\boldsymbol{\rho}^k=0$ for a $k>0$, then for any $e=1,\ldots,E$ we have that
\begin{equation*}
\begin{split}
  &\sum_{i\in\mathcal{V}_e}h_{ie}(u_i^k)=\sum_{i\in\mathcal{V}_e}\underbrace {\left\{h_{ie}(u_i^k)+\sum_{l\in\mathcal{N}_i\cap\mathcal{V}_e}(\lambda_{il}^k-\lambda_{li}^k)\right\}}_{ \le 0}\le 0,
\end{split}
\end{equation*}
which implies that the CBF constraints are satisfied with any control input solving \eqref{eq:dcbf} at iteration $k$.
The next theorem gives the convergence result. 
\begin{thm}\label{th:speed}
Consider Assumption \ref{ass:slater}, and let $M_i\ge \mu_{e}$ for every $i=1,\ldots,N$, $e=1,\ldots,E$. For every $i=1,\ldots,N$, and any initialized $\boldsymbol{\lambda}^0$,
\begin{itemize}
  \item [(a)] if $\mathcal{U}_i\subset\mathbb{R}^{m_i}.$ Choose the sequence $\{\gamma^k\}_{k\ge 0}$, with each $
  \gamma^k\ge 0$, and $\sum_{k=0}^\infty \gamma^k=\infty$, $\sum_{k=0}^\infty(\gamma^k)^2<\infty$. Then we have $\lim_{k\to\infty}H(\boldsymbol{u}^k,\boldsymbol{\rho}^k)-J^*\to 0$, and $\boldsymbol{u}^k$ converges to the primal optimal solution of \eqref{eq:centralizedqp}.
  \item [(b)] if $\mathcal{U}_i=\mathbb{R}^{m_i}$. Let the step size $\gamma^k=\gamma$ be small as \eqref{eq:stepsize}. $H(\boldsymbol{u}^k,\boldsymbol{\rho^k})$ converges to the optimal cost $J^*$ in \eqref{eq:centralizedqp} sublinearly, i.e. $H(\boldsymbol{u}^k,\boldsymbol{\rho}^k)-J^*\le \frac{2||\boldsymbol{\lambda^0}-\boldsymbol{\lambda^*}||_2^2}{\gamma k}$, and $\boldsymbol{u}^k$ converges to the primal optimal solution of \eqref{eq:centralizedqp}.
\end{itemize}
% \begin{subequations}\label{eq:parameterselection}
% \begin{align}
%   \sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^k)^2}{M_i}+\rho_{ie}^k)>\epsilon_i,\forall i=1,\ldots,N,\label{eq:para1}\\
%   \frac{P_i}{M_i}<\frac{1-\theta}{\theta}\epsilon_i,\forall i=1,\ldots,N,\label{eq:para2}
% \end{align}
% \end{subequations}
% then $0\le\rho_{\mathrm{sum}}^{k+1}<\rho_{\mathrm{sum}}^k$.
\end{thm}
\begin{pf}
  See Appendix.
\end{pf}

% Note that $\theta,\rho_{\mathrm{sum}}^k$, $\rho_{\mathrm{sum}}^{k+1}$, $u_i^k$, $u_i^{k+1}$ are functions of $\boldsymbol{x}$. We drop the arguments for simplicity. 
% Theorem \ref{th:speed} establishes that under tolerance $\epsilon_1,\ldots,\epsilon_N$, $\rho_{\mathrm{sum}}$ decreases monotonically when parameters $M_i$, $i=1,\ldots,N$ satisfy \eqref{eq:parameterselection}. The requirement of $M_i$ in Lemma \ref{lem:newproperty} is consistent with that of \eqref{eq:parameterselection}. With large enough $M_i$, \eqref{eq:para1} is approximated by $\sum_{e\in\mathcal{C}_i}\rho_{ie}^k>\epsilon_i$, which represents the case that the local control law $u_i$ violates the CBF constraint by at least $\epsilon_i$, while \eqref{eq:para2} and \eqref{eq:lem2eq1} hold. 

%We note here that it is $\rho_{\mathrm{sum}}$ but not every $\rho_{ie}$ that is necessary to decrease in every iteration. However, for any $e=1,\ldots,E$, for all $i\in\mathcal{V}_e$, $\nabla_{\rho_{ie}}\rho_{\mathrm{sum}}>0$, and $\lim_{\boldsymbol{\rho}\to 0}\rho_{\mathrm{sum}}= 0$, which indicates that the solution $\boldsymbol{u}^k$ can become feasible across iterations. 
Under certain regularity condition, \cite[Algorithm RSDD]{notarnicola2019constraint} only guarantees local sublinear convergence \cite{camisa2021distributed} since $\nabla d(\boldsymbol{\lambda})$ is only guaranteed to be bounded \cite[Proposition 5.2]{camisa2021distributed}. Lipschitz continuity of $\nabla d(\boldsymbol{\lambda})$ is important to establish a global sublinear convergence rate.

% Continuity of the controller $\boldsymbol{u}^*(\boldsymbol{x})$ is guaranteed under the presence of multiple CBFs. By regarding state $\boldsymbol{x}$ as a parameter, the CBF-QP problem \eqref{eq:relaxedqp} is a multi-parametric quadratic programming problem. Continuity is then guaranteed by sensitivity theory \cite{fiacco1983introduction}.

% \begin{cor}\label{co:convergence}
% Assume \eqref{eq:para2} holds for $\epsilon_1,\ldots,\epsilon_N >0 $, and $M_1,\ldots,M_N>0$ and in addition:
% \emph{Case I}:
% \begin{equation}\label{eq:coro2assum1}
%   \sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^0)^2}{M_i}+\rho_{ie}^0)>\epsilon_i,\forall i=1,\ldots,N.
% \end{equation}
% Then, for all $k\in\mathbb{N}$, $\rho_{\mathrm{sum}}^k$ satisfies
% \begin{equation}\label{eq:coro2eq1}
%   \rho_{\mathrm{sum}}^k\le\mathrm{max}\left\{\sum_{i=1}^NM_i\epsilon_i,\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i\right\}.
% \end{equation}
% Moreover, $\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^N P_i$ decreases monotonically and 
% \begin{equation}\label{eq:coro2eq2}
%   \lim_{k\to\infty}\theta^{k}\rho_{\mathrm{sum}}^0+\frac{\theta-\theta^{k+1}}{1-\theta}\sum_{i=1}^NP_i<\sum_{i=1}^NM_i\epsilon_i.
% \end{equation}

% \emph{Case II}:
% \begin{equation}\label{eq:coro2assum2}
%   0\le\sum_{e\in\mathcal{C}_i}(\frac{(\rho_{ie}^0)^2}{M_i}+\rho_{ie}^0)\le \epsilon_i,\forall i=1,\ldots,N.
% \end{equation}
% Then for all $k\in\mathbb{N}$, $\rho_{\mathrm{sum}}^k$ satisfies
% \begin{equation}\label{eq:coro2eq3}
%   \rho_{\mathrm{sum}}^k\le \sum_{i=1}^NM_i\epsilon_i.
% \end{equation}
% \end{cor}


% Conditions \eqref{eq:parameterselection}, \eqref{eq:coro2assum1}, \eqref{eq:coro2assum2} are all distributed, hence $M_i$, $i=1,\ldots,N$ can be designed by agents locally. 



\subsection{Truncated Control Law}
Algorithm \ref{al:dcbf} can be implemented in a distributed fashion with ensured safety and optimality properties, however, it may not be suitable for control tasks that require high actuation frequency, i.e. multi-robot system control, as its theoretical properties are established in an asymptotic manner. This motivates the use of a \emph{truncated algorithm}, Algorithm \ref{al:truncated}, where the algorithm terminates after a finite number of iterations, denoted by $\eta$.

\begin{algorithm}[h]
 \caption{Truncated Distributed Safe Control Design Algorithm for agent $i$}
  \hspace*{\algorithmicindent} \textbf{Initialization} Predefined $\lambda_{il}^0, \forall l\in\mathcal{N}_i\cap\mathcal{V}_e$, $\forall e\in\mathcal{C}_i$, truncated parameter $\eta\in\mathbb{N}$\\  \hspace*{\algorithmicindent} \textbf{Receive} $x_k$ for any $k\in\mathcal{V}_e\backslash i$ from $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
  \hspace*{\algorithmicindent} \textbf{Send} $x_i$ to any $l\in\mathcal{N}_i\cap\mathcal{V}_e$, for any $e\in\mathcal{C}_i$\\
 \hspace*{\algorithmicindent} \textbf{Output:} Optimal control input $u_i^*$\\
 \vspace{-3ex}
 \begin{algorithmic}[1]\label{al:truncated}
 \WHILE{$k\le \eta$}
 \STATE steps 2, 3, 4 in Algorithm \ref{al:dcbf}
 \STATE step 5 in Algorithm \ref{al:dcbf}
 \ENDWHILE
 \end{algorithmic}
\end{algorithm}
{Algorithm \ref{al:truncated} is computationally more efficient compared to Algorithm \ref{al:dcbf}, at the cost of potentially violating the control barrier function constraints. The violations are reflected in the non-zero relation variables $\boldsymbol{\rho}^\eta$. In general, it is challenging to provide an explicit bound for $\eta$, under which $\boldsymbol{\rho}^\eta=0$, as the distributed algorithm converges asymptotically as per Theorem \ref{th:speed}. Moreover, $\boldsymbol{\rho}^\eta$ depends on the state $\boldsymbol{x}\in\mathcal{H}:=\mathcal{X}\cap\mathcal{B}$, which parameterizes the optimization problem \eqref{eq:relaxedqp}. To address this challenge, we study the problem that \textit{given $\eta$, we characterize the confidence (probability) with which $\mathbb{P}\{x\in\mathcal{H}:\boldsymbol{\rho}^\eta(\boldsymbol{x})\ne0\}$.} This is established in the following section.}


\section{Distributed Safety Verification}
\label{sec:safetyverification}
%In the previous sections, two distributed safe control input design algorithms are presented with additional relaxations to guarantee feasibility of the optimisation problems across iterations. The algorithm may terminate before reaching the optimal control input $\boldsymbol{u}^*(\boldsymbol{x})$ which certainly renders the system safe. Moreover, if for some $\boldsymbol{x}$, the leveraged $\boldsymbol{u}(\boldsymbol{x})$ corresponds to a non-zero $\boldsymbol{\rho}^k$, the CBF constraints are violated. We point out here that constraint violation is not equivalent to becoming unsafe at the current state, but describes the \emph{risk} of becoming unsafe along the current trajectories by means of the CBFs. 

In this section we show how to verify safety { for a multi-agent system, using a given feedback controller $\boldsymbol{u}(\boldsymbol{x})$. The verification is conducted} by checking the \emph{risk} of becoming unsafe along the current trajectories by means of the CBFs using the so called scenario approach. We tend to measure the violations of the CBF constraints to estimate the trend of being unsafe for the system. { We note here the analysis conducted in this section can be applied to, but not limited to the controller designed using Algorithm \ref{al:truncated}. The only requirement for the verified controller $\boldsymbol{u}(\boldsymbol{x})$ is locally Lipschitz continuous, which is necessary for the solution of the multi-agent system to be unique. We also highlight that in this section a CBF is only regarded as a verification criterion but not necessarily as a control design principle.} 

%The rest of this section is organized in three parts: Section \ref{subsec:5a} proposes the scenario-based verification program, and compares them with the other programs; ii) Section \ref{subsec:5b} develops a distributed scenario sampling scheme, and gives a formal independency guarantee; iii) Section \ref{subsec:5c} shows the distributed implementation of the verification program, and gives probabilistic results. 

\subsection{Scenario Based Safety Verification}\label{subsec:5a}

Consider an $N$-agent system \eqref{eq:dynamics} and a safe invariant set $\mathcal{B}$. Our objective is to verify whether for the designed $\boldsymbol{u}(\boldsymbol{x}(t))$, $\boldsymbol{x}(t)\in\mathcal{S}$, for all $t>0$ and {for all $\boldsymbol{x}(0)\in\mathcal{H}=\mathcal{B}\cap\mathcal{X}$}.

We propose a scenario-based safety verification program as follows.
\begin{align}\label{eq:dscenvarification}\tag{SC-Verification}
    \min_{\boldsymbol{z}\le 0,\boldsymbol{\zeta}\ge 0}~&\sum_{i=1}^N\sum_{e\in\mathcal{C}_i} \left(z_{ie}^2+M\sum_{r=1}^{\bar N}\zeta_{ie}^{(r)}\right)\nonumber\\
    \mathrm{s.t.}~
    &\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))\le \sum_{i\in\mathcal{V}_e}(z_{ie}+\zeta_{ie}^{(r)}),\nonumber\\
    &\forall e=1,\ldots,E, \forall r=1,\ldots,\bar{N},
\end{align}
% \begin{equation}\label{eq:scenvarification}\tag{SC-Verification}
%     \begin{split}
%     \min_{\boldsymbol{\rho}\le 0,\boldsymbol{\zeta}\ge 0}~&\sum_{e=1}^E\left( \rho_e^2+M\sum_{r=1}^{\bar N}\zeta_e^{(r)}\right)\\
%     \mathrm{subject~to~}
%     &\sum_{l\in\mathcal{V}_e}h_{le}(u_l(\boldsymbol{x}^{(r)}))\le \rho_e+\zeta_e^{(r)},\\
%     &\forall e=1,\ldots,E, \forall r=1,\ldots,\bar N,
%   \end{split}
% \end{equation}
where scenarios $\boldsymbol{x}^{(r)}\in{ \mathcal{H}}$ for any $r=1,\ldots,\bar N$ are extracted according to some probability distribution to be clarified in the sequel. 
Throughout the section $\bar X=\{\boldsymbol{x}^{(1)},\ldots,\boldsymbol{x}^{(\bar N)}\}$ denotes the set of scenarios, where $\boldsymbol{x}^{(r)}=[(x^{(r)}_1)^\top,\ldots,(x^{(r)}_N)^\top]^\top\in\mathbb{R}^{\sum_{i=1}^Nn_i}$, for $r=1,\ldots,\bar N$. Relaxation variables $\boldsymbol{\zeta}$ are introduced to ensure feasibility, while $M>0$ is a large enough penalty coefficient.

Program \eqref{eq:dscenvarification} is a data-driven QP, where all the constraints are linear based on the samples. Roughly speaking, if for any $\boldsymbol{x}\in{ \mathcal{H}}$ and corresponding control input $\boldsymbol{u}(\boldsymbol{x})$, all the CBF constraints are satisfied, then $\boldsymbol{\zeta}^*=0$. Conversely, $\boldsymbol{\zeta}^*\ne0$ represents a CBF constraint violation, and indicates the risk of being unsafe by means of CBF. A new set $\mathcal{Z}({ \mathcal{H}})$ for optimal solution $\boldsymbol{z}^*$ is defined as follow
\begin{align}
    &\boldsymbol{z}^*\in\mathcal{Z}({ \mathcal{H}})\Longleftrightarrow\nonumber\\
    & \sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}))\le \sum_{i\in\mathcal{V}_e}z^*_{ie},\forall e=1,\ldots,E, \forall \boldsymbol{x}\in{ \mathcal{H}}.
  \end{align}
Then $\mathcal{Z}({ \mathcal{H}})$ is constituted of $N$ individual set $\mathcal{Z}_i({ \mathcal{H}})$ as
\begin{equation}\label{eq:constraints}
  \mathcal{Z}({ \mathcal{H}})=\bigcap_{i=1}^N\mathcal{Z}_i({ \mathcal{H}}).
\end{equation}
The argument of $\mathcal{Z}$ and $\mathcal{Z}_i$ is dropped in the sequel for simplicity.

% When the number of samples is large enough, i.e. $\bar N\to \infty$, the safety verification result is obtained by the following Proposition.

% \begin{prop}\label{th:inisafetyresult}
% Consider the verification program \eqref{eq:scenvarification} with $\bar N\to\infty$. If the minimizer $\boldsymbol{\rho}^*=0$, with relaxation variable $\boldsymbol{\zeta}^*=0$, the multi-agent system \eqref{eq:dynamics} is safe with control input $\boldsymbol{u}(\boldsymbol{x})$.
% \end{prop}

% \begin{pf}
% If $\boldsymbol{\rho}^*=0$ and $\boldsymbol{\zeta}^*=0$, we have 
% \begin{equation}
%   \sum_{l\in\mathcal{V}_e}h_{le}(u_l(\boldsymbol{x}))\le 0,\forall e=1,\ldots,E,\forall x\in\mathcal{B}.
% \end{equation}
% By Theorem \ref{th:theo1}, we directly have that the set $\mathcal{B}$ is forward-invariant with control input $\boldsymbol{u}(\boldsymbol{x})$.
% \end{pf}


% The reason why we use finte samples instead of optimizing over the whole set $\mathcal{B}$ is to avoid solving an uncertain optimisation problem
% \begin{equation}\label{eq:verification}
%   \begin{split}
%     \min_{\boldsymbol{\rho}}~&\sum_{e=1}^E \rho_e^2\\
%     \mathrm{subject~to~}
%     &\sum_{l\in\mathcal{V}_e} h_{le}(u_l(\boldsymbol{x}))\le \rho_e,\forall e=1,\ldots,E,\\
%     &\forall \boldsymbol{x}\in\mathcal{B}, u_i(\boldsymbol{x})\in\mathcal{U}_i,\forall i=1,\ldots,N.
%   \end{split}
% \end{equation}
% Here $u_i(\boldsymbol{x})$ with $i=1,\ldots,N$ is a function of $\boldsymbol{x}$. The verification program \eqref{eq:verification} is an uncertain problem parameterized by $\boldsymbol{x}$ in an set $\mathcal{B}$. Although mathematically sound, \eqref{eq:verification} is hard to solve in practice due to the set constraint $\forall \boldsymbol{x}\in\mathcal{B}$. In this sense, with a compact set $\mathcal{B}$, \eqref{eq:verification} is an infinitely constrained problem. Moreover, the form of $\boldsymbol{u}(\boldsymbol{x})$ is possibly unknown.

% Another deterministic verification program can be obtained by assuming the map from $\boldsymbol{x}$ to $\boldsymbol{u}(\boldsymbol{x})$ is known as a \emph{priori}. Under this assumption, the verification program \eqref{eq:verification} can actually be solved exactly. For example, the control input designed by solving the CBF-QP \eqref{eq:centralizedqp} can be explicit. Although the optimisation only gives an implicit expression, i.e. $u_i(\boldsymbol{x})$ for $i=1,\ldots,N$ are solved point-wisely at given $\boldsymbol{x}$, the explicit form of $u_i(\boldsymbol{x})$ can be evaluated exactly as a piece-wise Lipschitz continuous function \cite{wang2022explicit}. The alternative equivalent deterministic formulation of the problem \eqref{eq:verification} follows as
% \begin{equation}\label{eq:equivalentverification}
%   \begin{split}
%     \max_{\boldsymbol{x}\in\mathcal{B}}~&H(\boldsymbol{x})\\
%     \mathrm{subject~to~}&H(\boldsymbol{x})=\mathrm{max}
%     \left\{\vphantom{sum_{i=1}^N\sum_{l\in\mathcal{V}_e\cap\mathcal{N}_i}\tilde h_{l,\mathcal{C}_1}(u_l(\boldsymbol{x}))}\sum_{i\in\mathcal{C}_1} h_{i1}(u_i(\boldsymbol{x}))\right.\\
%     &,\ldots,\left.\sum_{i\in\mathcal{V}_e} h_{iE}(u_i(\boldsymbol{x}))\right\},\\
%   \end{split}
% \end{equation}

% If the problem \eqref{eq:verification} has a minimizer of $\boldsymbol{\rho}=0$, then $H(\boldsymbol{x}^*)\le 0$ for $\boldsymbol{x}^*$ as the minimizer to \eqref{eq:equivalentverification}. Though now the uncertain program \eqref{eq:verification} is equivalently formulated as a certain program \eqref{eq:equivalentverification}, solving \eqref{eq:equivalentverification} is still non-trivial since the functions $h_{ie}(u_i(\boldsymbol{x}))$ for $e=1,\ldots,E$ are all non-linear. Besides, in real applications the form of $u_i(x)$ is \emph{a priori}, at least not circulated across the whole system. To this end, the benefit of \eqref{eq:scenvarification} is clear: it is a finite convex optimisation problem.

\subsection{Sampling the Scenarios}
\label{subsec:5b}
The scenarios are sampled independently from the set ${ \mathcal{H}}$. For sampling we define a probability density $\pi(\boldsymbol{x})$ associated with set ${ \mathcal{H}}$ that satisfies
  $\int_{{ \mathcal{H}}}\pi(\boldsymbol{x})d\boldsymbol{x}=1.$
One typical choice of $\pi(\boldsymbol{x})$ is to set it according to the density of the uniform distribution, i.e., $\pi(x)=\pi^{\mathrm{uni}}(\boldsymbol{x})=\frac{1}{\int_{ \mathcal{H}}d\boldsymbol{x}}$.

{The existence of $\pi^{\mathrm{uni}}(\boldsymbol{x})$ is assured as $\mathcal{H}$ is a non-empty and compact set, due to Assumption \ref{ass:barrier}.} Then, $\boldsymbol{x}$ can be sampled $\bar N$ times independently from the distribution $\pi^{\mathrm{uni}}(\boldsymbol{x})$. Note that the choice of the probability distribution does not affect the probabilistic results established in the sequel due to the distribution-free nature of the results of \cite[Section 3.1]{garatti2019risk}. Although the uniform distribution here is well-defined, the set ${ \mathcal{H}}$ is defined implicitly as an intersection of multiple sets. Sampling a point from the proposed uniform distribution is rather arduous in practice, and agents may not have access to ${ \mathcal{H}}$. Here, we provide a sequential algorithm to sample scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar{N}$. 

\begin{algorithm}[h]
 \caption{Scenarios Sampling Algorithm}
  \hspace*{\algorithmicindent} \textbf{Initialization} { Set $\mathcal{H}=\mathcal{B}\cap\mathcal{X}$}, failed times $F=0$.\\
 \hspace*{\algorithmicindent} \textbf{Output:} Scenario $\boldsymbol{x}^{(r)}$.\\
 \vspace{-3ex}
 \begin{algorithmic}[1]\label{al:sampling}
 \STATE Sample $x_1^{(r)}$ from $\pi_1(x)$.
 \FOR{$i=2,\ldots,N$}
  \STATE Construct a {set} $\mathcal{H}_i=\cap_{e\in\mathcal{C}_i}\mathcal{H}_{ie}$ following \eqref{eq:fixedinvariant}.
 \IF {$\mathcal{H}_i=\emptyset$}
 \STATE $F \leftarrow F+1$.
 \STATE go to $i=i-F$ ($i=1$ is step $1$).
 \ENDIF
 \STATE {Sample $x_i^{(r)}$ from distribution $\pi_i=\frac{1}{\int_{\mathcal{X}_i}dx}$.}
 \WHILE{{$x_i^{(r)}\notin\mathcal{H}_i$}}
 \STATE {Sample $x_i^{(r)}$ from distribution $\pi_i$.}
 \ENDWHILE
 \ENDFOR
 
 \end{algorithmic}
\end{algorithm}
The algorithm constructs the densities from which samples are extracted sequentially for each agent. We first define the sets from which samples are extracted for agent $i$ with part of the states of agents in the same sub-network $\mathcal{G}_e$ fixed.
\begin{align}\label{eq:fixedinvariant}
  { \mathcal{H}}_{ie}&=\left\{ \begin{array}{l}
\mathcal{X}_i,~\mathrm{if}~\exists l\in\mathcal{V}_e,\mathrm{such}~\mathrm{that}~l> i\\
\{x_i\in{ \mathcal{X}_i}|b_{ie}(x_i,\{x_l^{(r)}\})\ge0)\},~\mathrm{otherwise}
\end{array} \right.
\end{align}
We then have that ${ \mathcal{H}}_i = \bigcap\limits_{e\in\mathcal{C}_i} { \mathcal{H}}_{i{e}}$. The parameters in \eqref{eq:fixedinvariant} can all be collected by local communication, since only states of agents in the same sub-network are required. Note here ${ \mathcal{H}}_i$ is possibly empty with some parameters $\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\}$.

At {Step} $1$, the first scenario $x_1^{(r)}$ associated with agent $1$ is sampled from distribution $\pi_1=\frac{1}{\int_{\mathcal{X}}dx}$, since now there are no other agents involved to restrict the set for agent $1$. Then, the sampling-construction procedures repeat sequentially from agent $2$ to agent $N$. {For $i=2,\ldots,N$, before sampling the scenario $x_i^{(r)}$, we first check whether $\mathcal{H}_i$ is empty (Step 4).} By Assumption \ref{ass:barrier}, there exists $\{x_1^{(r)},\ldots,x_{i-1}^{(r)}\}$ such that ${ \mathcal{H}}_i\ne \emptyset$. Therefore, if {$\mathcal{H}_i=\emptyset$} (Step 5), then go back to the sampling-construction of agent $i-F$, $F\ne 1$ is to avoid a deadlock on step $i$. The deadlock happens when for given scenarios $x_1^{(r)},\ldots,x_{i-2}^{(r)}$, the set ${ \mathcal{H}}_{i-1}$ is such that for any $ x_{i-1}^{(r)}\in{ \mathcal{H}}_{i-1}$, ${ \mathcal{H}}_i=\emptyset$. It is guaranteed that $F\le i-1$ for $i\ge 2$, since ${ \mathcal{H}}_1=\mathcal{X}_1\ne\emptyset$. {After finding feasible scenarios $x_1^{(r)},\ldots,x_{i-1}^{(r)}$, we sample the scenario $x_i^{(r)}$ for the $i$th agent from the uniform distribution $\pi_i$ (Step 8). The sampled scenario is then checked at Step 9. If $x_i^{(r)}\notin\mathcal{H}_i$, it will be sampled again following $\pi_1$. The loop will terminate in finite time since $\mathcal{H}_i\cap\mathcal{X}\ne \emptyset.$}

\begin{prop}\label{pro:independency}
The scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$, are feasible, i.e., $\boldsymbol{x}^{(r)}\in{ \mathcal{H}}$, and independent.
\end{prop}
\begin{pf}
The feasibility result holds directly from the definition of every set ${ \mathcal{H}}_i$ in \eqref{eq:fixedinvariant} that $x_i^{(r)}$ is sampled from. As a result, we have $b_{ie}(x_i^{(r)},\{x_k^{(r)}\})\ge 0$ for any $i=1,\ldots,N$, $e\in\mathcal{C}_i$, and $k\in\mathcal{V}_e$. Therefore, $\boldsymbol{x}^{(r)}\in{ \mathcal{H}}$. $\boldsymbol{x}^{(r)}$ for $r=1,\ldots,\bar N$ are independent since for $r=1,\ldots,\bar N$, $x_1^{(r)}$ are independently sampled from distribution $\pi_1$.
\end{pf}

We note here that the elements in $\boldsymbol{x}^{(r)}$ are correlated, but this will not influence the independence results in Proposition \ref{pro:independency} since we seek independence across $r$.



\subsection{Distributed Safety Verification}
\label{subsec:5c}
%After sampling every scenario $\boldsymbol{x}^{(r)}$, the scenario represents the states to the networked system \eqref{eq:dynamics}. Agents then design their control law $\boldsymbol{u}(\boldsymbol{x}^{(r)})$ with their methods. As we have stated in the beginning of this section, the control law $\boldsymbol{u}(\boldsymbol{x})$ is not necessarily designed via solving the CBF-QP \eqref{eq:centralizedqp}, but can also be synthesized by other methods. The only requirement is that every agent has access to its control input. Without additional communication, $x_i^{(r)}$ and $u_i(\boldsymbol{x}^{(r)})$ are private resources to agent $i$. Although $u_i(\boldsymbol{x}^{(r)})$ may be designed on the scenarios (states) of other agents, in the verification step we still assume the scenarios are private since the design of control input is not \textit{a priori}. 

% The verification program \eqref{eq:scenvarification} is well-defined, however it can not be directly solved locally with Algorithm \ref{al:dcbf} since the problem is still coupled across agents as the decision variables $\rho_e$ is common variable for all agents in the sub-network $\mathcal{G}_e$. A commonly used approach to split the problem is to decompose the ``edge" variables into several ``node" variables, entailing additional consensus constraints. Following this idea, a decoupled version is proposed as
After sampling scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$ using Algorithm \ref{al:sampling}, we are at the stage of solving the safety verification program \eqref{eq:dscenvarification}.

Letting the local cost function $J_i(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)$, and constraint function $\hat{h}_{ie}(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)$ be
\begin{align}\label{eq:scenariodistributed}
  &J_i(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)&&=\sum_{e\in\mathcal{C}_i} \left(z_{ie}^2+\sum_{r=1}^{\bar N}\zeta_{ie}^{(r)}\right),\nonumber\\
    &\hat{h}_{ie}^{(r)}(\boldsymbol{z}_i,\boldsymbol{\zeta}_i)&&={h}_{ie}(u_i(\boldsymbol{x}^{(r)}))-z_{ie}-\zeta_{ie}^{(r)},r=1,\ldots,\bar N,
\end{align}
Algorithm \ref{al:dcbf} can be applied to solve the distributed scenario optimisation problem \eqref{eq:dscenvarification}. The relaxation variables in Algorithm \ref{al:dcbf} are unnecessary, since every optimisation sub-problem in iteration is solvable. In the sequel, we use $\boldsymbol{z}^*$ and $\boldsymbol{\zeta}^*$ to represent the optimal solution to \eqref{eq:dscenvarification}, with scenarios $\boldsymbol{x}^{(r)}$, $r=1,\ldots,\bar N$. We then have the following theorem as the main result on probabilistic safety.

\begin{thm}\label{th:probability} Choose $\beta_i \in (0,1),i=1,\ldots,N$, and set $\beta=\sum_{i=1}^N \beta_i$. For $i=1,\ldots,N$, and $0\le s_i^*\le \bar N-1$, consider the polynomial equation in $t_i$
\begin{equation}\label{eq:scenariopolynomial}
\begin{split}
    &\left(\begin{array}{l}
{\bar N}\\
{s^*_i}
\end{array}\right)t_i^{\bar N-s^*_i}-\frac{\beta_i}{2\bar N}\sum_{j=s^*_i}^{\bar N-1}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-s^*_i}\\
&-\frac{\beta_i}{6\bar N}\sum_{j=\bar N+1}^{4\bar N}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-s^*_i}=0,
\end{split}
\end{equation}
while for $s_i^*=\bar N$ consider the polynomial equation
\begin{equation}\label{eq:scenariopolynomial2}
  1-\frac{\beta}{6N}\sum_{j=\bar N+1}^{4\bar N}\left(\begin{array}{l}
{j}\\
{s^*_i}
\end{array}\right)t_i^{j-\bar N}=0.
\end{equation}
For any $i=1,\ldots,N$, this equation has exactly two solutions in $[0,+\infty)$ denoted by $\underline t_i(s^*_i)$ and $\bar t_i(s^*_i)$, where $\underline t_i(s^*_i)\le \bar t(s^*_i)$. Let $\underline\epsilon_i(s^*_i):=\max\{0,1-\bar t_i(s^*_i)\}$, $\bar \epsilon_i(s^*_i):=1-\underline t_i(s^*_i)$, and $\underline \epsilon(s^*)=\sum_{i=1}^N\underline\epsilon_i(s_i^*)$, $\bar \epsilon(s^*)=\min\{\sum_{i=1}^N\bar\epsilon_i(s_i^*),1\}$. We then have that
\begin{equation}\label{eq:violation}
  \mathbb{P}^{\bar N}\left\{\frac{\underline\epsilon(s^*)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:0\notin\mathcal{Z} \right\}\le\bar\epsilon(s^*)
  \right\}\ge 1-\beta,
\end{equation}
where $s_i^*$ is the number of non-zero $\zeta_{ie}^{(r)*}$, $e\in\mathcal{C}_i$.
\end{thm}
\begin{pf}
  See Appendix.
\end{pf}

% The following corollary is a direct result from Lemma \ref{lem:uniqueness}.
% \begin{cor}\label{coro:violation}
% For state $\boldsymbol{x}\in\mathcal{B}$, if $\boldsymbol{z}^*\ne \boldsymbol{0}$, then at least one CBF constraint is violated for system \eqref{eq:dynamics} at $\boldsymbol{x}$, using control input $\boldsymbol{u}(\boldsymbol{x})$. 
% \end{cor}

% Under the assumption of Lemma \ref{lem:uniqueness}, the violation probability $V(\boldsymbol{z}^*)=\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\bigcap_{i=1}^N\mathcal{Z}_i \}$ shows the probability that at least one CBF constraint is violated. From Lemma \ref{lem:uniqueness}, the scenario program is guaranteed to have a unique solution, therefore the $V(\boldsymbol{z}^*)$ can be evaluated through scenario approach theory \cite{campi2018wait}, which points out that $V(\boldsymbol{z}^*)$ is with a quantifiable level $\bar \epsilon$ under confidence probability $\beta$. The relationship is built on the notion of \emph{support constraint}. For an optimisation problem, a constraint is called a support constraint if its removal (with all the other constraints remained) changes the solution of the problem. The \emph{support set} is a corresponding notion. A subset with minimal cardinality of constraints is called a support set if solving the optimisation problem with only these constraints considered returns the same solution as the nominal problem. If the support set is identified, the original optimisation problem can be simplified to be solved with removing all the other redundant constraints. 

% Let $s^*(\boldsymbol{x}^{(r)})$ to be the upper bound of cardinality of the support set. By \cite{calafiore2005uncertain}, $s^*(\boldsymbol{x}^{(r)})$ is less smaller to the dimension of the decision variables, which is $\sum_{i=1}^E|\mathcal{V}_e|$. In the sequel, $s^*(\boldsymbol{x}^{(r)})$ is substituted by $s^*$ for simplicity. Using $s_i^*$ to denote the number of support constraints belong to the constraints of agent $i$, then $s_i^*\le|\mathcal{C}_i|$, which is the dimension of decision variables for agent $i$. Directly, suppose the number of scenarios for agent $i$ is $\tilde N_i$. Adopting the scenario approach theory from \cite{garatti2019risk}, we have the following theorem as the main results of this section.

Note that Theorem \ref{th:probability} constitutes a generalization of \cite[Theorem 2]{garatti2019risk} to a multi-agent setting. It also extends \cite{margellos2017distributed} by determining the lower bound $\frac{\underline\epsilon(s^*)}{N}$.
Theorem \ref{th:probability} states that with confidence $1-\beta$, the system tends to be unsafe by means of the CBFs with probability within the interval $[\frac{\underline\epsilon(s^*)}{N}$, $\bar \epsilon(s^*)]$. 
%Note here that unlike the upper bound, the lower bound is divided by the amount of agents $N$. This is because in the extreme case where all the events $\boldsymbol{z}^*\notin\mathcal{Z}_i$ for $i=1,\ldots,N$ happen simultaneously, such that $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\{\boldsymbol{z}^*\notin\mathcal{Z}_i \}\right\}=$ $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_1 \right\}$ $=\ldots=\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_N \right\}$, then $\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}$ $\le N\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\bigcup_{i=1}^N\{\boldsymbol{z}^*\notin\mathcal{Z}_i \}\right\}$. 

% \begin{prop}
% For the scenario program \eqref{eq:dscenvarification} with level $Q$. Then $s^*(\boldsymbol{x}^{(r)})=I_{=0}(\boldsymbol{z}^*(\boldsymbol{x}^{(r)}))$ if $\forall \boldsymbol{x}^{(r)}\in\bar X$, and corresponding control input $\boldsymbol{u}(\boldsymbol{x}^{(r)})$, all the CBF constraints are satisfied with level $Q$.
% \end{prop}
% \begin{pf}
% For the case where all the CBF constraints are satisfied with level $Q$, we have $\boldsymbol{z}^*(\boldsymbol{x}^{(r)})=-\varepsilon$ or $0$ from Lemma \ref{lem:uniqueness}. For $i$ and $e$ such that $z_{ie}^*(\boldsymbol{x}^{(r)})=0$, there must exist at least one $r$ such that $\sum_{k\in\mathcal{V}_e}h_{ke}(u_k(\boldsymbol{x}^{(r)}))\le\sum_{k\in\mathcal{V}_e}z_{ke}+Q$ supports the problem. Besides, the number of support constraints is not bigger than the dimension of decision variables \cite{calafiore2005uncertain}. Hence, $s^*(\boldsymbol{x}^{(r)})$ equals to the number of zeros in $\boldsymbol{z}^*(\boldsymbol{x}^{(r)})$. We conclude the proof.
% \end{pf}

% The following lemma characterizes the distribution of violation probability $V(\boldsymbol{z}^*)$, which indicates the \emph{risk} of the system \eqref{eq:dynamics} by means of the CBFs.
% \begin{lem}\label{lem:safetyprobability}
% For the multi-agent system \eqref{eq:dynamics} and the CBFs, we have that
% \begin{equation}\label{eq:safetyprobability}
%   \mathbb{P}\left\{\frac{\underline\epsilon(0)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\ne\boldsymbol{0}\right\}\le\bar\epsilon(0)
%   \right\}\ge 1-\beta,
% \end{equation}
% where $\beta$, $\underline\epsilon$, $\bar\epsilon(0)$ follows Theorem \ref{th:probability} and Equation \eqref{eq:scenariopolynomial} by letting $s_i^*=0$ for any $i=1,\ldots,N$.
% \end{lem}

% Lemma \ref{lem:safetyprobability} shows the probability measure about the risk of the multi-agent system \eqref{eq:dynamics} under confidence $1-\beta$. Here $\mathbb{P}\left\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\notin\bigcap_{i=1}^N\mathcal{Z}_i\right\}$ has been substituted by $\mathbb{P}\{\boldsymbol{x}\in\mathcal{B}:\boldsymbol{z}^*\ne 0\}$ as they are equivalent at $\boldsymbol{z}^*=0$.
Furthermore, for a given $r$, \eqref{eq:dscenvarification} can be split into $\sum_{i=1}^E|\mathcal{V}_e|$ sub-problems, each one with its own CBF constraint. Each sub-problem is solved at the agent level and has only $\bar N$ constraints. Then, the probability that one of the CBF constraints is violated can be bounded as shown in the following corollary.

\begin{cor}\label{coro:sconecbf}
Consider the multi-agent system \eqref{eq:dynamics}, and let $\underline\epsilon_i(s_i^*)$, $\bar\epsilon_i(s_i^*)$, and $\beta_i$ as in Theorem \ref{th:probability}. We then have that
\begin{equation}
\begin{split}
   &\mathbb{P}^{\bar N}\left\{\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))>0\right\}\le\bar\epsilon_i(s_i^*)
  \right\}\\
  &\ge 1-\beta_i.
\end{split}
\end{equation}

\end{cor}




\section{Simulation Results}
\label{sec:simulation}
The distributed safe control input design and safety verification algorithms are numerically validated on a multi-robot positions swapping problem. To facilitate comparison, we adopt a similar setup as in \cite{wang2017safety}. 
\subsection{Multi-Robot Position Swapping}
Robots are assigned different initial positions and are required to navigate towards target locations. In a distributed framework, robots are equipped with sensing and communication modules for collision detection and information sharing. A group of ten robots, indexed by $i=1,\ldots,10$ are considered, with double integrator dynamics
\begin{equation}\label{eq:robotdynamics}
  \begin{bmatrix}
  \dot{\boldsymbol{p}_i}\\\dot{\boldsymbol{v}_i}
  \end{bmatrix}=
  \begin{bmatrix}
  0&I_{2\times 2}\\
  0&0
  \end{bmatrix}
  \begin{bmatrix}
  \boldsymbol{p}_i\\
  \boldsymbol{v}_i
  \end{bmatrix}+
  \begin{bmatrix}
  0\\
  I_{2\times 2}
  \end{bmatrix}\boldsymbol{a}_i,
\end{equation}
where $\boldsymbol{p}_i\in\mathbb{R}^2$, $\boldsymbol{v}_i\in\mathbb{R}^2$ represent positions and velocities, and $\boldsymbol{a}_i\in\mathbb{R}^2$ is the control input, representing accelerations. The acceleration is limited as $||\boldsymbol{a}_i||_\infty\le a_i^{\max}$. $a_i^{\max}$ will be cleared in the sequel. Each robot is regarded as a disk centered at $\boldsymbol{p}_i$ with radius $D_i\in\mathbb{R}_+$. The safety certificate $s_{ij}(\boldsymbol{p},\boldsymbol{v})$ for collision avoidance between robot $i$ and $j$ is defined by
\begin{equation}\label{eq:robotsafety}
  s_{ij}(\boldsymbol{p},\boldsymbol{v}) = ||\Delta\boldsymbol{p}_{ij}||_2^2-D_{ij},
\end{equation}
where $\Delta\boldsymbol{p}_{ij}=\boldsymbol{p}_i-\boldsymbol{p}_j$, $D_{ij}=D_i+D_j$.
Note here that the system is heterogeneous as different robots have different mobility. Following \cite{wang2017safety}, the control barrier function for invariance certificates is then defined pair-wisely, as
\begin{align}
  b_{ij}(\boldsymbol{p},\boldsymbol{v}) &= \sqrt{2(a_i^{\max}+a_j^{\max})(||\Delta\boldsymbol{p}_{ij}||_2^2-D_{ij})}\nonumber \\&+\frac{\Delta\boldsymbol{p}_{ij}^\top}{||\Delta\boldsymbol{p}_{ij}||_2^2}\Delta\boldsymbol{v}_{ij}, \label{eq:robotbarrierfunction}
\end{align}
where $\Delta\boldsymbol{v}_{ij}=\boldsymbol{v}_i-\boldsymbol{v}_j$. The function $b_{ij}(\boldsymbol{p},\boldsymbol{v})$ is guaranteed to be a CBF since when $b_{ij}(\boldsymbol{p},\boldsymbol{v})>0$, collision can be avoided with maximum braking acceleration $\boldsymbol{a}^{\max}_i+\boldsymbol{a}^{\max}_j$ applied to robots $i$ and $j$. For $i=1,\ldots,5$, $\boldsymbol{a}_i^{\max}=1$, while for $i=6,\ldots,10$, $\boldsymbol{a}_i^{\max}=10$. Note that although $b_{ij}(\boldsymbol{p},\boldsymbol{v})$ is guaranteed to be a CBF for safety certificate $s_{ij}(\boldsymbol{p},\boldsymbol{v})$, the corresponding invariant set $\mathcal{B}=\mathop{\bigcap}\limits_{\{i,j\}\in\mathcal{E}}\mathcal{B}_{ij}$ is possibly empty. Intuitively, this is since robots cannot utilize maximum braking force to avoid collision with multiple other robots simultaneously. This problem is beyond the scope of this paper, and we still adopt the CBF as in \eqref{eq:robotbarrierfunction}.

\subsection{Distributed Control: Asymptotic Algorithm}
The distributed safe control design procedure of Algorithm \ref{al:dcbf} that exhibits asymptotic convergence and optimality guarantees is implemented for robots to swap positions with the opposite robots while avoiding collision. The resulting simulation results are shown in Figure \ref{fig:fullcontrol}.

\begin{figure}[h]
   \centering

   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter1.eps}
     \caption{{ Time} 1}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter100.eps}
     \caption{{ Time} 100}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter200.eps}
     \caption{{ Time} 200}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter300.eps}
     \caption{{ Time} 300}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter400.eps}
     \caption{{ Time} 400}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/ceniter500.eps}
     \caption{{ Time} 500}
   \end{subfigure}
     \caption{Trajectory of ten robots swapping positions according to Algorithm \ref{al:dcbf}. Robots with the same color are swapping positions, and avoiding collision with the others.}
     \label{fig:fullcontrol}
\end{figure}


\subsection{Distributed Control: Truncated Algorithm}
The truncated Algorithm \ref{al:truncated} is then implemented for the same setting, the truncation parameter $\eta=30$.

\begin{figure}[h]
   \centering

   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter1.eps}
     \caption{{ Time} 1}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter100.eps}
     \caption{{ Time} 100}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter200.eps}
     \caption{{ Time} 200}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter300.eps}
     \caption{{ Time} 300}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter400.eps}
     \caption{{ Time} 400}
   \end{subfigure}
     \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/deciter500.eps}
     \caption{{ Time} 500}
   \end{subfigure}
     \caption{Trajectory of ten robots swapping positions while avoiding collision by means of Algorithm \ref{al:truncated}, with $\eta=30$.}
     \label{fig:truncontrol}
\end{figure}
The resulting swapping trajectories are shown in Figure \ref{fig:truncontrol}. { Define
\begin{align}
\rho_{\mathrm{sum}}^k&=\sum_{i=1}^N\sum_{e\in\mathcal{C}_i}\left((\rho_{ie}^k)^2+M_i\rho_{ie}^k\right).\label{eq:quan2}
\end{align}}
\noindent The evolution of the relaxation parameters $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ and $\rho_{\mathrm{sum}}^{30}(\boldsymbol{x})$ { at each time step along the trajectory} is shown in Figures \ref{fig:rho0} and \ref{fig:rho30}. { It can be seen that $\rho_{\mathrm{sum}}^{30}$ is close to zero at every time step, even $\rho_{\mathrm{sum}}^0$ is relatively large at some time steps. This empirically demonstrates the safety guarantees performance of the proposed distributed algorithm. From our experience, $\eta$ could be much smaller for a practical implementation.}

\begin{figure}[h]
   \centering

   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/toler0.eps}
     \caption{$\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ along the trajectory}
     \label{fig:rho0}
   \end{subfigure}
   \hfill
   \begin{subfigure}[b]{0.23\textwidth}
     \centering
     \includegraphics[width=\textwidth]{pic/toler30.eps}
     \caption{$\rho_{\mathrm{sum}}^{30}(\boldsymbol{x})$} along the trajectory
     \label{fig:rho30}
   \end{subfigure}
   \caption{Evolution of the relaxation parameters $\rho_{\mathrm{sum}}^0(\boldsymbol{x})$ and $\rho_{\mathrm{sum}}^{30}(\boldsymbol{x})$ evaluated at the state trajectory, across algorithm iterations.} 
\end{figure}

\subsection{Distributed Safety Verification}
Safety verification is performed for a four-robot system, within the working space $\mathcal{X}$, defined as $\{p:||p||\le p^{\mathrm{\max}}=6\}\times \{v:||v||\le v^{\mathrm{\max}}=1\}$. Each robot is using Algorithm \ref{al:truncated} to safely move towards the origin. 
We sample $200$ scenarios via Algorithm \ref{al:sampling}.
Theorem \ref{th:probability} yields then that with confidence at least $0.9$, 
$\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:0\notin\mathcal{Z} \right\}\in [0,0.146]$.
We repeat this procedure $300$ times, each time using $300$ scenarios, and construct the empirical cumulative distribution function of $\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:0\notin\mathcal{Z} \right\}$.
This is shown in Figure \ref{fig:distribution};
it can be observed that the empirical probability that $\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:0\notin\mathcal{Z} \right\} \in [0,0.146] \approx 1$, thus satisfying the theoretical confidence lower bound of $0.9$.
\begin{figure}[h]
   \centering

  % \begin{subfigure}[b]{0.23\textwidth}
  %   \centering
  %   \includegraphics[width=\textwidth]{pic/pdf.eps}
  %   \caption{PDF for safety violation}
  % \end{subfigure}
  % \hfill
   \begin{subfigure}[b]{0.3\textwidth}
     \centering
     \includegraphics[width=0.8\textwidth]{pic/cfg.eps}
    % \caption{CDF for safety violation}
     \label{fig:4cdf}
   \end{subfigure}
   \caption{Cumulative distribution function for safety violation.}
     \label{fig:distribution}
\end{figure}

\section{Conclusion}
\label{sec:conc}
In this paper we presented distributed safe control design and safety verification algorithms for multi-agent systems. The proposed control algorithms introduce auxiliary and relaxation variables to allow feasibility across iterations. We guaranteed convergence to an optimal solution and establish a sublinear convergence rate. We also addressed the problem of distributed safety verification for given control inputs. A scenario-based verification program is formulated and can be solved locally by each agent. The scenarios are sampled independently by a sequential algorithm from the controlled invariant set. The distributed scenario program characterizes the probability of being unsafe, with both lower and upper bounds being determined. Simulation on a multi-robot swapping position problem determines the efficacy of our result. Current work concentrates in accounting for communication delays and model uncertainty in real systems.

% 

\appendix
\section{Appendix}
\begin{pf}[Proof of Lemma \ref{lem:newproperty}]
% Combining the optimisation problems \eqref{eq:dcbf} in Step 3 of Algorithm \ref{al:dcbf} for all agents, we have
% \begin{equation}\label{eq:globalrelaxedcbf}
%   \begin{split}
%     \min_{\boldsymbol{u},\boldsymbol{\rho}}&~J(\boldsymbol{u},\boldsymbol{\rho})\\
%     \mathrm{subject~to}~&u_i\in\mathcal{U}_i,\forall i=1,\ldots,N,\boldsymbol{\rho}\ge 0\\
%     &\sum_{k\in\mathcal{V}_e} h_{ke}(u_k)\le\sum_{k\in\mathcal{V}_e}\rho_{ke},\forall e=1,\ldots,E,
%   \end{split}
% \end{equation}
% where for each $e=1,\ldots,E$, $\mu_e$ is the dual variable associated with the last constraint in \eqref{eq:globalrelaxedcbf}.
The dual function of \eqref{eq:relaxedqp} is given by
\begin{align}\label{eq:dual}
    q(\boldsymbol{\mu})&=\inf_{\{u_i\in\mathcal{U}_i\},\boldsymbol{\rho}\ge 0}\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}(\rho^2_{ie}+M_{i}\rho_{ie})\right\}\nonumber\\
    &+\sum_{e=1}^E\mu_e\left\{\sum_{i\in\mathcal{V}_e} h_{ie}(u_i)-\sum_{i\in\mathcal{V}_e}\rho_{ie}\right\}\nonumber\\
    &=\inf_{\{u_i\in\mathcal{U}_i\},\boldsymbol{\rho}\ge 0}\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}\mu_eh_{ie}(u_i)\right\}\nonumber\\
    &+\sum_{e=1}^E\sum_{i\in\mathcal{V}_e}\left\{\rho_{ie}^2+(M_{i}-\mu_e)\rho_{ie}\right\}
\end{align}
If there exists $e=1,\ldots,E$, and $i\in\mathcal{V}_e$, such that $M_i-\mu_e< 0$, then the minimizer of $\sum_{e=1}^E\sum_{k\in\mathcal{V}_e}\{\rho_{ie}^2+(M_{i}-\mu_e)\rho_{ie}\}$ is given by $\boldsymbol{\rho}^*>0$. Notice that this is an unconstrained QP, so its minimizer can be determined by setting its gradient with respect to $\rho_{ie}$ to zero. On the other hand if $M_i-\mu_e \ge 0$, for all $e=1,\ldots,E,i\in\mathcal{V}_e$, the unconstrained minimizer for $\boldsymbol{\rho}$ is negative, hence the constrained minimizer $\boldsymbol{\rho}^*=0$ as $\boldsymbol{\rho}\ge 0$. For this case, we obtain 
\begin{equation}
\begin{split}
  q(\boldsymbol{\mu})&=\inf_{\{u_i\in\mathcal{U}_i\}}\sum_{i=1}^N\left\{J_i(u_i)+\sum_{e\in\mathcal{C}_i}\mu_eh_{ie}(u_i)\right\},\\
\end{split}
\end{equation}
which is the dual function for the original unrelaxed problem \eqref{eq:centralizedqp}. Recall that \eqref{eq:centralizedqp} is a strictly convex quadratic problem, then $\boldsymbol{u}_{\mathrm{rel}}^*(\boldsymbol{x})=\boldsymbol{u}_{\mathrm{nom}}^*(\boldsymbol{x})$ if $M_i\ge \mu_e$, for all $e=1,\ldots,E$, $i\in\mathcal{V}_e$ { since $\boldsymbol{\rho}^*=0$.} The cost function $H(\boldsymbol{u},\boldsymbol{\rho})$ is strongly convex with Lipschitz continuous gradient since every $J_i(u_i)$ is a strongly convex quadratic function with respect to $u_i$, and $\sum_{e\in\mathcal{C}_i}(\rho_{ie}^2+M_i\rho_{ie})$ is strongly convex with respect to $\rho_{ie}$.

\end{pf}
\begin{pf}[Proof of Theorem \ref{th:speed}]
We begin with (a). The proof follows a similar idea as \cite[Theorem II.6]{notarstefano2019distributed}, we only scratch the primal-dual exploration here. Under Assumption \ref{ass:slater}, strongly duality holds for the primal problem \eqref{eq:centralizedqp} and the dual problem \eqref{eq:dual}. To solve the dual problem $\max_{\boldsymbol{\mu}\ge 0}q(\boldsymbol{\mu})$ in a distributed manner, an equivalent decomposed problem \cite[Section 3.1.3]{notarstefano2019distributed} is formulated as
\begin{equation}\label{eq:dualdecomposition}
  \begin{split}
    \max_{\boldsymbol{\mu}_i\ge 0}~&\sum_{i=1}^Nq_i(\boldsymbol{\mu_i})\\
    \mathrm{subject~to}~&\boldsymbol{\mu}_i=\boldsymbol{\mu}_j,(i,j)\in\mathcal{E},
  \end{split}
\end{equation}
where $\boldsymbol{\mu}_i$ is a local copy of $\boldsymbol{\mu}$ for agent $i$. The dual problem of \eqref{eq:dualdecomposition} is given by
\begin{equation}\label{eq:dualdualdecomposition}
  \begin{split}
    d^*=\min_{\boldsymbol{\lambda}}d(\boldsymbol{\lambda}):=\sum_{i=1}^N\sup_{\boldsymbol{\mu}_i\ge 0}\left(q_i(\boldsymbol{\mu}_i)+\boldsymbol{\mu}_i^\top\sum_{j\in\mathcal{N}_i}(\lambda_{ij}-\lambda_{ji})\right),
  \end{split}
\end{equation}
where $\lambda_{ij}$ is a free dual variable for the constraint $\boldsymbol{\mu}_i=\boldsymbol{\mu}_j$. Strong duality holds between problem \eqref{eq:dualdecomposition} and \eqref{eq:dualdualdecomposition} since \eqref{eq:dualdecomposition} is an equality constrained concave problem. Using the gradient descent method to solve \eqref{eq:dualdualdecomposition} at each iteration $k$, each agent $i$ performs two steps: \begin{itemize}
  \item (i) calculates the gradient $\nabla d(\boldsymbol{\lambda}^k)$: receive $\lambda_{ji}^k$, $j\in\mathcal{N}_i$, and compute $\boldsymbol{\mu}_i^{k+1}$ by solving 
  \begin{equation}\label{eq:relaxeddual}
    \max_{\boldsymbol{\mu}_i\ge 0}\left(q_i(\boldsymbol{\mu}_i)+\boldsymbol{\mu}_i^\top\sum_{j\in\mathcal{N}_i}(\lambda_{ij}^k-\lambda_{ji}^k)\right)
  \end{equation}
  \item (ii) uses gradient descent: receive $\boldsymbol{\mu}_{j}^{k+1},$ and update $\lambda_{ij}$ by:
  \begin{equation}\label{eq:gradientdescent}
    \lambda_{ij}^{k+1}=\lambda_{ij}^k-\gamma^{k}(\boldsymbol{\mu}_i^{k+1}-\boldsymbol{\mu}_j^{k+1}).
  \end{equation}
\end{itemize}
Diminishing step-size is used here as \cite{notarnicola2019constraint}. Specifically, \eqref{eq:relaxeddual} is the dual problem of \eqref{eq:dcbf}. Strong duality holds for large enough $\boldsymbol{\rho}$ as the relaxed CBF constraints hold strictly. Updating \eqref{eq:gradientdescent} is the same as \eqref{eq:trunsubupdate} for every agent in iterations. Given that $d(\boldsymbol{\lambda})$ is convex, gradient descent guarantees that $d(\boldsymbol{\lambda}^k)$ convergence to the optimal value $d^*=J^*$ since strong duality holds between \eqref{eq:relaxedqp} and \eqref{eq:dualdecomposition}, as well as \eqref{eq:dualdecomposition} and \eqref{eq:dualdualdecomposition}. Moreover, the relaxed problem \eqref{eq:relaxedqp} is strongly (hence also strictly) convex, which indicates uniqueness of the optimal solution $(\boldsymbol{u}_{\mathrm{rel}}^*,\boldsymbol{\rho}^*)$ . Using Lemma \ref{lem:newproperty}, we obtain $\boldsymbol{u}_{\mathrm{rel}}^*=\boldsymbol{u}_{\mathrm{nom}}^*$, which is the optimal solution of \eqref{eq:centralizedqp}.

We then prove $(b)$. We show that $d(\boldsymbol{\lambda})$ is a convex quadratic function. First we prove that for every $i=1,\ldots,N$, $q_i(\boldsymbol{\mu}_i)$ in \eqref{eq:dualdecomposition} is a concave quadratic function. When every $\mathcal{U}_i=\mathbb{R}^{m_i}$, the relaxed CBF-QP \eqref{eq:relaxedqp} is a linearly constrained quadratic problem. Following the example \cite[Section 5.2.4, Eq. 5.28]{boyd2004convex}\footnote{The example demonstrates that the dual function of a convex quadratically constrained quadratic programming problem is a concave quadratic function. Our problem is as a special case where the quadratic terms are zero in the constraints. }, every $q_i(\boldsymbol{\mu}_i)$ is a concave quadratic function.
% with the quadratic part as $-\boldsymbol{\mu_i}^\top G_i G_i^\top\boldsymbol{\mu_i}$, where
% \begin{equation}\label{eq:quadraticmatrix}
% {G_i[i,e]} = \left\{ \begin{array}{l}
% {{\mathcal L}_{{g_i}}}{b_e},~\text{if $i\le N,i\in\mathcal{V}_e$}\\
% - 1~~~~~\text{if $i>N,i\in\mathcal{V}_e$}\\
% 0~~~~~~~\text{if $i>N,i\notin\mathcal{V}_e$}
% \end{array} \right.
% \end{equation}
% For $i\le N,i\in\mathcal{V}_e$, $G_{ie}$ corresponds to the coefficient for $u_{ie}$ in the linear constraints of \eqref{eq:relaxedqp}. For $e>E,e\in\mathcal{C}_i$, $G_{ie}$ corresponds to the coefficient, which is $-1$ for the relaxation variable $\rho_{i(e-E)}$.
Therefore, problem \eqref{eq:dualdecomposition} is a linearly constrained concave quadratic problem. Following \cite[Example 3.6]{guigues2020strong} $d(\boldsymbol{\lambda})$ is a convex quadratic function, which is necessarily smooth. Using constant step size
\begin{equation}\label{eq:stepsize}
  0 < \gamma < \frac{1}{2L},
\end{equation}
where $L$ is Lipschitz constant of $\nabla d(\boldsymbol{\lambda}),$ in a gradient descent method to minimize a smooth and convex function $d(\boldsymbol{\lambda})$, the generated iterates converge sublinearly as
\begin{align}
  d(\boldsymbol{\lambda}^{k})-J^*&\le \frac{2(d(\boldsymbol{\lambda}^0)-J^*)||\boldsymbol{\lambda^0}-\boldsymbol{\lambda^*}||_2^2}{2||\boldsymbol{\lambda}^0-\boldsymbol{\lambda}^*||_2^2+k\gamma(2-L\gamma)(d(\boldsymbol{\lambda}^0)-J^*)}\nonumber\\
  \le &\frac{2(d(\boldsymbol{\lambda}^0)-J^*)||\boldsymbol{\lambda^0}-\boldsymbol{\lambda^*}||_2^2}{k\gamma(d(\boldsymbol{\lambda}^0)-J^*)}\le \frac{2||\boldsymbol{\lambda}^0-\boldsymbol{\lambda}^*||_2^2}{k\gamma}.
\end{align}
The first inequality is proved by \cite[theorem 2.1.4]{nesterov2003introductory}, the second one comes from eliminating the term $||\boldsymbol{\lambda}^0-\boldsymbol{\lambda}^*||_2^2$, and considering $2-L\gamma\ge 1$ from \eqref{eq:stepsize}. The Lipschitz constant can be calculated by the largest eigenvalue of the quadratic term for $d(\boldsymbol{\lambda})$.
Although the expression of $d(\boldsymbol{\lambda}^k)$ is not derived, $d(\boldsymbol{\lambda}^k)$ can be calculated by
\begin{align}\label{eq:sublinearrate}
    &d(\boldsymbol{\lambda}^k)=\sum_{i=1}^N\sup_{\boldsymbol{\mu}_i\ge 0}\left(q_i(\boldsymbol{\mu}_i)+\boldsymbol{\mu}_i^\top\sum_{j\in\mathcal{N}_i}(\lambda_{ij}-\lambda_{ji})\right)\nonumber\\
    &=\sum_{i=1}^N\sup_{\boldsymbol{\mu}_i\ge 0}\left(\inf_{u_i,\boldsymbol{\rho}_i\ge 0}\left(J_i(u_i)+\sum_{e\in\mathcal{C}_i}\left(\rho_{ie}^2+M_i\rho_{ie}\right)\right)\right.\nonumber\\
    &\left.+\sum_{e\in\mathcal{C}_i}\mu_{ie}(h_{ie}(u_i)-\rho_{ie})+\boldsymbol{\mu}_i^\top \sum_{j\in\mathcal{N}_i}(\lambda_{ij}^k-\lambda_{ji}^k)\right).
\end{align}
For every $i=1,\ldots,N$, and $\boldsymbol{\lambda}^k$, there always exists $\boldsymbol{u}_i$ and $\boldsymbol{\rho}_i$, such that the inequality constraint in (4) strictly holds, which indicates strong duality. Therefore, we have
\begin{align}\label{eq:primaldual}
&d(\boldsymbol{\lambda}^k)=\nonumber\\
&\sum_{i=1}^N\inf_{u_i,\boldsymbol{\rho}_i\ge 0}\left(\sup_{\boldsymbol{\mu}_i\ge 0}\left(J_i(u_i)+\sum_{e\in\mathcal{C}_i}\left(\rho_{ie}^2+M_i\rho_{ie}\right)\right)\right.\nonumber\\
&\left.+\sum_{e\in\mathcal{C}_i}\mu_{ie}(h_{ie}(u_i)-\rho_{ie})+\boldsymbol{\mu}_i^\top \sum_{j\in\mathcal{N}_i}(\lambda_{ij}^k-\lambda_{ji}^k)\right)\nonumber\\
&=\sum_{i=1}^N\left(J_i(u_i^k+\sum_{e\in\mathcal{C}_i}((\rho_{ie}^k)^2+M_i\rho_{ie}^k)\right)\nonumber\\
&=\sum_{i=1}^N||u_i^{k}-u^{\mathrm{des}}||^2+\rho_{\mathrm{sum}}^{k}=H(\boldsymbol{u}^k,\boldsymbol{\rho}^k).
\end{align}
Hence, by \eqref{eq:sublinearrate} and \eqref{eq:primaldual} we conclude that $H(\boldsymbol{u}^k,\boldsymbol{\rho}^k)-J^*<\frac{2||\boldsymbol{\lambda}^0-\boldsymbol{\lambda}^*||_2^2}{\gamma k}$.
\end{pf}

% \begin{pf}[Proof of Theorem \ref{th:confidence}]
% Consider the random variables
% \begin{equation*}
%   \mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\delta_i\right\}, i=1,\ldots,N,
% \end{equation*}
% where $\delta_i=\sum_{e\in\mathcal{C}_i}\left(\frac{(\rho_{ie}^\eta(\boldsymbol{x}))^2}{M_i}+\rho_{ie}^\eta(\boldsymbol{x})\right)>\epsilon_i$ represents an event. Recall that every $\tilde{\epsilon}_i$ is calculated by solving \eqref{eq:localupperbound}, which is a \emph{fully supported} problem \cite[Definition 3]{campi2008exact}. Therefore, $\delta_i$ is a Beta variable with parameters $(1,\bar N)$ \cite[Theorem 1]{campi2008exact}, the cumulative distribution is given by
% \begin{equation*}
%   \mathbb{P}^{\bar N}\left\{ \mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\delta_i\right\}\le 1-\tilde{\varepsilon_i}\right\}= \beta_i, i=1,\ldots,N,
% \end{equation*}
% where $\tilde{\varepsilon_i}=\sqrt[\bar N-1]{1-\beta_i}$. Equivalently, we have
% \begin{equation}\label{eq:dontnohowtoname}
%   \mathbb{P}^{\bar N}\left\{ \mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\ge\tilde{\varepsilon_i}\right\}=\beta_i, i=1,\ldots,N,
% \end{equation}
% where $\bar{\delta_i}$ is the event complementary to $\delta_i$. We first show that
% \begin{equation}\label{eq:prior}
%   \mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\ge1-\sum_{i=1}^N\beta_i.
% \end{equation}
% We have that
% \begin{align*}
%   \mathbb{P}^{\bar N}&\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
%   =& \mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
%   \ge & \mathbb{P}^{\bar N}\left\{\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
%   \ge & \mathbb{P}^{\bar N}\left\{\bigcap_{i=1}^N\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}\right\}\right\}\\
%   \ge & 1- \sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}>\tilde{\varepsilon_i}\right\}
%   \ge 1-\sum_{i=1}^N\beta_i,
% \end{align*}
% where the first inequality is due to subbatitivity of $\mathbb{P}$. The second inequality is since an element in the intersection $\bigcap_{i=1}^N\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}\right\}$ will also be in the set of samples such that $\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\le \tilde{\varepsilon_i}$ for all $i=1,\ldots,N$, and hence also in the set of samples such that $\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bar{\delta_i}\right\}\le \sum_{i=1}^N\tilde{\varepsilon_i}$.
% The third inequality follows from the second one using the set complement and the subbatitivity of $\mathbb{P}^{\bar N}$, while the last inequality is due to \eqref{eq:dontnohowtoname}.
% Using \eqref{eq:prior}, we have
% \begin{align*}
%   \mathbb{P}^{\bar N}&\left\{\mathbb{P}\{\boldsymbol{x}\in{ \mathcal{H}}:\rho_{\mathrm{sum}}^\eta(\boldsymbol{x})>\epsilon\}\ge 1-\sum_{i=1}^N\tilde{\varepsilon_i} \right\}\\
%   \ge&\mathbb{P}^{\bar N}\left\{\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcap_{i=1}^N\delta_i\right\}\ge1-\sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
%   =&\mathbb{P}^{\bar N}\left\{1-\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcup_{i=1}^N\bar{\delta_i}\right\}\ge1-\sum_{i=1}^N\tilde{\varepsilon_i}\right\}\\
%   \ge&1-\sum_{i=1}^N\beta_i,
% \end{align*}
% thus concluding the proof.
% \end{pf}
\begin{pf}[Proof of Theorem \ref{th:probability}]
We have that 
\begin{align}\label{eq:scinequality1}
   \mathbb{P}^{\bar N}&\left\{\frac{\sum_{i=1}^N\underline\epsilon_i(s_i^*)}{N} \le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\boldsymbol{z}^*\notin\mathcal{Z} \right\} \le \sum_{i=1}^N\bar\epsilon_i(s_i^*)
  \right\}\nonumber\\
  &=\mathbb{P}^{\bar N}\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\vphantom{\bigcap_{i=1}^N}\boldsymbol{x}\in{ \mathcal{H}}: \right.\right.\nonumber\\
  &\hspace{0.1cm}\exists i\in\{1,\ldots,N\},\left.\left.\vphantom{\bigcap_{i=1}^N}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\nonumber\\
  &=\mathbb{P}^{\bar N}\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcup_{i=1}^N\left\{\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right\}\right.\nonumber\\
  &\bigcap\left.\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in{ \mathcal{H}}:\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right.\}
  \end{align}
  We separately deal with the inner and upper bounds on the probability. For the upper bound we have
  \begin{align*}
   \mathbb{P}^{\bar N}&\left\{\mathbb{P}\left\{\bigcup_{i=1}^N\left\{\boldsymbol{x}\in{ \mathcal{H}}:\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\\
   \ge &\mathbb{P}^{\bar N}\left\{\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}.
  \end{align*}
  The equality is achieved when for any $i\ne j$, $\boldsymbol{z}^*\notin\mathcal{Z}_i$ and $\boldsymbol{z}^*\notin\mathcal{Z}_j$ are mutually exclusive.
  For the lower bound we have
  \begin{align*}
    \mathbb{P}^{\bar N}&\left\{\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\bigcup_{i=1}^N\left\{\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right\}\right\}\\
    \ge &\mathbb{P}^{\bar N}\left\{N\cdot\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right\}.
  \end{align*}
  The equality is achieved if for any $i\ne j$, $\boldsymbol{z}^*\ne \mathcal{Z}_i\Leftrightarrow\boldsymbol{z}\ne\mathcal{Z}_j$ and $\underline{\epsilon}_i(s_i^*)=\underline{\epsilon}_j(s_j^*)$. The right-hand side of \eqref{eq:scinequality1} can be then lower-bounded by
  \begin{align}
  &\mathbb{P}^{\bar N}\left\{N\cdot\frac{1}{N}\sum_{i=1}^N\underline\epsilon_i(s_i^*)\le\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right.\nonumber\\&\bigcap
  \left.\sum_{i=1}^N\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\le\sum_{i=1}^N\bar\epsilon_i(s_i^*)\right\}\nonumber\\
    &\ge \mathbb{P}^{\bar N}\left\{\bigcap_{i=1}^N\left\{\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\le\bar\epsilon_i(s_i^*)\right\}\right\}\nonumber\\
    &\ge
    1-\sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\bar\epsilon_i(s_i^*)<\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right.\nonumber\\
    &\bigcup\left.\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}<\underline\epsilon_i(s_i^*)\right\}.
\end{align}
By \cite[Theorem 1]{garatti2019risk} we have that for any $i=1,\ldots,N$
\begin{align}\label{eq:scinequality2}
   &\mathbb{P}^{\bar N}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\underline\epsilon_i(s_i^*)\le\mathbb{P}\left\{\vphantom{\bigcup}\boldsymbol{x}\in{ \mathcal{H}}:\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\le\bar\epsilon_i(s_i^*)\right\}\nonumber\\
   &\ge 1-\beta_i\nonumber\\
   \Rightarrow&\sum_{i=1}^N\mathbb{P}^{\bar N}\left\{\bar\epsilon_i(s_i^*)<\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}\right.\nonumber\\
    &\bigcup\left.\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\vphantom{\bigcup}\boldsymbol{z}^*\notin\mathcal{Z}_i \right\}<\underline\epsilon_i(s_i^*)\right\}<\sum_{i=1}^N\beta_i.
\end{align}
Since $\frac{\underline \epsilon(s^*)}{N}<\underline\epsilon(s^*)<\bar\epsilon(s^*)$,
substituting \eqref{eq:scinequality2} into \eqref{eq:scinequality1} with $i=1,\ldots,N$ we obtain 
\begin{equation}\label{eq:55}
  \mathbb{P}^{\bar N}\left\{\frac{\underline\epsilon(s^*)}{N}\le\mathbb{P}\left\{\boldsymbol{x}\in{ \mathcal{H}}:\boldsymbol{z}^*\notin\mathcal{Z} \right\}\le\bar\epsilon(s^*)
  \right\}\ge 1-\beta.
\end{equation}
We then prove that $\boldsymbol{z}^*$ is unique, and $\boldsymbol{z}^*=0$. For the case where all the CBF constraints are satisfied, i.e. $\sum_{k\in\mathcal{V}_e} h_{ke}(u_k(\boldsymbol{x}^{(r)}))\le 0,\forall e=1,\ldots,E$, $r=1,\ldots,\bar N$, we have that $\boldsymbol{z}^*=0$ and $\boldsymbol{\zeta}^*= 0$. For the case where there exists violated CBF constraint, i.e. $\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))>0$, we have that $z_{ie}^*=0$ since $\boldsymbol{z}\le 0$, and $\zeta_{ie}^*>0$ for $i\in\mathcal{V}_e$. In summary, we always have $\boldsymbol{z}^*=0$ for any scenarios, thus \eqref{eq:55} is equivalent to \eqref{eq:violation}. In addition, we directly obtain that $\zeta_{ie}^*> 0$ shows that $\sum_{i\in\mathcal{V}_e}h_{ie}(u_i(\boldsymbol{x}^{(r)}))> z_{ie}^*=0$. Thus, for every agent, $s_i^*$ is the number of non-zero $\zeta_{ie}^*$, for $e\in\mathcal{C}_i$.

\end{pf}

\bibliographystyle{ieeetr}
\bibliography{main.bib} 

	% \begin{IEEEbiography}[
 % {\includegraphics[width=1in,height=1.2in,clip,keepaspectratio]{photo/HW.jpeg}}
	% 	]{Han Wang}
	% 	received B.S. in information security from Shanghai Jiao Tong University, China, in 2020. He is currently a Ph.D. student with the Department of Engineering Science at University of Oxford, Oxford, United Kingdom. He is a member of Control Group. His research interests include safety verification, safe control design, and sum-of-squares programming.
	% \end{IEEEbiography}
 % \vspace{-1cm}
	% \begin{IEEEbiography}[
	% 	{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/antonis-papachristodoulou.jpg}}
	% 	]{Antonis Papachristodoulou} (F'19) received the M.A./M.Eng. degree in electrical and information sciences from the University of Cambridge, Cambridge, U.K., and the Ph.D. degree in control and dynamical systems (with a minor in aeronautics) from the California Institute of Technology, Pasadena, CA, USA. He is currently Professor of Engineering Science at the University of Oxford, Oxford, U.K., and a Tutorial Fellow at Worcester College, Oxford. He was previously an EPSRC Fellow. His research interests include large scale nonlinear systems analysis, sum of squares programming, synthetic and systems biology, networked systems, and flow control.
	% \end{IEEEbiography}\vspace{-1cm}
 % 	\begin{IEEEbiography}[
 % {\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/KM.pdf}}
	% 	]{Kostas Margellos} received the Diploma degree in electrical engineering from the University of Patras, Patras, Greece, in 2008, and the Ph.D. degree in control engineering from ETH Zrich, Zrich, Switzerland, in 2012. He spent 20132015 as a Postdoctoral Researcher with ETH Zrich; UC Berkeley, Berkeley, CA, USA; and Politecnico di Milano, Milan, Italy, respectively. In 2016, he joined the Control Group, Department of Engineering Science, University of Oxford, Oxford, U.K., where he is currently an Associate Professor. He is also a Fellow of Reuben College, Oxford, U.K., and a Lecturer with Worcester College, Oxford, U.K. His research interests include optimization and control of complex uncertain systems, with applications to energy and transportation networks.
	% \end{IEEEbiography}
\end{document}
