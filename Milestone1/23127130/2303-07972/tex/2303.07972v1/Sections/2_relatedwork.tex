\section{related work}\label{sec:relatedwork}

Most constrained grasp sampling works either fall into task-based grasping, 4-\ac{dof} data-driven grasping, or geometrically constrained grasping. As these three categories are generally unrelated, we will review them separately.

\subsection{4-\ac{dof} Grasping}

4-\ac{dof} grasp samplers restrict the approach direction of the grasps to be perpendicular to a specific grasping plane \cite{morrisonClosingLoopRobotic2018b,mahlerDexNetDeepLearning2017a,zhou2018fully,satish2019policy,kumra2020antipodal,zhu2022sample}. As such, these methods are constrained by construction. One of the obvious benefits of constraining grasps to 4-\ac{dof} instead of 6 is that it restricts the space of possible grasps, which facilitates learning. If, additionally, grasps are constrained to a top-down direction, the surface the objects rest on hinders the gripper from tilting the object while approaching it, which generally improves grasp success rates substantially \cite{lundell2020beyond}. However, if grasps are generated from a camera plane that is not top-down, which is the case in this work, grasp success deteriorates drastically \cite{lundell2020beyond}. Therefore, we do not restrict the approach direction by construction and instead propose constraining it to \textit{any} subset of $\mathrm{SO}(3)$.   

\subsection{Task-based Grasping}

As the name suggests, task-based grasp samplers address how to sample grasps for completing tasks. Early such approaches used numerical methods to find grasps that could achieve specific task wrenches \cite{borst2004grasp,haschke2005task}. Although these solutions are computationally efficient and mathematically sound, specifying a task in the abstract wrench space is non-trivial. To avoid the need for specifying task wrenches, later work focused on learning to sample task-specific grasps from data  \cite{murali2021same,antonovaGlobalSearchBernoulli2018a,kokic2017affordance,song2010learning,song2015task,fang2020learning,detry2017task}. The main difference between these data-driven methods is in the model for learning the task-specific grasps, which ranged from Bayesian networks \cite{song2010learning,song2015task}, kernel methods \cite{antonovaGlobalSearchBernoulli2018a}, to \acp{dnn} \cite{kokic2017affordance,murali2021same}. Compared to task-based grasping methods, our method is more flexible because it can generate grasps not only for completing tasks but also grasps that can, for example, avoid parts of the environment that the robot would otherwise risk colliding with.

\subsection{Geometrically Constrained Grasping}\label{sec:geometrically_constrained_grasping}

In geometrically constrained grasping, grasps are constrained to align with the geometry of the object model \cite{pas2016localizing,stoyanov2016grasp}. One of the primary reasons for aligning grasps to the geometry of the object was found in the seminal work by \etal{Balasubramanian} \cite{balasubramanian2012physical} where they experimentally demonstrated that in highly successful human-planned robotic grasps, the robot's wrist was mainly aligned to the first \acp{pc} of the object or the plane normal to the first \ac{pc}.

In our work, we do not explicitly constrain the sampled grasps to the object's geometry. Nevertheless, we do draw inspiration from these as we select bins that constrain the generated grasp directions to lie in the plane normal to the largest \ac{pc} and along the second largest \ac{pc} of the observed \pc{}.

%Pose eller encoding av objected (Gaussian och anv√§nder kovariansmatrisen etc...)