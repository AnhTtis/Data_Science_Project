\section{Method}\label{sec:method}

As formalized in the previous section, two \acp{dnn} are required: a generative grasp sampler and a grasp discriminator. Next, we describe, in detail, \methodname{} our novel generative approach-constrained grasp sampling network and the automatic \ac{pc}-based bin selection process. Finally, we introduce the grasp discriminator from \cite{mousavian20196} for completeness but refer the reader to the original work in \cite{mousavian20196} for specific details.
% Finally, we overview the grasp discriminator for completeness but refer the reader to \cite{mousavian20196} for specific details.

\begin{figure*}
\centering
\begin{minipage}{.48\textwidth}
  \centering
  \captionsetup{margin=0.25cm}
        \includegraphics[width=0.55\linewidth]{figures/yaw_pitch_roll_obj.png}
    \captionof{figure}{The camera-centric grasp orientation representation. Here, $\Vec{a}$ is the gasp approach direction, $\alpha$ the roll angle, $\beta$ the pitch angle, and $\gamma$ the yaw angle, all represented in the camera coordinate system. 
    }
  \label{fig:yaw-pitch-cam}
\end{minipage}%
\begin{minipage}{.48\textwidth}
  \centering
  \captionsetup{margin=0.25cm}
        \includegraphics[width=1\linewidth]{figures/yaw_pitch_roll_cam_dist.png}
        % \includesvg[width=1\linewidth]{figures/yaw_pitch_roll_cam_dist.svg}
    \captionof{figure}{An example of discretizing $\mathrm{SO}(3)$ into 8 bins ($\text{N}_\beta=2$, $\text{N}_\gamma=4$). Yaw and pitch labels are generated for $\gamma$ and $\beta$ in \figref{fig:yaw-pitch-cam}.}
    \label{fig:yaw-pitch-discretize}
\end{minipage}
\end{figure*}


\subsection{\methodname{}}\label{sec:generator}

\methodname{} is an approach-constrained deep generative grasp sampling network $\mathcal{Q}_{\boldsymbol{\theta}}(\matr{G}|\matr{O}, \text{C})$ that approximates $\prob{(\matr{G}|\matr{O}, \text{C})}$, where $\matr{O} \in \mathbb{R}^{\text{N}\times3}$ is the object \pc{} and $\text{C}\subset \mathrm{SO}(3)$ is a subset of the rotation group $\mathrm{SO}(3)$. As discussed in the previous section, the idea behind conditioning the network on $\text{C}$ is to constrain the approach vector $\Vec{a}$ or the pitch and yaw Euler angles to lie within some subset of $\mathrm{SO}(3)$.  

Unfortunately, it is non-trivial to design \acp{dnn} that operates on sets. To alleviate this problem, we propose to discretize $\mathrm{SO}(3)$ into $\text{B}$ bins using the yaw and pitch of the Euler angles where each bin $\text{b}_{\text{i}} \in \text{B}$ is represented by a two-integer label $\text{b}_{\text{i}} = [\text{c}^{\text{i}}_{\beta},~\text{c}^{\text{i}}_{\gamma}] \in \mathbb{Z}_+^2$. The constraint $\text{C}$ then becomes one of the bins $\text{b}_\text{i} \in \text{B}$. Mathematically, the discretization is realized by first choosing a range of values for each of the two Euler angles pitch ($\beta \in [0,~\pi]$) and yaw ($\gamma \in [0,~2\pi]$). Next, these ranges are divided into equally spaced intervals of size $\text{N}_\beta$ and $\text{N}_\gamma$, respectively. Finally, a query Euler angle $\beta_\text{i}$ and $\gamma_\text{i}$ is mapped into the correct label $\text{b}_\text{i}=[\text{c}_\beta^{\text{i}},~\text{c}_\gamma^{\text{i}}]$ by:

\begin{equation}\label{eq:descritization}
\text{c}_{\beta}^{\text{i}} = \lfloor \frac{\text{N}_{\beta}\beta_{\text{i} }}{\pi} \rfloor,~\text{c}_{\gamma}^{\text{i}} = \lfloor \frac{\text{N}_{\gamma}\gamma_{\text{i}}}{2\pi} \rfloor.
\end{equation}
An example discretization using the above process is shown in \figref{fig:yaw-pitch-discretize}.

Using the two-integer constraint $\text{C}$, we design \methodname{} similarly to \cite{mousavian20196,lundell2023constrained} as a \ac{cvae}~\cite{sohnLearningStructuredOutput2015} but with both $\matr{O}$ \textit{and} \text{C} as the conditional variables. The \ac{cvae} consists of an encoder $\mathsf{q}_{\boldsymbol{\zeta}}(\mathbf{z}\mid\matr{O}, \text{C}, \matr{G})$ and a decoder $\mathsf{p}_{\boldsymbol{\chi}}(\matr{G}\mid\matr{O},\text{C},\mathbf{z})$, where $\mathbf{z}\in \mathbb{R}^{\text{L}}$ is a latent vector of size $\text{L}$. As we want to operate directly on \pcs{}, we choose \pointnet{} as the backbone of \methodname{}. The input \pc{} $\matr{X}\in \mathbb{R}^{\text{N}\times (3+\text{K})}$ to the encoder consist of the object \pc{} $\matr{O} \in \mathbb{R}^{\text{N}\times 3 }$ with the constraint $\text{C}$ and the grasp pose $\matr{G}$ as the K additional point-wise features. The decoder uses the same input \pc{} as the encoder but with $\mathbf{z}$ instead of $\matr{G}$ as additional point-wise features. 

For optimizing the parameters of \methodname{} we use the standard \ac{vae} loss:

\begin{align}
\label{eq:vae_loss}
    \mathcal{L}_{\text{VAE}} = \mathcal{L}(\matr{G}^*,\hat{\matr{G}}) + \eta \mathcal{D}_{\text{KL}}[\mathsf{q}_{\zeta} (\mathbf{z}\mid\matr{O},\text{C},\matr{G}^*),~\mathcal{N}(\matr{0},\matr{I})],
\end{align}
where $\eta$ is a scalar, $\matr{G}^*$ is a ground truth stable grasp, and $\mathcal{D}_{\text{KL}}$ is the KL-divergence. Similarly to \cite{mousavian20196,lundell2023constrained} we define the reconstruction loss $\mathcal{L}(\matr{G}^*,\hat{\matr{G}})$ as
\begin{align}
    \mathcal{L}(\matr{G}^*,\hat{\matr{G}}) = \norm{\text{h}(\matr{G}^*)-\text{h}(\mathbf{\hat{\matr{G}}})}_1,
\end{align}
where $\matr{\hat{G}}$ is a generated grasp from the decoder $\mathsf{p}_{\chi}$, and $\text{h}: \mathbb{R}^{7} \rightarrow  \mathbb{R}^{6\times 3}$ is a function that maps a 7-dimensional grasp pose into a \pc{} representation of the gripper $\matr{P} \in \mathbb{R}^{6\times 3}$. The benefit of a point cloud representation for the gripper pose is to combine orientation and translation into one loss function.
% The gripper pose is mapped to a \pc{} because it combines the orientation and translation into one loss function.

Although both the encoder and the decoder are used for training \methodname{}, only the decoder is used for sampling grasps on an unknown \pc{}. Specifically, to generate M grasps on an unknown object \pc{} $\matr{O}$ with the approach direction constrained to a yaw and pitch angle of $\beta_{\text{j}}$ and $\gamma_{\text{j}}$ the first step is to sample M iid latent vectors from the zero mean Gaussian $\mathbf{z}_{0,\dots,\text{M}}\sim \mathcal{N}(\matr{0},\matr{I})$.  Next, the yaw and pitch angles are mapped into the two-integer bin value $\text{b}_j$ using \eqref{eq:descritization}. Finally, M copies of the object \pc{} are created, where each \pc{} copy $\matr{O}_{\text{i}}$ is concatenated with a unique latent vector $\mathbf{z}_{\text{i}}$ and the constraint labels $\text{b}_{\text{j}}$, and passed through the decoder to produce the M grasps. 

\subsection{\ac{pc}-based Bin Selection}\label{sec:pc_selection}
The main downside of \methodname{} as described above is the need to a-priori specify the approach direction constraint $\text{C}$. Two options for specifying $\text{C}$ are to use a human or to learn it. Unfortunately, both of these options are expensive to realize. Therefore, we propose selecting bins that align with some easy-to-estimate latent features of the object's geometry. 

The features we use in this work are the \acp{pc} of the object's point cloud as these have been used in similar non-learning-based grasping works discussed in \secref{sec:geometrically_constrained_grasping}. To calculate the \acp{pc}, we ultilize the \ac{pca} using the covariance matrix $\Sigma_{\matr{O}} = \frac{1}{N}(\matr{O}-\bar{\matr{O}})^{T}(\matr{O}-\bar{\matr{O}})$ of the object point cloud $\matr{O}$ with the barycenter $\bar{\matr{O}}$. This results in three ordered eigenvalues $\lambda_1$, $\lambda_2$, $\lambda_3$ and corresponding eigenvectors, $\hat{v}_1$, $\hat{v}_2$, $\hat{v}_3$, where $\lambda_1 \geq \lambda_2 \geq \lambda_3$. The eigenvectors are also known as the \acs{pc}. In accordance with the prior work \cite{balasubramanian2012physical}, we select the second largest \ac{pc} $\hat{v}_2$ to constrain the approach direction. 

Due to the symmetry of the \acp{pc}, we need to find the bins that intersect with $\pm \hat{v}_2$. For that, we first calculate the roll, pitch, and yaw separately for $\pm \hat{v}_2$ using

\begin{equation}\label{eq:vec_to_euler}
\begin{split}
&\alpha \in [0, 2\pi], \\
&\gamma = \arctan (\hat{v}_{2,y}, \hat{v}_{2,x}) \in [0, 2\pi], \\
&\beta = \arccos (\hat{v}_{2,z}) \in [0,\pi], \\
\end{split}
\end{equation}
where $\hat{v}_{2,x}$, $\hat{v}_{2,y}$, and $\hat{v}_{2,z}$ represent the x-, y-, and z-component of the vector $\hat{v}_{2}$ respectively.
Then, for each $\pm \hat{v}_2$, the pitch ($\beta$) and yaw ($\gamma$) angles are mapped into the corresponding two-integer label using \eqref{eq:descritization}. These two two-integer labels are then used one after the other to generate grasps with the approach vector constrained to $\pm \hat{v}_2$.    

\subsection{Grasp Discriminator}

\methodname{} can generate unsuccessful grasps between modes because it is only trained on distributions of successful grasps \cite{mousavian20196}. To avoid executing poor grasps, we used the grasp discriminator introduced in \cite{mousavian20196} to score how likely the sampled grasps were to succeed.

Mathematically, the  grasp discriminator $\mathcal{D}_{\boldsymbol{\psi}}(\text{S}=1 | \matr{G}, \matr{O})$ is optimized to approximates $\prob{(\text{S}=1 | \matr{G}, \matr{O})}$. It is based on the same \pointnet{} architecture as \methodname{}. However, the input \pc{} $\matr{Y} \in \mathbb{R}^{(\text{N}+6)\times (3+1)}$ to the evaluator differs significantly from the generator in that the object \pc{} $\matr{O} \in \mathbb{R}^{N \times 3}$ is concatenated with a grasp \pc{} $\matr{K} \in \mathbb{R}^{6\times 3}$ and an additional one-dimensional binary feature is added to the input \pc{} $\matr{Y}$ to distinguish between the two \pcs{} $\matr{O}$ and $\matr{K}$. The grasp discriminator is optimized to distinguish between successful and unsuccessful grasps using the binary cross-entropy loss:
\begin{align}
\mathcal{L}_{E}=(-\text{S}^*\log(\text{S})+(1-\text{S}^*)\log(1-\text{S})),    
\end{align}
where $\text{S}^*$ is the ground-truth success of a grasp and $\text{S}$ is the predicted success.
