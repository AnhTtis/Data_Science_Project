\section{conclusion}

We proposed \methodname{}, the first deep learning-based data-driven grasp sampler that can generate approach-constrained grasps in all of $\mathrm{SO}(3)$ together with a geometrical method to automatically extract specific grasp approach directions from the object's \pc{}. In simulation and real-world experiments, \methodname{} reached an 8--18\% higher grasp success rate and kept more than 7 times as many grasps as an unconstrained data-driven grasp sampler. The real-world shelf-picking experiment highlighted \methodname{}'s ability to pick from confined spaces by constraining grasp approach directions to collision-free directions instead of sampling all around the object.

In the future, we envision \methodname{} to constrain complete grasp poses to subsets of $\mathrm{SE}(3)$, including subsets that are easy to reach and have high manipulability. However, for that to become a reality, we believe that the discrete constraint needs to be replaced with a continuous one and that the orientation constraint should be combined with the position constraint from \cite{lundell2023constrained}, both of which are non-trivial but exciting future work directions.  

%We envision \methodname{}  generating approach-constrained grasps to creating pose-constrained ones, such as only reachable grasps or grasps with high manipulability. To reach those goals, we believe that the discrete constraint needs to be replaced with a continuous one and that the orientation constraints should be combined with the position constraint proposed in \cite{lundell2023constrained}, both of which are non-trivial but exciting future work directions.

%\zehang{Furthermore, while our model can currently accept human-prompted directions, an open question remains: can it learn to propose suitable approach directions based on the task and environment without explicit directional input? Exploring this ability to autonomously adapt the approach direction to environmental constraints and task requirements represents a promising avenue for future research.}