\section{Problem Formulation}\label{sec:problem}

In this work, we address the problem of synthesizing successful (S=1) parallel-jaw grasps $\matr{G}$ on partially observed object point clouds $\matr{O} \in \mathbb{R}^{\text{N}\times 3}$ where the approach directions $\Vec{a} \in \mathbb{R}^3$ of the grasps are constrained to a subset $\text{C}\subset \mathrm{SO}(3)$ of the rotation group $\mathrm{SO}(3)$. Mathematically, the objective is to learn the joint distribution $\prob{(\matr{G}, \text{S}=1 | \matr{O}, \text{C})}$. 

We define a grasp as successful if it can pick and hold the target object. Based on that definition, $\matr{G}$ and $\matr{O}$ fully determine the grasp success probability. Thus, the success of a grasp $\text{S}$ is conditionally independent of $\text{C}$ given $\matr{G}$. Using this independence, we can factorize $\prob{(\matr{G}, \text{S}=1 | \matr{O}, \text{C})}$ into $\prob{(\text{S}=1 | \matr{G}, \matr{O})}\prob{(\matr{G}|\matr{O}, \text{C})}$, where the first distribution $\prob{(\text{S}=1 | \matr{G}, \matr{O})}$ is a grasp discriminator and the second $\prob{(\matr{G}|\matr{O}, \text{C})}$ is a grasp generator. We approximate these distributions with separate \acp{dnn} $\mathcal{Q}_{\boldsymbol{\theta}}(\matr{G}|\matr{O}, \text{C})\approx \prob{(\matr{G}|\matr{O}, \text{C})}$ and $\mathcal{D}_{\boldsymbol{\psi}}(\text{S}=1 | \matr{G}, \matr{O}) \approx \prob{(\text{S}=1 | \matr{G}, \matr{O})}$, each with their own trainable parameters $\boldsymbol{\theta}$ and $\boldsymbol{\psi}$. 

%The goal of this work then becomes to design these networks to best fit to grasping data. 

In this work, we represent grasp poses $\matr{G}=[\matr{R}, \matr{T}]\in \mathbb{R}^7$ by a rotation $\matr{R}$ expressed as a 4-D quaternion and a translation $\matr{T}$ represented as a 3-D vector. It is also possible to express the rotation $\matr{R}$ as a unit length approach vector $\Vec{a}\in \mathbb{R}^3$ and a hand orientation angle $\alpha$ or, in terms of Euler angles, as a roll ($\alpha$), pitch ($\beta$) and yaw ($\gamma$) angle, both of which are visualized in \figref{fig:yaw-pitch-cam}. Out of these components, the approach vector (pitch and yaw angles) is explicitly constrained by C, while the hand orientation (roll angle) is learned. 

%To further make the learning problem easier, we assume that only one graspable object is present at a time.


%We assume that only one graspable object is present at a time to simplify the grasping and learning problem.


%The generated grasps must be conditioned on an explicit orientation constraint, $C_{ori} \in \mathbb{R}^3$, which encodes the grasp orientation in $$\mathrm{SO}(3)$$, including the direction of the grasp approaching vector and the roll angle information.

%Specifically, our objective is to learn the joint distribution, $P(G, S | O, C_{ori})$, where $S$ represents the grasp success state. We decompose the learning process into two sub-tasks, as follows:

%\begin{enumerate}
%\item Learning a constrained grasp sampler model, $P(G | O, C_{ori})$, that enables grasp sampling based on the observed point cloud, $O$, and the grasp orientation constraint, $C_{ori}$. The research problem is framed as maximizing the likelihood of successful constrained grasps.
%\item Learning a grasp evaluator model, $P(S | O, G)$, that assesses the grasp quality score. Given $O$ and $G$, the stability of the grasp is conditionally independent of the grasp orientation.
%\end{enumerate}


%Additionally, we also explore the problem of automatic orientation selection, enabling the automatic stable grasps synthesis for the learning constrained model without human in the loop.

%In the following sections, a novel grasp orientation representation in a camera-centric manner will be proposed to address the formation of $C_{ori}$. This representation will then be utilized for the two models in the sub-tasks as parametric networks. Finally, a strategy that incorporates global geometric information for automatic orientation selection and stable grasp synthesis will be presented.

% Here we would state our assumptions and in what space we difine the grasp. We need a picture of the coordinate systems. 



% In this work, we address the problem of generating parallel-jaw grasp poses $G$ on a single partial object point cloud $O \in \mathbb{R}^{N\times 3}$  with $N$ points captured by a single depth camera with explicit grasp orientation constraint $C_{ori} \in \mathbb{R}^3$. Grasp pose $G=[R, T]\in \mathbb{R}^7$ is a combination of a 4-D grasp quaternion representation and a 3-D grasp translation vector. $C_{ori}$ should encode the grasp orientation in $S(O3)$including the approaching vector direction and the gripper roll angle information.

% Speicifically, we aim to learn the joint distribution $P(G, S | O,  C_{ori})$ which is factorized by two sub problems in our work:

% (1) Learning a grasp sampler model $P(G | O, C_{ori})$ that enable grasp sampling conditioned on the obserserved point cloud $O$ and the grasp orientation constriant $C_{ori}$. The research problem is formulated as maximizing the likelihood of the successful constrained grasps.

% (2) Learning a grasp evaluator model $P(S | O, G)$ which estimates the grasp quality. Given $O$ and $G$, the grasp stability is conditionally independent to the grasp orientation.

% Besides, we target on automatic orientation selection for the sample model $P_{auto}(G | O, C_{ori}=C_{})$ that $C_{}$ [pca-2]

% Thus these two models can be approximated by parametric models and optimized through gradient descent based on the collected observed dataset. In the following sections, we propose propose a novel grasp orientation representation in camera-centric manner which addresses the formation of $C_{ori}$. We then propose the network structure called OCVGS that addresses the sub problems. Finally, based on the previous two things, we propose a 
% scheme that ultilizes the global geometric information for automatic orientation selection and stable grasp synthesis.