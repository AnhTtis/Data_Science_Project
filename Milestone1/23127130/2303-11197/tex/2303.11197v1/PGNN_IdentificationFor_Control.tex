%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphicx}
\usepackage{xcolor}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{assumption}{Assumption}[section]


\title{\LARGE \bf
Data--driven feedforward control design for nonlinear systems: \\
A control--oriented system identification approach*
}


\author{Max Bolderman$^{\dagger, 1}$, Mircea Lazar$^1$, and Hans Butler$^{1,2}$% <-this % stops a space
\thanks{*This work is supported by the NWO research project PGN Mechatronics, project number 17973.}% <-this % stops a space
\thanks{$^{\dagger}$Corresponding author: {\tt\small m.bolderman@tue.nl}.}% <- this % stops a space
\thanks{$^{1}$Control Systems Group, Eindhoven University of Technology, Groene Loper 19, Eindhoven, 5612 AP, The Netherlands.}%
\thanks{$^{2}$ASML, De Run 6501, Veldhoven, 5504 DR, The Netherlands.}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Feedforward controllers typically rely on accurately identified inverse models of the system dynamics to achieve high reference tracking performance.
However, the impact of the (inverse) model identification error on the resulting tracking error is only analyzed a posteriori in experiments.
Therefore, in this work, we develop an approach to feedforward control design that aims at minimizing the tracking error a priori. 
To achieve this, we show that the norm of the tracking error can be upperbounded by the sum of the inversion error and the identification error.
This yields a two--step feedforward control design procedure that consists of a feedforward control--oriented system identification, and a finite--horizon optimization to compute the feedforward control signal. 
The nonlinear feedforward control design method is validated using physics--guided neural networks on a nonlinear, nonminimum phase mechatronic example, where it outperforms standard ILC.
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
\label{sec:Introduction}
Feedforward control is a dominant actor in achieving high reference tracking performance within high--precision mechatronic industries.
The achieved performance is typically limited by the accuracy of the model describing the dynamics as well as the accuracy of the inversion~\cite{Devasia2002}. 
Conventional feedforward controllers derived from linear models are therefore intrinsically limited.  
Indeed, linear models are not capable to describe the complete dynamical behaviour of a mechatronic system, which includes unknown dynamics arising from, e.g., manufacturing tolerances~\cite{Nguyen2018}. 
Consequently, there is an interest to employ rich, nonlinear models for feedforward control that can learn the unknown dynamics from data~\cite{Bolderman2023}. 
This, however, brings (new) challenges to feedforward control design, which are briefly discussed next.


A common approach to feedforward control design is inverse model--based feedforward, which generates the feedforward signal by passing the reference through a model of the inverse system dynamics, see, e.g.,~\cite{Boerlage2003, Butterworth2012}. 
When the model of the system is nonminimum phase, i.e., it has an unstable inverse, different methods are available to generate a stable feedforward controller, see, e.g.,~\cite{Butterworth2012, Zundert2018}.
These methods however, are not directly extendable to nonlinear feedforward controllers.
Hence, a different approach is to formulate feedforward control as an optimization problem, where the goal is to minimize the norm of the difference between the reference and the model output. 
Within this category, it is possible to optimize the complete feedforward signal~\cite{Volckaert2009, Carrasco2011}, or to parameterize the feedforward signal as a function of time or the reference and optimize over the parameters~\cite{Ramani2017, Kasemsinsup2021}. 
When the system performs a repetitive task, an iterative learning control (ILC) method can be used to minimize the tracking error based on the tracking error of previous repetitions by updating the feedforward input~\cite{Bristow2006}, the parameters of an inverse model~\cite{Blanken2017}, or both~\cite{Saltik2022}. 


The aforementioned methods typically assume a known, physics--based model of the system.
To account for unknown or complex to model dynamics, data--driven techniques have been explored in combination with artificial intelligence, e.g., neural network (NN) models~\cite{Sorensen1999}, physics--informed neural networks~\cite{Bolderman2022b}, or physics--guided neural network (PGNN) models~\cite{Bolderman2021} and other hybrid model structures~\cite{Chou2023}. 
However, due to the non--invertibility of (PG)NN models, these approaches generally adopt an identification of the inverse system directly. 
Thereby, the objective function minimized during the identification is not related to the reference tracking objective.
In~\cite{Aarnoudse2021}, a control--relevant identification cost function, which filters the inverse model error with a linear model of the process sensitivity was proposed to mitigate this issue. 
To the best of the authors' knowledge, a framework for feedforward control design for nonlinear systems that quantifies the relation between the identification error and the resulting tracking error is not yet available. 

Motivated by the above observations, in this paper we develop a nonlinear data--driven feedforward control design method that aims to minimize the tracking error a priori. 
To achieve this, we derive a fundamental upperbound on the norm of the tracking error in terms of the norm of the identification error, i.e., how well is the system identified, and the inversion error, i.e., how well is the feedforward control input designed for the identified model. 
This is in the spirit of~\cite{Hof1995}, which merges the identification and feedback control design in a single framework for linear systems. 
To minimize the tracking error, we develop a two--step procedure:
\begin{enumerate}
	\item \emph{Indirect closed--loop identification} based on a data set which should include relevant operating conditions;
	\item \emph{Feedforward control input design} by minimizing the norm of the difference between the reference and the predicted output of the identified model. 
\end{enumerate}
We formulate a finite horizon optimal feedforward control (FHOFC) problem to design the feedforward input. 
Similar formulations were used in~\cite{Carrasco2011} and~\cite{Volckaert2009} for linear and nonlinear systems, respectively.
Several directions are highlighted to reduce the computational complexity induced by optimizing the complete feedforward signal. 
Generality of the developed FHOFC formulation is demonstrated by recovering inverse model--based feedforward and linear ILC for specific settings. 
The FHOFC is directly applicable to nonlinear, multi--input multi--output (MIMO) systems, which can be nonminimum phase and in state--space representation, while it allows for specifying constraints on the inputs, outputs, and states.






\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/Overview_ControlStructure.pdf}
\caption{Schematic overview of the control structure.}
\label{fig:ClosedLoopSystem}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PRELIMINARIES}
\label{sec:Preliminaries}
We consider the feedforward control design for a system~$G$ operating in closed--loop with feedback controller $C$ as visualized in Fig.~\ref{fig:ClosedLoopSystem}. 
Let $k \in \mathbb{Z}_{\geq 0}$ be the discrete time instant. % with $\mathbb{Z}$ the set of integers. 
Then, $y(k) \in \mathbb{R}^{n_y}$ is the output at time $k$, $r(k) \in \mathbb{R}^{n_y}$ the reference, $e(k) := r(k)-y(k)$ the tracking error, and $u(k) \in \mathbb{R}^{n_u}$ the input with $n_y, n_u \in \mathbb{Z}_{>0}$ the number of outputs and inputs, respectively.
The input $u(k)$ is the sum of the feedback and feedforward inputs, such that $u(k) := u_{\textup{fb}}(k) + u_{\textup{ff}}(k)$. 
We assume that a stabilizing feedback controller is available, e.g., it is tuned from a frequency response function.
We denote a signal of length $N_k \in \mathbb{Z}_{>0}$ by its capital symbol letter, e.g.,
\begin{align}
\begin{split}
\label{eq:SignalNotation}
	Y & := [y^T(0), ..., y^T(N_k-1)]^T.
\end{split}
\end{align}

When supplied with a reference and feedforward input, the closed--loop system generates an output satisfying
\begin{equation}
\label{eq:System}
	Y = \Phi (x_0, R, U_{\textup{ff}} ),
\end{equation}
where $x_0 \in \mathbb{R}^{n_x}$ is the initial state, and $\Phi :\mathbb{R}^{n_x} \times \mathbb{R}^{N_k n_y} \times \mathbb{R}^{N_k n_u} \rightarrow \mathbb{R}^{N_k n_y}$ is a (partially) unknown mapping that specifies $Y$ in terms of $x_0$, $R$, and $U_{\textup{ff}}$. 
For an $x_0$ of interest, a data set of length $N_d \in \mathbb{Z}_{>0}$ is generated on the system, such that we have $Y^d$, $R^d$, and $U_{\textup{ff}}^d$ satisfying~\eqref{eq:System}, i.e., 
\begin{equation}
\label{eq:DataSetSystem}
	Y^d = \Phi (x_0, R^d, U_{\textup{ff}}^d ). 
\end{equation}

\begin{remark}
	The user can freely design $R^d$ and $U_{\textup{ff}}^d$ supplied during the data generation experiment. 
	Typically,~$R^d$ is chosen to include the references for which we aim to find a feedforward input, while $U_{\textup{ff}}^d$ serves as an excitation signal.
\end{remark}

The optimal feedforward control input $U_{\textup{ff}}$ minimizes the tracking error $E = R-Y$ according to a chosen norm, i.e.,
\begin{equation}
\label{eq:FeedforwardPerformance}
	U_{\textup{ff}} = \textup{arg} \min_{U_{\textup{ff}}} \left\| R - Y \right\|. 
\end{equation}
The mapping $\Phi$ in~\eqref{eq:System} is unknown, which means that the output $Y$ in~\eqref{eq:FeedforwardPerformance} cannot be computed as a function of the feedforward input $U_{\textup{ff}}$, i.e.,~$Y$ can only be generated by fixing $U_{\textup{ff}}$ and performing an experiment on the system.
Therefore, it is common to parameterize a model of $\Phi$, such that
\begin{equation}
\label{eq:SystemModel}
	\hat{Y} = \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}} ),
\end{equation}
where $\hat{Y}$ is a prediction of the output $Y$, $\hat{\Phi}:\mathbb{R}^{n_{\theta}} \times \mathbb{R}^{n_x} \times \mathbb{R}^{N_k n_y} \times \mathbb{R}^{N_k n_u} \rightarrow \mathbb{R}^{N_k n_y}$ a parameterized model of $\Phi$, and $\theta \in \mathbb{R}^{n_{\theta}}$ the model parameters with $n_{\theta} \in \mathbb{Z}_{>0}$. 
The mapping in~\eqref{eq:SystemModel} can be obtained by simulation of a model of the system dynamics, which can be input--output
\begin{align}
\begin{split}
\label{eq:SystemModelInputOutput}
	\hat{y}(k) & = f \big( \theta, [\hat{y}^T(k-1), ..., \hat{y}^T(k-n_a), \\
	& \quad \quad \quad \hat{u}^T(k-n_k-1), ..., \hat{u}^T(k-n_k-n_b)]^T \big), 
\end{split}
\end{align}
or state--space
\begin{align}
\begin{split}
\label{eq:SystemModelStateSpace}
	\hat{x}(k+1) & = f_x \big( \theta, \hat{x}(k), \hat{u}(k) \big), \\
	\hat{y}(k) & = g_x \big( \theta, \hat{x}(k) \big),
\end{split}
\end{align}
operating in closed--loop with, e.g., a linear output feedback
\begin{align}
\begin{split}
\label{eq:OpenClosedLoop}
	\hat{u}(k) & = C(q)  \big( r(k) - \hat{y}(k) \big) + u_{\textup{ff}}(k).
\end{split}
\end{align}

\begin{remark}
	A suitable model class for nonlinear feedforward control, which is used in this paper, are PGNNs~\cite{Bolderman2021}. 
	For example, for a single--input single--output (SISO) system, i.e., $n_y = n_u = 1$, the PGNN in input--output form~\eqref{eq:SystemModelInputOutput} is given as
	\begin{align}
	\begin{split}
	\label{eq:PGNN}
		\hat{y}(k) & = f_{\textup{phy}} \big( \theta_{\textup{phy}}, \phi(k) \big) + f_{\textup{NN}} \big( \theta_{\textup{NN}}, \phi(k) \big), \\
		\phi(k) & = [\hat{y}(k-1), ..., \hat{y}(k-n_a), \\
		& \quad \quad \quad  \hat{u}(k-n_k-1), ..., \hat{u}(k-n_k-n_b)]^T,
	\end{split}
	\end{align}
	where $n_a, n_b, n_k \in \mathbb{Z}_{\geq 0}$ describe the order of the dynamics, $f_{\textup{phy}} : \mathbb{R}^{n_{\theta_{\textup{phy}}}} \times \mathbb{R}^{n_a+n_b} \rightarrow \mathbb{R}$ is a known model derived from physics, $f_{\textup{NN}} :\mathbb{R}^{n_{\theta_{\textup{NN}}}} \times \mathbb{R}^{n_a+n_b} \rightarrow \mathbb{R}$ is a neural network, and $\theta = [\theta_{\textup{phy}}^T, \theta_{\textup{NN}}^T]^T$ are the parameters.	
\end{remark}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}
\label{sec:ProblemStatement}
Since the mapping $\Phi$ in~\eqref{eq:System} is unknown, the feedforward control design is based on a model--based mapping $\hat{\Phi}$ as in~\eqref{eq:SystemModel}. 
This typically yields a two--step feedforward controller design procedure, consisting of an \emph{identification} step to fit the model~\eqref{eq:SystemModel} to the data~\eqref{eq:DataSetSystem}, and an \emph{inversion} step to compute the feedforward input.
Although this approach is generally adopted in literature, see, e.g.,~\cite{Bolderman2023, Bolderman2022b, Bolderman2021, Aarnoudse2021}, a quantitative relation between the identification and the tracking error, respectively, is still missing.
Hence, the first problem considered in this work is to establish a quantitative relation between the tracking error on one hand, and the identification error and inversion error on the other hand. 

The identification step typically finds the parameters ${\theta} = \hat{\theta}$ for the model~\eqref{eq:SystemModel} by minimizing a cost function, such that
\begin{equation}
\label{eq:Identification}
	\hat{\theta} = \textup{arg} \min_{\theta} V ( \theta, Y^d, R^d, U_{\textup{ff}}^d ).
\end{equation}
Therefore, the second problem considered is how to choose the cost function $V(\theta, Y^d, R^d, U_{\textup{ff}}^d)$ such that the identified parameters $\hat{\theta}$ yield a model--based mapping $\hat{\Phi}(\hat{\theta}, x_0, R, U_{\textup{ff}})$ that is suitable for the design of a feedforward controller.

Often, the nonlinear inverse model--based feedforward controller suffers a performance loss when the forward model is nonminimum phase. 
For example,~\cite{Bolderman2023} imposes stability of PGNN feedforward controllers by constraining the NN parameters based on sufficient conditions for stability.
This might unnecessarily limit the flexibility of the PGNN model, and, consequently, the accuracy of the identification. 
Hence, it would be of interest to develop a general nonlinear feedforward control framework for the identified model--based mapping $\hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}})$ which is capable to deal with nonlinear, nonminimum phase MIMO systems, state--space representations, and constraints on the inputs, outputs, or states. 



In what follows, we derive an explicit upperbound on the reference tracking performance for any feedforward control signal, which opens the path to such a generally applicable data--driven feedforward control design method. 





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FEEDFORWARD CONTROL--ORIENTED IDENTIFICATION}
\label{sec:IdentificationForControl}
To derive the bound on the tracking error, we define the inversion error as $R - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}})$ and the model error as $Y - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}})$. 
\begin{proposition}
\label{prop:UpperboundPerformance}
	Consider the mapping~\eqref{eq:System} and a corresponding parameterized model--based mapping~\eqref{eq:SystemModel}. 
	Then, for any $\theta$ and $U_{\textup{ff}}$, the norm of the corresponding tracking error is upperbounded by the sum of the norms of the inversion and model error, respectively, i.e.,
	\begin{equation}
	\label{eq:UpperboundTrackingErrorA}
		\| R - Y \| \leq \| R - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}}) \| + \| Y - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}}) \|.
	\end{equation}
\end{proposition}
\begin{proof}
	The proof follows by applying the triangle inequality, such that
	\begin{align}
	\begin{split}
	\label{eq:Proof1Step1}
		\| R - Y \| & = \| R - \hat{Y} + \hat{Y} - Y \| \\
		& \leq \| R - \hat{Y} \| + \| \hat{Y} - Y \| = \| R - \hat{Y} \| + \| Y - \hat{Y} \|. 
	\end{split}
	\end{align}
	Eq.~\eqref{eq:UpperboundTrackingErrorA} is obtained by substituting~\eqref{eq:SystemModel} in~\eqref{eq:Proof1Step1}. 
\end{proof}

Proposition~\ref{prop:UpperboundPerformance} states that the norm of the tracking error can be decreased by minimizing the norm of the inversion and the model error, respectively.
Computation of the model error requires~$Y$, which can only be generated on the system by applying $U_{\textup{ff}}$, which is yet unknown.
Therefore, we replace the model error by the identification error, i.e., 
\begin{equation}
\label{eq:IdentificationError}
	  Y^d - \hat{\Phi} ( \theta, x_0, R^d, U_{\textup{ff}}^d ) .
\end{equation}
The identification error~\eqref{eq:IdentificationError} can be made smaller by appropriately choosing $\theta$. 
Thereby, we obtain a two--step approach to design a data--driven nonlinear feedforward controller:
\begin{enumerate}
	\item \textbf{\emph{Identify}} the set of parameters $\theta = \hat{\theta}$ that minimizes the norm of the identification error, such that $\hat{\theta} = \textup{arg} \min_{\theta} \| Y^d - \hat{\Phi} ( \theta, x_0, R^d, U_{\textup{ff}}^d) \|$;
	\item \textbf{\emph{Compute}} the feedforward input $U_{\textup{ff}}$ that minimizes the norm of the inversion error for $\theta = \hat{\theta}$, such that $U_{\textup{ff}} = \textup{arg} \min_{U_{\textup{ff}}} \| R - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}} ) \|$. 
\end{enumerate}
Step $1)$ shows that the cost function~$V$ in~\eqref{eq:Identification} should be chosen as the norm of the \emph{closed--loop simulation error}. 

\begin{lemma}
\label{le:UpperboundPerformance}
	Consider the mapping~\eqref{eq:System} and the parameterized model--based mapping~\eqref{eq:SystemModel}, where $\hat{\theta}$ and $U_{\textup{ff}}$ are found by the two--step approach above. 
	Suppose that the $p$--norm is used, $p \in \mathbb{Z}_{>0}$, and define the data informativity measure
	\begin{equation}
	\label{eq:DataInformativity}
		\varepsilon := \frac{1}{N_k^{1/p}} \| Y - \hat{Y} \|_p - \frac{1}{N_d^{1/p}} \| Y^d - \hat{Y}^d \|_p.
	\end{equation}
	Then, the tracking error satisfies the following bound
	\begin{align}
	\begin{split}
	\label{eq:UpperboundTrackingErrorB}
		\frac{1}{N_k^{1/p}} \| R & - Y \|_p \leq \frac{1}{N_k^{1/p}} \| R - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}} ) \|_p \\
		&  + \frac{1}{N_d^{1/p}} \| Y^d - \hat{\Phi} (\hat{\theta}, x_0, R^d, U_{\textup{ff}}^d ) \|_p + \varepsilon. 
	\end{split}
	\end{align}
\end{lemma}
\begin{proof}
	Dividing both sides in~\eqref{eq:UpperboundTrackingErrorA} by $N_k^{1/p}$ and substituting~\eqref{eq:DataInformativity} yields~\eqref{eq:UpperboundTrackingErrorB}. 
\end{proof}

The division with $N_k^{1/p}$ normalizes the difference in length of $Y$ and $Y^d$, i.e., when $N_k \neq N_d$.
The parameter $\varepsilon$ in~\eqref{eq:DataInformativity} is a data informativity measure stating the relevance of the training data $\{Y^d, R^d, U_{\textup{ff}}^d\}$ with respect to the operation data $\{ Y, R, U_{\textup{ff}}\}$ for the identified set of parameters $\hat{\theta}$.
\begin{remark}
From the definition~\eqref{eq:DataInformativity} we have that $\varepsilon = 0$ when $\{ Y^d, R^d, U_{\textup{ff}}^d \} = \{ Y, R, U_{\textup{ff}} \}$. 
This hints to choosing $R^d$ and $U_{\textup{ff}}^d$ in the data generating experiment close to $R$ and $U_{\textup{ff}}$ to achieve a small $\varepsilon$, see also~\cite{Schoukens2019}. 
A reasonable choice is to have $R^d$ comprise of a set of target references, while $U_{\textup{ff}}^d$ is generated using a simple feedforward controller. 
Iterative identification using data generated with a new $U_{\textup{ff}}^d$ potentially decreases $\varepsilon$, see also~\cite{Hof1995} for iterative linear identification and feedback controller design.
\end{remark}

\begin{remark}
	In the (PG)NN--based feedforward control literature it is common to employ a regularization term in the cost function~\cite[Section 4]{Bolderman2023} and to use the squared $2$--norm due to its smoothness, such that
	\begin{equation}
	\label{eq:PGNNCostFunction}
		\hat{\theta} = \textup{arg} \min_{\theta} \| Y^d - \hat{\Phi} (\theta, x_0, R^d, U_{\textup{ff}}^d) \|_2^2 + \| \Lambda (\theta - \theta^* ) \|_2^2.
	\end{equation}
	In~\eqref{eq:PGNNCostFunction},~$\theta^*$ is a set of desired parameters, e.g., $0$ for $\theta_{\textup{NN}}$ and/or some known physical values for $\theta_{\textup{phy}}$, and $\Lambda \in \mathbb{R}^{n_{\theta} \times n_{\theta}}$ states the relative importance of $\theta - \theta^*$.
	Since the norm is non--negative and the square root is monotonically increasing, minimization of the norm and its square is equivalent (when neglecting the regularization term). 
	Hence,~\eqref{eq:PGNNCostFunction} is a suitable identification cost function when aiming to minimize the $2$--norm of the tracking error, i.e., $\| R - Y \|_2$. 
\end{remark}

\begin{remark}
	A similar derivation as presented in this section can be performed for a \emph{direct} closed--loop identification.
	This approach has the potential for consistent identification when noise is present in the data set, see, e.g.,~\cite{Bolderman2022c}.
\end{remark}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FINITE--HORIZON OPTIMAL FEEDFORWARD CONTROL}
\label{sec:FHOFC}
Based on Lemma~\ref{le:UpperboundPerformance} we fomulate the FHOFC problem as follows:
\begin{align}
\begin{split}
\label{eq:FHOFCP}
	U_{\textup{ff}}  = \textup{arg}& \min_{U_{\textup{ff}}} \| R - \hat{\Phi} ( \hat{\theta}, x_0, R, U_{\textup{ff}} ) \| + \| \Gamma U_{\textup{ff}} \|, \\
	\textup{subject to: }  U_{\textup{ff}} & \in \mathcal{R}_{U_{\textup{ff}}}, \; \hat{U} \in \mathcal{R}_U, \; \hat{Y} \in \mathcal{R}_Y, \; \hat{X} \in \mathcal{R}_X. 
\end{split}
\end{align}
In~\eqref{eq:FHOFCP}, $\| \Gamma U_{\textup{ff}} \|$ is a regularization term used to, e.g., penalize energy consumption or changes in the feedforward signal. 
Additionally, $\mathcal{R}_{U_{\textup{ff}}}$, $\mathcal{R}_U$, $\mathcal{R}_Y$ and $\mathcal{R}_X$ are the admissible sets of the feedforward and overall control inputs, outputs and states, respectively. 
Note that, $\hat{U}$, $\hat{Y}$ and $\hat{X}$ are used since $U$, $Y$ and $X$ are unknown when designing the feedforward signal. 
Since $\hat{U} \approx U$, $\hat{Y} \approx Y$ and $\hat{X} \approx X$, the constraints for the real trajectories may be violated. 
Still, this is an improvement to unconstrained feedforward control design.

\begin{remark}
	The FHOFC problem~\eqref{eq:FHOFCP} can be solved for \emph{any} reference and, therefore, is task flexible.
	Changes in the feedback controller are directly implementable in $\hat{\Phi}$. 
\end{remark}

It is worth to mention that solving~\eqref{eq:FHOFCP} becomes computationally expensive when $N_k$ is large. 
A constrained Gauss--Newton approach was proposed in~\cite{Volckaert2009} to solve the optimization by explicitly using the partial derivatives of the norm with respect to the feedforward inputs. 
Several other options to reduce the computational complexity are:
\begin{enumerate}
	\item {\emph{Parameterize the feedforward signal}} using basis functions~\cite{Ramani2017, Kasemsinsup2017}. Essentially, choose $U_{\textup{ff}} = \sum_{i=1}^{N_{\textup{bf}}} c_i \Psi_i$ with $c_i$ the coefficients, $\Psi_i$ the basis functions, $N_{\textup{bf}} << N_k$, and optimize over $c = [c_1, ..., c_{N_{\textup{bf}}}]^T$. 
	\item {\emph{Parameterize an inverse model}} as $U_{\textup{ff}} = \hat{\Phi}_{\textup{inv}} (\theta_{\textup{inv}}, R)$ and find $\hat{\theta}_{\textup{inv}}$ by minimizing~\eqref{eq:FHOFCP}. 
	\item {\emph{Solve the FHOFC problem in a receding horizon}} manner, i.e., let $\bar{u}_{\textup{ff}}(k) = [u_{\textup{ff}}^T(k), ..., u_{\textup{ff}}^T(k+h)]^T$, with $h \in \mathbb{Z}_{>0}$ the prediction horizon and solve
	\begin{align}
	\begin{split}
	\label{eq:FHOFCPRecedingHorizon}
		\bar{u}_{\textup{ff}}(k) &= \textup{arg} \min_{\bar{u}_{\textup{ff}}(k)} \| \bar{r}(k) - \hat{\bar{y}}(k) \| + \| \Gamma \bar{u}_{\textup{ff}}(k) \|, \\
		u_{\textup{ff}}(k) & = [I, 0, ..., 0] \bar{u}_{\textup{ff}}(k). 
	\end{split}
	\end{align}
\end{enumerate}


Next we show that the FHOFC design procedure for nonlinear systems can recover some of the state--of--the--art methods for feedforward control, namely: inverse model--based feedforward and linear ILC. 
To show the former, let the system model admit an input--output representation~\eqref{eq:SystemModelInputOutput}, and suppose that a unique inverse relation is known, such that, with a slight abuse of notation, we have
\begin{align}
\begin{split}
\label{eq:InverseModelPGNN}
	\hat{u}(k) = f^{-1}\big( \theta, [& \hat{y}^T(k+n_k+1), ..., \hat{y}^T(k+n_k-n_a+1), \\
	& \hat{u}^T(k-1), ..., \hat{u}^T(k-n_b+1)]^T \big).
\end{split}
\end{align}

\begin{lemma}
\label{le:InversionBasedFeedforward}
	Consider the feedforward control design using an identified input--output model~\eqref{eq:SystemModelInputOutput} for which the inverse relation~\eqref{eq:InverseModelPGNN} is unique. % is known as~\eqref{eq:InverseModelPGNN}. 
	Suppose that the initial conditions are such that $y(i) = r(i)$ for $i \in \{ n_k-n_a+1, ..., n_k \}$. 
	Then, the inverse model--based feedforward controller 
	\begin{align}
	\begin{split}
	\label{eq:InversionBasedFeedforward}
		u_{\textup{ff}}(k) = f^{-1} \big( \hat{\theta}, [& r^T(k+n_k+1), ..., r^T(k+n_k-n_a+1), \\
		& u_{\textup{ff}}^T(k-1), ..., u_{\textup{ff}}^T(k-n_b+1)]^T \big)
	\end{split}
	\end{align}
	solves the unconstrained receding horizon FHOFCP~\eqref{eq:FHOFCPRecedingHorizon} with $\Gamma = 0$ and $h = n_k+1$. 
\end{lemma}
\begin{proof}
	$u_{\textup{ff}}(k)$ appears first in the predicted output $\hat{y}(k+n_k+1)$, such that $u_{\textup{ff}}(k+i)$, $i \in \mathbb{Z}_{>0}$ does not play a role in the cost function when $\Gamma = 0$. 
	Hence, the receding horizon FHOFC~\eqref{eq:FHOFCPRecedingHorizon} with no constraints becomes
	\begin{equation}
	\label{eq:Proof3Step1}
		u_{\textup{ff}}(k) = \textup{arg} \min_{u_{\textup{ff}}(k)} \| r(k+n_k+1) - \hat{y} (k + n_k+1) \|. 
	\end{equation}
	Since the minimum is attained for $r(k+n_k+1) = \hat{y}(k+n_k+1)$, the solution of~\eqref{eq:Proof3Step1} equals~\eqref{eq:InversionBasedFeedforward} when~\eqref{eq:Proof3Step1} is solved sequentially, i.e., for $k = 0, 1, ..., N_k$. 
	Observing that, from~\eqref{eq:OpenClosedLoop}, $u_{\textup{fb}}(k) = 0$ for $r(i) - \hat{y}(i) = 0$, $i \in \{ 0, ..., k \}$, such that $\hat{u}(k) = u_{\textup{ff}}(k)$ completes the proof. 
\end{proof}
\begin{remark}
	In general, obtaining an analytical inverse relation as in~\eqref{eq:InverseModelPGNN} is not possible or tractable, e.g., when the system model~\eqref{eq:SystemModelInputOutput} is parametrized as a black--box NN. 
	In these cases, $u_{\textup{ff}}(k)$ can be found by minimizing~\eqref{eq:Proof3Step1} using a numerical solver, as in~\cite{Bolderman2022c}.
\end{remark}

Even when the identification in~\eqref{eq:PGNNCostFunction} and the FHOFC problem~\eqref{eq:FHOFCP} are solved accurately, it is still possible that the tracking error remains too large due to the presence of $\varepsilon$ in~\eqref{eq:UpperboundTrackingErrorB}. 
Options to generate new data and thereby achieve a smaller $\varepsilon$ were indicated in Sec.~\ref{sec:IdentificationForControl}. 
Alternatively, it is possible to use an iterative learning scheme when the same reference is executed repetitively, as done in ILC~\cite{Bristow2006}. 



Next, we present an iterative learning FHOFC (IL--FHOFC) scheme for nonlinear systems, inspired by ILC:
\begin{align}
\begin{split}
\label{eq:NonlinearILCEquivalent}
	R^{(i+1)} & = \hat{Y}^{(i)} + \alpha E^{(i)}, \\
	U_{\textup{ff}}^{(i+1)} & = \textup{arg} \min_{U_{\textup{ff}}} \big\| R^{(i+1)} - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}}) \big\| + \| \Gamma u_{\textup{ff}} \|,
\end{split}
\end{align}
where the superscript $(i)$ denotes the iteration index for signals, $i \in \mathbb{Z}_{>0}$, and $E := [e^T(0), ..., e^T(N_k-1)]^T$. 
The following result shows that~\eqref{eq:NonlinearILCEquivalent} recovers the standard ILC solution in the linear case.

\begin{lemma}
\label{le:FHOFCILCEquivalence}
	Suppose that $G$ is the transfer function matrix of a linear system, $C$ is a feedback controller, and $\hat{G}$ is a model of $G$, with all transfer functions represented in the digital domain. 
	Let $\hat{\Phi}$ be the closed--loop model--based mapping obtained from $C$ and $\hat{G}$, and let $\alpha \in (0, 1]$ be a learning gain. 
	Then, the ILC update law
	\begin{equation}
	\label{eq:LinearILCInput}
	u_{\textup{ff}}^{(i+1)}(k) = u_{\textup{ff}}^{(i)}(k) + \alpha \hat{G}^{-1} (1+\hat{G}C) e^{(i)}(k),
	\end{equation}
	solves the IL--FHOFC problem~\eqref{eq:NonlinearILCEquivalent} with $\Gamma = 0$. 
\end{lemma}
\begin{proof}
	The output predicted by $\hat{G}$ at iteration $i$ is 
	\begin{equation}
	\label{eq:LinearClosedLoop}
		\hat{y}^{(i)}(k) = (1+\hat{G}C)^{-1}\hat{G}Cr(k) + (1+\hat{G}C)^{-1}\hat{G}u_{\textup{ff}}^{(i)}(k).
	\end{equation}
	Substituting the ILC update law~\eqref{eq:LinearILCInput} in~\eqref{eq:LinearClosedLoop} gives
	\begin{align}
	\begin{split}
	\label{eq:Proof4Step1}
		\hat{y}^{(i+1)}(k) = \hat{y}^{(i)}(k) + \alpha e^{(i)}(k). 
	\end{split}
	\end{align}
	Placing the time entries of~\eqref{eq:Proof4Step1} in a column, shows that
	\begin{align}
	\begin{split}
	\label{eq:Proof4Step2}
		& \| R^{(i+1)} - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}}^{(i+1)} ) \| \\
		& \quad \quad \quad = \| R^{(i+1)} - \hat{Y}^{(i)} - \alpha E^{(i)} \| = 0.	
	\end{split}
	\end{align}
	Non--negativeness of the norm implies that~\eqref{eq:LinearILCInput} is a global optimum of~\eqref{eq:NonlinearILCEquivalent} when $\Gamma = 0$. 
\end{proof}


\begin{remark}
	An alternative approach is to re--identify $\theta$ based on new data, and compute $U_{\textup{ff}}^{(i+1)}$ by using the FHOFC~\eqref{eq:FHOFCP}, see~\cite{Volckaert2013}. 
\end{remark}


\begin{remark}
	The update of $R^{(i)}$ in~\eqref{eq:NonlinearILCEquivalent} is based on $\hat{Y}^{(i-1)}$ since the optimization does not necessarily yield $R^{(i)} = \hat{Y}^{(i)}$. 
\end{remark}





\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=0.85\linewidth]{Figures/Figure_NonMinimumPhaseExample.pdf}
\caption{Rotating--translating mass with actuation and sensing on opposite sides of the centre of mass.}
\label{fig:NonminimumPhaseExample}
\end{figure}
\begin{table}
\caption{Parameter values of the system displayed in Fig.~\ref{fig:NonminimumPhaseExample}.}
\label{tab:ParameterValues}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
$m$ & $l_x, l_y$ & $J$ & $f_v$ & $k$ & $d$ & $l_m$ & $c$ \\ \hline \hline
$20$ & $1$  & $\frac{40}{3}$  & $50$  & $\frac{25 \cdot 10^{3}}{3}$  & $\frac{575}{3}$ & $0.05$ & $1$ \\ \hline
$kg$ & $m$ & $kgm^2$ & $\frac{kg}{s}$ & $\frac{kg}{s^2}$ & $\frac{kg}{s}$ & $m$ & $N$ \\ \hline
\end{tabular}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{VALIDATION ON A NONMINIMUM PHASE NONLINEAR MECHATRONIC EXAMPLE}
\label{sec:Results}
\emph{\textbf{System description:}} We consider the position control of a translating--rotating mass with force input $u$ and position output $y$ at opposite sides of the centre of mass, see Fig.~\ref{fig:ClosedLoopSystem} and~\cite{Bolderman2023}. 
The continuous--time dynamics is given as
\begin{align}
\begin{split}
\label{eq:SimulationModel}
	& J m \frac{d^4 y}{dt^4} + (f_v J + 2 l_x d m) \frac{d^3 y}{dt^3} \\
	& + 2(l_x d f_v + l_x k m) \frac{d^2 y}{dt^2} + 2 l_x k f_v \frac{dy}{dt} \\
	& = (J - l_y^2 m ) \frac{d^2 \xi }{dt^2} + (2l_x d - l_y^2 f_v)\frac{d \xi }{dt} + 2 l_x k \xi. 
\end{split}
\end{align}
In~\eqref{eq:SimulationModel}, $l_x, l_y \in \mathbb{R}_{\geq 0}$ are the width and height of the mass $m \in \mathbb{R}_{>0}$, $J = \frac{1}{3} (l_x^2 + l_y^2)$ is the moment of inertia, $f_v \in \mathbb{R}_{>0}$ the viscous friction coefficient, and $d, k \in \mathbb{R}_{>0}$ the damping and spring constant counteracting the rotation from both ends of the mass.
The auxiliary input $\xi$ is given as
\begin{equation}
\label{eq:SimulationModelAuxiliaryInput}
	\xi := u - c \sin \big( \frac{2 \pi}{l_m} y \big),
\end{equation}
where $u$ is the input, and the $\sin$--function represents the cogging force which is assumed \emph{unknown} with $l_m \in \mathbb{R}_{>0}$ the magnet pole pitch and $c \in \mathbb{R}_{>0}$ the cogging magnitude.
Parameter values are listed in Table~\ref{tab:ParameterValues}.
The system~\eqref{eq:SimulationModel} is controlled in closed--loop at a frequency $F_s = 100$ $Hz$ by the ZOH discretization of
\begin{equation}
\label{eq:SimulationModelFeedback}
	C(s) = 5\cdot 10^{3} \frac{s+4\pi}{s+20 \pi}.
\end{equation}
A normally distributed noise $v(k) \sim \mathcal{N} \big( 0, (10^{-6})^2 \big)$ $m$ is added as \emph{measurement noise}, such that both the data set and the feedback controller use $y(k) + v(k)$ rather than $y(k)$. 

The system~\eqref{eq:SimulationModel} exhibits the following challenges for feedforward control:
\begin{enumerate}
	\item \emph{Nonlinear dynamics} in the form of a cogging force, which is assumed unknown;
	\item \emph{Nonminimum phase dynamics} which require non--causal actuation to return a stable feedforward signal.
\end{enumerate}

\emph{\textbf{Data generation:}} The training data is generated in closed--loop by sampling the output $y^d(k)$ at the frequency $F_s$ for a duration of $45$ $s$. 
The reference $R^d$ is a concatenation of $15$ times the third order reference $R$ in Fig.~\ref{fig:Reference}, which has bounded velocity $| \frac{d}{dt} r^d | \leq 0.1$ $\frac{m}{s}$, acceleration $| \frac{d^2}{dt^2} r^d | \leq 4$ $\frac{m}{s^2}$ and jerk $|\frac{d^3}{dt^3} r^d | \leq 40$ $\frac{m}{s^3}$. 
Additionally, $U_{\textup{ff}}^d$ is a zero--mean white noise with variance $\sigma^2 = 20^2$ $N^2$ for $t = [10, 40)$ $s$. 


\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/Reference.pdf}
\caption{Reference $R$ used for performance evaluation.}
\label{fig:Reference}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=1.0\linewidth]{Figures/Norms_IdentificationInversionTrackingError_V10_LeftRight.pdf}
\caption{Normalized $2$--norm of the identification ($Y^d - \hat{Y}^d$, $N = N_d$), inversion ($R - \hat{Y}$, $N=N_k$) and tracking ($R-Y$, $N = N_k$) error for PGNNs with different number of neurons using $\gamma = 10^{-6}$ (left window) and $\gamma = 5 \cdot 10^{-5}$ (right window).}
\label{fig:TrackingErrorsNeurons}
\end{figure}


\emph{\textbf{Model parameterization:}} We parameterize the system with an input--output PGNN model~\eqref{eq:PGNN} as proposed in~\cite{Bolderman2021}, with a \emph{linear physical model} and a \emph{black--box NN} with one hidden layer with $n_1$ neurons using $\tanh$ activation, i.e.,
\begin{equation}
\label{eq:SimulationPGNN}
	\hat{y}(k) = \theta_{\textup{phy}}^T \phi(k) + W_2 \tanh \big( W_1 \phi(k) + B_1 \big) + B_2.
\end{equation}
In~\eqref{eq:SimulationPGNN},~$\theta_{\textup{NN}} = [\textup{col}(W_1)^T, B_1^T, \textup{col}(W_2)^T, B_2^T]^T$, where $\textup{col}(W_i)$ stacks the columns of $W_i$. 
ZOH discretization of the linear part of~\eqref{eq:SimulationModel} gives $n_a = n_b = 4$, $n_k = 0$ in~$\phi(k)$. 

\emph{\textbf{System identification:}} The PGNN parameters are identified according to~\eqref{eq:PGNNCostFunction} (using the \emph{lsqnonlin} MATLAB function) with $\Lambda = [I , 0]$, $\theta^* = [{\theta_{\textup{phy}}^*}^T, 0]^T$, and $\theta_{\textup{phy}}^*$ the parameters identified with the physical model.

\emph{\textbf{Feedforward:}} The feedforward signals $U_{\textup{ff}}$ have length $N_k = 300$ and are computed by solving the FHOFC~\eqref{eq:FHOFCP} while penalizing the rate of change in $U_{\textup{ff}}$ by choosing
\begin{equation}
\label{eq:RegularizationR}
	\Gamma = \gamma \Delta,
\end{equation}
where $\gamma \in \mathbb{R}_{\geq 0}$ states the importance of the regularization and $\Delta \in \mathbb{R}^{N_k \times N_k}$ has $1$ on the diagonal, $-1$ on the subdiagonal and $0$ elsewhere.
Solving the FHOFC~\eqref{eq:FHOFCP} converges in $7$ $s$ with \emph{lsqnonlin} on a $2.59$ $GHz$ Intel Core--I7--9750H using MATLAB 2019A.

\emph{\textbf{Results:}} Fig.~\ref{fig:TrackingErrorsNeurons} visualizes the $2$--norm of the identification, inversion and tracking error in~\eqref{eq:UpperboundTrackingErrorB} for the reference $R$ in Fig.~\ref{fig:Reference} using different number of neurons $n_1$, with $\gamma = 10^{-6}$ (top window) and $\gamma = 5\cdot 10^{-5}$ (bottom window). 
Due to the nonlinearity present in the system~\eqref{eq:SimulationModel}, the identification error becomes smaller when increasing the number of neurons $n_1$. 
For $\gamma = 10^{-6}$ the inversion error is small, such that the tracking error is limited by the accuracy of the identification.
In contrast, for $\gamma = 5 \cdot 10^{-5}$ the inversion error increases, which limits the achievable performance for $n_i > 20$. 
Comparing the upperbound~\eqref{eq:UpperboundTrackingErrorB} with the results in Fig.~\ref{fig:TrackingErrorsNeurons} indicates that $\varepsilon$ is small.
Correspondingly, Lemma~\ref{le:UpperboundPerformance} can be used to aim for a desired reference tracking performance a priori by performing the identification and inversion sufficiently accurate.



Fig.~\ref{fig:ILCImprovements} shows the $2$--norm of the tracking error for a linear and a PGNN model over multiple iterations of the reference $R$ in Fig.~\ref{fig:Reference} when using the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} with $\alpha = 1$ and $\gamma = 10^{-8}$. 
Since both approaches reach the noise--floor, results are added where $v(k) = 0$ to emphasize the benefit of the nonlinear PGNN model structure.
The tracking error converges both faster, and to a lower value when using the PGNN model.
After $6$ repetitions the normalized $2$--norm of the tracking error with $v(k) = 0$ is $4.96 \cdot 10^{-9}$~$m$ for the PGNN and $1.14 \cdot 10^{-8}$~$m$ for the linear model, respectively. 

\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/ILC_Improvements_V10_LeftRight.pdf}
\caption{Normalized $2$--norm of the tracking error over the iterations using IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} with $\alpha = 1$ and $\gamma = 10^{-8}$ using a linear and a PGNN~\eqref{eq:SimulationPGNN} model with $n_1 = 32$, simulated with $v(k) \sim \mathcal{N} \big( 0, (10^{-6})^2 \big)$ (left window) and with $v(k) = 0$ (right window).}
\label{fig:ILCImprovements}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}
\label{sec:Conclusions}
In this paper, we presented a generalized approach to nonlinear data--driven feedforward control design from the perspective of minimizing tracking errors.
We showed that the norm of the reference tracking error is upperbounded by the sum of the inversion and the identification error, respectively. 
This resulted in a two--step approach to feedforward control design, consisting of a feedforward control--oriented system identification followed by a finite--horizon optimization to compute the feedforward input signal.
Generality of the FHOFC formulation was demonstrated by recovering inverse model--based feedforward and linear ILC for specific settings.
The developed methodology was validated using physics--guided neural networks on a nonlinear, nonminimum phase mechatronic example, where it outperformed a standard ILC method.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\addtolength{\textheight}{-0.22cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%\section*{APPENDIX}
%Appendixes should appear before the acknowledgment.







\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,References}




\end{document}
