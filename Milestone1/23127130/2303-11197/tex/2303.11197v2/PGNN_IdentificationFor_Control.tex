%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphicx}
\usepackage{xcolor}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{assumption}{Assumption}[section]


\title{\LARGE \bf
Data--driven feedforward control design for nonlinear systems: \\
A control--oriented system identification approach*
}


\author{Max Bolderman$^{\dagger, 1}$, Mircea Lazar$^1$, and Hans Butler$^{1,2}$% <-this % stops a space
\thanks{*This work is supported by the NWO research project PGN Mechatronics, project number 17973.}% <-this % stops a space
\thanks{$^{\dagger}$Corresponding author: {\tt\small m.bolderman@tue.nl}.}% <- this % stops a space
\thanks{$^{1}$Control Systems Group, Eindhoven University of Technology, Groene Loper 19, Eindhoven, 5612 AP, The Netherlands.}%
\thanks{$^{2}$ASML, De Run 6501, Veldhoven, 5504 DR, The Netherlands.}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
%Feedforward control is crucial for achieving high reference tracking performance within mechatronic systems.
%High--performance feedforward controllers typically require a rich model structure to accurately identify the system dynamics from data. %, e.g., physics--guided neural networks (PGNNs). 
%Feedforward control is a key control technique for precision motion control.
Feedforward controllers typically rely on accurately identified inverse models of the system dynamics to achieve high reference tracking performance.
However, the impact of the (inverse) model identification error on the resulting tracking error is only analyzed a posteriori in experiments.
%However, a quantitative relation between the identification error and the resulting tracking error is not established.
%Therefore, in this work, we develop an approach to feedforward control design, which aims at minimizing the tracking error a priori.
Therefore, in this work, we develop an approach to feedforward control design that aims at minimizing the tracking error a priori. 
%Therefore, in this work, we develop a data--driven nonlinear feedforward control approach. % from the perspective of minimizing the tracking error.
%High--performance feedforward controllers are obtained from flexible model structures, such as neural networks (NNs) or physics--guided neural networks (PGNNs), which are used to learn the inverse system dynamics accurately from data. 
%Since the inverse identification does not relate to the reference tracking objective, in this work, we develop a data--driven nonlinear feedforward control approach from the perspective of minimizing tracking error.
To achieve this, we present a model of the system in a lifted space of trajectories, based on which we derive an upperbound on the reference tracking performance.
Minimization of this bound yields a feedforward control--oriented system identification cost function, and a finite--horizon optimization to compute the feedforward control signal.
%To achieve this, we show that the norm of the tracking error can be upperbounded by the sum of the inversion error and the identification error.
%This yields a two--step feedforward control design procedure that consists of a feedforward control--oriented system identification, and a finite--horizon optimization to compute the feedforward control signal. 
%To achieve this, we derive an upperbound on the norm of the tracking error, based on which a two--step feedforward control design procedure is developed which consists of a feedforward control--oriented system identification, and a finite--horizon optimization to compute the feedforward control signal. 
%An upperbound on the norm of the tracking error is derived, based on which a two--step feedforward control design procedure is developed which consists of a feedforward control--oriented system identification, and a finite--horizon optimization to compute the feedforward control signal.
%By deriving an upperbound on the norm of the tracking error, we obtain a two--step feedforward control design procedure consisting of a feedforward control--oriented system identification, and a finite--horizon optimal feedforward control input computation.
The nonlinear feedforward control design method is validated using physics--guided neural networks on a nonlinear, nonminimum phase mechatronic example, where it outperforms linear ILC.%, where it demonstrates significant improvements with respect to a conventional, linear feedforward controller.
%The effectiveness of the nonlinear feedforward control design method is illustrated on a benchmark nonlinear, nonminimum phase mechatronic system example. 
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
\label{sec:Introduction}
Feedforward control is a dominant actor in achieving high reference tracking performance, and typically relies on linear, physics--based models~\cite{Boerlage2003, Devasia2002}.
Linear models have good extrapolation properties, but limited accuracy. 
As such, it would be desirable to employ rich, nonlinear models for feedforward control that can learn the complete system dynamics from data~\cite{Bolderman2023}. 
%This, however, brings (new) challenges to feedforward control design, which are briefly discussed next.

A common approach to feedforward control design is inverse model--based feedforward, which generates the feedforward signal by passing the reference through a model of the inverse system dynamics, see, e.g.,~\cite{Boerlage2003, Butterworth2012}. 
When the model of the system is nonminimum phase, i.e., it has an unstable inverse, different methods are available to generate a stable feedforward controller, see, e.g.,~\cite{Butterworth2012, Zundert2018}.
These methods however, are not directly extendable to nonlinear feedforward controllers.
%These stable inversion methods do not directly translate to the design of nonlinear feedforward controllers.
Hence, a different approach is to formulate feedforward control as an optimization problem, where the goal is to minimize the norm of the difference between the reference and the model output. 
Within this category, it is possible to optimize the complete feedforward signal~\cite{Volckaert2009, Carrasco2011}, or to parameterize the feedforward signal as a function of time or the reference and optimize over the parameters~\cite{Ramani2017, Kasemsinsup2017}. 
%When the system performs a repetitive task, an iterative learning control (ILC) method can be used to minimize the tracking error by updating the feedforward input~\cite{Bristow2006} or the parameters of an inverse model~\cite{Blanken2017} based on the tracking error of previous repetitions.
When the system performs a repetitive task, an iterative learning control (ILC) method can be used to minimize the tracking error based on the tracking error of previous repetitions by updating the feedforward input~\cite{Bristow2006}, the parameters of an inverse model~\cite{Blanken2017}, or both~\cite{Saltik2022}. 
%iterative learning control (ILC) improves performance further by updating the feedforward input~\cite{Bristow2006} or the parameters of an inverse model~\cite{Blanken2017} based on the tracking error of previous repetitions. 
%In~\cite{Graichen2005} the feedforward control problem for nonlinear systems is formulated as a two--point boundary value problem.

The aforementioned methods typically assume a known, physics--based model of the system.
To account for unknown dynamics, data--driven techniques have been explored in combination with artificial intelligence, e.g., neural network (NN) models~\cite{Sorensen1999}, physics--informed neural networks and physics--guided neural network (PGNN) models~\cite{Bolderman2021}, other hybrid model structures~\cite{Chou2023}, or Gaussian processes~\cite{Jilles2022}. 
%However, with the increasing demands on precision, obtaining an accurate model that includes the unknown dynamics, becomes as important as the feedforward controller design itself.
%Since the unknown dynamics are difficult, if not impossible to model based on first--principle models, data--driven techniques have been explored using, e.g., neural network (NN) models~\cite{Sorensen1999}, or physics--guided neural network (PGNN) models~\cite{Bolderman2021} and other hybrid model structures~\cite{Chou2023}. 

When performing the identification, i.e., fit the model to the data, the identification cost function should be relevant for the intended use of the model~\cite{Hof1995, Schoukens2019}. %, see, e.g.,~\cite{Hof1995} for linear identification for feedback controller design.
Therefore, when identifying a model for feedforward control, the identification cost function should push model errors in a region where these errors least affect the tracking performance.
%the model errors, which are inevitable when identifying any real--life system, should be located to where these least affect the reference tracking objective.
%Consequently, we aim to establish a quantitative link between the reference tracking performance and the identification error. 
This is not achieved when performing an identification of the inverse dynamics directly, which is generally adopted in nonlinear (including PGNN) feedforward control due to the non--invertibility of nonlinear models in general, see, e.g.,~\cite{Bolderman2023, Bolderman2021, Kon2022}. 
%Such a link is not obtained when performing an identification of the inverse dynamics directly, which is generally adopted in (PG)NN feedforward control due non--invertible model structure, see, e.g.,~\cite{Bolderman2021, Bolderman2023, Kon2022}. }
In~\cite{Aarnoudse2021}, a control--relevant identification cost function, which filters the inverse model error with a linear model of the process sensitivity, was proposed to mitigate this issue. 
Alternatively, in~\cite{Bolderman2022c}, the authors proposed an inversion method for (PG)NNs which opens up the path to perform the identification of the forward dynamics, but did not yet achieve a quantitative relation between the tracking error and the identification error.
Such a quantitative relation is desired to have a relevant identification cost function for the feedforward control objective. 
%However, to the best of the authors' knowledge, a framework for feedforward control design for nonlinear systems that \emph{quantifies} the relation between the identification error and the tracking error is not yet available.

Motivated by the above observations, in this paper, we establish a quantitative link between the tracking error and the identification error. 
The main contributions of this paper are as follows:
\begin{enumerate}
	\item A lifted formulation of the nonlinear feedforward control problem in the space of finite--length trajectories, which enables the derivation of an explicit upperbound on the norm of the tracking error;
	%We present the closed--loop system and model in a lifted space of trajectories, based on which we derive a novel upperbound on the norm of the tracking error;
	\item A feedforward control--oriented identification cost function, which minimizes the upperbound on the tracking error, and hence, it minimizes the tracking error itself a priori, during the design stage;
	%We present a feedforward control--oriented identification cost function, which minimizes the upperbound;
	\item A finite--horizon optimal feedforward control (FHOFC) formulation for a general class of nonlinear, possibly nonminimum phase MIMO systems which allows for specifying input, output, and state constraints.
\end{enumerate}
The developed FHOFC problem can be solved iteratively, yielding an iterative learning scheme for nonlinear systems. 
We prove that this iterative learning FHOFC recovers linear ILC~\cite{Bristow2006}, which is another contribution of this work.

%By rewriting the closed--loop system and model in a lifted form, we derive a fundamental upperbound on the norm of the tracking error in terms of the norm of the identification error, i.e., how well is the system identified, and the inversion error, i.e., how well is the feedforward control input designed for the identified model. 
%Therefore, the main contribution of this paper is the formulation of the feedforward control synthesis problem for nonlinear systems as a finite--horizon optimal feedforward control (FHOFC) problem in a lifted space of trajectories. 
%Moreover, a feedforward control--oriented cost function is derived, which explicitly links the tracking error with the identification, i.e., how well does the model explain the data, and inversion error, i.e., how well is the feedforward control input designed for the identified model.
%The developed FHOFC problem can be solved iteratively, yielding an iterative learning feedforward control method for nonlinear systems. We prove that, when solved iteratively, the developed FHOFC recovers linear ILC~\cite{Bristow2006}, which is another contribution of this work. 
	







\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/Overview_ControlStructure.pdf}
\caption{Schematic overview of the control structure.}
\label{fig:ClosedLoopSystem}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PRELIMINARIES}
\label{sec:Preliminaries}
\subsection{Notation}
We denote $y(k) \in \mathbb{R}^{n_y}$ as the output at time $k \in \mathbb{N}_{>0}$, $r(k) \in \mathbb{R}^{n_y}$ is the reference, $e(k) := r(k)-y(k)$ the tracking error and $n_y \in \mathbb{Z}_{>0}$ the number of outputs.
The input $u(k) \in \mathbb{R}^{n_u}$ is the sum of the feedback and the feedforward input, such that $u(k) := u_{\textup{fb}}(k) + u_{\textup{ff}}(k)$ with $n_u \in \mathbb{Z}_{>0}$ the number of inputs. 
The state of a system is denoted as $x(k) \in \mathbb{R}^{n_x}$ with $n_x \in \mathbb{Z}_{>0}$ the state dimension.
A signal of length $N_k \in \mathbb{Z}_{>0}$ is denoted by its capital letter, e.g., $R := [r(1)^T, ..., r(N_k)^T]^T$ is the reference signal and $E := [e(1)^T, ..., e(N_k)^T]^T$ is the error signal.
The superscript $d$ is used to indicate that a signal is from the data set, e.g., $U_{\textup{ff}}^d = [u_{\textup{ff}}^d(1)^T, ..., u_{\textup{ff}}^d(N_d)^T]^T$ is the feedforward input measured during the data generating experiment of length $N_d \in \mathbb{Z}_{>0}$. 
Let a hat denote a prediction of a model, e.g., $\hat{Y} := [\hat{y}(1)^T, ..., \hat{y}(N_k)^T]^T $ is a prediction of the output $Y$ and $\hat{Y}^d := [\hat{y}^d(1)^T, ..., \hat{y}^d(N_d)^T]^T$ a prediction of $Y^d$. 
A model is parametrized by the parameters $\theta \in \mathbb{R}^{n_{\theta}}$, $n_{\theta} \in \mathbb{Z}_{>0}$, and $\hat{\theta}$ denotes the identified parameters. 

\subsection{System dynamics and model--based feedforward}
We consider the feedforward control design for a system~$G$ operating in closed--loop with feedback controller $C$ as visualized in Fig.~\ref{fig:ClosedLoopSystem}. 
The closed--loop system dynamics is (partly) unknown, which is the case in real--life systems, e.g., for a linear motor, one has to deal with parasitic effects, such as nonlinear friction and electromagnetic distortions. The closed--loop system dynamics is denoted as $\phi$, such that
\begin{align}
\begin{split}
\label{eq:SystemDynamics}
	\phi : \begin{cases} x(k+1) & = f \big( x(k), u(k) \big), \\
	y(k) & = g \big( x(k) \big), \\
	u(k) & = C(q) \big( r(k) - y(k) \big) + u_{\textup{ff}}(k). 
	\end{cases}
\end{split}
\end{align}
In~\eqref{eq:SystemDynamics}, $f : \mathbb{R}^{n_x} \times \mathbb{R}^{n_u} \rightarrow \mathbb{R}^{n_x}$ describes the unknown system dynamics, with $g : \mathbb{R}^{n_x} \rightarrow \mathbb{R}^{n_y}$ the unknown output equation. 
The feedback controller is assumed to be linear, such that $u_{\textup{fb}}(k) = C(q) \big( r(k) - y(k) \big)$ with $C(q)$ the discrete--time transfer function of the feedback controller, and $q$ the forward shift operator. 


An input--output data set is generated by exciting the system via the reference $r(k)$ and the feedforward input $u_{\textup{ff}}(k)$, such that we obtain $Y^d = [y^d(1)^T, ..., y^d(N_d)^T]^T$, $R^d = [r^d(1)^T, ..., r^d(N_d)^T]^T$, and $U_{\textup{ff}}^d = [u_{\textup{ff}}^d(1)^T, ..., u_{\textup{ff}}^d(N_d)^T]^T$ that satisfies~\eqref{eq:SystemDynamics} for $k = 1, ..., N_d$. 


The optimal feedforward input $u_{\textup{ff}}(k)$ yields $y(k) = r(k)$ for all $k$ when supplied to the system~\eqref{eq:SystemDynamics}.
However, since $f$ and $g$ in~\eqref{eq:SystemDynamics} are unknown, it is common practice to parameterize a model $\hat{\phi}$ of the system $\phi$ in~\eqref{eq:SystemDynamics}, such that
\begin{align}
\begin{split}
\label{eq:ModelDynamics}
	\hat{\phi} : \begin{cases} \hat{x}(k+1) & = \hat{f} \big( \theta, \hat{x}(k), \hat{u}(k) \big), \\
	\hat{y}(k) & = \hat{g} \big( \theta, \hat{x}(k) \big), \\
	\hat{u}(k) & = C(q) \big( r(k) - \hat{y}(k) \big) + u_{\textup{ff}}(k). 
	\end{cases}
\end{split}
\end{align}
where $\hat{f}$ and $\hat{g}$ are a model of $f$ and $g$ in~\eqref{eq:SystemDynamics}, respectively, and $\theta \in \mathbb{R}^{n_{\theta}}$ are the free parameters. 


The state--space model in~\eqref{eq:ModelDynamics} reduces to the input--output representation used in, e.g.,~\cite{Bolderman2021, Aarnoudse2021} by choosing the state as past inputs and outputs, i.e.,
\begin{align}
\begin{split}
\label{eq:ModelDynamicsInputOutput}
	\hat{y}(k+1) & = \hat{f} \big( \theta, [\hat{y}(k)^T, ..., \hat{y}(k-n_a+1)^T,\\
	& \quad \quad  \hat{u}(k-n_k)^T, ..., \hat{u}(k-n_k-n_b)^T]^T \big), \\
	\hat{u}(k) & = C(q) \big( r(k) - \hat{y}(k) \big) + u_{\textup{ff}}(k),
\end{split}
\end{align}
where $n_a, n_b, n_k \in \mathbb{Z}_{>0}$ denote the order of the dynamics. 
Suppose that there exists an inverse relation $\hat{f}^{-1}$ of $\hat{f}$ in~\eqref{eq:ModelDynamicsInputOutput}, such that, with a slight abuse of notation, we have
\begin{align}
\begin{split}
\label{eq:ModelDynamicsFeedforward}
	\hat{u}(k) & = \hat{f}^{-1} \big( \theta, [\hat{y}(k+n_k+1)^T, ..., \hat{y}(k+n_k-n_a+1)^T, \\
	& \quad \quad \hat{u}(k-1)^T, ..., \hat{u}(k-n_b+1)^T]^T \big).
\end{split}
\end{align}
Then, the inverse model--based feedforward controller is obtained by substitution of $\hat{y}(i) = r(i)$, $i = k+n_k-n_a+1, ..., k+n_k+1$, and $\hat{u}(i) = u_{\textup{ff}}(i)$, $i = k-n_b+1, ..., k$. 










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}
\label{sec:ProblemStatement}
Since the dynamics~$f$ in~\eqref{eq:SystemDynamics} is unknown, the feedforward control design is based on a model~$\hat{f}$ as in~\eqref{eq:ModelDynamics}. 
This typically yields a two--step feedforward controller design procedure, consisting of an \emph{identification} to fit the model~\eqref{eq:ModelDynamics} to the system~\eqref{eq:SystemDynamics} using the data $\{Y^d, R^d, U_{\textup{ff}}^d \}$, and an \emph{inversion} to find the feedforward input $U_{\textup{ff}}$ for which the output $\hat{Y}$ of the model~\eqref{eq:ModelDynamics} follows the reference $R$.

The identification step aims to find the parameters $\theta = \hat{\theta}$ for the model $\hat{\phi}$ in~\eqref{eq:ModelDynamics} that best fit the data by minimizing a cost function, such that
\begin{equation}
\label{eq:IdentificationCriterion}
	\hat{\theta} = \textup{arg} \min_{\theta} V_{\textup{id}} ( \theta, Y^d, R^d, U_{\textup{ff}}^d ) + \| \Lambda (\theta - \theta^* )\|,
\end{equation}
where $V_{\textup{id}} : \mathbb{R}^{n_{\theta}} \times \mathbb{R}^{n_y N_d} \times \mathbb{R}^{n_y N_d} \times \mathbb{R}^{n_u N_d} \rightarrow \mathbb{R}$ is the identification cost function, and $\Lambda \in \mathbb{R}^{n_{\theta} \times n_{\theta}}$ and $\theta^* \in \mathbb{R}^{n_{\theta}}$ are used for regularization. 
Suppose that $\hat{f}$ is a nonlinear input--output representation as in~\eqref{eq:ModelDynamicsInputOutput}. Then, it is not generally possibly to find an inverse $\hat{f}^{-1}$ as in~\eqref{eq:ModelDynamicsFeedforward}.
A common approach to circumvent this issue is to parametrize a model $\hat{f}^{-1}$ directly, and identify its parameters using, e.g., a one step--ahead direct inverse identification, such that
\begin{align}
\begin{split}
\label{eq:IdentificationInverseDynamics}
	V_{\textup{id}} & (\theta, Y^d, R^d, U_{\textup{ff}}^d ) = \frac{1}{N} \sum_{i = 1}^{N_d} \Big( u^d(k) - \hat{f}^{-1} \big( \theta, x^d(k) \Big)^2, \\
	x^d & (k) = [y^d(k+n_k+1), ..., y^d(k+n_k-n_a+1), \\
	& \quad \quad \quad \quad u^d(k-1), ..., u^d(k-n_b+1)]^T. 
\end{split}
\end{align}
This approach is commonly adopted in literature, see, e.g.,~\cite{Bolderman2023, Kon2022}, but fails to provide a quantitative relation between the identification and the tracking error. 
Note that, the tracking error $e(k) = r(k)-y(k)$ does not even have the same unit as $u^d(k) - \hat{f}^{-1} \big( \theta, x^d (k) \big)$. 
In order to mitigate this issue,~\cite{Aarnoudse2021} proposes to filter the inverse model error by a linear model of the process sensitivity, i.e., minimize $G(q)S(q) \Big( u^d(k) - \hat{f}^{-1} \big( \theta, x^d(k) \big) \Big)$, with $G(q)$ and $S(q)$ the transfer function of the model of the system and the sensitivity, respectively. 
This approach establishes a qualitative relation between the tracking error and the identification cost function, but a quantitative relation is still missing. 

Hence, in this work we will address two main issues: how to design the identification cost function $V_{\textup{id}}$ in~\eqref{eq:IdentificationCriterion}, and how to compute the feedforward control input $u_{\textup{ff}}(k)$ based on the identified nonlinear model, i.e., $\hat{\phi}$ in~\eqref{eq:ModelDynamics} with $\theta = \hat{\theta}$, such that the resulting tracking error is minimized for a general class of nonlinear, possibly nonminimum phase MIMO systems. 
%Hence, the first problem considered in this work is: how to choose the identification cost function $V_{\textup{id}}$ in~\eqref{eq:IdentificationCriterion} such that the identified parameters $\hat{\theta}$ yield a model that is suitable for feedforward control.
%Hence, the first problem considered in this work is to find a quantitative relation between the tracking error on one hand, and the identification error and inversion error on the other hand. 

%Secondly, we develop an approach to compute the feedforward control input $u_{\textup{ff}}(k)$ from the identified nonlinear model, i.e., $\hat{\phi}$ in~\eqref{eq:ModelDynamics} with $\theta = \hat{\theta}$, which is capable to deal with nonlinear, nonminimum phase MIMO systems, that can be in state--space representations and allows to specify constraints on the inputs, outputs, or states.
%Often, the nonlinear inverse model--based feedforward controller suffers a performance loss when the forward model is nonminimum phase. 
%For example,~\cite{Bolderman2023} imposes stability of PGNN feedforward controllers by constraining the NN parameters based on sufficient conditions for stability.
%This might unnecessarily limit the flexibility of the PGNN model, and, consequently, the accuracy of the identification. 
%Hence, the second problem is to develop a general nonlinear feedforward control framework for the identified model, i.e.,~\eqref{eq:ModelDynamics} with $\theta = \hat{\theta}$, which is capable to deal with nonlinear, nonminimum phase MIMO systems, state--space representations, and constraints on the inputs, outputs, or states. 


%In what follows, we derive an explicit upperbound on the reference tracking performance for any feedforward control signal, which opens the path to such a generally applicable data--driven feedforward control design method. 


%Since the mapping $\Phi$ in~\eqref{eq:System} is unknown, the feedforward control design is based on a model--based mapping $\hat{\Phi}$ as in~\eqref{eq:SystemModel}. 
%This typically yields a two--step feedforward controller design procedure, consisting of an \emph{identification} step to fit the model~\eqref{eq:SystemModel} to the data~\eqref{eq:DataSetSystem}, and an \emph{inversion} step to compute the feedforward input.
%Although this approach is generally adopted in literature, see, e.g.,~\cite{Bolderman2023, Bolderman2021, Aarnoudse2021}, a quantitative relation between the identification and the tracking error, respectively, is still missing.
% there does not yet exist a quantitative relation between the identification and the tracking error, respectively. 
%Although this approach is generally adopted in literature, see, e.g.,~\cite{Bolderman2023, Bolderman2021, Aarnoudse2021}, there does not yet exist a quantitative relation to the tracking error.
%Hence, the first problem considered in this work is to establish a quantitative relation between the tracking error on one hand, and the identification error and inversion error on the other hand. 

%The identification step typically finds the parameters ${\theta} = \hat{\theta}$ for the model~\eqref{eq:SystemModel} by minimizing a cost function, such that
%\begin{equation}
%\label{eq:Identification}
%	\hat{\theta} = \textup{arg} \min_{\theta} V ( \theta, Y^d, R^d, U_{\textup{ff}}^d ).
%\end{equation}
%Therefore, the second problem considered is how to choose the cost function $V(\theta, Y^d, R^d, U_{\textup{ff}}^d)$ such that the identified parameters $\hat{\theta}$ yield a model--based mapping $\hat{\Phi}(\hat{\theta}, x_0, R, U_{\textup{ff}})$ that is suitable for the design of a feedforward controller.

%Often, the nonlinear inverse model--based feedforward controller suffers a performance loss when the forward model is nonminimum phase. 
%For example,~\cite{Bolderman2023} imposes stability of PGNN feedforward controllers by constraining the NN parameters based on sufficient conditions for stability.
%This might unnecessarily limit the flexibility of the PGNN model, and, consequently, the accuracy of the identification. 
%Hence, it would be of interest to develop a general nonlinear feedforward control framework for the identified model--based mapping $\hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}})$ which is capable to deal with nonlinear, nonminimum phase MIMO systems, state--space representations, and constraints on the inputs, outputs, or states. 
%This gives the third research question: develop a general nonlinear feedforward control framework for the identified model $\hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}})$ which is capable to deal with nonminimum phase dynamics, MIMO systems, state--space representation, and constraints on the inputs, outputs, or states. 



%In what follows, we derive an explicit upperbound on the reference tracking performance for any feedforward control signal, which opens the path to such a generally applicable data--driven feedforward control design method. 
%To solve these problems, we derive an upperbound on the achieved reference tracking performance based on which we obtain a feedforward control--oriented identification and a finite--horizon optimal feedforward control.  
%To solve the aforementioned problems, we derive a fundamental upperbound on the achieved reference tracking performance in terms of the parameters $\theta$ and the designed feedforward input $u_{\textup{ff}}$. 
%By minimizing the upperbound of the tracking error, we indirectly obtain a feedforward control--oriented identification procedure, as well as a the feedforward design as a FHOFC problem. 





\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/Simulation_Formulation.pdf}
\caption{Visual representation of the dynamics~\eqref{eq:SystemDynamics} in lifted form~\eqref{eq:SystemDynamicsLifted}.}
\label{fig:Lifted_Form}
\end{figure}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FEEDFORWARD CONTROL--ORIENTED IDENTIFICATION}
\label{sec:IdentificationForControl}
We rewrite the closed--loop system~\eqref{eq:SystemDynamics} and model~\eqref{eq:ModelDynamics} into a lifted form, based on which we propose the feedforward control--oriented identification cost function as well as the FHOFC formulation.
Afterwards, we show that, indeed, minimizing the identification cost function and finding an optimal solution to the FHOFC minimizes the reference tracking error. 


The lifted form of the closed--loop system is obtained by simulating~$\phi$ in~\eqref{eq:SystemDynamics} as in Fig.~\ref{fig:Lifted_Form}, such that
\begin{equation}
\label{eq:SystemDynamicsLifted}
	Y = \Phi (x_0, R, U_{\textup{ff}}).
\end{equation}
In~\eqref{eq:SystemDynamics}, $x_0 \in \mathbb{R}^{n_x}$ are the initial conditions, and $\Phi : \mathbb{R}^{n_x} \times \mathbb{R}^{n_y N_k} \times \mathbb{R}^{n_u \times N_k} \rightarrow \mathbb{R}^{n_y N_k}$ is a mapping obtained by recursive composition of the system~$\phi$.
Similarly, the lifted form of the model~$\hat{\phi}$ in~\eqref{eq:ModelDynamics} is defined as follows
\begin{equation}
\label{eq:ModelDynamicsLifted}
	\hat{Y} = \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}} ),
\end{equation}
where $\hat{\Phi} : \mathbb{R}^{n_{\theta}} \times \mathbb{R}^{n_x} \times \mathbb{R}^{n_y N_k} \times \mathbb{R}^{n_u N_k} \rightarrow \mathbb{R}^{n_y N_k}$ is a model--based mapping obtained by recursive composition of~$\hat{\phi}$. 
The data set is generated by exciting the system with $U_{\textup{ff}}^d$ and $R^d$, such that, from~\eqref{eq:SystemDynamicsLifted} and~\eqref{eq:ModelDynamicsLifted}, we can write
\begin{equation}
\label{eq:DataSetLifted}
	Y^d = \Phi (x_0^d, R^d, U_{\textup{ff}}^d), \quad \hat{Y}^d = \hat{\Phi} (\theta, x_0^d, R^d, U_{\textup{ff}}^d),
\end{equation}
with $x_0^d \in \mathbb{R}^{n_{\theta}}$ the initial state of the experiment.


We aim to minimize the $p$--norm of the tracking error, i.e., $\| E \|_p = \| R - Y \|_p$ for some $p \in \mathbb{Z}_{\geq 1}$, while keeping the input, output, and states in the safe sets, i.e., $U \in \mathcal{R}_{U}$, $Y \in \mathcal{R}_{Y}$, and $X \in \mathcal{R}_{x}$.
The feedforward control signal computation is done as follows:
\begin{enumerate}
	\item \textbf{Identify} the optimal set of parameters $\hat{\theta}$ for the model~$\hat{\phi}$ in~\eqref{eq:ModelDynamics} according to~\eqref{eq:IdentificationCriterion} with the feedforward control--oriented identification cost function
\end{enumerate}
	\begin{equation}
	\label{eq:CostFunction_FeedforwardControl}
		V_{\textup{id}} (\theta, Y^d, R^d, U_{\textup{ff}}^d) = \frac{1}{N_d^{1/p}} \| Y^d - \hat{\Phi} (\theta, x_0^d, R, U_{\textup{ff}} ) \|_p.
	\end{equation}
\begin{enumerate}
	\setcounter{enumi}{1}
	\item \textbf{Compute} the feedforward input $U_{\textup{ff}}$ using the identified model, i.e.,~$\hat{\phi}$ with $\theta = \hat{\theta}$, according to the FHOFC
\end{enumerate}
\begin{align}
\begin{split}
\label{eq:FHOFCP}
	U_{\textup{ff}}  = \textup{arg}& \min_{U_{\textup{ff}}} V_{\textup{ff}} (\hat{\theta}, R, U_{\textup{ff}} )  + \| \Gamma U_{\textup{ff}} \|, \\
	\textup{subject to:}\;  U_{\textup{ff}} \in \, &\mathcal{R}_{U_{\textup{ff}}}, \; \hat{U} \in \mathcal{R}_U, \; \hat{Y} \in \mathcal{R}_Y, \; \hat{X} \in \mathcal{R}_X. 
\end{split}
\end{align}
\begin{enumerate}
	\item[] with the FHOFC cost function
\end{enumerate}
\begin{align}
\begin{split}
\label{eq:CostFunction_FHOFCP}
	V_{\textup{ff}} (\hat{\theta}, R, U_{\textup{ff}} ) = \frac{1}{N_k^{1/p}} \| R - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}} ) \|_p. 
\end{split}
\end{align}
\begin{remark} The feedforward control--oriented identification cost function~\eqref{eq:CostFunction_FeedforwardControl} penalizes the closed--loop simulation error of the model~$\hat{\phi}$. 
This is different from the one--step--ahead inverse identification in~\eqref{eq:IdentificationInverseDynamics}, even when it is filtered with the process sensitivity. 
Moreover,~\cite{Bolderman2022c} did not consider the feedback controller in the identification, and was therefore unable to link the tracking and identification error.
\end{remark}


\begin{remark}
Solving the FHOFC optimization~\eqref{eq:FHOFCP} becomes computationally expensive when $N_k$ is large. 
However, the partial derivative of $V_{\textup{ff}}$ with respect to $U_{\textup{ff}}$ is known, such that, e.g., the constraint Gauss--Newton approach in~\cite{Volckaert2009} can be used. 
Several other options to reduce the computational complexity are: $1)$ \emph{parametrize the feedforward signal} using basis functions~\cite{Ramani2017, Kasemsinsup2017}, $2)$ \emph{Parametrize an inverse model} of the system and find its parameters via~\eqref{eq:FHOFCP}, or $3)$ \emph{solve~\eqref{eq:FHOFCP} in a receding horizon manner}. 
\end{remark}
%\begin{remark}
%\begin{enumerate}
%	\item {\emph{Parameterize the feedforward signal}} using basis functions~\cite{Ramani2017, Kasemsinsup2017}. Essentially, choose $U_{\textup{ff}} = \sum_{i=1}^{N_{\textup{bf}}} c_i \Psi_i$ with $c_i$ the coefficients, $\Psi_i$ the basis functions, $N_{\textup{bf}} << N_k$, and optimize over $c = [c_1, ..., c_{N_{\textup{bf}}}]^T$. 
%	\item {\emph{Parameterize an inverse model}} as $U_{\textup{ff}} = \hat{\Phi}_{\textup{inv}} (\theta_{\textup{inv}}, R)$ and find $\hat{\theta}_{\textup{inv}}$ by minimizing~\eqref{eq:FHOFCP}. 
%	\item {\emph{Solve the FHOFC problem in a receding horizon}} manner, i.e., let $\bar{u}_{\textup{ff}}(k) = [u_{\textup{ff}}^T(k), ..., u_{\textup{ff}}^T(k+h)]^T$, with $h \in \mathbb{Z}_{>0}$ the prediction horizon and solve
%	\begin{align}
%	\begin{split}
%	\label{eq:FHOFCPRecedingHorizon}
%		\bar{u}_{\textup{ff}}(k) &= \textup{arg} \min_{\bar{u}_{\textup{ff}}(k)} \| \bar{r}(k) - \hat{\bar{y}}(k) \| + \| \Gamma \bar{u}_{\textup{ff}}(k) \|, \\
%		u_{\textup{ff}}(k) & = [I, 0, ..., 0] \bar{u}_{\textup{ff}}(k). 
%	\end{split}
%	\end{align}
%\end{enumerate}
%\end{remark}
\begin{proposition}
\label{prop:Upperbound}
Consider the system~$\phi$ in~\eqref{eq:SystemDynamics} with lifted form $\Phi$ in~\eqref{eq:SystemDynamicsLifted} and a corresponding parametrized model $\hat{\phi}$ in~\eqref{eq:ModelDynamics} with lifted form $\hat{\Phi}$ in~\eqref{eq:ModelDynamicsLifted}. 
Suppose that $\hat{\theta}$ is identified according to~\eqref{eq:IdentificationCriterion} with $V_{\textup{id}}$ in~\eqref{eq:CostFunction_FeedforwardControl}, that $U_{\textup{ff}}$ is obtained from~\eqref{eq:FHOFCP} with $V_{\textup{ff}}$ in~\eqref{eq:CostFunction_FHOFCP}, and define 
\begin{equation}
\label{eq:Varepsilon}
	\varepsilon := \frac{1}{N_k^{1/p}} \| Y - \hat{Y} \|_p - \frac{1}{N_d^{1/p}} \| Y^d - \hat{Y}^d \|_p.
\end{equation}
Then, the tracking error resulting from $U_{\textup{ff}}$ satisfies
\begin{align}
\begin{split}
\label{eq:UpperboundPerformance}
	\frac{1}{N_k^{1/p}} \| R - Y \|_p \leq V_{\textup{id}} (\hat{\theta}, Y^d, R^d, U_{\textup{ff}}^d) + V_{\textup{ff}} ( \hat{\theta}, R, U_{\textup{ff}} ) + \varepsilon. 
\end{split}
\end{align}
\end{proposition}

\begin{proof}
	From the triangular inequality and~\eqref{eq:Varepsilon}, we have
	\begin{align}
	\begin{split}
	\label{eq:Prop1Step1}
		\|R-Y \|_p & = \| R -\hat{Y} + \hat{Y} - Y \|_p \\
		& \leq \| R - \hat{Y} \|_p + \| Y - \hat{Y} \|_p \\
		\leq \| &R - \hat{Y} \|_p + \frac{N_k^{1/p}}{N_d^{1/p}} \| Y^d - \hat{Y}^d \|_p + N_k^{1/p} \varepsilon .
	\end{split}
	\end{align}
	Dividing both sides by $N_k^{1/p}$ and using $V_{\textup{id}}$ and $V_{\textup{ff}}$ as in~\eqref{eq:CostFunction_FeedforwardControl} and~\eqref{eq:CostFunction_FHOFCP} on the right hand side concludes~\eqref{eq:UpperboundPerformance}. 
	% of $V_{\textup{id}}$ in~\eqref{eq:CostFunction_FeedforwardControl} and $V_{\textup{ff}}$ in~\eqref{eq:CostFunction_FHOFCP} on the right hand side concludes~\eqref{eq:UpperboundPerformance}. 
\end{proof}

The parameter $\varepsilon$ in~\eqref{eq:Varepsilon} is a measure stating the relevance of the \emph{training data} $\{Y^d, R^d, U_{\textup{ff}}^d\}$ with respect to the \emph{operation data} $\{Y, R, U_{\textup{ff}} \}$, which can be interpreted as the \emph{validation data}.
Accordingly, $\varepsilon > 0$ indicates that the training data does not sufficiently represent the operation data, while $\varepsilon < 0$ indicates that the training data covers all system dynamics that contribute to the tracking error. 
We aim for $\varepsilon = 0$, which is achieved when either:
\begin{enumerate}
	\item \emph{Training data} is the \emph{operation data}, i.e., design $\{ R^d, U_{\textup{ff}}^d \} = \{R, U_{\textup{ff}} \}$. An existing feedforward controller could be used for $U_{\textup{ff}}^d$ as an approximation of~$U_{\textup{ff}}$;
	\item \emph{Consistent parameter identification}, such~that $\Phi(x_0, R, U_{\textup{ff}}) =\hat{\Phi}(\hat{\theta}, x_0, R, U_{\textup{ff}})$ and $\Phi (x_0^d, R^d, U_{\textup{ff}}^d) = \hat{\Phi} (\hat{\theta}, x_0^d, R^d, U_{\textup{ff}}^d)$. This requires standard assumptions from system identification, i.e., the system is in the model set, the data is persistently exciting, and the optimization of~\eqref{eq:IdentificationCriterion} yields a global optimum, see, e.g.,~\cite{Bolderman2022c} for the formalized assumptions. 
\end{enumerate}
Suppose that the operation data has the same length as the data set, i.e., $N_k = N_d = N$ and that $x_0^d = x_0$. Then, with the triangular inequality, we upperbound $\varepsilon$ in~\eqref{eq:Varepsilon} by
\begin{align}
\begin{split}
\label{eq:Varepsilon_Upperbound}
	\varepsilon & \leq \frac{1}{N^{1/p}} \| Y - \hat{Y} - Y^d + \hat{Y}^d \|_p \\
	& \leq \frac{1}{N^{1/p}} \left\| \begin{bmatrix} \gamma_R , \gamma_{U_{\textup{ff}}} \end{bmatrix}  \begin{bmatrix} R - R^d \\ U_{\textup{ff}} - U_{\textup{ff}}^d \end{bmatrix} \right\|_p.
\end{split}
\end{align}
where $\gamma_R = \max \big| \frac{\partial (Y - \hat{Y})}{\partial R} \big|$ and $\gamma_{U_{\textup{ff}}} = \max \big| \frac{\partial (Y - \hat{Y})}{\partial U_{\textup{ff}}} \big|$. 
Since $Y$ and $\hat{Y}$ in~\eqref{eq:Varepsilon_Upperbound} result from a closed--loop simulation, the feedback controller $C(q)$ also affects the upperbound in~\eqref{eq:Varepsilon_Upperbound}. 
Note that, for a linear system, $\frac{\partial Y}{\partial R}$ and $\frac{\partial Y}{\partial U_{\textup{ff}}}$ describe the complementary sensitivity and process sensitivity, respectively. 
%Note that, for a linear system (model), $\frac{\partial Y}{\partial R}$ ($\frac{\partial \hat{Y}}{\partial R}$) and $\frac{\partial Y}{\partial U_{\textup{ff}}}$ ($\frac{\partial \hat{Y}}{\partial U_{\textup{ff}}}$) describe the complementary sensitivity, and process sensitivity (of the model), respectively.  

\begin{remark} 
Once the feedforward input $U_{\textup{ff}}$ is obtained from~\eqref{eq:FHOFCP}, it is possible to use it for generating new data which results in a smaller $\varepsilon$.
\end{remark}








%We derive an upperbound on the reference tracking performance in terms of the inversion and model error.
%The model error is later used to develop a feedforward control--oriented system identification.
%To derive the bound on the tracking error, we define the inversion error as $R - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}})$ and the model error as $Y - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}})$. 
%\begin{proposition}
%\label{prop:UpperboundPerformance}
%	Consider the mapping~\eqref{eq:System} and a corresponding parameterized model--based mapping~\eqref{eq:SystemModel}. 
	%Let the reference tracking performance be quantified according to some norm, i.e.,~$\| e \|$. 
%	Then, for any $\theta$ and $U_{\textup{ff}}$, the norm of the corresponding tracking error is upperbounded by the sum of the norms of the inversion and model error, respectively, i.e.,
%	\begin{equation}
%	\label{eq:UpperboundTrackingErrorA}
%		\| R - Y \| \leq \| R - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}}) \| + \| Y - \hat{\Phi} (\theta, x_0, R, U_{\textup{ff}}) \|.
%	\end{equation}
%\end{proposition}
%\begin{proof}
%	The proof follows by applying the triangle inequality, such that
%	\begin{align}
%	\begin{split}
%	\label{eq:Proof1Step1}
%		\| R - Y \| & = \| R - \hat{Y} + \hat{Y} - Y \| \\
%		& \leq \| R - \hat{Y} \| + \| \hat{Y} - Y \| = \| R - \hat{Y} \| + \| Y - \hat{Y} \|. 
%	\end{split}
%	\end{align}
%	Eq.~\eqref{eq:UpperboundTrackingErrorA} is obtained by substituting~\eqref{eq:SystemModel} in~\eqref{eq:Proof1Step1}. 
%\end{proof}

%Proposition~\ref{prop:UpperboundPerformance} states that the norm of the tracking error can be decreased by minimizing the norm of the inversion and the model error, respectively.
%Proposition~\ref{prop:UpperboundPerformance} indicates that, with the aim to minimize the norm of the tracking error, we can minimize the norm of the inversion and the model error. 
%Computation of the model error requires~$Y$, which can only be generated on the system by applying $U_{\textup{ff}}$, which is yet unknown.
%Therefore, we replace the right half of~\eqref{eq:UpperboundTrackingErrorA} by
%Therefore, we replace the model error by the identification error, i.e., %, i.e., by substituting the training data
%\begin{equation}
%\label{eq:IdentificationError}
%	  Y^d - \hat{\Phi} ( \theta, x_0, R^d, U_{\textup{ff}}^d ) .
%\end{equation}
%The identification error~\eqref{eq:IdentificationError} can be made smaller by appropriately choosing $\theta$. 
%Thereby, we obtain a two--step approach to design a data--driven nonlinear feedforward controller:
%\begin{enumerate}
%	\item \textbf{\emph{Identify}} the set of parameters $\theta = \hat{\theta}$ that minimizes the norm of the identification error, such that $\hat{\theta} = \textup{arg} \min_{\theta} \| Y^d - \hat{\Phi} ( \theta, x_0, R^d, U_{\textup{ff}}^d) \|$;
%	\item \textbf{\emph{Compute}} the feedforward input $U_{\textup{ff}}$ that minimizes the norm of the inversion error for $\theta = \hat{\theta}$, such that $U_{\textup{ff}} = \textup{arg} \min_{U_{\textup{ff}}} \| R - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}} ) \|$. 
%\end{enumerate}
%Step $1)$ shows that the cost function~$V$ in~\eqref{eq:Identification} should be chosen as the norm of the \emph{closed--loop simulation error}. 
%A similar derivation can be performed for a \emph{direct closed--loop identification}.

%\begin{lemma}
%\label{le:UpperboundPerformance}
%	Consider the mapping~\eqref{eq:System} and the parameterized model--based mapping~\eqref{eq:SystemModel}, where $\hat{\theta}$ and $U_{\textup{ff}}$ are found by the two--step approach above. 
%	Suppose that the $p$--norm is used, $p \in \mathbb{Z}_{>0}$, and define the data informativity measure
%	\begin{equation}
%	\label{eq:DataInformativity}
%		\varepsilon := \frac{1}{N_k^{1/p}} \| Y - \hat{Y} \|_p - \frac{1}{N_d^{1/p}} \| Y^d - \hat{Y}^d \|_p.
%	\end{equation}
%	Then, the tracking error satisfies the following bound
%	\begin{align}
%	\begin{split}
%	\label{eq:UpperboundTrackingErrorB}
%		\frac{1}{N_k^{1/p}} \| R & - Y \|_p \leq \frac{1}{N_k^{1/p}} \| R - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}} ) \|_p \\
%		&  + \frac{1}{N_d^{1/p}} \| Y^d - \hat{\Phi} (\hat{\theta}, x_0, R^d, U_{\textup{ff}}^d ) \|_p + \varepsilon. 
%	\end{split}
%	\end{align}
%\end{lemma}
%\begin{proof}
%	Dividing both sides in~\eqref{eq:UpperboundTrackingErrorA} by $N_k^{1/p}$ and substituting~\eqref{eq:DataInformativity} yields~\eqref{eq:UpperboundTrackingErrorB}. 
%	The proof follows by dividing both sides in~\eqref{eq:UpperboundTrackingErrorA} by $K$ and substituting~\eqref{eq:DataInformativity}. 
%\end{proof}

%The division with $N_k^{1/p}$ normalizes the difference in length of $Y$ and $Y^d$, i.e., when $N_k \neq N_d$.
%\begin{remark}
%The parameter $\varepsilon$ in~\eqref{eq:DataInformativity} is a data informativity measure stating the relevance of the training data $\{Y^d, R^d, U_{\textup{ff}}^d\}$ with respect to the operation data $\{ Y, R, U_{\textup{ff}}\}$ for the identified set of parameters $\hat{\theta}$.
%\begin{remark}
%From the definition~\eqref{eq:DataInformativity} we have that $\varepsilon = 0$ when $\{ Y^d, R^d, U_{\textup{ff}}^d \} = \{ Y, R, U_{\textup{ff}} \}$. 
%This hints to choosing $R^d$ and $U_{\textup{ff}}^d$ in the data generating experiment close to $R$ and $U_{\textup{ff}}$ to achieve a small $\varepsilon$, see also~\cite{Schoukens2019}. 
%This suggests that $R^d$ and $U_{\textup{ff}}^d$ should be chosen close to the operating conditions $R$ and $U_{\textup{ff}}$ to achieve a small $\varepsilon$, see also~\cite{Schoukens2019}. 
% This is in line with the guidelines in~\cite{Schoukens2019}, stating that the training data should cover the complete domain of interest.
% with the nonlinear system identification guideline to cover the complete domain of interest in~\cite{Schoukens2019}.
%A reasonable choice is to have $R^d$ comprise of a set of target references, while $U_{\textup{ff}}^d$ is generated using a simple feedforward controller. 
%Iterative identification using data generated with a new $U_{\textup{ff}}^d$ potentially decreases $\varepsilon$, see also~\cite{Hof1995} for iterative linear identification and feedback controller design.
%Iterative approaches that use new data generated with a better $U_{\textup{ff}}^d$ to further decrease $\varepsilon$ are discussed for linear feedback controller design in~\cite{Hof1995}.
%Using Lemma~\ref{le:UpperboundPerformance} we can aim for a desired tracking performance by performing the identification and inversion sufficiently accurate.  
%\end{remark}

%\begin{remark}
%	In the (PG)NN--based feedforward control literature it is common to employ a regularization term in the cost function~\cite[Section 4]{Bolderman2023} and to use the squared $2$--norm due to its smoothness, such that
%	To prevent overfitting during the identification, it is common in (PG)NN literature, see~\cite{Bolderman2023} to employ a regularization term. Due to its smoothness, the squared $2$--norm is often chosen as the cost function, such that%, while using the squared $2$--norm as a cost function, such that
%	\begin{equation}
%	\label{eq:PGNNCostFunction}
%		\hat{\theta} = \textup{arg} \min_{\theta} \| Y^d - \hat{\Phi} (\theta, x_0, R^d, U_{\textup{ff}}^d) \|_2^2 + \| \Lambda (\theta - \theta^* ) \|_2^2.
%	\end{equation}
%	In~\eqref{eq:PGNNCostFunction},~$\theta^*$ is a set of desired parameters, e.g., $0$ for $\theta_{\textup{NN}}$ and/or some known physical values for $\theta_{\textup{phy}}$, and $\Lambda \in \mathbb{R}^{n_{\theta} \times n_{\theta}}$ states the relative importance of $\theta - \theta^*$.
	% with respect to the data fit. 	
%	Since the norm is non--negative and the square root is monotonically increasing, minimization of the norm and its square is equivalent (when neglecting the regularization term). 
%	Hence,~\eqref{eq:PGNNCostFunction} is a suitable identification cost function when aiming to minimize the $2$--norm of the tracking error, i.e., $\| R - Y \|_2$. 
	%Since a norm is non--negative by definition, minimization of a norm automatically minimizes its square.
%	\begin{align}
%	\begin{split}
%	\label{eq:EquivalenceSquare}
%		\textup{arg} \min_{\theta} \sqrt{(y^d - \hat{y}^d)^T (y^d-\hat{y}^d)} = \textup{arg} \min_{\theta} (y^d-\hat{y}^d)^T(y^d-\hat{y}^d),
%	\end{split}
%	\end{align}
%\end{remark}

%\begin{remark}
	%Identification according to~\eqref{eq:PGNNCostFunction} is an indirect closed--loop identification, i.e., the identification is based on the closed--loop behaviour. 
%	A similar derivation as presented in this section can be performed for a \emph{direct} closed--loop identification.
%	This approach has the potential for consistent identification when noise is present in the data set, see, e.g.,~\cite{Bolderman2022c}.
	%A similar derivation can be performed for a direct closed--loop identification, i.e., by parameterizing the open--loop system, such that
	%\begin{equation}
	%\label{eq:SystemModelOpenLoop}
	%	\hat{y} = \hat{\Phi}_{\textup{OL}} (\theta, u).
	%\end{equation}
	%Although the direct identification can have advantageous when noise enters the system, it requires asymptotic stability of the model to make predictions over longer time periods. 
%\end{remark}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FINITE--HORIZON OPTIMAL FEEDFORWARD CONTROL}
\label{sec:FHOFC}
Next we show that the FHOFC~\eqref{eq:FHOFCP} can recover some of the state--of--the--art methods for feedforward control, namely: inverse model--based feedforward and linear ILC. 
For simplicity, we neglect the constraints in~\eqref{eq:FHOFCP}. 
%Inverse model--based feedforward control is recovered when computing the analytic solution of the receding horizon FHOCFC~\eqref{eq:FHOFCPRecedingHorizon}. 
%To show the former, let the system model admit an input--output representation~\eqref{eq:ModelDynamicsInputOutput}, and suppose that a unique inverse relation as in~\eqref{eq:ModelDynamicsFeedforward} is known.
\begin{lemma}
\label{le:InversionBasedFeedforward}
	Consider the feedforward control design using an identified input--output model~\eqref{eq:ModelDynamicsInputOutput} for which the inverse relation~\eqref{eq:ModelDynamicsFeedforward} is unique. % is known as~\eqref{eq:InverseModelPGNN}. 
	Suppose that the initial conditions are such that $y(i) = r(i)$ for $i \in \{ n_k-n_a+1, ..., n_k \}$. 
	Then, the inverse model--based feedforward controller 
	\begin{align}
	\begin{split}
	\label{eq:InversionBasedFeedforward}
		u_{\textup{ff}}(k) = f^{-1} \big( \hat{\theta}, [& r^T(k+n_k+1), ..., r^T(k+n_k-n_a+1), \\
		& u_{\textup{ff}}^T(k-1), ..., u_{\textup{ff}}^T(k-n_b+1)]^T \big)
	\end{split}
	\end{align}
	solves the unconstrained FHOFC~\eqref{eq:FHOFCP} with $\Gamma = 0$ in a receding horizon manner with a preview of $n_k+1$.  
\end{lemma}
\begin{proof}
	$u_{\textup{ff}}(k)$ appears first in the predicted output $\hat{y}(k+n_k+1)$, such that $u_{\textup{ff}}(k+i)$, $i \in \mathbb{Z}_{>0}$ does not play a role in the cost function when $\Gamma = 0$. 
%	$u_{\textup{ff}}(k)$ first affects $\hat{y}(k+n_k+1)$, such that $u_{\textup{ff}}(k+i)$, $i \in \mathbb{Z}_{>0}$ does not affect the cost function when $\Gamma = 0$. 
	Hence, the FHOFC~\eqref{eq:FHOFCP} with preview $n_k+1$ becomes
%	Since $u_{\textup{ff}}(k)$ at first affects $\hat{y}(k+n_k+1)$, the receding horizon FHOFC problem~\eqref{eq:FHOFCPRecedingHorizon} with $R = 0$ becomes
	\begin{equation}
	\label{eq:Proof3Step1}
		u_{\textup{ff}}(k) = \textup{arg} \min_{u_{\textup{ff}}(k)} \| r(k+n_k+1) - \hat{y} (k + n_k+1) \|. 
	\end{equation}
	Since the minimum is attained for $r(k+n_k+1) = \hat{y}(k+n_k+1)$, the solution of~\eqref{eq:Proof3Step1} equals~\eqref{eq:InversionBasedFeedforward} when~\eqref{eq:Proof3Step1} is solved sequentially, i.e., for $k = 0, 1, ..., N_k$. 
	Observing that, from~\eqref{eq:ModelDynamicsInputOutput}, $\hat{u}(k) = C(q) \big( r(k)-y(k) \big) + u_{\textup{ff}}(k) = u_{\textup{ff}}(k)$ for $r(i) - \hat{y}(i) = 0$, $i \in \{ 0, ..., k \}$, completes the proof. 
%	Note that, from~\eqref{eq:OpenClosedLoop}, $u_{\textup{fb}} (k) = 0$ for $r(i)-\hat{y}(i) =0$, $i \in \{ 0, ..., k \}$, such that $\hat{u}(k) = u_{\textup{ff}}(k)$. 
\end{proof}

\begin{remark}
	In~\cite{Bolderman2022c}, the optimization~\eqref{eq:Proof3Step1}, which is a specific case of the FHOFC~\eqref{eq:FHOFCP}, was solved by proposing a specific PGNN structure for which $f^{-1}$ of $f$ in~\eqref{eq:ModelDynamicsInputOutput} is known analytically. Moreover, it discusses the use of a numerical solver when $f^{-1}$ is not known. 
%	In general, obtaining an analytical inverse relation as in~\eqref{eq:ModelDynamicsFeedforward} is not possible or tractable, e.g., when the system model~\eqref{eq:ModelDynamicsInputOutput} is parametrized as a black--box NN. 
%	In these cases, $u_{\textup{ff}}(k)$ can be found by minimizing~\eqref{eq:Proof3Step1} using a numerical solver, as in~\cite{Bolderman2022c}.
\end{remark}





When the identification in~\eqref{eq:IdentificationCriterion} and the FHOFC~\eqref{eq:FHOFCP} are solved accurately, the tracking error may remain large due to $\varepsilon$ in~\eqref{eq:UpperboundPerformance}. 
To improve performance, it is possible to re--identify $\theta$ based on new data that is generated with $U_{\textup{ff}}$. 
%New data can be generated to achieve a smaller $\varepsilon$, and thereby obtain a more accurate model.
%Options to generate new data and thereby achieve a smaller $\varepsilon$ were indicated in Sec.~\ref{sec:IdentificationForControl}. 
%It was discussed in Sec.~\ref{sec:IdentificationForControl} to generate new data and thereby achieve a smaller $\varepsilon$. 
Alternatively, when the system has to perform a repetitive tasks, i.e., has to track a reference $R$ multiple iterations, an iterative learning scheme can be implemented when the same reference is executed repetitively, as is done in ILC~\cite{Bristow2006}. 
Inspired by ILC, we present the iterative learning FHOFC (IL--FHOFC) scheme:
%In the remainder of this section, we show how to integrate an iterative learning scheme in the FHOFC formulation~\eqref{eq:FHOFCP} by establishing a relation to linear ILC~\cite{Bristow2006}.
%We denote iteration $i \in \mathbb{Z}_{>0}$ with the superscript $(i)$ for signals, and integrate an iterative learning scheme in the FHOFC formulation~\eqref{eq:FHOFCP} to obtain the iterative learning FHOFC (IL--FHOFC) as follows
%Next, we present an iterative learning FHOFC (IL--FHOFC) scheme for nonlinear systems, inspired by ILC:
\begin{align}
\begin{split}
\label{eq:NonlinearILCEquivalent}
	\zeta & = \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}}^{(i)}) + \alpha E^{(i)}, \\
	U_{\textup{ff}}^{(i+1)} & = Q_m \left[ \textup{arg} \min_{U_{\textup{ff}}} \big\| \zeta - \hat{\Phi} (\hat{\theta}, x_0, R, U_{\textup{ff}}) \big\| + \| \Gamma U_{\textup{ff}} \| \right].
\end{split}
\end{align}
In~\eqref{eq:NonlinearILCEquivalent}, the superscript $(i)$ relates to iteration $i \in \mathbb{Z}_{>0}$ of a signal, $E^{(i)} = R - Y^{(i)}$ is the tracking error since $R$ is constant over the iterations, $\zeta \in \mathbb{R}^{n_u N_k}$ is an auxiliary signal, and $Q_m \in \mathbb{R}^{n_u N_k \times n_u N_k}$ contains the Markov parameters of a robustness filter with transfer function matrix $Q$.
%The following result shows that~\eqref{eq:NonlinearILCEquivalent} recovers linear ILC when $\hat{\Phi}$ is comprised of a linear model $\hat{\phi}$~\eqref{eq:ModelDynamics}.

\begin{lemma}
\label{le:FHOFCILCEquivalence}
	Suppose that $G$ is the transfer function matrix of a linear system, $C$ is a feedback controller, and $\hat{G}$ is a model of $G$, with all transfer functions represented in the digital domain. 
	Let $\hat{\Phi}$ be the closed--loop model--based mapping obtained from $C$ and $\hat{G}$, and let $\alpha \in (0, 1]$ be a learning gain and $Q$ a robustness filter. %, and denote iteration $i \in \mathbb{Z}_{>0}$ with the superscript $(i)$ for signals. 
	Then, the ILC law
	%Consider the ILC update law
	%The superscript $(i)$ denotes iteration $i \in \mathbb{Z}_{\geq 0}$.
	\begin{align}
	\begin{split}
	\label{eq:LinearILCInput}
	\xi^{(i)}(k) & = u_{\textup{ff}}^{(i)}(k) + \alpha \hat{G}^{-1} ( 1 + \hat{G}C) e^{(i)}(k), \\
	u_{\textup{ff}}^{(i+1)}(k) & = Q \xi^{(i)}(k),
	\end{split}
	\end{align}
	%where the superscript $(i)$ denotes the iteration $i \in \mathbb{Z}_{\geq 0}$, and $\alpha \in [0, 1)$ is the learning gain.
%	with learning gain $\alpha \in [0, 1)$. 
	%Let $\hat{\Phi}$ be the closed--loop model obtained from $C$ and $\hat{G}$.
	%is equivalent to the global optimum of
	solves the IL--FHOFC problem~\eqref{eq:NonlinearILCEquivalent} with $\Gamma = 0$. 
\end{lemma}
\begin{proof}
	The output predicted by $\hat{G}$ at iteration $i$ is 
	\begin{equation}
	\label{eq:LinearClosedLoop}
		\hat{y}^{(i)}(k) = (1+\hat{G}C)^{-1}\hat{G}Cr(k) + (1+\hat{G}C)^{-1}\hat{G}u_{\textup{ff}}^{(i)}(k).
	\end{equation}
	The output of the system with input $\xi^{(i+1)}(k)$ in~\eqref{eq:LinearILCInput} is
	\begin{align}
	\begin{split}
	\label{eq:Proof4Step1}
		\hat{y}^{(i+1)}(k) = \hat{y}^{(i)}(k) + \alpha e^{(i)}(k).
	\end{split}
	\end{align}
	Placing the time entries of~\eqref{eq:Proof4Step1} in a column, shows that
	\begin{align}
	\begin{split}
	\label{eq:Proof4Step2}
		& \big\| \zeta^{(i+1)} - \hat{\Phi} (\hat{\theta}, x_0, R, [\xi^{(i+1)}(1)^T, ..., \xi^{(i+1)}(N_k)^T]^T ) \big\| = 0. 
	\end{split}
	\end{align}
	Hence, the first line of the linear ILC~\eqref{eq:LinearILCInput} solves the optimization in the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} for $\Gamma = 0$. 
	Since $Q_m$ describes the robustness filter $Q$ in ILC~\eqref{eq:LinearILCInput}, $U_{\textup{ff}}^{(i+1)}$ in~\eqref{eq:NonlinearILCEquivalent} is the column of $u_{\textup{ff}}^{(i+1)}(k)$ in~\eqref{eq:LinearILCInput}. 
	%Afterwards, $U_{\textup{ff}}^{(i+1)}$ is obtained by filtering $\xi^{(i+1)}(k)$ with the filter $Q$ and placing the time entries in a column.
\end{proof}
\begin{remark}
	Both $Q_m$ and $\Gamma$ in the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} are parameters that affect convergence.
	Proving convergence for specific systems and models will be done in future work. 
\end{remark}
%\begin{remark}
	%An alternative approach is to re--identify $\theta$ based on new data, and compute $U_{\textup{ff}}^{(i+1)}$ by using the FHOFC~\eqref{eq:FHOFCP}. 
%\end{remark}

%\begin{remark}
	%Lemma~\ref{le:FHOFCILCEquivalence} shows the equivalence between the linear ILC update~\eqref{eq:LinearILCInput} and the IL--FHOFC formulation~\eqref{eq:NonlinearILCEquivalent} for a linear model $\hat{\Phi}$.
	%The equivalence in Lemma~\ref{le:FHOFCILCEquivalence} holds for linear ILC~\eqref{eq:LinearILCInput} and a linear model $\hat{\Phi}$. 
%	Lemma~\ref{le:FHOFCILCEquivalence} holds for linear ILC~\eqref{eq:LinearILCInput} and a linear model--based mapping $\hat{\Phi}$. 
%	Nevertheless, the IL--FHOFC in~\eqref{eq:NonlinearILCEquivalent} is directly applicable to nonlinear models.
%\end{remark}
%Note that we make a separation between the target reference $r^{(i)}$ and the predicted output $\hat{y}^{(i)}$ in~\eqref{eq:NonlinearILCEquivalent}, which is caused by the fact that the feedforward input $u_{\textup{ff}}^{(i)}$ does not necessarily yield $r^{(i)} = \hat{y}^{(i)}$. 







\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=1.0\linewidth]{Figures/Figure_NonMinimumPhaseExample_V2.pdf}
\caption{Rotating--translating mass with actuation and sensing on opposite sides of the centre of mass.}
\label{fig:NonminimumPhaseExample}
\end{figure}
\begin{table}
\caption{Parameter values of the system displayed in Fig.~\ref{fig:NonminimumPhaseExample}.}
\label{tab:ParameterValues}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
$m$ & $l_x, l_y$ & $J$ & $f_v$ & $c$ & $d$ & $l_m$ & $c_{\alpha}$ & $c_g$ \\ \hline \hline
$20$ & $1$  & $\frac{40}{3}$  & $50$  & $\frac{25 \cdot 10^{3}}{3}$  & $\frac{575}{3}$ & $0.05$ & $0.05$ & $1$ \\ \hline
$kg$ & $m$ & $kgm^2$ & $\frac{kg}{s}$ & $\frac{kg}{s^2}$ & $\frac{kg}{s}$ & $m$ & $-$ & $N$ \\ \hline
\end{tabular}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{VALIDATION ON A NONMINIMUM PHASE NONLINEAR MECHATRONIC EXAMPLE}
\label{sec:Results}
\emph{\textbf{System description:}} We consider the position control of a translating--rotating mass with force input $u$ and position output $y$ at opposite sides of the centre of mass, see Fig.~\ref{fig:NonminimumPhaseExample}.
Let $x_1$ be the position of the centre of mass, and $x_2$ the rotation, such that $u$, $x_1$, $x_2$ and $y$ are functions of time. Then, the continuous time dynamics are
%\begin{align}
%\begin{split}
%\label{eq:SimulationModel}
%	& J m \frac{d^4 y}{dt^4} + (f_v J + 2 l_x d m) \frac{d^3 y}{dt^3} + 2(l_x d f_v + l_x k m) \frac{d^2 y}{dt^2} \\
%	& + 2 l_x k f_v \frac{dy}{dt} = (J - l_y^2 m ) \frac{d^2 \xi }{dt^2} + (2l_x d - l_y^2 f_v)\frac{d \xi }{dt} + 2 l_x k \xi. 
%\end{split}
%\end{align}
\begin{align}
\begin{split}
\label{eq:SimulationModel}
	\ddot{x}_1 & = \frac{1}{m} \Big( -f_v\dot{x}_1 + \big( 1 + \alpha (x_1 + l_y x_2) \big) u \\
	& \quad \quad \quad - g(x_1 + l_y x_2) \Big), \\
	\ddot{x}_2 & = \frac{1}{J} \Big( - 2l_x (d\dot{x}_2	+cx_2) + \\
	& \quad l_y  \big( 1 + \alpha(x_1 + l_y x_2) \big) u - l_y g (x_1 + l_y x_2 ) \Big), \\
	y & = x_1 - l_y x_2. 
\end{split}
\end{align}
In~\eqref{eq:SimulationModel}, $l_x, l_y \in \mathbb{R}_{\geq 0}$ are the width and height of the mass $m \in \mathbb{R}_{>0}$, $J = \frac{1}{3} m(l_x^2 + l_y^2)$ is the moment of inertia, $f_v \in \mathbb{R}_{>0}$ the viscous friction coefficient, and $d, c \in \mathbb{R}_{>0}$ the damping and spring constant counteracting rotation from both ends of the mass. 
The nonlinearities $\alpha (x_1+l_yx_2)$ and $g(x_1 + l_y x_2)$ represent the force ripple and cogging force, and are \emph{unknown}. For simulation purposes, they are modelled as
\begin{align}
\begin{split}
\label{eq:RippleAndCogging}
	\alpha (x_1 + l_y x_2) & = c_{\alpha} \sin \big( \frac{2 \pi}{l_m} (x_1 + l_y x_2) + \frac{\pi}{4} \big), \\
	g (x_1 + l_y x_2) & = c_{g} \sin \big( \frac{2 \pi}{l_m} (x_1 + l_y x_2) \big) ,
\end{split}
\end{align}
with $l_m \in \mathbb{R}_{>0}$ the magnet magnet pole pitch and $c_{\alpha}, c_{g} \in \mathbb{R}$ the riple and cogging magnitude. Parameter values are listed in Table~\ref{tab:ParameterValues}.
The system~\eqref{eq:SimulationModel} is controlled in closed--loop at a frequency $F_s = 100$ $Hz$ by the ZOH discretization of
\begin{equation}
\label{eq:SimulationModelFeedback}
	C(s) = 5\cdot 10^{3} \frac{s+4\pi}{s+20 \pi}.
\end{equation}
A normally distributed noise $v(k) \sim \mathcal{N} \big( 0, (10^{-6})^2 \big)$ $m$ is added as \emph{measurement noise}. %, such that both the data set and the feedback controller use $y(k) + v(k)$ rather than $y(k)$. 
The system~\eqref{eq:SimulationModel} exhibits the following challenges for feedforward control:
\begin{enumerate}
	\item \emph{Nonlinear dynamics} on the input (force ripple) and output (cogging force), depending on an internal state;
	\item \emph{Nonminimum phase dynamics} which requires non--causal actuation to return a stable feedforward signal.
\end{enumerate}

\emph{\textbf{Data generation:}} The training data is generated in closed--loop by sampling the output $y^d(k)$ at the frequency $F_s$ for a duration of $45$ $s$. 
The reference $R^d$ is a concatenation of $15$ times the third order reference $R$ in Fig.~\ref{fig:Reference}, which has bounded velocity $| \frac{d}{dt} r^d | \leq 0.1$ $\frac{m}{s}$, acceleration $| \frac{d^2}{dt^2} r^d | \leq 4$ $\frac{m}{s^2}$ and jerk $|\frac{d^3}{dt^3} r^d | \leq 40$ $\frac{m}{s^3}$. 
Additionally, $U_{\textup{ff}}^d$ is a zero--mean white noise with variance $\sigma^2 = 10^2$ $N^2$ for $t = [10, 40)$ $s$. 


\begin{figure}
\centering
\vspace{7pt}
\includegraphics[width=0.9\linewidth]{Figures/Reference.pdf}
\caption{Reference $R$ used for performance evaluation.}
\label{fig:Reference}
\end{figure}
\begin{figure}
\centering
%\includegraphics[width=0.95\linewidth]{Figures/Norm_IdentificationInversionTrackingError_A_LogY_V2.pdf}
%\includegraphics[width=0.95\linewidth]{Figures/Norm_IdentificationInversionTrackingError_B_LogY_V2.pdf}
%\includegraphics[width=0.91\linewidth]{Figures/Norms_IdentificationInversionTrackingError.pdf}
\includegraphics[width=1.0\linewidth]{Figures/Neurons_IdInvTr_V2.pdf}
%\caption{Normalized $2$--norm of the identification ($Y^d - \hat{Y}^d$), inversion ($R - \hat{Y}$) and tracking ($R-Y$) error for PGNNs with different number of neurons using $\gamma = 10^{-6}$ (top window) and $\gamma = 5 \cdot 10^{-5}$ (bottom window).}
\caption{Normalized $2$--norm of the identification ($Y^d - \hat{Y}^d$, $N = N_d$), inversion ($R - \hat{Y}$, $N=N_k$) and tracking ($R-Y$, $N = N_k$) error for PGNNs with different number of neurons using $\gamma = 2 \cdot 10^{-4}$ (left window) and $\gamma = 10^{-3}$ (right window).}
\label{fig:TrackingErrorsNeurons}
\end{figure}

\emph{\textbf{Model parametrization:}} We parameterize the system~\eqref{eq:SimulationModel} with a state--space PGNN as
\begin{align}
\begin{split}
\label{eq:StateSpacePGNN}
	\dot{\hat{x}} &= A(\theta_{\textup{phy}}) \hat{x} + B(\theta_{\textup{phy}})\big( \hat{u} + f_{\textup{NN}} (\theta_{\textup{NN}}, \hat{x}, \hat{u}) \big), \\
	\hat{y} & = C(\theta_\textup{phy}) \hat{x}, 
\end{split}
\end{align}
where $\hat{u}$, $\hat{x}$ and $\hat{y}$ are functions of time,~$f_{\textup{NN}} :\mathbb{R}^{n_{\theta_{\textup{nn}}}} \times \mathbb{R}^{4} \times \mathbb{R} \rightarrow \mathbb{R}^4$ is a NN, and $\theta = [\theta_{\textup{phy}}^T, \theta_{\textup{NN}}^T]^T$ with $\theta_{\textup{phy}}$ representing the physical parameters, and $\theta_{\textup{NN}}$ the NN weights and biases. 
The NN has a single hidden layer with $n_1 \in \mathbb{Z}_{\geq 0}$ neurons, which we can vary. 
We discretize~\eqref{eq:StateSpacePGNN} using ZOH while assuming that $f_{\textup{NN}}$ remains constant in between two samples. 

%\emph{\textbf{Model parameterization:}} We parameterize the system with an input--output PGNN model~\eqref{eq:PGNN} as proposed in~\cite{Bolderman2021}, with a \emph{linear physical model} and a \emph{black--box NN} with one hidden layer with $n_1$ neurons using $\tanh$ activation, i.e.,
%\begin{equation}
%\label{eq:SimulationPGNN}
%	\hat{y}(k) = \theta_{\textup{phy}}^T \phi(k) + W_2 \tanh \big( W_1 \phi(k) + B_1 \big) + B_2.
%\end{equation}
%In~\eqref{eq:SimulationPGNN},~$\theta_{\textup{NN}} = [\textup{col}(W_1)^T, B_1^T, \textup{col}(W_2)^T, B_2^T]^T$, where $\textup{col}(W_i)$ stacks the columns of $W_i$. 
%ZOH discretization of the linear part of~\eqref{eq:SimulationModel} gives $n_a = n_b = 4$, $n_k = 0$ in~$\phi(k)$. 

\emph{\textbf{System identification:}} The PGNN parameters are identified according to~\eqref{eq:IdentificationCriterion} with feedforward control--oriented identification cost function~\eqref{eq:CostFunction_FeedforwardControl} (using the \emph{lsqnonlin} MATLAB function) with $\Lambda = 10^{-5} [\textup{diag}(\theta_{\textup{phy}}^T)^{-1} , 0]$, $\theta^* = [{\theta_{\textup{phy}}^*}^T, 0]^T$, and $\theta_{\textup{phy}}^*$ the parameters obtained for the linear part of~\eqref{eq:StateSpacePGNN}. 

\emph{\textbf{Feedforward:}} The feedforward signal $U_{\textup{ff}}$ has length $N_k = 300$ and is computed by solving the FHOFC~\eqref{eq:FHOFCP} while penalizing the rate of change in $U_{\textup{ff}}$ by choosing
%\begin{equation}
%\label{eq:RegularizationR}
%	\Gamma = \gamma \begin{bmatrix} 1 & 0 & \hdots \\ -1 & 1 & \ddots \\ 0 & \ddots & \ddots \end{bmatrix},
%\end{equation}
%\begin{equation}
%\label{eq:RegularizationR}
	$\Gamma = \gamma \Delta,$
%\end{equation}
with $\gamma \in \mathbb{R}_{\geq 0}$ the importance of the regularization and $\Delta \in \mathbb{R}^{N_k \times N_k}$ has $1$ on the diagonal, $-1$ on the subdiagonal and $0$ elsewhere.
Solving the FHOFC~\eqref{eq:FHOFCP} converges in $7$ $s$ with \emph{lsqnonlin} on a $2.59$ $GHz$ Intel Core--I7--9750H using MATLAB 2019A.
%where $\Delta \in \mathbb{R}^{N_k \times N_k}$ has $1$ on the diagonal, $-1$ on the subdiagonal, and $0$ elsewhere, and $\gamma \in \mathbb{R}_{\geq 0}$ states the importance of the regularization. 
%where $\gamma \in \mathbb{R}_{\geq 0}$ states the importance of the regularization. 

\emph{\textbf{Results:}} Fig.~\ref{fig:TrackingErrorsNeurons} visualizes the $2$--norm of the identification, inversion and tracking error in~\eqref{eq:UpperboundPerformance} for the reference $R$ in Fig.~\ref{fig:Reference} using different number of neurons $n_1$, with $\gamma = 2\cdot 10^{-4}$ (left window) and $\gamma = 1 \cdot 10^{-3}$ (right window). 
Increasing the number of neurons $n_1$ in the model~\eqref{eq:StateSpacePGNN} improves the accuracy of the identification.
%Due to the nonlinearity present in the system~\eqref{eq:SimulationModel}, the identification error becomes smaller when increasing the number of neurons $n_1$. 
For $\gamma = 2\cdot 10^{-4}$ the inversion error is small, such that the tracking error is limited by the accuracy of the identification.
%Since the inversion is performed accurately for $\gamma = 10^{-8}$, this translates into a smaller tracking error, i.e., the accuracy of the identification is limiting performance. 
In contrast, for $\gamma = 10^{-3}$ the inversion error increases, which limits the achievable performance for $n_i > 12$. 
Comparing the upperbound~\eqref{eq:UpperboundPerformance} with the results in Fig.~\ref{fig:TrackingErrorsNeurons} indicates that $\varepsilon$ is small.
%For this example, we observe that $\varepsilon$ in~\eqref{eq:UpperboundTrackingErrorB} is close to zero.
Correspondingly, hyperparameters can be tuned based on~\eqref{eq:UpperboundPerformance}, e.g., Fig.~\ref{fig:TrackingErrorsNeurons} shows that at least $n_l = 16$ neurons are required to achieve $\frac{1}{\sqrt{N_k}} \| E \|_2 < 10^{-4}$~$m$. 
%Correspondingly, can be used for hyperparameter tuning, e.g., Fig.~\ref{fig:TrackingErrorsNeurons} shows that at least $n_1 = 12$ neurons are required to achieve $\frac{1}{\sqrt{N_k}} \| E \|_2 < 2 \cdot 10^4$~$m$. %to aim for a desired reference tracking performance a priori by performing the identification and inversion sufficiently accurate. 
%, such that Lemma~\ref{le:UpperboundPerformance} gives a clear performance indication. , which indicates that Lemma~\ref{le:UpperboundPerformance} has significant use in validating performance before applying the feedforward to the system.



Fig.~\ref{fig:ILCImprovements} shows the $2$--norm of the tracking error for a linear and a PGNN model over multiple iterations of the reference $R$ in Fig.~\ref{fig:Reference} when using the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent}.
Since both approaches reach the noise--floor, results are added where $v(k) = 0$ to emphasize the benefit of the nonlinear PGNN model structure. 
The IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} with nonlinear PGNN model yields a significant reduction in the number of iterations required to reach a target performance.  
%The ability of the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} to handle nonlinear models, yields significantly less required iterations to
%The ability of the IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} to handle nonlinear models creates a faster convergence of the tracking error, such that fewer iterations are required to achieve a desired performance. 
%Since both approaches reach the noise--floor, results are added where $v(k) = 0$ to emphasize the benefit of the nonlinear PGNN model structure.
%The tracking error converges both faster, and to a lower value when using the PGNN model.
%After $6$ repetitions the normalized $2$--norm of the tracking error with $v(k) = 0$ is $4.96 \cdot 10^{-9}$~$m$ for the PGNN and $1.14 \cdot 10^{-8}$~$m$ for the linear model, respectively. 
% i.e., $\| r - y \|_2$ after $6$ repetitions is $7.78 \cdot 10^{-8}$ $m$ for the PGNN, and $2.08 \cdot 10^{-7}$ $m$ for the linear model. 

\begin{figure}
\centering
\vspace{7pt}
%\includegraphics[width=1.0\linewidth]{Figures/ILC_Improvements_V3_Alpha09_R1e-3_V2.pdf}
%\includegraphics[width=0.98\linewidth]{Figures/ILC_Improvements_V3_Alpha1_R1e-3.pdf}
\includegraphics[width=1.0\linewidth]{Figures/ILC_Results_V2.pdf}
%\caption{Normalized $2$--norm of the tracking error over the iterations using IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} with $\alpha = 1$ and $\gamma = 10^{-8}$ using a linear and a PGNN~\eqref{eq:SimulationPGNN} model with $n_1 = 32$, simulated with ($+$) and without ($\times$) noise $v(k)$.}
\caption{Normalized $2$--norm of the tracking error over the iterations using IL--FHOFC~\eqref{eq:NonlinearILCEquivalent} with $\alpha = 1$, $\gamma = 10^{-5}$ and $Q_m = I$ using a linear and a PGNN~\eqref{eq:StateSpacePGNN} model with $n_1 = 24$, simulated with $v(k) \sim \mathcal{N} \big( 0, (10^{-6})^2 \big)$ (left window) and with $v(k) = 0$ (right window).}
\label{fig:ILCImprovements}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}
\label{sec:Conclusions}
In this paper, we presented a generalized approach to nonlinear data--driven feedforward control design from the perspective of minimizing tracking errors.
%The norm of the reference tracking error was upperbounded by the inversion and the identification error, respectively. 
We showed that the norm of the reference tracking error is upperbounded by the sum of the inversion and the identification error, respectively. 
%It was demonstrated that the achieved tracking performance is upperbounded by the inversion error and the identification error.
This resulted in a two--step approach to feedforward control design, consisting of a feedforward control--oriented system identification followed by a finite--horizon optimization to compute the feedforward input signal.
Generality of the FHOFC formulation was demonstrated by recovering inverse model--based feedforward and linear ILC for specific settings.
%It was demonstrated how inversion--based feedforward control and ILC fit in the general formulation of the FHOFC problem. 
%The developed methodology was validated using physics--guided neural networks on a nonlinear, nonminimum phase mechatronic example, where it outperformed a standard ILC method.
%Finally, it was demonstrated in simulation using physics--guided neural networks that the proposed methodology significantly improves tracking performance. 

%Future work will focus on efficiently solving the FHOFC problem and developing automatic retraining algorithms based on the fundamental upperbound on tracking performance derived in this work.








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\addtolength{\textheight}{-0.22cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%\section*{APPENDIX}
%Appendixes should appear before the acknowledgment.







\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,References}




\end{document}
