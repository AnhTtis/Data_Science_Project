@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{doughty2020action,
  title={Action modifiers: Learning from adverbs in instructional videos},
  author={Doughty, Hazel and Laptev, Ivan and Mayol-Cuevas, Walterio and Damen, Dima},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{doughty2022you,
  title={How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs},
  author={Doughty, Hazel and Snoek, Cees GM},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{miech19howto100m,
   title={How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
   author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
   booktitle={ICCV},
   year={2019},
}

@inproceedings{miech19endtoend,
   title={{E}nd-to-{E}nd {L}earning of {V}isual {R}epresentations from {U}ncurated {I}nstructional {V}ideos},
   author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
   booktitle={CVPR},
   year={2020},
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{wang2019vatex,
  title={Vatex: A large-scale, high-quality multilingual dataset for video-and-language research},
  author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{kingma2015adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR},
  year={2015}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  booktitle={JMLR},
  year={2014},
}

@inproceedings{pang2018human,
  title={Human action adverb recognition: Adha dataset and a three-stream hybrid model},
  author={Pang, Bo and Zha, Kaiwen and Lu, Cewu},
  booktitle={CVPR (workshop)},
  year={2018}
}

@inproceedings{pang2020further,
  title={Further understanding videos through adverbs: A new video task},
  author={Pang, Bo and Zha, Kaiwen and Zhang, Yifan and Lu, Cewu},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{fan2016video,
  title={Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
  author={Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
  booktitle={ACM - Multimodal interaction},
  year={2016}
}

@inproceedings{anne2017localizing,
  title={Localizing moments in video with natural language},
  author={Anne Hendricks, Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{gao2017tall,
  title={Tall: Temporal activity localization via language query},
  author={Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{wang2019language,
  title={Language-driven temporal activity localization: A semantic matching reinforcement learning model},
  author={Wang, Weining and Huang, Yan and Wang, Liang},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{mun2020local,
  title={Local-global video-text interactions for temporal grounding},
  author={Mun, Jonghwan and Cho, Minsu and Han, Bohyung},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{zeng2020dense,
  title={Dense regression network for video grounding},
  author={Zeng, Runhao and Xu, Haoming and Huang, Wenbing and Chen, Peihao and Tan, Mingkui and Gan, Chuang},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{dong2019dual,
  title={Dual encoding for zero-example video retrieval},
  author={Dong, Jianfeng and Li, Xirong and Xu, Chaoxi and Ji, Shouling and He, Yuan and Yang, Gang and Wang, Xun},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{liu2019use,
  title={Use what you have: Video retrieval using representations from collaborative experts},
  author={Liu, Yang and Albanie, Samuel and Nagrani, Arsha and Zisserman, Andrew},
  booktitle=BMVC},
  year={2019}
}

@inproceedings{yang2021taco,
  title={Taco: Token-aware cascade contrastive learning for video-text alignment},
  author={Yang, Jianwei and Bisk, Yonatan and Gao, Jianfeng},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{mithun2018learning,
  title={Learning joint embedding with multimodal cues for cross-modal video-text retrieval},
  author={Mithun, Niluthpol Chowdhury and Li, Juncheng and Metze, Florian and Roy-Chowdhury, Amit K},
  booktitle={ACM - Multimedia Retrieval},
  year={2018}
}

@inproceedings{chen2020fine,
  title={Fine-grained video-text retrieval with hierarchical graph reasoning},
  author={Chen, Shizhe and Zhao, Yida and Jin, Qin and Wu, Qi},
  booktitle={CVPR 2020},
  year={2020}
}

@inproceedings{xu2015jointly,
  title={Jointly modeling deep video and compositional text to bridge vision and language in a unified framework},
  author={Xu, Ran and Xiong, Caiming and Chen, Wei and Corso, Jason},
  booktitle={AAAI},
  year={2015}
}

@inproceedings{wray2019fine,
  title={Fine-grained action retrieval through multiple parts-of-speech embeddings},
  author={Wray, Michael and Larlus, Diane and Csurka, Gabriela and Damen, Dima},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{yu2017end,
  title={End-to-end concept word detection for video captioning, retrieval, and question answering},
  author={Yu, Youngjae and Ko, Hyungjin and Choi, Jongwook and Kim, Gunhee},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{sun2022human,
  title={Human action recognition from various data modalities: A review},
  author={Sun, Zehua and Ke, Qiuhong and Rahmani, Hossein and Bennamoun, Mohammed and Wang, Gang and Liu, Jun},
  booktitle={TPAMI},
  year={2022},
}

@inproceedings{li2022compositional,
  title={Compositional temporal grounding with structured variational cross-graph correspondence learning},
  author={Li, Juncheng and Xie, Junlin and Qian, Long and Zhu, Linchao and Tang, Siliang and Wu, Fei and Yang, Yi and Zhuang, Yueting and Wang, Xin Eric},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{vahdani2022deep,
  title={Deep learning-based action detection in untrimmed videos: A survey},
  author={Vahdani, Elahe and Tian, Yingli},
  booktitle={TPAMI},
  year={2022},
}

@inproceedings{heidarivincheh2018action,
  title={Action completion: A temporal model for moment detection},
  author={Heidarivincheh, Farnoosh and Mirmehdi, Majid and Damen, Dima},
  booktitle={BMVC},
  year={2018}
}

@inproceedings{doughty2019pros,
  title={The pros and cons: Rank-aware temporal attention for skill determination in long videos},
  author={Doughty, Hazel and Mayol-Cuevas, Walterio and Damen, Dima},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{doughty2018s,
  title={Who's better? who's best? pairwise deep ranking for skill determination},
  author={Doughty, Hazel and Damen, Dima and Mayol-Cuevas, Walterio},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{feichtenhofer2021large,
  title={A large-scale study on unsupervised spatiotemporal representation learning},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Xiong, Bo and Girshick, Ross and He, Kaiming},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{wang2017untrimmednets,
  title={Untrimmednets for weakly supervised action recognition and detection},
  author={Wang, Limin and Xiong, Yuanjun and Lin, Dahua and Van Gool, Luc},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{xie2018rethinking,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={NeurIPS},
  year={2014}
}

@inproceedings{moltisanti2017trespassing,
  title={Trespassing the boundaries: Labeling temporal bounds for object interactions in egocentric video},
  author={Moltisanti, Davide and Wray, Michael and Mayol-Cuevas, Walterio and Damen, Dima},
  booktitle={ICCV},
  year={2017}
}


@inproceedings{alwassel2018diagnosing,
  title={Diagnosing error in temporal action detectors},
  author={Alwassel, Humam and Heilbron, Fabian Caba and Escorcia, Victor and Ghanem, Bernard},
  booktitle={ECCV},
  year={2018}
}


@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  year={2017}
}

@software{ines_montani_2022_7310816,
  author       = {Ines Montani and
                  Matthew Honnibal and
                  Matthew Honnibal and
                  Sofie Van Landeghem and
                  Adriane Boyd and
                  Henning Peters and
                  Paul O'Leary McCann and
                  jim geovedi and
                  Jim O'Regan and
                  Maxim Samsonov and
                  Duygu Altinok and
                  György Orosz and
                  Daniël de Kok and
                  Søren Lind Kristiansen and
                  Raphaël Bournhonesque and
                  Madeesh Kannan and
                  Lj Miranda and
                  Peter Baumgartner and
                  Edward and
                  Explosion Bot and
                  Richard Hudson and
                  Roman and
                  Leander Fiedler and
                  Raphael Mitsch and
                  Ryn Daniels and
                  Grégory Howard and
                  Wannaphong Phatthiyaphaibun and
                  Yohei Tamura and
                  Sam Bozek},
  title        = {{explosion/spaCy: v3.4.3: Extended Typer support 
                   and bug fixes}},
  month        = nov,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v3.4.3},
  doi          = {10.5281/zenodo.7310816},
  url          = {https://doi.org/10.5281/zenodo.7310816}
}