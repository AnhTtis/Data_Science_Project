\section{Conclusion}
\label{sec:conclusion}
This paper proposes a new LiDAR augmentation method to remedy the sensor-bias issue in LiDAR semantic segmentation models. Our method efficiently transforms real-world LiDAR data to another LiDAR domain having the desired configuration. Due to its efficiency, our method can be deployed as an online data augmentation module in the learning frameworks, which leads us to call our method instant domain augmentation. Our method does not require access to any target data, so it encourages models to learn a sensor-agnostic representation by providing random LiDAR configurations of data. Extensive experiments show that training with our method significantly improves the LiDAR semantic segmentation performance in the unseen datasets collected by a different LiDAR.
\vspace{2mm}


\noindent\textbf{Limitation and future work.}
Our method requires accurate 6-DoF ego-motions to construct the world models, but it could be estimated by off-the-shelf LiDAR SLAM method~\cite{bai2022fasterlio}. Our method is crafted for a cylindrical LiDAR, the most common type utilized in most of the existing public datasets. However, our trivial extension to a more complex setting, i.e., two LiDAR settings consisting of a solid-state LiDAR and a cylindrical LiDAR, shows a promising result (see Section \textcolor{red}{E} in the supplement). Since our method can be used for a generic LiDAR domain augmentation, our future work is to apply our method to other 3D perception tasks, such as object detection or instance semantic segmentation.
