


In this section we present the main results of our experiments. Further evaluations are added in the supplementary material which also includes all the implementation details as well as the code. Our PyTorch implementation covers all the methods evaluated in the benchmark to guarantee maximal transparency and reproducibility. It can also easily include other methods for future benchmark extensions. Unless stated otherwise, for all the experiments 
we adopted the same validation protocol described in \cite{zietlow2022leveling}.



\subsection{Classification Results}
For the binary classification tasks, we organize the tables with different horizontal sections that group the cross-domain methods by family. 
The bottom part of the tables contains the SOTA fairness approaches. 
Besides the standard metrics and our newly introduced $\sigma(HF)$ we consider
$\Delta DTO = DTO_b - DTO_m$: as the baseline is fixed and shared by all the methods, $\Delta DTO$ ranks the methods exactly as $DTO$ but makes the tables easier to read.


\textbf{The results on CelebA} are presented in Table \ref{tab:celebaA_EB_C} and focus on the two most challenging attributes: \emph{EyeBags} and \emph{Chubby}. Out of the whole set of 13 attributes (complete results in the supplementary), they are the ones with the highest $DA$ and lowest $Acc$. 
By focusing on both $\sigma(HF)$ and $\Delta DTO$ we can state that several cross-domain methods provide an accuracy and fairness gain over the baseline, and are also able to improve over the SOTA fairness methods which appear particularly inefficient on Chubby. The AFN approach shows the best performance, followed by DANN on Eyebags and SagNets on Chubby.  
%% leave space%%

Regarding the metrics,
$\Delta DTO$ and $\sigma(HF)$ 
agree on the general ranking. On the other hand, neither $mGA$ nor $DA$ is sufficiently informative. For instance on Eyebags, RelRot and RelRotAlign have the same $mGA$, while both their $\Delta DTO$ and $\sigma(HF)$ are significantly different, with RelRotAlign even worsening the baseline. Moreover, the best $DA$ result of RelRotAlign is clearly misleading as it comes with a noteworthy decrease in Acc. 
%
Finally, we notice 
how $DEO$ and $DEOdds$ for Chubby reward the \emph{leveling down} behavior already criticized in \cite{zietlow2022leveling}, by largely relying on $DA$ without considering the decrease in $MGA$ and $mGA$ with respect to the baseline.  

\textbf{The results on COVID-19 Chest X-Ray and Fizpatrick17} are presented in Table \ref{tab:covid+melanoma}. 
On the first dataset, 
according to both $\Delta DTO$ and $\sigma(HF)$, RSC is the top method and RelRotAlign is the second best, while AFN ranks third. 
%
Interestingly, now 
the rankings of DANN and SagNets differ depending on the used metric: 
$\sigma(HF)$ rewards the former, more than the latter. DANN has a significant advantage in $mGA$ despite a loss in $MGA$,  while SagNets shows a minimal increase in both $mGA$ and $MGA$ in spite of a worse discrepancy among the groups.
%
Even in this case it is clear that referring only to $mGA$ may not be sufficient to differentiate among the methods as many of them share the exact same value for this metric. 

The results on Fizpatrick17 lead to similar conclusions, with RelRot and LSR presenting the best results. DANN, which was among the top methods for CelebA, now ranks sixth among all the CD approaches and still shows results comparable with the best SOTA fairness approach.

Overall, the exact the family that best suits each classification task may vary (feature alignment and adversarial training methods for faces, regularization-based and self-supervised approaches for medical images), but the results confirm the effectiveness of cross-domain learning for unfairness mitigation and the relevance of our study. 




\input{figure_landmark_curves}
\input{table_landmark}
\subsection{Landmark Detection Results}
The performance of a model which locates keypoints on facial components may be affected by a change in \emph{skin tone} and \emph{age}, resulting in a less precise prediction in case of high melanin pigmentation or wrinkles. To investigate the presence of a bias related to these demographics we run experiments on the UTK Face dataset and we verify the effectiveness of correction strategies based on cross-domain learning by considering RegDA together with AFN and DANN, as they have shown successful results in classification on face images. The training procedure follows the one presented in \cite{jiang2021regda}, with validation protocol in line with that of \cite{zietlow2022leveling}. 
%
We assess the performance of the methods by considering both our $\sigma(HF)$ and $\Delta DTO$ obtained from $SDR$ calculated with a standard 8\% $NME$ threshold \cite{mccouat2022contour}. 

Table \ref{tab:landmark} shows how the baseline reference has an unfair behavior with more than 5\% difference in group accuracy ($DS$). All the cross-domain methods provide an advantage: in particular, RegDA ranks higher or equal to AFN, and they are both better than DANN. The latter shows a large improvement in $MGS$ and $mGS$ when the sensitive attribute is age, but the group discrepancy appears worse than the baseline.  
%
By reducing the $NME$ threshold the evaluation becomes progressively more demanding until the extreme of considering a predicted point as successful only if it perfectly overlaps with the ground truth. The curves in Figure \ref{fig:NMEth} show that even moving toward this condition most of the cross-domain methods maintain their advantage over the baseline confirming their effectiveness.  
The difference between RegDA and AFN becomes more evident at lower threshold values. In that regime $HF$ (as well as $\sigma(HF)$) and $\Delta DTO$ show different trends for RegDA with the first discouraging the use of this approach.



\input{table_celeba_transfer2}
\section{Model Transferability}
Considering the effort needed to train novel models, it is always desirable to exploit existing ones for new tasks.  
For unfairness mitigation approaches, what is learned by reducing the bias over some protected groups might be helpful also for other demographics. We study this aspect on the CelebA dataset considering \emph{EyeBags} as the target attribute with \emph{Male} and \emph{Young} as sensitive attributes.
We train and validate a classifier to recognize whether eye bags are present while learning to disregard gender-specific features through a cross-domain approach. Then, we test the obtained model by assessing how the eye bags prediction performance differs among age groups. We analyze the CD methods AFN and DANN, reporting also the results of the SOTA unfairness mitigation strategies. 
%
The top part of Table \ref{tab:celeba_transfer} shows the effect on age groups of the approaches trained to be gender agnostic while focusing on the semantic features relevant to identify the target \emph{EyeBags} attribute. The results exceed those of the baseline with a particular advantage of DANN over GroupDRO, indicating that the knowledge acquired with cross-domain learning is easily transferrable.
The bottom part of the table presents the performance of \emph{oracle} methods trained and validated with the aim of mitigating age bias. They represent an upper bound and allow to better appreciate the surprisingly competitive results of transferred cross-domain models.
We note also how the SOTA unfairness mitigation models obtain low results even in this oracle setting.
%
More experiments with inverted roles for the sensitive attributes (\textit{Young/Old} $\rightarrow$ \textit{Male/Female}) and similar settings on the landmark detection task are reported and discussed in the supplementary.
