%
\begin{figure}[tb]
\centering
\includegraphics[width=0.93\linewidth]{metrics.pdf}
\caption{Left: $C1$ and $C2$ have the same $DEO$ but $C1$ is clearly preferable to $C2$. Right: $C2$ has a higher $mGA$ than $C1$, but it also has a higher $DA$. Neither $DEO$ nor $mGA$ are sufficient for selecting a fair classifier with respect to sensitive attribute $a$. 
}\vspace{-4mm}
\label{fig:hist_fair}
\end{figure}

To formalize the problem of fairness we start by defining a data sample as $(\bx,y,a)$, where $\bx$ is an image, $y$ is its semantic label and $a$ is a sensitive attribute. 
In the simplest case, the labels are binary $y \in \{0,1\}$  (\eg for faces, eye bags  yes/no), and the same holds for the attributes $a \in \{0,1\}$ (\eg male/female or young/old). 
%
Given a set of annotated data spanning all the semantic labels and attributes, the goal is to learn a classifier $\hat{y}=f(\bx)$ that correctly predicts the label and achieves certain group fairness criteria with respect to $a$. 
These criteria mainly focus on the difference in performance between privileged and disadvantaged data groups associated with distinct attributes (see section \ref{sec:criteria}).

The presented fairness problem shares some common traits with that of cross-domain learning, where source $(\bx^s,y^s)\sim p^s$ and target $(\bx^t,y^t)\sim p^t$ data differ on the basis of the distribution from which they are drawn. The information about the distribution is usually summarized by a label indicating the data type: considering one source and one target domain, it holds  $d \in \{0,1\}$ (\eg photos/sketches). 
By simply switching $d$ with $a$ in the SDA setting we get to the framework described for the fairness problem.
%
As SDA can leverage the whole cross-domain literature, there is a large set of methods that can be applied and evaluated for unfairness mitigation. Some of them have been considered in previous fairness-related publications (\eg discrepancy, adversarial, and disentanglement strategies), but a thorough benchmark is still missing. As discussed in the following, letting cross-domain learning \emph{meet} fairness may lead to new evaluation strategies and interesting research questions.
