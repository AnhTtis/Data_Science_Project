
For our analysis, we focus on two tasks that may be affected by fairness issues: attribute recognition and landmark detection. For the former, we consider two binary classification scenarios based on face and medical images.
For the latter, we focus on localizing keypoints on face images. To our knowledge, we are the first to study the impact of unfairness on landmark detection and to propose for it cross-domain learning as a possible solution. 



\input{table_celeba_eyebags_chubby2}

\subsection{Datasets}
\noindent\textbf{CelebFaces Attribute (CelebA)} \cite{liu2015faceattributes}
comprises 202,599 RGB face images of celebrities, each with 40 binary attribute annotations. 
We focus on the same subset of 13 reliable target attributes considered in \cite{ramaswamy2021fair,zietlow2022leveling}.
We select \textit{male} and \textit{young} as protected attributes, and adopt the same setting of \cite{zietlow2022leveling}, based on the official train/val/test splits. 

\noindent\textbf{COVID-19 Chest X-Ray} \cite{cohen2020covidProspective} is composed of 719 images of chest x-ray coming from different online sources showing scans of patients affected by pulmonary diseases. Each image has a structured label describing many attributes of the patient.  
We focus on the \textit{finding} attribute as target, considering the COVID-19 pathology, while \textit{gender} is selected as sensitive attribute. 
We split the dataset into 80/20\% training/test sets, using 20\% of the training split for validation.

\noindent\textbf{Fitzpatrick17k} \cite{groh2021evaluating} is a collection of 16,577 clinical images depicting 114 skin conditions from two dermatology atlases.
The images are annotated with the six Fitzpatrick skin type labels, that describe the skin phenotype's sun reactivity. The dataset is widely used in algorithmic fairness research \cite{zong2023medfair}. 
We classify whether the dermatological condition in each picture is either \emph{benign/non-neoplastic} or \emph{malignant} and we use \emph{skin tone} as the protected attribute, keeping only the examples belonging to \emph{skin type I} (light) and \emph{skin type VI} (dark) of the Fitzpatrick scale. We split the dataset into 80/20\% training/test sets, using 20\% of the training split for validation.

\noindent\textbf{UTK Face} \cite{zhang2017age} consists of over 20k RGB face images
characterized by great variability in terms of pose, facial expression, illumination, \etc., and present age, gender, and race annotations.
We focus on landmark localization (68 points) considering the values \emph{white} and \emph{black} of the label \textit{race}
as protected groups for the experiments related to \emph{skin tone}. Moreover, we define the \emph{young} and \emph{old} groups by collecting respectively samples with the value of label \emph{age} in 0-10 and 40-50 years old.
Training/test division is in the proportion 80/20\% with 20\% of the training split used for validation.




\subsection{Reference Methods}
\noindent\textbf{Baselines.} 
For our classification experiments we follow the fairness literature \cite{zietlow2022leveling,sagawa2019distributionally} adopting as baseline ResNet50 with standard cross-entropy minimization objective, pre-trained on ImageNet. 
For landmark detection we follow \cite{jiang2021regda,simple_baseline_landmark} and consider ResNet18 pre-trained on ImageNet with a dedicated head composed of deconvolutional layers. It is optimized with an $L2$ loss to reduce the discrepancy between the predicted probability distribution of the location of each landmark and the ground truth.

\noindent\textbf{Fairness References.}
We consider three SOTA  
unfairness mitigation methods. GroupDRO~\cite{sagawa2019distributionally}
minimizes the worst-case training loss over a set of pre-defined groups. FSCL~\cite{park2022fair} re-designs supervised contrastive learning to ensure fairness by paying attention to the choice of the negative samples and to the distribution of the anchors between data groups. Finally, g-SMOTE~\cite{zietlow2022leveling} is a generative approach that reduces unfairness by synthesizing new samples of the most disadvantaged group.
All of them focus on classification problems while we are not aware of works dedicated to unfairness mitigation on landmark detection. 

\noindent\textbf{Cross-Domain Models.}
We investigate methods from four main families. 
%
The \emph{regularization-based approaches} include all the techniques designed to prevent overfitting with a consequent boost in the model generalization ability. 
LSR~\cite{szegedy2016rethinking} encourages the model to avoid overconfidence by smoothing data annotation.
SWAD~\cite{cha2021swad} searches for flat minima. 
RSC~\cite{huang2020self} is based on a refined drop-out.
L2D~\cite{wang2021learning} includes a module trained to synthesize new images with a style distribution complementary to that of the training data.
%
The models based on \emph{Adversarial training} encode domain-invariant representations by preventing the network to recognize the domains.
In DANN~\cite{ganin2016domain} the gradient computed by a domain discriminator is inverted while learning the data representation. 
CDANN~\cite{li2018deep} improves over DANN by matching the conditional data distributions across domains rather than the marginal distributions. 
Finally, SagNets~\cite{nam2021reducing} introduces dedicated data randomizations to disentangle style from class encodings.
%
\emph{Feature alignment} models involve training objectives that minimize domain distance measures.
AFN~\cite{xu2019larger} measures domain shift by comparing the feature norms of two domains and adapts them to a common large value. 
MMD~\cite{sejdinovic2013equivalence} minimizes the homonym metric to reduce the domain discrepancy. 
Lastly, Fish~\cite{shi2021gradient} proposes to align the domain distributions by maximizing the inner product between their gradients.
%
\emph{Self-Supervised Learning}-based techniques exploit auxiliary self-supervised tasks to let the network focus on semantic-relevant features.
RelRot~\cite{bucci2020effectiveness} predicts the relative orientation between a reference image (anchor) and the rotated counterpart as auxiliary task.
%
Here we also consider a variant
that we name RelRotAlign to encourage the domain alignment using as anchor a sample with the same target attribute but from a different protected group. SelfReg~\cite{kim2021selfreg}, exploited contrastive losses to regularize the model and guide it to learn domain-invariant representations.

\input{table_covidcxr+fizpatrick2}

\noindent\textbf{Landmark Detection.}
The community has dedicated less attention to domain adaptive approaches for keypoint detection. For our analysis, we consider the recent RegDA~\cite{jiang2021regda} that was developed to target human pose estimation and introduced an adversarial regressor based on the 
Kullback-Leibler divergence between domains to narrow their gap.
We also extend  DANN~\cite{ganin2016domain} and AFN~\cite{xu2019larger} to this task.
