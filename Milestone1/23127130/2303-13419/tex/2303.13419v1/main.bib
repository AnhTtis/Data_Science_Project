@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{gururangan2021demix,
  title={Demix layers: Disentangling domains for modular language modeling},
  author={Gururangan, Suchin and Lewis, Mike and Holtzman, Ari and Smith, Noah A and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2108.05036},
  year={2021}
}

@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}

@article{dai2021knowledge,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Chang, Baobao and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08696},
  year={2021}
}

@inproceedings{meng2022locating,
  title={Locating and editing factual associations in gpt},
  author={Meng, Kevin and Bau, David and Andonian, Alex J and Belinkov, Yonatan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{gao2021condenser,
  title={Condenser: a pre-training architecture for dense retrieval},
  author={Gao, Luyu and Callan, Jamie},
  journal={arXiv preprint arXiv:2104.08253},
  year={2021}
}

@article{mao2022biases,
  title={The biases of pre-trained language models: An empirical study on prompt-based sentiment analysis and emotion detection},
  author={Mao, Rui and Liu, Qian and He, Kai and Li, Wei and Cambria, Erik},
  journal={IEEE Transactions on Affective Computing},
  year={2022},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{gao2019target,
  title={Target-dependent sentiment classification with BERT},
  author={Gao, Zhengjie and Feng, Ao and Song, Xinyu and Wu, Xi},
  journal={Ieee Access},
  volume={7},
  pages={154290--154299},
  year={2019},
  publisher={IEEE}
}

@article{xiong2020approximate,
  title={Approximate nearest neighbor negative contrastive learning for dense text retrieval},
  author={Xiong, Lee and Xiong, Chenyan and Li, Ye and Tang, Kwok-Fung and Liu, Jialin and Bennett, Paul and Ahmed, Junaid and Overwijk, Arnold},
  journal={arXiv preprint arXiv:2007.00808},
  year={2020}
}

@article{taher2020beheshti,
  title={Beheshti-NER: Persian named entity recognition using BERT},
  author={Taher, Ehsan and Hoseini, Seyed Abbas and Shamsfard, Mehrnoush},
  journal={arXiv preprint arXiv:2003.08875},
  year={2020}
}

@inproceedings{sun2021rpbert,
  title={RpBERT: a text-image relation propagation-based BERT model for multimodal NER},
  author={Sun, Lin and Wang, Jiquan and Zhang, Kai and Su, Yindu and Weng, Fangsheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13860--13868},
  year={2021}
}

@article{yang2019simple,
  title={Simple applications of BERT for ad hoc document retrieval},
  author={Yang, Wei and Zhang, Haotian and Lin, Jimmy},
  journal={arXiv preprint arXiv:1903.10972},
  year={2019}
}

@article{jiang2020cross,
  title={Cross-lingual information retrieval with BERT},
  author={Jiang, Zhuolin and El-Jaroudi, Amro and Hartmann, William and Karakos, Damianos and Zhao, Lingjun},
  journal={arXiv preprint arXiv:2004.13005},
  year={2020}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{bromley1993signature,
  title={Signature verification using a" siamese" time delay neural network},
  author={Bromley, Jane and Guyon, Isabelle and LeCun, Yann and S{\"a}ckinger, Eduard and Shah, Roopak},
  journal={Advances in neural information processing systems},
  volume={6},
  year={1993}
}

@article{liu2021pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={arXiv preprint arXiv:2107.13586},
  year={2021}
}

@article{tang2022dptdr,
  title={DPTDR: Deep Prompt Tuning for Dense Passage Retrieval},
  author={Tang, Zhengyang and Wang, Benyou and Yao, Ting},
  journal={arXiv preprint arXiv:2208.11503},
  year={2022}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1022--1035},
  year={2021}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{xian2018zero,
  title={Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly},
  author={Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2251--2265},
  year={2018},
  publisher={IEEE}
}

@inproceedings{mahapatra2021medical,
  title={Medical image classification using generalized zero shot learning},
  author={Mahapatra, Dwarikanath and Bozorgtabar, Behzad and Ge, Zongyuan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3344--3353},
  year={2021}
}

@article{wang2019survey,
  title={A survey of zero-shot learning: Settings, methods, and applications},
  author={Wang, Wei and Zheng, Vincent W and Yu, Han and Miao, Chunyan},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--37},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{zhuang2020comprehensive,
  title={A comprehensive survey on transfer learning},
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE},
  volume={109},
  number={1},
  pages={43--76},
  year={2020},
  publisher={IEEE}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@article{thakur2021beir,
  title={BEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models},
  author={Thakur, Nandan and Reimers, Nils and R{\"u}ckl{\'e}, Andreas and Srivastava, Abhishek and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2104.08663},
  year={2021}
}

@article{meyerson2019modular,
  title={Modular universal reparameterization: Deep multi-task learning across diverse domains},
  author={Meyerson, Elliot and Miikkulainen, Risto},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{xu2021zero,
  title={Zero-shot compositional concept learning},
  author={Xu, Guangyue and Kordjamshidi, Parisa and Chai, Joyce Y},
  journal={arXiv preprint arXiv:2107.05176},
  year={2021}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@inproceedings{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Naik, Atharva and Ashok, Arjun and Dhanasekaran, Arut Selvan and Arunkumar, Anjana and Stap, David and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5085--5109},
  year={2022}
}

@article{asai2022task,
  title={Task-aware retrieval with instructions},
  author={Asai, Akari and Schick, Timo and Lewis, Patrick and Chen, Xilun and Izacard, Gautier and Riedel, Sebastian and Hajishirzi, Hannaneh and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2211.09260},
  year={2022}
}

@article{zhang2019sentiment,
  title={Sentiment tagging with partial labels using modular architectures},
  author={Zhang, Xiao and Goldwasser, Dan},
  journal={arXiv preprint arXiv:1906.00534},
  year={2019}
}

@article{pfeiffer2020mad,
  title={Mad-x: An adapter-based framework for multi-task cross-lingual transfer},
  author={Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian},
  journal={arXiv preprint arXiv:2005.00052},
  year={2020}
}

@article{khashabi2020unifiedqa,
  title={Unifiedqa: Crossing format boundaries with a single qa system},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2005.00700},
  year={2020}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ansell2021composable,
  title={Composable sparse fine-tuning for cross-lingual transfer},
  author={Ansell, Alan and Ponti, Edoardo Maria and Korhonen, Anna and Vuli{\'c}, Ivan},
  journal={arXiv preprint arXiv:2110.07560},
  year={2021}
}

@article{foroutan2022discovering,
  title={Discovering language-neutral sub-networks in multilingual language models},
  author={Foroutan, Negar and Banaei, Mohammadreza and Lebret, Remi and Bosselut, Antoine and Aberer, Karl},
  journal={arXiv preprint arXiv:2205.12672},
  year={2022}
}

@article{yang2019simple,
  title={Simple applications of BERT for ad hoc document retrieval},
  author={Yang, Wei and Zhang, Haotian and Lin, Jimmy},
  journal={arXiv preprint arXiv:1903.10972},
  year={2019}
}

@article{pan2020transfer,
  title={Transfer learning},
  author={Pan, Sinno Jialin},
  journal={Learning},
  volume={21},
  pages={1--2},
  year={2020}
}

@article{DBLP:journals/corr/XianLSA17,
  author    = {Yongqin Xian and
               Christoph H. Lampert and
               Bernt Schiele and
               Zeynep Akata},
  title     = {Zero-Shot Learning - {A} Comprehensive Evaluation of the Good, the
               Bad and the Ugly},
  journal   = {CoRR},
  volume    = {abs/1707.00600},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.00600},
  eprinttype = {arXiv},
  eprint    = {1707.00600},
  timestamp = {Mon, 13 Aug 2018 16:48:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/XianLSA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@inproceedings{petroni-etal-2021-kilt,
    title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
    author = {Petroni, Fabio  and
      Piktus, Aleksandra  and
      Fan, Angela  and
      Lewis, Patrick  and
      Yazdani, Majid  and
      De Cao, Nicola  and
      Thorne, James  and
      Jernite, Yacine  and
      Karpukhin, Vladimir  and
      Maillard, Jean  and
      Plachouras, Vassilis  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.200",
    doi = "10.18653/v1/2021.naacl-main.200",
    pages = "2523--2544",
    abstract = "Challenging problems such as open-domain question answering, fact checking, slot filling and entity linking require access to large, external knowledge sources. While some models do well on individual tasks, developing general models is difficult as each task might require computationally expensive indexing of custom knowledge sources, in addition to dedicated infrastructure. To catalyze research on models that condition on specific information in large textual resources, we present a benchmark for knowledge-intensive language tasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia, reducing engineering turnaround through the re-use of components, as well as accelerating research into task-agnostic memory architectures. We test both task-specific and general baselines, evaluating downstream performance in addition to the ability of the models to provide provenance. We find that a shared dense vector index coupled with a seq2seq model is a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue, and yielding competitive results on entity linking and slot filling, by generating disambiguated text. KILT data and code are available at https://github.com/facebookresearch/KILT.",
}

@article{jang2023exploring,
  title={Exploring the Benefits of Training Expert Language Models over Instruction Tuning},
  author={Jang, Joel and Kim, Seungone and Ye, Seonghyeon and Kim, Doyoung and Logeswaran, Lajanugen and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2302.03202},
  year={2023}
}

@article{han2016dsd,
  title={Dsd: Dense-sparse-dense training for deep neural networks},
  author={Han, Song and Pool, Jeff and Narang, Sharan and Mao, Huizi and Gong, Enhao and Tang, Shijian and Elsen, Erich and Vajda, Peter and Paluri, Manohar and Tran, John and others},
  journal={arXiv preprint arXiv:1607.04381},
  year={2016}
}

@article{zhang2018overview,
  title={An overview of multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={National Science Review},
  volume={5},
  number={1},
  pages={30--43},
  year={2018},
  publisher={Oxford University Press}
}

@inproceedings{ruder2022modular,
  title={Modular and Parameter-Efficient Fine-Tuning for NLP Models},
  author={Ruder, Sebastian and Pfeiffer, Jonas and Ivan Vulić},
  booktitle={Proceedings of EMNLP 2022: Tutorials},
  year={2022}
}

@article{reed1993pruning,
  title={Pruning algorithms-a survey},
  author={Reed, Russell},
  journal={IEEE transactions on Neural Networks},
  volume={4},
  number={5},
  pages={740--747},
  year={1993},
  publisher={IEEE}
}

@inproceedings{voorhees2005trec,
  title={The TREC robust retrieval track},
  author={Voorhees, Ellen M},
  booktitle={ACM SIGIR Forum},
  volume={39},
  number={1},
  pages={11--20},
  year={2005},
  organization={ACM New York, NY, USA}
}

@article{nguyen2016ms,
  title={MS MARCO: A human generated machine reading comprehension dataset},
  author={Nguyen, Tri and Rosenberg, Mir and Song, Xia and Gao, Jianfeng and Tiwary, Saurabh and Majumder, Rangan and Deng, Li},
  journal={choice},
  volume={2640},
  pages={660},
  year={2016}
}

@article{gao2021unsupervised,
  title={Unsupervised corpus aware language model pre-training for dense passage retrieval},
  author={Gao, Luyu and Callan, Jamie},
  journal={arXiv preprint arXiv:2108.05540},
  year={2021}
}

@article{santhanam2021colbertv2,
  title={Colbertv2: Effective and efficient retrieval via lightweight late interaction},
  author={Santhanam, Keshav and Khattab, Omar and Saad-Falcon, Jon and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2112.01488},
  year={2021}
}

@article{dai2022promptagator,
  title={Promptagator: Few-shot dense retrieval from 8 examples},
  author={Dai, Zhuyun and Zhao, Vincent Y and Ma, Ji and Luan, Yi and Ni, Jianmo and Lu, Jing and Bakalov, Anton and Guu, Kelvin and Hall, Keith B and Chang, Ming-Wei},
  journal={arXiv preprint arXiv:2209.11755},
  year={2022}
}

@misc{bajaj_ms_2018,
	title = {{MS} {MARCO}: {A} {Human} {Generated} {MAchine} {Reading} {COmprehension} {Dataset}},
	shorttitle = {{MS} {MARCO}},
	url = {http://arxiv.org/abs/1611.09268},
	doi = {10.48550/arXiv.1611.09268},
	abstract = {We introduce a large scale MAchine Reading COmprehension dataset, which we name MS MARCO. The dataset comprises of 1,010,916 anonymized questions---sampled from Bing's search query logs---each with a human generated answer and 182,669 completely human rewritten generated answers. In addition, the dataset contains 8,841,823 passages---extracted from 3,563,535 web documents retrieved by Bing---that provide the information necessary for curating the natural language answers. A question in the MS MARCO dataset may have multiple answers or no answers at all. Using this dataset, we propose three different tasks with varying levels of difficulty: (i) predict if a question is answerable given a set of context passages, and extract and synthesize the answer as a human would (ii) generate a well-formed answer (if possible) based on the context passages that can be understood with the question and passage context, and finally (iii) rank a set of retrieved passages given a question. The size of the dataset and the fact that the questions are derived from real user search queries distinguishes MS MARCO from other well-known publicly available datasets for machine reading comprehension and question-answering. We believe that the scale and the real-world nature of this dataset makes it attractive for benchmarking machine reading comprehension and question-answering models.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and Rosenberg, Mir and Song, Xia and Stoica, Alina and Tiwary, Saurabh and Wang, Tong},
	month = oct,
	year = {2018},
	note = {arXiv:1611.09268 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {arXiv Fulltext PDF:C\:\\Users\\jinyl\\Zotero\\storage\\J2WCTAX6\\Bajaj 等 - 2018 - MS MARCO A Human Generated MAchine Reading COmpre.pdf:application/pdf},
}

@inproceedings{voorhees2021trec,
  title={TREC-COVID: constructing a pandemic information retrieval test collection},
  author={Voorhees, Ellen and Alam, Tasmeer and Bedrick, Steven and Demner-Fushman, Dina and Hersh, William R and Lo, Kyle and Roberts, Kirk and Soboroff, Ian and Wang, Lucy Lu},
  booktitle={ACM SIGIR Forum},
  volume={54},
  number={1},
  pages={1--12},
  year={2021},
  organization={ACM New York, NY, USA}
}


@article{tsatsaronis_overview_2015,
	title = {An overview of the {BIOASQ} large-scale biomedical semantic indexing and question answering competition},
	volume = {16},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/s12859-015-0564-6},
	doi = {10.1186/s12859-015-0564-6},
	abstract = {This article provides an overview of the first BioASQ challenge, a competition on large-scale biomedical semantic indexing and question answering (QA), which took place between March and September 2013. BioASQ assesses the ability of systems to semantically index very large numbers of biomedical scientific articles, and to return concise and user-understandable answers to given natural language questions by combining information from biomedical articles and ontologies.},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Tsatsaronis, George and Balikas, Georgios and Malakasiotis, Prodromos and Partalas, Ioannis and Zschunke, Matthias and Alvers, Michael R. and Weissenborn, Dirk and Krithara, Anastasia and Petridis, Sergios and Polychronopoulos, Dimitris and Almirantis, Yannis and Pavlopoulos, John and Baskiotis, Nicolas and Gallinari, Patrick and Artiéres, Thierry and Ngomo, Axel-Cyrille Ngonga and Heino, Norman and Gaussier, Eric and Barrio-Alvers, Liliana and Schroeder, Michael and Androutsopoulos, Ion and Paliouras, Georgios},
	month = apr,
	year = {2015},
	pages = {138},
}

@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press}
}

@inproceedings{yang-etal-2018-hotpotqa,
    title = "{H}otpot{QA}: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    author = "Yang, Zhilin  and
      Qi, Peng  and
      Zhang, Saizheng  and
      Bengio, Yoshua  and
      Cohen, William  and
      Salakhutdinov, Ruslan  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1259",
    doi = "10.18653/v1/D18-1259",
    pages = "2369--2380",
    abstract = "Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems{'} ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.",
}


@misc{noauthor_www18_nodate,
	title = {{WWW}'18 {Open} {Challenge} {\textbar} {Companion} {Proceedings} of the {The} {Web} {Conference} 2018},
	url = {https://dl.acm.org/doi/10.1145/3184558.3192301},
	urldate = {2023-01-09},
}

@inproceedings{hasibi2017dbpedia,
  title={DBpedia-entity v2: a test collection for entity search},
  author={Hasibi, Faegheh and Nikolaev, Fedor and Xiong, Chenyan and Balog, Krisztian and Bratsberg, Svein Erik and Kotov, Alexander and Callan, Jamie},
  booktitle={Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1265--1268},
  year={2017}
}

@inproceedings{maia201818,
  title={Www'18 open challenge: financial opinion mining and question answering},
  author={Maia, Macedo and Handschuh, Siegfried and Freitas, Andr{\'e} and Davis, Brian and McDermott, Ross and Zarrouk, Manel and Balahur, Alexandra},
  booktitle={Companion proceedings of the the web conference 2018},
  pages={1941--1942},
  year={2018}
}

@article{bondarenko2020overview,
  title={Overview of touch{\'e} 2020: Argument retrieval-extended abstract},
  author={Bondarenko, Alexander and Fr{\"o}be, Maik and Beloucif, Meriem and Gienapp, Lukas and Ajjour, Yamen and Panchenko, Alexander and Biemann, Chris and Stein, Benno and Wachsmuth, Henning and Potthast, Martin and others},
  journal={Arampatzis et al.[7]},
  pages={384--395},
  year={2020}
}

@article{wadden2020fact,
  title={Fact or fiction: Verifying scientific claims},
  author={Wadden, David and Lin, Shanchuan and Lo, Kyle and Wang, Lucy Lu and van Zuylen, Madeleine and Cohan, Arman and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2004.14974},
  year={2020}
}

@inproceedings{cohan-etal-2020-specter,
    title = "{SPECTER}: Document-level Representation Learning using Citation-informed Transformers",
    author = "Cohan, Arman  and
      Feldman, Sergey  and
      Beltagy, Iz  and
      Downey, Doug  and
      Weld, Daniel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.207",
    doi = "10.18653/v1/2020.acl-main.207",
    pages = "2270--2282",
    abstract = "Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, accurate embeddings of documents are a necessity. We propose SPECTER, a new method to generate document-level embedding of scientific papers based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, Specter can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that Specter outperforms a variety of competitive baselines on the benchmark.",
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
    abstract = "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.",
}


@misc{diggelmann_climate-fever_2021,
	title = {{CLIMATE}-{FEVER}: {A} {Dataset} for {Verification} of {Real}-{World} {Climate} {Claims}},
	shorttitle = {{CLIMATE}-{FEVER}},
	url = {http://arxiv.org/abs/2012.00614},
	doi = {10.48550/arXiv.2012.00614},
	abstract = {We introduce CLIMATE-FEVER, a new publicly available dataset for verification of climate change-related claims. By providing a dataset for the research community, we aim to facilitate and encourage work on improving algorithms for retrieving evidential support for climate-specific claims, addressing the underlying language understanding challenges, and ultimately help alleviate the impact of misinformation on climate change. We adapt the methodology of FEVER [1], the largest dataset of artificially designed claims, to real-life claims collected from the Internet. While during this process, we could rely on the expertise of renowned climate scientists, it turned out to be no easy task. We discuss the surprising, subtle complexity of modeling real-world climate-related claims within the {\textbackslash}textsc\{fever\} framework, which we believe provides a valuable challenge for general natural language understanding. We hope that our work will mark the beginning of a new exciting long-term joint effort by the climate science and AI community.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Diggelmann, Thomas and Boyd-Graber, Jordan and Bulian, Jannis and Ciaramita, Massimiliano and Leippold, Markus},
	month = jan,
	year = {2021},
	note = {arXiv:2012.00614 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: Accepted for the Tackling Climate Change with Machine Learning Workshop at NeurIPS 2020},
}

@inproceedings{jin2019pubmedqa,
  title={PubMedQA: A Dataset for Biomedical Research Question Answering},
  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2567--2577},
  year={2019}
}


@misc{devaraj_paragraph-level_2021,
	title = {Paragraph-level {Simplification} of {Medical} {Texts}},
	url = {http://arxiv.org/abs/2104.05767},
	doi = {10.48550/arXiv.2104.05767},
	abstract = {We consider the problem of learning to simplify medical texts. This is important because most reliable, up-to-date information in biomedicine is dense with jargon and thus practically inaccessible to the lay audience. Furthermore, manual simplification does not scale to the rapidly growing body of biomedical literature, motivating the need for automated approaches. Unfortunately, there are no large-scale resources available for this task. In this work we introduce a new corpus of parallel texts in English comprising technical and lay summaries of all published evidence pertaining to different clinical topics. We then propose a new metric based on likelihood scores from a masked language model pretrained on scientific texts. We show that this automated measure better differentiates between technical and lay summaries than existing heuristics. We introduce and evaluate baseline encoder-decoder Transformer models for simplification and propose a novel augmentation to these in which we explicitly penalize the decoder for producing "jargon" terms; we find that this yields improvements over baselines in terms of readability.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Devaraj, Ashwin and Marshall, Iain J. and Wallace, Byron C. and Li, Junyi Jessy},
	month = apr,
	year = {2021},
	note = {arXiv:2104.05767 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: NAACL 2021},
	file = {arXiv Fulltext PDF:C\:\\Users\\jinyl\\Zotero\\storage\\RCY7LUWQ\\Devaraj 等 - 2021 - Paragraph-level Simplification of Medical Texts.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jinyl\\Zotero\\storage\\CYIYCTUH\\2104.html:text/html},
}

@inproceedings{SciQ,
    title={Crowdsourcing Multiple Choice Science Questions},
    author={Johannes Welbl, Nelson F. Liu, Matt Gardner},
    year={2017},
    journal={arXiv:1707.06209v1}
}

@inproceedings{wachsmuth-etal-2018-retrieval,
    title = "Retrieval of the Best Counterargument without Prior Topic Knowledge",
    author = "Wachsmuth, Henning  and
      Syed, Shahbaz  and
      Stein, Benno",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1023",
    doi = "10.18653/v1/P18-1023",
    pages = "241--251",
    abstract = "Given any argument on any controversial topic, how to counter it? This question implies the challenging retrieval task of finding the best counterargument. Since prior knowledge of a topic cannot be expected in general, we hypothesize the best counterargument to invoke the same aspects as the argument while having the opposite stance. To operationalize our hypothesis, we simultaneously model the similarity and dissimilarity of pairs of arguments, based on the words and embeddings of the arguments{'} premises and conclusions. A salient property of our model is its independence from the topic at hand, i.e., it applies to arbitrary arguments. We evaluate different model variations on millions of argument pairs derived from the web portal idebate.org. Systematic ranking experiments suggest that our hypothesis is true for many arguments: For 7.6 candidates with opposing stance on average, we rank the best counterargument highest with 60{\%} accuracy. Even among all 2801 test set pairs as candidates, we still find the best one about every third time.",
}

@inproceedings{dai2019deeper,
  title={Deeper text understanding for IR with contextual neural language modeling},
  author={Dai, Zhuyun and Callan, Jamie},
  booktitle={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={985--988},
  year={2019}
}

@article{10.1561/1500000019,
author = {Robertson, Stephen and Zaragoza, Hugo},
title = {The Probabilistic Relevance Framework: BM25 and Beyond},
year = {2009},
issue_date = {April 2009},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000019},
doi = {10.1561/1500000019},
abstract = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
journal = {Found. Trends Inf. Retr.},
month = {apr},
pages = {333–389},
numpages = {57}
}

@inproceedings{Lin2016TowardRB,
  title={Toward Reproducible Baselines: The Open-Source IR Reproducibility Challenge},
  author={Jimmy J. Lin and Matt Crane and Andrew Trotman and Jamie Callan and Ishan Chattopadhyaya and John Foley and Grant Ingersoll and Craig Macdonald and Sebastiano Vigna},
  booktitle={European Conference on Information Retrieval},
  year={2016}
}

@inproceedings{mussmann2016learning,
  title={Learning and inference via maximum inner product search},
  author={Mussmann, Stephen and Ermon, Stefano},
  booktitle={International Conference on Machine Learning},
  pages={2587--2596},
  year={2016},
  organization={PMLR}
}

@inproceedings{ram2012maximum,
  title={Maximum inner-product search using cone trees},
  author={Ram, Parikshit and Gray, Alexander G},
  booktitle={Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={931--939},
  year={2012}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{schick2020s,
  title={It's not just size that matters: Small language models are also few-shot learners},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2009.07118},
  year={2020}
}

@article{asai2022attentional,
  title={Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient Multi-task Knowledge Sharing},
  author={Asai, Akari and Salehi, Mohammadreza and Peters, Matthew E and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2205.11961},
  year={2022}
}

@article{arivazhagan2019massively,
  title={Massively multilingual neural machine translation in the wild: Findings and challenges},
  author={Arivazhagan, Naveen and Bapna, Ankur and Firat, Orhan and Lepikhin, Dmitry and Johnson, Melvin and Krikun, Maxim and Chen, Mia Xu and Cao, Yuan and Foster, George and Cherry, Colin and others},
  journal={arXiv preprint arXiv:1907.05019},
  year={2019}
}

@article{izacard2022unsupervised,
  title={Unsupervised dense information retrieval with contrastive learning},
  author={Izacard, Gautier and Caron, Mathilde and Hosseini, Lucas and Riedel, Sebastian and Bojanowski, Piotr and Joulin, Armand and Grave, Edouard},
  year={2022}
}

@article{ponti2022combining,
  title={Combining modular skills in multitask learning},
  author={Ponti, Edoardo M and Sordoni, Alessandro and Reddy, Siva},
  journal={arXiv preprint arXiv:2202.13914},
  year={2022}
}

@inproceedings{hofstatter2021efficiently,
  title={Efficiently teaching an effective dense retriever with balanced topic aware sampling},
  author={Hofst{\"a}tter, Sebastian and Lin, Sheng-Chieh and Yang, Jheng-Hong and Lin, Jimmy and Hanbury, Allan},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={113--122},
  year={2021}
}

@inproceedings{zhounot,
  title={Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization},
  author={Zhou, Jing and Lin, Zongyu and Zheng, Yanan and Li, Jian and Yang, Zhilin},
  booktitle={International Conference on Learning Representations}
}

@article{mcmahan2016federated,
  title={Federated learning of deep networks using model averaging},
  author={McMahan, H Brendan and Moore, Eider and Ramage, Daniel and y Arcas, Blaise Ag{\"u}era},
  journal={arXiv preprint arXiv:1602.05629},
  volume={2},
  year={2016},
  publisher={Technical report}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@book{fodor1983modularity,
  title={The modularity of mind},
  author={Fodor, Jerry A},
  year={1983},
  publisher={MIT press}
}

@article{ballard1986cortical,
  title={Cortical connections and parallel processing: Structure and function},
  author={Ballard, Dana H},
  journal={Behavioral and brain sciences},
  volume={9},
  number={1},
  pages={67--90},
  year={1986},
  publisher={Cambridge University Press}
}

@book{baldwin2000design,
  title={Design rules: The power of modularity},
  author={Baldwin, Carliss Young and Clark, Kim B},
  volume={1},
  year={2000},
  publisher={MIT press}
}

@article{ulrich1995role,
  title={The role of product architecture in the manufacturing firm},
  author={Ulrich, Karl},
  journal={Research policy},
  volume={24},
  number={3},
  pages={419--440},
  year={1995},
  publisher={Elsevier}
}

@book{wagner2001natural,
  title={Natural selection and the origin of modules},
  author={Wagner, G{\"u}nter P and Mezey, Jason and Calabretta, Raffaele},
  year={2001},
  publisher={na}
}

@article{booch2008object,
  title={Object-oriented analysis and design with applications},
  author={Booch, Grady and Maksimchuk, Robert A and Engle, Michael W and Young, Bobbi J and Connallen, Jim and Houston, Kelli A},
  journal={ACM SIGSOFT software engineering notes},
  volume={33},
  number={5},
  pages={29--29},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@article{jacobs1991task,
  title={Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks},
  author={Jacobs, Robert A and Jordan, Michael I and Barto, Andrew G},
  journal={Cognitive science},
  volume={15},
  number={2},
  pages={219--250},
  year={1991},
  publisher={Elsevier}
}

@article{rosenbaum2017routing,
  title={Routing networks: Adaptive selection of non-linear functions for multi-task learning},
  author={Rosenbaum, Clemens and Klinger, Tim and Riemer, Matthew},
  journal={arXiv preprint arXiv:1711.01239},
  year={2017}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{rebuffi2018efficient,
  title={Efficient parametrization of multi-domain deep neural networks},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8119--8127},
  year={2018}
}

@article{bapna2019simple,
  title={Simple, scalable adaptation for neural machine translation},
  author={Bapna, Ankur and Arivazhagan, Naveen and Firat, Orhan},
  journal={arXiv preprint arXiv:1909.08478},
  year={2019}
}

@article{le2021lightweight,
  title={Lightweight adapter tuning for multilingual speech translation},
  author={Le, Hang and Pino, Juan and Wang, Changhan and Gu, Jiatao and Schwab, Didier and Besacier, Laurent},
  journal={arXiv preprint arXiv:2106.01463},
  year={2021}
}

@inproceedings{dumais2003stuff,
  title={Stuff I've seen: a system for personal information retrieval and re-use},
  author={Dumais, Susan and Cutrell, Edward and Cadiz, Jonathan J and Jancke, Gavin and Sarin, Raman and Robbins, Daniel C},
  booktitle={Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
  pages={72--79},
  year={2003}
}

@article{he2022parameter,
  title={Parameter-efficient fine-tuning for vision transformers},
  author={He, Xuehai and Li, Chunyuan and Zhang, Pengchuan and Yang, Jianwei and Wang, Xin Eric},
  journal={arXiv preprint arXiv:2203.16329},
  year={2022}
}

@article{pfeiffer2023modular,
  title={Modular Deep Learning},
  author={Pfeiffer, Jonas and Ruder, Sebastian and Vuli{\'c}, Ivan and Ponti, Edoardo Maria},
  journal={arXiv preprint arXiv:2302.11529},
  year={2023}
}

@inproceedings{boteva2016full,
  title={A full-text learning to rank dataset for medical information retrieval},
  author={Boteva, Vera and Gholipour, Demian and Sokolov, Artem and Riezler, Stefan},
  booktitle={Advances in Information Retrieval: 38th European Conference on IR Research, ECIR 2016, Padua, Italy, March 20--23, 2016. Proceedings 38},
  pages={716--722},
  year={2016},
  organization={Springer}
}

@book{caruana1998multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  year={1998},
  publisher={Springer}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@article{maillard2021multi,
  title={Multi-task retrieval for knowledge-intensive tasks},
  author={Maillard, Jean and Karpukhin, Vladimir and Petroni, Fabio and Yih, Wen-tau and O{\u{g}}uz, Barlas and Stoyanov, Veselin and Ghosh, Gargi},
  journal={arXiv preprint arXiv:2101.00117},
  year={2021}
}

@inproceedings{ZhangRMW0022,
  author    = {Chen Zhang and
               Lei Ren and
               Fang Ma and
               Jingang Wang and
               Wei Wu and
               Dawei Song},
  title     = {Structural Bias for Aspect Sentiment Triplet Extraction},
  booktitle = {Proceedings of the 29th International Conference on Computational
               Linguistics, {COLING} 2022, Gyeongju, Republic of Korea, October 12-17,
               2022},
  pages     = {6736--6745},
  publisher = {International Committee on Computational Linguistics},
  year      = {2022},
}

@inproceedings{MaZS21,
  author    = {Fang Ma and
               Chen Zhang and
               Dawei Song},
  title     = {Exploiting Position Bias for Robust Aspect Sentiment Classification},
  booktitle = {Findings of the Association for Computational Linguistics: {ACL/IJCNLP}
               2021, Online Event, August 1-6, 2021},
  series    = {Findings of {ACL}},
  volume    = {{ACL/IJCNLP} 2021},
  pages     = {1352--1358},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}

@article{artetxe2021efficient,
  title={Efficient large scale language modeling with mixtures of experts},
  author={Artetxe, Mikel and Bhosale, Shruti and Goyal, Naman and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Lin, Xi Victoria and Du, Jingfei and Iyer, Srinivasan and Pasunuru, Ramakanth and others},
  journal={arXiv preprint arXiv:2112.10684},
  year={2021}
}

@article{ren2022thorough,
  title={A thorough examination on zero-shot dense retrieval},
  author={Ren, Ruiyang and Qu, Yingqi and Liu, Jing and Zhao, Wayne Xin and Wu, Qifei and Ding, Yuchen and Wu, Hua and Wang, Haifeng and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2204.12755},
  year={2022}
}

@article{konevcny2016federated,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@article{li2020federated,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE signal processing magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}

@article{chronopoulou2023adaptersoup,
  title={AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models},
  author={Chronopoulou, Alexandra and Peters, Matthew E and Fraser, Alexander and Dodge, Jesse},
  journal={arXiv preprint arXiv:2302.07027},
  year={2023}
}

@InProceedings{Rebuffi_2018_CVPR,
author = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
title = {Efficient Parametrization of Multi-Domain Deep Neural Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@misc{nllbteam2022language,
      title={No Language Left Behind: Scaling Human-Centered Machine Translation}, 
      author={NLLB Team and Marta R. Costa-jussà and James Cross and Onur Çelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Al Youngblood and Bapi Akula and Loic Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon Spruit and Chau Tran and Pierre Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzmán and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
      year={2022},
      eprint={2207.04672},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}