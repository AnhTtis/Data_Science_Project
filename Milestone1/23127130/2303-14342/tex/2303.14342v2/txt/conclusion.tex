\section{Conclusion}
We find that the GPT-3.5 and GPT-4 models demonstrate strong performance in grammatical error correction as defined in a sentence revision task.
During prompt and hyperparameter search, we observe that a low temperature hyperparameter is consistently associated with better performance in this task. 
While the models are subject to some prompt sensitivity, our best prompt consistently results in the desired format and behavior.
Our GEC task setting and prompt search resulted in a tendency for the models to produce fluency corrections and occasional over-editing, resulting in high scores on fluency metrics and human evaluation, but comparatively lower scores on the BEA-2019 dataset, which favors minimal edits.

Our experiments emphasize that GEC is a challenging subfield of NLP with a number of distinct subtasks and variables.
Even humans can have conflicting definitions of desirable corrections to ill-formed text, and this may change depending on contexts such as the task setting (e.g. language education, revising an academic paper) and the roles of the editor and recipient (e.g., student and instructor).
It is important to define these variables as clearly as possible in all discussions of GEC.