\section{Prompt Engineering}

GPT models are autoregressive decoder-only language models with a natural language text prompt as input.
In our task, given an instruction prompt $c$ and input sentence $x$, GPT models generate a text sequence ($y$, tokenized as $(w_1, w_2, \dots w_T)$) based on the following log likelihood:
\begin{align*}
\log p_{\theta}(y|c,x) = \sum_{t=1}^{T} \log p_{\theta}(w_t | c, x, w_{< t-1})
\end{align*}

To best apply the GPT models to this task, it is necessary to first devise an appropriate prompt. 
Therefore, our first step is prompt engineering.

Since the format and even exact wording of a large language model's prompts can have a significant effect on task performance \cite{jiang-etal-2020-know,shin-etal-2020-autoprompt,schick-schutze-2021-just}, we design several different candidate prompts for the GEC task, starting with a zero-shot setting.
Table~\ref{tab:prompts} shows the zero-shot prompts we experimented with, as well as their results. 
Elsewhere in this paper, we will refer to these prompts by number based on their index from this table. 
We begin the prompt search with GPT-3.5 using OpenAI's example prompt for grammatical error correction:\footnote{\url{https://platform.openai.com/examples/default-grammar}, as of April 22, 2023}

\begin{enumerate}
    \item[] Correct this to standard English:\bn\bn
\end{enumerate}

Interestingly, this prompt is defined within the \textsc{completions} endpoint in the OpenAI API.
As an \textsc{edits} endpoint also exists, it may occur to a user to define this task with that endpoint, as grammatical error correction can be considered an editing task.
In our initial experiments, however, we found that the performance of the \textsc{edits} endpoint in this task lagged behind that of the \textsc{completions} endpoint, so we continued our prompt engineering experiments using \textsc{completions} as seen in the example.
Unlike the GPT-3.5 model, GPT-4 only has a \textsc{chat} completion endpoint available via the API.
To maintain similarity across experiments, we submit our prompts to GPT-4 as a single input as the ``user'' role, without defining a system message. \par
We start our prompt engineering experiments with slight modifications to the wording of the example prompt, such as adding quotes to the target sentence, as seen in Prompt \#4.
We then experiment with ``fields'' such as ``Sentence:'' and ``Correction:'', as seen in Prompt \#8.
These relatively small adjustments are designed to test the GPT models' prompt sensitivity.
Finally, we experiment with a more complex prompt, \#10, which specifies a behavior when the sentence is already correct.

In addition, we use nucleus (top-p) sampling~\cite{Holtzman2020The} to generate tokens, repeating experiments with temperature hyperparameters $\tau$ of 0.1, 0.5, and 0.9.\footnote{Other hyperparameters used include logprobs=0, num\_outputs=1, top\_p=1.0, and best\_of=1}

To select the best prompt and temperature combination, we use GLEU scores on the JFLEG development set.

After identifying the best zero-shot prompt, we proceeded to experiments in a few-shot setting, adding one or more example sentence-correction pairs to our best zero-shot prompt to demonstrate the GEC task. 
We experimented with up to six example sentence-correction pairs.