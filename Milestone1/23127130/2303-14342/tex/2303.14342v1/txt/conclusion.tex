\section{Conclusion}
We find that GPT-3 demonstrates strong performance in the task of grammatical error correction, especially with the right prompting strategies. 
We also find that the temperature hyperparameter is consistently associated with better performance in this task. 
Human raters assign high scores to GPT-3's corrections, but reference-based automated metrics such as F$_{0.5}$ and GLEU are limited in their ability to recognize the quality of these outputs. 
We join previous works such as~\citet{napoles-etal-2016-theres} and~\citet{kasai-etal-2022-bidimensional} in calling for the field of GEC to move beyond the overuse of reference-based evaluation on the same handful of datasets.