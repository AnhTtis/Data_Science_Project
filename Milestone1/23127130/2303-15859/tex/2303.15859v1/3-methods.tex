\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.95\linewidth]{fig/SpareseOLN-Variants.pdf}
  \centering
  \caption{Overview of OpenInst. OpenInst leverages the encoder-decoder architecture. The decoder contains L stages. Query boxes and features of the decoder are updated in each stage and serve as the queries for the next stage. According to the different learning objective and loss function, OpenInst can be categorized to 4 variants: OpenInst-void, OpenInst-box, OpenInst-mask, and OpenInst-fusion.}
  \label{fig:OpenInstvariants}
\end{figure*}


% Based on Faster R-CNN, OLN has demonstrated that replacing classification scores with geometric cues can improve the generalizability of the detector on dense proposals. However, geometric cues occur in 2 places within OLN: being a learning objective and a ranking score to filter boxes from dense proposals. We propose an end-to-end instance segmentation method for open-world scenarios, named OpenInst. OpenInst leverages the powerful query-based instance segmentation framework and attention mechanism. Our main goal is to find out that learning which kind of objectness can help improve recall performance when given a fixed number of predictions. We use classification score, box IoU, and mask IoU as the learning objective respectively to find the answer. The overall variants of OpenInst are demonstrated in Fig.~\ref{fig:OpenInstvariants}.
% According to the learning objectives, the variants of OpenInst are named OpenInst-void, OpenInst-box, OpenInst-mask, and OpenInst-fusion respectively. In Sec.~\ref{sec:exp}, OpenInst denotes OpenInst-box if without special specification.


\subsection{Problem Definition} 
Open-world instance segmentation is to localize and segment all objects in arbitrary images. However, due to limited and fixed training images, it is unrealistic to expect the model to encounter all kinds of objects during training. Therefore, we use base categories $C_{base}$ and novel categories $C_{novel}$ to denote seen categories during training and unseen categories during testing, respectively. Testing images may contain both $C_{base}$ and $C_{novel}$ objects. There are two common settings for evaluating the performance of open-world instance segmentation models: cross-category and cross-dataset. In the cross-category setting, the model is trained with $C_{base}$ objects and tested on $C_{novel}$ objects. In cross-dataset setting, the model is trained on dataset $A$ and tested on dataset $B$, where dataset $B$ may contain both $C_{base}$ and $C_{novel}$ objects. The performance of both settings is measured by Average Recall (AR).

\subsection{Baseline Framework}
OpenInst can be constructed on many query-based frameworks. We adopt QueryInst~\cite{queryinst} as our baseline model for subsequent research. QueryInst is a typical query-based method for instance segmentation. Its decoder consists of six decode stages after the backbone and neck modules. Each stage is equipped with a unique dynamic box head as well as mask head. Query features are shared in both box and mask heads of each stage. Supervisions from ground truths are applied to all six stages. The training objective of each stage can be formulated as follows:
%公式，介绍每个stage的Loss组成, box loss , cls loss, mask loss, iou loss.  
\begin{align}
\label{eq:level}\mathcal{L}_{l} &= \mathcal{L}_{objectness} + \mathcal{L}_{box} + \mathcal{L}_{mask}, \\[10pt]
\label{eq:obj:cls}\mathcal{L}_{objectness} &= \lambda_{cls} \cdot \mathrm{FL}(p_c, p_c^*), \\[10pt]
\label{eq:box}\mathcal{L}_{box} &= \lambda_{reg} \cdot \mathrm{L1}(t, t^*) + \lambda_{giou} \cdot \mathrm{GIoU}(t, t^*), \\[10pt]
\label{eq:mask}\mathcal{L}_{mask} &= \lambda_{mask} \cdot \mathrm{dice}(m, m^*).
\end{align}
$\mathcal{L}_{l}$ is the aggregation of all losses applied in the $l$ stage of the decoder. It consists of three losses: $\mathcal{L}_{objectness}$, $\mathcal{L}_{box}$ and $\mathcal{L}_{mask}$. $\mathrm{FL}$ denotes focal loss~\cite{focalloss}. $\mathcal{L}_{objectness}$ uses focal loss to learn the objectness as a classification score. $\mathcal{L}_{box}$ combines a $L1$ loss and a auxiliary $\mathrm{GIoU}$ loss~\cite{giou} for box regression learning. $\mathcal{L}_{mask}$ uses dice loss~\cite{diceloss} to learn the mask of an object. The $\lambda_{cls}$, $\lambda_{cls}$ and $\lambda_{cls}$ denote the weights of $\mathcal{L}_{objectness}$, $\mathcal{L}_{reg}$, $\mathcal{L}_{giou}$ and $\mathcal{L}_{mask}$ respectively. The $p_c$, $t$, and $m$ denote the classification score, box coordinates, and the mask of the predictions. The $p_c^*$, $t^*$, and $m^*$ denote the classification score, box coordinates, and the mask of the corresponding ground truth. The total loss $\mathcal{L}_{total}$ used optimize the detector is a sum of all $\mathcal{L}_{l}$:
\begin{equation}
    \mathcal{L}_{total} = \sum_{l=1}^{L} \mathcal{L}_{l},
\end{equation}
where $L$ denotes the number of layers in the decoder.

Query-based methods such as QueryInst predict all instances directly, with the number of predicted instances determined prior to training. The decoder refines \textbf{all} predictions stage by stage. 
When evaluating the generalizability of detectors using the recall metric, the objectness score can be omitted as the primary metric is often Average Recall (AR) at a budget of 100. This is the main metric used to evaluate the generalizability of open-world instance segmentation methods. To establish a fair comparison with prior works that do not use objectness scores, we set the query number to 100.

\subsection{OpenInst Framework}

% 因为要解释为什么要在query-based上使用geometry的原因。
% 所以要尝试去说明query based方法和dense proposal方法的不同，那就是前者是通过decoder逐步refine已有的box，后者是从众多的proposls里面通过objectness score来挑选出
Besides the difference in the complexity and performance, there is another notable difference in the utilization of the objectness score between dense proposal-based methods and query-based methods. 
In the case of dense proposal-based methods, the objectness score is employed in two ways. Firstly, it serves as a learning objective during the training phase and secondly, it functions as a ranking indicator in both the training and testing phases, enabling the filtering of boxes with high confidence from dense proposals. 
On the other hand, in query-based methods, the objectness score, which is mostly a classification score, is used only as an auxiliary learning objective in the training phase. It does \textbf{not} serve as a ranking index for filtering boxes from dense proposals, as the number of boxes in query-based methods is fixed. The existing boxes are refined stage by stage.

To investigate the effect of geometric cues on query-based methods, we have applied them to QueryInst and removed the classification branch, replacing it with either a box IoU branch or a mask IoU branch, resulting in the variants named OpenInst-box and OpenInst-mask, respectively. The variant that uses both the box and mask IoU branch is named OpenInst-fusion.
Furthermore, based on the observation that the objectness score is not needed in calculating the main metric AR@100, we question the necessity of treating the objectness score as a learning objective in query-based methods. we remove all objectness branches and name the resulting variant OpenInst-void.
The comprehensive framework of OpenInst and its variants is depicted in Fig.~\ref{fig:OpenInstvariants}. Notably, the modifications made to QueryInst are minimal, as our primary goal is to simplify the structure while maintaining high performance.

We use $L1$ loss as the supervision to train box or mask IoU branches. The $\mathcal{L}_{objectness}$ in Eq.~\ref{eq:level} is modified as Eq.~\ref{eq:OpenInst}. The symbols $p_b$ and $p_m$ denote the predicted box IoU score and mask IoU score, respectively. Meanwhile, the ground-truth scores are represented by $p_b^*$ and $p_m^*$. The symbols $\lambda_{box IoU}$ and $\lambda_{mask IoU}$ denote the corresponding weights used in the training phase.


\begin{equation}\label{eq:OpenInst}
\resizebox{\textwidth}{!}{%
$\mathcal{L}_{objectness} = \begin{cases}
0, &\text{if $\mathcal{L}_{objectness}$ in OpenInst-void} \\
\lambda_{box IoU} \cdot \mathrm{L1}(p_b, p_b^*), &\text{if $\mathcal{L}_{objectness}$ in OpenInst-box} \\
\lambda_{mask IoU} \cdot \mathrm{L1}(p_m, p_m^*), &\text{if $\mathcal{L}_{objectness}$ in OpenInst-mask} \\
\lambda_{box IoU} \cdot \mathrm{L1}(p_b, p_b^*) + \lambda_{mask IoU} \cdot \mathrm{L1}(p_m, p_m^*), &\text{if $\mathcal{L}_{objectness}$ in OpenInst-fusion}
\end{cases}$%
}
\end{equation}

\subsection{Best Practice in Open-World Instance Segmentation}
%在实践中遇到的一些问题
%待完善
\textbf{Deformable modules.}
Deformable convnet~\cite{dcn,dcnv2} is a powerful tool in the closed-world object detection task as well as instance segmentation task. The deformable property makes it more precise than vanilla convnet. In the open-world instance segmentation task, we also want to leverage the deformable property to find more potential objects in an image. We add the advanced deformable convnet to our models and gain non-trivial promotions.

\textbf{Neck structure.}
Since FPN~\cite{fpn} has been raised, lots of works have concentrated on neck structure designing, such as BiFPN~\cite{bifpn}, PAFPN~\cite{pafpn}, and NAS-FPN~\cite{nasfpn}. Those works try to enhance the expressiveness of feature maps at different scales, in order to capture more accurate information from feature maps. These FPNs have made great contributions to the closed-world instance segmentation task. We here extend their applicability to the open-world instance segmentation, since the communication conducted in different feature maps may also enhance the information of novel objects. We choose BiFPN as the neck of our model.
