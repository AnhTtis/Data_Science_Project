\section{Optimizing the Fourier Transform}%
\label{sect:unzip}%
In Fig.~\ref{fig:fft} it is clear that there is a large penalty for FFT
sizes above \num{16384}, and that this penalty is worse for real-to-complex
transforms. This threshold is the point at which cuFFT switches from doing the
entire transform in a single pass, to performing two (for C2C) or three (for
R2C) passes over the memory.

To eliminate this penalty for larger channel counts, we stop treating the
FFT as a black box, and split off some of the work to the other kernels.

\subsection{Real-to-Complex Transform}
We will start by eliminating the extra pass required for the real-to-complex
transform. While the cuFFT documentation does not describe how real-to-complex
transforms are implemented, the name of the final kernel
(\verb"postprocessC2C_kernelmem") suggests that it uses a technique that first
treats the even and odd elements as real and imaginary components of complex
numbers, performs a complex-to-complex transform, then performs
post-processing to get the final result\cite{real-fft}.

Instead of having cuFFT apply this technique, we can apply it manually, with
cuFFT handling just the complex-to-complex step. The advantage of doing the
post-processing ourselves is that it can be integrated into the
post-processing kernel, thus eliminating a round trip to memory.

\subsection{Unzipping the FFT}
The two passes used by cuFFT's complex-to-complex transform correspond to the
``four-step'' FFT\cite{four-step-fft}, in which a transform of size $ab$ is
decomposed into $b$ transforms of size $a$ followed by $a$ transforms of size
$b$, with the smaller transforms all computed within a faster level of the
memory hierarchy (in this case, on-chip shared memory).

As in the previous subsection, we can improve efficiency by performing this
decomposition ourselves, and merging some of the steps with existing kernels.
Our approach is actually based on the ``six-step'' FFT\cite{four-step-fft}:
\begin{enumerate}
  \item Transpose the input data, interpreted as an $a\times b$ matrix, to a
    $b\times a$ matrix (all matrices being row-major).
  \item Perform $b$ individual $a$-point FFTs.
  \item Multiply the resulting $b\times a$ matrix by appropriate roots of
    unity (the so-called ``twiddle factors'').
  \item Transpose this $b\times a$ matrix into an $a\times b$ matrix.
  \item Perform $a$ individual $b$-point FFTs.
  \item Transpose the resulting $a\times b$ matrix into a $b\times a$ matrix,
    which can be interpreted as a one-dimensional $ab$-element array.
\end{enumerate}

In our implementation, there are no explicit transposition passes; instead,
indexing of the surrounding operations is adjusted to take the transposition
into account. This makes the transposition ``free'' in the sense that it
does not directly cause extra memory transfers, but it does lead to less
efficient memory access patterns as contiguous accesses are replaced with
strided access.

We incorporate step 1 into the PFB FIR kernel (adjusting the addresses at
which values are written), perform step 2 with cuFFT, and fold the remaining
steps into the post-processing kernel.

We refer to $b$ as the ``unzipping'' factor. While the four-step FFT is normally
used with $a$ and $b$ having similar magnitude, we prefer to use a small
value, specifically $b = 4$, for several reasons:
\begin{itemize}
  \item We need to implement our own $b$-point FFT inside the post-processing
    kernel. While writing a general FFT implementation handling a range of
    sizes (even if only powers of two) is a major undertaking, a 4-point FFT
    is simple to code.
  \item Our $b$-point FFT implementation operates serially, holding all the
    data in registers of a single thread. Larger values of $b$ thus create
    more register pressure, and would probably require a rewrite using a
    parallel implementation. This is exacerbated by the post-processing for
    the real-to-complex transform, which requires two such FFTs to be
    computed by the same thread.
  \item The implicit transpositions result in access strides of $b$ elements,
    so smaller values of $b$ have better data locality.
\end{itemize}
Fig.~\ref{fig:fft} shows that the cost of step 2 is largely independent of $a$
provided it is at most \num{8192}, so the increase in $a$ that comes from
reducing $b$ is not an issue. For simplicity we have kept $b = 4$ for all
channel counts (\num{1024}--\num{32768}).

We also attempted to make the transpositions more explicit by using shared
memory\cite{transpose}, but found that the synchronization overheads
outweighed the benefits. It is possible that a more sophisticated
implementation (for example, using recent CUDA asynchronous APIs) would
achieve better results.
