\section{Discussion \& Conclusion}
% If emotions are expressions of internal states and robots do not have consciousness, is it not ingenuine to make them display emotions?
As emotions are expressions of internal states and robots do not have consciousness, it is controversial to make them display emotions \cite{giger2019humanization, coeckelbergh2011emotional, ojha2018essence}. 
It could be argued that even humans use facial expressions as tools and communicational shortcuts \cite{crivelli2018facial}, so letting robots utilize them will only positively affect the ability to interact with them. Furthermore, many researchers are of the opinion that human-robot interaction can be facilitated by letting robots show emotion \cite{Azeem2012emotions,loffer2018multimodel}, and the feedback of the participants suggests the same. Still, we believe  it is essential always to make the human partner aware that it is interacting with a robot. 
In the context of using androids in care homes, it is necessary to remember that people with impairments could be at risk of mistaking an android for a human. This can lead to expectations that are ultimately not met.
SH1 and SH3 raised an important point with their assertion that even if the use of robots as emotional support surely is ethically difficult, we have to ensure to weigh the potential threats against the benefits. A robot counterpart could be an enjoyable distraction that is welcomed by care home residents and might contribute to a decrease in loneliness. 
It can be argued that robots might have some advantages of providing emotional support to humans as they are equipped with certain “superpowers” like endless patience or unconditional subordination that humans do not possess \cite{ welge2016better}. Still, it is necessary that new laws and guidelines accompany the potential use of robots in care homes that ensure enough staff supervises the interactions and that the artificiality of the robot is openly communicated to everyone who interacts with it \cite{carros2022care, schwaninger2022video}.


The smile of the robot was generally seen as beneficial. It leads the participants to rate the android as more human and likable. This is most likely not because the participants thought the robot was actually happy but caused by the fact that smiling at someone signals understanding. This type of encouragement can extend the motivation to engage in conversation, which is why participants also said it increased their willingness to speak to the android. This is consistent with the theory that smiles are not predominantly used to convey happiness but more often simply signify affiliate intent \cite{fang2019unmasking}.
When it comes to other and potentially more negative emotions, there are a lot of risks and benefits to be weighed. On the one hand, there is a desire for humans to interact with a real counterpart that is capable of discussion and offering dissenting views, one that would have reason to display emotions like anger and disgust. On the other hand, there is the valid assertion that robots should only display emotions that will evoke a positive reaction in the interactant.
Likewise, the display of sadness or pity comes with the threat of leading to expectations for the relationship that will ultimately be disappointed or create a situation that is so emotionally charged that the robot cannot help the human to overcome them.


This study is limited by the number of participants and the lengths of the interactions. For now, it has to be clearly stated, though, that any of the participants experienced no difficulty in telling that they were not, in fact, interacting with a human, indicating that the robot is not that human-like after all \cite{carros2023not}. This might change in the future; therefore, it might be reasonable to establish internationally binding guidelines to differentiate robots and humans visually. In addition, the display of negative emotions, such as sadness, fear, etc., needs further investigation.
%Many participants reported a positive reaction to being smiled at. However, the display of other, potentially more negative emotions, like sadness, fear, or anger, has to be evaluated in further studies.