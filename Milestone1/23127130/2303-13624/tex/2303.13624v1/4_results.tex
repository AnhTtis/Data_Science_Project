\section{Results}
Despite the fact that the android was capable of displaying the emotions of happiness, surprise, anger and sadness, most participants only recalled that the robot showed joy. All the participants who interacted with the android in the university mentioned its smile and so did two of the stakeholders.
SH1 stated that the android’s smile encouraged her to keep talking. It was also described as \textit{“pretty cute, only just alluded but visible.”} (P8) and \textit{“nice”} (P4) and P3 explained that she thought the smile was astute and that it brought her joy. P7 was more tentative and described that the android had tried to smile, implying he would not consider it a success.
Sadness and surprise were only recalled by P1, P3 and P7. This disparity can be explained by the fact that the facial expressions were only used when they were appropriate in the context of the conversation, which was true more often for happiness than it was for either sadness or surprise.
SH2 stressed that the important part about the facial expression was not that they were present, but rather that they were displayed in the right moment within the context of the conversation.
SH4 saw the facial expressions as providing an additional path of communication.
SH1 emphasized the fact that the android smiling at her made her realize that she understood what the topic was about. She also mentioned that this encouraged her to talk more. P8 mentioned that she considered the nodding of the android to have a reassuring effect on her and stressed that this aspect, in particular, made the android appear very human-like. Reaction was one of the most important keywords in regard to emotion. Whenever they spoke positively about the display of emotions, the participants stressed how the android, which they often even called by its human name, reacted with a smile or mirrored their own emotions (P1, P2).
%In general, the fact that the android was capable of displaying facial expressions was seen as very positive. 
P2, P3 and P8 stated that they were positively surprised by the fact that the android was capable of displaying facial expressions. P6 said that the expressions made the robot likable and human-like.


When asked how the emotions of the robot could be expanded, the participants mentioned that they could imagine a robot displaying embarrassment (P3), compassion (P4), laughing out loud (P3, SH2), or crying (SH1).
P6 stressed that it was important that the robot never showed aggression though and always stayed gentle. P8 and SH2 also emphasized that the robot’s main objective should be to be calm and not upset anyone interacting with it. They also wished the android would show more intrinsic curiosity (P4) by asking questions and inquiring about them.
In contrast to this, P1, P2 and P8 all wished for the robot to have its own opinion and be able to discuss controversial topics and even explained that they would want the robot to disagree, set boundaries and actively urge the counterpart to discuss with them. P8 even elaborated that she would consider it problematic for humans to constantly interact with a counterpart that always agreed with them and never opposed them.
SH2 imagined a specific future scenario in which the robot could help older adults overcome traumatic losses in their lives.
P8, on the other hand, doubted that the robots could ever do certain emotional tasks. Her examples were hugging a person in need or helping a patient with dementia to return to the real world by reacting with empathy and understanding.
%SH2 also brought up the interesting consideration that the still lower body of the robot could potentially be explained by having her sit in a wheelchair. This would imply that the robot was in need of support or help and could trigger interesting reaction from her human counterparts. A similar idea would be to make the robot look like a child (P1, P2). P1 elaborated that a childlike look might help especially older adults to set realistic expectations for the android, because the android would be in the process of learning about the world, just like children are.


A prominent concern is that emotional display will eventually blur the lines between humans and robots to a point where it is no longer easy to tell them apart. %P8 even described that she briefly thought of the android as human. She explained: “I honestly have to say this happened to me just now. I always looked in her eyes. Those eyes appear very natural due to the blinking. Yes, it’s an illusion that you start to go along with in parts.“
SH3 explained that people in care homes were at an especially great risk to make that mistake due to their health situation. P3 saw it as important to ensure that robots and humans could always be told apart.
P8 and SH3 also mentioned that they would think it was very likely for an older adult to fall in love with a robot. P6 stated \textit{“when you are with a robot there will somehow always be relationships that develop. And whether they can bring fulfillment or lead to disappointment we cannot tell.”}
SH1 also said: \textit{“A robot will not be able to react right when the other person starts to cry or show emotions.”}
SH2 did not see any risks in humans mistaking robots for others humans.
Although concerns were also raised by SH1 she did draw the conclusion that it would ultimately be the “lesser evil” to have some older adults mistake a robot for a human, if they could at least be connected to an actual human by the robot. 
%The stakeholder described a scenario where the robot could animate and enable the older adults in a care home to make the decision to call their loved ones and assist them in doing so. She was imagining this scenario specifically as a use case that would have been beneficial during the Covid-19 lockdowns and stressed that in her opinion the treatment of older adults during this time was so worrisome that almost all interaction would have been an improvement. P8 agreed that it was important to weigh the benefits and disadvantages.
SH1 stated that she was sure many people would accuse a robot that could display realistic gestures, facial expressions and emotions of lying to the users and deceiving them.
%SH3 also initially stated that she would consider it wrong to deceive people as they had the right to agency. Then she reflected on the fact that many people in care homes were not able to live their life with agency anyways and finally decided that she would consider it the best strategy to clearly state that the android was in fact a robot in the beginning but not repeat it over and over, as she saw potential for a very close and fruitful relationship as well. She also stressed though that there was a need to intercede as soon as there was any indication that the interaction with the robot had a negative influence on anybody. In conclusion it seemed like honesty was the most important value for her in this regard.
P6 and P8 both agreed that they would not see any threat of manipulation in the current state of the robot. P8 and SH3 also elaborated that she considered it non-problematic to create the illusion of emotion as long as the users had a positive experience. P7 added that many books and movies also created illusions and that those were not seen as ethically questionable.
