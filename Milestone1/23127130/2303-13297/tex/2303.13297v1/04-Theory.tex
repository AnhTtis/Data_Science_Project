\section{Heuristic Analysis}
\label{sec:theory_proof}
In section~\ref{sec:method} we cast DG as a domain convex game and present the detailed formulation of our framework which revolves around the proposed regularization term.
Though this term is designed directly according to the supermodularity and has clear objective to achieve our goals, someone may still be curious about the mechanisms behind its effectiveness.
So in this section, we provide some heuristic analyses and intuitive explanations to further validate the rationality.

For brevity, we take $S=\{(\boldsymbol{x}_i, y_i)\}$ and $T=\{(\boldsymbol{x}_j,y_j)\}$ as an example, where $\boldsymbol{x}_i$ and $\boldsymbol{x}_j$ are from different domains.
According to Eq.~\eqref{eq:l_reg}, the optimization goal of our proposed regularization is to make the following inequality hold:
\begin{equation}\small
\begin{split}
    &\mathcal{G}(\boldsymbol{\theta} - \nabla_{\boldsymbol{\theta}}\ell(f(\boldsymbol{x}_i,\boldsymbol{\theta}),y_i) -\nabla_{\boldsymbol{\theta}}\ell(f(\boldsymbol{x}_j,\boldsymbol{\theta}),y_j))  + \mathcal{G}(\boldsymbol{\theta})\\
    & - \mathcal{G}(\boldsymbol{\theta} - \nabla_{\boldsymbol{\theta}} \ell(f(\boldsymbol{x}_i,\boldsymbol{\theta}),y_i))
     - \mathcal{G}(\boldsymbol{\theta} - \nabla_{\boldsymbol{\theta}} \ell(f(\boldsymbol{x}_j,\boldsymbol{\theta}),y_j)) \le 0.
\end{split}
\label{eq:example_obj}
\end{equation}
We then carry out the second-order Taylor expansion on the terms in Eq.~\eqref{eq:example_obj} and obtain:
\begin{equation}
\small
\begin{split}
    &(\nabla_i + \nabla_j)^T H (\nabla_i + \nabla_j) -  \nabla_i^T H \nabla_i - \nabla_j^T H \nabla_j \\
   & =\nabla_i^T H \nabla_j + \nabla_j^T H \nabla_i    \le 0   ,
\end{split}
\label{eq:taylor_expansion}
\end{equation}
$\nabla_i, \nabla_j$ denote $\nabla_{\boldsymbol{\theta}} \ell(f(\boldsymbol{x}_i,\boldsymbol{\theta}),y_i)$, $\nabla_{\boldsymbol{\theta}} \ell(f(\boldsymbol{x}_j,\boldsymbol{\theta}),y_j)$ respectively, $H = \frac{ \partial^{2} \mathcal{G}(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^T}$ is the Hessian matrix of $\mathcal{G}(\boldsymbol{\theta})$.
We can see that all the zero- and first-order terms of the Taylor-expansion have been dissolved and only the second-order terms are left, which makes the optimization more stable.


Since Hessian matrix $H$ is a real symmetric matrix, for the case where $H$ is positive (negative) definite, we can perform Cholesky decomposition on $H (-H)$ as $L^T L$, where $L$ is an upper triangular matrix with real and positive diagonal elements. Thus, Eq.~\eqref{eq:taylor_expansion} can be further deduced as follows:
\begin{equation}
\small
\begin{split}
&\nabla_i^T H \nabla_j + \nabla_j^T H \nabla_i\\
& =
\begin{cases}
    (L \nabla_i)^T (L \nabla_j) + (L \nabla_j)^T (L \nabla_i) \le 0,& \text{$H \succ 0$,}\\
    -((L \nabla_i)^T (L \nabla_j) + (L \nabla_j)^T (L \nabla_i)) \le 0,& \text{$H \prec 0$.}
    \end{cases}
\end{split}
\label{eq:h_decomposition}
\end{equation}
Denote $L \nabla_i, L \nabla_j$ as $\tilde{\nabla_i}, \tilde{\nabla_j}$ respectively, which can be regarded as a mapping transformation of the original gradients. Specifically, $\nabla_i, \nabla_j$ are sample gradients generated in the original "training space" during the meta-training process, while $\tilde{\nabla_i}, \tilde{\nabla_j}$ are sample gradients transformed by matrix $L$. Since $L$ is derivated from the regularization term calculated on meta-test data that can indicate the model generalization, we can intuitively regard the transformed $\tilde{\nabla_i}, \tilde{\nabla_j}$ as sample gradients mapped to a "generalization space". Therefore, constraining sample gradients in this mapped "generalization space" may generalize better on the real test set compared to constraining the gradients in the original "training space".

Then two main cases can be analysed respectively.
\begin{case}
For Hessian matrix $H \prec 0$ (a.k.a. negative definite), Eq.~\eqref{eq:taylor_expansion} holds when \lv{${\tilde{\nabla_i}}^T\tilde{\nabla_j} \ge 0$}.
\label{cond:non-positive}
\end{case}

\textbf{\textit{mechanism.}}
When $H \prec 0$, i.e., achieving local maxima, which suggests inferior model generalization, the proposed regularization would help the model improve by enforcing domain consistency on discriminability, that is, pulling the samples from different classes apart and bringing the ones from the same class closer \lv{in the "generalization space"}. 
As for sample filtering, samples that possess inconsistent gradients, e.g., noisy samples, are more prone to be discarded.


\textbf{\textit{analysis.}}
\lv{As Eq.~\eqref{eq:h_decomposition} shows, our regularization aims to make the inner product of transformed sample gradients positive when $H \prec 0$, i.e., make the sample gradients consistent in the "generalization space".}
Assuming samples $\boldsymbol{x}_i$, $\boldsymbol{x}_j$ belong to the same class, then their transformed gradients will be inconsistent when they are apart in the "generalization space", and be consistent when they are close.  
In contrast, if $\boldsymbol{x}_i$, $\boldsymbol{x}_j$ are from different classes, their transformed gradients would certainly be inconsistent if the samples are close, since they share the same model while possessing different labels. Thus, the optimization of our regularization will draw the samples from the same class closer while pulling the ones from different classes apart to make the gradients consistent, which enforces domain consistency on discriminability. 
\lv{As for sample filtering, the samples that possess very inconsistent gradients are contrary to our goal most and are more likely to obtain larger scores, which are generally noise samples since they are often located at outliers. Therefore, the noise samples are more prone to be discarded in this case.}

\begin{case}
For Hessian matrix $H \succ 0$ (a.k.a. positive definite), Eq.~\eqref{eq:taylor_expansion} holds when \lv{${\tilde{\nabla_i}}^T\tilde{\nabla_j} \le 0$}.
\label{cond:positive}
\end{case}

\textbf{\textit{mechanism.}}
When $H \succ 0$, i.e., achieving local optima, the proposed regularization would help the model jump out by further squeezing out the information within hard samples, that is, detecting the hard samples and then assigning them larger weights implicitly. As for sample filtering, samples that possess very consistent gradients, e.g., redundant samples, are more prone to be discarded.

\textbf{\textit{analysis.}}
As Eq.~\eqref{eq:h_decomposition} shows, our regularization aims to make the inner product of the transformed sample gradients negative  when $H \succ 0$, i.e., make the gradients inconsistent in the "generalization space". This objective is contrary to our main supervision loss that aims to make all the samples clustered, so it can be regarded as an adversarial optimization. Concretely, the regularization enables the model to generate and detect samples with inconsistent gradients which generally be hard samples since they are often far away from the class center. Then these hard samples would contribute more to the main supervision loss and thus can be considered as being assigned larger weights implicitly during the optimization, just like the mechanism of focal loss~\cite{focal_loss}. Thus, our regularization can help model jump out of the local optima by squeezing out more information within hard samples, avoiding the model depending on easy patterns or even overfitting on redundant ones. 
For sample filtering, the samples that produce very consistent gradients, which also means they are redundant ones to a certain, are more likely to be detrimental to our regularization loss and be filtered. 


For the general case that $H$ is not fully positive or negative definite, we can take SVD decomposition and regard the model as combined by positive or negative definite sub-matrices. Then our conclusion holds for each subspace represented by each submatrix.
