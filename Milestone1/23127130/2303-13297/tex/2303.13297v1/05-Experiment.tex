    
\section{Experiments}
\label{sec:exp}

\subsection{Dataset and Implementation Details}
\label{sec:dataset}
To evaluate our method, we conduct extensive experiments on three popular benchmarks for DG:
\noindent\textbf{PACS}\cite{pacs} is an object recognition benchmark that covers 9991 images of 7 categories from four different domains, i.e., Art, Cartoon, Photo and Sketch, which with large discrepancy in image styles.
\noindent\textbf{Office-Home}\cite{home} is a commonly-used benchmark including four domains (Art, Clipart, Product, RealWorld). It contains
15,500 images of 65 classes in total.
\noindent\textbf{mini-DomainNet}\cite{dael} is a very large-scale domain generalization benchmark consists of about 140k images with 126 classes from four different domains (Clipart, Painting, Real, Sketch).
For all benchmarks, we conduct the commonly used leave-one-domain-out experiments~\cite{DBA} and adopt ResNet-18/50 pre-trained on ImageNet~\cite{resnet} as backbone.
We train the network using mini-batch SGD with batch size 16, momentum 0.9 and weight decay 5e-4.
The initial learning rate is 0.001 and decayed by 0.1 at 80\% of the total epochs. 
For hyper-parameters, we set $\omega = 0.1$ and $k=5$ for all experiments, which are selected on validation set following standard protocol.
All results are reported based on the average accuracy over three independent runs. More details and results with error bars are provided in Appendix. 



\subsection{Experimental Results}


\begin{table}
%   \setlength{\tabcolsep}{3.0pt}
  \centering
  \small
%   \vspace{-5mm}
    % \vspace{-2mm}
    %   \setlength{\tabcolsep}{0.4mm}{
      \resizebox{\columnwidth}{!}{
      \begin{tabular}{l|cccc|c}
      \toprule
      Methods & Art & Cartoon & Photo & Sketch & Avg. \\
      \midrule
      \multicolumn{6}{c}{\textit{ResNet18}} \\
      \midrule
      DeepAll\cite{FACT} & 77.63 & 76.77 & 95.85 & 69.50 & 79.94 \\
    %   MetaReg~\cite{MetaReg} & 83.70& 77.20 & 95.50 & 70.30 & 81.70 \\
    %   JiGen~\cite{Jigen} & 79.42 & 75.25 & 96.03 & 71.35 & 80.51 \\
      MLDG~\cite{MLDG} & 78.70 & 73.30 & 94.00 & 65.10 & 80.70 \\
      MASF~\cite{MASF} & 80.29 & 77.17 & 94.99 & 71.69 & 81.04 \\
      L2A-OT~\cite{L2A-OT} & 83.30 & 78.20 & \underline{96.20} & 73.60 & 82.80 \\
      DDAIG~\cite{DEEPALL} & 84.20 & 78.10 & 95.30 & 74.70 & 83.10 \\
      RSC~\cite{RSC} & 83.43 & \underline{80.31} & 95.99 & 80.85 & 85.15 \\
      MixStyle ~\cite{MixStyle} & 84.10 &  78.80 & 96.10 &  75.90 & 83.70 \\
      FACT \cite{FACT}& \underline{85.37} &78.38& 95.15& 79.15 &84.51 \\
      % \lv{ITL-Net\cite{ITL-Net} } & 83.90 & 78.90 & 94.80 & 80.10 & 84.40 \\
      \lv{DSU~\cite{DSU} } & 83.60 &79.60& 95.80& 77.60& 84.10\\
      \lvv{STNP}~\cite{STNP} & 84.41 & 79.25 & 94.93 & \textbf{83.27} & \underline{85.47}\\
      \midrule
      DCG (\textit{ours})  & \textbf{85.94} &	\textbf{80.76}	& \textbf{96.41} &	\underline{82.08}	& \textbf{86.30} \\
      \midrule
      \multicolumn{6}{c}{\lvv{\textit{ResNet50}}} \\
      \midrule
      DeepAll~\cite{FACT} & 84.94 & 76.98 & 97.64 & 76.75 & 84.08 \\
      % MetaReg~\cite{MetaReg} & 87.20 & 79.20 & 97.60 & 70.30 & 83.60 \\
      % MASF~\cite{MASF}  & 82.89 & 80.49 & 95.01 & 72.29 & 82.67 \\
      % EISNet~\cite{EISNet} & 86.64 & 81.53 & 97.11 & 78.07 & 85.84 \\
      % MatchDG \cite{MatchDG} & 85.61 & 82.12 & \textbf{97.94} & 78.76 & 86.11 \\
      % \lv{Contrastive-ACE~\cite{contrastive-ACE}} & \lv{88.8} &\lv{ 81.9} & \lv{97.7} & \lv{80.6} & \lv{87.3}\\
      RSC~\cite{RSC} & 87.89 & 82.16 & \underline{97.92} & 83.35 & 87.83 \\
      % FACT \cite{FACT} & 89.63 & 81.77 & 96.75 & 84.46 & 88.15 \\
      FACT \cite{FACT} & 89.63 & 81.77 & 96.75 & 84.46 & 88.15 \\
      DDG~\cite{DDG}  &88.90& \underline{85.00}& 97.20& 84.30& 88.90\\
      PCL~\cite{PCL} &90.20& 83.90& \textbf{98.10}& 82.60& 88.70\\
      STNP~\cite{STNP} &\textbf{90.35}& 84.20& 96.73& \underline{85.18}& \underline{89.11}\\
      \midrule
      DCG (\textit{ours}) & \underline{90.24} & \textbf{85.12} & 97.76 & \textbf{86.31} & \textbf{89.84} \\
      \bottomrule
      \end{tabular}}
      \vspace{-2mm}
      \caption{Leave-one-domain-out results on PACS.}
    \label{tab:pacs_res18}
  \vspace{-3mm}
\end{table}

\noindent\textbf{Results on PACS} \lvv{based on ReNet-18 and ResNet-50 are summarized in Table~\ref{tab:pacs_res18}. 
It is clear that DCG achieves the best performance among all the competitors \lvv{on both backbones}.
% Our method is the first to reach $86\%$ average accuracy on PACS dataset, which exceeds the DeepAll baseline by $6.
% 4\%$.
We notice that DCG surpasses the Fourier based augmentation method FACT by a large margin of $1.8\%$ and $1.7\%$ on ResNet-18 and ResNet-50, respectively, which indicate the importance of encouraging each domain to contribute to model generalization.
Especially, on the harder target domains Cartoon and Sketch, our method still outperforms the SOTA. 
There also exist cases where DCG performs relatively poorly, this may due to the task is relatively simple (e.g. \textit{photo}).
In general, the comparisons reveal the effectiveness of DCG and further demonstrate that the convex game between domains improves model generalization.}

\begin{table}
  %   \setlength{\tabcolsep}{3.0pt}
    \centering
    \small
        %\setlength{\tabcolsep}{0.4mm}{
        \resizebox{\columnwidth}{!}{
        \begin{tabular}{l|cccc|c}
        \toprule
        Methods & Art & Clipart & Product & Real & Avg. \\
        \midrule
        DeepAll  & 57.88 & 52.72 & 73.50 & 74.80 & 64.72 \\
      %   CCSA~\cite{CCSA}  & 59.90 & 49.90 & 74.10 & 75.70 & 64.90 \\
        MLDG~\cite{MLDG} &52.88 & 45.72 & 69.90 & 72.68 & 60.30 \\
        SagNet~\cite{SagNet}  & 60.20  &45.38& 70.42& 73.38& 62.34\\
      %   MMD-AAE~\cite{MMD-AAE} & 56.50 & 47.30 & 72.10 & 74.80 & 62.70 \\
      %   CrossGrad~\cite{CrossGrad} & 58.40 & 49.40 & 73.90 & 75.80 & 64.40 \\
      %   Jigen~\cite{Jigen} & 53.04 & 47.51 & 71.47 & 72.79 & 61.20 \\
        RSC~\cite{RSC}   & 58.42 & 47.90 & 71.63 & 74.54 & 63.12 \\
        DDAIG~\cite{DEEPALL} & 59.20 & 52.30 & 74.60 & 76.00 & 65.50 \\
        L2A-OT~\cite{L2A-OT} & \underline{60.60} & 50.10 & \underline{74.80} & \textbf{77.00} & 65.60 \\
        MixStyle~\cite{MixStyle} & 58.70 & 53.40 & 74.20 & 75.90 & 65.50\\
        FACT \cite{FACT}& 60.34 & 54.85 & 74.48 & 76.55 & \underline{66.56} \\
        \lv{DSU~\cite{DSU}} & 60.20 & 54.80 & 74.10 & 75.10 & 66.10 \\
        \lvv{STNP~\cite{STNP}} & 59.55 & \underline{55.01} & 73.57 & 75.52 & 65.89\\
        \midrule
        DCG (\textit{ours}) & \textbf{60.67} &	\textbf{55.46} &	\textbf{75.26}	& \underline{76.82} &	\textbf{67.05}  \\
        \bottomrule
        \end{tabular}}
        \vspace{-2mm}
        \caption{Leave-one-domain-out results on Office-Home.
        %   with ResNet-18. The best and second-best results are bold and underlined.
        }
      \label{tab:officehome}
      \vspace{-5mm}
  \end{table}
  
  
  
  \noindent\textbf{Results on Office-Home} \lvv{based on ReNet-18} are presented in Table~\ref{tab:officehome}, where we beat all the compared baselines in terms of the average accuracy. 
  Due to the similarity to the pre-trained dataset ImageNet,
  DeepAll acts as a strong baseline on Office-Home.
  Many previous DG methods, such as MLDG, SagNet, and RSC, can not improve over the simple DeepAll baseline.
  Nevertheless, our DCG achieves a consistent improvement over DeepAll on all the held-out domains. 
  Moreover, DCG surpasses the latest domain augmentation methods L2A-OT and FACT. The incremental advantages may be due to the relatively smaller domain shift, where the decreasing marginal contribution of domains is more severe. 
  % However, this still justifies the superiority of DCG.
  
  
  


\begin{table}
%   \setlength{\tabcolsep}{0.5mm}
  \centering
  \small
%   \vspace{-0.5mm}
    %\setlength{\tabcolsep}{0.35mm}{
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{l|cccc|c}
    \toprule
    Methods & Clipart & Painting & Real & Sketch & Avg. \\
    \midrule
    DeepAll & 65.30 &	58.40	&64.70&	59.00&	61.86  \\
    ERM~\cite{ERM}  & 65.50 & 57.10 & 62.30 & 57.10 & 60.50 \\
     MLDG~\cite{MLDG} & 65.70 & 57.00 & 63.70 & 58.10 & 61.12 \\
     Mixup~\cite{mixup} & \underline{67.10} & 59.10 & 64.30 & 59.20 & 62.42 \\
    MMD~\cite{MMD} & 65.00 & 58.00 & 63.80 & 58.40& 61.30 \\
    SagNet~\cite{SagNet} & 65.00 & 58.10 & 64.20 & 58.10 & 61.35 \\
     CORAL~\cite{CORAL} & 66.50 & \underline{59.50} & \underline{66.00} & \underline{59.50} & \underline{62.87} \\
     MTL~\cite{MTL} & 65.30 & 59.00 & 65.60 & 58.50 & 62.10 \\
    \midrule
     DCG (\textit{ours}) & \textbf{69.38} &	\textbf{61.79}&	\textbf{66.34}&	\textbf{63.21}&	\textbf{65.18}  \\
    \bottomrule
    \end{tabular}}
    \vspace{-2mm}
    \caption{Leave-one-domain-out results on mini-DomainNet. 
    %   with ResNet-18. The best and second-best results are bold and underlined.
    }
  \label{tab:domainnet}
  \vspace{-5mm}
\end{table}





\begin{figure*}[t]
  \centering
  \vspace{-1mm}
   \includegraphics[width=1.0\linewidth]{Figures/Fig_visualization.pdf}
  \vspace{-7mm}
   \caption{The visualization of samples with top-$k$ and bottom-$k$ score respectively with Cartoon as the unseen target domain. }
   \label{fig:visualization}
   \vspace{-3mm}
\end{figure*}


\noindent\textbf{Results on Mini-DomainNet} \lvv{based on ReNet-18} are shown in Table~\ref{tab:domainnet}. The much larger number of categories and images makes DomainNet a much more challenging benchmark. DCG still achieves the state-of-the-art performance of $65.18\%$, surpassing the SOTA by a large margin of $2.31\%$. \lvv{It indicates that the waste of diversified information in large datasets is more serious, further validating our efficacy.}









\subsection{Analysis}


\noindent\textbf{Ablation Study.}
In Table~\ref{tab:ablation}, we investigate the role of each component in DCG, including Fourier augmentation (Aug.), supermodularity regularization (Reg. ($\mathcal{L}_{sm}$)) and sample filter (Filter. ($\mathcal{F}_{sm}$)).
The Baseline is trained only with the supervision loss of all the original source data. We incorporating our supermodularity regularization $\mathcal{L}_{sm}$ with the Fourier augmentation to obtain Model 3, which greatly surpasses Model 1, demonstrating the significance of encouraging each diversified domain to contribute to generalization. 
Besides, we aslo apply a regularization $\mathcal{L}_{maml}$ which sums the meta-test losses of all the tasks as MAML~\cite{MAML} to conduct Model 2, its inferiority to Model 3 indicates conducting 
\begin{table}
  \setlength{\tabcolsep}{0.4mm}
  \centering
  \small
  \centering
    % \setlength{\tabcolsep}{0.1mm}{
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{c|ccc|cccc|c}
    \toprule
    Method & Aug. & Reg. & Filter. & Art & Cartoon & Photo & Sketch & Avg.\\
    \midrule
    Baseline & - & - & - & 77.6 & 76.8 & 95.9 & 69.5 & \lv{79.9}\\
    \midrule
    Model 1 & $\checkmark$ & - & - & 83.9& 77.0 & 95.6 & 77.4 & \lv{83.4}\\
    Model 2 & $\checkmark$ & $\mathcal{L}_{maml}$ & - & 84.7 &	79.0 &	95.7 &	80.1 &	\lv{84.9}	\\
    Model 3 & $\checkmark$ & $\mathcal{L}_{sm}$ & - &85.1 &	80.1 &	95.9 &	81.4 & \lv{85.6} \\
    Model 4 & $\checkmark$ & - & $\mathcal{F}_{maml}$ & 84.1 &	77.7 &	95.5 &	78.2 &	\lv{83.9} \\
    Model 5 & $\checkmark$ & - & $\mathcal{F}_{sm}$ & 84.4 &	78.2 &	95.8 &	79.3 &	\lv{84.4} \\
    Model 6 & $\checkmark$ & $\mathcal{L}_{maml}$ & $\mathcal{F}_{maml}$ & 85.3 & 79.9 & 96.0 &	81.5 &	\lv{85.7} \\
    \midrule
    DCG & $\checkmark$ & $\mathcal{L}_{sm}$ & $\mathcal{F}_{sm}$ & \textbf{85.9} &	\textbf{80.8}&	\textbf{96.4} &	\textbf{82.1} &	\textbf{86.3}\\
    \bottomrule
    \end{tabular}}
    \vspace{-2mm}
    \caption{Ablation study of DCG on PACS dataset.}
  \label{tab:ablation}
 \vspace{-5mm}
\end{table}
convex game between domains is more helpful to generalization than simply applying the meta loss. 
Comparing Model 5 with Model 1, we can observe that the proposed sample filter is also conducive to generalization, suggesting the importance of eliminating nonprofitable information. Finally, DCG performs best in all variants, indicating that the two proposed components complement and benefit each other.


\begin{figure*}
  \centering
  \begin{subfigure}{0.23\linewidth}
  \includegraphics[width=1.0\linewidth]{Figures/Fig_increase_cartoon.pdf}
    \caption{Cartoon.}
    \label{fig:inc_cartoon}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.23\linewidth}
  \includegraphics[width=1.0\linewidth]{Figures/Fig_increase_sketch.pdf}
    \caption{Sketch.}
    \label{fig:inc_sketch}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.23\linewidth}
    \includegraphics[width=1.0\linewidth]{Figures/Fig_sensitivity_cartoon.pdf}
      \caption{Cartoon.}
      \label{fig:sens_cartoon}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.23\linewidth}
    \includegraphics[width=1.0\linewidth]{Figures/Fig_sensitivity_sketch.pdf}
      \caption{Sketch.}
      \label{fig:sens_sketch}
    \end{subfigure}
    \vspace{-2mm}
  \caption{(a)(b): relation between model generalization 
and domain diversity; (c)(d): sensitivity to hyper-parameters $\omega$ and $k$; with Cartoon and Sketch on PACS
dataset as the unseen target domain.}
  \vspace{-5mm}
\end{figure*}


\noindent\textbf{Generalization with Domain Diversity.}
Figure~\ref{fig:inc_cartoon},~\ref{fig:inc_sketch} show the model generalization with the increase of domain diversity. We use the classification accuracy on the held-out target domain as the metric of model generalization across domains, and the number of augmented domains to measure the domain diversity.
It is clear that on both Cartoon and Sketch tasks, the model generalization capability of the baseline methods do not necessarily improve with the increase of domain diversity, but sometimes decrease instead. While in our DCG, the model generalization increases monotonically with the domain diversity on the whole and the decrease of marginal contribution of domains is alleviated. 
Meanwhile, in a few cases, the generalization of DCG drops a little when domain diversity increases. This is reasonable since the additional augmented domains may be low-quality or harmful to generalization. 
The results demonstrate that our framework indeed encourages each diversified domain to contribute to model generalization, hence guarantee and further improve the performance of domain augmentation methods.




\noindent\textbf{Visualization of Filtered Samples.}
To visually verify that our sample filter can effectively eliminate low-quality samples, we provide the samples that obtain the top-$k$ / bottom-$k$ score the most times in the whole training process in Figure~\ref{fig:visualization}.
We can see that the discarded original samples with top-$k$ score in the first row either be noisy images that have messy background and fuzzy objects, or be images containing naive or classical information which may be redundant. While the high-quality original images in the bottom row are all vivid and rich in information. As for the augmented samples, the discarded ones are almost distinguishable while the retained high-quality ones are limpid.
These comparisons demonstrate the effectiveness of our sample filter.



\noindent\textbf{Sensitivity of Hyper-parameters.}
Figure~\ref{fig:sens_cartoon},~\ref{fig:sens_sketch} show the sensitivity of DCG to hyper-parameters $\omega$ and $k$. Specifically, the value of $\omega$ varies from $\{0.01, 0.05, 0.1, 0.5, 1,0\}$, while
$k$ changes from $\{1, 3, 5, 7, 9\}$.  
It can be observed
that DCG achieves competitive performances robustly under a wide range of hyper-parameter values, i.e., $0.05 \le \omega \le 0.3$ and $3 \le k \le 7$, in either task Cartoon or Sketch, which further verifies the stability of our method.





\subsection{Discussion}
\label{sec:discussion_main}

\begin{table}
%  \setlength{\tabcolsep}{0.8mm}
  \centering
  \small
 \resizebox{\columnwidth}{!}{
 \begin{tabular}{c|cccc|c}
    \toprule
     Methods & Art & Cartoon & Photo & Sketch & Avg.\\
    \midrule
     Random\_meta\_split &85.6	&80.2&	96.0&	81.8&	85.9\\
    \midrule
     Filter\_only\_on\_aug & 85.4 & 80.6 & 96.7 &	81.8 &	86.1 \\
     Filter\_only\_on\_ori & 85.2 &80.0 & 96.5 &	82.3 &	86.0\\
    \midrule
    DCG & \textbf{85.9} &	\textbf{80.8}&	\textbf{96.4} &	\textbf{82.1} &	\textbf{86.3}\\
    \bottomrule
    \end{tabular}}
    \vspace{-2mm}
    \caption{Leave-one-domain-out results on PACS.}
    \label{tab:discussion}
    \vspace{-5mm}
\end{table}
\noindent\textbf{How to conduct the meta-train and meta-test domains?}
In DCG, we considers all the diversified domains $\mathcal{D}_s \cup \mathcal{D}_s^{aug}$ into training. We first randomly split the original source domains $\mathcal{D}_s$ into meta-train and meta-test domains, next pick out the domains in $\mathcal{D}_s^{aug}$ that are augmented by the current meta-train domains and then merge them into together. Thus, there is no domain augmented by the meta-test domains in the meta-train domains, and vice versa. However, why don't we also randomly split $\mathcal{D}_s^{aug}$ into two parts, since each diversified domain can be regarded as a novel domain?
We conduct experiments of this variant and the results in Table~\ref{tab:discussion} shows inferior performance to DCG. 
This may be because the synthetic novel domains still contain part of the domain-related information of the original ones. In this view, the strategy to conduct meta-train/test domains in Section~\ref{sec:sm_reg} can guarantee the meta-test domains are completely unseen, which better simulates the domain shift between diversified source domains and the held-out unseen target domain.

\noindent\textbf{Is low-quality sample filtering necessary for both original and augmented samples?}
We conduct experiments that apply the proposed sample filter only on the original samples or augmented samples and the results are shown in Table~\ref{tab:discussion}. 
It can be seen that both variants suffer from a performance drop, which indicates that there exist low-quality samples among both original and augmented samples.
Limiting the filtering range will make some low-quality samples be retained to participate in the training process, which may damage the model generalization.
Besides, the performance of only filtering the original samples is slightly lower than that of only filtering the augmented ones, which should be due to the augmented samples being less natural.


