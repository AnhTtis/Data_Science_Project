\section{Introduction}
\label{sec:intro}
Owning extraordinary representation learning ability, deep neural networks (DNNs) have achieved remarkable success on a variety of tasks when the training and test data are drawn from the same distribution ~\cite{DeepLearning,resnet,DeepLearning2}. 
Whereas for out-of-distribution data, DNNs have demonstrated poor generalization capability since the i.i.d. assumption is violated, which is common in real-world conditions~\cite{RTN,MMAN,robustness}. 
To tackle this issue, domain generalization (DG) has become a propulsion technology, aiming to learn a robust model from multiple source domains so that can generalize well to any unseen target domains with different statistics~\cite{MetaReg,DICA,MMD-AAE,DBA}. 

Among extensive solutions to improve generalization, domain augmentation~\cite{AdvAug,CrossGrad,MixStyle,FACT} has been a classical and prevalent strategy, which focuses on exposing the model with more diverse domains via some augmentation techniques. A common belief is that generalizable models would become easier to learn when the training distributions become more diverse, which has been also emphasized by a recent work~\cite{DomainAug}. 
Notwithstanding the promising results shown by this strand of approaches, the claims above are vague and lack of theoretical justification, formal analyses of the relation between domain diversity and model generalization are sparse. 
Further, the transfer of knowledge may
even hurt the performance on target domains in some cases, which is referred to as negative transfer~\cite{TransferLearning, DistantTL}. Thus the relation of domain diversity and model generalization remains unclear. In light of these points, we begin by considering the question: \textbf{The stronger the domain diversity, will it certainly help to improve the model generalization capability?}



\begin{figure}[t]
    \centering
    \begin{subfigure}{0.493\linewidth}
      \includegraphics[width=1.0\linewidth]{Figures/Fig_motivation_cartoon.pdf}
      \caption{Cartoon.}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.493\linewidth}
    \includegraphics[width=1.0\linewidth]{Figures/Fig_motivation_sketch.pdf}
      \caption{Sketch.}
    \end{subfigure}
    \caption{The relation between model generalization and domain diversity with Cartoon and Sketch on PACS dataset as the unseen target domain, respectively. \lv{$N$ is the maximum number of augmented domains. Note that the \textit{solid lines} denote the actual results of a BASELINE method that combines DeepAll with Fourier augmentation strategy and a SOTA domain augmentation method FACT, while the \textit{dash lines} represent the ideal relation in this work. }}
    \label{fig:motivation}
    \vspace{-8mm}
  \end{figure}


\lvv{To explore this issue, we first quantify domain diversity as the number of augmented domains. Then we conduct a brief experiment using Fourier augmentation strategy~\cite{FACT} as a classical and representative instance.}
% We conduct a brief experiment to explore this question.
The results presented in Fig~\ref{fig:motivation} show that with the increase of domain diversity, the model generalization (measured by the accuracy on unseen target domain) \lvv{may} not necessarily increase, but sometimes decreases instead, as the solid lines show.
On the one hand, this may be because the model does not best utilize the rich information of diversified domains; on the other hand, it may be due to the existence of low-quality samples which contain redundant or noisy information that is unprofitable to generalization~\cite{CleanNet}.
This discovery indicates that there is still room for improvement of the effectiveness of domain augmentation if we enable each domain to be certainly conducive to model generalization as the dash lines in Fig~\ref{fig:motivation}.

In this work, we therefore aim to ensure the strictly positive correlation between model generalization and domain diversity to guarantee and further enhance the effectiveness of domain augmentation.
% \lvv{Given the target domain is unseen in DG, this correlation is difficult to be directly guaranteed in training. What we can do instead is to make the training domains cooperate better when the number of augmented domain increases. }
% This problem then can be naturally cast into a convex game between domains, the property of which is to achieve maximum benefits via full data cooperation.
To do this, we take inspiration from the literature of convex game that requires each player to bring profit to the coalition~\cite{ConvexGame,supermodularity,convexfuzzygame}, which is consistent to our key insight, i.e, make each domain bring benefit to model generalization. Thus, we propose to formalize DG as a convex game between domains.
First, we design a novel regularization term based on the supermodularity of convex game.
This regularization encourages each diversified domain to contribute to improving model generalization, thus enables the model to better exploit the diverse information.
In the meawhile, considering that there may exist samples with unprofitable or even harmful information to generalization, we further construct a sample filter based on the proposed regularization to get rid of the low-quality samples such as noisy or redundant ones, so that their deterioration to model generalization can be avoided.
We provide some heuristic analyses and intuitive explanations about the mechanisms behind to demonstrate the rationality in Section~\ref{sec:theory_proof}.


Nevertheless, it is well known that the supermodularity also indicates increasing marginal contribution, which may not hold intuitively in DG, where the marginal contribution of domains is generally decreasing. To mitigate the gap between theory and practice, we impose a constraint on the naive supermodularity when construct our regularization term. We constrain the regularization to work only in case that the supermodularity is violated, i.e., when the marginal contribution of domains decreases. Thus, the limit of our regularization optimization is actually to achieve a \emph{constant marginal contribution}, rather than an impracticable \emph{increasing marginal contribution}.
Hence, our regularization can additionally regularize the decreasing speed of the marginal contribution as slow as possible by optimizing towards the \emph{constant marginal contribution}, just like changing the line \textit{Ideal (a)} in Fig~\ref{fig:motivation} into line \textit{Ideal (b)}.
Generally, the role of our proposed supermodularity regularization is to encourage the contribution of each domain, and further relieve the \emph{decreasing marginal contribution} of domains to a certain extent, so as to better utilize the diversified information.


\textbf{Contributions.} Our contributions in this work include: (i) Exploring the relation of model generalization and source domain diversity, which reveals the limit of previous domain augmentation strand;
(ii) Introducing convex game into DG to guarantee and further enhance the validity of domain augmentation. The proposed framework encourages each domain to conducive to generalization while avoiding the negative impact of low-quality samples, enabling the model to better utilize the information within diversified domains;
(iii) Providing heuristic analysis and intuitive explanations about the rationality. The effectiveness and superiority are verified empirically across extensive real-world datasets.





