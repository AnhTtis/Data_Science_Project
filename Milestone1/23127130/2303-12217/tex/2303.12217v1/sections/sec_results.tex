\section{Experimental Results}


% \subsection{Model Selection} \label{sec:results-model-selection}

%\subsection{Learning the IGM to solve inverse problems} \label{sec:results-joint}
We now consider solving a set of inverse problems via the framework described in \ref{sec:learning}. For each of these experiments, we use a multivariate Gaussian distribution to parameterize each of the posterior distributions $q_{\phi^{(i)}}$ and a Deep Decoder \cite{HH2018} with $6$ layers of size $150$, a latent size of $40$, and a dropout of $10^{-4}$ as the IGM. The multivariate Gaussian distributions are parameterized by means and covariance matrices $\{\mu^{(i)}, \Lambda^{(i)} = L^{(i)}L^{{(i)}^T} + \varepsilon I\}_{i = 1}^N$, where $\varepsilon I$ with $\varepsilon = 10^{-3}$ is added to the covariance matrix to help with stability of the optimization.

%We choose to parameterize the posterior using simple Gaussian distributions due to memory constraints. %; the memory of the whole setup with Normalizing Flows using 75 images is around 5 times larger than the setup using a Gaussian variational family. 
%Note that we do not employ early stopping.   


%We train for 99,000 epochs using the Adam \cite{kingma2014adam} optimizer with a learning rate of 1e-4, which takes around 54 hours for 75 images and 4 hours for 4 images on a single NVIDIA A100 GPU. We use a batch size of 20 samples per measurement $i$, and we perform batch gradient descent based on all measurements $i \in \{1, \dots, N\}$.


% \subsubsection{Denoising with MNIST}
% We show results on denoising noisy images of 8's from the MNIST digits dataset in Fig~\ref{fig:MNIST_denoising} and denoising noisy images from a single face in Fig~\ref{fig:Bond_Denoising}. The measurements for both are defined by $y = x + \eta$ where $\eta \sim \mathcal{N}(0,0.1I)$. The reconstructed images become sharper as the number of measurements increases because we are learning a stronger image formation model.'

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.45\textwidth]{figures/bonddenoise.pdf}
%     \caption{\textbf{Denoising 95 images of a celebrity.} We demonstrate our method described in \ref{sec:learning} using 95 noisy images of a celebrity. Here we show the ground truth (top), noisy measurements (middle), and mean reconstruction (bottom) for a subset of the 95 different noisy images. Our reconstructions are much less noisy, exhibiting sharper features that are hard to discern in the noisy images. Note that no predefined prior/regularizer was used in denoising.}
%     \label{fig:Bond_Denoising}
% \end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/bondbaselines.pdf}
    \caption{\textbf{Denoising baseline comparisons.} We compare to AmbientGAN, DIP, and TV-RML with weight $\lambda$, and we report the average PSNR across all 95 reconstructions. We show both early stopping and full training results using DIP. Our method exhibits higher PSNR and less noise than all other baselines while maintaining distinct features of the ground-truth images.}
    \label{fig:bondbaselines}
\end{figure}

\subsection{Denoising}
 We show results on denoising noisy images of a single face from the PubFig \cite{kumar2009attribute} dataset in Fig.~\ref{fig:bondbaselines}. The measurements for both are defined by $y = x + \eta$ where $\eta \sim \mathcal{N}(0,\sigma^2I)$ with an SNR of $\sim$54 for the faces. Our method is able to remove much of the noise and recovers small scale features, even with only 95 examples. Our reconstructions also substantially outperform the baseline methods AmbientGAN \cite{bora2018ambientgan}, Deep Image Prior (DIP) \cite{ulyanov2018deep}, and regularized maximum likelihood using total variation (TV-RML), as shown in Fig.~\ref{fig:bondbaselines}. Unlike DIP, our method does not seem to overfit and does not require early stopping. Our method also does not exhibit noisy artifacts like those seen in AmbientGAN results.
 

\begin{figure}[ht]
    \centering
    \includegraphics[width=.48\textwidth]{figures/uvcoverage.pdf}
    \caption{\textbf{Visualization of the intrinsic resolution of the EHT compressed sensing measurements.} The EHT measures sparse spatial frequencies of the image (i.e., components of the image's Fourier transform). In order to generate the ground truth image (c), all frequencies in the entire domain of (a) must be used. Restricting spatial frequencies to the ones in (a) and (b)'s green circle generates the target (d). 
    %The region inside the green circle represents the maximum resolution of the EHT. 
    The EHT samples a subset of this region, indicated by the sparse black samples in (b). Naively recovering an image using only these frequencies results in the \textit{dirty image} (e), which is computed by $A^Hy$. 
    The 2D spatial Fourier frequency coverage represented with $(u, v)$ positions is referred to as the UV coverage. \textcolor{red}{update the results to the current ones}
    }
    \label{fig:uvcoverage}
\end{figure}
\vspace{-.3em}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/bh_timevangle.pdf}
    \caption{\textbf{Compressed sensing with a video of a black hole.} We demonstrate our method described in \ref{sec:learning} using 60 images from an evolving black hole target. Here we show the ground-truth, dirty ($A^Hy$), and mean reconstruction images, respectively. We also show the unwrapped space Ã— time image, which is taken along the overlaid white ring illustrated in the T=1 ground-truth image. The bright-spot's temporal trajectory of our reconstruction matches that of the ground-truth.\textcolor{red}{remove this}}
    \label{fig:BH_compressed_sensing}
\end{figure}

\subsection{Compressed sensing}
We consider a compressed sensing problem inspired by astronomical imaging of black holes with the Event Horizon Telescope (EHT): suppose we are given access to measurements of the form $y = Ax + \eta,\ \eta \sim \mathcal{N}(0,\sigma^2 I)$ where $A\in \mathbb{C}^{p \times n}$ is a low-rank compressed sensing matrix arising from interferometric telescope measurements. This problem is ill-posed and requires the use of priors or regularizers to recover a reasonable image \cite{akiyama2019first4}. Moreover, it is impossible to acquire ground-truth images of black holes, so any explicit prior defined {\it a priori} will exhibit human bias. However, we can assume that although the black hole evolves, it will not change drastically from day-to-day. 
%source does not change much day to day, which matches the assumptions of our approach.

We show results on 60 frames from a video of a simulated evolving black hole target \cite{porth2019event, akiyama2019first5} with an SNR of $\sim$7 in Fig.~\ref{fig:BH_compressed_sensing}. Our reference target image is the ground-truth filtered with a low-pass filter that represents the maximum resolution intrinsic to the EHT array, which is visualized and explained in Fig.~\ref{fig:uvcoverage}. 
%In particular, we use a maximum resolution of $20 \mu\text{as}$ \cite{akiyama2019first4}.
Our method is not only able to reconstruct the large scale features of the ground-truth images without any aliasing artifacts, but also  achieves a level of super-resolution. Our reconstructions also achieve higher super-resolution than the baselines, as seen in Fig.~\ref{fig:BH_compressed_sensing}, and do not exhibit artifacts evident in the AmbientGAN and TV-RML baselines. %We additionally note that the reconstructions from DIP are strong in this case, which is partially due to the fact that the DIP is not prone to overfitting in compressed sensing problems \cite{CS_untrained_nets}.


\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{figures/bh_baselines.pdf}
    \caption{\textbf{Baselines for compressed sensing with a video of a black hole.} We compare our method to various baselines methods. Our results are much sharper and exhibit less artifacts than AmbientGAN and TV-RML with weight $\lambda$.}
    \label{fig:BH_compressed_sensing}
\end{figure}


% \begin{figure}
%     \centering
%     \includegraphics[width=0.48\textwidth]{figures/bondbaselines.pdf}
%     \caption{\textbf{Denoising baseline comparisons.} We compare to various baselines (AmbientGAN, Deep Image Prior (DIP), and regularized maximum likelihood using TV (TV-RML) with weight $\lambda$, and we report the average PSNR across all 75 reconstructions. We show both early stopping and full training results using DIP. Our method exhibits substantially PSNR and less noise than all other baselines while maintaining distinct features that are smoothed out by DIP.}
%     \label{fig:bondbaselines}
% \end{figure}

% \subsection{Phase retrieval} Here we demonstrate a limitation of our approach with an example where our method obtains sub-optimal performance. In particular, we consider the non-linear inverse problem of phase retrieval. Our measurements are described by $y^{(i)} = |\mathcal{F}(x^{(i)})| + \eta^{(i)}$ where $\mathcal{F}$ is the Fourier transform and $\eta^{(i)} \sim \mathcal{N}(0, \sigma^2 I)$. Since each measurement is the magnitude of the Fourier transform, possible reconstructed images include all spatial shifts. Due to the severe ill-posedness of the problem, representing this complicated posterior that includes all spatial shifts is challenging. Thus, we incorporate an envelope as the final layer of $G_{\theta}$ to encourage the reconstruction to be centered. Nonetheless, multiple shifts are still possible within this enveloped region. 

% We show results from 75 noisy phase retrieval measurements from the MNIST 8's class with an SNR of $\sim$0.04 in Fig.~\ref{fig:Mnist_phase_retrieval}. Our reconstructions have features similar to the digit $8$, but contain significant artifacts. These artifacts are due to the fact that a highly multi-modal distribution is being represented by a unimodal Gaussian variational distribution. In denoising, increasing the number of measurements $N$ improved the IGM; however, this shift ambiguity will remain even if we increase the number of available measurements.
%increasing the number of measurements $N$ does not reduce the space of possible allowed shifts in the image domain. 
%affect the reconstructed location of each $8$. if we increased the number of measurements $N$, we would still need additional structure since it is equally plausible that the ground truth is either all shifted 8's or all centered 8's. 
% This problem would benefit from a translation-invariant generator $G_{\theta}$, which would simplify the complexity of the posterior distribution. We save this for future work.



% \begin{figure}
%     \centering
%     %\includegraphics[width=0.95\textwidth]{figures/mnist8_phase-retrieval.pdf}
%     \caption{\textbf{Phase retrieval from MNIST 8's.} We demonstrate our method described in \ref{sec:learning} to perform phase retrieval on 75 images. Here we show the target image, the log magnitude of the Fourier transform, mean of the posterior, standard deviation of the posterior, and samples from the posterior. Note that the posterior samples exhibit diversity even with a simple Gaussian latent distribution.}
%     \label{fig:Mnist_phase_retrieval}
% \end{figure}

% \subsection{Generalization to new data and forward models}

% We consider generalizing to new measurements given an IGM $G_{\theta}$ learned using the methods described in Section \ref{sec:learning}. These measurements could be from the same forward model (e.g., the IGM was trained with noisy MNIST digits, and we want to use it to denoise an unseen 
% MNIST digit) or from a different forward model (e.g., the IGM was trained with noisy MNIST digits, and we want to use it to perform compressed sensing on an MNIST digit), but the measurements are all from the same underlying ground-truth image distribution that the IGM was originally trained with. To solve the new inverse problem, we learn the latent posterior $z \sim q_{\phi}(z)$ given fixed weights $m$ of the IGM $G_{\theta}$ and our measurement $y$ using Eq.~\ref{eqref:ELBOProxy}. Due to the additional complexity in generalizing to a new image and forward model, we parameterize $q_{\phi}$ with a Normalizing Flow model. We show results in Fig.~\ref{fig:generalization} showcasing the generalization performance of an IGM pre-trained on $75$ noisy images to 1) novel images under the same forward model and 2) novel images under a different forward model. Our method is able to reconstruct primary features of the face in both generalization tests. This demonstrates that the IGM avoids overfitting to specific images and measurements, and is able to learn generalizable properties of the underlying data distribution even from few examples.

% \begin{figure}
%     \centering
%     %\includegraphics[width=.75\textwidth]{figures/generalization.pdf}
%     \caption{\textbf{Generalization to novel measurements.} We show results using an IGM trained on 75 noisy images to solve inverse problems on novel measurements/images. These ground-truth images were not used during training. We perform denoising on the left and compressed sensing on the right. Note that when performing compressed sensing, there are two sources of novelty: the underlying ground-truth image and the forward model. }
%     \label{fig:generalization}
% \end{figure}

% \subsection{Learning a prior from multiple forward models}

% The framework we introduce can also be applied to situations in which one has access to a collection of measurements where the measurements themselves are induced by different forward models. For example, if one had access to noisy images corrupted by Gaussian noise and linear measurements, one could in principle learn a prior from these observations jointly. Importantly, we require that the underlying images themselves all share common structure. We show examples of reconstructions from a prior that was learned from a collection of...