

\vspace{-4mm}
\section{Introduction}
\vspace{-3mm}
In imaging inverse problems, the goal is to recover the ground-truth image from corrupted measurements, where the measurements and image are related via a forward model: $y = f(x) + \eta$. Here, $y$ are our measurements, $x$ is the ground-truth image, $f$ is a known forward model, and $\eta$ is noise. Such problems are ubiquitous and include denoising \cite{Burger2012}, super-resolution \cite{CandesGranda}, compressed sensing \cite{CandesRombergTao2006, Dono2007}, and phase retrieval \cite{Numerics-of-PR}. These problems are often ill-posed: there are many images that are consistent with the observed measurements. Thus, traditionally structural assumptions on the image are required to reduce the space of possible solutions. We encode these structural assumptions in an \textit{image generation model (IGM)}, which could take the form of either an implicit or explicit image prior. 

In order to define an IGM it is necessary to have knowledge of the structure of the underlying image distribution. If ground-truth images are available, then an IGM can be learned directly \cite{venkatakrishnan2013pnp, Boraetal17}. However, this approach requires access to an abundance of clean data and there are many scientific applications (e.g., geophysical imaging and astronomical imaging) where we do not have access to ground-truth images. Collecting ground-truth images in these domains can be extremely invasive, time-consuming, expensive, or even impossible. For instance, how should we define an IGM for black hole imaging without having ever seen a direct image of a black hole or knowing what one should look like?
Moreover, classical approaches that utilize hand-crafted IGMs \cite{TV-ROF} are prone to human bias \cite{akiyama2019first4}.
%to regularize inversion, hyperparameter tuning is imperative to success; in practice, this results in choosing a regularizer based on trial and error and such approaches are heavily prone to
%human bias \cite{Levinetal09}.
%Other works have considered solving inverse problems without an IGM \cite{Lehtinenetal18, liu2020rare}, but operate under the assumption that one has access to multiple independent measurements of a single, static target, limiting their applicability to many real-world problems.

In this work, we show how one can solve a set of ill-posed image reconstruction tasks without access to an explicit image prior. The key insight of our work is that knowledge of common structure across multiple problems is sufficient regularization alone. In particular, we suppose we have access to a collection of measurements $\{y^{(i)}\}_{i=1}^N$ which are observed through a forward model $y^{(i)} := f(x^{(i)}) + \eta^{(i)}$.  An important assumption we make is that the ground-truth images $\{x^{(i)}\}_{i=1}^N$ are drawn from the same distribution (unknown {\it a priori}) and share common, low-dimensional structure. This assumption is satisfied in a number of applications where ground-truth images are not available. For instance, although we might not know what a black hole looks like, we might expect it to be similar in appearance over time. Our main result is that one can exploit this common structure by jointly inferring 1) a single generator $G_{\theta}$ and 2) $N$ low-dimensional latent distributions $q_{\phi^{(i)}}$, such that the distribution induced by the push-forward of $q_{\phi^{(i)}}$ through $G_{\theta}$ approximates the posterior $p(x| y^{(i)})$ for each example $i \in [N]$. 

%the core message of our work is the following:

%Our main result is that one can capitalize on this common structure by learning 1) a single generator $G_{\theta}$ and 2) $N$ low-dimensional latent distributions $q_{\phi^{(i)}}$ such that the distribution induced by the push-forward of $q_{\phi^{(i)}}$ through $G_{\theta}$ approximately captures the posterior $p(x| y^{(i)})$ for each example $i \in [N]$. The parameters of $G_{\theta}$ and the variational distributions $q_{\phi^{(i)}}$ are jointly learned by maximizing a loss inspired by the Evidence Lower Bound (ELBO), which we show is able to effectively learn priors in a variety of inverse problems. %The use of a single generator with a low-dimensional latent space captures the common, low-dimensional structure shared across images while the latent distributions aim to model each complex measurement posterior. 


%\begin{center}
%It is possible to learn an image prior from a small set of measurements to solve inverse problems when the ground-truth images share low-dimensional structure.
%\end{center}