@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


%Entries
@inproceedings{harvey2018recurrent,
author = {Harvey, F\'{e}lix G. and Pal, Christopher},
title = {Recurrent Transition Networks for Character Locomotion},
year = {2018},
isbn = {9781450360623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3283254.3283277},
doi = {10.1145/3283254.3283277},
abstract = {We present a novel approach, based on deep recurrent neural networks, to automatically generate transition animations given a past context of a few frames, a target character state and optionally local terrain information. The proposed Recurrent Transition Network (RTN) is trained without any gait, phase, contact or action labels. Our system produces realistic and fluid transitions that rival the quality of Motion Capture-based animations, even without any inverse-kinematics post-process. Our system could accelerate the creation of transition variations for large coverage or even replace transition nodes in a game's animation graph. The RTN also shows impressive results on a temporal super-resolution task.},
booktitle = {SIGGRAPH Asia 2018 Technical Briefs},
articleno = {4},
numpages = {4},
keywords = {neural networks, LSTM, locomotion, deep learning, animation},
location = {Tokyo, Japan},
series = {SA '18}
}

@article{harvey2020robust,
  title={Robust motion in-betweening},
  author={Harvey, F{\'e}lix G and Yurick, Mike and Nowrouzezahrai, Derek and Pal, Christopher},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={60--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{zhou2021learning,
  title={Learning a deep motion interpolation network for human skeleton animations},
  author={Zhou, Chi and Lai, Zhangjiong and Wang, Suzhen and Li, Lincheng and Sun, Xiaohan and Ding, Yu},
  journal={Computer Animation and Virtual Worlds},
  volume={32},
  number={3-4},
  pages={e2003},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{hernandez2019human,
  title={Human motion prediction via spatio-temporal inpainting},
  author={Hernandez, Alejandro and Gall, Jurgen and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7134--7143},
  year={2019}
}

@inproceedings{fragkiadaki2015recurrent,
title={Recurrent network models for human dynamics},
author={Fragkiadaki, Katerina and Levine, Sergey and Felsen, Panna and Malik, Jitendra},
booktitle={Proceedings of the IEEE international conference on computer vision},
pages={4346--4354},
year={2015}
}

@article{cui2021efficient,
  title={Efficient human motion prediction using temporal convolutional generative adversarial network},
  author={Cui, Qiongjie and Sun, Huaijiang and Kong, Yue and Zhang, Xiaoqian and Li, Yanmeng},
  journal={Information Sciences},
  volume={545},
  pages={427--447},
  year={2021},
  publisher={Elsevier}
}

@article{wang2021pvred,
  title={PVRED: A Position-Velocity Recurrent Encoder-Decoder for Human Motion Prediction},
  author={Wang, Hongsong and Dong, Jian and Cheng, Bin and Feng, Jiashi},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={6096--6106},
  year={2021},
  publisher={IEEE}
}

@article{holden2017phase,
  title={Phase-functioned neural networks for character control},
  author={Holden, Daniel and Komura, Taku and Saito, Jun},
  journal={ACM Transactions on Graphics (TOG)},
  volume={36},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{starke2019neural,
  title={Neural state machine for character-scene interactions.},
  author={Starke, Sebastian and Zhang, He and Komura, Taku and Saito, Jun},
  journal={ACM Trans. Graph.},
  volume={38},
  number={6},
  pages={209--1},
  year={2019}
}

@article{starke2020local,
  title={Local motion phases for learning multi-contact character movements},
  author={Starke, Sebastian and Zhao, Yiwei and Komura, Taku and Zaman, Kazi},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={54--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{starke2021neural,
  title={Neural animation layering for synthesizing martial arts movements},
  author={Starke, Sebastian and Zhao, Yiwei and Zinno, Fabio and Komura, Taku},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--16},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{kania2021trajevae,
  title={TrajeVAE--Controllable Human Motion Generation from Trajectories},
  author={Kania, Kacper and Kowalski, Marek and Trzci{\'n}ski, Tomasz},
  journal={arXiv preprint arXiv:2104.00351},
  year={2021}
}

@inproceedings{zhang2021we,
  title={We are more than our joints: Predicting how 3d bodies move},
  author={Zhang, Yan and Black, Michael J and Tang, Siyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3372--3382},
  year={2021}
}

@inproceedings{petrovich2021action,
  title={Action-conditioned 3d human motion synthesis with transformer vae},
  author={Petrovich, Mathis and Black, Michael J and Varol, G{\"u}l},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10985--10995},
  year={2021}
}

@inproceedings{cai2021unified,
  title={A unified 3d human motion synthesis model via conditional variational auto-encoder},
  author={Cai, Yujun and Wang, Yiwei and Zhu, Yiheng and Cham, Tat-Jen and Cai, Jianfei and Yuan, Junsong and Liu, Jun and Zheng, Chuanxia and Yan, Sijie and Ding, Henghui and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11645--11655},
  year={2021}
}

@inproceedings{mourot2022survey,
  title={A Survey on Deep Learning for Skeleton-Based Human Animation},
  author={Mourot, Lucas and Hoyet, Ludovic and Le Clerc, Fran{\c{c}}ois and Schnitzler, Fran{\c{c}}ois and Hellier, Pierre},
  booktitle={Computer Graphics Forum},
  volume={41},
  number={1},
  pages={122--157},
  year={2022},
  organization={Wiley Online Library}
}

@article{ho2021render,
  title={Render In-between: Motion Guided Video Synthesis for Action Interpolation},
  author={Ho, Hsuan-I and Chen, Xu and Song, Jie and Hilliges, Otmar},
  journal={arXiv preprint arXiv:2111.01029},
  year={2021}
}

@inproceedings{kaufmann2020convolutional,
  title={Convolutional autoencoders for human motion infilling},
  author={Kaufmann, Manuel and Aksan, Emre and Song, Jie and Pece, Fabrizio and Ziegler, Remo and Hilliges, Otmar},
  booktitle={2020 International Conference on 3D Vision (3DV)},
  pages={918--927},
  year={2020},
  organization={IEEE}
}

@inproceedings{yu2019fast,
author = {Yu, Moonwon and Kwon, Byungjun and Kim, Jongmin and Kang, Shinjin and Jang, Hanyoung},
title = {Fast\&nbsp;Terrain-Adaptive\&nbsp;Motion\&nbsp;Generation Using\&nbsp;Deep\&nbsp;Neural\&nbsp;Networks},
year = {2019},
isbn = {9781450369459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3355088.3365157},
doi = {10.1145/3355088.3365157},
abstract = {We propose a fast motion adaptation framework using deep neural networks. Traditionally, motion adaptation is performed via iterative numerical optimization. We adopted deep neural networks and replaced the iterative process with the feed-forward inference consisting of simple matrix multiplications. For efficient mapping from contact constraints to character motion, the proposed system is composed of two types of networks: trajectory and pose generators. The networks are trained using augmented motion capture data and are fine-tuned using the inverse kinematics loss. In experiments, our system successfully generates multi-contact motions of a hundred of characters in real-time, and the result motions contain the naturalness existing in the motion capture data.},
booktitle = {SIGGRAPH Asia 2019 Technical Briefs},
pages = {57â€“60},
numpages = {4},
keywords = {Character Animation, Inverse Kinematics, Deep Neural Networks},
location = {Brisbane, QLD, Australia},
series = {SA '19}
}

@inproceedings{xu2020hierarchical,
  title={Hierarchical style-based networks for motion synthesis},
  author={Xu, Jingwei and Xu, Huazhe and Ni, Bingbing and Yang, Xiaokang and Wang, Xiaolong and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={178--194},
  year={2020},
  organization={Springer}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{bao2017cvae,
  title={CVAE-GAN: fine-grained image generation through asymmetric training},
  author={Bao, Jianmin and Chen, Dong and Wen, Fang and Li, Houqiang and Hua, Gang},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2745--2754},
  year={2017}
}

%new
@inproceedings{jain2016structural,
  title={Structural-rnn: Deep learning on spatio-temporal graphs},
  author={Jain, Ashesh and Zamir, Amir R and Savarese, Silvio and Saxena, Ashutosh},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={5308--5317},
  year={2016}
}

@inproceedings{aksan2019structured,
  title={Structured prediction helps 3d human motion modelling},
  author={Aksan, Emre and Kaufmann, Manuel and Hilliges, Otmar},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7144--7153},
  year={2019}
}

@article{li2019efficient,
  title={Efficient convolutional hierarchical autoencoder for human motion prediction},
  author={Li, Yanran and Wang, Zhao and Yang, Xiaosong and Wang, Meili and Poiana, Sebastian Iulian and Chaudhry, Ehtzaz and Zhang, Jianjun},
  journal={The Visual Computer},
  volume={35},
  number={6},
  pages={1143--1156},
  year={2019},
  publisher={Springer}
}


@article{yang2021lobstr,
  doi = {10.1111/cgf.142631},
  url = {https://doi.org/10.1111%2Fcgf.142631},
  year = 2021,
  month = {may},
  publisher = {Wiley},
  volume = {40},
  number = {2},
  pages = {265--275},
  author = {Dongseok Yang and Doyeon Kim and Sung-Hee Lee},
  title = {{LoBSTr}: Real-time Lower-body Pose Prediction from Sparse Upper-body Tracking Signals},
  journal = {Computer Graphics Forum}
}

@inproceedings{martinez2017human,
  title={On human motion prediction using recurrent neural networks},
  author={Martinez, Julieta and Black, Michael J and Romero, Javier},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2891--2900},
  year={2017}
}

@inproceedings{ghorbani2020probabilistic,
author = {Ghorbani, S. and Wloka, C. and Etemad, A. and Brubaker, M. A. and Troje, N. F.},
title = {Probabilistic Character Motion Synthesis Using a Hierarchical Deep Latent Variable Model},
year = {2020},
publisher = {Eurographics Association},
address = {Goslar, DEU},
url = {https://doi.org/10.1111/cgf.14116},
doi = {10.1111/cgf.14116},
abstract = {We present a probabilistic framework to generate character animations based on weak control signals, such that the synthesized motions are realistic while retaining the stochastic nature of human movement. The proposed architecture, which is designed as a hierarchical recurrent model, maps each sub-sequence of motions into a stochastic latent code using a variational autoencoder extended over the temporal domain. We also propose an objective function which respects the impact of each joint on the pose and compares the joint angles based on angular distance. We use two novel quantitative protocols and human qualitative assessment to demonstrate the ability of our model to generate convincing and diverse periodic and non-periodic motion sequences without the need for strong control signals.},
booktitle = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
articleno = {21},
numpages = {15},
location = {Virtual Event, Canada},
series = {SCA '20}
}

@article{wang2019combining,
  title={Combining recurrent neural networks and adversarial training for human motion synthesis and control},
  author={Wang, Zhiyong and Chai, Jinxiang and Xia, Shihong},
  journal={IEEE transactions on visualization and computer graphics},
  volume={27},
  number={1},
  pages={14--28},
  year={2019},
  publisher={IEEE}
}

@article{li2017auto,
  title={Auto-conditioned recurrent networks for extended complex human motion synthesis},
  author={Li, Zimo and Zhou, Yi and Xiao, Shuangjiu and He, Chong and Huang, Zeng and Li, Hao},
  journal={arXiv preprint arXiv:1707.05363},
  year={2017}
}

@inproceedings{kundu2019bihmp,
author = {Kundu, Jogendra Nath and Gor, Maharshi and Babu, R. Venkatesh},
title = {BiHMP-GAN: Bidirectional 3D Human Motion Prediction GAN},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33018553},
doi = {10.1609/aaai.v33i01.33018553},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1049},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{habibie2017recurrent,
  title={A recurrent variational autoencoder for human motion synthesis},
  author={Habibie, Ikhsanul and Holden, Daniel and Schwarz, Jonathan and Yearsley, Joe and Komura, Taku},
  booktitle={28th British Machine Vision Conference},
  year={2017}
}

@inproceedings{cao2020long,
  title={Long-term human motion prediction with scene context},
  author={Cao, Zhe and Gao, Hang and Mangalam, Karttikeya and Cai, Qi-Zhi and Vo, Minh and Malik, Jitendra},
  booktitle={European Conference on Computer Vision},
  pages={387--404},
  year={2020},
  organization={Springer}
}

@inproceedings{xu2019human,
  title={Human motion prediction via pattern completion in latent representation space},
  author={Xu, Yi Tian and Li, Yaqiao and Meger, David},
  booktitle={2019 16th conference on computer and robot vision (CRV)},
  pages={57--64},
  year={2019},
  organization={IEEE}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{toyer2017human,
  title={Human pose forecasting via deep markov models},
  author={Toyer, Sam and Cherian, Anoop and Han, Tengda and Gould, Stephen},
  booktitle={2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
  pages={1--8},
  year={2017},
  organization={IEEE}
}

@incollection{du2019stylistic,
  title={Stylistic locomotion modeling and synthesis using variational generative models},
  author={Du, Han and Herrmann, Erik and Sprenger, Janis and Fischer, Klaus and Slusallek, Philipp},
  booktitle={Motion, Interaction and Games},
  pages={1--10},
  year={2019}
}

@inproceedings{yan2018mt,
  title={Mt-vae: Learning motion transformations to generate multimodal human dynamics},
  author={Yan, Xinchen and Rastogi, Akash and Villegas, Ruben and Sunkavalli, Kalyan and Shechtman, Eli and Hadap, Sunil and Yumer, Ersin and Lee, Honglak},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={265--281},
  year={2018}
}

@inproceedings{aliakbarian2020stochastic,
  title={A stochastic conditioning scheme for diverse human motion prediction},
  author={Aliakbarian, Sadegh and Saleh, Fatemeh Sadat and Salzmann, Mathieu and Petersson, Lars and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5223--5232},
  year={2020}
}

@inproceedings{barsoum2018hp,
  title={Hp-gan: Probabilistic 3d human motion prediction via gan},
  author={Barsoum, Emad and Kender, John and Liu, Zicheng},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={1418--1427},
  year={2018}
}

@article{wang2020adversarial,
  title={Adversarial learning for modeling human motion},
  author={Wang, Qi and Arti{\`e}res, Thierry and Chen, Mickael and Denoyer, Ludovic},
  journal={The Visual Computer},
  volume={36},
  number={1},
  pages={141--160},
  year={2020},
  publisher={Springer}
}

@inproceedings{yan2019convolutional,
  title={Convolutional sequence generation for skeleton-based action synthesis},
  author={Yan, Sijie and Li, Zhizhong and Xiong, Yuanjun and Yan, Huahan and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4394--4402},
  year={2019}
}

@inproceedings{wang2020learning,
  title={Learning diverse stochastic human-action generators by learning smooth latent transitions},
  author={Wang, Zhenyi and Yu, Ping and Zhao, Yang and Zhang, Ruiyi and Zhou, Yufan and Yuan, Junsong and Chen, Changyou},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={07},
  pages={12281--12288},
  year={2020}
}

@inproceedings{walker2017pose,
  title={The pose knows: Video forecasting by generating pose futures},
  author={Walker, Jacob and Marino, Kenneth and Gupta, Abhinav and Hebert, Martial},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3332--3341},
  year={2017}
}

@article{lin2018human,
  title={Human motion modeling using dvgans},
  author={Lin, Xiao and Amer, Mohamed R},
  journal={arXiv preprint arXiv:1804.10652},
  year={2018}
}

@article{duan2022unified,
  author = {Seyed Sina Mirrazavi Salehian and Nadia Figueroa and Aude Billard},
  title ={A unified framework for coordinated multi-arm motion planning},
  journal = {The International Journal of Robotics Research},
  volume = {37},
  number = {10},
  pages = {1205-1232},
  year = {2018},
  doi = {10.1177/0278364918765952},
  URL = {https://doi.org/10.1177/0278364918765952},
  eprint = { https://doi.org/10.1177/0278364918765952},
}

@inproceedings{cai2018deep,
  title={Deep video generation, prediction and completion of human action sequences},
  author={Cai, Haoye and Bai, Chunyan and Tai, Yu-Wing and Tang, Chi-Keung},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={366--382},
  year={2018}
}

@InProceedings{Mao_2017_ICCV,
author = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y.K. and Wang, Zhen and Paul Smolley, Stephen},
title = {Least Squares Generative Adversarial Networks},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@article{ionescu2013human3,
  title={Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments},
  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={36},
  number={7},
  pages={1325--1339},
  year={2013},
  publisher={IEEE}
}

@book{dam1998quaternions,
  title={Quaternions, interpolation and animation},
  author={Dam, Erik B and Koch, Martin and Lillholm, Martin},
  volume={2},
  year={1998},
  publisher={Citeseer}
}

@article{StarkeMANN,
  author = {Zhang, He and Starke, Sebastian and Komura, Taku and Saito, Jun},
  title = {Mode-Adaptive Neural Networks for Quadruped Motion Control},
  year = {2018},
  issue_date = {August 2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {37},
  number = {4},
  issn = {0730-0301},
  url = {https://doi.org/10.1145/3197517.3201366},
  doi = {10.1145/3197517.3201366},
  journal = {ACM Trans. Graph.},
  month = {jul},
  articleno = {145},
  numpages = {11},
  keywords = {neural networks, human motion, character control, locomotion, deep learning, character animation}
}

@article{Pavllo2018QuaterNetAQ,
  title={QuaterNet: A Quaternion-based Recurrent Model for Human Motion},
  author={Dario Pavllo and David Grangier and Michael Auli},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.06485}
}

@article{Gopalakrishnan2019ANT,
  title={A Neural Temporal Model for Human Motion Prediction},
  author={Anand Gopalakrishnan and Ankur Arjun Mali and Daniel Kifer and C. Lee Giles and Alexander Ororbia},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={12108-12117}
}

@article{deltainterpolate,
  author    = {Boris N. Oreshkin and
               Antonios Valkanas and
               F{\'{e}}lix G. Harvey and
               Louis{-}Simon M{\'{e}}nard and
               Florent Bocquelet and
               Mark J. Coates},
  title     = {Motion Inbetweening via Deep {\(\Delta\)}-Interpolator},
  journal   = {CoRR},
  volume    = {abs/2201.06701},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.06701},
  eprinttype = {arXiv},
  eprint    = {2201.06701},
  timestamp = {Fri, 21 Jan 2022 13:57:15 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-06701.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tang2022real,
  doi = {10.1145/3528223.3530090},
  url = {https://doi.org/10.1145%2F3528223.3530090},
  year = 2022,
  month = {jul},
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {41},
  number = {4},
  pages = {1--10},
  author = {Xiangjun Tang and He Wang and Bo Hu and Xu Gong and Ruifan Yi and Qilong Kou and Xiaogang Jin},
  title = {Real-time controllable motion transition for characters},
  journal = {{ACM} Transactions on Graphics}
}

@article{Kim2022condition,
  doi = {10.1016/j.patcog.2022.108894},
  url = {https://doi.org/10.1016%2Fj.patcog.2022.108894},
  year = 2022,
  month = {dec},
  publisher = {Elsevier {BV}},
  volume = {132},
  pages = {108894},
  author = {Jihoon Kim and Taehyun Byun and Seungyoun Shin and Jungdam Won and Sungjoon Choi},
  title = {Conditional motion in-betweening},
  journal = {Pattern Recognition}
}

@article{qin2022motion,
  title={Motion In-betweening via Two-stage Transformers},
  author={QIN, JIA and ZHENG, YOUYI and ZHOU, KUN},
  year={2022}
}