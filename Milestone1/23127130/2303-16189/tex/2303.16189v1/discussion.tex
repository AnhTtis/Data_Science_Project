\vspace{-7pt}
\section{Properties of Multistep Energy-Minimization Planner}
\vspace{-3pt}

Next, we analyze the unique properties enabled by \netName described in \S \ref{sec:prop} in customized BabyAI environments.
For each environment,
we design at most three settings with increasing difficulty levels to gradually challenge the planning model. 
As before, the target reaching success rate is measured as the evaluation criteria.
The performances are compared against
Implicit Q-Learning (IQL) \citep{kostrikov2021offline} and Decision Transformer (DT) \citep{chen2021dt}.



% Go to goal location while avoiding lava & Go to goal location while avoiding larger lava & Go to goal location in maze while avoiding lavas

\vspace{-5pt}
\subsection{Online adaptation} 
\vspace{3pt}

\myparagraph{Setup} To examine \netName's adaptation ability to test-time constraints, 
we construct an BabyAI environment with multiple lethal lava zones at the test time as depicted in Figure~\ref{fig:property} (a).
The planner $\enModel_\theta$ generates the trajectory without the awareness of the lava zones.
Once planned, the energy prediction is corrected by the constraint energy function $\enModel_{\text{constraint}}(\btau{})$, which assigns large energy to the immediate action leading to lava, and zero otherwise.
The agent traverses under the guidance of the updated energy estimation. \hongyi{To make the benchmark comparison fair, we also remove the immediate action that will lead to a lava for all baselines.}
The difficulty levels are characterized by the amount of lava grids added and the way they are added, where \textit{easy}, \textit{medium} correspond to adding at most 2 and 5 lava grids respectively on the way to the goal object in 8$\times$8 grids world. The third case is hard due to the unstructured maze world in which the narrow paths can be easily blocked by lava grids and requires the agents to plan a trajectory to bypass. 


% The iterative planning can be guided by a perturbation functions $h(\tau )$, which can be learned from another external data source or designed by human experts. 
% We can easily combine the planning procedure with online perturbation function $h(\tau )$ satisfy the online constraints, like avoiding the unsafe set, that are not observed during the training. We construct a 8$\times$8 trajectory planning tasks with unobservable dangerous lava grids in BabyAI({\color{red} here we need to use the ground-truth environment dynamics and perturbation function that is able to observe the dangerous areas.}), and test models' performance with and without adaptation. From the Table~\ref{tbl:property_adaptation}, the perturbation can be perfectly merged into the iterative multi-step planning in \netName and successfully leads to higher success rate and guarantee safety. {\color{red} IQL also perform good due to it's robustness in multi-step dynamic programming problems.} While DT benefits less because the single-step perturbation can help to avoid the dangerous zone but can't lead it to the goal. 

\myparagraph{Results}
The quantitative comparison is collected in the Table~\ref{tbl:property_results}, \textit{Left}. 
Although drops with harder challenges, the performance of our model still exceeds both baselines under all settings.
Visual illustration of \textit{medium} example results can be seen in Figure~\ref{fig:property} (a) that the agent goes up first to bypass the lava grids and then drives to the goal object.




\vspace{-3pt}
\subsection{Novel Environment Generalization} 
\vspace{3pt}

\myparagraph{Setup} 
To evaluate \netName's generalization ability in unseen testing environments, we train the model in easier environments but test them in more challenging environments. In \textit{easy} case, the model is trained in 8$\times$8 world without any obstacles but tested in the world with 14 obstacles as distractors. In \textit{medium} and \textit{hard} cases, the model is trained in single-room world but tested in maze world containing multi-rooms connected by narrow paths (Figure~\ref{fig:property} (b)). The maze size and the number of rooms in \textit{hard} case are 10$\times$10 and 9, which are larger than 7$\times$7 and 4 in \textit{medium} case.

\myparagraph{Results}
Our model achieves best averaged performance across three cases, but slightly worse than IQL in \textit{hard} case, see Table~\ref{tbl:property_results}, \textit{Middle}. In contrast, sequential RL model DT has significantly lower performance when moved to in unseen maze environments. \netName trained in plane world could still plan a decent trajectory in unseen maze environment after blocked by walls, see Figure~\ref{fig:property} (b).


\begin{table*}[t!]
\centering
    \small
    \scalebox{0.8}{
    \begin{tabular}{r|rrr|rrr|rrr}
        \toprule
         \multirow{2}{*}{\bf Test} & \multicolumn{3}{c|}{\bf Online Adaptation} & \multicolumn{3}{c|}{\bf Generalization} & \multicolumn{3}{c}{\bf Task Composition} \\
        {} & {\bf \netName} & {\bf DT} & {\bf IQL} & {\bf \netName} & {\bf DT} & {\bf IQL} & {\bf \netName} & {\bf DT} & {\bf IQL}\\
        \midrule
        Easy&$\bf{92.0\%}$& $68.0\%$  & $90.5\%$&$\bf{77.5\%}$ & $36.0\%$ & $60.5\%$&$\bf{83.5\%}$ & $58.0\%$ & $42.5\%$ \\ 
        Medium&$\bf{64.5\%}$& $20.0\%$  & $52.0\%$&$\bf{64.0\%}$ & $37.5\%$ & $57.5\%$&$\bf{43.0\%}$ & $15.5\%$ & $11.5\%$  \\ 
        Hard&$\bf{54.5\%}$&  $48.0\%$ & $44\%$&$61.0\%$ & $24.5\%$ & $\bf{65.5\%}$&N/A&N/A& N/A \\ 
        \bottomrule
    \end{tabular}
    }
    % \caption{\textbf{Online adaptation.}}
    \vspace{-4pt}
    \caption{\small 
    \textbf{Property Test on Modified BabyAI Environments.}
    Three properties performance of \netName and prior algorithms on BabyAI tasks with different difficulty.
    \textit{Left}: Online Adaptation;
    \textit{Middle}: Generalization;
    \textit{Right}: Task Composition.
    }
    \label{tbl:property_results}
    \vspace{-10pt}
\end{table*}

\input{figs/figPropResults}

\begin{comment}
{GoToLocalS8N1} & {GoToLocalS8N15} 
{GoToLocalS7N5} & {GoToObjMazeS4R2Obs} 
{GoToLocalS10N3} & {GoToObjMazeS4}
\end{comment}

\begin{comment}

\begin{table*}[h]
\centering
\small
\begin{tabular}{lrrrr}
\toprule
\multicolumn{1}{c}{\bf Property} & \multicolumn{1}{c}{\bf Task} & \multicolumn{1}{c}{\bf \netName} & \multicolumn{1}{c}{\bf DT} & \multicolumn{1}{c}{\bf IQL} \\ 
\midrule
Generalization & \makecell[c]{Train in plane env w/o obstacle \\while test in plan env w multi-obstacles}  &$\bf{77.5\%}$ & $36.0\%$ & $60.5\%$\\ 
Generalization & \makecell[c]{Train in plane env w obstacle \\while test in maze env w multi-obstacles}  &$\bf{64.0\%}$ & $37.5\%$ & $57.5\%$ \\ 
Generalization & \makecell[c]{Train in plane env w obstacle \\while test in maze env w/o obstacles}  &$61.0\%$ & $24.5\%$ & $\bf{65.5\%}$ \\ 
\bottomrule
\end{tabular}
\caption{The three properties performance of \netName and prior algorithms on BabyAI tasks.}
\label{tbl:property_main}
\end{table*}
\end{comment}

\vspace{-3pt}
\subsection{Task compositionality}
\vspace{3pt}
\myparagraph{Setup}
We design composite trajectory planning and instruction completion tasks for \textit{easy} and \textit{medium} cases respectively. In \textit{easy} case, all obstacles are equally separated into two subsets, each observable by one of the two planners, see Figure~\ref{fig:property} (c). As a result, the planning needs to add up model's predictions using two partial observations to successfully avoid the obstacles. In \textit{medium} case, two separate models trained for different tasks; one for planning trajectory in 10$\times$10 maze world and the other for object pickup in single-room world. The composite task is to complete the object pickup in 10$\times$10 maze world. 

\myparagraph{Results}
Our model significantly outperforms the baselines in both two testing cases, while IQL and DT suffer great success rate drop indicating they can not be applied to composite tasks directly, see Table~\ref{tbl:property_results}, \textit{Right}. This proves that \netName can be easily combined with other models responsible for different tasks, making it more applicable and general for wide-range tasks. In Figure~\ref{fig:property} (c), the composite \netName could reach the goal by avoiding all obstacles even though the first \netName planner is blocked by unperceivable obstacle.

\begin{comment}
\begin{table}[t]
\caption{The compositionality performance of \netName and a variety of prior algorithms on babyai GoToLocalS8N15 env.}
\label{compositionality-table}
\begin{center}
\begin{tabular}{@{}cccc@{}}
\toprule
& w/o compositionality & w compositionality \\ 
 \midrule
{DT} & \%& 58\%\\
{IQL} & \%& \%\\
{\netName} & \%& 83.5 \%\\
\bottomrule
\end{tabular}
\end{center}
\end{table}
\end{comment}



\begin{comment}
\begin{table}[t]
\caption{The generalization performance of \netName and a variety of prior algorithms on babyai env. The number after $\downarrow$ means the performance drops when trained with trajectories in the same testing envs.}
\label{generalization-table}
\begin{center}
\begin{tabular}{@{}ccccccc@{}}
\toprule
Training Env & Testing Env & DT & IQL & \netName\\ 
 \midrule
{GoToLocalS8N1} & {GoToLocalS8N15} &36\% ($\downarrow$11.5\%) & 60.5\%(59.5\%)&77.5\% ($\downarrow$11\%)\\
{GoToLocalS7N5} & {GoToObjMazeS4R2Obs} &37.5\% ($\downarrow$10.5\%) & 57.5\%(48\%)&64\% ($\downarrow$3.5\%)\\
{GoToLocalS10N3} & {GoToObjMazeS4} &24.5\% ($\downarrow$22.5\%) & 65.5\% (37\%)&61\% ($\downarrow$4\%)\\
\bottomrule
\end{tabular}
\end{center}
\end{table}


\begin{table*}[h]
    \centering
    \small
    \begin{minipage}[]{0.48\linewidth}
        \begin{tabular}{lrrrr}
            \toprule
            \multicolumn{1}{c}{\bf Property} & \multicolumn{1}{c}{\bf Task} & \multicolumn{1}{c}{\bf \netName} & \multicolumn{1}{c}{\bf DT} & \multicolumn{1}{c}{\bf IQL} \\ 
            \midrule
            Task composition   & Go to goal location with multiple models &$\bf{83.5\%}$ & $58.0\%$ & $42.5\%$ \\
            Task composition   & Go to pickup the goal object in maze &$\bf{43.0\%}$ & $15.5\%$ & $11.5\%$ \\
            \bottomrule
        \end{tabular}
        \caption{The three properties performance of \netName and prior algorithms on BabyAI tasks.}
    \label{tbl:property_main}
    \end{minipage}
\end{table*}
\end{comment}

% \subsection{MCMC Sampling and Planning Horizon}
% In this section, we aim to study (1) the effects of MCMC sampling on the performance and (2) the relationship between planning horizon and the MCMC sampling iterations. For (1), we notice that the success rate is pretty low if we sample only once and the overall performance improves as we increase the sampling iteration number to 5, 10 and lager values. But in different tasks, the optimal sampling time may vary a lot depending on the size of environment and the planning horizon. For (2), in small size environment like LocalS7N5 (7$\times$7) and GoToSeqS5R2 (8$\times$8), the shorter planning horizon (H=5) and fewer sample iterations (10 and 20 respectively) give the best performance 100\% and 55\%. While the large size environment MazeS7 (19$\times$19) requires longer planning horizon (H=10) and correspond more sample iterations (50) to achieve good performance 72.5\%.

% \begin{table*}[h]
% \centering
% \small
% \begin{tabular}{lcccccc}
% \toprule
%  & \multicolumn{2}{c}{\bf H=5} & \multicolumn{2}{c}{\bf H=10} & \multicolumn{2}{c}{\bf H=15}\\ %  & \multicolumn{1}{c}{\bf BC} \\
% \multicolumn{1}{c}{\bf Game} & {\bf iteration} & {\bf success rate} & {\bf iteration} & {\bf success rate} & {\bf iteration} & {\bf success rate}\\
% \midrule
% LocalS7N5    & $10$ & & $50$ & & $50$ &  \\ 
% GoToObjMazeS4 & $30$& 60.5\%& $50$ & 63.5\%& $30$ & 55.0\%\\ 
% GoToObjMazeS7   &  $50$& 29.0\%& $50$& & $50$ & 42.0\% \\
% %GoToSeqS5R2 & $20$ & $10$ & $30$   \\ 
% \bottomrule
% \end{tabular}
% \caption{
% The number of sampling iterations (1,5,10,20,30,50) with different planning horizon (H=5,10,15) that gives best average performance in BabyAI environments.}
% \label{tbl:MCMC}
% \end{table*}

% \begin{comment}
% \begin{figure*}[htbp]
%     \centering
%     \subfigure[H=5]{\label{fig:a}\includegraphics[width=45mm]{figs/mcmc_plot5.png}}
%     \subfigure[H=10]{\label{fig:b}\includegraphics[width=45mm]{figs/mcmc_plot10.png}}
%     \subfigure[H=15]{\label{fig:b}\includegraphics[width=45mm]{figs/mcmc_plot15.png}}
%      \caption{\netName success rate with different planning horizon H and MCMC sampling iterations.}
%      \label{fig:mcmc sampling}
% \end{figure*}
% \end{comment}



