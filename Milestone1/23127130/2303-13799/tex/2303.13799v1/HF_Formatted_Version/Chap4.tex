\section{The Structure of Human-Machine Trust} \label{sec:meta-anal}
% These trust factors can be pretty neatly grouped into the three layers proposed by \cite{Hoff2015}, as in Fig. \ref{fig:layers}. 

% \begin{figure}
%     \centering
%     \includegraphics[width=\columnwidth]{Layers_of_Trust_Pretty.001.png}
%     \caption{The Layers of Trust}
%     \label{fig:layers}
% \end{figure}

The inter-relations between these ten antecedents and trust factors was further refined and validated by closely examining the 15 studies that performed regressions and structural equation modeling.  While not every study tested every factor, the meta-analysis presented in Table 3 reveals some general trends that suggest a common set of relationships, if not an underlying joint structure. 

\begin{table*}[]
% \scriptsize
    \centering
        \caption{Meta-Analysis of Regression Coefficients.  Adjusted partial correlations (adj.) for publication bias (trim and fill) when appropriate.  Standard Error (SE), hypothesis testing, and significance level (Z-Value), $95\%$ upper and lower confidence intervals (CI).  Also reported are metrics for estimating heterogeneity: Cochrane's Q, $I^2$, $T^2$, and $\tau$ [32]. $*=p<.1, **=p<0.05, ***=p<.01$.  Relations with only one sample have no heterogeneity to report, and their significance (in parenthesis) reflects what was reported by the original authors.  Publication bias is only reported where there are 3+ sources, and heterogeneity did not overly threaten adjustment (Terrin et al., 2003)}
        \resizebox{6in}{!}{
    \begin{tabular}{ll|cccccccccccc}
      \begin{tabular}{@{}c@{}}\textbf{Starting}\\\textbf{Level}\end{tabular}&\textbf{Relation}& \textbf{Sources}&\textbf{partial corr.}&   \begin{tabular}{@{}c@{}}\textbf{partial}\\\textbf{ corr. adj.}\end{tabular}&\textbf{SE}&\textbf{Z-value} &\begin{tabular}{@{}c@{}}\textbf{95\% CI}\\\textbf{ Lower}\end{tabular}&\begin{tabular}{@{}c@{}}\textbf{95\% CI}\\\textbf{ Upper}\end{tabular}&\textbf{Q}&\textbf{p$_Q$}&\textbf{I$^2$}&\textbf{T$^2$}&\textbf{$\tau$}\\
     
     \thickhline
     
     Disp.&\begin{tabular}{@{}l@{}}\textbf{Faith in Technology\protect\MVRightarrow}\\ \textbf{Situational Normality}\end{tabular}  & 2&0.2 & - & 0.04&2.61*** &-0.78 &1.19&4.33&0.037&77\%&.01&0.1  \\\hline
      Disp.&\begin{tabular}{@{}l@{}}\textbf{Faith in Technology \protect\MVRightarrow}\\ \textbf{Shared Mental Model}\end{tabular}  &1& 0.37 & - & 0.05&(***) &0.28&0.46&-&-&-&-&- \\\hline
     Disp.&\begin{tabular}{@{}l@{}}\textbf{Faith in Technology\protect\MVRightarrow}\\ \textbf{Structural Trust}\end{tabular}  &2& 0.23 & - & 0.04&3.82*** &-0.53 &0.99&2.65&0.104&62\%&0.0&0.07  \\\hline
     Disp.&\begin{tabular}{@{}l@{}}\textbf{Faith in Technology\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}  &3& 0.25 & 0.30& 0.03&2.77*** &0.19 &0.41&26.14&0.000&92\%&0.03&0.17  \\\hline
      Disp.&\begin{tabular}{@{}l@{}}\textbf{Faith in Technology\protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}  &1& 0.16 & -& 0.05&(***)&0.06 &0.26&-&-&-&-&-  \\ \thickhline
      Sit.&\begin{tabular}{@{}l@{}}\textbf{Emotional Response\protect\MVRightarrow}\\ \textbf{Situational Normality}\end{tabular}  &1& 0.54 & -& 0.13&(**)&0.27 &0.81&-&-&-&-&-  \\\hline
         Sit.&\begin{tabular}{@{}l@{}}\textbf{Emotional Response\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}  &1& 0.36 & -& 0.03&(***)&0.29 &0.43&-&-&-&-&-  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Emotional Response\protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}&1  &0.33& - & 0.06& (*)&0.22 &0.44&-&-&-&-&-  \\\thickhline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Situation Normality\protect\MVRightarrow}\\ \textbf{Faith in Technology}\end{tabular}&1  &0.41& - & 0.16& (*)&0.09 &0.73&-&-&-&-&-  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Situation Normality\protect\MVRightarrow}\\ \textbf{Shared Mental Model}\end{tabular}&1  &0.47& - & 0.05& (**)&0.36 &0.58&-&-&-&-&-  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Situation Normality\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&3  &0.33& - & 0.03& ND &0.33 &0.33&0&1&ND&0&0  \\\thickhline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Familiarity\MVRightarrow}\\ \textbf{Shared Mental Model}\end{tabular}&2  &0.25& - & 0.05& 54.02*** &0.19 &0.31&0.01&0.933&0\%&0&0  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Familiarity\protect\MVRightarrow}\\ \textbf{Structural Trust}\end{tabular}&1  &0.21& - & 0.50& (*) &0.02 &0.40&-&-&-&-&-  \\\hline Sit.&\begin{tabular}{@{}l@{}}\textbf{Familiarity\protect\MVRightarrow}\\ \textbf{Capability-based Trust}\end{tabular}&2  &0.23& - & 0.07& 11.49*** &-0.02 &0.48&0.08&0.772&0\%&0&0  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Familiarity \protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&1 &0.42& - & 0.05& (***) &0.33 &0.52&-&-&-&-&-  \\\hline
          Sit.&\begin{tabular}{@{}l@{}}\textbf{Familiarity \protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}&1  &0.10& - & 0.06& (**) &-0.01 &0.22&-&-&-&-&-  \\\thickhline
          Learn.&\begin{tabular}{@{}l@{}}\textbf{Shared Mental Model\protect\MVRightarrow}\\ \textbf{Capability-based Trust}\end{tabular}&4  &0.41& 0.42 & 0.03& 7.99*** &0.34 &0.50&10.64&0.014&71\%&0.01&0.08  \\\hline
          Learn.&\begin{tabular}{@{}l@{}}\textbf{Shared Mental Model\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&7  &0.47& 0.52 & 0.02& 6.65*** &0.47 &0.57&86.11&0.00&93\%&0.04&0.19  \\\thickhline
          Learn.&\begin{tabular}{@{}l@{}}\textbf{Structural Trust\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&5  &0.40& - & 0.02& 19.45*** &0.34 &0.46&3.26&0.515&0\%&0&0  \\\hline
          Learn.&\begin{tabular}{@{}l@{}}\textbf{Structural Trust\protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}&1  &0.12& - & 0.10& (*) &-0.02 &0.38&-&-&-&-&-  \\\thickhline
          Learn.&\begin{tabular}{@{}l@{}}\textbf{Capability-based Trust\protect\MVRightarrow}\\ \textbf{Shared Mental Model}\end{tabular}&1  &0.47& - & 0.15& (**) &0.16 &0.78&-&-&-&-&-  \\\hline
             Learn.&\begin{tabular}{@{}l@{}}\textbf{Capability-based Trust\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&7  &0.47& - & 0.01& 5.56** &0.26 &0.67&224.74&0&97\%&0.05&0.21  \\\hline
             Learn.&\begin{tabular}{@{}l@{}}\textbf{Capability-based Trust\protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}&3  &0.28& 0.33 & 0.05& 3.32*** &0.12 &0.53&4.83&0.09&58\%&0.01&0.12\\\thickhline
            Learn.& \begin{tabular}{@{}l@{}}\textbf{Affective Trust\protect\MVRightarrow}\\ \textbf{Structural Trust}\end{tabular}&1  &0.43& - & 0.08& (**) &0.27&0.59&-&-&-&-&-\\\hline
              Learn.&\begin{tabular}{@{}l@{}}\textbf{Affective Trust\protect\MVRightarrow}\\ \textbf{Capability-based Trust}\end{tabular}&2  &0.66& - & 0.04& 2.92*** &0.27&0.59&24.09&0&96\%&0.10&0.31\\\hline
              Learn.&\begin{tabular}{@{}l@{}}\textbf{Affective Trust\protect\MVRightarrow}\\ \textbf{General Trust}\end{tabular}&8  &0.37& - & 0.01& 4.40*** &0.17&0.57&341.54&0&98\%&0.080&0.28\\\thickhline
             
             Learn.&\begin{tabular}{@{}l@{}}\textbf{General Trust\protect\MVRightarrow}\\ \textbf{Faith in Technology}\end{tabular}&1  &0.36& - & 0.17& (*) &0.02&0.70&-&-&-&-&-\\\hline
             
             Learn.&\begin{tabular}{@{}l@{}}\textbf{General Trust\protect\MVRightarrow}\\ \textbf{Capability-Based Trust}\end{tabular}&1  &0.26& - & 0.06& (**) &0.02&0.70&-&-&-&-&-\\\hline
             
             Learn.&\begin{tabular}{@{}l@{}}\textbf{General Trust\protect\MVRightarrow}\\ \textbf{Intent to Use}\end{tabular}&7  &0.55& 0.63 & 0.01& 8.53*** &0.60&0.66&110.83&0&95\%&0.03&0.16\\\thickhline
    \end{tabular}
    }
    \label{tab:meta_anal}
\end{table*}


% \begin{figure*}
%     \centering
%     \includegraphics[scale=0.52]{figures/Fig4_2_MetaAnlTbl.png}
%     % \Description{A table showing the meta-analysis between 29 pairs of factors in the internal trust model.}
%     \label{tab:meta_anal}
% \end{figure*}


As can be seen in Table \ref{tab:meta_anal} at the \textbf{\emph{Dispositional trust}} level,  \textbf{Faith in Technology} has the strongest effect on the \textbf{Shared Mental Model}, followed by \textbf{Structural} and \textbf{Capability-based Trust}, \textbf{General Trust}, \textbf{Situational Normality}, and finally, and most weakly, on \textbf{Intention to Use}.  Its effect weakens over the interaction \cite{Merritt2008} and over repeated interactions \cite{Sollner2013} as one gets used to a specific technology and better calibrates their trust.  Thinking about trust as a Bayesian expectation (such as in \citeA{josang2016subjective}), \textbf{Faith in Technology} essentially serves as an initial \emph{prior} belief whose contribution diminishes over time.  Therefore, \textbf{Faith in Technology} is most crucial at the initial stages of trust formation, when potential users decide whether to accept and try out new technology.  \textbf{Faith in Technology} gets updated through feedback as both \textbf{General Trust}, and the \textbf{Shared Mental Model} more generally, are calibrated \cite{Heerink2009,Hoff2015}.  

The factors within the \textbf{\emph{Situational trust}} level, like those in the \textbf{\emph{Dispositional}} level, show larger effects early on that diminish overuse \cite{Merritt2008}.  Likeability can even account entirely for early usage of a system until trust is calibrated \cite{Merritt2011}.  \textbf{Emotional Response} is significantly correlated (partial corr: 0.54**, SE: 0.13) with \textbf{Situation Normality} \cite{Heerink2009}.  This relationship, perhaps, is best exemplified by anthropomorphism, which increases naturalness, likeability, and comfort that all directly impact \textbf{Situation Normality} \cite{Chi2021}.  Likewise, there is some evidence that \textbf{Situation Normality} increases comfort and attachment \cite{Chi2021}.  \textbf{Situation Normality} and  \textbf{Emotional Response} both appear to be significant and fairly strong antecedents (partial corr: 0.33-0.47) to more `downstream' factors such as the \textbf{Shared Mental Model}, \textbf{General Trust}, and \textbf{Intent to Use}.  \textbf{Familiarity}, on the other hand, seems somewhat weaker (partial corr: 0.1-0.42), perhaps some of its explanatory power being divided with \textbf{Situation Normality}.  It appears plausible from the SEM models that \textbf{Familiarity} primarily affects the \textbf{Shared Mental Model}, and through that, the sub-factors of trust (\textbf{Affective, Structural, Capability-based}), and eventually \textbf{Intent to Use}.  Few experiments \cite{Heerink2009,Chi2021} have separately tested the sub-factors of \emph{reputation} and \emph{recommendation}, for which there are mixed results from the human-human side \cite{yamagishi2001}. Because the above strength of \textbf{\emph{Situational Trust}} factors weaken over experience, their effect on \textbf{Intent to Use} and actual use may be underestimated or exhibit higher variance, depending on the point in time at which they are measured.

The \textbf{Shared Mental Model} sits at the foundation of \textbf{\emph{Learned trust}} and is crucial in supporting \textbf{Capability-based} (partial corr adj:0.42, SE 0.03) and \textbf{General Trust} (partial corr adj:0.52, SE 0.02).  Like other \textbf{\emph{Learned trust}} factors, the \textbf{Shared Mental Model} gets calibrated over time and is correlated with transparency and the ability to monitor (and thus is also affected by workload \cite{Razin2021a}).  At the crux of the \textbf{Shared Mental Model} is recognizing the goals of the robot \cite{Hoffman2013,tomlinson2020revisiting} and the developers' intentions \cite{Korber2018}, such that one can determine if the robot or machine shares the human's goals or at least is cooperative vs. competitive \cite{castelfranchi2010trust}.  Likewise, the \textbf{Shared Mental Model} is equally necessary for determining whether another will follow laws or norms and hence warrant \textbf{Structural Trust} \cite{Razin2020}.

%%While only \textbf{Capability-based Trust} has so far been shown to mediate between the \textbf{Shared Mental Model} and \textbf{General Trust}, there is some evidence from other trust and \textbf{Shared Mental Model} research that it is also mediated through Affective and Structural Trust \cite{Razin. 

\textbf{Affective trust} is the foundation of the main trust factors, indicating expected cooperativeness and goal adoption.  Expected cooperativeness vs. competitiveness is critical to understanding whether the potential actors and situation call for trust \cite{Razin2021b}, while goal adoption is the very purpose of task-focused interpersonal trust \cite{castelfranchi2010trust}.  \textbf{Affective Trust} correlates with both \textbf{Structural} (partial corr: 0.43, SE: 0.08) and \textbf{Capability-based Trust} (partial corr: 0.66, SE: 0.04), as well as \textbf{General Trust} (partial corr: 0.37, SE: 0.01).  The extent literature remains unclear as to how \textbf{\emph{learned}} \textbf{Affective Trust} is formed or what its antecedents are, though it may be directly shaped \textbf{\emph{Dispositionally}} \cite{schaefer2013perception,tussyadiah2018}.

Despite its relative lack of attention in the HRI/HAI trust literature, the effect of \textbf{Structural Trust} on \textbf{General Trust} has proven surprisingly strong (partial corr:0.40, SE: 0.02).  Its strength may be an indication that, indeed, ethics and integrity are relevant to specific robotics applications in contradiction to earlier suppositions \cite{Tegmark}.  While \textbf{Structural Trust}'s importance may be application specific, the minor variance across experiments in its effective strength indicates otherwise.  However, \textbf{Structural Trust} may have a weaker effect on \textbf{Intent to Use} (partial corr: 0.12, SE: 0.10) because it gets over-ridden by other factors (e.g., \textbf{Capability-based Trust}, \emph{workload}) \cite{Tegmark}.

\textbf{Capability-based Trust} is usually the go-to in HAI/HRI/HCI; however, these results indicate that focusing on it alone may be a mistake.  \textbf{Capability-based Trust} is only marginally more strongly correlated with \textbf{General Trust} (partial corr: 0.47, SE: 0.01) than \textbf{Structural} (partial corr: 0.40, SE: 0.02) or \textbf{Affective Trust} (partial corr: 0.37, SE: 0.01).  On the other hand, \textbf{Capability-based Trust} has a much stronger direct effect on \textbf{Intent to Use} (partial corr adj: 0.33, SE: 0.05).  It also becomes increasingly important over time, replacing the effects of \textbf{\emph{Dispositional}} and \textbf{\emph{Situational Trust}} \cite{Merritt2008}.  Many instruments found that \textbf{Capability-based Trust} encompassed two distinct sub-factors, often called \emph{Performance} and \emph{Reliability}.  The former can be defined as one's belief in another's ability, while the latter is their confidence assessment of that belief.  For example, I may think that a machine is accurate 80\% of the time, but I may only be 30\% sure that I am correct.  How these beliefs may be combined into a singular assessment is another matter (two ways forward may be Dempster-Shafer Theory or Subjective Logic \cite{josang2016subjective}).  A similar dichotomy between expectation and confidence may be paralleled in \textbf{Structural Trust} with the sub-groupings of \emph{Ethical} and \emph{Sincere}, respectively  \cite{law2021trust}.  While no survey has yet demonstrated a similar dichotomy in \textbf{Affective Trust}, the linguistic cluster analysis in \cite{jian} suggests that \emph{Wariness} may serve as the inverse of \emph{confidence} in \textbf{Affective Trust}.   

While \textbf{General Trust} does not fully determine \textbf{Intent to Use}, it is strongly correlated with it (partial corr adj: 0.63, SE: 0.01).  While strong, this amount of correlation reinforces that \textbf{Intent to Use} is not just a matter of trusting beliefs but is affected by a range of external factors, such as cognitive workload and perceived risk \cite{Desai2012}.

\section{Structure of HRI Trust - An Emergent Model }

\begin{figure*}
    \centering
    \includegraphics[width=0.9\textwidth]{HF_Formatted_Version/figures/Fig4_3_Trust_Theory-kf.pdf}
    \caption{Summary of relations between trust antecedents and factors that emerge from the meta-analysis. Black arrows indicate directed connections established by multiple independent works.  Red and blue lines were only established by individual works.  Red and black indicate connections from dispositional to situational to learned,  and blue arrows are in the reverse direction. }
    % \Description{A flow chart showing the reliable and validated structure of internal trust and its 10 constituent factors.}
    \label{fig:caus_graph}
\end{figure*}

The meta-analysis reveals a convergent picture of HAI/HRI Trust emerging out of the efforts of many researchers.  Figure~\ref{fig:caus_graph} provides a graphical summary of this emergent model of trust.  As can be seen, the trust factors and antecedents can be fairly neatly grouped into three layers, substantiating the early findings of \citeA{Hoff2015}.  The overall direction of plausible causality and strong inter-survey agreement has revealed a tentative picture of trust that is, in many ways, intuitive. \emph{A priori} \textbf{\emph{Dispositional}} expectations are first filtered through contextual, \textbf{\emph{Situational}} trust antecedents such as one`s \textbf{Familiarity} with the system, its similarity to previous systems (\textbf{Situational Normality}), and one's impression of the system (\textbf{Emotional Response}). These antecedents all feed into one's \textbf{Shared Mental Model} of the system, which then supports three different types of expectations - whether the system shares the user's goal (\textbf{Affective}), whether it is \textbf{Capable} of achieving that goal, and whether it will follow expected norms or laws when trying to achieve that goal (\textbf{Structural}).  They all contribute to a \textbf{General} assessment of trust, which in turn influences their \textbf{Intent to Use} the system.  Additional studies have further bolstered this model, especially regarding the dynamics of trust over time.  Throughout the interaction, the higher-level factors play decreasingly important roles, as the \textbf{Shared Mental Model} gets updated and the \textit{learned} trust factors  calibrate more closely to {\fontfamily{qzc}\selectfont external} circumstances.

\subsection{Are the differences between Affective and Structural Trust substantial enough to merit separate categories?}

The best way to conceive of \textbf{Structural Trust} is to go back to Luhmann \cite{luhmann}, the originator of the whole science of trust.  \textbf{Structural}, or what he called societal trust, is the abstraction of \textbf{Affective}, or personal, trust.  \textbf{Affective Trust} is founded in the dyadic trust relationship, is rooted in personal knowledge, and is realized through individual attachment, bond, loyalty, and love.  In contrast, \textbf{Structural Trust} universalized this in a world of strangers. 

Thus, while the two are related and both fall under \emph{relation-based trust} \cite{law2021trust}, there are also fundamental differences between \textbf{Structural} and \textbf{Affective Trust}.  \textbf{Affective Trust} is driven by the particular, recognizing the individual's specific goals and supporting them.  In human-human trust, this can be out of benevolence, loyalty, love, or attachment.  However, we have contended that these sources for \textbf{Affective Trust} are not essential, especially in the human-machine context \cite{Razin2021b}.  Instead, we can understand it as arising from inter-agent expectations of commitment and cooperation to achieve shared goals.  On the other hand, \textbf{Structural Trust} is about fairness and equality of treatment.  In humans, it may be driven by fear of sanction or internally-driven honor or integrity to uphold universal norms \cite{dunning2014trust}, and in general, is about how power dynamics encourage compliance around how goals are achieved \cite{Razin2021b}.

That being said, as one factor is derived from the other, the difference between them may not always be so clear, as is illustrated by the correlation between \textbf{Affective} and \textbf{Structural Trust}.  This is because it can be unclear whether honesty, loyalty, and respect should be situated as \textbf{Affective} or \textbf{Structural}. How one differentiates these concepts can depend on cultural understanding, personal motivations, ethical framing, and whether they are attributed to internal or external motivations \cite{dunning2014trust,Chien2014,malle2021multidimensional}. 


A common question arises as to whether \textbf{Affective} and \textbf{Structural Trust} are both worth measuring, as many may not see how they are relevant to a specific robot pick-and-place task in a lab, for example.  That the robot could be nefarious and have competitive goals (\textbf{Affective Trust}) or not follow the rules (\textbf{Structural Trust}) is often not even considered).  Asking about deception can, in fact, elicit suspicion in both of these categories, an issue to which we will return.  \textbf{Affective Trust} is likely always at play, even if it is only in the narrowest \emph{calculative-based} sense, i.e., \cite{Gefen2003}.  Ignoring \textbf{Structural Trust} in the lab presents a severe threat to etiological validity where it may have clear effects on behavior and beliefs in the real world when it comes to branding; attitudes toward tech companies, government, and industry regulations; and insurance liability.  Furthermore, AIs and robots are assumed to be more fair and ethical than humans \cite{starke2021fairness}, demonstrating potential bias in \textbf{Structural Trust}.  

%Instead of personal, special treatment customized to individuals, Structural Trust, means to be fair through rules equally applied to all.  The direction of technological development has meant that robots and automation are usually seen as tools that have no knowledge of the individual, so they are usually bound by Structural Trust.  Newer systems that learn from individuals and are becoming more adaptive and personalized may be expected to be governed more effectively.  However, Structural Trust is often ignored in lab settings, whereas it has clear effects in the real world with regard to branding, attitudes toward tech companies, government and industry regulations, and insurance liability.  Affective Trust can be difficult to separate from structural at times since we buy, accept, and use technologies that we believe will help fulfill our goals, but we choose goals with enabling constraints that conform to societal norms.  Such questions are at the bleeding edge, at the border of science fiction, which has often dealt with villains who override ethical constraints in AI agents (violating Structural Trust) to align these AIs with their own personal goals (establishing Affective Trust).  AIs and robots are generally assumed to be more fair and ethical than humans \cite{starke2021fairness}, demonstrating potential bias in Structural Trust.  Though others have shown that this is domain-specific, for instance, in a driving simulator, autonomous cars were presumed to follow the law as much as human drivers \cite{razin2019}.


Another reason to differentiate between \textbf{Affective}, \textbf{Structural}, and \textbf{Capability-based} trust is that antecedent factors have different effects on them.  For instance, \textbf{Structural Trust} is directly affected by \textbf{\emph{Dispositional}} factors, whereas \textbf{Affective Trust} does not seem to be.   We rely on structural assurance to protect us from strangers and new technologies, linking \textbf{Faith in Technology} and \textbf{Structural Trust}. Another example of the differential effect of antecedents was found in our own experiments \cite{razin2019}, where \textbf{Familiarity} affected \textbf{Capability-based Trust} but not \textbf{Structural}. By dividing out the factors that compose trust, we can better understand which antecedents affect which aspects of our expectations and better understand the {\fontfamily{qzc}\selectfont internal} dynamics of trust.

%This difference may be due to the research context.  Many of the experiments used to validate these instruments are novel, and, like trusting a stranger, dispositional trust informs how we impute the likelihood of norm compliance.

%One would expect both structural and Affective Trust to converge quickly and to only change after a severe trust failure.  In humans, this failure is easily forgiven if attributed to capability but unrecoverable if attributed to affective or structural, crucially revealed in the well-known attribution bias.  This is likely the same in robots unless re-programming/training or a security/privacy/safety upgrade is possible.  It is also not surprising that Structural Trust is directly affected by Dispositional Trust, whereas Affective is not.  Many of the experiments used to validate these instruments are novel, and, like trusting a stranger, dispositional trust informs how we impute the likelihood of norm compliance.  We rely on structural assurance to protect us from strangers and new technologies, and thus both Faith in Technology and Structural Trust are more heavily externally influenced by culture.

\subsection{Comparison with Human-Human Trust Measurement}
Unlike HRI/HAI trust, early works on human-human trust were entirely focused on \textbf{\emph{Dispositional trust}} measures \cite{Rotter_67, gillespie2003measuring, mcevily2011measuring}.  Measures for inter-personal trust started developing in many professional contexts, from organizational trust between employees and managers, between firms, and within business networks \cite{Mayer1995,bhattacherjee2002individual,schoorman2007integrative,johnson2005cognitive}.  A second major approach developed that studied trust in friendships and intimate relationships \cite{gottman2011science,bukowski1994measuring}.  Building off these approaches, other veins developed in the healthcare community between patients and doctors \cite{thom2004measuring,anderson1990development}, as well as trust in media \cite{matthes2008content}, and trust in strangers \cite{ermisch2009measuring}.  

While HRI trust rarely explored \emph{Faith in People} or \emph{Faith in Technology Companies}, it did occasionally employ or adapt questions from human-human works \cite<e.g.,>{Rotter_67,wheeless,Mayer1995,Hoffman2013,Mann2015}, though generally did not incorporate them into their larger model or show that they correlated with other antecedents or trust factors.  The influence and trust definition of \citeA{Mayer1995}, who primarily worked in organizational trust, is hard to overstate.  Human-human trust work should also be credited for dividing out \textbf{Affective} from \textbf{Capability-based Trust} \cite{lewis1985trust}, as well as \textbf{Structural Assurance} from \textbf{Situational Normality} \cite{McKnight2001}. 

An essential point of comparison to this study is \citeA{mcevily2011measuring}, who performed a similar review for human-human trust scales.  Interestingly, they identified a similar number of trust scales in human-human trust with a similar pattern of development, where 60\% had created their own \emph{ad hoc} measures, and 40\% re-used a previously validated instrument.  They also discussed the reliability and construct validity patterns over time.  During their review, they found that even fewer human-human scales had reported empirical validity measures than we found for HRI/HAI/HCI scales.  Only 22\% of human-human scales considered multi-factorial trust as opposed to single uni-dimensional items.

The dimensions reported fall closely in line with our own, as seen in Table \ref{tab:hu-hum}. 

\begin{table}
    \centering
    \caption{Operationalized factors of human-human trust \protect\cite{mcevily2011measuring}}
    \begin{tabular}{l|c}
      Factor&\# of times operationalized\\\thickhline
       Capability-based Trust  & 58  \\\hline
       Affective Trust     &  40 \\\hline
       Structural Trust & 22 \\\hline
       General Trust & 9 \\\hline
       Familiarity & 2\\\hline
       Emotional Response & 3\\\hline
       Faith in People & 4\\\hline
       Willingness to Risk & 4 \\\hline
       \begin{tabular}{@{}l@{}}\textbf{Openness, Availability,}\\ \textbf{Receptivity, Forbearance}\end{tabular} & 13\\ 
    \end{tabular}
    \label{tab:hu-hum}
\end{table}

Beyond analogous factors, the similarity in structure is more than apparent.  Thus, trust appears to be exapted; trust mechanisms that developed over millennia for humans and animals are co-opted for robot interaction.  This resemblance lends support to the model of Computers-as-Social actors (CASA) \cite{nass1997computers}, though the internal weights or expectations assigned to individual factors may indeed differ \cite{deVisser2016almost}.

There was only one major grouping that our model did not capture, which was how available, open, and receptive the potential trustees and trustors were.  Likely, this grouping is closely tied to the importance of \emph{Agreeableness} in trust from Personality research \cite{freitag2016personality}, as well as our factor of \textbf{Emotional Response}.  However, it seems distinct enough within human-human trust to merit its own factor and a potential focus of future work in HRI.  On the other hand, \textbf{Shared Mental Models} were entirely missing in \citeA{mcevily2011measuring}.  However, while a decade ago, human-human trust may have lacked such measures, the importance of this factor in human-human trust is now being recognized \cite<e.g.,>{mccomb2017evaluation}.  While many have considered the differences between human-human and human-robot trust \cite{Madhavan2007,Lyons2012,deVisser2016almost,alarcon2021role}, the relevant factors and their measurement are highly similar, and we hope that works like this one will continue to bridge the gap.

%\section{}
\subsection{Limitations and Outstanding Issues}
As this is a meta-analysis where not every survey covered every factor, many factors were not assessed for their potential as mediating factors.  Furthermore, of the 29 relationships examined, 15 are only supported by a single source in our sample, 5 by two sources, and only 9 have three or more sources.  Of those 9, 7 exhibit high heterogeneity, making it challenging to identify which values are outliers or to detect certain biases.  There are also 5 relationships whose lower confidence interval bounds cross 0, which threatens their significance level.  Additionally, there are two relationships where the standard error is nearly as large as, if not larger(!) than, the partial correlation.   Finally, there are three relationships (see blue dashed arrows in Fig. \ref{fig:caus_graph}) where the plausible direction of causality is reversed in one source compared to all other surveys.  Many of these relationships require further repeated testing with reliable and valid instruments over large samples to clarify their significance and plausible direction.

Another challenge is correctly understanding what structural equation models (SEMs) imply and do not imply with regard to causality.  There are many misunderstandings about SEMs, and it should be understood that SEMs do not prove causality.  However, \emph{if} the assumptions of SEMs and statistical measures of fit prove sufficient, then evidence for the plausibility of causality \cite{bollen2013eight} is gained.  While we combine SEM and regression results in the meta-analysis, it is also worthwhile to clarify that SEM and regression are \emph{not} the same, as SEM incorporates causally-relevant assumptions \cite{bollen2013eight}.  This does not preclude combining them in a meta-analysis, but we can no longer assume those assumptions hold.

Another issue can arise with modeling; too few questions may be asked to establish individual factors.  This issue caused us to not include 3 reliable and valid instruments in our meta-analysis.  For example, single \textbf{Affective trust} items focusing on cooperativeness, shared goals, and benevolence often cluster with \textbf{Calculative-based} factors due to their high correlation (partial corr:0.66, SE 0.04) when an insufficient number of questions on \textbf{Affective trust} are asked (e.g., \cite{schaefer2013perception}).  This merger is especially true for surveys that treat trust as a single factor \citeA<e.g.,>{Rupp2016}'s use of \citeA{jian}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{HF_Formatted_Version/figures/Fig4_1_Expanded_Trust_Layers.jpg}
    \caption{The emergent trust model in relation to significant external factors}
    % \Description{A flow chart showing the emergent model of trust and how the external dispositional, situational, and learned trust factors and antecedents inform the internal trust model.}
    \label{fig:expanded_trust}
\end{figure*}