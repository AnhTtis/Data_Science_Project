\section{Related Work}

\begin{comment}
\paragraph{Supervised 3D instance segmentation}
As instance segmentation is a key challenge in 3D scene understanding, it has been of central focus in 3D perception. 
Significant progress has been made in the fully-supervised settings, with myriad approaches developed in recent years on various 3D representations.
In particular, unstructured points \cite{qi2017pointnet++,wu2019pointconv,wang2019dynamic,rethage2018fully,wang2018sgpn,hu2020randla,fan2021scf} have been popular, characterizing raw data representations, with sparse voxels \cite{3DSemanticSegmentationWithSubmanifoldSparseConvNet,choy20194d,spconv2022} offering an effective trade-off between resolution and structure. 
In instance segmentation, both bottom-up methods focused on clustering features \cite{occuseg, chen2021hierarchical,hou20193d,rozenberszki2022language,liang2021instance,vu2022softgroup,vu2022softgroup++} as well as top-down approaches which first predict regions followed by classes \cite{yang2019learning,yi2019gspn,hou20193d,hou2020revealnet} have been explored.
Recently, with the emergence of transformer architectures, 3D attention-based models \cite{sun2022spformer,Schult23mask3d} have also achieved state-of-the-art 3D instance segmentation performance. 
We also employ a 3D transformer-based backbone for self-training, but in contrast to these works, do not require any manually annotated data for training. 
\end{comment}


\paragraph{Self-supervised 3D pretraining}

% Inspired by success in the 2D domain, various 3D pretraining methods have been developed to boost semantic and instance segmentation performance when fine-tuning with annotated semantic labels. 
While significant progress has been made in fully supervised 3D instance segmentation \cite{qi2017pointnet++,fan2021scf,3DSemanticSegmentationWithSubmanifoldSparseConvNet,choy20194d,occuseg,hou20193d,rozenberszki2022language,vu2022softgroup++,sun2022spformer,hou2023mask3d} the amount of densely annotated 3D data is scarce. Inspired by success in the 2D domain, various 3D pretraining methods have been developed to boost semantic and instance segmentation performance when fine-tuning with annotated semantic labels. 
Such methods leverage instance discrimination based on different camera views \cite{xie2020pointcontrast,hou2021exploring}, local augmentations \cite{zhang_depth_contrast}, or multiple LIDAR sweeps \cite{nunes2022segcontrast}.
While these methods can provide powerful 3D feature extraction, they do not construct any notion of object instances.

\paragraph{Weakly-supervised 3D segmentation}
Classical methods have leveraged object template information to match or retrieve templates to local geometry in a scene \cite{searchclassify,kim2012acquiring,karpathy2013object,chen2014automatic,li2015database,Nakajima_2019_ICCV}, thereby identifying potential object locations.
% Box2Mask~\cite{chibane2021box2mask} additionally formulated 3D instance segmentation with only 3D box annotation requirements rather than full dense masks.
Other methods formulated 3D dense instance segmentation with only 3D box annotation \cite{chibane2021box2mask, Peng2023PointCI} or single-point supervision and active-learning \cite{Liu2021OneTO, Wang2022OneCO}. 
More recent methods have focused on exploiting knowledge from powerful pre-trained vision-language models to inform text-guided queries in 3D scenes \cite{shafiullah2022clipfields, conceptfusion, Peng2022OpenScene, ding2022language, Liu2022PartSLIPLP}; however, such methods still rely on large-scale annotated data in the 2D domain.

\begin{comment}
    \paragraph{Graph Cuts}
\DAVID{move evrything to the 2d part and only briefly mention these}
Classical graph-cut algorithms can also be used to detect objects in scenes, regardless of the representation, be it images described by pixels or 3D rooms composed of triangular meshes. These methods \cite{wu1993_mincut,Chopra1993ThePartitionProblem,Deza2009GeometryOC,shi2000normalized_cut} have successfully demonstrated that even low-level features can serve as node attributes for effectively clustering self-similar regions, enabling quasi-instance segmentation. In our work, we leverage this insight. However, instead of relying on raw color information, we harness powerful self-trained features for higher-level clustering.
\end{comment}


\paragraph{Clustering-based segmentation}
There has been very little work done in fully unsupervised 3D instance segmentation, but classical clustering methods have been used to group regions with similar geometric properties together. 
A particularly notable approach is the density-based clustering of DBSCAN~\cite{dbscan} and its hierarchical counterpart HDBSCAN~\cite{mcinnes2017accelerated_hdbscan}. 
These methods can be used to group point clusters in a 3D scene based on point normals and colors.
The ScanNet dataset~\cite{dai2017scannet} showed that the Felzenswalb algorithm~\cite{felzenszwalb2004efficient} originally developed for image over-segmentation, can generate useful geometric segment clusters. 
We also exploit such geometric primitives to guide dimensionality reduction and feature aggregation. 

Finally, recent methods have been developed to detect instances with self-supervised pretrained features in driving scenarios. 
These methods often leverage the unique properties of such data  including dynamics and instance sparsity. 
Song et. al.~\cite{song2022_ogc} identify object instances through  motion, showing promise for self-driving scenarios, but limited to moving objects.
Nunes et. al.~\cite{nunes2022unsupervised} additionally propose a clustering and graph cut based refinement on pre-trained 3D features, focusing on sparse outdoor scenarios to identify spatially separate objects. 
Our solution aims to segments instances  in complex, cluttered indoor environments. 

\paragraph{Unsupervised 2D instance segmentation}

Classical graph-cut algorithms \cite{wu1993_mincut,Chopra1993ThePartitionProblem,Deza2009GeometryOC,shi2000normalized_cut} can be used to detect objects in scenes, employing low-level feature clustering to identify self-similar regions.
% In our work, we leverage this insight. However, instead of relying on raw color information, we harness powerful self-trained features for higher-level clustering.
Recent advances in self-supervised feature learning have been employed in  2D unsupervised instance segmentation methods, which  use two-stage training pipelines to achieve remarkable segmentation results \cite{wang2022freesolo,wang2023cut}. 
These methods first generate a set of coarse pseudo masks building on the insights of graph-cut algorithms and then refine them with a series of self-training iterations. 
%
In particular, FreeSolo~\cite{wang2022freesolo} uses multi-branch feature extraction to obtain self-similar regions as mask proposals, producing a dense set of initial pseudo-annotated instances.
%
CutLER~\cite{wang2023cut} uses the normalized cut (NCut) algorithm~\cite{shi2000normalized_cut} with deep self-supervised features from DINO~\cite{caron2021emerging_dino} to identify multiple prominent regions as pseudo masks.  
%Inspired by such approaches, we also develop a two-stage pipeline for unsupervised 3D instance segmentation. 
%
Inspired by such approaches we also leverage pseudo mask generation and self-training, but to handle high-dimensional, noisy real-world 3D scan data, we employ a multi-modal feature reasoning and geometric graph coarsening for robust unsupervised 3D instance segmentation. 
%\NEW{We also draw inspiration from pseudo masks and self-training, but in response to the limited data inherent to 3D scenes, our approach leans on multi-modal features, preserving the power of 3D reasoning and the generality of 2D features. Furthermore, we tackle dimensionality challenges and high-frequency noise by incorporating graph coarsening into our framework, facilitating robust unsupervised 3D instance segmentation.}