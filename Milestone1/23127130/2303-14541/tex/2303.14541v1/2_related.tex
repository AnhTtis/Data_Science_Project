\section{Related Work}

\paragraph{Supervised 3D instance segmentation}
As instance segmentation is a key challenge in 3D scene understanding, it has been of central focus in 3D perception. 
Significant progress has been made in the fully-supervised settings, with myriad approaches developed in recent years on various 3D representations.
In particular, unstructured points \cite{qi2017pointnet++,wu2019pointconv,wang2019dynamic,rethage2018fully,wang2018sgpn,hu2020randla,fan2021scf} have been popular, characterizing raw data representations, with sparse voxels \cite{3DSemanticSegmentationWithSubmanifoldSparseConvNet,choy20194d,spconv2022} offering an effective trade-off between resolution and structure. 
In instance segmentation, both bottom-up methods focused on clustering features \cite{occuseg, chen2021hierarchical,hou20193d,rozenberszki2022language,liang2021instance,vu2022softgroup,vu2022softgroup++} as well as top-down approaches which first predict regions followed by classes \cite{yang2019learning,yi2019gspn,hou20193d,hou2020revealnet} have been explored.
Recently, with the emergence of transformer architectures, 3D attention-based models \cite{sun2022spformer,Schult23mask3d} have also achieved state-of-the-art 3D instance segmentation performance. 
We also employ a 3D transformer-based backbone for self-training, but in contrast to these works, do not require any manually annotated data for training. 

\paragraph{Self-supervised 3D pretraining}
Inspired by success in the 2D domain, various 3D pretraining methods have been developed to boost semantic and instance segmentation performance when fine-tuning with annotated semantic labels.
Such methods leverage instance discrimination based on different camera views \cite{xie2020pointcontrast,hou2021exploring}, local augmentations \cite{zhang_depth_contrast}, or multiple LIDAR sweeps \cite{nunes2022segcontrast}.
While these methods can provide powerful 3D feature extraction, they do not construct any notion of object instances.

\paragraph{Weakly-supervised 3D segmentation}
Classical methods have leveraged object template information to match or retrieve templates to local geometry in a scene \cite{searchclassify,kim2012acquiring,karpathy2013object,chen2014automatic,li2015database,Nakajima_2019_ICCV}, thereby identifying potential object locations.
Box2Mask~\cite{chibane2021box2mask} additionally formulated 3D instance segmentation with only 3D box annotation requirements rather than full dense masks.
More recent methods have focused on exploiting knowledge from powerful pre-trained vision-language models to inform text-guided queries in 3D scenes \cite{shafiullah2022clipfields, conceptfusion, Peng2022OpenScene, ding2022language}; however, such methods still rely on large-scale annotated data in the 2D domain.

\paragraph{Unsupervised 3D clustering}
There has been very little work done in fully unsupervised 3D instance segmentation, but classical clustering methods have been used to group regions with similar geometric properties together. 
A particularly notable approach is the density-based clustering of DBSCAN~\cite{dbscan} and its hierarchical counterpart HDBSCAN~\cite{mcinnes2017accelerated_hdbscan}. 
These methods can be used to group point clusters in a 3D scene based on point normals and colors.
The ScanNet dataset~\cite{dai2017scannet} showed that the Felzenswalb algorithm~\cite{felzenszwalb2004efficient} originally developed for image over-segmentation, can generate useful geometric segment clusters. 
We also exploit such geometric primitives to guide dimensionality reduction and feature aggregation. 

Recent methods have been developed to detect instances with self-supervised pretrained features in driving scenarios. 
These methods often leverage the unique properties of such data  including dynamics and instance sparsity. 
Song et. al.~\cite{song2022_ogc} identify object instances through  motion, showing promise for self-driving scenarios, but limited to moving objects.
Nunes et. al.~\cite{nunes2022unsupervised} additionally propose a clustering and graph cut based refinement on pre-trained 3D features, focusing on sparse outdoor scenarios to identify spatially separate objects. 
Our solution aims to segments instances  in complex, cluttered indoor environments. 