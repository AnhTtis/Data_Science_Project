\documentclass[aps,pra,superscriptaddress,twocolumn,longbibliography]{revtex4-2}
%\usepackage[T1]{fontenc}
%\usepackage[latin9]{inputenc}
%\usepackage{geometry}
%\usepackage[a4paper, left=1.5cm, right=1.5cm, top=0.8in, bottom=0.8in]{geometry}
%\geometry{verbose,lmargin=1cm,rmargin=1cm}
%\setcounter{secnumdepth}{3}
\usepackage{units}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{xcolor}
\usepackage{bbold}

\usepackage[colorlinks=true, urlcolor=blue, citecolor=blue,linkcolor=blue,citebordercolor={1 0 0},linkbordercolor={0 0 1}]{hyperref}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\providecommand{\definitionname}{Definition}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}

%\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%

%\usepackage[ruled,vlined]{algorithm2e}
\usepackage[linesnumbered, ruled,vlined]{algorithm2e}


\graphicspath{{./images/},{./imagesAppendix/}}

\renewcommand{\eqref}[1]{Eq.~(\ref{#1})} % Reference to equation



%\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
%\numberwithin{equation}{section}
%\numberwithin{figure}{section}
%\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
%\theoremstyle{plain}
\newtheorem{fact}[thm]{\protect\factname}
\ifx\proof\undefined
\newenvironment{proof}[1][\protect\proofname]{\par
	\normalfont\topsep6\p@\@plus6\p@\relax
	\trivlist
	\itemindent\parindent
	\item[\hskip\labelsep\scshape #1]\ignorespaces
}{%
	\endtrivlist\@endpefalse
}
\providecommand{\proofname}{Proof}
\fi
%\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
%\theoremstyle{remark}
\newtheorem{claim}[thm]{\protect\claimname}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\ket}[1]{|#1 \rangle}
\makeatother
\newcommand{\braket}[2]{\langle #1 \vert #2 \rangle}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\idg}[1]{{\bfseries #1)}}
\newcommand{\im}{{\rm i}}

\newcommand{\defeq}{\mathrel{\mathop:}=}
\newcommand{\eqdef}{\mathrel{\mathop=}:}

\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\knote}[1]{{\color{red} #1}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\providecommand{\factname}{Fact}
\providecommand{\theoremname}{Theorem}
\providecommand{\claimname}{Claim}
\providecommand{\lemmaname}{Lemma}
\providecommand{\definitionname}{Definition}
\providecommand{\observationname}{Observation}

\newtheorem{observation}{\protect\observationname}

\providecommand{\propositionname}{Proposition}

\newtheorem{proposition}{\protect\propositionname}


%\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}

\definecolor{KB}{rgb}{0.4,0.3,0.9}
\newcommand{\KB}[1]{{\color{KB} #1}}

\definecolor{THc}{rgb}{0.9,0.3,0.2}
\newcommand{\tfh}[1]{{\color{THc} #1}} 


\newcommand{\revA}[1]{{\color{blue} #1}}
%\newcommand{\revA}[1]{{#1}}


\newcommand{\prlsection}[1]{{\em {#1}.---~}}




\newcommand{\subfigimg}[3][,]{%
	\setbox1=\hbox{\includegraphics[#1]{#3}}% Store image in box
	\leavevmode\rlap{\usebox1}% Print image
	\rlap{\hspace*{2pt}\raisebox{\dimexpr\ht1-0.5\baselineskip}{{\bfseries \large\textsf{#2}}}}% Print label
	\phantom{\usebox1}% Insert appropriate spcing
}

\newcommand{\sectionMain}[1]{
\let\oldaddcontentsline\addcontentsline% Store \addcontentsline
\renewcommand{\addcontentsline}[3]{}% Make \addcontentsline a no-op
\section{#1}
\let\addcontentsline\oldaddcontentsline
}

%APS Guide: https://cdn.journals.aps.org/files/revtex/auguide4-1.pdf
\setcounter{secnumdepth}{2} %to number sections in PRL revtex option

\newcommand{\rvline}{\hspace*{-\arraycolsep}\vline\hspace*{-\arraycolsep}}
\allowdisplaybreaks


\hyphenation{DQFIM}

\begin{document}


\title{Generalization with quantum geometry for learning unitaries}

\author{Tobias Haug}
\email{tobias.haug@u.nus.edu}
\affiliation{QOLS, Blackett Laboratory, Imperial College London SW7 2AZ, UK}

\author{M. S. Kim}
\affiliation{QOLS, Blackett Laboratory, Imperial College London SW7 2AZ, UK}

\begin{abstract}
Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. 
Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize.
For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and  training data needed to successfully train and generalize. 
We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. 
Further, we can improve generalization by removing symmetries from training data. 
Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data
distributions, can be better than using the same distribution.
Our work opens up new approaches to improve generalization in quantum machine learning.
\end{abstract}


\maketitle

%\section{Introduction}


The key challenge in quantum machine learning  is to design models that can learn from data and apply their acquired knowledge to perform well on new data~\cite{biamonte2017quantum}. This latter ability is called generalization and has been intensely studied recently~\cite{poland2020no,caro2020pseudo,abbas2020power,abbas2021effective,sharma2022reformulation,banchi2021generalization,caro2022out,peters2022generalization,gibbs2022dynamical,volkoff2021universal,cai2022sample,popescu2021learning,caro2021encoding,bu2022statistical,bowles2023contextuality,du2022demystify}. Constructing models that generalize well is essential for quantum machine learning tasks such as variational learning of unitaries~\cite{bisio2010optimal,marvian2016universal,bharti2021noisy,cerezo2020variational,xue2022variational,gebhart2023learning,kiani2020learning}, which is applied to unitary compiling~\cite{khatri2019quantum,ezzell2022quantum,volkoff2021universal}, quantum simulation~\cite{cirstoiu2020variational,gibbs2022dynamical,gibbs2022long}, quantum autoencoders~\cite{romero2017quantum,zhang2022resource} and black-hole recovery protocols~\cite{leone2022retrieving}. 

However, a priori it is difficult to predict whether a given quantum machine learning model will be able to generalize and usually time-consuming numerical studies have to be performed.
This is further confounded by the fact that the training of quantum machine learning models is usually hard~\cite{anschuetz2021critical,anschuetz2022quantum,bittel2021training,you2021exponentially,mcclean2018barren} and requires careful design to succeed~\cite{larocca2021theory,anschuetz2022quantum,you2022convergence,anschuetz2021critical,wiersema2020exploring}.

Thus, a metric that quantitatively predicts both training success and generalization is essential to aid the quest for better quantum machine learning models~\cite{schatzki2022theoretical,ragone2022representation,nguyen2022theory,zheng2021speeding,meyer2022exploiting,larocca2022group,sauvage2022building,skolik2022equivariant,haug2021capacity,anschuetz2022efficient,caro2022out} and potential advantages over classical models~\cite{huang2021power,liu2020rigorous,huang2021provably,liu2023towards}. In classical machine learning, measures of capacity have been developed which can directly evaluate generalization~\cite{bartlett2017spectrally,jiang2019fantastic,liang2019fisher,abbas2020power,abbas2021effective}. 
Recent works proposed the quantum Fisher information metric to measure the capacity of parameterized quantum states~\cite{haug2021capacity,larocca2021theory,meyer2021fisher,garcia2023effects}, however a connection with generalization has not been established.





Here, we introduce the data quantum Fisher information metric (DQFIM) to predict the performance of quantum machine learning models for learning unitaries.
Given an ansatz circuit and training data, the rank of the DQFIM quantifies the circuit depth and amount of data needed for generalization and convergence to a global minimum of the cost function. We apply the DQFIM to reduce the cost of generalization by finding models which require a low number of training data.
Further, out-of-distribution generalization, i.e. the training data is drawn from a different distribution than the test data, can exhibit better performance compared to in-distribution generalization.
Finally, while symmetries can reduce complexity, they can also hinder generalization. 
Our measure provides a practical way to understand the generalization capability of quantum machine learning models and guides the design of better models.



\noindent\prlsection{Model}
Let us consider a target unitary $V$, which we want to approximate with ansatz unitary $U(\boldsymbol{\theta})$ parameterized by $M$-dimensional parameter vector~$\boldsymbol{\theta}$. We learn  from a training set $S_L=\{\ket{\psi_\ell}, V\ket{\psi_\ell}\}_{\ell=1}^L$ of $L$ states which are randomly drawn from a distribution of states $\ket{\psi_\ell}\in W$~\cite{caro2021generalization,gibbs2022dynamical,gibbs2022long}.
We learn by minimizing the cost function given by the fidelity
\begin{equation}\label{eq:cost_train}
C_\text{train}(\boldsymbol{\theta},S_L)=1-\frac{1}{L}\sum_{\ell=1}^L\vert\bra{\psi_\ell}V^\dagger U(\boldsymbol{\theta})\ket{\psi_\ell}\vert^2\,,
\end{equation}
which can be efficiently measured with the SWAP test~\cite{garcia2013swap}.
This model generalizes when the learned unitary correctly transforms any state sampled from $W$ which is evaluated with the test error
\begin{equation}\label{eq:cost_test}
C_\text{test}(\boldsymbol{\theta},W)=1- \underset{\ket{\psi}\in W}{\mathbb{E}}[\vert\bra{\psi}V^\dagger U(\boldsymbol{\theta})\ket{\psi}\vert^2]\,.
\end{equation}
In variational quantum algorithms~\cite{bharti2021noisy} and quantum control~\cite{chakrabarti2007quantum}, the parameterized ansatz unitary $U(\boldsymbol{\theta})=\prod_{k=1}^G U^{(k)}(\boldsymbol{\theta}_k)$ commonly consists of $G$ repeating layers of unitaries $U^{(k)}(\boldsymbol{\theta}_k)=\prod_{n=1}^K\exp(-i\theta_{kn}H_n)$, where $H_n$ are hermitian operators, $\boldsymbol{\theta}_k$ a $K$-dimensional vector, and $\boldsymbol{\theta}=\{\boldsymbol{\theta}_1,\dots,\boldsymbol{\theta}_G\}$ the $M=GK$ dimensional parameter vector.
The optimization program starts with a randomly chosen $\boldsymbol{\theta}$ and iteratively minimizes~\eqref{eq:cost_train} with the gradient $\nabla C_\text{train}(\boldsymbol{\theta})$, which can be efficiently estimated by a quantum computer~\cite{mitarai2018quantum}.
Gradient descent iteratively updates $\boldsymbol{\theta}\rightarrow \boldsymbol{\theta}-\alpha\nabla C_\text{train}$ with some $\alpha$ until reaching a minimum after $E$ training steps, where $\nabla C_\text{train}(\boldsymbol{\theta}^*)=0$ with parameter $\boldsymbol{\theta}^*$. 
We assume  that ansatz $U(\boldsymbol{\theta})$ can represent the target unitary $V$, i.e. there is a parameter $\boldsymbol{\theta}_\text{g}$ such that $C_\text{test}(\boldsymbol{\theta}_\text{g},W)=C_\text{train}(\boldsymbol{\theta}_\text{g},S_L)=0$, which we enforce by choosing $V=U(\boldsymbol{\theta}_\text{g})$ with a randomly selected $\boldsymbol{\theta}_\text{g}$. 


After training we have three possible outcomes:
$(i)$ Reach a local minimum $C_\text{train}(\boldsymbol{\theta}^*,S_L)>0$, $C_\text{test}(\boldsymbol{\theta}^*,S_L)>0$ with an incorrect unitary for both training set $S_L$ and distribution $W$;
$(ii)$ Reach global minimum $C_\text{train}(\boldsymbol{\theta}^*,S_L)=0$, however no generalization with $C_\text{test}(\boldsymbol{\theta}^*,W)>0$. Here, $U(\boldsymbol{\theta}^*)$ correctly transform $S_L$, but performs poorly on states from $W$.
$(iii)$ Achieve global minimum and generalization with $C_\text{train}(\boldsymbol{\theta}^*,S_L)=C_\text{test}(\boldsymbol{\theta}^*,W)=0$ for any state from $W$.
In the following, we show that the DQFIM determines the critical number of circuit parameters $M_\text{c}$ and training states $L_\text{c}$ required to reach the global minimum and generalization which is the main result of our work. 


\begin{figure}[htbp]
	\centering	
\subfigimg[width=0.48\textwidth]{}{LearningSketch.pdf}\hfill
	\caption{ 
 \idg{a}~We represent unitary $V$ with ansatz unitary $U(\boldsymbol{\theta})$ by optimizing the $M$-dimensional parameter vector $\boldsymbol{\theta}$ in respect to cost function~\eqref{eq:cost_train} using $L$ training states $S_L=\{\ket{\psi_\ell},V\ket{\psi_\ell}\}_{\ell=1}^L$. 
 Only the isometry $U(\boldsymbol{\theta})\Pi_L$ can be learned, where $\Pi_L$ is the projector onto the space spanned by $\{\ket{\psi_\ell}\}_{\ell=1}^L$. The maximal rank of the data quantum Fisher information metric (DQFIM) $R_L$ describes the degrees of freedom of $U(\boldsymbol{\theta})\Pi_L$ that can be learned with $L$ training states. 
 \idg{b}~Phase diagram of optimisation and generalization with $M$ and $L$. 
 Convergence to global minimum ($C_\text{train}\approx0)$ is likely when $M\ge R_L$. The trained unitary can generalize to unseen test data ($C_\text{test}\approx0$) for $L\ge L_\text{c}\approx 2R_\infty/R_1$ and $M\ge R_\infty$. 
	}
	\label{fig:phases}
\end{figure}

\noindent\prlsection{DQFIM} 
A given training set $S_L$ allows us to learn a part of the unitary $U(\boldsymbol{\theta})$, which we define as follows: 
\begin{defn}[Learnable isometry]\label{def:dstate}
Given  training set $S_L=\{\ket{\psi_{\ell}},V\ket{\psi_\ell}\}_{\ell=1}^L$ of $L$ states, we define projector $\Pi_L$ onto the space spanned by the states $\{\ket{\psi_{\ell}}\}_{\ell=1}^L$ and its normalization $\tilde{\Pi}_L$
\begin{equation}\label{eq:datastate}
\Pi_L=\sum_{k=1}^{B_L}\ket{\phi_k}\bra{\phi_k}\,;\,\,\,\tilde{\Pi}_L=\Pi_L/B_L
\end{equation}
where $\ket{\phi_k}$ are the eigenvectors with non-zero eigenvalue of $\rho_L=L^{-1}\sum_{\ell=1}^L\ket{\psi_{\ell}}\bra{\psi_{\ell}}$ and $B_L=\mathrm{rank}(\rho_L)$.
Training with cost function~\eqref{eq:cost_train} learns the projection of the unitary $U(\boldsymbol{\theta})$ onto $\Pi_L$, which is the isometry
\begin{equation}\label{eq:isometry}
U_L(\boldsymbol{\theta})=U(\boldsymbol{\theta})\Pi_L\,.
\end{equation}
\end{defn}
To understand~\eqref{eq:isometry}, let us consider the $d$-dimensional unitary $U\equiv U(\boldsymbol{u})= \sum_{n,k=1}^d u_{nk}\ket{n}\bra{k}$ with complex parameters $\boldsymbol{u}=\{u_{11},u_{12},\dots,u_{dd}\}$ and training set $S_L=\{\ket{\ell},V\ket{\ell}\}_{\ell=1}^L$, where $\ket{\ell}\in W_\text{comp}$ are computational basis states and $V$ some unitary.
For $L=1$, training with~\eqref{eq:cost_train} optimizes $U\ket{1}=\sum_{n=1}^d u_{n1}\ket{n}$. Here, only the parameters of the column vector $u_1=(u_{11},u_{21},\dots,u_{d1})$ of $U$ have an effect on the state and can be learned, while all other parameters are hidden. 
For any $L$, applying $U$ on the states of $S_L$ gives us $\{U\ket{\ell}=\sum_{n=1}^d u_{n\ell}\ket{n}\}_{\ell=1}^L$. The learnable parameters of $U$ correspond to
the $d\times L$-dimensional isometry $U_L=(u_1,\dots, u_L)\equiv U\Pi_L$ with projector $\Pi_L=\sum_{\ell=1}^L\ket{\ell}\bra{\ell}$ and $U_L^\dagger U_L=\Pi_L$ (see Fig.~\ref{fig:phases}a).
Even if we find a global minima with $C_\text{train}=0$, training set $S_L$ with $L<d$ provides no information about the column vectors $(u_{L+1},\dots,u_d)$. The trained model $U(\boldsymbol{u}^*)$ will randomly guess these column vectors, resulting in generalization error $C_\text{test}>0$. Only for $L=d$, we have a complete training set that can achieve generalization $C_\text{test}=0$.

We can understand generalization with the number of independent parameters (or effective dimension) $D_L$  of the isometry $U_L$. For $L=1$, $U\ket{1}=\sum_{n=1}^d u_{n1}\ket{n}=\sum_{n=1}^d (a_{n1}+ib_{n1})\ket{n}$ has $2d$ real parameters $a_{n1}$, $b_{n1}$. However, due to global phase and norm, there are only $D_1=2d-2$ independent parameters. For $L=d$, parameterizing a complete unitary $U$ requires $D_d=d^2-1$ parameters. 
For example, a single qubit has $D_1=2$ (Bloch sphere) and $D_2=3$ (arbitrary unitary) free parameters~\cite{nielsen2002quantum}, and thus we require $L\ge2$ states to generalize.
However, depending on ansatz and data there can be less independent parameters $D_L$. 
Let us consider  $U(\theta_1,\theta_2)=\exp(-i\sigma_z \theta_1)\exp(-i\sigma_z \theta_2)$ and distribution $\{\ket{+},\ket{-}\}$ with $\ket{+}=\frac{1}{\sqrt{2}}(\ket{0}\pm\ket{1})$ and $z$-Pauli $\sigma_z$. While we have $M=2$ parameters, the generators commute and there is only $D_1=D_d=1$ independent parameter and $L=1$ state is already sufficient to generalize. In contrast, for distribution $\{\ket{0},\ket{1}\}$ we have $D_L=0$ and $L=0$ as only the global phase is rotated.

For general $S_L$ and $U(\boldsymbol{\theta})$, we now propose the DQFIM to quantify the effective dimension that can be learned (see Supplemental materials (SM)~\ref{sec:dQFIM} for derivation):
\begin{figure*}[htbp]
	\centering	
 \includegraphics[width=0.99\textwidth]{RankPlot.pdf}
\caption{DQFIM for different unitaries $U$ with $M$ parameters and $L$ training states. As defined in SM~\ref{sec:ansatz}, we show hardware efficient circuit $U_\text{HE}$ with no symmetries and Haar random training states (blue curves), as well as $U_{XY}$ with particle number symmetry using as training data either product states $W_\text{prod}$ (orange) or symmetry-conserving states  $W_{p=1}$ (green). 
 \idg{a}~Effective dimension $D_L$ increases linearly with $M$, until it reaches a maximal value $R_L$ for $M\ge M_\text{c}(L)$. We have $N=8$ qubits.
 \idg{b}~$R_L$ increases with $L$ until converging to $R_\infty$ for $L\ge L_\text{c}$. Black dashed line shows approximation $R_L\sim R_1L$. Inset shows generic ansatz without log-plot, highlighting the non-linear behavior of $R_L$.
 \idg{c}~Scaling of $R_1$ and $R_\infty$ with qubit number $N$. 
 \idg{d}~Number $L_\text{c}$ of training states needed for generalization. Black dashed line shows $L_\text{c}\approx 2R_\infty/R_1$.
	}
	\label{fig:rank}
\end{figure*}


\begin{defn}[DQFIM]\label{def:dQFIM}
For unitary $U(\boldsymbol{\theta})$ and training set $S_L$, the DQFIM is defined as 
\begin{align*}
&\mathcal{Q}_{nm}(S_L,U(\boldsymbol{\theta}))=\numberthis\label{eq:dQFIM}\\
&4\mathrm{Re}(\mathrm{tr}(\partial_n U^\dagger \tilde{\Pi}_L \partial_m U)-\mathrm{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\mathrm{tr}(U^\dagger \tilde{\Pi}_L\partial_m U))
\end{align*}
where $\partial_n$ is the derivative in respect to the $n$th entry of the $M$-dimensional vector $\boldsymbol{\theta}=(\theta_1,\dots,\theta_M)$ and $\tilde{\Pi}_L$ is given by~\eqref{eq:datastate}.
We also define the effective dimension
\begin{equation}
D_L(S_L,U(\boldsymbol{\theta}))=\mathrm{rank}(\mathcal{Q}(S_L,U(\boldsymbol{\theta}))\le M\,.
\end{equation}
\end{defn}
Intuitively, $\mathcal{Q}(S_L,U(\boldsymbol{\theta}))$ is a metric that describes how a variation in $\boldsymbol{\theta}$ changes the isometry $U(\boldsymbol{\theta})\Pi_L$. 
For $L=1$, we recover the QFIM $\mathcal{F}_{nm}=4\text{Re}(\braket{\partial_n\psi}{\partial_m\psi}-\braket{\partial_n\psi}{\psi}\braket{\psi}{\partial_m\psi})$~\cite{liu2020quantum,meyer2021fisher}, where $D_1$ describes the effective dimension that a parameterized state $U(\boldsymbol{\theta})\ket{\psi_1}$ can explore~\cite{haug2021capacity}.
$D_1$ increases when adding more layers $G$ and thus parameters $M$ to $U(\boldsymbol{\theta})$, until reaching a maximal value $R_1$ (see Fig.~\ref{fig:rank}a). Here,  the state $U(\boldsymbol{\theta})\ket{\psi_1}$ is overparameterized as it can explore all possible degrees of freedom of the ansatz for $L=1$~\cite{larocca2021theory}.  
Similarly, we introduce $R_L$ to describe the maximal number of degrees of freedom that the isometry $U_L$ can explore for any $L$:
\begin{defn}[Overparameterization]\label{def:ovp_U}
Ansatz $U(\boldsymbol{\theta},M)$ with training set $S_L$ is overparameterized when effective dimension $D_L$ does not increase further upon increasing the number of parameters $M$. The maximal rank $R_L$ reached for $M\ge M_\text{c}(L)$ is given by
\begin{equation}\label{eq:RLMc}
R_L\equiv\max_{M\ge  M_\text{c}(L),\boldsymbol{\theta}}D_L(S_L,U(\boldsymbol{\theta},M)) \,.
\end{equation}
\end{defn}
Once $M\ge M_\text{c}(L)$, a variation of $\boldsymbol{\theta}$ can explore all degrees of freedom of $U_L$. Thus, minimization is unlikely to get stuck in a local minimum of cost function $C_\text{train}$~\cite{rabitz2004quantum,bukov2018reinforcement,anschuetz2021critical,you2022convergence,larocca2021theory}.


\begin{figure*}[htbp]
	\centering	
\includegraphics[width=0.99\textwidth]{GraphPhases.pdf}
\caption{\idg{a} $C_\text{train}$ against $M$ and $L$.  Dashed black lines indicate $M_\text{c}(L)=R_L$ and $L_\text{c}=2R_\infty/R_1$. We have a $N=4$ qubit hardware-efficient ansatz with  Haar random training states, where we initialize with a random parameter, train with a gradient descent algorithm~\cite{fletcher2013practical} simulated with~\cite{johansson2012qutip} and average over 10 training repetitions. Target unitary is chosen as $V=U(\boldsymbol{\theta}_\text{g})$, where $\boldsymbol{\theta}_\text{g}$ is a random parameter of the ansatz unitary.
 \idg{b} Average $C_\text{test}$ against $M$ and $L$.
 \idg{c} Number of training steps $E$ until reaching $C_\text{train}< 10^{-4}$.
 \idg{d} $C_\text{test}$ and $C_\text{train}$ against $M$ with $U_{XY}$ ansatz for $N=6$ qubits, where we train with $L=1$ and $L=2$ product states $W_{\mathrm{prod}}$. We use $W_{\mathrm{prod}}$ as test states, except for green dotted curve $C_\text{test}^{p=1}$ where we show out-of-distribution generalization with symmetric test states $W_{p=1}$. 
 The dashed vertical lines indicate $R_1$ (yellow) and $R_2$ (red).
}
	\label{fig:test}
\end{figure*}



\begin{observation}[Convergence to global minima]\label{obs:overparam}
Global minimum $C_\text{train}(\boldsymbol{\theta}^*)\approx0$ with training set $S_L$ is reached with high probability when $M\ge M_\text{c}(L)\ge R_L$.
\end{observation}
As seen in Fig.~\ref{fig:rank}b, $R_L$ and thus the circuit parameters needed to reach the global minimum increases with $L$, where the growth slows down due to unitary constraints. We find the upper bound (SM~\ref{sec:RLexact} or~\cite{polcari2016representing})
\begin{equation}\label{eq:DLsin}
    R_L \le  2dL-L^2-1  \,\,\mathrm{for}\, L \le d\,;\,\, R_L \le d^2-1  \,\,\mathrm{for }\,\, L > d\,.
\end{equation}

Once the maximal possible $R_L$ is reached, the training states are sufficient to learn all degrees of freedom of $U$. Thus, we have an overcomplete training set:

\begin{defn}[Overcomplete data for learning unitaries]\label{eq:ovp_S}
For a given ansatz $U$, training set $S_L$ of $L$ training states $\ket{\psi_\ell}\in W$ drawn from ensemble $W$ is overcomplete  when $R_L$ does not increase further upon increase of $L$. The maximal rank $R_\infty$ is reached for $L_\text{c}$ training states
\begin{equation}
R_\infty = R_{L_\text{c}}(W,U)\equiv\max_{L\ge L_\text{c}}\underset{\ket{\psi_\ell}\in W}{\mathbb{E}}[R_L(S_L,U)]\,.
\end{equation}
\end{defn}

We bound $R_L$ similar to $R_1$ for Ref.~\cite{larocca2021theory} (see SM~\ref{sec:liebound}):
\begin{theorem}\label{th:liebound}
    The maximal rank $R_L$  is bounded by the dimension of the dynamical Lie algebra (DLA)
    \begin{equation}
        R_L\leq\dim(\mathfrak{g})\,,
    \end{equation}
    where $\mathfrak{g}=\mathrm{span}\left\langle iH_1, \ldots, iH_K \right\rangle_\text{Lie}$ is generated by the repeated nested commutators of the generators $H_k$ of $U(\boldsymbol{\theta})$.
\end{theorem}
By choosing the training states on the support of the DLA, we can find an overcomplete training set with $L_\text{c}\le \text{dim}(\mathfrak{g})$. In particular, when $\text{dim}(\mathfrak{g})\sim\text{poly}(N)$ we have $L_\text{c}\sim\text{poly}(N)$ and $M_\text{c}\sim\text{poly}(N)$.

We can estimate $L_\text{c}$ with the following consideration: To generalize we have to learn all $R_\infty$ degrees of freedom of the unitary. The first training state allows us to learn $R_1$ degrees of freedom, while each additional  state provides a bit less as seen in~\eqref{eq:DLsin}. For the upper bound~\eqref{eq:DLsin} we have $L_\text{c}\approx 2 R_\infty/R_1$, which we numerically find to be a good estimation also for other models:
\begin{observation}[Generalization for learning unitaries]\label{obs:threshold}
A trained model generalizes $C_\text{test}(\boldsymbol{\theta}^*)\approx0$ with high probability when the model is overparameterized (i.e. $M\ge M_\text{c}\ge R_L$ for Def.~\ref{def:ovp_U}) and overcomplete (i.e. $L\ge L_\text{c}$ for Def.~\ref{eq:ovp_S}). The critical number of training states $L_\text{c}$ needed to generalize can be approximated by
\begin{equation}\label{eq:Lcapprox}
    L_\text{c}\approx 2R_\infty/R_1\,.%2\frac{R_\infty}{R_1}\,.
\end{equation}
\end{observation}






\prlsection{Applications}
We want to learn the unitary evolution $V_{XY}=\exp(-iH_{XY} t)$ in time $t$ of the XY-Hamiltonian $H_{XY}=\sum_{k=1}^N(\sigma_k^x\sigma_{k+1}^x+\sigma_k^y\sigma_{k+1}^y+h_k \sigma_k^z)$, where $\sigma^\alpha_k$, $\alpha\in\{x,y,z\}$ is the Pauli operator acting on qubit $k$  and  $h_k\in \mathbb{R}$. We learn $V_{XY}$ with the $U_{XY}(\boldsymbol{\theta})$ ansatz (see SM~\ref{sec:ansatz}), which can represent $V_{XY}$ with a polynomially number of parameters~\cite{kokcu2022algebraic}. Further, $H_{XY}$ and $U_{XY}$ are symmetric in respect to the particle number operator $P=\sum_{k=1}^N\frac{1}{2}(1+\sigma^z_k)$ with $[U_{XY},P]=[H_{XY},P]=0$, where $[.]$ is the commutator.
We define the distribution $W_{p=1}$ of states $\ket{\psi_{\ell}}$ which are symmetric in regards to $P$, i.e. $P\ket{\psi_{\ell}}=\ket{\psi_{\ell}}$  with the same eigenvalue $p=1$ for all $\ell$. Further, we define the distribution of single-qubit product states $W_{\text{prod}}$ 
where $\ket{\psi_\ell}=\bigotimes_{k=1}^N\ket{\phi^{k}_\ell},\, \ket{\phi^{k}_\ell}\in\mathcal{H}(\mathbb{C}^2)$ which do not respect particle symmetry in general.
We now study generalization with $U_{XY}$ depending on the symmetry of the training states:
\begin{observation}[Generalization requires more data with symmetries]\label{obs:symmetry}
Ansatz $U_{\text{XY}}$ conserves particle number operator $P$ with $[U_{\text{XY}},P]=0$. We learn with $(i)$ the ensemble of particle-number conserving states  $\ket{\psi_\ell}\in W_{p=1}$ 
and $(ii)$ single-qubit product states $\ket{\psi_\ell}\in W_{\text{prod}}$. We generalize with $L\ge L_\text{c}$ training states where
\begin{align*}
(i)\; L_\text{c}=&N \;\mathrm{for}\; \ket{\psi_\ell}\in W_{p=1}\\
(ii)\;L_\text{c}=&2 \;\;\mathrm{for}\;  \ket{\psi_\ell}\in W_{\mathrm{prod}}\,\,,N>4\,.
\end{align*}
\end{observation}
This result follows directly from the scaling of $R_L$ (see Fig.~\ref{fig:rank}c,d). In particular, for $W_{p=1}$ we have $R_1=2N-2$, $R_\infty=N^2-1$, while for $W_{\mathrm{prod}}$ we find via numerical extrapolation $R_1=2N^2-3N+2$ and $R_\infty=2N^2-1$.
Generalization improves without symmetries as $R_1$ grows larger for $p>1$ and thus product states with support on all $p$ gain more information about $U_{XY}$ than data restricted to $p=1$.


Next, we consider out-of-distribution generalization where one generates the training set from a different ensemble than the test states~\cite{caro2022out}: 
\begin{observation}[Out-of-distribution generalization requires less data]\label{obs:outofdist}
Training $U_{XY}$ with $L\ge 2$ product states $\ket{\psi_\ell}\in W_{\mathrm{prod}}$ out-of-distribution generalizes symmetry conserving data $W_{p=1}$ with $C_\mathrm{test}(\boldsymbol{\theta}^*,W_{\mathrm{prod}})=C_\mathrm{test}(\boldsymbol{\theta}^*,W_{p=1})=0$.
In contrast, training $U_{XY}$ with $\ket{\psi_\ell}\in W_{p=1}$ requires $L\ge N$ training states to achieve $C_\mathrm{test}(\boldsymbol{\theta}^*,W_{p=1})=0$.
\end{observation}





\prlsection{Numerical results}
In Fig.~\ref{fig:test}a-c we study  training for hardware-efficient ansatz $U_\text{HE}$ (see SM~\ref{sec:ansatz}). In Fig.~\ref{fig:test}a, we converge to local minima with $C_\text{train}\gg0$ for $M\le R_L$, while we find global minimum $C_\text{train}\approx0$ for $M\ge R_L$, which is indicated as black dashed line. In Fig.~\ref{fig:test}b, generalization $C_\text{test}\approx0$ is achieved only for $M\ge R_\infty$ and $L\ge L_\text{c}\approx 2R_\infty/R_1$ indicated by the vertical black lines.
In Fig.~\ref{fig:test}c, the number of training steps $E$ needed to converge show characteristic peaks close to $M_\text{c}$ and $L_\text{c}$ indicated by black dashed lines. 
In Fig.~\ref{fig:test}d we study test and training error for the $U_{XY}$ ansatz for training with product state ensemble $W_{\mathrm{prod}}$. For sufficient $M$, we have $C_\text{train}\approx 0$ for $L=1$ and $L=2$ training data. Generalization with $C_\text{test}\approx 0$ requires $L\ge2$ when testing in-distribution $W_{\mathrm{prod}}$ or out-of-distribution $W_{p=1}$. 
We study other models which generalize for constant $L$ in SM~\ref{sec:cphase} and \ref{sec:training_gen}.

In Fig.~\ref{fig:gen_ovp}a we study $C_\text{test}$ against $L$, $M$ for $U_{XY}$ when training with particle-conserved ensemble $W_{p=1}$ (see also SM~\ref{sec:trainXY}). Generalization improves with $M$ and $L$, where the lower bound $C_\text{test}\sim 1-(L/L_\text{c})^2$~\cite{sharma2022reformulation} is saturated for $M\ge M_\text{c}$. In Fig.~\ref{fig:gen_ovp}b, we show that the training steps needed for convergence scale as $E\sim N^2$ with a clear peak at $L\approx L_\text{c}$ when overparameterized. 

\begin{figure}[htbp]
	\centering	
\subfigimg[width=0.24\textwidth]{a}{SingleTestFit.pdf}\hfill
\subfigimg[width=0.24\textwidth]{b}{SingleIteration.pdf}
	\caption{Learning with $U_{XY}$ and particle conserved data $\ket{\psi_\ell}\in W_{p=1}$.
 \idg{a} $C_\text{test}$ against $L$ for different $M$ with $N=16$, $L_\text{c}=N$. Black dashed  line is $C_\text{test}\sim 1- (L/L_\text{c})^2$.
 \idg{b} Training steps $E$ needed to converge to $C_\text{train}<10^{-4}$ against $L$ for $M\gg M_\text{c}$.
	}
	\label{fig:gen_ovp}
\end{figure}




\prlsection{Conclusion}
The newly introduced DQFIM $\mathcal{Q}$ and its maximal rank $R_L$ tell us the amount of data $L$ and circuit parameters $M$ needed to successfully learn unitaries. 
Overparameterized models~\cite{larocca2021theory,you2022convergence,anschuetz2021critical} converge to a global minimum with high probability for $M\ge M_\text{c}\ge R_L$. Generalization, i.e. correctly predicting new data, requires a critical number of training states $L\ge L_\text{c}$, which depends on the ratio $L_\text{c}\approx 2R_\infty/R_1$.
Overparameterization and generalization appear in three distinct regimes, where training time increases substantially at the transitions, which could indicate a computational phase transition~\cite{kiani2020learning,anschuetz2021critical}.
While the complexity of unitaries grows linearly with $M$~\cite{haferkamp2022linear,haug2021capacity}, the growth in learnable degrees of freedom $R_L$ and thus the circuit depth needed for overparameterization slows down with $L$. 
Generalization  for overparameterized models scales as $C_\text{test}\sim 1- (L/L_\text{c})^2$ saturating the lower bound of Ref.~\cite{sharma2022reformulation}, which is substantially better than the upper bound $C_\text{test}\sim \sqrt{1/L}$~\cite{caro2021generalization,banchi2021generalization}. For underparameterized models the empirical risk $C_\text{test}-C_\text{train}$~\cite{caro2021generalization} can insufficiently characterize generalization due to convergence to bad local minima (see SM~\ref{sec:risk}).



We show that generalization and overparameterization can be achieved with polynomial circuit depth and dataset size when the dimension of the DLA scales polynomially with $N$. When $R_1\sim N^\gamma$, $R_\infty\sim N^\gamma$ scale with the same $\gamma$, then $O(1)$ training states are sufficient to generalize, explaining the numerical observations of Ref.~\cite{gibbs2022dynamical} (see also SM~\ref{sec:training_gen}).
While symmetries can improve generalization~\cite{meyer2022exploiting,larocca2022group}, we show that symmetries in data can also hinder generalization by increasing the $R_\infty/R_1$ ratio.
Generalization improves here as symmetry-broken data has access to information of other symmetry sectors. 
This feature also allows out-of-distribution generalization~\cite{caro2022out} to outperform in-distribution generalization.
Note that symmetry-broken data requires slightly more parameters, which implies an interesting trade-off between dataset size and circuit depth. 
Finally, the DQFIM could be extended to evaluate generalization for other quantum machine learning tasks~\cite{bharti2021noisy} as well as data re-uploading ~\cite{perez2020data,jerbi2023quantum}, kernel models~\cite{schuld2019quantum,haug2021large} and the effect of noise~\cite{garcia2023effects}.
The code for this work is available online~\cite{haug2023gen}.

 \let\oldaddcontentsline\addcontentsline% Store \addcontentsline
\renewcommand{\addcontentsline}[3]{}% Make \addcontentsline a no-op


\medskip
\begin{acknowledgments}
%{{\em Acknowledgements---}} %\noindent 
%\section{Acknowledgements}
{{\em Acknowledgements---}} We acknowledge discussions with
Adithya Sireesh.
This work is supported by a Samsung GRC project and the UK Hub in Quantum Computing and Simulation, part of the UK National Quantum Technologies Programme with funding from UKRI EPSRC grant EP/T001062/1. 
\end{acknowledgments}
%\bibliographystyle{apsrev4-1}
\bibliography{generalization}


\let\addcontentsline\oldaddcontentsline


\clearpage
\onecolumngrid
\appendix 



\tableofcontents


\section{Ansatz unitaries}\label{sec:ansatz}
The ansatz unitaries used in the maint text are shown in Fig.~\ref{fig:ansatze}.
We assume that the considered unitaries have a periodic structure of $G$ layers with 
\begin{align*}
    &U(\boldsymbol{\theta})=\prod_{k=1}^G U_k(\boldsymbol{\theta}_k) \,,\,\,U^{(k)}(\theta_k)=\prod_{n=1}^K\exp(-i\theta_{kn} H_n)\label{eq:ansatz_sup}\numberthis
\end{align*} 
where $U^{(k)}(\theta_k)$ is the unitary of the $k$th layer. Here, $H_n$ are $K$ hermitian matrices and $\boldsymbol{\theta}_k=\{\theta_{k1},\dots,\theta_{kn}\}$ are the parameters of the $k$th layer. The total parameter vector $\theta=\{\boldsymbol{\theta}_1,\dots,\boldsymbol{\theta}_G\}$ of the ansatz has $M=GK$ parameters.

In Fig.\ref{fig:ansatze}a, we show a hard-ware efficient ansatz $U_\text{HE}$, which produces highly random circuits which span the full Hilbertspace nearly uniformly and are known to be hard to simulate classically. Overparameterization requires for this circuit exponentially many parameters.

\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.7\textwidth]{}{SketchLearningCircuits.pdf}\hfill
	\caption{ Ansatz unitaries for the main text. The circuits are repeated for $G$ layers. 
 \idg{a} Hardware-efficient ansatz $U_\text{HE}$ consisting of parameterized $y$, $z$ rotations and CNOT gates. Has no symmetries and can realize arbitrary $N$-qubit unitaries for sufficient depth.
 \idg{b} $U_{XY}$ circuit inspired by $XY$-model~\eqref{eq:XY}. Composed of single qubit $z$ rotations and nearest-neighbor $\sqrt{\text{iSWAP}}$ gates, arranged with periodic boundary condition. Commutes with particle number operator $P$ and for sufficient depth can realize any time evolution generated by $\exp(-iH_{XY} t)$.
 \idg{c} Real-valued ansatz $U_\text{Y-CZ}$ consisting of $y$-rotations and control-$Z$ gates in a nearest-neighbor chain configuration. 
	}
	\label{fig:ansatze}
\end{figure*}





In Fig.\ref{fig:ansatze}b, we show an ansatz $U_\text{XY}$ with symmetries that overparameterizes in polynomial depth.
This ansatz is inspired from the integrable XY Hamiltonian with random field $h_k$
\begin{equation}\label{eq:XY}
H_{XY}=\sum_{k=1}^N h_k \sigma_k^z +\sum_{k=1}^N( \sigma_k^x\sigma_{k+1}^x+\sigma_k^y\sigma_{k+1}^y)
\end{equation}
$H_{XY}$ commutes with the particle number operator
%\begin{equation}
$P=\sum_{k=1}^N\frac{1}{2}(1+\sigma^z_k)$
%\end{equation}
where $\sigma^z_k$ is the Pauli $z$ operator acting on qubit $k$. In particular, we have $[H_{XY},P]$.
Time evolution $U=\exp(-iH_{XY}t)$ also conserves the symmetry, i.e. $[U,P]=0$. The ansatz $U_{XY}$ shown in~\ref{fig:ansatze}b can represent the time evolution of the Hamiltonian. $U_{XY}$ consists of parameterized $z$-rotations and nearest-neighbor $\sqrt{\text{iSWAP}}=\exp(i\pi/8(\sigma_k^x\sigma_{k+1}^x+\sigma_k^y\sigma_{k+1}^y))$ gates.  One can think of this model similar to a Trotterized version of the time evolution $U=\exp(-iH_{XY}t)$.  The generators of $U_{XY}$ are the Pauli operators of $H_{XY}$. Thus, the time-evolution operator $U_{XY}$ spans the same dynamical Lie algebra as the time evolution generated by $H_\text{XY}$ and can represent any time evolution of $H_\text{XY}$~\cite{kokcu2022algebraic}. The dimension of the dynamical Lie-algebra spanned by  $U_{XY}$ scales polynomial with qubit number $N$ and thus can be overparameterized with polynomially many parameters $M$~\cite{larocca2021theory}. 
For random product states $W_\text{prod}$ as training set, we we find via numerical extrapolation $R_1=2N^2-3N+2$ and $R_\infty=2N^2-1$.
We also choose a training set $W_{p=1}$ with $P=1$ particles, which consists of arbitrary superpositions of permutations of the basis states $\ket{10\dots0}$. We have $P\ket{\psi_\ell}=\ket{\psi_\ell}$ for any state $\ket{\psi_\ell}\in W_{p=1}$. These states live in an effective $N$-dimensional subspace, yielding $R_1=2N-2$ and $R_\infty=N^2-1$.



\section{Generalization and empirical risk}\label{sec:risk}
We define generalization via the error of the cost function $C_\text{test}$ averages over the full data ensemble $W$.  In our studies, we choose the problem such that $C_\text{test}=0$ can be achieved for at least one parameter $\boldsymbol{\theta}_\text{g}$.

In general, the minimal achievable $C_\text{test}$ for given ansatz and data distribution may not be known. 
Thus, often the empirical risk $\zeta=C_\text{test}-C_\text{train}$ of the trained model is used as a proxy to evaluate generalization~\cite{caro2021generalization}. 
In Fig.~\ref{fig:risk}, we compare $C_\text{train}$, $C_\text{test}$ and empirical risk $C_\text{test}-C_\text{train}$. We show the hardware-efficient ansatz with $N=4$ overparameterizes  for $M\ge M_\text{c}=4^N-1=255$ and $L_\text{c}=2^N=16$.
When the model is underparameterized $M\le M_\text{c}$, the training error in Fig.~\ref{fig:risk}a and test error in Fig.~\ref{fig:risk}b can be quite large. In contrast, the empirical risk in Fig.~\ref{fig:risk}c shows favorable scaling with $L$. However, note that the actual test error decreases in absolute value only slightly with $L$.
Overparameterization $M\ge M_\text{c}$ drastically reduces the training error to zero, and for $L\ge L_\text{c}$ allows us to find $C_\text{test}\approx0$.


\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.28\textwidth]{a}{RiskTrain.pdf}
\subfigimg[width=0.28\textwidth]{b}{RiskTest.pdf}
\subfigimg[width=0.28\textwidth]{c}{RiskRisk.pdf}
	\caption{Training error, test error and empirical risk for hardware-efficient ansatz with haar random training states for $N=4$ qubits. We assume that there is an optimal solution, i.e. there is at least one parameter with $C_\text{test}(\boldsymbol{\theta_\text{g}})=0$.
 \idg{a} $C_\text{train}$ against  $L$ for different $M$.
 \idg{b} $C_\text{test}$ against  $L$ for different $M$.
 \idg{c} Empirical risk $C_\text{test}$-$C_\text{test}$ against  $L$ for different $M$.
	}
	\label{fig:risk}
\end{figure*}



In Fig.~\ref{fig:singleRisk} we study  generalization and empirical risk for $U_{XY}$ ansatz and symmetric data $W_{p=1}$. In Fig.~\ref{fig:singleRisk}a,b we see that $C_\text{train}$ and $C_\text{test}$ decreases with $M$, and reaches near-zero for $M\ge M_\text{c}$.
In Fig.~\ref{fig:singleRisk}c we plot the empirical risk $C_\text{test}-C_\text{train}$ against $M$. We find that the empirical risk first increases, then decreases with $M$. We also note that the empirical risk increases with $N$.


\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.28\textwidth]{a}{SingleParameterTrain.pdf}
\subfigimg[width=0.28\textwidth]{b}{SingleParameterTest.pdf}
\subfigimg[width=0.28\textwidth]{c}{SingleParameterRisk.pdf}
	\caption{Learning with $U_{XY}$ and $\ket{\psi_\ell}\in W_{p=1}$ with fixed overcomplete data $L=40\gg L_\text{c}$ for $N=16$.
 \idg{a} $C_\text{train}$ against $M$ for different $N$, where $M_\text{c}=N^2-1=255$.
 \idg{b} $C_\text{test}$ against $M$ for different $N$. 
 \idg{c} Empirical risk $C_\text{test}-C_\text{train}$ against $M$.
	}
	\label{fig:singleRisk}
\end{figure*}





\section{Training of XY model}\label{sec:trainXY}
We now show additional numerical results on training with the $U_{XY}$ ansatz and symmetric data $W_{p=1}$. 

In Fig.~\ref{fig:singleN}a, we study generalization in the overparameterized regime. We find $C_\text{test}\sim 1-(L/L_\text{c})^2$ independent of $N$.

In Fig.~\ref{fig:singleN}b we study 
the steps $E$ needed to converge against $M$ for different $N$ for overcomplete data $L\gg L_\text{c}$. We observe $E\sim N^2$. At $M_\text{c}$ the steps needed to converge sharply decreases, indicating the transition to an  optimization landscape where the global minimum can be reached easily.
\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.28\textwidth]{a}{SingleCostTestN.pdf}
\subfigimg[width=0.28\textwidth]{b}{SingleParameterIterations.pdf}
	\caption{Learning with $U_{XY}$ and $\ket{\psi_\ell}\in W_{p=1}$.
 \idg{a}~Test error $C_\text{test}$ relative to error without training $C_\text{test}^0$ for varying training set size $L$ and $M\gg M_\text{c}$. We find $C_\text{test}/C_\text{test}^0=1- (L/L_\text{c})^2$, where $L_\text{c}=N$ and we average over 10 random instances.
 \idg{b}~Training steps $E$ required to find $C_\text{test}<10^{-3}$. 
	}
	\label{fig:singleN}
\end{figure*}





Fig.~\ref{fig:single2d}, we show two-dimensional plots of $C_\text{train}$, $C_\text{test}$ and number of iterations $E$ against $L$ and $M$. We find training and test error matches closely the transitions derived from $R_L$ which are shown as black dashed lines.
\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.24\textwidth]{a}{SingleCostTrain2D.pdf}
\subfigimg[width=0.24\textwidth]{b}{SingleCostTest2D.pdf}
\subfigimg[width=0.24\textwidth]{c}{SingleIterations2D.pdf}
	\caption{Mean error for training $U_{XY}$ for symmetric data $W_{p=1}$ for $N=16$ qubits.
 \idg{a} $C_\text{train}$ against $M$ and $L$. Color shows logarithm $\log_{10}(C_\text{train})$.
 \idg{b} $C_\text{test}$ against $M$ and $L$.
 \idg{c} Number of training steps $E$ until reaching $C_\text{train}< 10^{-3}$.
	}
	\label{fig:single2d}
\end{figure*}

Next, we show the $U_{XY}$ ansatz where we learn with random product states $W_{\text{prod}}$ in Fig.\ref{fig:XYprod2d}. Here, we generalize already for $L\ge2$. In Fig.\ref{fig:XYprod2d}d, we show out-of-distribution generalization, where we train with $W_{\text{prod}}$, but test with $W_{p=1}$. We find the same test error as when testing with $W_{\text{prod}}$.
\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.24\textwidth]{a}{productXYtrain2d.pdf}
\subfigimg[width=0.24\textwidth]{b}{productXYtest2d.pdf}
\subfigimg[width=0.24\textwidth]{c}{productXYiterations2d.pdf}
\subfigimg[width=0.24\textwidth]{d}{productXYtestOutOfDistSingle.pdf}
	\caption{Mean error for training $U_{XY}$ ansatz for random product state data sampled from $W_\text{prod}$ and $N=6$ qubits.
 \idg{a} $C_\text{train}$ against $M$ and $L$. Color shows logarithm $\log_{10}(C_\text{train})$.
 \idg{b} $C_\text{test}$ against $M$ and $L$ tested against $W_\text{prod}$.
 \idg{c} Number of training steps $E$ until reaching $C_\text{train}< 10^{-3}$.
  \idg{d} Out-of-distribution generalization $C_\text{test}$ against $M$ and $L$ tested against $W_{p=1}$.
	}
	\label{fig:XYprod2d}
\end{figure*}

 


\section{Quantum Fisher information metric}
The Quantum Fisher information metric (QFIM) ~\cite{meyer2021fisher,liu2020quantum} is an essential tool for quantum sensing, parameter estimation and optimization of quantum circuits.
Here, we review the derivation of the QFIM or Fubini-Study metric  $\mathcal{F}$~\cite{cheng2010quantum}.
We have a parameterized quantum state $\ket{\psi(\boldsymbol{\theta})}$.
 We now study the variation
\begin{align*}
&\text{d}s^2=\vert\vert \ket{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}-\ket{\psi(\boldsymbol{\theta})}\vert\vert= \braket{\delta\psi}{\delta\psi}=\\
&\braket{\partial_n \psi}{ \partial_m \psi}\text{d}\boldsymbol{\theta}^n\boldsymbol{\theta}^m=(\gamma_{nm}+i\sigma_{nm})\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m
\end{align*}
where we defined the real and imaginary part  $\gamma_{nm}$ and $\sigma_{nm}$ of $\braket{\partial_n \psi}{ \partial_m \psi}$. As $\text{d}s^2$ is hermitian, we have $\gamma_{nm}=\gamma_{mn}$ and $\sigma_{nm}=-\sigma_{mn}$, such that $\sigma_{nm}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m$ vanishes. However, $\gamma_{nm}$ is not a proper metric as it is not invariant under the gauge transformation $\ket{\psi'}=\exp(i\alpha)\ket{\psi}$ under a global phase rotation with $\alpha$. We now construct a proper gauge invariant metric.

First, one can easily show by using $\braket{\psi}{\psi}=1$ that $\beta_n=i\braket{\psi}{ \partial_n \psi}\in\mathbb{R}$. 
Next, we compute $\braket{\psi'}{\psi'}=\gamma_{nm}'+i\sigma_{nm}'$, where a straightforward calculation yields
\begin{equation}
\gamma_{nm}'=\gamma_{nm}+\partial_n\alpha\partial_m\alpha-\beta_m\gamma_n\alpha-\beta_n\gamma_m
\end{equation}
and $\sigma_{nm}'=\sigma_{nm}$.
From this result, we now define a gauge-invariant metric
\begin{equation}
g_{nm}=\gamma_{nm}-\beta_n\beta_m
\end{equation}
where one can easily confirm $g_{nm}'=g_{nm}$ by using $\beta_n'=\beta_n-\partial_n\alpha$.
We can think of $\gamma_{nm}$ measuring the change of $\ket{\psi(\boldsymbol{\theta})}$ in the Hilbertspace, while $g_{nm}$ measures its change excluding global phases which have no observable effect.

The quantum geometric tensor is defined as
\begin{equation}
\Xi_{nm}=\braket{\partial_n \psi}{ \partial_m \psi}-\braket{\partial_n\psi}{\psi}\braket{\psi}{\partial_m\psi}
\end{equation}
and the QFIM as $\mathcal{F}_{nm}=\text{Re}(\Xi_{nm})$, which corresponds to the real part of $g_{nm}$.



The QFIM describes the change in fidelity for $\vert\braket{\psi(\boldsymbol{\theta})}{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}\vert^2$ as we will see in the following.
First, note that $\braket{\psi}{\partial_n\psi}\in\text{Im}$. Thus, its derivative must be also imaginary, i.e. $\braket{\psi}{\partial_n\partial_m\psi}+\braket{\partial_m\psi}{\partial_n\psi}\in\text{Im}$, which immediately implies 
\begin{equation}\label{eq:helpU_fub}
\braket{\psi}{\partial_n\partial_m\psi}=-\braket{\partial_m\psi}{\partial_n\psi}\,.
\end{equation}
Now, we find via Taylor expansion
\begin{align*}
&\braket{\psi(\boldsymbol{\theta})}{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}\approx\numberthis\label{eq:Taylor_fub}\\
&1+i\braket{\psi}{\partial_n\psi}\text{d}\boldsymbol{\theta}^n
+\frac{1}{2}\braket{\psi}{\partial_n\partial_m\psi}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m=\\
&1+i\braket{\psi}{\partial_n\psi}\text{d}\boldsymbol{\theta}^n
-\frac{1}{2}\braket{\partial_n\psi}{\partial_m\psi}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m
\end{align*}
Now, we compute using~\eqref{eq:Taylor_fub}
\begin{align*}
&\vert\braket{\psi(\boldsymbol{\theta})}{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}\vert^2=\\
&\braket{\psi(\boldsymbol{\theta})}{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}\braket{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}{\psi(\boldsymbol{\theta})}\approx\\
&1-[\braket{\partial_n\psi}{\psi}\braket{\psi}{\partial_m\psi}\\
&+\frac{1}{2}\braket{\partial_n\psi}{\partial_m\psi}+\frac{1}{2}\braket{\partial_m\psi}{\partial_n\psi}]\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m=\\
&1-\text{Re}[\braket{\partial_n\psi}{\partial_m\psi}-\braket{\partial_n\psi}{\psi}\braket{\psi}{\partial_m\psi}]\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m.
\end{align*}
where in the second step we used \eqref{eq:helpU_fub}.
Finally, we have
\begin{equation}
\vert\braket{\psi(\boldsymbol{\theta})}{\psi(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})}\vert^2=1-\frac{1}{4}\mathcal{F}_{nm}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m\,.
\end{equation}
This implies that $\mathcal{F}$ is a metric that describes the change in state space under a variation in parameter $\boldsymbol{\theta}$.

\section{Data quantum Fisher information metric}\label{sec:dQFIM}

We now generalize the QFIM to the DQFIM, which describes learning $U$ with training states. We have a training set $S_L=\{\ket{\psi_{\ell}},V\ket{\psi_{\ell}}\}_{\ell=1}^L$ and an ansatz $U(\theta)$.
We learn using the cost function
$C=1-L^{-1}\sum_{\ell=1}^L \vert\bra{\psi_{\ell}}V^\dagger U(\theta)\ket{\psi_{\ell}}\vert^2$. 
Let us recall the projector onto the training data projector 
$\Pi_L=\sum_{k=1}^{B_L}\ket{\phi_k}\bra{\phi_k}$ and its normalization
$\tilde{\Pi}_L=\Pi_L/B_L$
where $\ket{\phi_k}$ are the eigenvectors with non-zero eigenvalue of $\rho_L=L^{-1}\sum_{\ell=1}^L\ket{\psi_{\ell}}\bra{\psi_{\ell}}$ and $B_L=\mathrm{rank}(\rho_L)$.




We now derive the DQFIM~\eqref{eq:Fisher_sup} from a variational principle in a similar manner as the QFIM. 
The variation of isometry $U(\theta)\Pi_L/\beta$ with normalization factor $\beta=\sqrt{\text{tr}(\Pi_L)}$ is given by 
\begin{align*}
&\text{d}s^2=\vert\vert (U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})-U(\boldsymbol{\theta}))\Pi_L/\beta\vert\vert=\text{tr}(\delta U^\dagger\tilde{\Pi}_L\delta U)=\\
&\text{tr}(\partial_n U^\dagger \tilde{\Pi}_L\partial_m U)\text{d}\boldsymbol{\theta}^n\boldsymbol{\theta}^m=(\gamma_{nm}+i\sigma_{nm})\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m\,,
\end{align*}
where we have the difference $\delta U=U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})-U(\boldsymbol{\theta})$, the square of the Frobenius norm $\vert\vert A\vert\vert=\text{tr}(A^\dagger A)$, the real and imaginary part  $\gamma_{nm}$ and $\sigma_{nm}$ of $\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L \partial_m U)$, and $\tilde{\Pi}_L=\Pi_L/\text{tr}(\Pi_L)$.
Note that we have $\text{tr}(U^\dagger \tilde{\Pi}_L U)=1$. One can now immediately check that one recovers the regular QFIM for $\rho_1=\ket{\psi}\bra{\psi}$.
 As $\text{d}s^2$ is hermitian, we have $\gamma_{nm}=\gamma_{mn}$ and $\sigma_{nm}=-\sigma_{mn}$, such that $\sigma_{nm}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m$ vanishes. However, $\gamma_{nm}$ is not a proper metric as it is not invariant under the gauge transformation $U'=\exp(i\alpha)U$, i.e. a global phase rotation with $\alpha$. We now construct a proper gauge invariant metric.

First, we apply $\partial_n$ to $\text{tr}(U^\dagger\tilde{\Pi}_L U)=1$ and see that $\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)+\text{tr}(U^\dagger\tilde{\Pi}_L \partial_n U)=0$. It follows that $\text{tr}(U^\dagger\tilde{\Pi}_L \partial_n U)+\text{tr}(U^\dagger\tilde{\Pi}_L \partial_n U)^\dagger=0$ and thus  $\beta_n=i\text{tr}(U^\dagger\tilde{\Pi}_L\partial_n U)\in\mathbb{R}$. 
Next, we compute $\text{tr}({U'}^\dagger \tilde{\Pi}_L U')=\gamma_{nm}'+i\sigma_{nm}'$, where a straightforward calculation yields
\begin{equation}
\gamma_{nm}'=\gamma_{nm}+\partial_n\alpha\partial_m\alpha-\beta_m\gamma_n\alpha-\beta_n\gamma_m
\end{equation}
and $\sigma_{nm}'=\sigma_{nm}$.
From this result, we now define a gauge-invariant metric
\begin{equation}
g_{nm}=\gamma_{nm}-\beta_n\beta_m
\end{equation}
where one can easily confirm $g_{nm}'=g_{nm}$ by using $\beta_n'=\beta_n-\partial_n\alpha$.
We can think of $\gamma_{nm}$ measuring the change of $U(\boldsymbol{\theta})$ in the full Hilbertspace, while $g_{nm}$ measures the change excluding global phases which have no observable effect.

In analogy to the quantum geometric tensor, we define the data quantum geometric tensor 
\begin{equation}
\Xi_{nm}=\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L \partial_m U)-\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\text{tr}(U^\dagger \tilde{\Pi}_L\partial_m U)
\end{equation}
and the DQFIM as $\mathcal{Q}_{nm}=\text{Re}(\Xi_{nm})$, which corresponds to the real part of $g_{nm}$, with
\begin{align*}
&\mathcal{Q}_{nm}(S_L,U(\boldsymbol{\theta}))=
4\text{Re}(\text{tr}(\partial_n U^\dagger \tilde{\Pi}_L \partial_m U)-\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\text{tr}(U^\dagger \tilde{\Pi}_L\partial_m U))\,.\numberthis\label{eq:Fisher_sup}
\end{align*}
Indeed, we find for $L=1$ that $\mathcal{Q}(S_1)=\mathcal{F}$. In contrast, for a training set with $\Pi_L=I$, we find what we call the unitary QFIM
\begin{align*}
&\mathcal{Q}_{nm}^I=
4\text{Re}(d^{-1}\text{tr}(\partial_n U^\dagger \partial_m U)-d^{-2}\text{tr}(\partial_n U^\dagger U)\text{tr}(U^\dagger \partial_m U))\,.\numberthis\label{eq:Fisher_unitary}
\end{align*}
The DQFIM describes the change of $\vert\text{tr}(U(\boldsymbol{\theta})^\dagger \tilde{\Pi}_L U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta}))\vert^2$ which we are going to show in the following.
First, note that $\text{tr}(U^\dagger\tilde{\Pi}_L\partial_n U)\in\text{Im}$. Thus, its derivative must be also imaginary, i.e. $\text{tr}(U^\dagger\tilde{\Pi}_L\partial_n\partial_m U)+\text{tr}(\partial_nU^\dagger\tilde{\Pi}_L\partial_m U)\in\text{Im}$, which immediately implies 
\begin{equation}\label{eq:helpU}
\text{tr}(U^\dagger\tilde{\Pi}_L\partial_n\partial_m U)=-\text{tr}(\partial_nU^\dagger\tilde{\Pi}_L\partial_m U)\,.
\end{equation}
Now, we find via Taylor expansion
\begin{align*}
&\text{tr}(U(\boldsymbol{\theta})^\dagger \rho_L U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta}))\approx\numberthis\label{eq:Taylor}\\
&1+i\text{tr}( U^\dagger \tilde{\Pi}_L\partial_n U)\text{d}\boldsymbol{\theta}^n
+\frac{1}{2}\text{tr}(U^\dagger\tilde{\Pi}_L \partial_n\partial_m U)\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m=\\
&1+i\text{tr}( U^\dagger\tilde{\Pi}_L \partial_n U)\text{d}\boldsymbol{\theta}^n
-\frac{1}{2}\text{tr}(\partial_nU^\dagger\tilde{\Pi}_L \partial_m U)\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m
\end{align*}
Now, we compute using~\eqref{eq:Taylor}
\begin{align*}
&\vert\text{tr}(U(\boldsymbol{\theta})^\dagger \tilde{\Pi}_L U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta}))\vert^2=\\
&\text{tr}(U(\boldsymbol{\theta})^\dagger \tilde{\Pi}_L U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta}))\text{tr}(U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta})^\dagger U(\boldsymbol{\theta}))\approx\\
&1-[\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\text{tr}( U^\dagger\tilde{\Pi}_L \partial_mU)\\
&+\frac{1}{2}\text{tr}(\partial_nU^\dagger \tilde{\Pi}_L\partial_m U)+\frac{1}{2}\text{tr}(\partial_m U^\dagger\tilde{\Pi}_L  \partial_n U)]\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m=\\
&1-\text{Re}[\text{tr}(\partial_nU^\dagger\tilde{\Pi}_L \partial_m U)-\\
&\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\text{tr}(U^\dagger \partial_m\tilde{\Pi}_L U)]\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m.
\end{align*}
where in the second step we used \eqref{eq:helpU}.
Finally, we have
\begin{equation}
\vert\text{tr}(U(\boldsymbol{\theta})^\dagger \tilde{\Pi}_L U(\boldsymbol{\theta}+\text{d}\boldsymbol{\theta}))\vert^2=1-\frac{1}{4}\mathcal{Q}_{nm}\text{d}\boldsymbol{\theta}^n\text{d}\boldsymbol{\theta}^m\,,
\end{equation}
which relates a change in parameter $\boldsymbol{\theta}$ to the change in the unitary projected onto the training states.






\section{Degrees of freedom of isometries}\label{sec:RLexact}
Now, we calculate the degrees of freedom when learning a training set of $L$ states with a $d$-dimensional unitary 
\begin{equation}\label{eq:U_arb}
U=\sum_{n,k=1}^d u_{nk}\ket{n}\bra{k}
\end{equation}
with $u_{nk}=a_{nk}+ib_{nk}$, where $a_{nk}$, $b_{nk}$ are real parameters. 
First, note that $U$ can be described using $2d^2$ real parameters, however due to $U^\dagger U=I$ and global phase, only $d^2-1$ real parameters are independent. 
We now compute the maximal number of degrees of freedom when $U$ is projected onto a training set of $L$ states. For any set $S_L$ of training states, the rank of the projector $\Pi_L$ is upper bounded by $\text{rank}(\Pi_L)\le L$.


We apply $U$~\eqref{eq:U_arb} on a training set $\{\ket{\ell}\}_{\ell=1}^L$ of $L$ states, where $\ket{\ell}$ are computational basis states. 
For a single training state $L=1$, we have $U\ket{1}=\sum_{n=1}^d u_{n1}\ket{n}$. Via training, we can only learn the column vector $u_1=(u_{11},u_{21},\dots,u_{d1})$, which has $2d$ real parameters and $2d-2$ independent parameters due to constraints of global phase and norm $\sum_{n=1}^d\vert u_{n1}\vert^2=1$. However, all other column vectors besides $u_1$ cannot be learned.
With the DQFIM we find $R_1=2d-2$, i.e. $R_1$ indeed counts the number of degrees of freedom that can be learned.
Next, we consider $L=2$. Here, we additional have the state $U\ket{2}=\sum_{n=1}^d u_{n2}\ket{n}$ and we can also learn the vector $u_2=(u_{12},u_{22},\dots,u_{d2})$ with $2d$ real parameters. 
However, due to unitarity, $u_2$ must be orthogonal to $u_1$, which removes two degrees of freedom. Additionally, we have to subtract one parameter for the norm condition. The global phase has already been incorporated in $u_1$, thus $u_2$ holds $2d-3$ degrees of freedom, with the $d\times 2$-dimensional isometry $(u_1,u_2)$ combined having $R_2=4d-5$. 
For any $L$, each additional training state adds a column $u_L$,  which has additional $2d-2L+1$ degrees of freedom due to $L-1$ orthogonality conditions~\cite{polcari2016representing}. For $L$ states, we have the isometry $U_L=(u_1,\dots, u_L)$, which can be described using 
\begin{equation}
    R_L=(2d-2)L-(L-1)^2=2dL-L^2-1
\end{equation}
real independent parameters and for $L\ge1$.
The maximum is reached for $L_\text{c}=d$ with $R_d=d^2-1$ and $U\Pi_d=U$ with $\Pi_d=I$, where we can completely learn $U$. For further increase in $L$ we find that $R_L$ stays constant. As our choice of $U$ is a generic representation of a unitary and our chosen training set has maximal rank $\text{rank}(\Pi_L)=L$, our calculation gives us the upper bound for $R_L$. 
Note that by choosing a more constrained ansatz unitary and training sets $R_L$ can be smaller.

For an arbitrary unitary, the gain in effective dimension by increasing dataset size $L\rightarrow L+1$ is given by $\Delta R_L=R_{L+1}-R_L=\text{max}(2d-2L-1,0)$ for $L\ge1$, and $\Delta R_0=2d-2$ for $L=0$. Thus, the gain decreases with $L$, i.e. with increasing $L$ each additional state reveals less degrees of information of $U$.




\section{Lie-algebra bounds DQFIM}\label{sec:liebound}

Recall that our ansatz~\eqref{eq:ansatz_sup} consist of $G$ layers with 
\begin{equation}\label{eq:ansatzGen}
    U(\boldsymbol{\theta})=\prod_{k=1}^G U_k(\boldsymbol{\theta}_k)\,\,\text{with}\,\, U^{(k)}(\theta_k)=\prod_{n=1}^K\exp(-i\theta_{kn} H_n)
\end{equation}
where $U^{(k)}(\theta_k)$ is the unitary of the $k$th layer. Here, $H_n$ are $K$ hermitian matrices and $\boldsymbol{\theta}_k=\{\theta_{k1},\dots,\theta_{kn}\}$ are the parameters of the $k$th layer. The total parameter vector $\theta=\{\boldsymbol{\theta}_1,\dots,\boldsymbol{\theta}_G\}$ of the ansatz has $M=GK$ parameters. 

To simplify the notation, we treat each parameter entry as its own layer and relabel each generators $H_k$ such that we can write the ansatz as
\begin{equation}\label{eq:ansatzdla}
U(\boldsymbol{\theta})=\prod_{k=1}^M\exp(-i\theta_{k} H_k)\,.
\end{equation}
First, we define the generators of the ansatz $U$~\cite{d2021introduction,larocca2021theory}:
\begin{defn}[Set of generators $\mathcal{T}$]\label{def:generators}
Consider ansatz~\eqref{eq:ansatzdla}. The set of generators $\mathcal{T}=\{H_k\}_{k=1}^K$ (with size $|\mathcal{T}|=K$) are defined as the set of Hermitian operators that generate the unitaries of each layer of $U(\boldsymbol{\theta})$.
\end{defn}
Further the dynamical Lie Algebra $\mathfrak{g}$ is given by:
\begin{defn}[Dynamical Lie Algebra (DLA)]\label{def:dynamical_lie_algebra-SM}
Consider the generators $\mathcal{T}$ according to Def.~\ref{def:generators}. The DLA $\mathfrak{g}$ is generated by repeated nested commutators of the operators in $\mathcal{T}$
\begin{equation}
\mathfrak{g}=\mathrm{span}\left\langle iH_1, \ldots, iH_K \right\rangle_\text{Lie}\,,
\end{equation}
where $\left\langle \mathcal{S}\right\rangle_\text{Lie}$ is the Lie closure, which is the set obtained by repeatedly taking the commutator of the elements in $\mathcal{S}$. 
\end{defn}


Next, we show that the DLA bounds the rank of the DQFIM.
First, lets recall the entries of the matrix of the DQFIM
\begin{align*}
&\mathcal{Q}_{nm}(S_L,U(\boldsymbol{\theta}))=4\text{Re}(\text{tr}(\partial_n U^\dagger \tilde{\Pi}_L \partial_m U)-\text{tr}(\partial_n U^\dagger\tilde{\Pi}_L U)\text{tr}(U^\dagger \tilde{\Pi}_L\partial_m U))\,.\numberthis\label{eq:Fisher_supdla}
\end{align*}
where we shorten $U=U(\boldsymbol{\theta})$, $\tilde{\Pi}_L=\Pi_L/\text{rank}(\Pi_L)$ is the normalized projector onto the space spanned by the training states and $\partial_n U$ the derivative in respect to the $n$th element of parameter vector $\boldsymbol{\theta}$.




We now restate Theorem~\ref{th:liebound} for convenience.
\begin{theorem}\label{th:liebound_sup}
    The maximal rank $R_L$ of the DQFIM  is upper bounded by the dimension of the dynamical Lie algebra (DLA) $\dim(\mathfrak{g})$
    \begin{equation}
    R_L\leq\dim(\mathfrak{g})\,,
    \end{equation}
    where $\mathfrak{g}=\mathrm{span}\left\langle iH_1, \ldots, iH_K \right\rangle_\text{Lie}$ is generated by the repeated nested commutators of the generators $H_k$ of the unitary $U(\boldsymbol{\theta})$.
\end{theorem}
The proof follows in analogy to the bound of the QFIM (i.e. $R_1$) of Ref.~\cite{larocca2021theory}.

First, we note that $R_L\le R_\infty$ as $L$ simply increases the dimension of the projector $\Pi_L$. Now, we assume $S_L$ spans the complete relevant Hilbertspace with $\Pi_L=I$ and thus we can simplify to the unitary QFIM
\begin{align*}
&\mathcal{Q}_{nm}=4\text{Re}(d^{-1}\text{tr}(\partial_n U^\dagger \partial_m U)-d^{-2}\text{tr}(\partial_n U^\dagger U)\text{tr}(U^\dagger\partial_m U))\,.\numberthis\label{eq:Fisher_supdlaUp}
\end{align*}
As we have $\partial_n \exp(-i\theta_n H_n)= -iH_n\exp(-i\theta_n H_n)$, we can write the derivatives as 
\begin{equation}
\partial_n U(\boldsymbol{\theta})=-iU_{n+1\rightarrow M}H_nU_{1\rightarrow n}\,.
\end{equation}
Here, we define  
\begin{equation}U_{m\rightarrow n}=U_n U_{n-1} \dots U_{m+1}U_m
\end{equation}
as the propagator from layer $m$ to layer $n$ and
\begin{equation}
    \tilde{H}_k=U_{1\rightarrow k}^\dagger H_k U_{1\rightarrow k}\,.
\end{equation}


Using above expressions, we find for the first term of the DQFIM~\eqref{eq:Fisher_supdla} 
\begin{align*}
    &\text{Re}(\text{tr}(\partial_n U^\dagger \partial_m U) =
    \text{Re}( i(-i)\text{tr}(U_{1\rightarrow n}^\dagger H_nU_{n+1\rightarrow M}^\dagger U_{m+1\rightarrow M}H_mU_{1\rightarrow m}))=
    \text{Re}(\text{tr}(\tilde{H}_n\tilde{H}_m))\,.
 \end{align*}
Similarly, we find for the second term of~\eqref{eq:Fisher_supdla} 
\begin{align*}
    &\text{Re}(\text{tr}(\partial_n U^\dagger U)\text{tr}(U^\dagger \tilde{\Pi}_L\partial_m U))=
    \text{Re}(i(-i)\text{tr}(U_{1\rightarrow n}^\dagger H_nU_{n+1\rightarrow M}^\dagger U_{1\rightarrow M})\cdot\\
    &\text{tr}(U_{1\rightarrow M}^\dagger U_{m+1\rightarrow M}H_mU_{1\rightarrow m}))=
     \text{Re}(\text{tr}(\tilde{H}_n)\text{tr}(\tilde{H}_m))\,.
\end{align*}


We combine these results to get the DQFIM as
\begin{equation}\label{eq:tildeQFIM}
\begin{split}
   \mathcal{Q}_{mn}^I=\text{Re}(d^{-1}\text{tr}(\tilde{H}_n\tilde{H}_m)-d^{-2}\text{tr}(\tilde{H}_n)\text{tr}(\tilde{H}_m))
\end{split}
\end{equation}
Note that $H_k$ are elements of the DLA $\mathfrak{g}$. As the unitaries $U_n$ of the ansatz are also elements of the dynamical Lie group generated by $\mathfrak{g}$, a product of $H_k$ with any $U_n$ will yield another element of the dynamical Lie group.
Thus, we can always expand $\tilde{H}_k$ using the DLA as a basis with $\text{dim}(\mathfrak{g})$ elements:
\begin{equation}
    \tilde{H_k} = \sum_{m=1}^{\text{dim}(\mathfrak{g})}  a_{m}^{(k)} \chi_m\,,
\end{equation}
where $a_{m}^{(k)}$ are real coefficients and $\{\chi_m\}_{m=1}^{\text{dim}(\mathfrak{g})}$ are a basis of the DLA $\mathfrak{g}$. 
Thus, the matrix of the DQFIM $\mathcal{Q}$ can be expressed in a basis with $\text{dim}(\mathfrak{g})$ elements. Thus, the rank of $\mathcal{Q}$ is upper bounded by the dimension of the DLA $\mathfrak{g}$
\begin{equation}
    R_L\le\text{rank}(\mathcal{Q}^I)\le \text{dim}(\mathfrak{g})\,.
\end{equation}








\section{Ansatz unitaries for SM}\label{sec:ansatz_sup}
Next, in Fig.\ref{fig:ansatze_sup} we show additional ansatz unitaries which are considered in the next sections of the SM. 


\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.9\textwidth]{}{SketchLearningCircuitsSup.pdf}\hfill
	\caption{ Ansatz unitaries  for the the supplemental materials. The circuits are repeated for $G$ layers. 
 \idg{a} $U_{XY}^{\text{open}}$ circuit with open boundary condition, i.e. the $\sqrt{\text{iSWAP}}$ do not cross from the first to the last qubit in contrast to $U_{XY}$. Commutes with particle number operator $P$ and for sufficient depth can realize any time evolution generated by $\exp(-iH_{XY}^{\text{open}} t)$.
 \idg{b} $U_{XXZ}$ circuit related to evolution of Heisenberg model $H_{XXZ}$.
 Composed of parameterized single qubit $z$ rotations and the $\sqrt{\text{iSWAP}}z$ gate defined in the text.
 \idg{c} Real-valued ansatz $U_\text{Y-CZ}$ consisting of $y$-rotations and control-$Z$ gates in a nearest-neighbor chain configuration. 
	}
	\label{fig:ansatze_sup}
\end{figure*}

In Fig.\ref{fig:ansatze_sup}a we show the $U_{XY}^\text{open}$ circuit, which is the same as the $U_{XY}$ circuit but with open boundary conditions, i.e. the $\sqrt{\text{iSWAP}}$ gates that interact between the first and last qubit are removed. This ansatz conserves particle number $P$.



In Fig.\ref{fig:ansatze_sup}b we show the $U_{XXZ}$ ansatz, which is composed of parameterized $z$ rotations and the $\sqrt{\text{iSWAP}}z=\sqrt{\text{CZ}}\sqrt{\text{iSWAP}}$ gate, where $\sqrt{\text{CZ}}=\text{diag}(1,1,1,i)$ is the square-root of the control-$Z$ gate. This ansatz conserves particle number $P$. 


In Fig.\ref{fig:ansatze_sup}c we show the $U_{Y-CZ}$ ansatz~\cite{haug2021capacity}, consisting of parameterized $y$-rotations and control-$Z$ gate $\text{diag}(1,1,1,-1)$. Due to its connection to Cluster-state generation, it overparameterizes with a polynomial number of parameters with $R_L\propto N^2$.





\section{Generalization with further models}\label{sec:training_gen}
Here, we study the number of training states needed for generalization for further models.

First, in Fig.\ref{fig:test_models}a we study the $U_{XY}^\text{open}$ ansatz shown in Fig.\ref{fig:ansatze_sup}a. This ansatz describes the evolution of the $H_{XY}^\text{open}=\sum_{k=1}^N h_k \sigma_k^z +\sum_{k=1}^{N-1}( \sigma_k^x\sigma_{k+1}^x+\sigma_k^y\sigma_{k+1}^y)$ Hamiltonian with open boundary conditions. The difference to $H_{XY}$ is the absence of interaction between first and last qubit. We find generalization for $L=1$ training states and $M\ge M_\text{c}$ when using random product states as training data.
A similar ansatz was studied numerically in Ref.~\cite{gibbs2022dynamical}. It was shown numerically that only $1$ training state was needed for generalization, and $O(N^2)$ gates for successful training. 
Here, we explain this result with the DQFIM. In particular, our ansatz has the maximal rank of the DQFIM with $R_L=R_1=R_\infty=N^2$ for all $N$. This implies that $L_\text{c}=1$ training state is sufficient to get an overcomplete model and achieve generalization.


\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.28\textwidth]{a}{TestXYOpen.pdf}
\subfigimg[width=0.28\textwidth]{b}{TestHeisenberg.pdf}
	\caption{\idg{a} Test error $C_\text{test}$ for $U_{XY}^\text{open}$ ansatz and for $L=1$ product training states against circuit parameters $M$. $C_\text{test}$ is averaged over 20 random instances. $M_\text{c}$ is determined with the DQFIM. 
 \idg{b}  $C_\text{test}$ for $U_{XZZ}$ ansatz for product training states against $L$ for $N=4$ and $M=100$.  
	}
	\label{fig:test_models}
\end{figure*}

Next, we study the $U_{XXZ}$ ansatz shown in Fig.\ref{fig:ansatze_sup}b. This model can describes the evolution of the $H_{XXZ}=\sum_{k=1}^N h_k \sigma_k^z +\sum_{k=1}^N( \sigma_k^x\sigma_{k+1}^x+\sigma_k^y\sigma_{k+1}^y+\Delta \sigma_k^z\sigma_{k+1}^z)$ Hamiltonian. A similar ansatz was studied in Ref.~\cite{gibbs2022dynamical}. It was numerically shown that $5$ training states are needed for generalization for $N=4$. In Fig.\ref{fig:test_models}b, we show the test error of the $U_{XXZ}$ ansatz against $L$ in the overparameterized regime and indeed find the test error vanishes for $L\ge5$.
Using the DQFIM, we find $R_1=24$ and $R_\infty=R_{L_\text{c}}=51$ with  $L_\text{c}=5$, matching the numerical results. 
Thus, the DQFIM accurately predicts the needed training states.
Note that the approximation $L_\text{c}\approx 2R_\infty/R_1=4.25$ gives a good estimation of the number of needed training states as well.


\section{Training of Y-CZ model}\label{sec:cphase}
We show numerical results on training with the $U_\text{Y-CZ}$ ansatz (see Fig.~\ref{fig:ansatze_sup}c for definition) in Fig.~\ref{fig:cphase2d}. This model requires $L=2$ states to generalize as we have $R_L\sim N^2$. We find training and test error matches closely the transitions derived from $R_L$ shown as black dashed lines.
\begin{figure*}[htbp]
	\centering	
\subfigimg[width=0.24\textwidth]{a}{CphaseTrain2d.pdf}
\subfigimg[width=0.24\textwidth]{b}{CphaseTest2d.pdf}
\subfigimg[width=0.24\textwidth]{c}{CphaseIterations2d.pdf}
	\caption{Mean error for training $U_\text{Y-CZ}$ for product state as training data and $N=6$ qubits.
 \idg{a} $C_\text{train}$ against $M$ and $L$.  Color shows logarithm $\log_{10}(C_\text{train})$.
 \idg{b} $C_\text{test}$ against $M$ and $L$.
 \idg{c} Number of training steps $E$ until reaching $C_\text{train}< 10^{-3}$.
	}
	\label{fig:cphase2d}
\end{figure*}



\end{document}
