\section{Use Cases for Ecosystem Graphs}
\label{sec:uses}
To demonstrate the value of \EG, we enumerate social roles to explain their concrete informational needs and fundamental questions that \EG addresses.
\EG may be insufficient to fully meet their demand, but we highlight how it makes progress: is a minimum transparency standard and unifying abstraction across diverse use cases.

\paragraph{Foundation model developers.}
FM developers need to be aware of the available assets they can build upon (\eg new instruction-tuning datasets like P3), the assets they will compete with (\eg new releases from competitors), and current/foreseeable demand from downstream application developers.
Each of these informational needs are directly addressed from the ecosystem graph.
In fact, at a more fine-grained level, the ecosystem graph allows developers to compare their practices with their competitors.
For example, developer A may come to realize that developer B implements a more robust quality control pipeline.
While developers likely already track this information themselves about their competitors, centralized information could inform more intentional decisions in choosing to either conform to or diverge from the practices of other developers \citep[\eg norms on release;][]{liang2022community-norms}.

\paragraph{Application developers.}
Akin to foundation model developers, downstream application developers also should be aware of the full space of foundation models in choosing which foundation model to build upon (or investing to build foundation models themselves).
However, the graph structure provides further clarity, since implicitly it indicates which foundation models are more popular (perhaps because they are easier or preferable to build upon). 
This signal is complementary to other signals \citep[\eg comparing models on standardized evaluations like HELM;][]{liang2022helm}, because application developers can make decisions informed by prior developer choices.
For example, several organizations (\ie OpenAI, Cohere, Anthropic) currently offer similar language model API offerings but they have been differentially adopted by downstream developers. 
% \pl{moreover, this provides links to HELM}
We could imagine that a new copywriting startup might find this information illuminating in making decisions on which API to use: (i) if they use the same API as their competitors, how will they distinguish themselves, or (ii) if they use a different API, why is it better for them given their competitor chose to use a different one. 
In fact, metadata in the ecosystem card could be composed to further constrain the search space: for example, one could look for a permissively-licensed available model that has been evaluated on relevant benchmarks (by filtering on the "license", "access", and "analysis" properties).

\paragraph{End users of FM applications.}
Consumers deserve to know how the technology they use was built, akin to requirements that require food in the US be labeled with ingredients.\footnote{\url{https://www.fda.gov/food/food-ingredients-packaging/}}
The graph structure and the simple web interface make this practical: a user can look up the product, see if it is in the graph, and trace its dependencies.
This process surfaces any existing mechanisms for feedback reporting, which could prove to be useful if the user experiences an issue.
While the existing documentation is quite scarce, the user would also be able to find any existing documentation of similar issues or failures \citep[see][]{costanzachock2022audits}.
In the future, we imagine this information could become the basis for more formal consumer protections: if a user experiences harm, what are their means for recourse?
Or if they pursue legal action, how might society attribute responsibility to different entities implicated upstream?
Symmetrically, the benefits to end users do not only involve harm mitigation: for example, if a user is able to better understand how their data would be used, they might be more informed and more willing to donate their data to data collection efforts.

\paragraph{Investors.}
Much as developers benefit from \EG in that it better allows them to understand their competitors, investors benefit from \EG in that it identifies new opportunities.
For example, a venture capitalist could sort by "modality" and "created date" to understand modalities on the rise (\eg music) even before high-profile products emerge for this modality.
In turns, this suggests prime candidates for investors to take risk and fund early on the basis of concrete data and trends.
Compared to parallel public efforts in venture capital (\eg market maps documenting the foundation model ecosystem \citep{turow2023madrona} and specific startups \citep{kaufmann2022scaleindex}), \EG provides finer-grained insight by grounding to specific assets rather than institution-level trends.
We revisit the contrast between asset-centric and institution-centric analysis in \autoref{sec:related-work-dependencies}.

\paragraph{AI researchers.}
\EG provides an array of functionalities that are relevant for AI research.
However, one of the most fundamental is the increased potential for AI researchers to be aware of how foundation models are deployed.
As a concrete example, many of the applications of image-based models like Stable Diffusion diverge from what has been traditionally studied in computer vision research.
Perhaps even more clearly, billions have been invested into language-based startups whose applications (\eg copywriting) clearly differ from standard tasks studied in natural language processing (\eg natural language inference).

While academic research should not blindly follow industry trends, we do believe academic research should pay more attention to how research materializes in practice.
\EG precisely provides the opportunity for such reflection. 
Much of AI research concentrates on building better models in many senses (\eg more accurate, efficient, robust, fair):  understanding (i) what is being deployed in society, (ii) the demand for such technology, and (iii) the resulting societal impact all can help AI researchers better achieve their goals.
Similarly, many AI benchmarks are designed such that progress on the benchmark will generalize more broadly: aligning these benchmarks with deployment, or at least measuring correlations between benchmark-induced rankings and deployment-induced rankings, could prove fruitful in realizing this vision.
We specifically highlight this for work on the \textit{harms} of foundation models and AI: understanding how risks posited in the scientific literature \citep[][\textit{inter alia}]{bender2021dangers, weidinger2022taxonomy, bommasani2021opportunities, abid2021persistent, buchanan2021truth} manifest in practice could clarify how these risks should be studied, measured, mitigated, and prioritized. 

\paragraph{Economists.}
Foundation models are general-purpose technologies \citep{bresnahan1995gpt, brynjolfsson2021jcurve} that define an emerging market \citep[][\S5.5]{eloundou2023gpts, bommasani2021opportunities} worthy of study in the (digital) economy \citep{acemoglu2010skills, acemoglu2018race}.
Early work shows that foundation models can complete tasks of significant economic value \citep{noy2023experimental, felten2023chatgpt, korinek2023language}, \ie the \textit{realizable} potential of foundation models. 
\EG naturally complements this work by defining the \textit{realized} impact of foundation models at macro-scale, complementing more grounded analyses such as \citet{peng2023copilot} on developer productivity using GitHub Copilot and \citet{eloundou2023gpts} on labor exposure using GPT-4.
Put together, these works delineate inefficiencies and potential opportunities: where are foundation models not being deployed, despite showing demonstrable potential for these jobs?
More broadly, we believe \EG naturally supports efforts to understand the market structure of AI and the digital economy\citep{brynjolfsson2017ml, acemoglu2020ai, agrawal2021ai, autor2022work}.
How do pre-existing inter-organizational relationships (\eg between Microsoft and Google) interface with the new relationships mediated by the rise of foundation models?

\paragraph{Auditors.}
Auditors need to prioritize assets to allocate attention to \citep[see][]{metaxa2021audit, raji2019actionable}.
To inform these decisions, \EG provides several forms of guidance.
Most directly, auditors can prioritize (i) assets with known reports of "failures", (ii) unsatisfactory "quality control" or "analysis" information and (iii) assets with significant opacity (\ie much is unknown about the node).
Further, auditors should factor in the impact of these nodes: we recommend auditors target \textit{algorithmic monocultures} \citep{kleinberg2021monoculture, bommasani2022homogenization} that are made legible by \EG. 
Namely, if an upstream asset has extensive downstream dependencies (\eg the ChatGPT API as in \reffig{hubs}), then risks associated with this asset may propagate downstream perniciously if unchecked (\eg what if the ChatGPT API goes down?\footnote{See \url{https://status.openai.com/incidents/y6cdztrnth60}.}; what if LAION-400M is subject to data poisoning \citep[][\S4.7]{carlini2023poisoning, bommasani2021opportunities}?).
\citet{bommasani2022homogenization} directly recommend this by studying how monocultures may lead to \textit{homogeneous outcomes}: specific end users of different foundation applications being systemically failed due to the shared upstream dependence.

\paragraph{Policymakers.}
AI policy specific to foundation models is still in its infancy: \citet{bommasani2023transparency} specifically highlight the importance of transparency, directly aligning with the value proposition of \EG. 
Properties like the "access" status, "license", and "terms of service" at the scale of the ecosystem are policy-relevant: for example, policymakers should intervene if there is pervasive dependence on assets that are largely inaccessible, as these nodes will likely evade external scrutiny/oversight despite having outsized societal impact.
Beyond this, the distribution of different uses of foundation models will help clarify whether policy should adopt the perspective of regulating only the downstream applications (\eg if there is too much diversification in downstream use) or consider the upstream foundation models as well (which introduces challenges due to their generality/lack of specificity).\footnote{See the recent announcement of a UK FM taskforce: \url{https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1142410/11857435_NS_IR_Refresh_2023_Supply_AllPages_Revision_4_WEB_PDF_NoCrops_-_gov.uk.pdf}.}
In testimony before the US House Subcommittee on Cybersecurity, Information Technology, and Government Innovation, \citet{madry2023supplychain} more broadly pointed to how policymakers should prioritize the emerging AI supply chain based on foundation models.
To precisely track this supply chain, and how it evolves over time, \EG provides the concrete public infrastructure.