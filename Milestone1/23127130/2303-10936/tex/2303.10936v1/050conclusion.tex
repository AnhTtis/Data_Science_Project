We propose to generalize the perception model pre-trained on internet images to the unseen 3D environments with as few annotations as possible. Therefore, efficiently learning the exploration policy and selection method to gather training samples is the key to this task. In this work, we propose a novel informative trajectory exploration method via semantic distribution disagreement and semantic distribution uncertainty. Then the uncertainty-based hard sample selection method is proposed to further reduce unnecessary observations that can be correctly identified. Extensive ablation studies verify the effectiveness of each component of our method.

Although our method is more efficient than previous works, there are still some limitations. Through exploring the informative trajectories and samples, we can efficiently generalize the pre-trained model to the embodied task, where labeling the
segmentation mask is still costly. The weakly-supervised methods (e.g., utilizing box annotations to train segmentation models) can be utilized to fine-tune the perception model in the future. In addition, we collect all samples before fine-tuning the perception model, which results in our perception model not being updated. In the future, we can explore updating the perception module when learning the exploration policy. 

%The training of exploration policy is based on the perception model, which will result in policy retraining when using a new perception model. 


