@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}
@inproceedings{wang2021demograsp,
  title={DemoGrasp: Few-shot learning for robotic grasping with human demonstration},
  author={Wang, Pengyuan and Manhardt, Fabian and Minciullo, Luca and Garattoni, Lorenzo and Meier, Sven and Navab, Nassir and Busam, Benjamin},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5733--5740},
  year={2021},
  organization={IEEE}
}

@inproceedings{leeper2012strategies,
  title={Strategies for human-in-the-loop robotic grasping},
  author={Leeper, Adam Eric and Hsiao, Kaijen and Ciocarlie, Matei and Takayama, Leila and Gossow, David},
  booktitle={Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction},
  pages={1--8},
  year={2012}
}


@article{kent2020leveraging,
  title={Leveraging depth data in remote robot teleoperation interfaces for general object manipulation},
  author={Kent, David and Saldanha, Carl and Chernova, Sonia},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={39--53},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{helenon2020learning,
  title={Learning prohibited and authorised grasping locations from a few demonstrations},
  author={H{\'e}l{\'e}non, Fran{\c{c}}ois and Bimont, Laurent and Nyiri, Eric and Thiery, St{\'e}phane and Gibaru, Olivier},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  pages={1094--1100},
  year={2020},
  organization={IEEE}
}
@article{van2018learning,
  title={Learning to grasp from a single demonstration},
  author={Van Molle, Pieter and Verbelen, Tim and De Coninck, Elias and De Boom, Cedric and Simoens, Pieter and Dhoedt, Bart},
  journal={arXiv preprint arXiv:1806.03486},
  year={2018}
}
@article{rajeswaran2019meta,
  title={Meta-learning with implicit gradients},
  author={Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{nichol2018reptile,
  title={Reptile: a scalable metalearning algorithm},
  author={Nichol, Alex and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  volume={2},
  number={3},
  pages={4},
  year={2018}
}
@inproceedings{mousavian20196,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2901--2910},
  year={2019}
}
@inproceedings{sundermeyer2021contact,
  title={Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes},
  author={Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13438--13444},
  year={2021},
  organization={IEEE}
}
@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}
@article{saito2022task,
  title={Task-grasping from human demonstration},
  author={Saito, Daichi and Sasabuchi, Kazuhiro and Wake, Naoki and Takamatsu, Jun and Koike, Hideki and Ikeuchi, Katsushi},
  journal={arXiv preprint arXiv:2203.00733},
  year={2022}
}

@article{kopicki2016one,
  title={One-shot learning and generation of dexterous grasps for novel objects},
  author={Kopicki, Marek and Detry, Renaud and Adjigble, Maxime and Stolkin, Rustam and Leonardis, Ales and Wyatt, Jeremy L},
  journal={The International Journal of Robotics Research},
  volume={35},
  number={8},
  pages={959--976},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{guo2022few,
  title={Few-Shot Instance Grasping of Novel Objects in Clutter},
  author={Guo, Weikun and Li, Wei and Hu, Ziye and Gan, Zhongxue},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  publisher={IEEE}
}
@inproceedings{yang2021attribute,

  title={Attribute-based Robotic Grasping with One-grasp Adaptation},

  author={Yang, Yang and Liu, Yuanhao and Liang, Hengyue and Lou, Xibai and Choi, Changhyun},

  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},

  year={2021},

  organization={IEEE}

}

@inproceedings{sofiiuk2020f,
  title={f-brs: Rethinking backpropagating refinement for interactive segmentation},
  author={Sofiiuk, Konstantin and Petrov, Ilia and Barinova, Olga and Konushin, Anton},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8623--8632},
  year={2020}
}

@article{coleman2014reducing,
  title={Reducing the barrier to entry of complex robotic software: a moveit! case study},
  author={Coleman, David and Sucan, Ioan and Chitta, Sachin and Correll, Nikolaus},
  journal={arXiv preprint arXiv:1404.3785},
  year={2014}
}


@inproceedings{butler2017interactive,
  title={Interactive scene segmentation for efficient human-in-the-loop robot manipulation},
  author={Butler, Daniel J and Elliot, Sarah and Cakmak, Maya},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2572--2579},
  year={2017},
  organization={IEEE}
}


@inproceedings{milletari2016v,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={565--571},
  year={2016},
  organization={IEEE}
}


@inproceedings{liu2020cage,
  title={Cage: Context-aware grasping engine},
  author={Liu, Weiyu and Daruna, Angel and Chernova, Sonia},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2550--2556},
  year={2020},
  organization={IEEE}
}

@inproceedings{do2018affordancenet,
  title={Affordancenet: An end-to-end deep learning approach for object affordance detection},
  author={Do, Thanh-Toan and Nguyen, Anh and Reid, Ian},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={5882--5889},
  year={2018},
  organization={IEEE}
}

@inproceedings{liang2019pointnetgpd,
  title={Pointnetgpd: Detecting grasp configurations from point sets},
  author={Liang, Hongzhuo and Ma, Xiaojian and Li, Shuang and G{\"o}rner, Michael and Tang, Song and Fang, Bin and Sun, Fuchun and Zhang, Jianwei},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3629--3635},
  year={2019},
  organization={IEEE}
}

@inproceedings{fang2020graspnet,
  title={Graspnet-1billion: A large-scale benchmark for general object grasping},
  author={Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11444--11453},
  year={2020}
}


