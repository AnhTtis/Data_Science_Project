\begin{table}[!hbt]
    \centering
        \caption{
        Evaluation on additional zero-shot classification tasks. 
        \textbf{First place} is in bold and \textcolor{red}{second place} is in red. 
        \colorbox{LimeGreen}{LilT} models are boxed in green.
        Acc-1 stands for top-1 accuracy, and Acc-5 is top-5 accuracy.
        Higher is better.
        }
    \label{tab:additional-datasets}
    \begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lccccccccc}
% \hline & \multicolumn{4}{c}{ Pre-training Task } & & \multicolumn{2}{c}{ Zero-Shot Performance } \\
% \cline { 2 - 5 } \cline { 6 - 7 } 
\toprule
% \multicolumn{4}{c}{Components} &  \multicolumn{5}{c}{Flickr30k True 0-shot (1k test set)} \\
\multicolumn{4}{c}{Model} &  \multicolumn{2}{c}{CIFAR100} & \multicolumn{2}{c}{SVHN} & \multicolumn{2}{c}{ImageNet-A} \\
\cmidrule(l{0.5em}r{0.5em}){2-4}  \cmidrule(l{0.5em}r{0.5em}){5-6} \cmidrule(l{0.5em}r{0.5em}){7-8} \cmidrule(l{0.5em}r{0.5em}){9-10}
& Configuration & \# Trainable & \% Trained &  Acc-1 & Acc-5 & Acc-1 & Acc-5 & Acc-1 & Acc-5 \\
\midrule
  \rowcolor{LimeGreen}(a) & LilT-tiny & 736.45 K & 7.37 & 16.98 & 37.49 & \textcolor{red}{13.0} & 57.39 & 2.77 & 9.15  \\
 (b) & LiT-tiny & 4.45 M & 44.57 & 18.33 & 39.14 & 12.47 & 55.02 & 3.39 & 11.03  \\
 \rowcolor{LimeGreen}(c) & LilT-small & 5.19 M & 10.28 & 27.52 & 50.28 & 11.95 & 54.15 & 4.79 & 13.8  \\
 (d) & CLIP-tiny & 9.99 M & 100.0 & 18.74 & 41.1 & \textbf{14.97} & \textbf{63.18} & 2.73 & 10.49  \\
 \rowcolor{LimeGreen}(e) & LilT-base & 14.65 M & 7.51 & \textcolor{red}{29.9} & \textcolor{red}{53.77} & 11.84 & 57.08 & 5.11 & 15.8  \\
 \rowcolor{LimeGreen}(f) & LilT-large & 25.92 M & 4.06 & \textbf{31.33} & \textbf{57.93} & 7.39 & 42.21 & \textbf{7.61} & \textbf{23.44}  \\
 (g) & LiT-small & 28.73 M & 56.98 & 26.88 & 47.17 & 12.3 & \textcolor{red}{59.17} & 5.37 & 16.01  \\
 (h) & CLIP-small & 50.42 M & 100.0 & 26.43 & 49.54 & 7.18 & 54.41 & 4.41 & 14.45  \\
 (i) & LiT-base & 109.28 M & 56.01 & 26.15 & 48.69 & 11.51 & 55.75 & \textcolor{red}{5.92} & \textcolor{red}{18.13}  \\
 (j) & CLIP-base & 195.13 M & 100.0 & 25.25 & 50.93 & 9.47 & 53.33 & 4.68 & 16.41  \\
 \midrule
 (k) & VGG-19\cite{natural_adversarial_examples} & 143M M & 100.0 & - & - & - & - & 2.72 & -  \\
 (l) & ResNet-50\cite{natural_adversarial_examples} & 23 M & 100.0 & - & - & - & - & 2.17 & -  \\
 (m) & ResNet-101 \cite{natural_adversarial_examples} & 44.7 M & 100.0 & - & - & - & - & 4.9 & -  \\
 (n) & ResNet-152\cite{natural_adversarial_examples} & 60.4 M & 100.0 & - & - & - & - & 5.2 & -  \\
\bottomrule
% (e) & $\checkmark$ & & $\checkmark$ & & & $-$ & $-$ & & & &\\
% (f) & $\checkmark$ & & & $\checkmark$ & & $-$ & $-$ & & & &\\
% (g) & & $\checkmark$ & $\checkmark$ & & & $-$ & $-$ & & & &\\
% \hline (h) & $\checkmark$ & & $\checkmark$ & $\checkmark$ & & $-$ & $-$ & & & &\\
% (i) & $\checkmark$ & $\checkmark$ & & $\checkmark$ & & $-$ & $-$ & & & &\\
% (j) & $\checkmark$ & $\checkmark$ & $\checkmark$ & & & $-$ & $-$ & & & &\\
% (k) & & $\checkmark$ & $\checkmark$ & $\checkmark$ & & $-$ & $-$ & & & &\\
% (k) & & $\checkmark$ & $\checkmark$ & $\checkmark$ & & $-$ & $-$ & & & &\\
% \hline (l) & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & & $-$ & $-$ & & & &\\
% \hline
\end{tabular}
\end{adjustbox}
\end{table}