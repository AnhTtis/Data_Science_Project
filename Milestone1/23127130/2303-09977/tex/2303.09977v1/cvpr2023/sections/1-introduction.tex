\section{Introduction}
\label{sec:intro}
3D scene understanding is an important visual task for many practical applications, \eg, robotic navigation~\cite{garg2020semantics} and augmented reality~\cite{tanzi2021real}, where the scene geometry and semantics are two key factors to the agent interaction with the real world~\cite{hou2020revealnet,zhang2021self}.
% 
However, visual sensors can only perceive a partial world given their limited field of view with sensory noises~\cite{roldao20223d}. Therefore, an agent is expected to leverage prior knowledge to estimate the complete geometry and semantics from the imperfect perception.
% 
Semantic Scene Completion (SSC) is designed for such an ability to infer complete volumetric occupancy and semantic labels for a scene from a single depth and/or RGB image~\cite{song2017semantic,roldao20223d}.
% ----------------------------------
% \input{cvpr2023/Figures/teaser}
% ----------------------------------

Based on an input 2D image, the 2D$\rightarrow$3D projection is a vital bond for mapping 2D perception to the corresponding 3D spatial positions, which is determined by the depth value~\cite{chen2019learning}.
% 
After this, the model recovers the visible surface in 3D space, which sheds light on completing and labeling the occluded regions~\cite{song2017semantic,li2019rgbd}, because the geometry of the visible and occluded areas is tightly intertwined.
%  
For example, you can easily infer the shapes and the semantic labels when you see a part of a ``{chair}'' or ``{bed}''.
Thus, a high-quality visible surface is crucial for the SSC task.
% -------------------------------
\input{cvpr2023/Figures/figure1}
% ------------------------------- 

However, due to the inherent imperfection of the depth camera, the depth information is quite noisy, what follows is an imperfect visible surface that is usually represented by  Truncated Signed Distance Function (TSDF)~\cite{song2017semantic}. In general, the existing depth noises can be roughly categorized into the following two basic types:

\noindent\textbf{1) Zero Noise}. This type of noise happens when a depth sensor cannot confirm the depth value of some local regions, it will fill these regions with zeroes~\cite{fu2012kinect,nguyen2012modeling}. Zero noise generally occurs on object surfaces with reflection or unevenness~\cite{mallick2014characterizations}. 
Based on zero noise, the visible surface will be incomplete after the 2D-3D projection via TSDF~\cite{roldao20223d}, so the incomplete volumetric prediction problem may occur in the final 3D voxels. 
For example, as shown in the upper-half of Figure~\ref{fig:problem}, for the input RGB ``{kitchen}'' image, the depth value of some parts of the ``{cupboard}'' surface (marked with the red dotted frames) (in (b)) is set to zero due to reflections. Based on this, both the visible surface (in (d)) and the predicted 3D voxels (in (f)) appear incomplete in reflective regions of this ``{cupboard}''. Our method uses the perfect visible surface (in (e)) generated by the noise-free ground-truth depth value (in (c)) as intermediate supervision in training , which helps the model to estimate ``{cupboard}'' 3D voxels in inference even with the noisy depth value as input.


\noindent\textbf{2) Delta Noise}. This type of noise refers to the inevitable deviation of the obtained depth value due to the inherent quality defects of the depth camera~\cite{mallick2014characterizations}, \ie, the obtained depth value does not match the true depth value. Delta noise shifts the 3D position of the visible surface, resulting in the wrong semantic labels, such that the final 3D voxels will suffer from the problem of confusing semantic labels~\cite{song2017semantic}.
% 
%
A real delta noise case is shown in the bottom half part of Figure~\ref{fig:problem}. For the input RGB ``{classroom}'' image, the depth camera mistakenly estimates the depth value of the ``{table}'' as the depth value of ``{furniture}'' (in (b)). Therefore, the visible surface represented by TSDF shifts from the class of ``{table}'' (marked with blue points) to the class of ``{furniture}'' (marked with orange points in (d)). Based on this, the final estimated 3D voxels (in (f)) also mistakenly estimate the part of the ``{table}'' 
as the ``{furniture}''. In comparison, when our SSC model is trained on the visible surface in (e), which is generated by the correct depth value in (c), as the intermediate supervision, semantic labels for both the ``{table}'' and the ``{furniture}'' can be estimated correctly in (g).


In practice, these two types of noise are randomly mixed together to form a more complex noise~\cite{fu2012kinect,zhang2020feature}. To handle these two noise types, although some recent SSC attempts have been made by rendering the noise-free depth value from 3D voxel ground-truth~\cite{silberman2012indoor,firman2016structured}, they are not of practical use as the 3D voxels ground-truth is still needed in inference. However, they indeed validate the potential that more accurate recognition performance can be achieved using the noise-free depth value~\cite{chen20203d,zhang2019cascaded-ccpnet,wang2022ffnet}. To the best of our knowledge, no prior work focuses on mitigating the noisy depth values in SSC without the use of ground-truth depth values in inference. Therefore, the crux is to transfer the clean knowledge learned from ground-truth depth into the noisy-depth pipeline only during training. So, in inference, we can directly use this pipeline without the need for ground-truth.

In this paper, we propose a Cleaner Self (CleanerS) framework to shield the harmful effects of the two depth noises for SSC. 
CleanerS consists of two networks that share the same network architecture (that is what ``self'' means). The only difference between these two networks is that the depth value of the teacher network is rendered from ground-truth, while the depth value of the student network is inherently noisy. Therefore, the depth value of the teacher network is cleaner than the depth value of the student network. 
In the training stage, we make the teacher network to provide intermediate supervision for learning of the student network via knowledge distillation (KD), such that the student network can disentangle the clean visible surface reconstruction and occluded region completion.
To preserve both the detailed information and the abstract semantics of the teacher network, we adopt both \textbf{feature-based} and \textbf{logit-based} KD strategies. In inference, only the student network is used.
Compared to the noisy self, as shown in Figure~\ref{fig:problem}, CleanerS achieves more accurate performance with the help of ground-truth depth values in training but not in testing.
% 

% --------------------------------------------
\input{cvpr2023/Figures/noise-perf}
% --------------------------------------------

The main contributions of this work are summarized as the following two aspects: 1) we propose a novel CleanerS framework for SSC, which can mitigate the negative effects of the noisy depth value in training; 2) CleanerS achieves the new state-of-the-art results on the challenging NYU dataset with the input of noisy depth values.



