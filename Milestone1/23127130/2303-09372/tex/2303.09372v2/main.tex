%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\documentclass[%
 aip,
%
%
%
%
 amsmath,amssymb,
%
 reprint,%
%
%
%
]{revtex4-1}

\usepackage{graphicx}%
\usepackage{dcolumn}%
\usepackage{bm}%
%
%

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{etoolbox}
\usepackage{color}
\usepackage{SIunits}


%
%
\makeatletter
\def\@email#1#2{%
 \endgroup
 \patchcmd{\titleblock@produce}
  {\frontmatter@RRAPformat}
  {\frontmatter@RRAPformat{\produce@RRAP{*#1\href{mailto:#2}{#2}}}\frontmatter@RRAPformat}
  {}{}
}%
\makeatother
\begin{document}

\newcommand{\gb}{\textcolor{red} }
\newcommand{\tf}{\textcolor{blue} }
\preprint{AIP/123-QED}

\title{Refinement of molecular dynamics ensembles using experimental data and flexible forward models}
%
\author{Thorben Fr\"ohlking}%
\altaffiliation[Current address:]{ Universit\'e{} de Gen\`eve, Switzerland}%
\author{Mattia Bernetti}%
\altaffiliation[Current address:]{ Universit\`a{} di Bologna, Italy}%
\author{Giovanni Bussi}
\email{bussi@sissa.it}
\affiliation{ 
Scuola Internazionale Superiore di Studi Avanzati, via Bonomea 265, 34136 Trieste, Italy
}%

\date{\today}%
             %

\begin{abstract}
A novel method combining maximum entropy principle, the Bayesian-inference of ensembles approach,
and the optimization of empirical forward models is presented.
Here we focus on the Karplus parameters for RNA systems, which relate the dihedral angles of $\gamma$, $\beta$, and the dihedrals in the sugar ring to the corresponding $^3J$-coupling signal between coupling protons.
Extensive molecular simulations are performed on a set of RNA tetramers and hexamers and combined with available nucleic-magnetic-resonance data.
Within the new framework, the sampled structural dynamics can be reweighted to match experimental data while the error arising from inaccuracies in the forward models can be corrected simultaneously and consequently does not leak into the reweighted ensemble.
Carefully crafted cross-validation procedure and regularization terms enable obtaining transferable Karplus parameters.
Our approach identifies the optimal regularization strength and new sets of Karplus parameters balancing good agreement between simulations and experiments with minimal changes to the original ensemble.
\end{abstract}

\maketitle

\begin{quotation}
Abstract.
\end{quotation}

Molecular dynamics (MD) simulations are a fundamental tool to model the conformational dynamics of molecular systems \cite{hollingsworth2018molecular}.
In order to improve their accuracy, it is more and more common to use integrative approaches where MD simulations are combined
with experimental data \cite{bonomi2017principles,bottaro2018biophysical,bernetti2023integrating}. This makes it possible to either improve the employed force fields \cite{norgaard2008experimental,li2011iterative,wang2012systematic,wang2014building,cesari2016combining,cesari2019fitting,frohlking2020toward,kofinger2021empirical,frohlking2022automatic} or to directly refine the generated ensembles.
In particular, ensembles can be constructed by enforcing agreement with the experiment on the fly
\cite{cavalli2013molecular,white2014efficient,hummer2015bayesian,bonomi2016metainference,cesari2016combining}
or by refining
the ensembles \emph{a posteriori} \cite{costa2022reweighting}, using either selection \cite{bernado2007structural,tria2015advanced} or reweighting
\cite{pitera2012use,hummer2015bayesian,brookes2016experimental,kofinger2019efficient,bottaro2020integrating,medeiros2021comparison}  approaches. Methods based on the idea of minimally perturbing
the initially generated ensemble
are particularly appealing as they maximally use the microscopic information generated by the MD simulation
and only modify it when deviation with respect to the experiment is observed \cite{pitera2012use,cesari2018using}.
All the mentioned methods are based on a fundamental step, namely the back-calculation of the experimental
data from a simulated ensemble. The formulas used for this aim are often referred to as \emph{forward models}.
Forward models based on pairwise distances or angles between atoms or bonds are for instance used to back-calculate nuclear-magnetic-resonance (NMR) data,
whereas more complex calculations involving sums over all the observed atoms and possible solvent effects are used to back-calculate small-angle X-ray
scattering \cite{svergun1995crysol,kofinger2013atomic,knight2015waxsis} or cryo-electron-microscopy data \cite{bonomi2019bayesian}.
Many  forward models are based on empirical relationships, as is the case for the so-called Karplus equations \cite{karplus1963vicinal}.
However, the parameters of these relationships are usually determined once and for all and are not optimized for the specific problem.

In this paper, we propose a procedure to systematically refine parametrized forward models by combining MD simulations performed
on multiple systems. The refinement is simultaneously done on the simulated ensembles and on the forward models so that
it is not necessary to have an accurate reference ensemble to start with. The procedure is here applied to the refinement of
Karplus equations used to back-calculate $^3J$ scalar couplings in RNA systems, by using extensive MD simulations of a number 
of RNA oligomers for which NMR experimental data are available. The formalism is here derived
starting from the Bayesian-inference of ensembles method \cite{hummer2015bayesian}
but can be also seen as an extension of the equivalent regularized maximum entropy  approach \cite{cesari2018using}.

\section{Methods}

\subsection{The Bayesian-inference of ensembles method}
We consider a molecular system whose conformation is denoted by the high-dimensional vector $\mathbf{x}$.
The canonical distribution function is
$\rho_0(\mathbf{x})\propto e^{-\frac{U(\mathbf{x})}{k_BT}}$,
where $U(\mathbf{x})$ is the energy calculated using a molecular force field,
$k_B$ is the Boltzmann constant, and $T$ the temperature.
We use as a starting point the Bayesian inference of ensemble (BioEn) method \cite{hummer2015bayesian},
which requires minimizing the following cost function
\begin{equation}
\label{eq:cost-bioen}
\mathcal{L}_{\textrm{BioEn}}[\rho] = \frac{\chi^2[\rho]}{2} - \tilde{\alpha} S[\rho|\rho_0]~,
\end{equation}
thus obtaining the refined distribution $\rho(\mathbf{x})$.

The first term in Eq.~\ref{eq:cost-bioen} contains $\chi^2$, which
represents the discrepancy
between simulation and experiment and is defined as
\begin{equation}
\label{eq:def-chi2}
\chi^2[\rho]=\sum_i^{N_{\textrm{exp}}}
\frac{
\left(
\bar{g}_i[\rho] - g_{i,\textrm{exp}}
\right)^2
}{
\sigma^2_i
}~.
\end{equation}
The variable $N_{\textrm{exp}}$ represents the total number of experimental data points that are available. These data points can come from different sources, including multiple measurements taken in one experiment (such as in small-angle X-ray scattering), multiple separate experiments, or a combination of both.
$g_{i,\textrm{exp}}$ is the value of the experimental data,
$\sigma_i$ its associated uncertainty, and
$\bar{g}_i$ the value back-calculated from the refined ensemble, which is computed as
\begin{equation}
\bar{g}_i[\rho] = \int d\mathbf{x} \rho(\mathbf{x}) g_i(\mathbf{x})~.
\end{equation}
The function used to back-calculate the experimental values ($g_i(\mathbf{x})$)
can have an arbitrary functional form.  For instance, for nuclear Overhauser effect (NOE) experiments,
it is the inverse of the sixth power of the distance between the involved atoms and,
for $^3J$ scalar couplings, it is an empirically parametrized Karplus equation.

The second term in Eq.~\ref{eq:cost-bioen}
contains a hyperparameter ($\tilde{\alpha}>0$, named $\theta$ in the original BioEn method) that controls the relative confidence that we have in the initial ensemble and in the experimental data, and multiplies the relative entropy
between the refined ensemble ($\rho$) and the original ensemble ($\rho_0$),
defined as 
\begin{equation}
S[\rho|\rho_0] = -\int d\mathbf{x} \rho(\mathbf{x}) \ln \frac{\rho(\mathbf{x})}{\rho_0(\mathbf{x})}~.
\end{equation}
In the limit of small (positive) $\tilde{\alpha}$, the minimization is dominated by $\frac{\chi^{2}}{2}$. If one assumes that one or more ensembles that agree with all experimental data points exist, the minimum $\chi^{2}$ will be exactly equal to zero. Among all the ensembles that agree with the experiment, the method will choose the one that has the maximum relative entropy. In this regime, this approach is thus exactly equivalent to the maximum entropy principle \cite{pitera2012use}.


The form of $\rho$ that maximizes the relative entropy at a fixed value of the back-calculated observables ($\bar{g}_i[\rho]$) can be shown to be 
\cite{pitera2012use,cesari2018using}:
\begin{equation}
\rho_{\lambda}(\mathbf{x})\propto\exp\left(-\sum_{i=1}^{N_{exp}}\lambda_{i}g_{i}(\mathbf{x})\right).
\label{eq:rho-of-lambda}
\end{equation}
This allows rephrasing the dependence of $\mathcal{L}$ on $\rho$ as a dependence on the free parameters $\lambda_i$, one for each
experimental data point. It is also common to introduce a function
\begin{multline}
\Gamma(\lambda)=\ln\int d\mathbf{x}\rho(\mathbf{x}) P_{0}(\mathbf{x})e^{-\sum_{i}\lambda_{i}\left(g_{i}(\mathbf{x})-g_{i,exp}\right)}= \\S[P_{\lambda}|P_{0}]-\sum_{i}\lambda_{i}\left(\bar{g}_{i}[P_{\lambda}]-g_{i,exp}\right)~.
\label{eq:gamma}
\end{multline}
The gradient of this function is
\begin{equation}
\frac{\partial \Gamma}{\partial\lambda_{i}}=\left(g_{i,exp}-\bar{g}_{i}[P_{\lambda}]\right)~.
\end{equation}
Thus, if a set of $\{\lambda\}$ such that back-calculated observables are identical to the experimental ones exists,
$\Gamma(\lambda)$ will be minimal. In addition, since $\Gamma$ is convex, this will be a global minimum \cite{cesari2018using}.
 
%
 Finite values of $\tilde{\alpha}$ can be used to better regularize the fitting procedure, and can be shown to be equivalent to directly modeling experimental errors in the maximum-entropy framework \cite{cesari2016combining}. We notice that Eq.~\ref{eq:rho-of-lambda} is also valid for a finite $\tilde{\alpha}$. By exploiting the relationship between $\Gamma$ and $S$ (Eq.~\ref{eq:gamma}), one can rewrite the cost function as
 \begin{equation}
 \mathcal{L}_{\textrm{BioEn}}(\lambda)=\frac{\chi^{2}[\rho_{\lambda}]}{2}-\tilde{\alpha}\left(\Gamma(\lambda)+\sum_{i}\lambda_{i}\left(\bar{g}_{i}[\rho_{\lambda}]-g_{i,exp}\right)\right)
 \end{equation}
The gradient of this function with respect to $\lambda$ is
 \begin{equation}
\frac{\partial\mathcal{L}_{\textrm{BioEn}}(\lambda)}{\partial\lambda_{i}}=\sum_{j}\frac{\partial\bar{g}_{j}[\rho_{\lambda}]}{\partial\lambda_{i}}\left(\frac{\bar{g}_{j}[\rho_{\lambda}]-g_{j,exp}}{\sigma_{j}^{2}}-\tilde{\alpha}\lambda_{j}\right)
 \end{equation}
This gradient can be set to zero by setting $\bar{g}_{i}[\rho_{\lambda}]=g_{i,exp}+\tilde{\alpha}\sigma_{i}^{2}\lambda_{i}$. The interpretation is the following: for a finite $\tilde{\alpha}$, the back-calculated observables ($\bar{g}_{i}[\rho_{\lambda}]$) will not match exactly the experiment ($g_{i,exp}$). The larger $\tilde{\alpha}$ is, the larger a mismatch will be accepted.

Remarkably, the same condition can be obtained by minimizing a regularized version of the $\Gamma$ function above, defined as
\begin{equation}
\tilde{\Gamma}(\lambda)=\Gamma(\lambda)+\frac{\tilde{\alpha}\sum_{i}\sigma_{i}^{2}\lambda_{i}^{2}}{2}
\label{eq:gamma-tilde}
\end{equation}
In other words, a regularization proportional to the relative entropy in Eq.~\ref{eq:cost-bioen} is completely equivalent to a L2 regularization on $\Gamma$. By defining the optimal value of $\lambda$ that minimizes $\tilde{\Gamma}$ as:
\begin{equation}
\lambda^{*}=\arg\min_{\lambda}\left(\tilde{\Gamma}(\lambda)\right)
\end{equation}
and by exploiting the fact that
$\bar{g}_{i}[\rho_{\lambda^*}]=g_{i,exp}+\tilde{\alpha}\sigma_{i}^{2}\lambda_i^*$ it is possible to show that:
\begin{equation}
\mathcal{L}_{\textrm{}}(\lambda^{*}) = -\tilde{\alpha}\tilde{\Gamma}(\lambda^{*})
\label{eq:l-of-gamma}
\end{equation}
Notice that this identify is only valid for $\lambda = \lambda^*$, that is, after the function $\tilde{\Gamma}$ has been minimized.
Also notice that, for any finite choice of $\tilde{\alpha}$,  $\tilde{\Gamma}$ is strictly convex and has a single minimum.
The advantage of minimizing $\tilde{\Gamma}(\lambda)$, which only depends on $N_{exp}$ degrees of freedom, rather than minimizing
$\mathcal{L}[\rho]$, which has a functional dependence on $\rho$, has been already recognized in other works \cite{cesari2018using,bottaro2020integrating}.
To clarify, if the variable $\rho$ is defined as a collection of weights assigned to various snapshots in an analyzed trajectory, then the function $\mathcal{L}[\rho]$ will take an input argument whose dimensionality is equal to the number of snapshots. This number of snapshots is typically much greater than the number of experimental data points denoted by $N_{exp}$.

\subsection{Flexible forward models}

The functions $g_i(\mathbf{x})$ are usually given a priori. In this work, we consider the possibility to fine-tune these functions so as to maximize the agreement between simulation and experiment. To this aim, we define a new cost function as
\begin{equation}
\mathcal{L}[\rho,\theta]=\frac{\chi^{2}[P,\theta]}{2}-\tilde{\alpha} S[\rho|\rho_{0}]+\tilde{\beta} R(\theta|\theta_{0})~.
\label{eq:cost}
\end{equation}
Here $\theta$ are the parameters controlling the forward models, $R$ is a regularization term that penalizes too large deviations from the original forward-model parameters, and $\tilde{\beta}$ the associated hyperparameter.

To minimize this function, we first rewrite it as a function of the free parameter $\lambda_i$ and of the forward-model parameters $\theta$:
\begin{equation}
\mathcal{L}(\lambda,\theta)=\frac{\chi^{2}[\rho_{\lambda},\theta]}{2}-\tilde{\alpha} S[\rho_{\lambda}|\rho_{0}]+\tilde{\beta} R(\theta|\theta_{0})~.
\label{eq:cost2}
\end{equation}

For practical purposes, it is convenient to rephrase the minimization of $\mathcal{L}$ as a nested minimization over $\theta$ and $\lambda$. The minimization over $\lambda$ is done in an inner loop and can be performed as discussed in the previous section, namely minimizing the convex regularized function $\tilde{\Gamma}(\lambda)$ for a fixed choice of the forward-model parameters $\theta$. Since this function depends on $\theta$, we reference to it as $\tilde{\Gamma}_{\theta}(\lambda)$, which emphasizes that the maximum entropy method should be applied with a fixed set of forward-model parameters $\theta$. We define the solution of the inner minimization as:
\begin{equation}
\lambda_{\theta}^{*}=\arg\min_{\lambda}\left(\tilde{\Gamma}_{\theta}(\lambda)\right)~.
\end{equation}In the outer loop, one should miminize the function $\mathcal{L}(\theta)$, which, using Eq.~\ref{eq:l-of-gamma}, can be written as:
\begin{equation}
\mathcal{L}(\theta)=-\tilde{\alpha}\tilde{\Gamma}_{\theta}(\lambda_{\theta}^{*})+\tilde{\beta} R(\theta|\theta_{0})~.
\end{equation}
In order to compute the gradient of $\mathcal{L}(\theta)$ one can consider that $\tilde{\Gamma}$ is in a stationary point as a function of $\lambda$, so that it is not necessary to consider the derivative of $\lambda_{\theta}^{*}$ with respect to $\theta$. One thus obtains:
\begin{multline}
\label{eq:l-gradient-theta}
\frac{\partial\mathcal{L}(\theta)}{\partial\theta}=-\tilde{\alpha}\frac{\partial\tilde{\Gamma}_{\theta}(\lambda_{\theta}^{*})}{\partial\theta}+\tilde{\beta}\frac{\partial R(\theta|\theta_{0})}{\partial\theta}=\\ \tilde{\alpha}\sum_{i}\lambda_{i}\int d\mathbf{\mathbf{x}}P(\mathbf{x})\frac{\partial g_{\theta,i}(\mathbf{x})}{\partial\theta}+\tilde{\beta}\frac{\partial R(\theta|\theta_{0})}{\partial\theta}
\end{multline}

In short, we iteratively minimize $\mathcal{L}$ as a function of the forward-model parameters $\theta$ (outer minimization). For each iteration, we:
\begin{itemize}
  \item Minimize the function $\tilde{\Gamma}(\lambda)$ at fixed forward-model parameters $\theta$ (inner minimization).
  \item Compute the gradients of the cost function $\mathcal{L}$ with respect to $\theta$ using Eq.~\ref{eq:l-gradient-theta}.
\end{itemize}

Notice that the inner minimization is done for a function that is proportional to the negative of the function used in the outer minimization.
This means that the nested minimization exactly correspond to the following minimax problem:
\begin{equation}
\min_{\theta} \max_{\lambda} \left( - \tilde{\alpha} \tilde{\Gamma}_{\theta}(\lambda) \right)~.
\label{eq:minimax}
\end{equation}
The inner minimization is guaranteed to be convex. The outer minimization instead might have multiple solutions.
For simplicity, we used the  L-BFGS-B algorithm \cite{morales2011remark} for both minimizations
as implemented in the SciPy library \cite{virtanen2020scipy}.

\subsection{Calculations using reweighting}

In the above derivations we assumed to be able to compute averages in the form:
\begin{equation}
\int d\mathbf{x} \rho_{\theta,\lambda}(\mathbf{x}) f(\mathbf{x})
\end{equation}
with $f(\mathbf{x})=g_{\theta}(\mathbf{x})$, to compute the back-calculated observables,
or with $f(\mathbf{x})=\frac{\partial g_{\theta}(\mathbf{x})}{\partial \theta}$, to compute the gradients of the back-calculated observables
with respect to the forward-model parameters. In both cases, the integrals are here replaced with weighted averages performed over
a set of snapshots sampled from an initial simulated trajectory:
\begin{equation}
\int d\mathbf{x} \rho_{\theta,\lambda}(\mathbf{x}) f(\mathbf{x})
\approx
\frac{
\sum_t w_t f(\mathbf{x}_t)
}{
\sum_t w_t
}
\end{equation}
where the non-normalized weights $w$ are obtained as
\begin{equation}
w_t = e^{-\frac{\sum_i \lambda_i g_{i,\theta}(\mathbf{x}_i)}{k_BT}}~.
\end{equation}
This relationship can be straightforwardly adjusted to take into account initial weights if the trajectories have been generated
using enhanced sampling methods based on a biasing potential. This is not necessary for the application presented here.


%





\subsection{Generalization to multiple systems}

The formalism above can be generalized to simultaneously fit over multiple systems. This is an advantage when the same forward models can be expected to be valid for multiple data points across different systems.
A fit including multiple systems would thus result in more transferable forward models.
To do so, one can just average the contribution of $N_{sys}$ systems:
\begin{equation}
\mathcal{L}[\{\lambda\},\theta]=-\frac{1}{N_{sys}}\sum_{k=1}^{N_{sys}}\tilde{\alpha}\tilde{\Gamma}_{\theta,k}(\lambda_{\theta,k}^{*})+\tilde{\beta} R(\theta|\theta_{0})~.
\end{equation}
Here, each system has a separate set of $\lambda$ parameters, corresponding to each of the available experimental data points.
The forward-model parameters $\theta$ instead are shared across all the analyzed systems.

Notice that, in line of principle, each system could be regularized with a separate hyper-parameter $\tilde{\alpha}$. The hyper-parameter $\tilde{\alpha}$, indeed, reports on how accurate we expect the prior distribution to be. In addition, a separate weight might be used for the different systems, so as to encode how much we would like each system to be relevant in the fit. In this work, we consider a homogeneous set of systems so that we don't exploit this possibility, which however might be useful if one wants to mix more heterogeneous sets of experimental data.

We also notice that, especially when combining multiple systems, it is convenient to report the $\chi^2$ discrepancy as an average, rather than a sum, over
all datapoints and all systems. For clarity, we explicitly indicate this average as a reduced $\chi^2$ ($\chi^2_{\textrm{red}}$).

\subsection{Interpretation of the hyperparameters $\tilde{\alpha}$ and $\tilde{\beta}$}

The hyperparameter $\tilde{\alpha}$ tunes how much we consider the prior ensemble trustable with respect to the experimental data points. Similarly, the hyperparameter $\tilde{\beta}$ tunes how much the original forward models are considered reliable. One can consider the following limiting cases:

\begin{itemize}
\item
$\tilde{\alpha}\rightarrow\infty, \tilde{\beta}\rightarrow\infty$: in this case, both the ensemble and the forward models are not modified ($\rho=\rho_{0}$ and $\theta=\theta_{0}$). The resulting $\chi^{2}$ reports the mismatch between theory and experiment as it is before ensemble refinement.
\item
$\tilde{\alpha}\rightarrow\infty, \tilde{\beta}\rightarrow0$: in this case, the ensemble is considered as perfectly trustable and thus not modified ($\rho=\rho_{0}$), but the forward models are adjusted so as to minimize the mismatch between theory and experiment. We notice that typically the same forward model is used for multiple data points and not flexible enough to simultaneously fit all of them. Thus, this fitting typically results in $\chi^{2}>0$.
\item
$\tilde{\alpha}\rightarrow0,\tilde{\beta}\rightarrow\infty$: in this case the ensemble is maximally modified to match experimental data, without modifying the forward models. Unless one is in a situation where no ensemble can be constructed compatible with the experimental data, this would result in $\chi^{2}\rightarrow0$. This is the most standard application of the maximum entropy method, without accounting for experimental errors.
\item
$\tilde{\alpha}\rightarrow0, \tilde{\beta}\rightarrow0$: in this case, both the ensemble and the forward models are modified. Multiple solutions might be possible, where either the ensemble or the forward models are given a different relevance, depending on the order in which the two limits are taken.
\end{itemize}

Limiting cases where the hyperparameters tend to zero can lead to overfitting.
By choosing finite values for $\tilde{\alpha}$ and $\tilde{\beta}$, we can optimize the performance of the procedure.
In particular, the original ensemble can be modified to agree with the experimental data while accounting for errors both in the experiments and in the forward models used.

\subsection{Using cross-validation to fine-tune hyperparameters $\tilde{\alpha}$ and $\tilde{\beta}$}

Hyperparameters should be chosen based on the reliability
of (a) experimental data points, (b) reference forward models, and (b) original ensembles. As described in more detail in Ref.~\onlinecite{froehlking2020toward}, this
can be assessed by performing a cross-validation test where some of
the experiments are left out in training and tested in validation.
In $n$-fold cross validation, the dataset is randomly split into $n$ blocks of equal size.
One block at a time is left out of the training set and only used to compute the cross-validation error.
The parameters are trained on the remaining $n-1$ blocks.
This is repeated once for each block, yielding multiple sets of trained parameters $\lambda$ and $\theta$. The error obtained with these parameters in reproducing the left-out block is then computed, and the average over the $n$ results is the cross-validation error. Since $\tilde{\beta}$ mostly affects the fitting of the forward-model parameters $\theta$, it is crucial that in the cross-validation procedure the training and left-out
sets of experiment share the same forward models. In this way, it
is possible to see if the forward models trained on one set of experiments
are usable on a separate set of experiments. In addition, since the
evaluation of $\chi^{2}$ is affected by statistical errors and might
thus differ when using different time windows of the same simulation,
cross-validation tests should be designed to also validate parameters
trained on one simulation window against a different validation window \cite{frohlking2022automatic}.
%
In Fig.~\ref{fig:SchematicCV} we show how errors were computed and the data subdivided.
\begin{figure*}
\includegraphics[width=0.5\textwidth]{MM_CVSchematic.pdf}
\caption{\label{fig:SchematicCV}
Schematic depiction of the cross-validation procedure used in this study to decrease overfitting and allow more generalizable parameters. Datasets are shown as 2D objects, which represent the time in one dimension and space of available observables in the other. In order to keep data for validation after the fitting procedure including cross-validation and optimization on the training dataset at the optimal regularization strength has been performed, 20$\%$ of data were excluded from the fitting, here called 'True Validation'. Next the 'True Training' dataset is split $n$-times ($n=5$ in this study) randomly into blocks for training containing 70$\%$ of all the data and blocks for validation containing the remaining 30$\%$.
%
To minimize correlation between blocks, the trajectories are first split into 10 blocks along the dimension corresponding to time and subsequently we select a number of experimental data which result in a training or validation with 70$\%$ or 30$\%$ respectively.
The cross-validation error $E_{CV}^{(n)}$ is obtained by training the parameters $\theta^{(n)}$ and $\lambda^{*(n)}$ on the training data and evaluating their performance on the left-out validation block.
This is repeated once for each block, yielding multiple sets of trained parameters $(\theta^{(1)},\lambda^{*(1)}),\dots,(\theta^{(n)},\lambda^{*(n)})$ and the average over the $n$ results is the cross-validation error $E_{CV}$.}
\end{figure*}
In practice, performing a cross validation using a cost function in the form of Eq.~\ref{eq:cost} has an important practical limitation: modifications
of the original forward-model parameters in regions that were not explored in the analyzed simulations will not enter in any way in the cross-validation
cost function. As discussed in the Results section, by simply choosing the value of $\tilde{\beta}$ that minimizes the cost function calculated on the cross-validation set
results in a not-sufficiently regularized fit, that will alter the forward models too much. For this reason, we used the cross-validation cost-function to
pick the optimal $\tilde{\alpha}$ only. The optimal $\tilde{\beta}$ was instead chosen to also ensure that the optimized forward models are not excessively
modified with respect to the original ones.

\subsection{Simulation details}

To test the introduced formalism, we report simulation results for a set of RNA tetramers with sequence AAAA, CAAU, CCCC, GACC, UUUU, and for two hexamers with
sequence UCAAUC and UCUCGU (Fig.~\ref{fig:SchematicKarplus}). For the simulation we used the standard OL3 RNA ff~\cite{Cornell1996,Wang2000,Perez2007,Zgarbova2011}  with the van-der-Waals modification of phosphate oxygens developed in Ref.~\onlinecite{Steinbrecher2012} without adjustment of dihedral parameters. As a water model we chose OPC~\cite{IzadiOPC2014}.
This combination has been originally proposed in Ref.~\onlinecite{bergonzo2015improved} and 
already tested on one of the hexamers studied here \cite{bergonzo2022conformational}.
Tetranucleotide simulations were run at salt concentrations corresponding to the experimental conditions to which they are compared to a later point. Therefore, CCCC and GACC were simulated at $\approx$0.09 M KCl, AAAA, UUUU and CAAU at $\approx$0.15 M KCl,  UCAAUC at $\approx$0.11 M KCl, always using the Joung-Cheatham ion parameters~\cite{CheathamIons2008} optimized for TIP4PEwald.
Enhanced sampling simulations of tetranucleotides and tetraloops were run with GROMACS2018~\cite{abraham2015gromacs}. For tetra- and hexanucleotides standard parallel tempering ~\cite{hansmann1997,sugita1999} protocol was used with 24 replicas.
The temperatures were chosen from a geometric distribution ranging from 275 K to 400 K and systems were simulated for 1~$\mu$s per replica.
Only the trajectory closest to 300 K is considered in the following analysis.
%
%
%

\begin{figure*}
\includegraphics[width=0.5\textwidth]{SchematicKarplus.pdf}
\caption{\label{fig:SchematicKarplus}
(a) Systems included in the training set. The conformational ensembles of these systems are refined simultaneously with forward-model refinement. 
(b)  Schematic visualization of all dihedral angles related to the $^3J$-couplings that are object of the optimization. As an exemplary nucleotide we show Adenosine with all relevant dihedral angles. Since multiple couplings, for which signals are obtainable, can be related using the same Karplus relationship, we list the possible coupled atoms for the respective dihedral angle in the following. $\beta:$ (P-O5$^\prime$-C5$^\prime$-H5$^\prime$, P-O5$^\prime$-C5$^\prime$-H5$^{\prime\prime}$), $\gamma:$   (H5$^\prime$-C5$^\prime$-C4$^\prime$-H4$^\prime$, H5$^{\prime\prime}$-C5$^\prime$-C4$^\prime$-H4$^\prime$), $sugar (\nu_1, \nu_2, \nu_3):$ (H1$^\prime$-C1$^\prime$-C2$^\prime$-H2$^\prime$, H2$^\prime$-C2$^\prime$-C3$^\prime$-H3$^\prime$, H3$^\prime$-C3$^\prime$-C4$^\prime$-H4$^\prime$).
(c) The optimized Karplus parameters are then validated on the UCUCGU hexamer system.}
\end{figure*}

\subsection{Experimental data}

All small RNAs simulated in this work can be compared to experimental studies providing NMR data in the form of $^3J$-scalar-couplings as well as observed and unobserved NOEs (uNOEs): AAAA~\cite{condon2015stacking}, CAAU~\cite{condon2015stacking}, CCCC~\cite{tubbs2013nuclear}, GACC~\cite{yildirim2011benchmarking,condon2015stacking}, UUUU~\cite{condon2015stacking}, UCAAUC~\cite{zhao2020nuclear} and UCUCGU~\cite{zhao2022nuclear}.
%
%
The choice of simulated RNA systems is based on previous works showing that AAAA, CAAU and CCCC are sequences which possess overpopulated states with intercalated structures, which can hinder correct folding of systems containing them~\cite{mlynsky2020fine}.
%
The GACC tetramer  was reported to sample intercalated structures not compatible with experiment~\cite{condon2015stacking,bergonzo2015highly} as well,
although this artifact can be significantly decreased using
modified dihedral potentials~\cite{gil2016empirical,Aytenfisu2017,chen2022rna} 
or modified water models~\cite{bergonzo2015improved,Yang2017,bottaro2018conformational,tan2018rna}.
%
The UUUU system is in disagreement with available experimental NMR data~\cite{condon2015stacking}.
%
In a study comparing MD simulations with NMR experiments it was found that for CAAU and UCAAUC the simulated dynamics of the termini did not agree with experiment~\cite{zhao2020nuclear}. %

\subsection{Optimized forward models}

We here optimized the forward models used to back-calculate $^3J$ scalar couplings in RNA systems.
We use the functional form proposed in Ref.~\onlinecite{Hecht1963}:
\begin{equation}
^3J(\phi)
= Acos^2(\phi)-Bcos(\phi)+C~.
\label{UniversalKarplusEq}
\end{equation}
where $\phi$ is the involved dihedral angle.
%
%
%
%
On the basis of previous studies~\cite{bottaro2019barnaba}, we use as an initial guess
the parameters proposed in previous papers: Ref.~\onlinecite{Davies1978} for $\gamma$, Ref.~\onlinecite{Lankhorst1985} for $\beta$,
and Ref.~\onlinecite{condon2015stacking} for the sugar angles.
These parametrizations are only used to set a Gaussian prior on the forward-model parameters $\theta$ for regularization.
The regularization function for each Karplus equation is defined as
\begin{equation}
R = (\frac{A}{2}-\frac{A_0}{2})^2+(B-B_0)^2+(\sqrt{2}(C+\frac{A}{2})-\sqrt{2}(C_0+\frac{A_0}{2}))^2
\label{ExactRegularizationForm}
\end{equation}
where $A_0$, $B_0$, and $C_0$ are the reference parameters.
This is twice the square deviation between the new and the reference Karplus equations averaged over
the angle and thus allows equivalent regularization among the $A$, $B$, and $C$ parameters.
In this work, we consider the functional form of Eq.~\ref{UniversalKarplusEq} using the involved nuclei, and not the corresponding
heavy-atoms, so that no phase shift is required. The exact atoms involved are shown in Fig.~\ref{fig:SchematicKarplus}.
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\section{\label{sec:Results}Results}

\subsection{Cross-validation procedure}
\label{Cross_validation_procedure}
We perform a scan in the space of hyperparameters $\tilde{\alpha}$ and $\tilde{\beta}$ to begin with. In Fig.~\ref{fig:CV}a we collected the average $\chi^2_{\textrm{red}}$ error on the training set. L2 regularization is applied in the outer minimization on the difference between the reference Karplus parameters and any new choice.
L2 regularization is also applied to the inner minimization of $\tilde{\Gamma}$ (Eq.~\ref{eq:gamma-tilde}) as a function of the parameters $\lambda$, as we have shown that this regularization
corresponds to a relative entropy regularization for the cost function.
Therefore, by construction the $\chi^2_{\textrm{red}}$ error is maximal at large hyperparameter choice and equal to the error in the original ensemble. The limit of low hyperparameters
corresponds instead to fitting without any regularization and, accordingly, we expect to observe a decrease in average training $\chi^2_{\textrm{red}}$ when decreasing $\tilde{\alpha}$ and $\tilde{\beta}$ values. 
We notice that the choice of $\tilde{\alpha}$ has an impact on the entire dataset, while changes to $\tilde{\beta}$ impact only the error contribution of $^3J$-couplings. Consequently, the training error is changing more significantly along $\tilde{\alpha}$  than along $\tilde{\beta}$.
When monitoring the average $\chi^2_{\textrm{red}}$ evaluated on the validation set (Fig.~\ref{fig:CV}b), which was left-out during training,
we observe that the cross-validation error is not continuously decreasing with decreasing magnitude in hyperparameters,
indicating that overfitting can occur.
This is especially visible when monitoring the dependence of the cross-validation error on $\tilde{\alpha}$.
The specific values of the hyperparameters $\tilde{\alpha}$ and $\tilde{\beta}$ that minimize the cross-validation error are shown with a star.

%
%
The main contribution to the error in Fig.~\ref{fig:CV}a and b is the discrepancy of the simulations with NOE and uNOE experiments.
When using the hyperparameters that minimize the cross-validation error, 
the combined error from those amounts up to $\chi^2_{\textrm{red}}=73.91$, while the error from $^3J$-coupling experiments is only at $\chi^2_{\textrm{red}}=1.54$.
This imbalance might hide possible overfitting issues on the Karplus equations. In addition, and perhaps more importantly,
the overfitting identified here are limited to regions of the dihedral angles that are actually explored in the MD simulation,
and do not consider in any way the agreement between the proposed Karplus parameters and those already used in previous works.
In order to make sure that the trained Karplus parameters do not deviate too much from those proposed in previous works,
we additionally monitor the value of $\chi_{\textrm{red}}^2+\frac{\tilde{\gamma}R}{3}$, where $R$ is the regularization penalty for the Karplus parameters
which is here divided by three to consider that we are modifying three Karplus equations. The prefactor $\tilde{\gamma}$ is an additional
hyperparameter that takes into account the relative importance of finding Karplus equations that agree with the currently analyzed experiments
and Karplus equations that agree with the literature.
Heuristically, we found that $\tilde{\gamma}=1 Hz^{-2}$ allows to identify Karplus parameters that do not deviate too much from those in the literature.
This value corresponds to (a) assigning an uncertainty of $\approx$ 0.7 Hz to the equations reported in the literature and (b)
assigning the same relative weight to the cross validation against left-out datapoints and to the cross validation against the reference Karplus parameters.
In Fig.~\ref{fig:CV}c we observe a decrease in average training $\chi_{\textrm{red}}^2+\frac{\tilde{\gamma}R}{3}$ when decreasing $\tilde{\alpha}$ and $\tilde{\beta}$ values. However, in the limit of small $\tilde{\alpha}$ and $\tilde{\beta}$ the behaviour changes and a strong increase in the error can be seen. This indicates a significant change in the Karplus parameters.
In Fig.~\ref{fig:CV}d we see an accentuated trend of what was already seen in Fig.~\ref{fig:CV}b. In the limit of small $\tilde{\beta}$ one would identify new Karplus parameters, which would be non-transferable to new data points and, additionally, would deviate significantly from those reported in the literature.

\begin{figure*}
\includegraphics[width=0.5\textwidth]{CV.pdf}
\caption{\label{fig:CV}
Results of the cross-validation tests using L2 regularization method.
The error function is evaluated on the training (panels a, c) and validation set (panels b, d), using Karplus parameters obtained minimizing the error
and a scan over a wide range of values for both regularization hyperparameters.
The error function for the reference force field is equivalent to the error at maximal hyperparameters. Ranges of both horizontal and vertical axes as well as the sidebar are identical. While panels a and c show the error on the training dataset, panels b, d show the error on the dataset left-out during the training. The definition of the error in a and b is $\chi^2_{\textrm{red}}$ while in c and d it is $\chi^2_{\textrm{red}}+\frac{\tilde{\gamma}R}{3}$ instead, with $\tilde{\gamma}=1\textrm{Hz}^{-2}$,
meaning the average $\chi^2$-error with the added average discrepancy between original and optimized Karplus parameters.}
\end{figure*}


\subsection{Discovery of optimized Karplus parameters}
\label{Discovery_opt_Karplus_params}
The minimum cross-validation error identified in Fig.~\ref{fig:CV}d, as shown in the previous section, is the criterion to choose the strength of a specific form of the regularization term for inner and outer minimization.
%
%
%
%
In Table~\ref{tab_KarplusParameters} and Fig.~\ref{fig:OptimizedKarplus} we compare the Karplus parameters and their resulting Karplus curves before and after the optimization procedure is completed. From Table~\ref{tab_KarplusParameters} we can appreciate significant differences in parameter values for the sets related to the $\beta$ and the $sugar$ dihedral angles
(root-mean-square-deviation is $\approx$ 1 Hz).
Optimization of the Karplus parameters for $\gamma$ leads to small changes instead
(root-mean-square-deviation is $\approx$ 0.15 Hz).
%
Fig.~\ref{fig:OptimizedKarplus} additionally reports the curves obtained with other sets of parameters reported in the literature
as well as the range of experimental value spanned by the datapoints used in this work.
Optimized Karplus equations are shown as obtained using both options for the definition of the cross-validation error,
namely $\chi^2_{\textrm{red}}$, reporting the disagreement with cross-validation datapoints, and $\chi^2_{\textrm{red}}+\frac{\tilde{\gamma}R}{3}$, which also reports on the disagreement
with Karplus equations taken from the literature.
Importantly, a significant difference can be spotted for the Karplus curves optimized based on the 2 different definitions. While the ones obtained based on the $\chi^2$-error suffer from overfitting issues, the parameter set obtained with the $\chi^2_{\textrm{red}}+\frac{\tilde{\gamma}R}{3}$ is closer to the experimental range considered in this study and, as expected, lies within the standard deviation of Karplus curves previously published.
The departure from previously determined Karplus curves is particularly evident for the $\gamma$ Karplus parameters,
whereas it is very mild for  $sugar$ parameters. This can be explained by the fact that the distribution of the
$\gamma$ angle is peaked (compare SI Fig.~1 for histograms of the dihedral angles cumulated over all systems) %
with the consequence that the cross-validation test is not sensitive to modification of the Karplus curves in regions with
very low population.
The sampling of the dihedral angle used with $sugar$ related parameters spans instead entire range between $-\pi$ and $\pi$ reducing overfitting on local regions in dihedral angle space.
%
%
%
%

 The results of optimizing Karplus parameters and performing maximum entropy reweighting at the optimal hyperparameter identified via cross-validation and using the entire database are reported in Table~\ref{tab_KarplusTrainingErrors}.
The errors in the original ensemble are very large for NOEs and are significantly reduced by the reweighting procedure.
The errors are moderate for $^3J$ scalar couplings, and are further reduced when using the optimized Karplus curves.
Notably, the use of the optimized Karplus equations further reduces the discrepancy between simulation and experiment.


\subsection{Validation of the optimized Karplus parameters on left-out data}

%
The weights computed using the procedure above were also used to evaluate the discrepancy between simulation and experiment
in a set of data points, 20$\%$ of the entire dataset, which was completely left-out from the optimization procedures.
This validation set allows testing the fitting results on new unknown data for the same systems considered during optimizations.
The original $\chi^2_{\textrm{red}}$ containing NOEs and uNOEs is 10.16. Using the weights obtained during maximum entropy reweighting at $\tilde{\beta}=\infty$ decreases the error to 1.94. The evaluation of the error after reweighting with the optimized Karplus parameters obtained at  optimal hyperparameters leads to the same contribution of NOE and uNOEs, however the contribution coming from $^3J$-couplings is further reduced.
As can be seen from SI Fig.~2, this is due to the fact that the weights are not changing significantly when reweighting the ensemble with the optimized Karplus parameters.
For the specific systems, this is a consequence of the strong dominance of the non-refined NOEs and uNOEs data over the refined scalar couplings.

\begin{table}%
%
\caption{In this table we collect the original ($\beta$~\cite{Lankhorst1985}, $\gamma$~\cite{Davies1978} and  $sugar$~\cite{condon2015stacking} ) and the optimized set of parameters in this work. The functional form relating observed $^3J$ vicinal proton coupling to the dihedral angle is: $^3J(HH)=Acos^2(\phi)-Bcos(\phi)+C$. 
Coefficients are reported in Hz.
}
\makebox[0.5\textwidth]{
\def\arraystretch{1.3}
\begin{tabular}{ c|c|c|c|c   }
%
\textbf{Name} & \textbf{A} & \textbf{B} & \textbf{C}& \textbf{Ref.}\\
\hline 
\multicolumn{5}{c}{\textit{$\beta \pm \frac{2\pi}{3}$}} \\
\hline 
original  & 15.3 & -6.1 & 1.6 & Lankhorst~\cite{Lankhorst1985}, 1985\\
\hline 
optimized  & 18.34 & -5.39 & 0.11 & this study \\
\hline 
\multicolumn{5}{c}{\textit{$\gamma,\gamma-\frac{2\pi}{3}$}} \\
\hline 
original  & 9.7 & -1.8 & 0 & Davies~\cite{Davies1978}, 1978 \\
\hline 
optimized  & 10.07 & -1.87 & -0.13 & this study \\
\hline
\multicolumn{5}{c}{\textit{$sugar$}} \\
\hline 
original  & 9.67 & -2.03 & 0 & Condon~\cite{condon2015stacking}, 2015 \\
\hline 
optimized  & 7.81 & -2.05 & 0.25 & this study \\
\end{tabular}}
\label{tab_KarplusParameters}
\end{table}


\begin{figure*}
\includegraphics[width=\textwidth]{OptimizedKarplus.pdf}
\caption{\label{fig:OptimizedKarplus}
Comparison of the optimized Karplus parameters identified in this study to Karplus curves corresponding to parameter sets previously proposed in the literature including the ones used as starting parameters for the fitting ($\beta$: Lankhorst~\cite{Lankhorst1985}-Mooren~\cite{mooren1994solution}-Lee~\cite{lee1976aqueous}-Blackburn~\cite{blackburn1973proton}-Altona~\cite{altona1982conformational}, $\gamma$: Davies~\cite{Davies1978}-Haasnoot~\cite{condon2015stacking}, $sugar$: Condon~\cite{condon2015stacking}-Davies~\cite{Davies1978}-Haasnoot~\cite{condon2015stacking}). Light-grey horizontal bar corresponds to minimal and maximal experimental values for the respective $^3J$-coupling considering the entire training database. In order to show overfitting issues, the Karplus curves resulting from optimization with hyperparameters chosen based on Fig.~\ref{fig:CV}b are also included.}
\end{figure*}


\begin{table}%
\caption{
Average $\chi^2_{\textrm{red}}$-errors and Kish size evaluated on the training database as well as on the left-out data used for validation. We report both the direct results of the original simulations and the results predicted by reweighting those simulations at different choices of the hyperparameters. Reweighting is performed at the hyperparameters $\tilde{\alpha}$ and $\tilde{\beta}$ specified in the first 2 rows of the table. The optimized Karplus parameters obtained with hyperparameters chosen based on Fig.~\ref{fig:CV}d reduce the average $\chi^2_{\textrm{red}}$-errors in training and validation dataset the most.
}
\makebox[0.5\textwidth]{
\def\arraystretch{1.3}
\begin{tabular}{ c|c|c|c   }
%
 & \textbf{orig. ensemble} & \textbf{orig. Karplus} & \textbf{opt. Karplus}\\
\hline 
$\tilde{\alpha}$  & $\infty$ &  174 &  174\\
\hline 
$\tilde{\beta}$  & $\infty$ &  $\infty$ &  3.4  \\
\hline 
\multicolumn{4}{c}{\textit{Training dataset}} \\
\hline 
$\chi^2_{\textrm{red}}$ $^3J$-couplings only   & 1.54 &  0.82 &  0.53\\
\hline
$\chi^2_{\textrm{red}}$ NOEs only   & 73.91 &  0.22 &  0.22\\
\hline 
\multicolumn{4}{c}{\textit{Validation dataset}} \\
\hline 
$\chi^2_{\textrm{red}}$ $^3J$-couplings only   & 9.66 &  4.22 &  3.11\\
\hline 
$\chi^2_{\textrm{red}}$ NOEs only   & 10.16 &  1.94 &  1.94\\
\end{tabular}}
\label{tab_KarplusTrainingErrors}
\end{table}

\subsection{Validation of the optimized Karplus parameters on a separate system}
\label{Validation_opt_Karplus_params}
The optimized set of Karplus parameters seems in agreement with the available experimental data and do not depart significantly from sets previously reported. Therefore, we proceed by evaluating their performance on a new system not considered during training, namely the UCUCGU hexamer. For this RNA system experimental NMR data, consisting of $^3J$-coupling, NOEs and uNOEs, are made available in Ref.~\onlinecite{zhao2022nuclear} such that comparisons to simulations can be made. 
Instead of performing cross-validation to identify the optimal hyperparameter $\tilde{\alpha}$ for maximum entropy reweighting we perform a scan over a range of regularization strengths. The results of this analysis are collected in Fig.~\ref{fig:Validation} and suggest that this set of parameters allows better agreement of training and validation data to their corresponding experimental data when compared to our choice of original Karplus parameters. Not surprisingly, the new Karplus parameters optimized on the training database reduce the $\chi^2$ contribution of $^3J$-couplings significantly over the entire range of regularization strengths. From Fig.~\ref{fig:Validation}a we notice that NOEs and uNOEs are the main contribution to the $\chi^2$ in the limit of large $\tilde{\alpha}$, while for smaller regularization strength $^3J$-couplings exhibit equal contribution to $\chi^2$. The set of Karplus parameters optimized on a $\chi^2$ with these relative error contributions do not change the increase in agreement which can be achieved for NOEs and uNOEs for the training data by performing maximum entropy reweighting, while by construction increasing the agreement with experimental $^3J$-coupling data (compare Fig.~\ref{fig:Validation}a and b). Focusing on the independent UCUCGU system in Fig.~\ref{fig:Validation}c and d, and considering the contributions of NOEs, uNOEs and $^3J$-couplings to the $\chi^2$ one can see that in this specific system the disagreement between simulation and experiments is significantly larger for the $^3J$-couplings compared to the NOEs and uNOEs. However, applying the optimized Karplus parameter set is showing similar results as for the training database by reducing the  $\chi^2$ in $^3J$-couplings significantly while simultaneously allowing the same increase in agreement with experimental NOE data as the original Karplus parameters.

\begin{figure*}
\includegraphics[width=0.5\textwidth]{Validation.pdf}
\caption{\label{fig:Validation}
Sensitivity test evaluating the average $\chi^2$ contributions with the original parameters and the optimal parameters found in this study, considering $^3J$-couplings (a, c), NOEs and uNOEs (b, d) for the training systems (a, b) as well as the new independent UCUCGU hexamer system (c, d). The ensembles are reweighted via maximum entropy method over a range of L2 regularization strengths $\tilde{\alpha}$. The $\tilde{\alpha}$ at which the new Karplus parameters are obtained is indicated by stars. 'orig.' and 'opt.' denote which Karplus parameters are used during reweighting. 
The optimized Karplus parameters are performing well on the training dataset and more importantly are transferable to the dataset completely unknown during the optimization procedure. As intended, the NOE and uNOE errors are not influenced by the optimization of the Karplus parameters.}
\end{figure*}

\section{\label{sec:Discussion}Discussion}

In this work, we combine the BioEn method, introduced in Ref.~\onlinecite{hummer2015bayesian}, with the optimization of the empirical Karplus parameters for $\beta$ (H-C-O-P), $\gamma$ (H-C-C-H) and $sugar$ (H-C-C-H). These forward models have been introduced in~\cite{Lankhorst1985,Davies1978,condon2015stacking} and were used in previous works to improve the agreement of simulations with experimental data~\cite{cesari2016combining,bottaro2018conformational,cesari2019fitting,bottaro2020integrating,frohlking2022automatic}.
Specifically, we combine MD simulations with experimental data for a database of the RNA systems AAAA, CAAU, CCCC, GACC, UUU and UCAAUC to fit the Karplus parameters while simultaneously reweighting the simulated ensemble using the maximum entropy method. The optimized Karplus parameters of this study allow for a significant increase in agreement between simulations and experiments for all RNA systems and are transferable to an additional system (UCUCGU) not seen during training.
We apply a rigorous regularization protocol, which probes for errors due to finite data space in multiple directions. We test the L2 regularization strategy, which is standard in the machine learning community and can be directly interpreted as a Gaussian prior distribution on the parameters aimed at keeping them small and close to their \textit{a priori} parametrization.
Whereas the importance of dynamics in the determination of Karplus parameters has been recognized since a long time for protein systems
\cite{lindorff2005interpreting}, we are not aware of similar attempts done for nucleic acids. Indeed, the most commonly used
parametrizations, that we here used as a starting point, are all based on the analysis of static structures.

A weakness of the current reweighting-based approach is that it might statistically inefficient \cite{shen2008statistical}.
The investigated oligomers are sufficiently simple and with relatively accurate initial ensembles so that this
is not creating significant issues. For more complex systems, methods based on on-the-fly restraining might be more effective \cite{rangan2018determination}.
Interestingly, in the metainference approach \cite{bonomi2016metainference}, (systematic) forward-model errors
are treated on par with (random) experimental errors. Whereas one could imagine to adjust forward models
on the fly, it is not clear how to do it efficiently without the need to perform the simulation of all
the studied systems simultaneously and with an explicit coupling, as done for instance in Ref.~\onlinecite{cesari2016combining}. The reweighting approach used here allows
to combine multiple systems a posteriori, and so is less limited in this respect.

%
%
%
%
%

From a mathematical point of view,
the optimizations performed in this work correspond to solving a minimax problem (Eq.~\ref{eq:minimax}). Given the relevance of minimax problems in current machine learning
literature (see, e.g., \cite{sanjabi2018convergence}), it might be interesting to test more advanced minimax algorithms, especially if a larger number of forward-model parameters
are to be simultaneously optimized. The nested minimization algorithm used here was sufficient for the current application.

The interpretation of the optimized Karplus parameters is straightforward, as they directly transform a dihedral angle between a specific choice of atoms into a corresponding $^3J$-coupling signal. Ideally, the sampled dihedral angle configurations span the entire range between $-\pi$ and $\pi$. In this study, however, the $\gamma$ angle is missing data points in some regions of the dihedral space (compare SI Fig.~1). In those cases, overfitting parameters on the regions with data points can occur, meaning we are introducing extrapolation errors in the regions in which data points are missing. Monitoring simultaneously disagreement of the validation set with experiments and how much the optimized Karplus parameters depart from the initial choice during cross-validation allows us to avoid such overfitting due to finite sampling or data points. We herein split the data into 70$\%$ for training and 30$\%$ for validation.
The splitting is done so as to combine cross-validation on the trajectory and cross-validation on observables.
Performed in this way, cross-validation simultaneously tests how well the fitted corrections are transferable to newly sampled data points along the trajectory and new experimental measurements. We identify overfitting issues in absence of regularization for both Karplus parameters and the ensemble reweighting, emphasizing the importance of
using a regularization term.

The idea of tuning free parameters related to forward models can be extended to other experimental observables, where parameters could
be either transferable or non-transferable between different experiments.
We here focused on transferable Karplus parameters for $^3J$-coupling experiments.
However, it is instructive to consider how cross-peaks are used to generate upper (or lower) distance bounds for observed (or unobserved) NOEs.
Specifically, peak intensities are calibrated iteratively, and different protons are assigned different calibration constants
\cite{herrmann2002protein,lange2014automatic},
 for which more optimal choices could exist. The method introduced here could be used to calibrate them in a fashion consistent with MD ensembles during the ensemble refinement step.

A similar issue appears in SAXS data, where a scaling factor and a shift might be necessary to maximize the agreement with experiment and
compensate for imperfect background subtraction \cite{pesce2021refining}. Pesce and Lindorff-Larsen proposed
to determine these coefficients simultaneously with the ensemble refinement step, in an approach that is similar to the one introduce here.
The main differences are that (a) in Ref.~\onlinecite{pesce2021refining} the forward models and the ensembles are refined alternatively, rather than concurrently,
and that (b) the optimization is done on the $\chi^2$ rather than on the BioEN cost function.
Another important novelty introduced here is the application of a regularization term on the force-field parameters,
which facilitates obtaining parameters that are then transferable to other systems.
We notice that, in a previous work, we were adapting the maximum-entropy formalism so as to be able to
enforce SAXS data without specifying the scaling factor \cite{bernetti2021reweighting}.
This however made it difficult to add a suitable regularization term.
The approach of Ref.~\onlinecite{pesce2021refining}, or the approach introduced here, would be a better way to tackle the same issue.


%

%
%


%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%

Future works will investigate the possibility to add force field fitting~\cite{cesari2019fitting,frohlking2022automatic} to our combination of forward model optimization and ensemble refinement. This would translate into a framework which can integrate molecular simulations and experimental data considering that experiments, forward models and force fields might have errors.

\section{Supporting Information}
At \url{https://github.com/bussilab/forward-model-optimization} we provided the SI figures 1 and 2 as 'SI\_Figures\_1\_2.ipynb' as well as all scripts that are allowing one to obtain the results in this study.

\begin{acknowledgments}
We acknowledge J{\"u}rgen K{\"o}finger and Kenno Vanommeslaeghe
for reading the PhD thesis of T.F., including a preliminary version of this work, and providing several useful suggestions. We also acknowledge Gerhard Hummer for useful discussion.
%
\end{acknowledgments}

\section*{Data availability}

The data that support the findings of this study are openly available
at \url{https://zenodo.org/record/7746293}.
Analysis scripts
can be found at \url{https://github.com/bussilab/forward-model-optimization}.

%

%

%
%
%
%
%
%

%

%
%
\bibliography{main}

\end{document}
%
%
