\documentclass[lettersize,journal]{IEEEtran}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{ifthen}   % for environments
\usepackage{graphicx} 
\usepackage{balance}
\usepackage[hidelinks]{hyperref} % hyperlinks
\usepackage{booktabs} % tables
\usepackage{makecell}
\usepackage{multirow}
\usepackage{subcaption}  % sub captions of figures
\usepackage{enumitem} % roman enumeration


% Vectors, Matrices:
\newcommand{\bma}{\begin{bmatrix}}
\newcommand{\ema}{\end{bmatrix}}

\newcommand{\vect}[1]{\mathbf{#1}} % vector
\newcommand{\vectg}[1]{\boldsymbol{#1}} % italic vector (works also for greek)
\newcommand{\refl}[1]{\accentset{\leftarrow}{#1}} % reflection of function
\newcommand{\mat}[1]{\mathsf{#1}} % matrices (capital greek symbols work too)
\newcommand{\boldmat}[1]{\textnormal{\usefont{T1}{ba9}{r}{r}\selectfont #1}} % Humanist970BT-RomanC
\newcommand{\vmat}[1]{\mathbb{#1}} % random matrices
\newcommand{\inv}[1]{#1^{-1}} % inverse  
\newcommand{\trans}[1]{#1^{\textnormal{\textsf{\tiny T}}}} % transpose  
\newcommand{\transsmall}[1]{#1^{\textnormal{\textsf{\fontsize{1pt}{1pt}\selectfont T}}}} % tranpose small  
\newcommand{\invtrans}[1]{#1^{-\textnormal{\textsf{\tiny T}}}} % transpose of inverse
\newcommand{\invtranssmall}[1]{#1^{\scriptscriptstyle -\textnormal{\textsf{\fontsize{1pt}{1pt}\selectfont T}}}} % tranpose small  
\newcommand{\tpt}{\textnormal{\textsf{\tiny T}}} % transpose-t
\newcommand{\conj}[1]{#1^{\textnormal{\textsf{\footnotesize\raisebox{-0.5ex}{*}}}}} % conjugate 
\newcommand{\conjstar}{\textnormal{\textsf{\footnotesize\raisebox{-0.5ex}{*}}}} % star of conjugate 
\newcommand{\hermi}[1]{#1^{\dagger}} % transpose and conjugate
\newcommand{\invhermi}[1]{#1^{-\dagger}} % transpose and conjugate of inverse
\newcommand{\trace}[1]{\operatorname{tr}\left(#1\right)} % trace
\newcommand{\diag}[1]{\operatorname{diag}\left(#1\right)} % diagonal matrix
\newcommand{\rank}[1]{\operatorname{rank}\left(#1\right)} % rank operator
\newcommand{\T}{{\mathsf{T}}} % transpose

% Fields and Spaces
\newcommand{\Reals}{\mathbb{R}}      % real numbers
\newcommand{\Integers}{\mathbb{Z}}   % integers
\newcommand{\Rationals}{\mathbb{Q}}  % rational numbers
\newcommand{\Naturals}{\mathbb{N}}   % natural numbers 1,2,3,...
\newcommand{\Complex}{\mathbb{C}}    % complex numbers
\newcommand{\Field}{\mathbb{F}}      % field
\newcommand{\GF}{\textnormal{GF}}            % Galois-field


% Real and Imaginary Parts of a Complex Number
\renewcommand{\Re}[1]{\mathop{}\!\textnormal{Re}\left\{#1\right\}}
\renewcommand{\Im}[1]{\mathop{}\!\textnormal{Im}\left\{#1\right\}}


% Sets, cardinalities
\newcommand{\set}[1]{\mathcal{#1}} %set
\newcommand{\cset}[1]{\mathcal{#1}^{\textnormal{c}}} %complement of set
\newcommand{\comp}[1]{\left(#1\right)^{\textnormal{c}}} %complement of set
\newcommand{\card}[1]{\left|#1\right|} %cardinality of a set.


% Communication Constants 
\newcommand{\const}[1]{\textnormal{\usefont{U}{eur}{m}{n}\selectfont #1}} % new version Euler
\newcommand{\constb}[1]{\textnormal{\usefont{U}{eur}{b}{n}\selectfont #1}} % bold constant Euler
\newcommand{\Prs}[1]{\operatorname{\textnormal{Pr}}\left(#1\right)}
\newcommand{\Prv}[1]{\operatorname{\textnormal{Pr}}\left[#1\right]}
% \newcommand{\E}[2][]{\mathop{}\!\textnormal{\textsf{E}}_{#1}\left[#2\right]}
\newcommand{\Econd}[3][]{\mathop{}\!\textnormal{\textsf{E}}_{#1}\left[#2\middle|#3\right]}
\newcommand{\Normal}[1]{\mathcal{N}\!\left({#1}\right)} %Gaussian dist.


% Statistical Operators 
\newcommand{\eqlaw}{\stackrel{\mathscr{\scriptscriptstyle L}}{=}} %equivalence in prob. law
\newcommand{\indep}{\mathrel\bot\joinrel\mspace{-8mu}\mathrel\bot}  %independent
\newcommand{\dep}{\centernot\indep} %dependent 
\newcommand{\markov}{\mathrel\multimap\joinrel\mathrel-\mspace{-9mu}\joinrel\mathrel-}

% Various maths:
\newcommand{\dd}{\mathop{}\!\mathrm{d}} %d in integrals and differentiation
\newcommand{\intinf}{\int_{-\infty}^{\infty}}
\newcommand{\ii}{\mathsf{i}} %square root of -1.
\newcommand{\eqdef}{\triangleq} % definition
\newcommand{\Four}[1]{\hat{#1}} %The Fourier trans. of the argument
\newcommand{\InvFour}[1]{\check{#1}} %The Fourier trans. of the argument
\newcommand{\conv}[2]{#1 \star #2}
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\eps}{\epsilon} 
\newcommand{\veps}{\varepsilon}
\newcommand{\Exp}[1]{\exp \! \left(\! {#1} \! \right)} 

%% Messages (Message Passing)
\makeatletter
\DeclareFontFamily{U}{MnSymbolA}{}
\DeclareSymbolFont{MnSyA}{U}{MnSymbolA}{m}{n}
\DeclareFontShape{U}{MnSymbolA}{m}{n}{
<-6> MnSymbolA5
<6-7> MnSymbolA6
<7-8> MnSymbolA7
<8-9> MnSymbolA8
<9-10> MnSymbolA9
<10-12> MnSymbolA10
<12-> MnSymbolA12}{}
\DeclareMathSymbol{\smallrightarrow}{\mathrel}{MnSyA}{0}
\DeclareMathSymbol{\smallleftarrow}{\mathrel}{MnSyA}{2}
\DeclareMathSymbol{\smallleftrightarrow}{\mathrel}{MnSyA}{16}
\newcommand{\smallrightarrowfill@}{\arrowfill@\relbar\relbar\smallrightarrow}
\newcommand{\smallleftarrowfill@}{\arrowfill@\smallleftarrow\relbar\relbar}
\newcommand{\smallleftrightarrowfill@}
{\arrowfill@\smallleftarrow\relbar\smallrightarrow}
\renewcommand{\overrightarrow}{\mathpalette{\overarrow@\smallrightarrowfill@}}
\renewcommand{\overleftarrow}{\mathpalette{\overarrow@\smallleftarrowfill@}}
\renewcommand{\overleftrightarrow}
{\mathpalette{\overarrow@\smallleftrightarrowfill@}}
\makeatother
%%
\providecommand{\msgf}[2]{\protect\overrightarrow{#1}_{\mspace{-3mu}#2}} % Forward Message
\providecommand{\msgb}[2]{\protect\overleftarrow{#1}_{\mspace{-3mu}#2}} % Backward Message
\providecommand{\msgfb}[2]{\protect\overleftrightarrow{#1}_{\mspace{-3mu}#2}}

\newcommand{\iid}{\overset{\scriptscriptstyle\mathsf{iid}}{\sim}}

\DeclareMathOperator{\E}{\textnormal{\ensuremath{\mathbb{E}}}}
\newcommand{\EE}[1]{\E\!\left[{#1}\right]}
% \newcommand{\Ee}[1]{\E[{#1}]}

\newcommand{\Var}[1]{\operatorname{Var}\left[#1\right]} % trace

\newcommand{\Ident}{\mathbbm{1}}
\newcommand{\cond}{\hspace{0.02em}|\hspace{0.08em}}


% environments
\newcounter{examplecntr}
\newenvironment{example}[1][]%
{\begin{trivlist}\small\item[]\refstepcounter{examplecntr}%
  {\bfseries Example~\theexamplecntr%
  \ifthenelse{\equal{#1}{}}{}{ (#1)}.
}}%
{\end{trivlist}}

\newcounter{definitioncntr}
\newenvironment{definition}%
{\begin{trivlist}\item[]\refstepcounter{definitioncntr}%
{\bfseries Definition~\thedefinitioncntr.}}%
{\hfill$\Box$\end{trivlist}}

\newcounter{theoremcntr}
\newenvironment{theorem}[1][]%
{\begin{trivlist}\item[]\refstepcounter{theoremcntr}%
{\bfseries Theorem~\thetheoremcntr%
  \ifthenelse{\equal{#1}{}}{}{ (#1)}.
}}%
{\hfill$\Box$\end{trivlist}}

\newcounter{propositioncntr}
\newenvironment{proposition}[1][]%
{\begin{trivlist}\item[]\refstepcounter{propositioncntr}%
{\bfseries Proposition~\thepropositioncntr%
  \ifthenelse{\equal{#1}{}}{}{ (#1)}.
}}%
{\hfill$\Box$\end{trivlist}}
%{\hfill$\blacksquare$\end{trivlist}}

\newcounter{lemmacntr}
\newenvironment{lemma}[1][]%
{\begin{trivlist}\item[]\refstepcounter{lemmacntr}%
{\bfseries Lemma~\thelemmacntr%
  \ifthenelse{\equal{#1}{}}{}{ (#1)}.
}}%
{\hfill$\Box$\end{trivlist}}


%\newenvironment{proof}{\begin{trivlist}\item[]{\bfseries Proof: }
% }{\hfill$\Box$\end{trivlist}}
  
\newenvironment{proofof}[1]{\begin{trivlist}\item[]{\bfseries Proof\ifthenelse{\equal{#1}{}}{}{ #1}:}
% }{\hfill$\Box$\end{trivlist}}
  }{\hfill$\blacksquare$\end{trivlist}}

\newcommand{\eproofnegspace}{\\[-1.5\baselineskip]\rule{0em}{0ex}}

% ************************************************************************



% misc, project specific
\newcommand{\restrict}[2]{\left.#1\right|_{#2}}
\newcommand{\sgn}{\operatorname{sgn}}

\newcommand{\imk}{{1 - \kappa(s) z}}
%remark while editing
\newcommand{\rem}[1]{{\color{red} {#1}}}

\def\maxs{\max_{\sigma^2}}
\def\mins{\min_{\sigma^2}}

\def\limb{\lim_{b \rightarrow \infty}}
\def\binf{{b \rightarrow \infty}}

\newcommand{\va}{{\sigma_a^2}}
\newcommand{\vb}{{\sigma_b^2}}
\newcommand{\hva}{{{\hat \sigma_a}^2}}
\newcommand{\hvb}{{{\hat \sigma_b}^2}}
\newcommand{\sda}{{\sigma_a}}
\newcommand{\sdb}{{\sigma_b}}

\newcommand{\vak}{{\sigma_{a,k}^2}}
\newcommand{\vbk}{{\sigma_{b,k}^2}}
\newcommand{\hvak}{{\hat \sigma_{a,k}^2}}
\newcommand{\hvbk}{{\hat \sigma_{b,k}^2}}

\def\saa{\sigma_{1,a}^2}
\def\sab{\sigma_{1,b}^2}
\def\sba{\sigma_{2,a}^2}
\def\sbb{\sigma_{2,b}^2}
\def\hsaa{\hat{\sigma}_{1,a}^2}
\def\hsab{\hat{\sigma}_{1,b}^2}
\def\hsba{\hat{\sigma}_{2,a}^2}
\def\hsbb{\hat{\sigma}_{2,b}^2}
\def\mta{m_1}
\def\mtb{m_2}

\newcommand{\muth}{{\mu_\theta}}
\newcommand{\mth}{{m_\theta}}
\newcommand{\mtha}{{m_{\theta_1}}}
\newcommand{\mthb}{{m_{\theta_2}}}
\def\mtht{{\tilde{m}_{\hat \theta}}}
\def\vtht{{\tilde{\sigma}_{\hat \theta}^2}}

\newcommand{\vth}{{\sigma_\theta^2}}
\newcommand{\vtha}{{\sigma_{\theta_1}^2}}
\newcommand{\vthb}{{\sigma_{\theta_2}^2}}


\newcommand{\markblue}[1]{{\color{blue}#1}}
\newcommand{\markred}[1]{{\color{red}#1}}
  







\begin{document}
\title{Model-Predictive Control with New NUV Priors}
\author{Raphael~Keusch and Hans-Andrea Loeliger
        % <-this % stops a space
\thanks{R. Keusch and H.-A.~Loeliger are with the Department of Information
Technology and Electrical Engineering, ETH Zurich, 8092 Zurich, Switzerland
(e-mail: keusch@isi.ee.ethz.ch, loeliger@isi.ee.ethz.ch).}% <-this % stops
}%

% The paper headers
\markboth{XXXXXX}%
{Keusch \MakeLowercase{\textit{et al.}}: Model-Predictive Control with New NUV Priors}
% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
  Normals with unknown variance (NUV) can represent many useful priors 
  including $\text{L}_p$ norms and other sparsifying priors, 
  and they blend well with linear-Gaussian models and Gaussian message passing algorithms.
  In this paper, we elaborate on recently proposed discretizing NUV priors,
  and we propose new NUV representations of half-space constraints and box constraints. 
  We then demonstrate the use of such NUV representations 
  with exemplary applications in model predictive control, 
  with a variety of constraints on the input, the output, or the internal state
  of the controlled system. In such applications, the computations boil down 
  to iterations of Kalman-type forward-backward recursions,
  with a complexity (per iteration) that is linear in the planning horizon.
  In consequence, this approach can handle long planning horizons, 
  which distinguishes it from the prior art.
  For nonconvex constraints, this approach has no claim to optimality, 
  but it is empirically very effective.
\end{abstract}

\begin{IEEEkeywords}
  Normal with unknown variance (NUV); 
  sparse Bayesian learning; 
  composite NUV priors; 
  Gaussian message passing; 
  iteratively reweighted least squares (IRLS); 
  constrained control. 
\end{IEEEkeywords}





\section{Introduction}
\IEEEPARstart{N}{ormal} priors with unknown variance (NUV priors) 
are a central idea of sparse Bayesian learning~\cite{Tipping2001, Tipping2003, Wipf2004, Wipf2008}
and closely related to variational representations of cost functions
and iteratively reweighted least-squares methods~\cite{Bach2012, Daubechies2010, Loeliger2018}.
The point of such priors is the computational compatibility with linear Gaussian models. 
The primary use of such priors has been to encourage sparsity,
in applications including sparse input estimation~\cite{Loeliger2016, Zalmai2017}, 
localized event detection~\cite{zalmai_blind_2016, Zalmai2017a, wadehn_model-based_2020}, 
outlier removal~\cite{wadehn_outlier-insensitive_2016, Wadehn2019}, 
sparse least squares~\cite{Loeliger2018}, control~\cite{Bruderer2015, Hoffmann2017a}, 
and imaging~\cite{Ma2020, ma2022}.


A next step was made by the binarizing NUV prior recently proposed 
in~\cite{keusch2021binaryNUV, Marti21multiuser},
which may be viewed as consisting of two internal NUV priors.
Such composite NUV priors offer many additional possibilities, some of which 
are proposed and explored in this paper.
 

Specifically, in this paper, we propose\footnote{
The first write-ups of these new composite NUV priors 
are~\cite{keusch2021binaryNUVext,keusch2021boxPreprint},
which have not otherwise been published.
}
and explore a new composite NUV prior to enforce half-plane constraints,
and we generalize the mentioned binarizing NUV prior to $M$-level priors with $M>2$.
 



We then demonstrate the use of such NUV priors 
for a variety of constrained control problems. 
In such applications, the computations amount to iterating Kalman-type
forward-backward recursions, with simple closed-form updates 
of the NUV parameters in between.
The computational complexity of each such iteration is linear in ``time''
(i.e., in the planning horizon); in consequence, this approach 
can handle long planning horizons (with high temporal resolution), 
which distinguishes it from the prior art.
For the Kalman-type recursions, we will use an extended version
of the modified Bryson-Frazier (MBF) smoother 
with input estimation as in~\cite{Bruderer2015, Loeliger2016}, 
which does not require any matrix inversions
and is numerically stable.


The related literature of constrained optimization is vast. 
Numerous methods have been developed in the broader field of constrained convex optimization with 
linear inequality constraints---most notably the
projected Newton method~\cite{bertsekas1982projected,kim2010tackling},
the projected gradient method~\cite{rosen1960gradient}, 
the interior-point method~\cite{wright1997primal}, 
and the active set method~\cite{stark1995bounded}.
Generally speaking, the computational complexity of
these methods scales much faster than linearly 
with the number of constraints.


Adding discrete-level constraints generically results in NP-hard problems.
Finding the optimal solution to such problems using exhaustive enumeration is thus 
limited to short planning horizons~\cite{FSQS09}.
Another naive approach is to first solve the unconstrained problem 
and then project the solution to the feasible set;
% and round the solution such that the discrete-level 
% constraints are satisfied. 
unfortunately, most often, the obtained solution is far from optimal.
Tree-search algorithms with branch-and-bound methods such as 
sphere decoding~\cite{hassibi2005sphere, KaGK16} may help, but their complexity is 
still exponential in the planning horizon. By contrast, the approach of this 
paper offers excellent empirical performance with linear complexity in the 
planning horizon.

 

The paper is structured as follows.
In Section~\ref{sec:prob}, the proposed method is described in outline.
In Section~\ref{sec:compositeNUVPriors}, the proposed composite NUV priors are 
described in detail.
Section~\ref{sec:systemModel} describes how such NUV priors are combined with 
standard linear state space models. 
In Section~\ref{sec:algo}, the proposed algorithm is described in detail. 
Section~\ref{sec:app} demonstrates the application of the proposed method 
to a variety of exemplary constrained control problems including 
digital-to-analog conversion, bounded-error control, and minimal-time 
race track control.
  In a companion paper~\cite{Keusch2023LongHorizonMPCStateConstraints}, the approach of this paper is successfully 
applied to a nontrivial real-world control problem.



The following notation is used: 
The set of strictly positive integers is denoted by $\Naturals = \{ 1, 2, 3, \ldots \}$.
The identity matrix of dimension $n$ is denoted by $I_n$, 
and the all-zero matrix of dimension $n \times m$ is denoted by 
$0_{n \times m}$. 
A Gaussian probability density function in $x$ with mean $m$ and 
covariance matrix $V$ is denoted by $\Normal{x; m, V}$. 
Equality of functions up to a scale factor is denoted by $\propto$.
% A variance is denoted by $\sigma^2$.
A superscript in parentheses is used to denote the iteration index of an iterative algorithm; 
for example, $\theta^{(i)}$ denotes the parameter $\theta$ 
in iteration $i$.
The $p$-norm of a vector $x = \bma x_1, \dots, x_n \ema^\T$ is denoted by 
$\|x\|_p = \left( \sum_{k=1}^n |x_k|^p \right)^{1/p}$.

 



\section{Exemplary Control Problems and Outline of the Proposed Approach} \label{sec:prob}
\noindent
Consider a discrete-time linear dynamical system with input signal $u_1, u_2, \ldots \in \Reals$
and output signal $y_1, y_2, \ldots \in \Reals$.
(The generalization to vector-valued inputs and outputs is straightforward.)
For the sake of clarity, we assume that the initial state of the system is known
(and can therefore here be ignored).
Moreover, we assume that the system is causal and deterministic, 
i.e., $y_1, \ldots, y_k$ is a (deterministic) function of $u_1, \ldots, u_k$ for all $k$.

For a given planning horizon $K$ and a given target 
$\breve y = \bma \breve y_1, \ldots, \breve y_K \ema$,
we wish to compute an input signal $u = \bma u_1, \ldots, u_K \ema$
(and a resulting output signal $y = \bma y_1, \ldots, y_K \ema$)
that minimizes some cost function subject to some constraints,
as illustrated by the following examples:

%
\begin{figure}   
  \centering
    \includegraphics{inc/statModel}
    % \vspace{1em}
    \caption{Factor graph of the statistical model with Gaussian inputs and Gaussian likelihoods with unknown parameters.}
    \label{fig:prob:statModel} 
\end{figure}%
%


\begin{example} \label{example:prob:classicControl}
  Classical linear-quadratic control problem:
  \begin{IEEEeqnarray}{rCl}
    \hat u = \argmin_u \|y - \breve y\|^2 + \alpha \|u\|^2
  \end{IEEEeqnarray}
  for some given $\alpha \in\Reals, \alpha > 0$.
  % (Here $\alpha \in \Reals$ is a weight and $\breve y \in \Reals^K$ is a target trajectory.)
\end{example}

\begin{example} Squared fitting error with sparse input (the LASSO problem~\cite{Tibshirani1996}): 
  \begin{IEEEeqnarray}{rCl}
    \hat u = \argmin_u \|y - \breve y\|^2 + \alpha \|u\|_1
  \end{IEEEeqnarray}
  for some given $\alpha \in\Reals, \alpha > 0$.
  % (Here $\alpha \in \Reals$ is a weight and $\breve y \in \Reals^K$ is a target trajectory.)
\end{example}

\begin{example} \label{example:prob:binaryControl}
  Squared fitting error with binary input: 
  \begin{IEEEeqnarray}{rCl} \IEEEyesnumber \phantomsection \label{eqn:prob:binaryControlOptProb}  \IEEEyessubnumber*
    \hat u &=& \argmin_u \|y - \breve y\|^2 \quad \text{s.t.} \label{eqn:prob:binaryControlOptProbQuadPart}\\
         u_k &\in& \{0, 1\} \quad \text{or} \quad u_k \in \{-1, +1\}, \quad k \in \{1, \dots, K\}. \label{eqn:prob:binaryControlOptProbBinConstr}
  \end{IEEEeqnarray}
\end{example}

 

\begin{example} 
$\text{L}_1$ fitting error and bounded input: 
\begin{IEEEeqnarray}{rCl} \IEEEyesnumber \IEEEyessubnumber*
  \hat u &=& \argmin_u \|y - \breve y\|_1 \quad \text{s.t.} \\
       u_k &\in& [a, b], \quad k \in \{1, \dots, K\}
\end{IEEEeqnarray}
for given $a, b \in \Reals$.
\end{example}

\begin{example} Bounded fitting error and sparse input level switches: 
  \begin{IEEEeqnarray}{rCl} \IEEEyesnumber \IEEEyessubnumber*
    \hat u &=& \argmin_u \|\Delta u\|_0 \quad \text{s.t.} \\
        %  a_k &\leq& y_k - \breve y_k \leq b_k, \quad k \in \{1, \dots, K\}
         && | y_k - \breve y_k | \leq b, \quad k \in \{1, \dots, K\}
  \end{IEEEeqnarray}
  for some given $b \in \Reals, b > 0$, and $\Delta u \eqdef \bma u_2 \!-\! u_1, \ldots, u_K \!-\! u_{K-1} \ema$.
\end{example}
%
\noindent
Note that Example~\ref{example:prob:classicControl} is a classical control problem,
which is well-known to be solvable by Kalman-type forward-backward recursions,
with complexity linear in $K$ (cf. Section~\ref{sec:algo}).

The essence of this paper is that all these problems 
(and many other combinations of constraints and cost functions) 
can be efficiently solved (exactly or approximately) by 
an iterative algorithm, where each iteration solves a statistical 
estimation problem that is essentially equivalent to (some variation of)
Example~\ref{example:prob:classicControl}. 
This statistical model is obtained by assuming Gaussian inputs and Gaussian 
likelihoods, i.e., 
\begin{IEEEeqnarray}{rClrCl}
\msgf{p}{}(u_k;\theta_{U_k}) &\eqdef& \Normal{u_k;\msgf{m}{U_k}, \msgf{V}{U_k}},
  & \quad \theta_{U_k} &\eqdef& (\msgf{m}{U_k}, \msgf{V}{U_k}), \label{eqn:prob:inputPrior} \IEEEeqnarraynumspace\\
\msgb{p}{}(y_k;\theta_{Y_k}) &\eqdef& \Normal{y_k;\msgb{m}{Y_k}, \msgb{V}{Y_k}},
& \quad \theta_{Y_k} &\eqdef& (\msgb{m}{Y_k}, \msgb{V}{Y_k}), \label{eqn:prob:outputPrior}
\end{IEEEeqnarray}
for $k \in \{1, \dots, K\}$, see Fig.~\ref{fig:prob:statModel}. 
%
In Example~\ref{example:prob:classicControl}, 
the parameters ($\theta_{U_k}$ and $\theta_{Y_k}$)
are known and fixed;
in the other examples, these parameters are unknown and 
updated in each iteration.

Specifically, the algorithm iterates the following two steps until convergence:
\begin{enumerate}[label=\roman*)]
  \item For fixed NUV parameters $\theta_{U_k}$ and $\theta_{Y_k}$,
  compute the posterior means $m_{U_k}$ and $m_{Y_k}$
  and (if necessary) the posterior variances $V_{U_k}$ and $V_{Y_k}$
  for all inputs $U_k$ and outputs $Y_k$.
  \item Update the NUV parameters $\theta_{U_k}$ and $\theta_{Y_k}$ using 
  Tables~\ref{tab:prob:UpdateRulesNUV} and~\ref{tab:psum:UpdateRulesCNUV}.
\end{enumerate}
Note that Tables~\ref{tab:prob:UpdateRulesNUV} and~\ref{tab:psum:UpdateRulesCNUV} 
give the required update rules 
for the NUV parameters of some generic scalar variable $X$,
which are here applied to $X=U_k$ 
(with $\msgf{m}{X} = \msgf{m}{U_k}$ and 
$\msgf{V}{X} = \msgf{V}{U_k}$, respectively)
and/or $X=Y_k$
(with $\msgf{m}{X} = \msgb{m}{Y_k}$ and 
$\msgf{V}{X} = \msgb{V}{Y_k}$, respectively),
for $k \in \{1, \ldots, K\}$.
More explanations will be given in Section~\ref{sec:systemModel}.
A preview of a first numerical example (a special case of 
Example~\ref{example:prob:binaryControl} above) is shown in Fig.~\ref{fig:prob:dac}. 
%
\begin{figure}
  \centering
  \includegraphics{inc/dac}
  \caption{
  Binary-input control (or digital-to-analog conversion) as in 
  Example~\ref{example:prob:binaryControl} (cf. Section~\ref{sec:DAC}), 
  with target waveform $\breve y$ (dashed),
  binary control signal $u$ computed by the proposed algorithm (bottom), 
  and resulting output signal y (solid blue).
  }
  \label{fig:prob:dac}
\end{figure}
%

The update rules in Table~\ref{tab:prob:UpdateRulesNUV} are not new 
and stated here only for the sake of completeness.
The derivations of the update rules in Table~\ref{tab:psum:UpdateRulesCNUV} 
will be given in Section~\ref{sec:compositeNUVPriors}.




%%%% NUV table 
\begin{table}
  \centering
  % \caption*{NUV Priors}
  \scalebox{0.97}{
  \begin{tabular}[t]{lll}
  \toprule
   Prior & Use case & Update Rules \\
  \toprule
  
  
  \makecell[l]{$\text{L}_1$ (Laplace)\\(see~\cite{Bach2012, Loeliger2018})} & 
  sparsity &
  $\msgf{V}{X} = \gamma^{-1} |m_X|$
  \\
  \midrule

  \makecell[l]{$\text{L}_p$\\(see~\cite{Bach2012, ma2022})} & 
  various &
  $\displaystyle \msgf{V}{X} = \frac{|m_X|^{2-p}}{\gamma p}$
  \\
  \midrule


  \makecell[l]{Smoothed $\text{L}_1$/Huber\\(see~\cite{Loeliger2018, ma2022})} & 
  \makecell[l]{ outlier-\\insensitive\\fitting} &
  $\displaystyle \msgf{V}{X} = \max \left \{ r^2, \frac{|m_X|}{\gamma} \right \}$
  \\
  \midrule

  \makecell[l]{Plain NUV\\(see~\cite{Loeliger2016})} & 
  \makecell[l]{ sparsity/jumps \\in a state\\ space model} &
  $\msgf{V}{X} = V_X + m_X^2$
  \\
  \midrule

  \makecell[l]{Smoothed plain NUV\\(see~\cite{Ma2020, ma2022})} & 
  \makecell[l]{outlier-\\insensitive\\fitting} &
  \makecell[l]{ 
  $\msgf{V}{X} = \max \left \{ r^2, m_X^2 \right \} \quad $ or \\
  $\msgf{V}{X} = \max \left \{ r^2, V_X + m_X^2 \right \}$
  }
  \\
  \bottomrule
  \\
  \end{tabular}
  }
\caption{Update rules for the most useful basic NUV priors, with parameters 
$\gamma$ and $r^2$, cf.\ the cited references. (The mean $\msgf{m}{X}$ remains zero.)
\vspace{0.4em}
}
\label{tab:prob:UpdateRulesNUV}
\end{table}



\begin{table}
  \centering
  % \caption*{Composite NUV Priors}
  \scalebox{.87}{
  \begin{tabular}[t]{lll}
  \toprule
    Prior & Constraint  & Update Rules \\
  \toprule
  \multirow{3}{*}{\makecell[l]{\vspace{0mm}\\Half-space prior\\(Section~\ref{sec:halfSpacePrior})}} & 
  $x \geq a$ & 
  % AM &
  \makecell[l]{ 
    % $\msgf{V}{X} = \gamma^{-1} \left | m_X - a \right| $ \vspace{0.1cm} \\ 
    $\displaystyle \msgf{V}{X} = \frac{\left | m_X - a \right|}{\gamma} $ \vspace{0.1cm} \\ 
    $\msgf{m}{X} = a + \left | m_X - a \right|$ \vspace{0.15cm}
  } 
  \\
  \cline{2-3}
    & $x \leq a$ & 
  %  AM & 
    \rule{-3pt}{6.5ex} 
  \makecell[l]{
    % $\msgf{V}{X} = \gamma^{-1} \left | m_X - a \right| $ \vspace{0.1cm} \\
    $\displaystyle \msgf{V}{X} = \frac{\left | m_X - a \right|}{\gamma} $ \vspace{0.1cm} \\ 
    $\msgf{m}{X} = a - \left | m_X - a \right|$  \vspace{0.1cm}
    } 
    \\
    \midrule
  \makecell[l]{Box prior\\(Section~\ref{sec:boxPrior})} & 
  $a \leq x \leq b$ \hspace*{-1.5em}& 
  % AM &
  \makecell[l]{ 
    % $\msgf{V}{X} = \gamma^{-1} \left (\left | m_X - a \right|^{-1} + \left | m_X - b \right|^{-1} \right )^{-1}$ \\
    $\displaystyle \msgf{V}{X} =  \left ( \frac{\gamma}{\left | m_X - a \right|} + \frac{\gamma}{\left | m_X - b \right|} \right )^{-1}$  \vspace{0.2cm} \\
    % $\msgf{m}{X} = \gamma  \msgf{V}{X}  \left ( a \left | m_X - a \right|^{-1} + b \left | m_X - b \right|^{-1} \right)$ 
    $\displaystyle \msgf{m}{X} = \msgf{V}{X}  \left ( \frac{\gamma a}{\left | m_X - a \right|} + \frac{\gamma b}{\left | m_X - b \right|} \right)$ \vspace{0.1cm} \\
    % $\displaystyle \phantom{\msgf{m}{X}} = \begin{cases} m_X & \text{if} \; a \leq x \leq b, \\ \frac{m_X (a+b) - 2ab}{2 m_X - (a+b)} & \text{otherwise}  \end{cases}$ 
  } 
  \\
  \midrule


  \makecell[l]{Binarizing prior\\(\cite{keusch2021binaryNUV} and\\Section~\ref{sec:binaryPrior})} & 
  $x \in \{a, b\}$ \hspace*{-1.5em}& 
  % EM & 
  \makecell[l]{ 
    % $\msgf{V}{X}= \left [ \left( V_X + (m_{X} - a )^2 \right )^{-1} +\left(V_X + (m_{X} - b )^2 \right)^{-1} \right ]^{-1}$  \vspace{0.1cm}\\ 
    $\displaystyle \msgf{V}{X}= \left ( \! \frac{1}{ V_X \!+\! (m_{X} \!-\! a )^2 } \!+\! \frac{1}{V_X \!+\! (m_{X} \!-\! b )^2 } \! \right )^{\!-1}$  \vspace{0.1cm}\\ 
    % $\msgf{m}{X} = \msgf{V}{X}\left [ a \left( V_X + (m_{X} - a )^2 \right )^{-1} + b \left(V_X + (m_{X} - b )^2 \right)^{-1} \right ]$   
    $\displaystyle \msgf{m}{X} = \msgf{V}{X} \! \left ( \! \frac{a}{ V_X \!+\! (m_{X} \!-\! a )^2 } \!+\! \frac{b}{V_X \!+\! (m_{X} \!-\! b )^2 } \! \right )$   \vspace{0.1cm}
  } \hspace*{-1.5em}
  \\
  \bottomrule
  \\
  \end{tabular}
  }
\caption{Update rules for the composite NUV priors of Section~\ref{sec:compositeNUVPriors}.
  }
\label{tab:psum:UpdateRulesCNUV}
\end{table}



% \clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Composite NUV Priors} \label{sec:compositeNUVPriors}
\noindent
In this section, we provide detailed derivations of the update rules stated 
in Table~\ref{tab:psum:UpdateRulesCNUV}.

We begin with a box prior, which constrains a model variable $x \in \Reals$ to be lower- 
and upper-bounded, i.e., $a \leq x \leq b$ with $a, b \in \Reals$.
From the box prior, we derive a half-space prior, which constrains $x$ to be lower bounded or upper bounded, 
i.e., $x \geq a$ or $x \leq a$. 
Third, we describe a binarizing prior, which constrains  
$x$ to take values in a finite set with two elements, i.e, $x \in \{a, b\}$, 
with $a, b \in \Reals$. 
And finally, we discuss generalizations of the binarizing prior to $M > 2$ levels. 

In this section, we will describe and analyze these priors in a scalar setting; 
the sequence setting will be discussed in Section~\ref{sec:systemModel}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Box Prior} \label{sec:boxPrior}
\subsubsection{The Prior} \label{sec:box:thePrior}

 The proposed NUV representation of the box constraint is obtained as an almost 
 obvious combination of two ideas:  
\begin{itemize}
  \item The (well-known) NUV representation of the Laplace prior~\cite{Bach2012,Loeliger2018}.
  \item Adding two cost functions of the form $|x-a|$ and $|x-b|$ to
  create a cost function that is constant for $x \in [a, b]$, 
  as illustrated in Fig.~\ref{fig:box:CostBoxPrior}. (This idea is closely related 
  to sum of absolute values (SOAV) optimization~\cite{nagahara2015discrete}.)
\end{itemize}
\noindent 
% \\
% \vspace{0.1em}
Specifically, we will use the cost function 
\begin{IEEEeqnarray}{rCl}
  \kappa(x) \eqdef \gamma \big ( |x-a| + |x-b| - |b-a| \big ) \label{eqn:box:CostFunctionBoxPrior}
\end{IEEEeqnarray}
with sufficiently large $\gamma>0$ (as discussed in Section~\ref{sec:box:trivialExample}) 
and the associated prior\footnote{$p(x)$ is not properly normalized, but can be so.}
\begin{IEEEeqnarray}{rCl} \label{eqn:box:priorModelEffective}
  p(x) \eqdef \exp \! \big(-\kappa(x) \big ).
\end{IEEEeqnarray}
%
For the NUV representation, we first recall that the Laplace prior has the  
NUV representation
%
\begin{figure}   
  \centering
    \includegraphics{inc/boxConstraintCostFunc}
    \caption{Cost function~(\ref{eqn:box:CostFunctionBoxPrior}) (solid blue) 
    for $a=-1, b=1$ and $\gamma = 1$.}
    \label{fig:box:CostBoxPrior} 
\end{figure}
%
\begin{IEEEeqnarray}{rCl}
  \exp \! \big (\!-\! \gamma |x| \big ) = \max_{\sigma^2} \Normal{x; 0, \sigma^2} \tilde \rho(\sigma^2), \label{eqn:box:laplaceNUVrep}
\end{IEEEeqnarray}
with $\gamma > 0$ and with 
$\tilde \rho(\sigma^2) \eqdef \sqrt{2 \pi \sigma^2} e^{-\gamma^2 \sigma^2/2}$~\cite{Loeliger2018}.
% \begin{IEEEeqnarray}{rCl}
%   \tilde \rho(\sigma^2) \eqdef \sqrt{2 \pi \sigma^2} \Exp{- \frac{\gamma^2 \sigma^2}{2}}.
% \end{IEEEeqnarray}
Furthermore, the maximizing variance in~(\ref{eqn:box:laplaceNUVrep}) is
\begin{IEEEeqnarray}{rCl} \label{eqn:box:laplaceSigmaHat}
  \hat \sigma^2 = \argmax_{\sigma^2} \Normal{x;0, \sigma^2} \tilde \rho(\sigma^2) = \frac{|x|}{\gamma}. 
\end{IEEEeqnarray}
The NUV representation of the prior~(\ref{eqn:box:priorModelEffective}) is then obtained as
\begin{IEEEeqnarray}{rCl}
  p(x) &=& \exp \! \big (\!-\! \gamma |x-a| \big ) \cdot \exp \! \big (\!-\! \gamma |x-b| \big ) \\
  &=& \max_{\va} \Normal{x;a, \va} \tilde \rho(\va) \cdot \max_{\vb} \Normal{x;b, \vb} \tilde \rho(\vb), \IEEEeqnarraynumspace \label{eqn:box:NUVrep}
\end{IEEEeqnarray}
where we ignored the irrelevant constant term in~(\ref{eqn:box:CostFunctionBoxPrior}).
From~(\ref{eqn:box:laplaceSigmaHat}), the maximizing variances in~(\ref{eqn:box:NUVrep}) are
% 
\begin{IEEEeqnarray}{rCl}
  \hva = \frac{|x-a|}{\gamma} \quad \text{and} \quad \hvb = \frac{|x-b|}{\gamma}. \label{eqn:box:boxOptimalVars}
\end{IEEEeqnarray}
%
We further note that~(\ref{eqn:box:NUVrep}) can be written as a (single) 
Gaussian probability density in $x$ and a scale factor that does 
not depend on $x$. Specifically, the prior can be written as 
\begin{IEEEeqnarray}{rCl} \label{eqn:box:decomposedRep}
  p(x) &=& \max_{\theta} p(x, \theta) = \max_{\theta} p(x \cond \theta) \rho(\theta)   \label{eqn:box:priorModelExp}
\end{IEEEeqnarray}
with
\begin{IEEEeqnarray}{rCl} \label{eqn:box:boxPriorGaussianPart}
  p(x \cond \theta) = \Normal{x;\mth, \vth}
\end{IEEEeqnarray} 
and 
\begin{IEEEeqnarray}{rCl} \label{eqn:box:scaleFactorRho}
  \rho(\theta) &=& \Normal{a-b;0, \va + \vb} 
                  \tilde \rho(\va) \tilde \rho(\vb), 
\end{IEEEeqnarray}
where $\theta \eqdef (\va, \vb)$, %$\psi(\gamma, a, b) \eqdef e^{\gamma |b-a|}$,
\begin{IEEEeqnarray}{rCl} \label{eqn:box:boxPriorMeanVar}
  \vth = \left ( \frac{1}{\va} + \frac{1}{\vb} \right)^{-1} \!\!\!\!, \;\; \text{and} \;\; \mth = \vth \left ( \frac{a}{\va} + \frac{b}{\vb} \right).
\end{IEEEeqnarray}
% 
Note that $p(x, \theta)$ in~(\ref{eqn:box:priorModelExp}) can be seen as a 
(improper) joint prior on~$X$ and~$\theta$.
The derivation 
of~(\ref{eqn:box:boxPriorGaussianPart})--(\ref{eqn:box:boxPriorMeanVar}) follows 
from standard properties of Gaussian probability densities, cf.~\cite[Section 1]{bromiley2003products}.
(The factor~(\ref{eqn:box:scaleFactorRho}) will actually not be used below.)

Finally, plugging the maximizing variances~(\ref{eqn:box:boxOptimalVars}) 
into~(\ref{eqn:box:boxPriorMeanVar}) yields the closed-form update 
rules 
\begin{IEEEeqnarray}{rCl}
  \msgf{V}{X} &=& \left ( \frac{\gamma}{\left | x - a \right|} + \frac{\gamma}{\left | x - b \right|} \right )^{-1} \label{eqn:box:VXfBox}\\
  \msgf{m}{X} &=& \msgf{V}{X}  \left ( \frac{\gamma a}{\left | x - a \right|} + \frac{\gamma b}{\left | x - b \right|} \right), \label{eqn:box:mXfBox}
\end{IEEEeqnarray}
which are given in Table~\ref{tab:psum:UpdateRulesCNUV} (in slightly different notation).
In summary, the NUV representation of the box constraint amounts to a Gaussian prior 
(up to a scale factor) with mean and variance given by~(\ref{eqn:box:mXfBox}) 
and~(\ref{eqn:box:VXfBox}), respectively.





\subsubsection{Analysis of the Scalar Case} \label{sec:box:trivialExample}


In order to study the constraining effect of the proposed prior,
we now assume that the joint prior $p(x, \theta)$ in~(\ref{eqn:box:priorModelExp}) is used 
in some model with fixed observation(s) $\breve y$
and likelihood function $p(\breve y \cond x)$. 
Moreover, we assume $p(\breve y \cond x)$ to be Gaussian in $x$, 
with mean $\mu$ and variance $s^2$ depending on $\breve y$,
i.e.,
\begin{IEEEeqnarray}{rCl} \label{eqn:box:GaussianLikelihood}
p(\breve y \cond x) \eqdef \Normal{x;\mu, s^2}.
\end{IEEEeqnarray}
The resulting statistical model is 
\begin{IEEEeqnarray}{rCl} \label{eqn:box:statModelTrivialEx}
  p(\breve y \cond x) p(x, \theta) &=& \Normal{x; \mu, s^2} \cdot
   \Normal{x; a, \va}  \tilde \rho(\sigma_a) \nonumber \\
   && \cdot \Normal{x; b, \vb}  \tilde \rho(\sigma_b),
\end{IEEEeqnarray}
which is illustrated as factor graph~\cite{Loeliger2004} in Fig.~\ref{fig:box:FGTrivialExample}.
%
\begin{figure}
  \centering
  \includegraphics[scale=0.87]{inc/FGTrivialExample}
  % \vspace{1em}
  \caption{Factor graph representation of statistical model~(\ref{eqn:box:statModelTrivialEx}). 
  The boxes labeled $\Normal{0, \sigma^2}$ represent zero-mean normal probability density functions.
  } 
  \label{fig:box:FGTrivialExample}
\end{figure}


Assume now that $x$ and $\theta$ are determined by joint MAP estimation according to
\begin{IEEEeqnarray}{rCl} \label{eqn:box:JointMAPEstimateBox}
  \hat x &=& \argmax_{x} \max_\theta  p(\breve y \cond x)  p(x , \theta),
\end{IEEEeqnarray}
with $p(x, \theta)$ as in~(\ref{eqn:box:decomposedRep}).
%
In the scalar setting of this section, the estimate~(\ref{eqn:box:JointMAPEstimateBox}) 
can certainly be computed numerically,
but such a brute-force approach does not generalize 
to the sequence setting of Section~\ref{sec:systemModel}.
With that generalization in mind, we consider 
computing~(\ref{eqn:box:JointMAPEstimateBox}) by alternating maximization (AM)
over $x$ and $\theta$. As mentioned,
the maximization over $\theta$ in~(\ref{eqn:box:JointMAPEstimateBox}) 
can be carried out explicitly, and~(\ref{eqn:box:JointMAPEstimateBox})
can be solved by iteratively maximizing 
\begin{IEEEeqnarray}{rCl}
  \hat x &=& \argmax_x p(\breve y \cond x) \Normal{x; \msgf{m}{X}, \msgf{V}{X}}, \label{eqn:box:jointMAPSimplified} 
\end{IEEEeqnarray}
and updating $\msgf{m}{X}$ and $\msgf{V}{X}$ according to~(\ref{eqn:box:mXfBox}) and~(\ref{eqn:box:VXfBox}).
More specifically, we alternate the following two steps in iterations $i=1, 2, 3, \ldots$:
\begin{enumerate}[label=\roman*)]
\item
  For fixed $\msgf{m}{X}^{(i-1)}$ and $\msgf{V}{X}^{(i-1)}$, 
  compute the MAP estimate
  \begin{IEEEeqnarray}{rCl}
    \hat x^{(i)} 
    & = & \argmax_{x} p(\breve y \cond x) \Normal{x; \msgf{m}{X}^{(i-1)}, \msgf{V}{X}^{(i-1)}} \label{eqn:box:xHatAM}\\
    & = & 
      \left( \frac{1}{\msgf{V}{X}^{(i-1)}} + \frac{1}{s^2} \right)^{-1} 
      \!\! \left( \frac{\msgf{m}{X}^{(i-1)}}{\msgf{V}{X}^{(i-1)}} + \frac{\mu}{s^2} \right)\!. \IEEEeqnarraynumspace
    \end{IEEEeqnarray}
\item
  For fixed $x = \hat x^{(i)}$, compute $\msgf{m}{X}^{(i)}$ and $\msgf{V}{X}^{(i)}$ 
  according to~(\ref{eqn:box:mXfBox}) and~(\ref{eqn:box:VXfBox}), respectively. 
\end{enumerate}
%
Note that this AM is guaranteed to converge to a local 
maximum or a saddle point, provided that the underlying objective function is 
smooth; in the present case, the estimate~(\ref{eqn:box:xHatAM}) is thus 
guaranteed to converge to~(\ref{eqn:box:JointMAPEstimateBox}).

Some numerical results with the estimate~(\ref{eqn:box:JointMAPEstimateBox}) are shown
in Fig.~\ref{fig:box:boxConstChar}.
%
\begin{figure}
  \centering
  \includegraphics{inc//boxConstraintChar}
  \caption{Estimate~(\ref{eqn:box:JointMAPEstimateBox}) for $a=-1$, $b=1$, $\gamma=1$, and
  different values of $s^2$. The unknown parameters were initialized to $\msgf{m}{X}^{(0)} = 0$ 
  and $\msgf{V}{X}^{(0)} = 1$.} 
  \label{fig:box:boxConstChar}
\end{figure}  
%
We observe that for given $\mu$ and $\gamma > 0$, and 
sufficiently large $s^2$, the estimate (\ref{eqn:box:JointMAPEstimateBox}) is 
indeed restricted to $a \leq \hat x \leq b$. 
Quantitatively, we have
\begin{theorem} \label{theorem:box:hardConstraint}
The estimate~(\ref{eqn:box:JointMAPEstimateBox}) satisfies $a \leq \hat x \leq b$ 
if and only if
\begin{IEEEeqnarray}{rCl} \label{eqn:box:HardCondition}
  s^2 > \begin{cases}
  0 & \text{if $a \leq \mu \leq b$}, \\
  \min \left \{ \frac{|a-\mu|}{2\gamma}, 
                \frac{|b - \mu|}{2\gamma} \right \} &
  \text{otherwise}.
  \end{cases} 
\end{IEEEeqnarray}
\end{theorem}
\noindent
Since $\gamma$ is a free design parameter, it can essentially always be chosen 
so that $a \leq \hat x \leq b$.
The proof of Theorem~\ref{theorem:box:hardConstraint} is given in 
Appendix~\ref{sec:apds:ProofBox}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Half-Space Prior} \label{sec:halfSpacePrior}

\subsubsection{The Prior}

Taking the limit $b\rightarrow\infty$ in~(\ref{eqn:box:CostFunctionBoxPrior}) 
yields 
% the cost function of a right-sided half-space prior 
\begin{IEEEeqnarray}{rCl} \label{eqn:hsc:costFuncPlus}
  \kappa(x) &=& %\lim_\binf  \gamma ( |x-a| + |x-b| - |b-a| ) = 
  \begin{cases} 2 \gamma (a - x) & \text{if $x < a$},  \\ 
              0 &\text{otherwise},
  \end{cases} \IEEEeqnarraynumspace 
\end{IEEEeqnarray}
and taking the limit $b\rightarrow -\infty$ in~(\ref{eqn:box:CostFunctionBoxPrior}) 
yields 
% the cost function of a left-sided half-space prior
\begin{IEEEeqnarray}{rCl} \label{eqn:hsc:costFuncMinus}
  \kappa(x) &=& %\lim_{b \rightarrow - \infty}  \gamma ( |x-a| + |x-b| - |b-a| )= 
  \begin{cases} 0 & \text{if $x < a$}, \\ 
    2 \gamma (x - a) &\text{otherwise}.
\end{cases} \IEEEeqnarraynumspace
\end{IEEEeqnarray}
%
The cost function~(\ref{eqn:hsc:costFuncPlus}) 
%and~(\ref{eqn:hsc:costFuncMinus}) 
is shown in Fig.~\ref{fig:hsc:costFuncPlus}.
% and Fig.~\ref{fig:hsc:costFuncMinus}, respectively.

By taking the limit $b \rightarrow \infty$ in~(\ref{eqn:box:VXfBox}) 
and~(\ref{eqn:box:mXfBox}), we further obtain
\begin{IEEEeqnarray}{rCl}
  \msgf{V}{X} &=& \lim_{\binf} \left ( \frac{\gamma}{\left | x - a \right|} + \frac{\gamma}{\left | x - b \right|} \right )^{-1} 
  = \frac{|x - a|}{\gamma} \label{eqn:hsc:mXfHscRight}\\
  \msgf{m}{X} &=& \lim_{\binf} \msgf{V}{X}  \left ( \frac{\gamma a}{\left | x - a \right|} + \frac{\gamma b}{\left | x - b \right|} \right) 
  = a + |x - a| \label{eqn:hsc:VXfHscRight} \IEEEeqnarraynumspace
\end{IEEEeqnarray}
for the right-sided half-space prior, and by taking the limit 
$b \rightarrow -\infty$ in~(\ref{eqn:box:VXfBox}) and~(\ref{eqn:box:mXfBox}), 
we obtain
\begin{IEEEeqnarray}{rCl}
  \msgf{V}{X} &=& 
  \frac{|x - a|}{\gamma} \label{eqn:hsc:mXfHscLeft}\\
  \msgf{m}{X} &=& 
  a - |x - a| \label{eqn:hsc:VXfHscLeft}
\end{IEEEeqnarray}
for the left-sided half-space prior, 
which are the update rules in Table~\ref{tab:psum:UpdateRulesCNUV} 
(in slightly different notation).
%
\begin{figure}
  \centering
  \includegraphics{inc/CostBoxPriorPlanePlus}
  \caption{Cost function~(\ref{eqn:hsc:costFuncPlus}) 
  of a ride-sided half-space prior, for $a = 0$ and different
  values of $\gamma$.
  }
  \label{fig:hsc:costFuncPlus}
  \end{figure}




\subsubsection{Analysis of the Scalar Case} \label{sec:hsc:trivialExample}

We proceed to examine the proposed prior in 
a model as in Section~\ref{sec:box:trivialExample}, with $p(\breve y \cond x)$ as 
in~(\ref{eqn:box:GaussianLikelihood}). Analogously, we compute the estimate
\begin{IEEEeqnarray}{rCl}
    \hat x &=& \argmax_x p(\breve y \cond x) \Normal{x; \msgf{m}{X}, \msgf{V}{X}} \label{eqn:hsc:jointMAPSimplified} 
\end{IEEEeqnarray}
by iterating the two steps outlined in Section~\ref{sec:box:trivialExample}, 
except that $\msgf{m}{X}$ and $\msgf{V}{X}$ are updated according 
to~(\ref{eqn:hsc:VXfHscRight}) and~(\ref{eqn:hsc:mXfHscRight}), or 
(\ref{eqn:hsc:VXfHscLeft}) and~(\ref{eqn:hsc:mXfHscLeft}), respectively.
%
More specifically, we alternate the following two steps in iterations $i=1, 2, 3, \ldots$:
\begin{enumerate}[label=\roman*)]
\item
  For fixed $\msgf{m}{X}^{(i-1)}$ and $\msgf{V}{X}^{(i-1)}$, 
  compute the MAP estimate
  \begin{IEEEeqnarray}{rCl}
    \hat x^{(i)} 
    & = & \argmax_{x} p(\breve y \cond x) \Normal{x; \msgf{m}{X}^{(i-1)}, \msgf{V}{X}^{(i-1)}} \label{eqn:hsc:xHatAM}\\
    & = & 
      \left( \frac{1}{\msgf{V}{X}^{(i-1)}} + \frac{1}{s^2} \right)^{-1} 
      \!\! \left( \frac{\msgf{m}{X}^{(i-1)}}{\msgf{V}{X}^{(i-1)}} + \frac{\mu}{s^2} \right)\!. \IEEEeqnarraynumspace
    \end{IEEEeqnarray}
\item
  For fixed $x = \hat x^{(i)}$, compute $\msgf{m}{X}^{(i)}$ and $\msgf{V}{X}^{(i)}$ 
  according to~(\ref{eqn:hsc:VXfHscRight}) and~(\ref{eqn:hsc:mXfHscRight}), or 
  (\ref{eqn:hsc:VXfHscLeft}) and~(\ref{eqn:hsc:mXfHscLeft}), respectively.
\end{enumerate}
%
Some numerical results of the estimate~(\ref{eqn:hsc:jointMAPSimplified}) are
shown in Fig.~\ref{fig:hsc:halfPlaneConstraintChar}.
%
\begin{figure}
  \centering
  \includegraphics{inc/halfPlaneConstraintChar}
  \caption{Estimate~(\ref{eqn:hsc:jointMAPSimplified}) for $a=0$, $\binf$, $\gamma=1$, and
  different values for $s^2$. The unknown parameters were initialized to $\msgf{m}{X}^{(0)} = 0$ 
  and $\msgf{V}{X}^{(0)} = 1$. }
  \label{fig:hsc:halfPlaneConstraintChar}
  % \vspace{1em}
\end{figure}
%
We observe that for any fixed $\mu$ and $\gamma$, and 
sufficiently large $s^2$, 
the estimate~(\ref{eqn:hsc:jointMAPSimplified}) 
indeed satisfies $\hat x \geq a$. Quantitatively, we have
\begin{theorem} \label{theorem:hsc:hardConstraint}
  For a right-sided constraint, 
  the estimate~(\ref{eqn:hsc:jointMAPSimplified}) satisfies
  $\hat x \geq a$ if and only if 
  \begin{IEEEeqnarray}{rCl} \label{eqn:hsc:HardConditionHPRight}
    s^2 >  \begin{cases}
      0 & \text{if $\mu \geq a$}, \\
      \frac{|a-\mu|}{2\gamma} &
      \mathrm{otherwise}.
      \end{cases} 
  \end{IEEEeqnarray}
  Analogously, for a left-sided constraint, 
  % $\hat x$ is upper-bounded by $a$, i.e., 
  $\hat x \leq a $ if and only if 
  \begin{IEEEeqnarray}{rCl} \label{eqn:hsc:HardConditionHPLeft}
    s^2 >  \begin{cases}
      0 & \text{if $\mu \leq a$}, \\
      \frac{|a-\mu|}{2\gamma} &
      \mathrm{otherwise}.
      \end{cases}
  \end{IEEEeqnarray}
\end{theorem}
\noindent
Note that since $\gamma$ is a free design 
parameter,~(\ref{eqn:hsc:HardConditionHPRight}) (or~(\ref{eqn:hsc:HardConditionHPLeft}),
respectively) can essentially always be satisfied.
The proof of Theorem~\ref{theorem:hsc:hardConstraint} is easily obtained as a 
suitably simplified version of the proof of Theorem~\ref{theorem:box:hardConstraint}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Binarizing Prior}
\label{sec:binaryPrior}
\noindent
In this section, we discuss the composite NUV representation of a binarizing 
constraint (enforcing $x\in \{ a, b\}$) that was proposed in~\cite{keusch2021binaryNUV}.


\subsubsection{The Prior} \label{sec:disc:binModel}
Consider
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:TwoLvlPrior}
p(x, \theta) \eqdef \Normal{x; a, \va} \Normal{x; b, \vb},
\end{IEEEeqnarray}
where $\theta \eqdef (\va, \vb)$
is a shorthand for the two variances in~(\ref{eqn:disc:TwoLvlPrior}).
It turns out that this prior strongly prefers $X$ to lie in $\{ a, b\}$.
The detailed working of this binarizing effect depends
on how the unknown variances $\theta$ are determined.
Two different ways to estimate these variances 
are considered in Sections \ref{sec:disc:JointMAP} and~\ref{sec:disc:TypeII}.

Before examining this binarizing effect, 
we first note that, for fixed variances $\theta$,
$p(x, \theta)$ is a Gaussian probability density in $x$ (up to a scale factor).
Specifically, $p(x, \theta)$ can be written as
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:PriorWithHyperPrior}
p(x, \theta) = p(x \cond \theta) \rho(\theta)
\end{IEEEeqnarray}
with
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:ScalarPriorWithFixedTheta}
p(x \cond \theta) = \Normal{x; \mth, \vth}, 
\end{IEEEeqnarray}
and $\mth$ and $\vth$ as in~(\ref{eqn:box:boxPriorMeanVar}), and with 
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:HyperPrior}
\rho(\theta) =  \Normal{a-b; 0, \va + \vb}.
      % \frac{1}{\sqrt{2\pi (\va + \vb)}}
      % \exp\!\left( \frac{-(a-b)^2}{2(\va + \vb)} \right).
\end{IEEEeqnarray}
%

\subsubsection{Cost Function for MAP Estimation}
Assume for now that the unknown variances $\theta$ are 
determined by
\begin{IEEEeqnarray}{rCl} 
  \hat \theta = \argmax_\theta p(x, \theta).  \label{eqn:disc:jointPriorMax}
\end{IEEEeqnarray}
(However, we will see that estimating $\theta$ as in Section~\ref{sec:disc:TypeII} works much better.) 
We then obtain
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:binPriorOptimalVar}
  \hat \theta =  (\hva, \hvb) = \left ( (x - a)^2,  (x - b)^2 \right ),
\end{IEEEeqnarray}
cf.~Appendix~\ref{sec:apds:binVariances}.
The effective prior is then obtained by plugging~(\ref{eqn:disc:binPriorOptimalVar}) 
into~(\ref{eqn:disc:TwoLvlPrior}), resulting in 
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:binPriorEffective}
  p(x) \eqdef p(x, \hat \theta) \propto \frac{1}{|x-a| \cdot |x-b|}
\end{IEEEeqnarray}
with associated cost function 
\begin{IEEEeqnarray}{rCl}
  \kappa(x) = -\log p(x) =  \log|x-a| +  \log|x-b| + \operatorname{const.} 
  \IEEEeqnarraynumspace
  \label{eqn:disc:CostFunctionBinPrior} 
\end{IEEEeqnarray}
The cost function~(\ref{eqn:disc:CostFunctionBinPrior}) is illustrated in Fig.~\ref{fig:disc:costFuncBinPrior}.
It is obvious that such a prior 
strongly favors $X$ to lie in $\{a, b\}$.
%
\begin{figure}
  \centering
  \includegraphics[]{inc/effectiveBinaryCostFunc}
  \caption{The cost function~(\ref{eqn:disc:CostFunctionBinPrior}) for $a=0$ and $b=1$.}
  \label{fig:disc:costFuncBinPrior}%
  \end{figure}


\subsubsection{Analysis of the Scalar Case}
In order to further study the binarizing effect of the proposed prior,
we now assume that~(\ref{eqn:disc:TwoLvlPrior}) is used in a model 
as in Section~\ref{sec:box:trivialExample}, with $p(\breve y \cond x)$ as 
in~(\ref{eqn:box:GaussianLikelihood}).
A factor graph of the resulting statistical model
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:BinaryPriorWithGaussianLikelihood}
p(\breve y \cond x) p(x, \theta)
= \Normal{x; \mu, s^2} \Normal{x; a, \va} \Normal{x; b, \vb} \IEEEeqnarraynumspace
\end{IEEEeqnarray}
is shown in Fig.~\ref{fig:disc:BinaryPriorWithGaussianLikelihood}.
%
\begin{figure}
  \centering
  \includegraphics[scale=0.85]{inc/FGBinaryPrior}
  % \vspace{1em}
  \caption{%
  Factor graph of~(\ref{eqn:disc:BinaryPriorWithGaussianLikelihood})
  for fixed $\breve y$,
  with parameters $\mu$ and $s^2$ depending on $\breve y$.
  }
  \label{fig:disc:BinaryPriorWithGaussianLikelihood}
\end{figure}

As mentioned, the detailed working of the binarizing effect of $p(x, \theta)$ 
depends on how the unknown variances $\theta$ are determined.
Two different ways to estimate these variances 
are considered in Sections~\ref{sec:disc:JointMAP} and~\ref{sec:disc:TypeII}.
Empirically, the method of Section~\ref{sec:disc:TypeII} works much better than
the method of Section~\ref{sec:disc:JointMAP},
which confirms what has long been known for other NUV priors~\cite{Giri2016}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Joint MAP Estimation}
\label{sec:disc:JointMAP}

An obvious approach to estimate $x$ and $\theta$
is by joint MAP estimation,
which results in
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:hatXJointMAP2}
\hat x 
& = & \argmax_{x} \max_{\theta} p(\breve y \cond x) p(x, \theta) 
      \IEEEeqnarraynumspace\label{eqn:disc:ScalarAM}\\
& = & \argmax_{x} 
     p(\breve y \cond x) p(x) \\
& = & \argmax_x  \frac{\Normal{x; \mu, s^2}}{|x-a|\cdot|x-b|}.
      \label{eqn:disc:ScalarJointMAPx}
\end{IEEEeqnarray}
%
In the scalar setting of this section, the estimate 
(\ref{eqn:disc:ScalarAM}) can certainly be computed numerically for any $s^2$,
but such a brute-force approach does not generalize 
to the sequence setting of Section~\ref{sec:systemModel}.
With that generalization in mind,
we now consider computing (\ref{eqn:disc:ScalarAM}) 
by AM over $x$ and $\theta$.
As in Section~\ref{sec:box:thePrior}, we precompute the maximization 
over $\theta$ by plugging the maximizing variances~(\ref{eqn:disc:binPriorOptimalVar}) 
into~(\ref{eqn:box:boxPriorMeanVar}), resulting in the closed-form update rules 
\begin{IEEEeqnarray}{rCl}
  \msgf{V}{X} &=& \left ( \frac{1}{  (x - a )^2 } + \frac{1}{ (x - b )^2 } \right )^{-1} \label{eqn:disc:VXfAM}\\ 
  \msgf{m}{X} &=& \msgf{V}{X}  \left ( \frac{a}{  (x - a )^2 } + \frac{b}{ (x - b )^2 } \right ). \label{eqn:disc:mXfAM}
\end{IEEEeqnarray}
Consequently, computing~(\ref{eqn:disc:hatXJointMAP2}) by AM
amounts to computing 
\begin{IEEEeqnarray}{rCl}
    \hat x &=& \argmax_x p(\breve y \cond x) \Normal{x; \msgf{m}{X}, \msgf{V}{X}} \label{eqn:disc:jointMAPSimplifiedAM} 
\end{IEEEeqnarray}
by iterating the two steps outlined in Section~\ref{sec:box:trivialExample}, 
except that $\msgf{m}{X}$ and $\msgf{V}{X}$ are updated according 
to~(\ref{eqn:disc:mXfAM}) and~(\ref{eqn:disc:VXfAM}).
%
More specifically, we alternate the following two steps in iterations $i=1, 2, 3, \ldots$:
\begin{enumerate}[label=\roman*)]
\item
  For fixed $\msgf{m}{X}^{(i-1)}$ and $\msgf{V}{X}^{(i-1)}$, 
  compute the MAP estimate
  \begin{IEEEeqnarray}{rCl}
    \hat x^{(i)} 
    & = & \argmax_{x} p(\breve y \cond x) \Normal{x; \msgf{m}{X}^{(i-1)}, \msgf{V}{X}^{(i-1)}} \\
    & = & 
      \left( \frac{1}{\msgf{V}{X}^{(i-1)}} + \frac{1}{s^2} \right)^{-1} 
      \!\! \left( \frac{\msgf{m}{X}^{(i-1)}}{\msgf{V}{X}^{(i-1)}} + \frac{\mu}{s^2} \right)\!. \IEEEeqnarraynumspace
    \end{IEEEeqnarray}
\item
  For fixed $x = \hat x^{(i)}$, compute $\msgf{m}{X}^{(i)}$ and $\msgf{V}{X}^{(i)}$ 
  according to~(\ref{eqn:disc:mXfAM}) and~(\ref{eqn:disc:VXfAM}).
\end{enumerate}
%
%
Some numerical results of the estimate~(\ref{eqn:disc:jointMAPSimplifiedAM}) are 
shown in Fig.~\ref{fig:hatXJointMAP}.
%
\begin{figure}
  \centering
  \includegraphics[]{inc/xHatAM}
  \caption{\label{fig:hatXJointMAP}%
  The estimate (\ref{eqn:disc:jointMAPSimplifiedAM})
  for $a=0$ and $b=1$, as a function of~$\mu$. The unknown parameters were initialized to $\msgf{m}{X}^{(0)} = 0$ 
  and $\msgf{V}{X}^{(0)} = 1$. For given $\mu$ and sufficiently large $s^2$, 
  the estimate $\hat x$ discretizes to the two levels $a$ and $b$.}
\end{figure}
%
We observe that for given $\mu$ and a sufficiently large $s^2$, 
the estimate discretizes, i.e., $\hat x \in \{a, b\}$.
For general $s^2$, however,~(\ref{eqn:disc:jointMAPSimplifiedAM}) 
need not agree with (\ref{eqn:disc:hatXJointMAP2})
since the algorithm may converge to a local maximum (or a saddle point).
This observation is summarized in the following theorem which guarantees that
for sufficiently large $s^2$,
the maximization in (\ref{eqn:disc:hatXJointMAP2})
is good-natured and~(\ref{eqn:disc:jointMAPSimplifiedAM}) will converge to $a$ or $b$ 
(one of the solutions of~ (\ref{eqn:disc:hatXJointMAP2})),
unless it is unluckily initialized to the (unavoidable)
local minimum between $a$ and~$b$. 
\begin{theorem}\label{theorem:AM:scalarLocalMaxima}
The function
\begin{IEEEeqnarray}{rCl}
x \mapsto \frac{\Normal{x; \mu, s^2}}{|x-a|\cdot|x-b|}
\end{IEEEeqnarray}
has no local maximum
(other than the global maxima at $x=a$ and $x=b$) 
if and only if
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:AM:CondNoLocal}
s^2 > s^2_{\mathrm{AM}},
\end{IEEEeqnarray}
where $s^2_{\mathrm{AM}}$ depends on $\mu, a$ and $b$.
\end{theorem}
%
\noindent
The proof of Theorem~\ref{theorem:AM:scalarLocalMaxima} 
(including the definition of $s^2_\text{AM}$) is lengthy 
and omitted here
but can be found in~\cite{keusch2021binaryNUVext}. 
Since $s^2_{\text{AM}}$ is the only real root of a cubic polynomial,
a closed-form expression for $s^2_{\text{AM}}$ exists, 
but it is cumbersome. 
However, $s^2_{\text{AM}}$ is easily computed numerically.
The value of $s^2_{\text{AM}}$ as a function of $\mu$
is plotted in Fig.~\ref{fig:BoundAM}. 
For example, $s_{\text{AM}}^2 = 0.028$ for $\mu = 0.3$, $a=0$, and $b=1$
(cf. Fig.~\ref{fig:hatXJointMAP}).
%
\begin{figure}
\centering
\includegraphics[]{inc/boundAM}
\caption{\label{fig:BoundAM}%
The value of $s^2_{\text{AM}}$ in (\ref{eqn:disc:AM:CondNoLocal})
as a function of $\mu$, 
for $a=0$ and $b=1$.}
\end{figure}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Type-II MAP Estimation%
\protect\footnote{in the sense of \cite{Tipping2001, Wipf2004}}}
\label{sec:disc:TypeII}
Another (and empirically much better) approach is to first form the MAP estimate 
\begin{IEEEeqnarray}{rCl} 
\hat\theta 
  & = & \argmax_{\theta} \int_{-\infty}^\infty p(\breve y \cond x) p(x, \theta)\, \dd x,
    \IEEEeqnarraynumspace
   \label{eqn:disc:scalarHatThetaMAP}
\end{IEEEeqnarray}
after which we estimate $x$ by
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:hatXTypeII}
\hat x = \argmax_{x} p(\breve y \cond x) p(x, \hat\theta).
\end{IEEEeqnarray}
The difference to the joint MAP approach of Section~\ref{sec:disc:JointMAP}
is the integration over $x$ in (\ref{eqn:disc:scalarHatThetaMAP}).
%
Having in mind the generalization to the sequence setting of Section~\ref{sec:systemModel},
we now consider computing (\ref{eqn:disc:scalarHatThetaMAP})
by expectation maximization (EM) \cite{stoica_cyclic_2004} with hidden variable $X$,
which operates by computing estimates $\hat \theta^{(1)}, \hat \theta^{(2)},\, \ldots\,$
according to
\begin{IEEEeqnarray}{rCl}
\hat \theta^{(i)} & = & \argmax_{\theta} \EE{\log\!\big( p(\breve y \cond X) p(X, \theta) \big)\rule{0em}{2ex}}
                  \IEEEeqnarraynumspace\label{eqn:disc:scalarThetaUpdateEM}\\
& = & \argmax_{\theta} \EE{\log p(X, \theta)\rule{0em}{2ex}},
      \IEEEeqnarraynumspace\label{eqn:disc:scalarThetaUpdateEM_middle}
\end{IEEEeqnarray}
where the expectation is with respect to $p(x \cond \breve y, \hat \theta^{(i-1)})$.
The computation of~(\ref{eqn:disc:scalarThetaUpdateEM_middle})
boils down to $\hat \theta^{(i)} = \left ( \! \big( \hva \big)^{(i)} , \big( \hvb \big)^{(i)} \! \right )$ with 
\begin{IEEEeqnarray}{rCl}
\big( \hva \big)^{(i)} 
 &=&  V_{X}^{(i)} + \big(\hat x^{(i)} - a \big)^2 \quad \text{and} \quad \label{eqn:disc:scalarEMUpdateA} \\ 
 \big( \hvb \big)^{(i)} 
 &=&  V_{X}^{(i)} + \big(\hat x^{(i)} -b \big)^2. \label{eqn:disc:scalarEMUpdateB}
\end{IEEEeqnarray}
The derivation of~(\ref{eqn:disc:scalarEMUpdateA}) and~(\ref{eqn:disc:scalarEMUpdateB})
is detailed in Appendix~\ref{sec:apds:EMUpdate}.
%
Again, the maximizing variances~(\ref{eqn:disc:scalarEMUpdateA}) and~(\ref{eqn:disc:scalarEMUpdateB})
can be plugged into~(\ref{eqn:box:boxPriorMeanVar}), 
resulting in
\begin{IEEEeqnarray}{rCl}
  \msgf{V}{X} &=& \left ( \frac{1}{ V_X + (\hat x - a )^2 } + \frac{1}{V_X + (\hat x - b )^2 } \right )^{-1} \label{eqn:disc:VXfEM}\\ 
  \msgf{m}{X} &=& \msgf{V}{X}  \left ( \frac{a}{ V_X + (\hat x - a )^2 } + \frac{b}{V_X + (\hat x - b )^2 } \right ), \label{eqn:disc:mXfEM}
\end{IEEEeqnarray}
where we have dropped the iteration index for readibility. The update 
rules~(\ref{eqn:disc:VXfEM}) and~(\ref{eqn:disc:mXfEM}) are given in 
Table~\ref{tab:psum:UpdateRulesCNUV} (in slightly different notation).

Computing~(\ref{eqn:disc:scalarHatThetaMAP}) and 
afterwards~(\ref{eqn:disc:hatXTypeII}) 
amounts to computing 
\begin{IEEEeqnarray}{rCl}
    \hat x &=& \argmax_x p(\breve y \cond x) \Normal{x; \msgf{m}{X}, \msgf{V}{X}} \label{eqn:disc:jointMAPSimplifiedEM} 
\end{IEEEeqnarray}
by iterating the two steps outlined in Section~\ref{sec:box:trivialExample}, 
except that $\msgf{m}{X}$ and $\msgf{V}{X}$ are updated according 
to~(\ref{eqn:disc:mXfEM}) and~(\ref{eqn:disc:VXfEM}), where the posterior 
variance is given by 
\begin{IEEEeqnarray}{rCl}
  V_X = \left( \frac{1}{\msgf{V}{X}} 
                        + \frac{1}{s^2} \right)^{-1}.
\end{IEEEeqnarray}
More specifically, we alternate the following two steps in iterations $i=1, 2, 3, \ldots$:
\begin{enumerate}[label=\roman*)]
\item
  For fixed $\msgf{m}{X}^{(i-1)}$ and $\msgf{V}{X}^{(i-1)}$, 
  compute the MAP estimate
  \begin{IEEEeqnarray}{rCl}
    \hat x^{(i)} 
    & = & \argmax_{x} p(\breve y \cond x) \Normal{x; \msgf{m}{X}^{(i-1)}, \msgf{V}{X}^{(i-1)}} \\
    & = & 
      \left( \frac{1}{\msgf{V}{X}^{(i-1)}} + \frac{1}{s^2} \right)^{-1} 
      \!\! \left( \frac{\msgf{m}{X}^{(i-1)}}{\msgf{V}{X}^{(i-1)}} + \frac{\mu}{s^2} \right)\!. \IEEEeqnarraynumspace
    \end{IEEEeqnarray}
\item
  For fixed $x = \hat x^{(i)}$, compute $\msgf{m}{X}^{(i)}$ and $\msgf{V}{X}^{(i)}$ 
  according to~(\ref{eqn:disc:mXfEM}) and~(\ref{eqn:disc:VXfEM}).
\end{enumerate}
%
Some numerical results of the estimate~(\ref{eqn:disc:jointMAPSimplifiedEM}) are
shown in Fig.~\ref{fig:hatXTypeII}.
%
\begin{figure}
  \centering
  \includegraphics[]{inc/xHatEM}
  \caption{
  The estimate~(\ref{eqn:disc:jointMAPSimplifiedEM})
  for $a=0$ and $b=1$, as a function of~$\mu$.  The unknown parameters were initialized to $\msgf{m}{X}^{(0)} = 0$ 
  and $\msgf{V}{X}^{(0)} = 1$. For a given $\mu$ and sufficiently large $s^2$, 
  the estimate $\hat x$ discretizes to the two levels $a$ and $b$.}
  \label{fig:hatXTypeII}%
\end{figure}
%
We observe that for a given $\mu$ and a sufficiently large $s^2$, 
the estimate discretizes, i.e., $\hat x \in \{a, b\}$.
For general $s^2$ however,~(\ref{eqn:disc:jointMAPSimplifiedEM}) 
need not agree with (\ref{eqn:disc:hatXTypeII})
since the algorithm may converge to a local maximum (or a saddle point).
This observation is summarized in the following theorem which guarantees that 
for sufficiently large $s^2$,
the maximization in (\ref{eqn:disc:scalarHatThetaMAP})
is good-natured and (\ref{eqn:disc:hatXTypeII}) 
returns $\hat x = a$ or $\hat x = b.$ Moreover (and in contrast to AM
of Section~\ref{sec:disc:JointMAP}), EM converges to $a$ if $\mu$ is closer 
to $a$ than to $b$, and to $b$ if $\mu$ is closer to $b$; this important 
property is probably the main reason for the empirical superiority of EM over AM.
%
\begin{theorem}\label{theorem:scalarEM}
%Let $a<b$. 
Assume $a<b$.
For $\mu < (a+b)/2$, the function
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:scalarEMtheoremIntegral}
\theta \mapsto
\int_{-\infty}^\infty \Normal{x; \mu, s^2} p(x,\theta) \dd x
\end{IEEEeqnarray}
has a maximum at $\va=0$ and $\vb=(a-b)^2$ (resulting in $\hat x = a$)
and no other extrema if and only if
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:BinCondEMa}
 s^2 > s_{\text{EM}}^2,
\end{IEEEeqnarray}
where 
\begin{IEEEeqnarray}{rCl}\label{eqn:disc:scalarEMtheorem:Condsa}
s_{\text{EM}}^2 \!=\! 
    \left\{ \begin{array}{ll}
       (3\!-\!\sqrt{8})(a\!-\!\mu)(b\!-\!\mu)   & \text{if $\mu \!<\! a \!-\! \frac{|a\!-\!b|}{\sqrt{2}}$}, \\
       \frac{(a-\mu)^2 |a-b|}{(a+b)-2\mu}       & \text{if $a \!-\! \frac{|a\!-\!b|}{\sqrt{2}} \leq \mu \!<\! \frac{a\!+\!b}{2}$}.
   \end{array}\right.  
\end{IEEEeqnarray}
Likewise, for $\mu > (a+b)/2$, (\ref{eqn:disc:scalarEMtheoremIntegral})
has a maximum at $\vb=0$ and $\va=(a-b)^2$ (resulting in $\hat x = b$)
and no other extrema if and only if 
\begin{IEEEeqnarray}{rCl} \label{eqn:disc:BinCondEMb}
 s^2 > s_{\text{EM}}^2, 
\end{IEEEeqnarray}
where 
\begin{IEEEeqnarray}{rCl}\label{eqn:disc:scalarEMtheorem:Condsb}
s_{\text{EM}}^2 \!=\! 
   \left\{ \begin{array}{ll}
       (3\!-\!\sqrt{8})(a\!-\!\mu)(b\!-\!\mu)           & \text{if $\mu \!>\! b \!+\! \frac{|a\!-\!b|}{\sqrt{2}}$}, \\
       \frac{(b-\mu)^2 |a-b|}{2\mu-(a+b)}   & \text{if $\frac{a\!+\!b}{2} \!<\! \mu \leq  b \!+\! \frac{|a\!-\!b|}{\sqrt{2}}$}. 
   \end{array} \right.
    \IEEEeqnarraynumspace
\end{IEEEeqnarray}
\end{theorem}
%
\noindent
The proof is lengthy and omitted here
but can be found in~\cite{keusch2021binaryNUVext}. 
The value of $s_{\text{EM}}^2$  
as a function of $\mu$ is plotted in Fig.~\ref{fig:BoundEM}.
For example, $s_{\text{EM}}^2 = 0.225$ for $\mu=0.3$, $a=0$ and $b=1$ (cf. Fig.~\ref{fig:hatXTypeII}).

\begin{figure}
\centering
\includegraphics[]{inc/boundEM}
\caption{\label{fig:BoundEM}%
The value of $s_{\text{EM}}^2$ in (\ref{eqn:disc:scalarEMtheorem:Condsa}) and (\ref{eqn:disc:scalarEMtheorem:Condsb}) 
as a function of $\mu$ for $a=0$ and $b=1$.
} 
\end{figure}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{$M$-Level Prior} \label{sec:MLevel}


\subsubsection{A False Start}

An obvious attempt to generalize (\ref{eqn:disc:TwoLvlPrior})
to more than two levels is 
\begin{equation} \label{eqn:disc:trivialPriorModel}
p(x, \theta) \eqdef \Normal{x; a, \sigma_a^2} \Normal{x; b, \sigma_b^2} 
    \Normal{x; c, \sigma_c^2} \cdots
\end{equation}
with $\theta \eqdef (\sigma_a^2, \sigma_b^2,\, \ldots)$.
However, this turns out not to work very well
since it introduces a bias towards the levels in the middle range.
The effect is illustrated in Fig.~\ref{fig:effectivePriorTrivialVsComposite},
where the dashed line shows the generalization of (\ref{eqn:disc:CostFunctionBinPrior}) 
and Fig.~\ref{fig:disc:costFuncBinPrior} using
$p(x, \theta)$ as in (\ref{eqn:disc:trivialPriorModel}).

\begin{figure}
\centering
\includegraphics[]{inc/M_lvl_cost_func_trivial_vs_composite}
\caption{\label{fig:effectivePriorTrivialVsComposite}%
Generalization of (\ref{eqn:disc:CostFunctionBinPrior}) to $M=6$ equidistant levels.
Solid blue: using (\ref{eqn:disc:SumOfBinaries}) and (\ref{eqn:disc:SumOfBinariesEqualCoeffs}).
Dashed: using (\ref{eqn:disc:trivialPriorModel}).}
\end{figure}


\subsubsection{Adding Binary Variables} \label{sec:MLevelWorking}

Good results are obtained with linear combinations of auxiliary binary (or binarized)
variables. For example, 
constraining $X$ to three levels $\{ -b, 0, b \}$
can be achieved by writing 
\begin{equation} \label{eqn:disc:TernarybySumOfTwo}
X = b X_1 - b X_2
\end{equation}
where both $X_1$ and $X_2$ are constrained to $\{ 0, 1 \}$ 
by means of independent priors (\ref{eqn:disc:TwoLvlPrior}), i.e.,
\begin{IEEEeqnarray}{rCl}
p(x_1, x_2, \theta_1, \theta_2) 
 & = & 
  \Normal{x_1; 0, \sigma_{1,a}^2} \Normal{x_1; 1, \sigma_{1,b}^2} \nonumber \\
  && \cdot\Normal{x_2; 0, \sigma_{2,a}^2} \Normal{x_2; 1, \sigma_{2,b}^2}.
\end{IEEEeqnarray}
The corresponding generalization of Fig.~\ref{fig:hatXTypeII}
is shown as solid line in Fig.~\ref{fig:hatXTypeIIThreeLvl}.

More generally, we can write $X$ as a linear combination
\begin{equation} \label{eqn:disc:SumOfBinaries}
X = \sum_{j=1}^J \beta_j X_j + \beta_0
\end{equation}
of independent binary (i.e., binarized to $\{ 0, 1\}$) variables $X_1,\, \ldots, X_J$.
The choice of $J$ and of the coefficients $\beta_0,\, \ldots, \beta_J$
is highly nonunique. 
Choosing $\beta_j = 2^{j-1}$ for $j>0$ does not work well empirically.
Good results are obtained with 
\begin{equation} \label{eqn:disc:SumOfBinariesEqualCoeffs}
\beta_1 = \ldots = \beta_J,
\end{equation}
resulting in $M=J+1$ equidistant levels for $X$.
(Related representations were used in \cite{FrLg:sradda2006}.)
The corresponding generalization of (\ref{eqn:disc:CostFunctionBinPrior})
is illustrated in Fig.~\ref{fig:effectivePriorTrivialVsComposite} (solid blue line).



\begin{figure}
\centering
\includegraphics[]{inc/three_lvl_cell_characteristic_EM}  % [width=\linewidth]
\caption{\label{fig:hatXTypeIIThreeLvl}%
Generalization of Fig.~\ref{fig:hatXTypeII} to three levels $\{ -1, 0, 1 \}$
using (\ref{eqn:disc:TernarybySumOfTwo}).}
\end{figure}


\subsubsection{Symmetry Breaking}

In (\ref{eqn:disc:SumOfBinaries}), 
$X_1=0$ and $X_2=1$ has the same effect on $X$ as $X_1=1$ and $X_2=0$. 
The estimation algorithm must somehow 
%make a choice 
choose
among such equivalent configurations. 
However, depending on the details of the implementation,
the estimation algorithm may not, by itself, be able to break such symmetries.
This problem can be solved
by a slightly asymmetric initialization of the variances,
e.g., 
\begin{equation}
\sigma_{1,a}^2 = \sigma_{1,b}^2 \neq \sigma_{2,a}^2 = \sigma_{2,b}^2,
\end{equation}
where the inequality is almost an equality.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear State Space Models with NUV Priors} \label{sec:systemModel}

\subsection{System Model}
\noindent
We will use the statistical system model~(\ref{eqn:lssm:statModelFirstExtension}),
which is a generalization of the standard linear Gaussian state space model. 
We begin with the latter. 

\subsubsection{Standard Linear Gaussian Model}
Recall the standard linear state space model (LSSM)
\begin{IEEEeqnarray}{rCl}  \IEEEyesnumber \phantomsection \label{eqn:lssm:detLSSM}  \IEEEyessubnumber* 
  x_k &=& A x_{k-1} + B u_k \\
  y_k &=& C x_k
\end{IEEEeqnarray}
with time index $k \in \Naturals$,
initial state $x_0 \in \Reals^N$, 
input $u_k \in \Reals^L$, 
state $x_k \in \Reals^N$,
output $y_k \in \Reals^H$, 
input dimension $L \in \Naturals$, state dimension $N \in \Naturals$
and output dimension $H \in \Naturals$. 
Further, we have the 
input matrix $B \in \Reals^{N \times L}$, 
the state transition matrix $A \in \Reals^{N \times N}$,
and the observation matrix $C \in \Reals^{H \times N}$. 
For the sake of clarity, we here assume a time-invariant state space model;
however, the proposed approach works also for time-varying state space models
(with $A,B,C$ depending on $k$)
and the pertinent generalizations are straightforward.

For the remainder of this paper, we assume a finite planning horizon 
$k \in \{1,\dots, K\}$.

The standard linear Gaussian model is obtained by turning the variables 
in~(\ref{eqn:lssm:detLSSM}) into random variables (denoted by capitals) as 
follows. First, $U_1, \dots, U_K$ are assumed to be independent Gaussian 
random variables; second, for $k \in \{1, \dots, K\}$ we observe 
$\breve Y_k = Y_k + Z_k$, where $Z_1, \dots, Z_K$ are independent zero-mean 
Gaussian random variables that model the measurement noise. For fixed 
observations $\breve Y_1 = \breve y_1, \dots, \breve Y_K = \breve y_K$, 
the joint posterior probability density of all other variables can then be 
written as 
\begin{IEEEeqnarray}{rCl} \label{eqn:lssm:statModelFirstExtension}
  p(u, x, y \cond \breve y) \propto p(x_0) \prod_{k=1}^K p(u_k) p(\breve y_k \cond y_k) 
  \bigg\rvert_{\text{(\ref{eqn:lssm:detLSSM})}}
\end{IEEEeqnarray}
with
$u \eqdef \bma u_1, \dots, u_K \ema$, 
$x \eqdef \bma x_0, \dots, x_K \ema$, 
$y \eqdef \bma y_1, \dots, y_K \ema$, and
$\breve y \eqdef \bma \breve y_1, \dots, \breve y_K \ema$.

\subsubsection{Linear Gaussian Model with NUV Parameters} \label{sec:lssm:statModel}
We will work with the generalization of~(\ref{eqn:lssm:statModelFirstExtension})
to 
\begin{IEEEeqnarray}{rCl} \label{eqn:lssm:stateModelSecondExtension}
  p(y, x, u; \theta) \!\propto\! \msgf{p}{}(x_0) \! \left ( \prod_{k=1}^K \msgf{p}{}(u_k;\theta_{U_k})
  \msgb{p}{}(y_k;\theta_{Y_k}) \! \! \right ) \msgb{p}{}(x_K) \bigg\rvert_{\text{(\ref{eqn:lssm:detLSSM})}}  
  \nonumber \\
\end{IEEEeqnarray}
(as illustrated in Fig.~\ref{fig:lssm:jointDensity}), 
where 
$\msgf{p}{}(u_k;\theta_{U_k})$ is Gaussian with parameters 
$\theta_{U_k} \eqdef (\msgf{m}{U_k}, \msgf{V}{U_k})$, 
$\msgb{p}{}(y_k;\theta_{Y_k})$ is Gaussian with parameters
$\theta_{Y_k} \eqdef (\msgb{m}{Y_k}, \msgb{V}{Y_k})$, and 
$\theta \eqdef (\theta_{U_1}, \dots, \theta_{U_K}, \theta_{Y_1} \dots , \theta_{Y_K})$.
%
Note that the special case~(\ref{eqn:lssm:statModelFirstExtension}) is obtained with 
$\msgf{p}{}(x_0) = p(x_0)$,
$\msgf{p}{}(u_k;\theta_{U_k}) = p(u_k)$,
$\msgb{p}{}(y_k;\theta_{Y_k}) = p(\breve y_k \cond y_k)$, where the 
observations $\breve y_k$ are subsumed in $\theta_{Y_k}$, and 
$\msgb{p}{}(x_K) = 1$.

If the inputs $U_k$ and the outputs $Y_k$ are scalars (i.e., $L = H = 1$), every 
factor 
$\msgf{p}{}(u_k;\theta_{U_k})$ and 
$\msgb{p}{}(y_k;\theta_{Y_k})$
can be a NUV prior; in particular, these factors can be used to impose any of the 
constraints discussed in Section~\ref{sec:compositeNUVPriors} on any input $U_k$
or any output $Y_k$. If $L > 1$ or $H > 1$, NUV priors on scalar components 
of $U_k$ and $Y_k$ can easily be included in 
$\msgf{p}{}(u_k;\theta_{U_k})$ and 
$\msgb{p}{}(y_k;\theta_{Y_k})$.

Concerning the initial state, we assume $\msgf{p}{}(x_0)$ to be Gaussian with known 
mean $\msgf{m}{X_0}$ and covariance matrix $\msgf{V}{X_0}$.
%
Concerning the terminal state, we assume either $\msgb{p}{}(x_K) = 1$
or else that $\msgb{p}{}(x_K)$ is Gaussian with known 
mean $\msgb{m}{X_K}$ and covariance matrix $\msgb{V}{X_K}$.
%
\begin{figure}
  \centering
  \includegraphics[scale=0.74]{inc/FGjointDensity}
  \caption{Factor graph of the model~(\ref{eqn:lssm:stateModelSecondExtension}).}
  \label{fig:lssm:jointDensity}
\end{figure}


\subsection{Iterative Augmented Kalman Estimation (IAKE)} \label{sec:algo}
\noindent
For fixed parameters $\theta$, the variables $U, X, Y$ 
in~(\ref{eqn:lssm:stateModelSecondExtension}) are jointly Gaussian, and the 
MAP estimate of any subset of these variables coincides with their (posterior)
mean. For the joint estimation of $U, Y$, and all NUV parameters in $\theta$, we 
will use the following algorithm. The final MAP estimate of $U$ (when the algorithm
stops) is the desired control signal $\hat u = \bma \hat u_1, \dots, \hat u_K \ema$.

Starting from an initial guess $\hat \theta^{(0)}$, the algorithm repeats the 
following two steps for $i=1,2,3,\ldots,$ until convergence (or for a sufficiently large number of 
iterations):






\begin{enumerate}[label=\roman*)]
\item \label{item:step_1}
  For fixed $\theta = \hat \theta^{(i-1)}$, compute for $k \in \{1, \dots, K\}$
  \begin{enumerate}
    \item the posterior means $m_{U_k}^{(i)}$ (and, if necessary, the posterior variances 
              $V_{U_k}^{(i)}$) of $U_k$, 
    \item the posterior means $m_{Y_k}^{(i)}$ (and, if necessary, the posterior variances 
              $V_{Y_k}^{(i)}$) of $Y_k$. 
  \end{enumerate}
\item \label{item:step_2}
  From these means and variances, determine new parameters $\theta^{(i)}$ using 
  Tables~\ref{tab:prob:UpdateRulesNUV} and~\ref{tab:psum:UpdateRulesCNUV}.
\end{enumerate}
%
These two steps are repeated until some convergence criterion is satisfied 
(e.g., some fixed number of iterations). 

Note that Step~\ref{item:step_1} operates with a standard linear Gaussian model.
In consequence, the required means and variances can be computed 
by Kalman-type recursions or, equivalently, by forward-backward Gaussian 
message passing, with a complexity that is linear in $K$.

A preferred such algorithm is the MBF smoother~\cite{Bierman1977}
augmented with input signal estimation as in~\cite{Bruderer2015, Loeliger2016}.
This algorithm requires no matrix inversion%
%
\footnote{This is obvious for $H=1$. For $H>1$, a little adaptation is required, 
see~\cite[Section 4.1.2]{Zalmai2017a}.}
%
and is numerically stable. For the convenience of readers unfamiliar with 
the setting of \cite{Loeliger2016}, 
the algorithm is concisely stated in Table~\ref{table:MBFMP}.
%
\begin{table}
  \centering
  \noindent

\framebox[0.49\textwidth]{
  \begin{minipage}{0.45\textwidth}
    \newcounter{saveequationcntr}
    \setcounter{saveequationcntr}{\value{equation}}
    \setcounter{equation}{0}
    \renewcommand{\theequation}{F.\arabic{equation}}
    
\noindent
\vskip0.2em
\rule{0pt}{3ex}The algorithm consists of a forward recursion followed by a backward recursion.
The former is a standard Kalman filter, but the latter is not quite standard.

Initialize $\msgf{m}{X_0}$, $\msgf{V}{X_0}$, $\msgb{m}{X_K}$, $\msgb{V}{X_K}$ 
according to Section~\ref{sec:lssm:statModel}.

  \vspace{0.2cm}
  \textbf{Forward recursion:} \\
  For $k = 1, 2, \dots, K$, compute  
  \vspace{-0.2cm}
  \begin{IEEEeqnarray}{rCl}
    \msgf{m}{X_k'} & = &  A \msgf{m}{X_{k-1}} + B \msgf{m}{U_k}  \\
    \msgf{V}{X_k'} &=& A \msgf{V}{X_{k-1}} A^{\T} + B \msgf{V}{U_k} B^{\T} \IEEEeqnarraynumspace \\
    \msgf{m}{X_k} & = &  \msgf{m}{X_k'} + \msgf{V}{X_k'} E_k \\
    \msgf{V}{X_k} &=& F_{k} \msgf{V}{X_k'}  \\
    %
    % \IEEEeqnarraymulticol{3}{l}{\text{with}} \nonumber \\
    \noalign{\noindent where \vspace{2\jot}}
    E_{k} &=& C^{\T} G_{k} (\msgb{m}{Y_{k}} -  C \msgf{m}{X_{k}'}) \\
    F_{k} &=& I_N - \msgf{V}{X_{k}'} C^{\T} G_{k}  C \\
    G_{k} &=& (\msgb{V}{Y_{k}} + C \msgf{V}{X_{k}'} C^{\T})^{-1}.
  \end{IEEEeqnarray}

  
  \setcounter{equation}{0}
  \renewcommand{\theequation}{B.\arabic{equation}}
  
  \textbf{Backward recursion:} \\
  Initialize with $\tilde W_{X_K}\!= 0_{N \times N}$ and $\tilde \xi_{X_K}\!= 0_N$ 
  if $\msgb{p}{(X_K)} = 1$, else
  \vspace{-0.2cm}
  \begin{IEEEeqnarray}{rCl}
    \tilde W_{X_K} &=& ( \msgf{V}{X_K} + \msgb{V}{X_K} )^{-1} \\ 
    \tilde \xi_{X_K} &=& \tilde W_{X_K} (\msgf{m}{X_K} - \msgb{m}{X_K}). \hspace{1.3em} \IEEEeqnarraynumspace
    % \vspace{-0.2cm}
  \end{IEEEeqnarray}
  For $k = K, K-1, \dots, 1$, compute 
  \vspace{-0.1cm}
  \begin{IEEEeqnarray}{rCl}
    \tilde{\xi}_{X_k'} &=& F_k^{\T} \tilde{\xi}_{X_k} - E_k  \\
    \tilde{W}_{X_k'} &=& F_k^{\T} \tilde{W}_{X_k} F_k + C^{\T} G_k C  \hspace{2.em} \IEEEeqnarraynumspace \\
    \tilde{\xi}_{X_{k-1}} &=& A^{\T} \tilde{\xi}_{X_k'}  \\
    \tilde{W}_{X_{k-1}} &=& A^{\T} \tilde{W}_{X_k'} A.
  \end{IEEEeqnarray}

  \setcounter{equation}{0}
  \renewcommand{\theequation}{P.\arabic{equation}}
  
  \textbf{Posterior quantities:} \\
  The posterior means and variances for $k \in \{1, \dots, K\}$ are given by
  \vspace{-0.2cm}
  \begin{IEEEeqnarray}{rCl}
    m_{U_k} &=& \msgf{m}{U_k} - \msgf{V}{U_k} B^{\T} \tilde \xi_{X_k'} \label{eqn:algo:mU}\\
    V_{U_k} &=& \msgf{V}{U_k} - \msgf{V}{U_k} B^{\T} \tilde{W}_{X_k'} B \msgf{V}{U_k} \label{eqn:algo:VU} \\
% %
    m_{Y_k} &=& C \left ( \msgf{m}{X_k} - \msgf{V}{X_k} \tilde \xi_{X_k} \right ) \label{eqn:algo:mY}\\
    V_{Y_k} &=& C \left ( \msgf{V}{X_k} - \msgf{V}{X_k} \tilde{W}_{X_k} \msgf{V}{X_k} \right ) C^{\T}. \label{eqn:algo:VY}
  \end{IEEEeqnarray}
  \vspace{-0.3cm}
  % restore counter
  \setcounter{equation}{\value{saveequationcntr}}
\end{minipage}
}

\caption{\label{table:MBFMP}
Step~\ref{item:step_1} of IAKE implemented by 
MBF message passing with input estimation assembled from \cite{Loeliger2016}.}
% \noindent
\end{table}

% \markblue{
Concerning Step~\ref{item:step_2}, we note that the derivations of the update rules 
in Section~\ref{sec:compositeNUVPriors} are easily adapted to the system 
model~(\ref{eqn:lssm:stateModelSecondExtension});
in particular, the estimation of all NUV parameters in~(\ref{eqn:lssm:stateModelSecondExtension}) 
splits into separate individual estimates, each as in Tables~\ref{tab:prob:UpdateRulesNUV} 
and~\ref{tab:psum:UpdateRulesCNUV}.

In practice, often only a subset of~(\ref{eqn:algo:mU})--(\ref{eqn:algo:VY}) needs to be computed, 
depending on the problem at hand and the relevant 
update rules in Tables~\ref{tab:prob:UpdateRulesNUV} and~\ref{tab:psum:UpdateRulesCNUV}.  

We also note that this algorithm is easily adapted to mildly nonlinear 
systems,
cf. Section~\ref{sec:racetrack}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Application Examples} \label{sec:app}
\subsection{Digital-To-Analog Conversion} \label{sec:DAC}
\noindent
We now describe Example~\ref{example:prob:binaryControl} of Section~\ref{sec:prob} 
in detail. For the numerical experiments, the physical system 
is a simple analog low-pass filter with transfer function 
(i.e., the Laplace transform of the impulse response)
\begin{IEEEeqnarray}{rCl} \label{eqn:dac:transferFunction}
  G(s) = \frac{35037.9}{s^3 + 71.9 s^2 + 2324.8s + 35037.9}.
\end{IEEEeqnarray}
The amplitude response (i.e., the magnitude of the frequency response $G(i\omega)$)
of this filter is shown in Fig.~\ref{fig:dac:freqResp}.
(Such low-order filters cannot be good low-pass filters,
but they are inexpensive by all relevant measures.)
\begin{figure}
  \begin{center}
  \includegraphics{inc/baude}
  % \vspace{0.5em}
  \caption{Frequency response of~(\ref{eqn:dac:transferFunction}).}
  \label{fig:dac:freqResp}
  \end{center} 
\end{figure}
%
The transfer function~(\ref{eqn:dac:transferFunction}) is transformed into 
state-space form and discretized 
using a sampling interval of $T = 0.003$ seconds, resulting in a 
discrete-time LSSM as in~(\ref{eqn:lssm:detLSSM}) with 
state space dimension $N=3$ and matrices
\begin{IEEEeqnarray}{rCl} \IEEEyesnumber \IEEEyessubnumber*
    A \!&=&\! \bma
            0.7967&  -6.3978& -94.2123\\
            0.0027 &  0.9902 & -0.1467\\
            0      &  0.0030 &  0.9999
          \ema, \; 
  B \!=\! \bma 0.0027 \\ 0 \\ 0  \ema,  \IEEEeqnarraynumspace
\end{IEEEeqnarray}
  and
\begin{IEEEeqnarray}{rCl}
  \IEEEyessubnumber*
  C &=& \bma 0 & 0 & 35037.9 \ema.
\end{IEEEeqnarray}

Recall that we wish to compute a binary input signal $u$, such that the model output~$y$
approximates a given target waveform~$\breve y$. 
%
We reformulate the constrained optimization 
problem~(\ref{eqn:prob:binaryControlOptProb}) 
as a statistical estimation problem using a linear Gaussian model with 
NUV parameters (see Section~\ref{sec:lssm:statModel}) as follows:
The quadratic penalty~(\ref{eqn:prob:binaryControlOptProbQuadPart}) is readily 
expressed by~(\ref{eqn:prob:outputPrior}) with fixed parameters 
$\msgb{m}{Y_k} = \breve y_k$ and $\msgb{V}{Y_k} > 0$.
The binary input constraint~(\ref{eqn:prob:binaryControlOptProbBinConstr}) is
expressed by~(\ref{eqn:prob:inputPrior}) with unknown 
parameters~$\msgf{m}{U_k}$ and~$\msgf{V}{U_k}$. The estimation problem is then solved 
using the IAKE algorithm proposed in Section~\ref{sec:algo}:

In Step~\ref{item:step_1} of the algorithm (Table~\ref{table:MBFMP}), 
we compute $m_{U_k}^{(i)}$ and $V_{U_k}^{(i)}$, for $k \in \{1, \dots, K\}$, 
using~(\ref{eqn:algo:mU}) and~(\ref{eqn:algo:VU}), where $i$ is 
the iteration index.
In Step~\ref{item:step_2} of the algorithm, we determine the unknown 
parameters $\theta^{(i)}$ using Table~\ref{tab:psum:UpdateRulesCNUV}.
%
Specifically, the parameters $\msgf{m}{U_{k}}^{(i)}$ and $\msgf{V}{U_{k}}^{(i)}$
are updated according to the last row of
Table~\ref{tab:psum:UpdateRulesCNUV}, with 
$m_X = m_{U_{k}}^{(i)}$, $V_X = V_{U_k}^{(i)}$, $a=0$ and $b=1$.
%
The final estimate of $U$ is 
\begin{IEEEeqnarray}{rCl}
  \hat u = \bma m_{U_1}^{(i)}, \ldots, m_{U_K}^{(i)} \ema,
\end{IEEEeqnarray}
where $i$ is the final iteration.

The numerical results shown in Fig.~\ref{fig:prob:dac} are obtained with 
$\msgb{V}{Y_k} = 0.045$ and $K=450$.  Note that $\msgb{V}{Y_k}$ controls the approximation 
quality as it scales the weight of the squared error between $y$ and $\breve y$.
The first half of Fig.~\ref{fig:prob:dac} shows the nominal operation of
the digital-to-analog converter, where the target waveform 
can be well approximated.
The second half of Fig.~\ref{fig:prob:dac} illustrates what happens 
if the (unreasonable) target waveform falls outside the passband of the analog filter.




  

\subsubsection{Comparison With Other Methods}
\label{sec:OptimalController}

The global minimum of~(\ref{eqn:prob:binaryControlOptProb})
can, in principle, be determined by an exhaustive search.
However, the complexity of such a search is exponential in the planning horizon $K$,
which limits its practicability to small $K$.
(Smart versions of tree search such as sphere decoding 
suffer from the same fundamental limitation.)

By contrast, the algorithm proposed in Section~\ref{sec:algo}
will normally converge to a local, rather than the global, maximum of 
(\ref{eqn:prob:binaryControlOptProb}).
However, in many applications, 
this deficiency is far outweighed by the ability to easily handle large~$K$.



\begin{figure}
\begin{center}
\includegraphics{inc/3th_ord_SK_filter_vs_optimal_with_w_8}
\caption{Comparing the proposed method (with planning horizon $K=200$) 
with an optimal (exhaustive search) controller
with planning horizon $K=8$.  
The former yields a significantly better approximation 
($y$ with $\text{MSE}=0.01972$) than the latter  
($y^*$ with $\text{MSE}=0.04885$).}
\label{fig:versus_optimal}
\end{center} 
\end{figure}


\begin{figure}
\begin{center}
\includegraphics{inc/3th_ord_SK_filter_with_w_8_vs_optimal_with_w_8}
\caption{Comparing the proposed method with planning horizon $K=8$ 
with an optimal controller with the same planning horizon. 
The former yields almost as good a solution ($y$ with $\text{MSE}=0.04899$) 
as the latter ($y^*$ with $\text{MSE}=0.04885$).}
\label{fig:versus_optimal_both_short_horizon}
\end{center} 
\end{figure}


For example, 
Fig.~\ref{fig:versus_optimal} compares 
an ``optimal'' (exhaustive search) controller with planning horizon $K=8$
with the proposed algorithm. 
The analog system is the same (3rd-order low-pass)
as in Section~\ref{sec:DAC}.
The results are obtained with $\msgb{V}{Y_k} = 0.01$ and full-length $K$.
It is obvious from Fig.~\ref{fig:versus_optimal}
that the ability to look sufficiently far ahead 
is crucial for good performance.

But how suboptimal is the proposed algorithm really?
Fig.~\ref{fig:versus_optimal_both_short_horizon} 
shows the performance of the proposed algorithm 
in online mode with the same planning horizon $K=8$
as the exhaustive-search controller:
it turns out, in this example, that the proposed algorithm
is very nearly optimal.







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Corridor Control with Different Input Constraints}  \label{sec:var:boxOutput}
\noindent
Assume we wish to keep the model output $y$ within a corridor around a target 
$\breve y$, i.e., 
we wish $y_k$ to satisfy
\begin{IEEEeqnarray}{rCl}
  a_k \leq y_k - \breve y_k \leq b_k, \quad k \in \{1, \dots, K\},
\end{IEEEeqnarray}
for fixed bounds $a_k, b_k \in \Reals$.
%
We can achieve this by 
$\msgb{p}{}(y_k;\theta_{Y_k})$
implementing (the NUV realization of) a box constraint on $Y_k$
as in Section~\ref{sec:boxPrior}, 
with bounds  
$a_k + \breve y_k$ and $b_k + \breve y_k$, 
and slope parameter $\gamma_o$.
%
In the following, we consider five different version of this problem,
with different constraints on the control signal $u$:

In version~1, the input $u$ is constrained by an $L_2$ penalty.

In version~2, the discrete derivative of the input $u$ is constrained to satisfy
$\Delta u_k \geq -0.03$ (by a half-space prior as in Section~\ref{sec:halfSpacePrior}).
Constraining the derivative instead of the input itself is easily handled by a small 
modification of~(\ref{eqn:lssm:detLSSM}); the augmented model amounts to 
\begin{IEEEeqnarray}{rCl}
  \tilde A = \bma 1 & 0_{1 \times N} \\ B & A \ema, \; 
  \tilde B = \bma 1 \\ 0_{N \times 1} \ema, \; \text{and} \;\; 
  \tilde C = \bma 0 & C \ema. \IEEEeqnarraynumspace
\end{IEEEeqnarray}

In version~3, the input $u$ is constrained to be sparse (by a sparsifying 
NUV prior~\cite{Loeliger2016}, which empirically works better than 
standard $L_1$ regularization~\cite{Tibshirani1996}).

In version~4, the input $u$ is constrained to be discrete-valued, i.e., 
to satisfy $u_k \in \{-1, 0, 1\}$ (by an $M$-level prior as in 
Section~\ref{sec:MLevelWorking} using EM).

In version~5, the discrete derivative of the input $u$ is constrained 
to be sparse (by a sparsifying NUV prior~\cite{Loeliger2016}).

Note that version~3,~4 and~5 are nonconvex problems. 
A variation of version~3 was also discussed in~\cite{Hoffmann2017}.

The numerical results in Fig.~\ref{fig:var:boxOutput} 
are obtained with the following state space model 
\begin{IEEEeqnarray}{rCl} \IEEEyesnumber \IEEEyessubnumber*
  A &=& \bma 1  & 0 & 0 \\ 1 & 1 & 0 \\ 1/2 & 1 & 1 \ema, \quad
  B = 0.0015 \bma 1 \\ 1/2 \\ 1/3 \ema,
\end{IEEEeqnarray}
and 
\begin{IEEEeqnarray}{rCl} \IEEEyessubnumber*
  C = \bma 0 & 0 & 1 \ema.
\end{IEEEeqnarray}
Furthermore, we have $K=175$, 
$\lambda_o = 10$ for the box prior on the output,
$\msgf{m}{U_k} = 0$ and $\msgf{V}{U_k} = 10$ in version~1, 
and $a_i = -0.03$ and $\lambda_i = 10$ for the half-space prior on the 
input in version~2.
The corresponding inputs and outputs are illustrated using different colors. 
The bounds of the corridor are indicated by dashed lines in the first plot.
%
\begin{figure}
  \centering
  \includegraphics{inc/boxConstraintOutput}
  \caption{
  Corridor control with different constraints on the input.
  Top row: allowed corridor (dashed) and output signals.
  Second row: input $u$ with $L_2$ penalty.
  Third row: input $u$ with constraint on its derivative.
  Fourth row: input $u$ with sparsifying penalty.
  Fifth row: input $u$ constrained to three levels.
  Bottom row: input $u$ with sparsifying penalty on its derivative.
  }
  \label{fig:var:boxOutput}
\end{figure}
\noindent





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Flappy Bird Control} \label{sec:flappyBird}
\noindent
The following control problem is a variation of the 
\emph{flappy bird} computer game~\cite{wiki_flappy_bird}.
(This example improves on the related example in~\cite{keusch2021binaryNUV}, 
which did not use box constraints.)

Consider a physical system consisting 
of a point mass $m$ moving forward (left to right in Fig.~\ref{fig:traj:FlappyBirdDoubleSlits}) 
with constant horizontal velocity
and ``falling'' vertically with constant acceleration $g$. 
The $\{0,1\}$-valued control signal $u$ affects the system only if $u_k=1$,
in which case a fixed value is added to the vertical momentum.
We wish to steer the point mass such that it passes 
through a sequence of double slits, and hence, does not collide with the obstacles 
(black bars in Fig.~\ref{fig:traj:FlappyBirdDoubleSlits}).

For this example, we need a slight generalization
of~(\ref{eqn:lssm:detLSSM}) as follows.
The state $x_k \in\Reals^2$ (comprising the vertical position and the vertical velocity) 
evolves according to
\begin{IEEEeqnarray}{rCl} 
x_k & = & \bma 1 & T \\ 0 & 1 \ema x_{k-1}
          + \bma 0 \\ 1/m \ema u_k + \bma 0 \\ -Tg \ema.
\end{IEEEeqnarray}
%
Let $\mathcal S \subset \{ 1, \ldots, K \}$ be the positions of the double slits.
For $k \in \mathcal S$, we have the augmented output
\begin{IEEEeqnarray}{rCl} \label{eqn:FlappyShiftAug}
  \tilde y_k = \bma 1 & 0 \ema x_k + s_k,
\end{IEEEeqnarray}
where $s_k \in \{0, d_k\}$ ``selects'' either the lower or
the upper slit, and where ${d_k \in \Reals}$ specifies the vertical distance between them.
%
The double-slit constraint~(\ref{eqn:traj:doubleSlitConstraint}) 
is achieved by a box constraint on $\tilde Y_k$ (with bounds $a_k$ and $b_k$)
and a binarizing constraint on $S_k$.
By doing so, the vertical position 
$y_k \eqdef \bma 1 & 0 \ema x_k$ is constrained to satisfy 
\begin{IEEEeqnarray}{rCl} \label{eqn:traj:doubleSlitConstraint}
  y_k \in [a_k, b_k]  \quad \text{or} \quad y_k \in [a_k-d_k, b_k-d_k].
\end{IEEEeqnarray}
%
In addition, we use a binarizing prior on $U_k$ with levels $\{0, 1\}$ for all $k$.

The numerical results in Fig.~\ref{fig:traj:FlappyBirdDoubleSlits} are obtained with 
$K = 300$, $m = 1$, $T = 0.1$, $g = 0.2$, $\gamma = 100$, and $a_k, b_k$ and 
$d_k$ according to Fig.~\ref{fig:traj:FlappyBirdDoubleSlits}.
%
\begin{figure}
  \centering
  \includegraphics{inc/flappy_bird_two_slits}
  \caption{Double-slit flappy bird control with binary control signal $u$, and
  resulting trajectory $y$, which must not collide with the obstacles (black bars).}
  \label{fig:traj:FlappyBirdDoubleSlits}
\end{figure}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Trajectory Planning with Obstacle Avoidance}
\noindent
Consider the following situation. 
An object is moving in a two-dimensional plane.
Its position at time $k$ is $y_k= \bma y_{k,1}, y_{k,2} \ema^\T \in \Reals^2$,
which is governed by the state space model~(\ref{eqn:lssm:detLSSM}) with
\begin{IEEEeqnarray}{rCl} 
  A &=& \bma  1 & 0 & 0 & 0 \\
              T & 1 & 0 & 0 \\
              0 & 0 & 1 & 0 \\
              0 & 0 & T & 1 
       \ema, \; 
  B = \bma T \\ 0 \\ T \\ 0 \ema, \; \text{and} \;\;  
  % \noalign{\noindent and\vspace{2\jot}} 
  C = \bma 0 \\ 1 \\ 0 \\ 1 \ema^\T \! , \IEEEeqnarraynumspace
\end{IEEEeqnarray}
where $T$ is the discretization interval
and $u_k = \bma u_{k,1}, u_{k,2} \ema^\T$ is the acceleration.

Assume we wish to plan a trajectory starting from $\bma 0, 0 \ema^\T$ (with zero velocity) 
and ending at  $ \bma 3,3 \ema^\T$ (with zero velocity), 
while avoiding a spherical obstacle 
at $c = \bma 1.5, 1.5 \ema^\T$ with radius $r = 0.75$ (see Fig.~\ref{fig:traj:koz_spheres_single}).
In addition, we wish to minimize the squared norm of the acceleration, i.e.,
\begin{IEEEeqnarray}{rCl}
  \sum_{k=1}^K \| u_k\|^2,
\end{IEEEeqnarray}
which is easily handled by a zero-mean Gaussian prior on $U_k$, for all $k$. 

The obstacle can be avoided by a half-space constraint on the auxiliary variable 
\begin{IEEEeqnarray}{rCl} \label{eqn:traj:nonLinFunc}
  \tilde z_k \eqdef  \| y_k - c\| = f(y_k), \quad k \in \{1, \dots, K\},
\end{IEEEeqnarray}
which is the distance from $y_k$ to the center $c$ of the obstacle. 
Specifically, we use a half-space NUV prior to enforce
\begin{IEEEeqnarray}{rCl}
  \tilde z_k > r.
\end{IEEEeqnarray}
%
It remains to deal with the problem that~(\ref{eqn:traj:nonLinFunc}) 
is a nonlinear function of $y_k$.
We solve this problem in the most obvious way,
by using the linearization 
\begin{IEEEeqnarray}{rCl}
  z_k = f(y_k^*) + \nabla f(y_k^*) (y_k - y_k^*) \approx f(y_k)
\end{IEEEeqnarray}
(as illustrated in Fig.~\ref{fig:traj:FGkozSingleObstacle}),
where $y_k^* \in \Reals^2$ is the previous estimate of $Y_k$ and $\nabla f(y_k^*)$ 
is the gradient of $f$ at $y_k=y_k^*$.
%
\begin{figure}
  \centering
  \includegraphics[scale=0.75]{inc/FGkozSingleObstacle}
  \caption{Factor graph representation of the modified observation model 
  with half-space prior $p(z_k; \theta_k)$.}
  \label{fig:traj:FGkozSingleObstacle}
\end{figure}
%

The numerical results illustrated in Fig.~\ref{fig:traj:koz_spheres_single} 
are obtained 
with $T=1$, $\gamma = 5$, $\msgf{m}{U_k} = \bma 0, 0 \ema^\T$, 
$\msgf{V}{U_k} = \diag{0.1, 0.1}$, 
and boundary conditions 
\begin{IEEEeqnarray}{rCl}
  \msgf{m}{X_0} &=& \bma 0 , 0 , 0 , 0 \ema^\T, \\
  \msgb{m}{X_K} &=& \bma 0 , 3 , 0 , 3 \ema^\T, \quad \text{and} \\
  \msgf{V}{X_0} &=& \msgb{V}{X_K} = 0_{4 \times 4}.
\end{IEEEeqnarray}
Note that the optimal solution of the given problem is not unique since the problem is 
geometrically symmetric. The obtained solution depends on the initial conditions. 

The method of this example is easily extended to multiple obstacles 
by concatenating multiple instances of the part shown 
in Fig.~\ref{fig:traj:FGkozSingleObstacle}.
The method is not limited to spherical obstacles as long as the nonlinearity of $f$ is good-natured. 
Ellipses, squares, rectangles, and linear transformations (e.g., scaling and rotations) 
thereof have been successfully implemented 
by choosing $f$ accordingly. An example with multiple obstacles of various shapes is given in 
Fig.~\ref{fig:traj:koz_mixed_I}, the details are omitted. 









%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Minimal-Time Race Track Control} \label{sec:racetrack}
\noindent
Autonomous racing is a version of autonomous driving where the goal is to 
complete a given race track in the shortest time possible.
The following challenges must be dealt with:
\begin{itemize}
  \item Nonlinear vehicle dynamics.
  \item Physical limitations of the vehicle such as maximal steering angle and maximal motor torque.
  \item Collision avoidance with track boundaries.
\end{itemize}
%
Several methods to solve this control problem have been proposed in the 
literature~\cite{Qian2016, Qian2016a, Rosolia2019}. 
We now show how this problem can be addressed with the approach of this paper.
As recommended in the literature,
we will use a curvilinear coordinate 
system~\cite{Lot2014, Micaelli1993, Lenain2007, Lenain2008}, which simplifies 
expressing the constraints imposed by the track boundaries.


\begin{figure}   
  \hspace*{-1.7em}
  \begin{subfigure}[b]{0.49\linewidth}
    \includegraphics{inc/keepOutZone_spheres_single}
    \caption{\hspace*{-5em}}\label{fig:traj:koz_spheres_single} 
  \end{subfigure}
\begin{subfigure}[b]{0.49\linewidth}
    \includegraphics{inc/keepOutZone_mixed_I}
    \caption{\hspace*{-6em}}\label{fig:traj:koz_mixed_I} 
\end{subfigure}
\caption{(a) Trajectory planning with a single spherical obstacle at 
$\bma 1.5, 1.5 \ema^\T$. 
Note that the optimal trajectory $y$ is not unique. (b) Trajectory planning with obstacles of various shapes. 
The obtained trajectory $y$ is only locally optimal.}
\end{figure}  

We begin by describing the vehicle dynamics using the standard 
\textit{Ackermann vehicle model}~\cite{rajamani2011vehicle}
in Cartesian coordinates $\tilde x$ and $\tilde y$,
from which the final state space model will be obtained in a series of transformations.
The model consists of the differential equation
\begin{IEEEeqnarray}{rCl} \label{eqn:race:ackermannDynamicsCartesian}
  \frac{\dd x}{\dd t} =  f(x(t), u(t)) = 
  \bma 
    v(t) \cos(\theta(t)) \\ 
    v(t) \sin(\theta(t)) \\ 
    v(t) \frac{\tan(\delta(t))}{\ell} \\ 
    a(t) \\
    \dot a(t) \\
    \dot \delta(t) 
  \ema
\end{IEEEeqnarray}
with state
\begin{IEEEeqnarray}{rCl}
  x(t) = \bma \tilde x(t) , \tilde y(t) , \theta(t) , v(t) , a(t) , \delta(t) \ema^\T
\end{IEEEeqnarray}
and input
\begin{IEEEeqnarray}{rCl}
  u(t) = \bma \dot \delta(t) \\ \dot a(t) \ema,
\end{IEEEeqnarray}
and with steering angle $\delta$ (front wheel, back wheel is fixed), vehicle 
length~$\ell$, heading angle~$\theta$, speed~$v$, and acceleration~$a$. 

In a next step, we transform this state space 
model into a curvilinear coordinate system
as illustrated in Fig.~\ref{fig:race:curvilinear}.
\begin{figure}
  \center
  \includegraphics[scale=0.9]{inc/curvi}
  \caption{Curvilinear coordinate system, where $s$ is the progress on the 
  center line, $z$ is the vehicle's displacement perpendicular to the centerline, 
  and $\theta$ is the heading angle relative to a tangent vector at $s$.}
  \label{fig:race:curvilinear}
\end{figure}
%
The first coordinate $s$ (of the curvilinear coordinate system) 
describes the progress along the center line of the race track,
whereas the second coordinate $z$ describes the perpendicular deviation of the
vehicle with respect to the center line at~$s$. The angle $\theta$ instances the
angle between the vehicle's direction of travel and the tangent vector at~$s$.
Consequently, the state vector is
\begin{IEEEeqnarray}{rCl}
  x(t) = 
  \bma 
    s(t) , 
    z(t) , 
    \theta(t) , 
    v(t) ,
    a(t) , 
    \delta(t)  
  \ema^\T.
\end{IEEEeqnarray}
The vehicle dynamics~(\ref{eqn:race:ackermannDynamicsCartesian}) in the 
curvilinear coordinates turn out to be
\begin{IEEEeqnarray}{rCl} \label{eqn:race:ackermannDynamicsCurvilinearTime}
  \frac{\dd x}{\dd t}
  % = \bma \dot s(t) \\ \dot y(t) \\ \dot \theta(t) \\ \dot v(t) \ema 
  = f_t(x(t), u(t)) 
  = \bma  
      v \frac{\cos(\theta)}{\imk} \\
      v \sin(\theta) \\
      v \left ( \frac{\tan(\delta)}{\ell} - \frac{\kappa(s) \cos(\theta)}{\imk} \right) \\
      a \\
      \dot a \\ 
      \dot \delta
    \ema, \IEEEeqnarraynumspace
\end{IEEEeqnarray}
where $\kappa(s)$ is the curvature of the center line.
Note that the right-hand side of~(\ref{eqn:race:ackermannDynamicsCurvilinearTime}) 
depends on the time $t$, which is omitted for readability.


In~(\ref{eqn:race:ackermannDynamicsCurvilinearTime}), the
independent variable is time, and hence, formulating a minimal-time optimization problem 
is nontrivial. We therefore transform the state space model once more, 
into a form where $s$ is the independent variable.
The transformed model follows directly from
\begin{IEEEeqnarray}{rCl}
  \frac{\dd x}{\dd s} 
  &=& \frac{\dd x}{\dd t} \frac{\dd t}{\dd s} 
  =  \left (\frac{\dd s}{\dd t} \right)^{-1} \frac{\dd x}{\dd t} \\
  &=& \left ( \frac{\imk}{v \cos(\theta)} \right) f_t(x(s), u(s)).
\end{IEEEeqnarray}
Accordingly, the new state and input vectors are no longer functions of $t$, but functions 
of $s$, i.e., $x(s)$, and $u(s)$, respectively.
%
Since $s$ is now the independent variable, we drop the first state and add time
as an additional state, i.e.,
\begin{IEEEeqnarray}{rCl}
  x(s) = 
  \bma 
    z(s) , 
    \theta(s) , 
    v(s) ,
    a(s) ,
    \delta(s) , 
    t(s) 
  \ema^\T.
\end{IEEEeqnarray}
The new model dynamics are
\begin{IEEEeqnarray}{rCl}
  \frac{\dd x}{\dd s}\!=\! f_s(x(s), u(s)) \!=\! 
  \frac{1 \!-\! \kappa(s) z }{v \cos(\theta)} \!
  \bma 
  v \sin(\theta) \\ 
  v \! \left (\! \frac{ \tan(\delta)}{\ell} \!-\! \frac{\cos(\theta)}{\kappa(s)^{-1} \!-\! z} \! \right ) \!\! \\
  a \\
  \dot a  \\
  \dot \delta \\
  1
\ema \!. \IEEEeqnarraynumspace
  \label{eqn:race:nonLinModel}
\end{IEEEeqnarray}
%
In order to impose suitable state constraints, we define  
\begin{IEEEeqnarray}{rCl} \label{eqn:race:outputModel}
  y(s) = f_o(x(s)) = 
  \bma 
  z \\ 
  a \\ 
  \delta \\ 
  a^2 + \psi \frac{v^4}{\ell^2} \tan(\delta)^2 
  \ema, 
\end{IEEEeqnarray}
where the last component of~(\ref{eqn:race:outputModel}) is the squared total acceleration~$a_{\text{tot}}^2$, 
and where $\psi$ is a weighting factor to incorporate all unmodeled physical properties of the vehicle. 
%
Keeping the vehicle within the track boundaries is achieved by imposing a box 
constraint on the vehicle's deviation from the center line $z$. 
Further box constraints on the longitudinal acceleration $a$ 
and the steering angle $\delta$ enforce physical limitations of the vehicle. 
Finally, a box constraint on the total acceleration $a_{\text{tot}}^2$
prevents the vehicle from slipping. 


\begin{figure}
  \center
  \includegraphics[scale=1]{inc/raceTrackTotalAccConstraint}
  \caption{Minimal-time racing with constrained longitudinal acceleration $a$, 
  steering angle $\delta$, 
  and total acceleration $a_{\text{tot}}$. The color of the resulting trajectory 
  is a function of the vehicle's speed.}
  \label{fig:race:raceTrackTotalAcc}
\end{figure}

%%%%%%%%%%%%%
In a final step, we linearize the nonlinear 
model~(\ref{eqn:race:nonLinModel}) and~(\ref{eqn:race:outputModel}) around 
the linearization point $(x^*, u^*)$, yielding the model 
\begin{IEEEeqnarray}{rCl}  \IEEEyesnumber \phantomsection \label{eqn:race:linearModel}  \IEEEyessubnumber*
  \frac{\dd x}{\dd s} &=& \tilde A (x(s) - x^*) + \tilde B(u(s) - u^*) + f_s(x^*, u^*) \IEEEeqnarraynumspace \\
  y(s) &=& \tilde C (x(s) - x^*) + f_o(x^*), 
\end{IEEEeqnarray}
with
\begin{IEEEeqnarray}{rCl}
  \tilde A &=& \frac{\partial f_s(x^*, u^*)}{\partial x}, \; 
  \tilde B = \frac{\partial f_s(x^*, u^*)}{\partial u}, \;
  \tilde C = \frac{\partial f_o(x^*)}{\partial x}. \IEEEeqnarraynumspace
\end{IEEEeqnarray}
%
The linear model~(\ref{eqn:race:linearModel}) is then discretized 
using a first-order approximation (Euler method), resulting in
\begin{IEEEeqnarray}{rCl} \label{eqn:race:lssm}
  x_{k+1} &=& A (x_k \!-\! x_k^*) + B (u_k \!-\! u_k^*) + x_k^* + T_s  f_s(x_k^*, u_k^*) \IEEEeqnarraynumspace \\
  y_{k} &=& C (x_k \!-\! x_k^*) + f_o(x_k^*),
\end{IEEEeqnarray}
with
\begin{IEEEeqnarray}{rCl}
  A = 1 + T_s \tilde A, \quad 
  B = T_s \tilde B, \quad \text{and} \quad 
  C = \tilde C,
\end{IEEEeqnarray}
and where $T_s$ is the spatial sampling interval. Finally, minimizing the track 
time is handled by imposing a zero-mean Gaussian penalty on the terminal 
state $X_{K, 6}$, i.e., on the time at the (spatial) index $K$.


%
The example shown in Fig.~\ref{fig:race:raceTrackTotalAcc} was obtained with 
the following numerical values:
We use box priors on the corresponding model outputs
to constrain the deviation from the centerline 
to $-0.006 \leq z \leq 0.006$
% $z$ by $[-0.006, 0.006]$ 
with $\gamma_z = 0.005$, 
the vehicle's longitudinal acceleration
to $-1 \leq a \leq 1$ 
% $a$ by $[-1, 1]$ 
with $\gamma_a = 0.001$,
the steering angle
to $-0.35 \leq \delta \leq 0.35$  
% $\delta$ by $[-0.35, 0.35]$ 
with $\gamma_\delta = 0.001$, 
and the total acceleration 
to 
$0 \leq a_\text{tot}^2 \leq 150$
% $a_\text{tot}^2$ by $[0, 150]$ 
with $\gamma_{a_\text{tot}^2} = 10^{-8}$,
where $\psi =  25$. The prior on the terminal state $X_{K,6}$ 
is zero-mean Gaussian with variance 
$\msgb{V}{X_{K,6}} = 500$. 
The model inputs are unconstrained, which is approximated by 
a zero-mean Gaussian on every $U_k$ with large variance 
$\msgf{V}{U_k} = \diag{10^8, 10^8}$.
Furthermore, $K=1000$ spatial samples are used.

The color of the resulting vehicle trajectory in Fig.~\ref{fig:race:raceTrackTotalAcc}
indicates the speed of the vehicle. Clearly,
the vehicle needs to slow down before taking sharp turns in order to keep the total 
acceleration sufficiently low, i.e., to prevent slipping. The turning radius is further 
limited by the maximum steering angle of the vehicle.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\noindent
NUV priors allow to incorporate non-Gaussian priors and constraints into linear 
Gaussian models without affecting their computational tractability. 
We proposed new NUV representations 
of half-space constraints,
and we elaborated on recently proposed discretizing NUV priors.
We then discussed the use of such NUV representations
for model predictive control, with a variety of constraints on the input, the 
output, or the internal state of the controlled system. 
In such applications, the computations amount to iterations 
of Kalman-type forward-backward recursions, 
with a complexity (per iteration) that is linear in the planning horizon. 
In consequence, this approach can handle long planning horizons, which 
distinguishes it from the prior art. 
For nonconvex constraints, this approach has no claim to optimality, but it is 
empirically very effective.

The proposed approach was illustrated with a variety of exemplary control problems 
including flappy-bird control and minimal-time race track control. An application 
  to a real-world industrial control problem is demonstrated in a companion 
  paper~\cite{Keusch2023LongHorizonMPCStateConstraints}.




\begin{appendix}
\section{Proofs and Derivations}
\subsection{Proof of Theorem~\ref{theorem:box:hardConstraint}} \label{sec:apds:ProofBox}
\noindent
% \begin{proof} 
  Assume, without loss of generality, that $a < b$.
  We first rewrite~(\ref{eqn:box:JointMAPEstimateBox})
  as 
  \begin{IEEEeqnarray}{rCl}
    \hat x &=& \argmax_x \max_\theta p(\breve y \cond x) p(x, \theta) \label{eqn:box:jointMAPtoCost}\\
    &=& \argmax_x p(\breve y \cond x) p(x) \\
    &=& \argmin_x - \log \! \left ( p(\breve y \cond x)  p(x) \right ) \\
    &=& \argmin_x \frac{(x-\mu)^2}{2 s^2} + \gamma |x-a| + \gamma |x-b| \\
    &\eqdef & \argmin_x \tilde \kappa(x). \label{eqn:box:HardConCostFunc}
  \end{IEEEeqnarray}
  Maximizing~(\ref{eqn:box:JointMAPEstimateBox}) is thus equivalent to minimizing 
  the cost function $\tilde \kappa(x)$, which is illustrated in 
  Fig.~\ref{fig:box:costFuncTrivialEx}, for different values of $s^2$.
  %
  \begin{figure}
    \centering
    \includegraphics{inc/costFuncTrivialEx}
    \caption{Cost function $\tilde \kappa(x)$ in~(\ref{eqn:box:HardConCostFunc}) 
    for $a=-1, b=1, \mu = 1.5, \gamma=1$, 
    and different values for $s^2$.
    Condition~(\ref{eqn:box:HardCondition}) is satisfied for the solid lines, critically 
    satisfied for the dashed line, and not satisfied for the dotted line.}
    \label{fig:box:costFuncTrivialEx}
  \end{figure}
  %
  Note that $\tilde \kappa(x)$ is a sum of convex functions and therefore also convex.
  Consequently, the estimate~(\ref{eqn:box:jointMAPtoCost}) 
  is in the interval $[a, b]$ if and only if the global minimum of $\tilde \kappa(x)$ is 
  in the interval $[a, b]$. This, in turn, is satisfied if and only if 
  \begin{IEEEeqnarray}{rCl}
    \lim_{\tilde x \uparrow a} \restrict{ \frac{\dd \tilde \kappa(x)}{\dd x}}{x = \tilde x} < 0 
    \quad \text{and} \quad 
    \lim_{\tilde x \downarrow b} \restrict{ \frac{\dd \tilde \kappa(x)}{\dd x}}{x = \tilde x} > 0,
  \end{IEEEeqnarray}
  i.e.,   
  \begin{IEEEeqnarray}{rCl}
    \frac{a-\mu}{s^2} - 2 \gamma < 0 \quad \text{and} \quad \frac{b - \mu}{s^2} + 2 \gamma > 0,
  \end{IEEEeqnarray}
  which boils down to~(\ref{eqn:box:HardCondition}).
  
  


\subsection{Derivation of~(\ref{eqn:disc:binPriorOptimalVar})} \label{sec:apds:binVariances}
\noindent
The derivation of $\hva$ in~(\ref{eqn:disc:binPriorOptimalVar}) is obtained 
by setting the derivative with respect to $\va$ of~(\ref{eqn:disc:jointPriorMax}) to zero, 
i.e.,
\begin{IEEEeqnarray}{rCl}
  \frac{\partial p(x, \theta)}{\partial \va} 
  &\stackrel{!}{=}& 0 \\
    &\Leftrightarrow& \nonumber \\
    (\va)^{-\frac{5}{2}} (x - a)^2  - (\va)^{-\frac{3}{2}}  &\stackrel{!}{=}& 0 
\end{IEEEeqnarray}
which yields the unique maximizer 
\begin{IEEEeqnarray}{rCl}
  (\hva) = \left (  x - a \right )^2.
\end{IEEEeqnarray} 
The maximizer $\hvb$ in~(\ref{eqn:disc:binPriorOptimalVar}) is derived likewise.


\subsection{Derivation of~(\ref{eqn:disc:scalarEMUpdateA}) and~(\ref{eqn:disc:scalarEMUpdateB}) }
\label{sec:apds:EMUpdate}
\noindent
The computation of $\big( \hva \big)^{(i)}$
follows from 
\begin{IEEEeqnarray}{rCl}
\big( \hva \big)^{(i)} 
& = & \argmax_{\va} \EE{\log \Normal{X; a, \va}} \\
& = & \argmin_{\va} \left(
      \log(\va)
      + \frac{1}{\va}\EE{ \left( X - a \right)^2 }
      \right) \label{eqn:apds:EMderStep1} \\
& = &  \EE{ \left( X - a \right)^2 }  \label{eqn:apds:EMderStep2} \\
&=& \EE{X^2} - \EE{X}^2 + \EE{X}^2 - 2a \EE{X} + a^2 \IEEEeqnarraynumspace \\ 
&=& V_X^{(i)} + (\hat x^{(i)} - a)^2, 
\end{IEEEeqnarray}
where $\EE{ X } = \hat x^{(i)}$ was used. 
The step from~(\ref{eqn:apds:EMderStep1}) to~(\ref{eqn:apds:EMderStep2}) 
is obtained by setting the derivative with respect to $\va$ of~(\ref{eqn:apds:EMderStep1}) 
to zero.
Likewise, we obtain
\begin{IEEEeqnarray}{rCl} 
\big( \hvb\big)^{(i)} 
=  V_{X}^{(i)} + \big(\hat x^{(i)} -b \big)^2.
\end{IEEEeqnarray}



\end{appendix}

\balance
\bibliographystyle{IEEEtran}
\bibliography{paper}


\end{document}
