{
    "arxiv_id": "2303.13112",
    "paper_title": "A Simple Explanation for the Phase Transition in Large Language Models with List Decoding",
    "authors": [
        "Cheng-Shang Chang"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "stat.ML"
    ],
    "abstract": "Various recent experimental results show that large language models (LLM) exhibit emergent abilities that are not present in small models. System performance is greatly improved after passing a certain critical threshold of scale. In this letter, we provide a simple explanation for such a phase transition phenomenon. For this, we model an LLM as a sequence-to-sequence random function. Instead of using instant generation at each step, we use a list decoder that keeps a list of candidate sequences at each step and defers the generation of the output sequence at the end. We show that there is a critical threshold such that the expected number of erroneous candidate sequences remains bounded when an LLM is below the threshold, and it grows exponentially when an LLM is above the threshold. Such a threshold is related to the basic reproduction number in a contagious disease.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13112v1"
    ],
    "publication_venue": "5 pages, 1 figure"
}