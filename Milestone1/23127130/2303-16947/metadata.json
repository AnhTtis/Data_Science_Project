{
    "arxiv_id": "2303.16947",
    "paper_title": "De-coupling and De-positioning Dense Self-supervised Learning",
    "authors": [
        "Congpei Qiu",
        "Tong Zhang",
        "Wei Ke",
        "Mathieu Salzmann",
        "Sabine SÃ¼sstrunk"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "Dense Self-Supervised Learning (SSL) methods address the limitations of using image-level feature representations when handling images with multiple objects. Although the dense features extracted by employing segmentation maps and bounding boxes allow networks to perform SSL for each object, we show that they suffer from coupling and positional bias, which arise from the receptive field increasing with layer depth and zero-padding. We address this by introducing three data augmentation strategies, and leveraging them in (i) a decoupling module that aims to robustify the network to variations in the object's surroundings, and (ii) a de-positioning module that encourages the network to discard positional object information. We demonstrate the benefits of our method on COCO and on a new challenging benchmark, OpenImage-MINI, for object classification, semantic segmentation, and object detection. Our extensive experiments evidence the better generalization of our method compared to the SOTA dense SSL methods",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16947v1"
    ],
    "publication_venue": null
}