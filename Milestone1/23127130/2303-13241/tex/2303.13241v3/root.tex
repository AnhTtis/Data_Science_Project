%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath,bm}
 % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{pifont}% http://ctan.org/pkg/pifont

%%%% Added by ulme_ma
\usepackage{import}
\usepackage{calrsfs}
\usepackage{mathtools,xparse}
\let\labelindent\relax
\usepackage[inline]{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{booktabs}
\usepackage{transparent}

\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\loss}{\pazocal{L}}

%%%% Added by durn_ma
%\usepackage{acro}          % Abbreviations
\usepackage{color, xcolor}
\usepackage{cleveref}      % For /cref command
\usepackage{caption}
\usepackage[bottom]{footmisc}

\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand{\etal}{\textit{et al.}~}
\newcommand{\eg}{e.g.,~}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\conc}{\mathbin{\|}}



\newcommand{\method}{{EagerNet}} %if required, name of method

\newcommand{\todo}[1]{\textbf{\color{red}{TODO: \textit{#1}}}}
\newcommand{\comMU}[1]{\textbf{\color{green}{MU: \textit{#1}}}} %MaxUlmer Comments
\newcommand{\comMD}[1]{\textbf{\color{cyan}{MD: \textit{#1}}}} %MaxDurner Comments
\newcommand{\comMS}[1]{\textbf{\color{green}{MS: \textit{#1}}}} %MartinSundermeyer Comments

\graphicspath{{figures/}}

\usepackage[toc,acronym,nonumberlist]{glossaries}
\makeglossaries
%\include{abbreviations}    % Definitions of abbreviations


%%%%%

\title{\LARGE \bf
%Learning 6D Pose Estimation without High-Quality 3D Models for Orbital Robotics
6D Object Pose Estimation from Approximate 3D Models \\ for Orbital Robotics
}


%%% Just some brainstorming ideas
%The devil is in the detail: 
%Learning 6D Pose Estimation robust to 3D Model Quality in Space
%6D Pose Estimation with inaccurate/imprecise object/satellite model for space robotics
%How far can you go:

\author{Maximilian Ulmer$^{1}$, Maximilian Durner$^{1,2}$, Martin Sundermeyer$^{1,2}$, Manuel Stoiber$^{1,2}$, and Rudolph Triebel$^{1,2}$% <-this % stops a space
%\thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$ Institute of Robotics and Mechatronics, German Aerospace Center (DLR), 82234 Wessling, Germany {\tt\small <first>.<second>@dlr.de}}%
\thanks{$^{2}$Department of Computer Science, Technical University of Munich (TUM), 85748 Garching, Germany}%
}


\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\input{abbreviations}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{abstract}
%Estimating the 6D pose of a non-cooperative spacecraft from a single monocular image remains an exceedingly challenging task. 
%However, such capabilities are essential for many close proximity operations in orbit such as docking, on-orbit servicing, debris removal, and assembly. 
%In contrast to the terrestrial setting, algorithms have to deal with difficult illumination conditions that can result in effects such as high contrast, %overexposure, and low signal-to-noise ratio. 
%To deal with such conditions, many \gls{DL}-based approaches have been proposed that focus on \textit{sparse} 2D-3D correspondences -- namely keypoints -- %for pose estimation. 
%In this work, we propose to predict \textit{dense} correspondences by regressing 3D model coordinates per pixel. 
%Simultaneously, we estimate the pixel-wise coordinate prediction error to discard correspondences with high uncertainty. 
%This allows us to effectively deal with the challenging visual conditions in orbit, 3D model inaccuracies, and occlusions. 
%Both pixel-wise predictions are then used to formulate multiple 6D pose hypotheses of the object. 
%We iteratively refine each pose hypothesis using a highly-efficient region-based refinement approach. 
%Furthermore, we introduce a novel pixel-wise posterior formulation in this refinement that allows us to locally optimize the object's pose in the most %challenging of visual conditions. 
%At last, we estimate the likelihood for each hypothesis to find the most probable pose.
%Our method achieves state-of-the-art performance on the SPEED+ dataset and overall won the SPEC2021 post-mortem competition. 
%In addition, we show that our approach is robust to 3D modeling errors on the TUDL dataset. 
%Training code and pre-trained models will be made available.

% state-of-the-art performance on the SPEED+ dataset and SPEC2021 competition
% \begin{itemize}
% 	\item Perception in space is an incredible challenging task.... lightning conditions, reflections etc.
% 	\item In this work, we present \textit{\method}...
% 	\item postmortem Speed+ challenge winner
% \end{itemize}
%\end{abstract}

%% My version (RT)
\begin{abstract}
 We present a novel technique to estimate the 6D pose of objects from single images where the 3D geometry of the object is only given approximately and not as a precise 3D model. To achieve this, we employ a dense 2D-to-3D correspondence predictor that regresses 3D model coordinates for every pixel. In addition to the 3D coordinates, our model also estimates the pixel-wise coordinate error to discard correspondences that are likely wrong. This allows us to generate multiple 6D pose hypotheses of the object, which we then refine iteratively using a highly efficient region-based approach. We also introduce a novel pixel-wise posterior formulation by which we can estimate the probability for each hypothesis and select the most likely one. As we show in experiments, our approach is capable of dealing with extreme visual conditions including overexposure, high contrast, or low signal-to-noise ratio. This makes it a powerful technique for the particularly challenging task of estimating the pose of tumbling satellites for in-orbit robotic applications. Our method achieves state-of-the-art performance on the SPEED+ dataset and has won the SPEC2021 post-mortem competition. 
 Code, trained models, and the used satellite model will be made publicly available.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{sections/introduction}
\input{sections/related_work}
\input{sections/method}
\input{sections/experiments}
\input{sections/conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{APPENDIX}
%Appendixes should appear before the acknowledgment.

%\input{sections/acknowledgment}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%References are important to the reader; therefore, each citation must be complete and correct. If at all possible, references should be commonly available publications.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}




\end{document}
