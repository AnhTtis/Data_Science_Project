\section{Related Work}
\subsection{Monocular Satellite Pose Estimation} 
Recently, the space community started adopting \gls{DL}-based pose estimation methods. 
In~\cite{sharma2018pose}, one of the earliest adoptions, a pre-trained backbone is used to directly classify discretized poses. 
Around the same time, the SPEED dataset~\cite{Kisantal2019-yp} was published and the \gls{SPEC} was organized for the first time.
It saw a diverse set of learning-based approaches, such as probabilistic rotation estimation with a soft classifier~\cite{Proenca2020-jg}. 
Notably, many competitors used keypoint-based methods~\cite{Park2019-fp, Chen2019-iw} which have been widely used in the domain since then~\cite{black2021real, pasqualetto2020cnn}.
Shortly after, \cite{Hu2021-pl} published the SwissCube dataset which is a purely synthetic satellite pose estimation dataset, created with a physics-based renderer. 
The dataset focuses on the wide-depth-range scenario and the authors propose a single-stage hierarchical keypoint-based method that can deal with large-scale variations.
In 2021, the \gls{SPEC} competition was organized again, based on the SPEED+~\cite{Park2021-jr} dataset which introduced a vastly larger training set, empowering new \gls{DL} approaches. 
Yet, many of the top competitors still employed keypoint-based approaches. 
For instance, \cite{Perez-Villar_undated-ly} estimates keypoint location and depth in two decoder heads, and \cite{Wang2022-rs} augments their training images with a \gls{GAN}~\cite{goodfellow2020generative} to bridge the domain gap.

In contrast to these sparse correspondence methods, we predict 2D-3D correspondences densely per pixel and, to the best of our knowledge, present the first such method for satellite pose estimation.
In \cite{Li2019-tq}, dense correspondences are applied to estimate the rotation of objects and utilize a second head to predict the object translation, while \cite{Park2019-ny} predicts correspondence errors and uses a \gls{GAN} to enhance target predictions, and ~\cite{Wang2021-sj} uses a neural network-based \gls{PnP} to estimate the pose from the predicted dense correspondences. 
However, in contrast to these methods, we only assume to have access to an approximate 3D CAD model for training and explicitly handle inaccuracies in the 3D model.


\subsection{6D Pose Refinement}
After estimating a global pose, a local search can be used to further invest computational resources and improve estimation accuracy. DeepIM~\cite{Li2018-fy} uses \gls{DL} to refine a pose hypothesis by iteratively estimating a relative pose between a rendered object view in the current pose and the observed object view. 
CosyPose~\cite{Labbe2020-mr} improves on this idea with an optimized architecture and rotation parameterization. 
Similarly, \cite{Lipson2022-pq} uses the "render-and-compare" approach for refinement but instead of directly regressing the pose they apply bidirectional depth-augmented \gls{PnP} to estimate a pose update. 

This work uses a classical, region-based method to refine poses based on~\cite{Stoiber2020-gb, Stoiber2022-ka}. 
This class of methods differentiates between a foreground and background area using image statistics. 
Then, an optimizer searches for the model pose that best explains this segmentation. 
In~\ref{subsec:multi_hypothesis} we show that global color statistics alone are not enough to refine object poses in the harsh visual conditions of space. 
We, therefore, introduce a novel formulation to apply \gls{DL}-based features to the refinement step that can cope with the most aggressive of lighting conditions.


% \subsection{Model Quality}
% An important and interesting challenge within object pose estimation is model abstraction.
% In general, there is a trade-off between reaching maximum precision against model limitations (\eg lack of details) and intra-categorical differences.
% In this context, the demands on the object replication mainly depend on the concept of the underlying method.
% As can be observed in the latest BOP challenge \cite{hodan_bop_2020} \todo{check if newer reference exists}, the current trend is to use training data created by photorealistic simulators~\cite{denninger_blenderproc_nodate,muller_photorealistic_2021}.
% Those simulation environments prefer precise object models to mimic reality as well as possible.
% Hence, pose estimators based on appearance~\todo{references} require detailed modeling of geometry and texture, since both influence the appearance with changing perspective and/or other external conditions (\eg light source).

% Earlier non-learning, template matching-based approaches that either evaluate correspondences between processed feature maps (\eg edges) and 3D models~\cite{lowe_perceptual_1985,lowe_three-dimensional_1987,costa_3d_2000} or directly work on depth maps~\cite{kriegel_combining_2013,drost_model_2010} only require object models with (almost) exact geometry.

% Other works that rely on highly abstract 3D models can be found in the early stages of object-centric vision~\cite{agin_computer_1976,brooks_model-based_1983,bergevin_part_1992,dickinson_3-d_1992}, where primitive volumetric bodies are fit with locally extracted shaped-based features.