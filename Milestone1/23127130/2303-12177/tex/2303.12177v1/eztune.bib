% Random Forests
@article{breiman2001random,
 title={Random forests},
 author={Breiman, Leo},
 journal={Machine Learning},
 volume={45},
 number={1},
 pages={5--32},
 year={2001},
 publisher={Springer},
 doi={10.1023/A:1010933404324},
}

% No free lunch
@inproceedings{schumacher2001no,
 title={The no free lunch and problem description length},
 author={Schumacher, Chris and Vose, Michael D. and Whitley, L. Darrell},
 booktitle={Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation},
 pages={565--570},
 year={2001},
 organization={Morgan Kaufmann Publishers Inc.},
 doi={10.5555/2955239.2955325},
}

% svn
@article{svm,
 title={Support-vector networks},
 author={Cortes, Corinna and Vapnik, Vladimir},
 journal={Machine Learning},
 volume={20},
 number={3},
 pages={273--297},
 year={1995},
 publisher={Springer}, 
 doi={10.1007/BF00994018},
}


@Article{glmnet,
  title={Regularization Paths for Generalized Linear Models via Coordinate Descent},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of Statistical Software},
  year={2010},
  volume={33},
  number={1},
  pages={1--22},
  doi={10.18637/jss.v033.i01},
  url={https://www.jstatsoft.org/v33/i01/},
 }

% Main GBM paper
@article{gbmpaper,
  title={Greedy function approximation: A gradient boosting machine},
  author={Friedman, Jerome H.},
  journal={Annals of Statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}, 
  doi={10.1214/aos/1013203451},
}

% Adaboost
@article{adaboost,
  title={A decision-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E.},
  journal={Journal of Computer and System Sciences},
  volume={55},
  number={1},
  pages={119--139},
  year={1997},
  publisher={Elsevier},
  doi={10.1006/jcss.1997.1504},
}

% Elastic net
@article{en,
  title={Regularization and variable selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={Journal of the royal statistical society: series B (statistical methodology)},
  volume={67},
  number={2},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library},
  doi={10.1111/j.1467-9868.2005.00503.x},
}

% caret
@Manual{caret,
  title={{caret}: Classification and regression training},
  author={Max Kuhn},
  year={2022},
  note={R package version 6.0-93},
  url={https://CRAN.R-project.org/package=caret},
 }

% tidymodels
@Manual{tidymodels,
  title={{tidymodels}: A collection of packages for modeling and machine learning using tidyverse principles},
  author={Kuhn, Max and Wickham, Hadley},
  year={2020},
  url={https://www.tidymodels.org},
 }

% Tutorial in SVR
@article{smola2004tutorial,
  title={A tutorial on support vector regression},
  author={Smola, Alex J. and Sch{\"o}lkopf, Bernhard},
  journal={Statistics and Computing},
  volume={14},
  number={3},
  pages={199--222},
  year={2004},
  publisher={Springer},
  doi={10.1023/B:STCO.0000035301.49549.88},
}

% Elements of statistical learning
@book{friedman2009elements,
  title={The elements of statistical learning: Data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer, New York, NY, USA},
  doi={10.1007/978-0-387-84858-7},
}

% dissertation
@phdthesis{dissertation,
  title={Tuning hyperparameters in supervised learning models and applications of statistical learning in genome-wide association studies with emphasis on heritability},
  author={Lundell, Jill F.},
  year={2019},
  school={Utah State University},
}

@Manual{apm,
  title={{AppliedPredictiveModeling}: Functions and data sets for applied predictive modeling},
  author={Kuhn, Max and Johnson, Kjell},
  year={2018},
  note={R package version 1.1-7},
  url={https://CRAN.R-project.org/package=AppliedPredictiveModeling},
 }

% mlbench
@Misc{mlbench,
  title={{UCI} repository of machine learning databases, 1998},
  author={Newman, David J and Hettich, SCLB and Blake, Cason L and Merz, Christopher J},
  year={1998},
  url={http://www.ics.uci.edu/~mlearn/MLRepository.html},
  institution={University of California, Irvine, Dept. of Information and Computer Sciences},
}

% R
@Manual{R,
  title={R: {A} language and environment for statistical computing},
  author={{R Core Team}},
  organization={R Foundation for Statistical Computing},
  address={Vienna, Austria},
  year={2022},
  url={https://www.R-project.org/},
 }

% Kuiper
@book{kuiper2013practicing,
  title={Practicing statistics: {G}uided investigations for the second course},
  author={Kuiper, Shonda and Sklar, Jeffrey},
  year={2013},
  publisher={Pearson, Boston, MA, USA},
}

% Ames data set
@article{de2011ames,
  title={Ames, {I}owa: {A}lternative to the {B}oston housing data as an end of semester regression project},
  author={De Cock, Dean},
  journal={Journal of Statistics Education},
  volume={19},
  number={3},
  year={2011},
  publisher={Taylor \& Francis}, 
  doi={10.1080/10691898.2011.11889627},
}

% kaggle
@misc{kaggle,
  title={Kaggle},
  author={Kaggle}, 
  howpublished={\url{https://www.kaggle.com/}},
  year={2019},
  note={Accessed: 2019-02-13},
}

% EZtune
@Article{eztune,
  title={There has to be an easier way: A simple alternative for parameter tuning of supervised learning methods},
  author={Lundell, Jill F.},
  journal={{JSM} Proceedings, Statistical Computing Section. Alexandria, VA: American Statistical Association},
  year={2017},
  pages={3028--3036},
 }
 
% gbm package
@Manual{gbm,
    title = {{gbm}: Generalized Boosted Regression Models},
    author = {Brandon Greenwell and Bradley Boehmke and Jay Cunningham and GBM Developers},
    year = {2022},
    note = {R package version 2.1.8.1},
    url = {https://CRAN.R-project.org/package=gbm},
  }

% optimix
@article{optimx,
  title={On best practice optimization methods in R},
  author={Nash, John C.},
  journal={Journal of Statistical Software},
  volume={60},
  number={2},
  pages={1--14},
  year={2014}, 
  doi={10.18637/jss.v060.i02},
}

% GA
@article{GA,
  title={{GA}: A package for genetic algorithms in R},
  author={Scrucca, Luca},
  journal={Journal of Statistical Software},
  volume={53},
  number={4},
  pages={1--37},
  year={2013},
  publisher={Citeseer},
  doi={10.18637/jss.v053.i04},
}

% tune
@Manual{tune,
    title={{tune}: Tidy tuning tools},
    author={Kuhn, Max},
    year={2022},
    note={R package version 1.0.1},
    url={https://CRAN.R-project.org/package=tune},
  }

% parsnip
@Manual{parsnip,
  title={{parsnip}: A common {API} to modeling and analysis functions},
  author={Kuhn, Max and Vaughan, Davis},
  year={2022},
  note={R package version 1.0.3},
  url={https://CRAN.R-project.org/package=parsnip},
 }

% rsample
@Manual{rsample,
  title={{rsample}: General resampling infrastructure},
  author={Frick, Hannah and Chow, Fanny and Kuhn, Max and Mahoney, Michael and Silge, Julia and Wickham, Hadley},
  year={2022},
  note={R package version 1.1.1},
  url={https://CRAN.R-project.org/package=rsample},
 }

% ant lion
@article{mirjalili2015ant,
  title={The ant lion optimizer},
  author={Mirjalili, Seyedali},
  journal={Advances in Engineering Software},
  volume={83},
  pages={80--98},
  year={2015},
  publisher={Elsevier},
  doi={10.1016/j.advengsoft.2015.01.010},
}

% metaheuristicopt
@Manual{metaheuristicOpt,
  title={{metaheuristicOpt}: Metaheuristic for optimization},
  author={Lala {Septem Riza} and {Iip} and Eddy {Prasetyo Nugroho}},
  year={2019},
  note={R package version 2.0.0},
  url={https://CRAN.R-project.org/package=metaheuristicOpt},
 } 
  
% dragonfly
@article{mirjalili2016dragonfly,
  title={Dragonfly algorithm: A new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems},
  author={Mirjalili, Seyedali},
  journal={Neural Computing and Applications},
  volume={27},
  number={4},
  pages={1053--1073},
  year={2016},
  publisher={Springer},
  doi={10.1007/2Fs00521-015-1920-1},
}

% firefly
@inproceedings{yang2009firefly,
  title={Firefly algorithms for multimodal optimization},
  author={Yang, Xin-She},
  booktitle={International Symposium on Stochastic Algorithms},
  pages={169--178},
  year={2009},
  organization={Springer},
  doi={10.1007/2F978-3-642-04944-6_14},
}

% grasshopper
@article{saremi2017grasshopper,
  title={Grasshopper optimisation algorithm: Theory and application},
  author={Saremi, Shahrzad and Mirjalili, Seyedali and Lewis, Andrew},
  journal={Advances in Engineering Software},
  volume={105},
  pages={30--47},
  year={2017},
  publisher={Elsevier},
  doi={10.1016/2Fj.advengsoft.2017.01.004},
}

@article{mirjalili2014grey,
  title={Grey wolf optimizer},
  author={Mirjalili, Seyedali and Mirjalili, Seyed Mohammad and Lewis, Andrew},
  journal={Advances in Engineering Software},
  volume={69},
  pages={46--61},
  year={2014},
  publisher={Elsevier},
  doi={10.1016/2Fj.advengsoft.2013.12.007},
}

% harmony search
@article{mahdavi2007improved,
  title={An improved harmony search algorithm for solving optimization problems},
  author={Mahdavi, Mehrdad and Fesanghary, Mohammad and Damangir, E.},
  journal={Applied Mathematics and Computation},
  volume={188},
  number={2},
  pages={1567--1579},
  year={2007},
  publisher={Elsevier},
  doi={10.1016/2Fj.amc.2006.11.033},
}

% moth flame
@article{mirjalili2015moth,
  title={Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm},
  author={Mirjalili, Seyedali},
  journal={Knowledge-Based Systems},
  volume={89},
  pages={228--249},
  year={2015},
  publisher={Elsevier},
  doi={10.1016/2Fj.knosys.2015.07.006},
}

% particle swarm
@inproceedings{shi1998modified,
  title={A modified particle swarm optimizer},
  author={Shi, Yuhui and Eberhart, Russell},
  booktitle={1998 IEEE International Conference on Evolutionary Computation Proceedings. IEEE World Congress on Computational Intelligence (Cat. No. 98TH8360)},
  pages={69--73},
  year={1998},
  organization={IEEE},
  doi={10.1109/ICEC.1998.699146},
}

% sine cosine
@article{mirjalili2016sca,
  title={{SCA}: A sine cosine algorithm for solving optimization problems},
  author={Mirjalili, Seyedali},
  journal={Knowledge-Based Systems},
  volume={96},
  pages={120--133},
  year={2016},
  publisher={Elsevier},
  doi={10.1016/2Fj.knosys.2015.12.022},
}

% whale
@article{mirjalili2016whale,
  title={The whale optimization algorithm},
  author={Mirjalili, Seyedali and Lewis, Andrew},
  journal={Advances in Engineering Software},
  volume={95},
  pages={51--67},
  year={2016},
  publisher={Elsevier},
  doi={10.1016/2Fj.advengsoft.2016.01.008},
}

% minqa
@Manual{minqa,
  title={{minqa}: Derivative-free optimization algorithms by quadratic approximation},
  author={Bates, Douglas and Mullen, Katharine M. and Nash, John C. and Varadhan, Ravi},
  year={2022},
  note={R package version 1.2.5},
  url={https://CRAN.R-project.org/package=minqa},
 }

%bobyqua
@article{powell2009bobyqa,
  title={The {BOBYQA} algorithm for bound constrained optimization without derivatives},
  author={Powell, Michael J.D.},
  journal={Cambridge NA Report NA2009/06, University of Cambridge, Cambridge},
  pages={26--46},
  year={2009},
}

% ga
@book{geneticalgorithm,
  title={Genetic algorithms in search optimization and machine learning},
  author={Goldberg, D.},
  year={1999},
  publisher={Addison-Wesley Longman Publishing Company, Boston, MA, USA},
  doi={10.1023/A:1022602019183},
}

% Hookes & Jeeves
@book{hookejeeves,
  title={Distributed generation: Induction and permanent magnet generators},
  author={Lai, Loi Lei and Chan, Tze Fun},
  year={2008},
  publisher={John Wiley \& Sons},
  doi={10.1002/9780470511824},
}

% dfoptim
@Manual{dfoptim,
  title={{dfoptim}: Derivative-free optimization},
  author={Varadhan, Ravi and {Johns Hopkins University} and Borchers, Hans W. and {ABB Corporate Research}.},
  year={2020},
  note={R package version 2020.10-1},
  url={https://CRAN.R-project.org/package=dfoptim},
 }

% lbfgsb3
@Manual{lbfgsb3,
  title={{lbfgsb3}: Limited memory {BFGS} minimizer with bounds on parameters},
  author={Nash, John C. and Zhu, Ciyou and Byrd, Richard and Nocedal, Jorge and Morales, Jose Luis},
  year={2020},
  note={R package version 2020-3.2},
  url={https://CRAN.R-project.org/package=lbfgsb3},
 }

% BFGS
@article{byrd1995limited,
  title={A limited memory algorithm for bound constrained optimization},
  author={Byrd, Richard H. and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  journal={SIAM Journal on Scientific Computing},
  volume={16},
  number={5},
  pages={1190--1208},
  year={1995},
  publisher={SIAM},
  doi={10.1137/0916069},
}

% Nelder-Meade
@book{kelley1999iterative,
  title={Iterative methods for optimization},
  author={Kelley, Carl T.},
  year={1999},
  publisher={Society for Industrial and Applied Mathematics, Philidelphia, PA, USA},
  doi={10.1137/1.9781611970920},
}

% rcgmin
@Manual{Rcgmin,
  title={{Rcgmin}: Conjugate gradient minimization of nonlinear functions with box
constraints},
  author={Nash, John C.},
  year={2022},
  note={R package version 2022-4.30},
  url={https://CRAN.R-project.org/package=Rcgmin},
 }

% BB
@Article{BB,
  title={{BB}: An R package for solving a large system of nonlinear equations and for optimizing a high-dimensional nonlinear objective function},
  author={Varadhan, Ravi and Gilbert, Paul},
  journal={Journal of Statistical Software},
  year={2009},
  volume={32},
  number={4},
  pages={1--26},
  url={http://www.jstatsoft.org/v32/i04/},
  doi={10.18637/jss.v032.i04},
 }

% spectral gradient
@article{birgin2000nonmonotone,
  title={Nonmonotone spectral projected gradient methods on convex sets},
  author={Birgin, Ernesto G. and Mart{\'\i}nez, Jos{\'e} Mario and Raydan, Marcos},
  journal={SIAM Journal on Optimization},
  volume={10},
  number={4},
  pages={1196--1211},
  year={2000},
  publisher={SIAM},
  doi={10.1137/S1052623497330963},
}

@Manual{e1071,
  title={{e1071}: Misc functions of the department of statistics, probability theory group (Formerly: {E1071}), TU Wien},
  author={Meyer, David and Dimitriadou, Evgenia and Hornik, Kurt and Weingessel, Andreas and Leisch, Friedrich},
  year={2022},
  note={R package version 1.7-12},
  url={https://CRAN.R-project.org/package=e1071},
 }

@Manual{ada,
  title={{ada}: The R package {ada} for stochastic boosting},
  author={Culp, Mark and Johnson, Kjell and Michailidis, George},
  year={2016},
  note={R package version 2.0-5},
  url={https://CRAN.R-project.org/package=ada},
  doi={10.18637/jss.v017.i02},
 }

@article{dai2001efficient,
  title={An efficient hybrid conjugate gradient method for unconstrained optimization},
  author={Dai, Yu-Hong and Yuan, Yaxiang},
  journal={Annals of Operations Research},
  volume={103},
  number={1-4},
  pages={33--47},
  year={2001},
  publisher={Springer},
  doi={10.1023/A:1012930416777},
}

@Manual{kernlab,
    title = {{kernlab} : {K}ernel-based machine learning lab},
    author = {Alexandros Karatzoglou and Alex Smola and Kurt Hornik},
    year = {2022},
    note = {R package version 0.9-31},
    url = {https://CRAN.R-project.org/package=kernlab},
}
  
@Manual{xgboost,
    title = {{xgboost}: Extreme gradient boosting},
    author = {Tianqi Chen and Tong He and Michael Benesty and Vadim Khotilovich and Yuan Tang and Hyunsu Cho and Kailong Chen and Rory Mitchell and Ignacio Cano and Tianyi Zhou and Mu Li and Junyuan Xie and Min Lin and Yifeng Geng and Yutian Li},
    year = {2022},
    note = {R package version 1.6.0.1},
    url = {https://CRAN.R-project.org/package=xgboost},
	doi={10.1145/2939672.2939785},
  }

@article{iterativebayes,
  title={Iterative bayes},
  author={Gama, Joao},
  journal={Theoretical Computer Science},
  volume={292},
  number={2},
  pages={417--430},
  year={2003},
  publisher={Elsevier},
  doi={10.1016/S0304-3975(02)00179-2},
}



