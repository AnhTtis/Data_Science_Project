\section{Experiments}
\label{sec:experiments}

\subsection{Setup}
\textbf{Datasets.} We evaluate RFFR with four challenging datasets specifically designed for deepfake detection. We adopt the high quality (HQ) version of Faceforensics++ (FF)~\cite{ff} for training our deepfake detector. Faceforensics++ includes videos of real faces as well as four subsets of fake faces, each manipulated with a different algorithm, namely Deepfakes (DF), Face2Face (F2F), FaceSwap (FSW) and NeuralTextures (NT). We also utilize the test set of Celeb-DF~\cite{celeb-df} and DFDC~\cite{dfdc} for evaluating the cross-dataset performance of our model. Finally, in addition to real faces of Faceforensics++, we adopt the real face images from ForgeryNet (FN)~\cite{forgerynet} for learning RFFR, which helps improve representation learning with additional data.

\textbf{Implementation Details.} We extract the frames from all video datasets and use RetinaFace~\cite{retinaface} to detect and align the faces. All images are scaled to the size of $224 \times 224$. For our RFFR model, we adopt a base version of Masked Autoencoder (MAE)~\cite{mae} and train it on real faces with a batch size of $128$. Following MAE, we set the learning rate at $7.5 \times 10^{-5}$ and adjust it with a schedule with warmup and cosine decay. By default, we train this model with the real faces from both FF~\cite{ff} and FN~\cite{forgerynet}. 

For training the deepfake detector, we divide each image with $k = 4$ (Refer to Appendix for the motivation of choosing $k$). Each block enters the classifier with a probability of $p = 0.25$, and the residual images are amplified by $\alpha=4$. No data augmentation is applied to the images. We initialize both branches of Vision Transformer with ImageNet-pretrained weights and train them with a learning rate of $2 \times 10^{-5}$. During testing, we iteratively mask and restore all blocks to obtain a full residual image for the detector to process. We evaluate the testing results with AUC (Area Under Curve). 

\subsection{Cross-domain performance evaluation}
In this section, we test the performance of our RFFR-based deepfake detector with cross-manipulation and cross-dataset evaluations. 

\textbf{Cross-manipulation evaluations.} We train our deepfake detector on each subset of Faceforensics++ and test on all four subsets to demonstrate our model's ability to identify different manipulations, including those not seen during training. \emph{We adopt the HQ version of FF for both training and testing, and only use one frame every video for testing.} We compare our results with state-of-the-art image-based methods Multi-Attention~\cite{multiatt}, DCL~\cite{dcl}, RECCE~\cite{recce} and UIA-ViT~\cite{uia}. We ran the public code of RECCE and UIA-ViT to produce results under the same setting.

In~\cref{tab:cross-manipulation}, we show that our method outperforms the state-of-the-art methods under most settings, with a maximum improvement of $10.25\%$ (F2F $\rightarrow$FSW). Meanwhile, our model remains effective under the four intra-domain settings, which are shown in gray. The method tends to slightly underperform when trained on NeuralTextures, likely because its manipulation patterns only exist in certain small regions, and may be neglected during our block sampling. Nevertheless, compared to existing methods, our deepfake detector yields much better overall performances. 

\begin{table}[t]
\setlength\tabcolsep{4.5pt} 
\caption{Cross-manipulation performances in terms of AUC(\%) compared with previous methods. Classifiers are trained on one subset of FF and tested on all four subsets. Intra-domain results are marked in gray. We ran the public code of methods marked with "*" to produce results under identical settings \emph{(HQ for training and single frames for testing).}}
\vspace{-1.5em}
\label{tab:cross-manipulation}
\begin{center}  
\scalebox{0.80}{
\begin{tabular}{c|l|cccc|c}
\toprule
Training &\multirow{2}*{Method} & \multicolumn{4}{c|}{Test data} & \multirow{2}*{Avg} \\
\cmidrule(lr){3-6}
     data  &            ~                   & DF    & F2F   & FSW   & NT    & ~   \\
     
\midrule
\multirow{5}*{DF}
& MultiAtt~\cite{multiatt} & \cellcolor{Gray}99.92 & 75.23 & 40.61 & 71.08 & 71.71                \\ 
& DCL~\cite{dcl}       & \cellcolor{Gray}\textbf{99.98} & \textbf{77.13} & 61.01 & 75.01 & 78.28              \\
& RECCE*~\cite{recce}     & \cellcolor{Gray}99.19 & 74.39 & 57.42 & \textbf{85.04} & 79.01                \\ 
& UIA-ViT*~\cite{uia}  & \cellcolor{Gray}99.39      &   74.44    &   53.89    &   70.92    & 74.66 \\ 
& Ours  & \cellcolor{Gray}99.19 & 76.61 & \textbf{68.96} & 74.83 & \textbf{79.90}            \\ 
       
\midrule
\multirow{5}*{F2F}
        & MultiAtt~\cite{multiatt}       & 86.15 & \cellcolor{Gray}99.13 & 60.14 & 64.59 & 77.50 \\
        & DCL~\cite{dcl}       & 91.91 & \cellcolor{Gray}99.21 & 59.58 & 66.67 & 79.34 \\
       & RECCE*~\cite{recce}       & 88.04 & \cellcolor{Gray}98.93 & 67.35 & 74.16 & 82.12 \\
       & UIA-ViT*~\cite{uia}       & 83.39 & \cellcolor{Gray}98.32 & 68.37 & 67.17 & 79.31 \\
       & Ours                                  & \textbf{93.75} & \cellcolor{Gray}\textbf{99.61} & \textbf{78.62} & \textbf{79.56} & \textbf{87.81} \\

\midrule
\multirow{5}*{FSW}
& MultiAtt~\cite{multiatt} & 64.13 & 66.39 & \cellcolor{Gray}99.67 & 50.10 & 70.07              \\
& DCL~\cite{dcl}           & 74.80 & 69.75 & \cellcolor{Gray}99.90 & 52.60 & 74.26              \\
& RECCE*~\cite{recce}       & 66.66 & 73.66 & \cellcolor{Gray}\textbf{99.76} & \textbf{57.46} & 74.39               \\

& UIA-ViT*~\cite{uia}       &   81.02    &   66.30    & \cellcolor{Gray}99.04      &   49.26    & 73.91 \\ 
& Ours                                           & \textbf{87.46} & \textbf{75.96} & \cellcolor{Gray}99.42 & 55.87 & \textbf{79.68}            \\ 

\midrule
\multirow{5}*{NT}
& MultiAtt~\cite{multiatt} & 87.23 & 75.33 & 48.22 & \cellcolor{Gray}98.66 & 77.36                \\
& DCL~\cite{dcl}      & 91.23 & 79.31 & 52.13 & \cellcolor{Gray}\textbf{98.97} & 80.41                \\
& RECCE*~\cite{recce}    & \textbf{90.20}  & 76.65 & \textbf{58.06} & \cellcolor{Gray}97.17 & \textbf{80.52}                \\
 & UIA-ViT*~\cite{uia}  &    79.37   &   67.98    &   45.94    &\cellcolor{Gray}94.59       & 71.97 \\
 & Ours     & 84.31 & \textbf{81.04} & 54.67 & \cellcolor{Gray}96.19 & 79.05          \\
       
\bottomrule
\end{tabular}}
\vspace{-2em}
\end{center}
\end{table}

\textbf{Cross-dataset evaluations.} We train our model on the Faceforensics++ dataset and evaluate its performance on the test sets of Celeb-DF\cite{celeb-df} and DFDC~\cite{dfdc}. Specifically, following the previous practice in~\cite{lip}, we validate the model on Celeb-DF and use the selected model to test on DFDC.  \emph{We adopt the HQ version of FF for training, and only use one frame every video for testing.} Under the same setting, we ran the public code of RECCE~\cite{recce}, UIA-ViT~\cite{uia} and SBI~\cite{sbi} to produce corresponding results. In Table~\ref{tab:cross-dataset}, we show a competitive performance with existing image-based methods, signaling satisfying adaptability of RFFR to different datasets, especially high quality datasets like Celeb-DF. 
  
SBI~\cite{sbi} is a recent powerful deepfake detection method. By utilizing a hand-crafted blending algorithm to produce diverse fake samples, it achieves highly competitive performances on datasets including Celeb-DF. We show that by training on fake samples generated by SBI, our approach can further improve upon their state-of-the-art result. 

\begin{table}[]
\setlength\tabcolsep{4.5pt} 
\caption{Cross-dataset performances in terms of AUC(\%) compared with previous methods. Classifiers are trained on FF and tested on Celeb-DF and DFDC. We ran the public code of methods marked with "*" to produce results under identical settings \emph{(HQ for training and single frames for testing).}}
\vspace{-1em}
\label{tab:cross-dataset}
\begin{center}  
\scalebox{0.90}{
\begin{tabular}{l|cc}
\toprule
\multirow{2}*{Method} & \multicolumn{2}{c}{Test data}\\
\cmidrule{2-3}
        ~                           &     Celeb-DF         &  DFDC \\
\midrule
      Xception~\cite{xception}  &     65.30       &    -  \\
      Face X-ray~\cite{xray}          &     74.20       &     70.00 \\
      MultiAtt~\cite{multiatt}        &     67.44       &     67.34 \\
      SPSL~\cite{SPSL}                &     76.88        &   -  \\
      SOLA~\cite{sola}                &       76.02         &  -    \\
      SLADD~\cite{sladd}              &    79.70       &  -  \\
      RECCE*~\cite{recce}             &     68.94       &   68.34   \\
      UIA-ViT*~\cite{uia}             &     80.31      &   67.93   \\
      SBI*~\cite{sbi}                       &       86.46     &   66.60     \\
\midrule
 	Ours                                      &   81.97  & \textbf{72.08}  \\
    Ours + SBI~\cite{sbi}                  &  \textbf{88.98}           &    67.84   \\
\bottomrule
\end{tabular}}
\vspace{-2.5em}
\end{center}
\end{table}

\subsection{Ablation Study}
\label{ablation}

In this section, we analyze the effect of our implementations for RFFR learning and deepfake detection. 

\textbf{Effect of the training data for RFFR.} The effectiveness of deepfake detection with RFFR depends on the quality of representation learning, where the real faces plays an important role. In this experiment, we examine the effect of scaling the real face dataset for representation learning. As a baseline, we learn RFFR with only real faces from Faceforensics++ (FF), the same data we use for the downstream classification tasks. Meanwhile, another model is supplemented with real faces from both FF and ForgeryNet (FN), a significantly larger and more diverse dataset. We train deepfake detectors on the F2F subset of FF with residual images produced by these two models. In Table~\ref{tab:data}, we demonstrate that including the extra dataset of ForgeryNet for learning RFFR consistently improves the performances of the deepfake detector in all tests, creating a maximum performance gain of $9.57\%$  in terms of AUC (F2F $\rightarrow$ NT).

We note that learning RFFR with FF already allows our deepfake detector to outperform the state-of-the-arts. Nevertheless, learning with extra data enhances the efficacy of our real face foundation representations, and further improves the downstream task of deepfake detection. Therefore, refining the representation learning of real faces, especially with large-scale datasets, could be a viable path for further improving generalized deepfake detection. 

In addition, we examine the scalability of RECCE under the same setting, considering that RECCE~\cite{recce} also involves learning to reconstruct real samples for deepfake detection. However, their performance gain is less significant than ours. Although the reconstruction branch of RECCE~\cite{recce} is able to highlight forgery cues with residual images, they tend to involve more background noise caused by imperfect reconstructions, as depicted in~\cref{fig:unet_comparison},. This undermines the ability of residual images to expose artifacts for deepfake detection. 

\begin{table}[t]
\setlength\tabcolsep{4.5pt} 
\caption{Deepfake detection performances of RECCE~\cite{recce} and our method with different real face dataset, namely the real faces from Faceforensics++ (FF) alone, and FF combined with ForgeryNet (FF + FN). Classifiers are trained on F2F and tested on four subsets of FF. We present the results in AUC (\%).  }
\vspace{-1.5em}
\label{tab:data}
\begin{center}  
\scalebox{0.90}{
\begin{tabular}{c|c|cccc|c}
\toprule
\multirow{2}*{Method} & Real face  & \multicolumn{4}{c|}{Test data} & \multirow{2}*{Avg} \\
\cmidrule(lr){3-6}
&dataset  &      DF    & F2F   & FSW   & NT    & ~   \\
    \midrule
\multirow{2}*{RECCE~\cite{recce}}&FF           & 88.04          & 98.93          & 67.35          & 74.16          & 82.12          \\
&FN + FF &  90.12       & 99.24       & 69.89    & 79.59     & 84.71		\\
    \midrule
\multirow{2}*{Ours}&FF           & 90.16          & 98.56          & 74.10          & 69.99          & 83.20          \\
&FN + FF & \textbf{93.44}       & \textbf{99.61}        & \textbf{78.62}       & \textbf{79.56}        & \textbf{87.81}		\\
\bottomrule
\end{tabular}}
\vspace{-1em}
\end{center}
\end{table}

\textbf{Effect of masked image modeling for RFFR.} We analyze the effect of using MIM-based residual images for deepfake detection. We train a UNet-based autoencoder (AE) to learn the reconstruction of real faces and obtain residual images. Our MIM-trained inpainting model and the AE are compared on the quality of reconstruction in~\cref{fig:unet_comparison}. Note that despite being trained with real faces, the AE "generalizes" well to fake images, preserving delicate details, including the artifacts caused by manipulations. Such generalization leaves the residual images empty with little information. 

\begin{figure}
\centering
  \includegraphics[width=0.9\columnwidth]{figs/compare_ICCV_Final.pdf}
  \vspace{-1em}
   \caption{Reconstruction results and residual images of the autoencoder (AE), RECCE~\cite{recce} and our inpainting model. AE reconstructs both images perfectly, leaving no information in residual images. RECCE~\cite{recce} suffers from insufficient training. Our model successfully highlights potential artifacts in the residual image of only the fake face, and therefore can best facilitate deepfake detection. }
\vspace{-1em}
\label{fig:unet_comparison}
\end{figure}

Masked image modeling enables our model to learn better real face representations and inpaint fake faces with real textures instead of artifacts. In the downstream task of deepfake detection,  our classifier generalizes significantly better than the AE-based classifier, which performs only marginally better than learning with no residuals (detailed in Appendix). Both the reconstruction results and the downstream performance confirm the validity of our choice to learn RFFR with MIM instead of direct reconstruction. 


\textbf{Effect of classifier backbone.} In Table~\ref{tab:backbone}, we present the deepfake detection results of vanilla Xception~\cite{xception} and Vision Transformer (ViT)~\cite{vit}, both trained with full original images. The models are trained with the F2F subset of FF and tested on all four subsets. While a larger backbone increases a deepfake detector's generalization performance in some cases, it is not the primary factor of our performance improvement. Instead, it is the residual input aided by RFFR that leads the performance gain.

\begin{table}[t]
\setlength\tabcolsep{4.5pt} 
\caption{Comparing ours results with vanilla backbones. We present the results in AUC (\%).  }
\label{tab:backbone}
\vspace{-1.5em}
\begin{center}  
\scalebox{0.90}{
\begin{tabular}{c|c|cccc|c}
\toprule
Training  &  \multirow{2}*{Method}    &   \multicolumn{4}{c|}{Test Data} & \multirow{2}*{Avg} \\
\cmidrule(lr){3-6}
 data  &   ~  &   DF    & F2F   & FSW   & NT    & ~   \\
    \midrule
\multirow{3}*{F2F} & Xception~\cite{xception} & 84.94          & 99.26          & 58.82          & 71.19          & 78.55          \\
                                   & ViT~\cite{vit}      & 84.25          & 97.89          & 65.53          & 65.18          & 78.21          \\
                                   & Ours     & \textbf{93.44} & \textbf{99.61} & \textbf{78.62} & \textbf{79.56} & \textbf{87.81} \\
\bottomrule
\end{tabular}}
\vspace{-1.5em}
\end{center}
\end{table}

\textbf{Effect of classifier design.} We compare different variants of our classifier design. Specifically, we analyze the performance gains brought by the introduction of two branches and the random input mechanism. We test six variants of our classifier by training them with the F2F subset of FF and testing with the FSW subset. The settings of these variants are specified by the input data they accept, as shown in~\cref{tab:classifier}. 

\begin{table}[t]
\caption{Deepfake detection performances with classifiers of different inputs in terms of AUC (\%). We train the classifiers on F2F and test on FSW.}
\label{tab:classifier}
\vspace{-1.5em}
\begin{center}
\begin{tabular}{c|c|c|c|c}
\toprule
\multicolumn{2}{c|}{Original Image} & \multicolumn{2}{c|}{Residual Image} & \multirow{2}*{AUC (\%)} \\
\cline{1-4}
               Full        &             Random           &          Full          &          Random          &   ~\\
 \hline
\checkmark        &                                       &                            &                                   &  65.53\\
% \hline
                              &                                      &   \checkmark    &                                   &  66.30  \\
 %\hline
\checkmark        &                                      &   \checkmark    &                                   &  71.48  \\
 %\hline
                             &       \checkmark          &                             &                                   &  70.76  \\
%\hline
                             &                                       &                             &      \checkmark       &  68.10  \\
 %\hline
                             &        \checkmark         &                             &      \checkmark       &  \textbf{78.62}  \\
\bottomrule
\end{tabular}
\vspace{-2em}
\end{center}
\end{table}

\begin{table*}[t]
\setlength\tabcolsep{4.5pt} 
\caption{Deepfake detection performances of validated and non-validated models. Classifiers are trained on F2F and tested on four subsets of FF. We present the results and the performance gaps in AUC (\%). Second best results are underlined. }
\label{tab:validation}
\vspace{-1em}
\begin{center}  
\scalebox{0.90}{
\begin{tabular}{c|c|llll|l}
\toprule
\multirow{2}*{Method}  & \multirow{2}*{Validated} & \multicolumn{4}{c|}{Test Data} & \multirow{2}*{Avg} \\
\cmidrule(lr){3-6}
~                   &                      ~                   &      DF               & F2F                    & FSW                 & NT                    & ~   \\
    \midrule
\multirow{2}*{Xception\cite{xception}} &   \checkmark    & 84.94                 & 99.26                & 58.82                 & 71.19                & 78.55            \\
~ &                                             -                              & 83.08   (- 1.86) & 99.12   (- 0.14) & 46.63   (- 12.19) & 64.93   (- 6.26)  & 73.44   (- 5.11)  \\
 \hline
 \multirow{2}*{RECCE\cite{recce}} &\checkmark               & 88.04                & 98.93                 & 67.35                & 74.16                & 82.12            \\
 ~&                                                -                  & 74.51   (- 8.57) & 99.22   (+ 0.29)  & 50.17   (- 17.18) & 59.46   (- 14.70)  & 70.84   (- 11.28) \\
 \hline
\multirow{2}*{Ours} &    \checkmark  & \textbf{93.44}            & \textbf{99.61}            & \textbf{78.62}            & \textbf{79.56}            & \textbf{87.81}            \\
 ~&  - & \underline{91.56} (- 1.88) & \underline{99.39}   (- 0.22) & \underline{76.00}   (- 2.62)  & \underline{76.41} (- 3.15) & \underline{85.84}   ( - 1.97)    \\
\hline
\end{tabular}}
\vspace{-2em}
\end{center}
\end{table*}

We treat the vanilla ViT with full original image input as a baseline, which achieves an AUC of $65.53\%$. By switching to accept the full residual images, we obtain a $0.77\%$ performance gain. Combining the two modalities to form a dual-branch classifier further increases our result to $71.48\%$. This demonstrates that the artifacts are better exploited when both the original and the residual images enter the classifier, and are used as references to each other. Therefore, both modalities should be considered for classification. 

In addition, we improve on the test by merely modifying the baseline ViT to accept randomly selected original image blocks. This results in a $5.23\%$ increase in performance. Similarly, changing full residual input to random residual blocks also results in a $1.8\%$ improvement. These observations confirm our hypothesis in \cref{sec:method_deepfake_detection} that models benefit from learning with random inputs, which prevents the model from only focusing on the most prominent features in an image, and forces it to learn from subtle artifacts. 

Finally, bringing in the random input mechanism for the dual-branch classifier completes our full implementation, which maximally exploits the artifacts exposed by RFFR and achieves the best performance of $78.62\%$. 



\subsection{Validation-free Model Selection}
\label{sec:validation-free}

\begin{figure}
\centering
  \includegraphics[width=0.5\textwidth]{figs/validation-free_ICCV_Final.png}
  \vspace{-1.5em}
   \caption{Comparing the validation curves of RFFR-based deepfake detector and previous methods. Detectors are trained on the F2F subset of FF for $15k$ iterations and validated on four different subsets. (a) to (d) correspond to experiments on DF, F2F, FSW and NT.  Results are reported in AUC (\%). All three methods perform well when validated on F2F. However, under cross-manipulation settings, only our method avoids overfitting during training. The curves are smoothed for better visibility.}
\label{fig:validation-free}
\vspace{-1em}
\end{figure}

Models expected to generalize to other domains benefit from target domain validations~\cite{domainbed}. By frequently performing model validation, we can select the model  that best suits the detection of target manipulation, resulting in high performance on the test set. While using such an \textit{oracle} could be acceptable for the early development of cross-domain algorithms~\cite{domainbed}, it is not ideal for applications, as labeled data of unseen manipulation is usually not available. 

In this section, we demonstrate the potential of our deepfake detector to circumvent this practice and therefore avoid the need for extra validation data. As shown in \cref{tab:validation}, we train our classifier on F2F for 15k iterations and directly use the final model for testing. Simultaneously, we employ four validation sets to select the models with the best validation performances on target data. All validated and non-validated models are tested under the same conditions. We report all results on the target test sets in Table~\ref{tab:validation}. The performance gaps between validated and non-validated models are reported along with the test results. Although our non-validated models are not performing as well as those selected with a validation set, we show that our model remains effective on target data, with a maximum performance drop of $3.15\%$ and an average drop of $1.97\%$. However, previous methods~\cite{xception, recce} suffer from significantly larger performance drops when evaluated under the same procedure. 

To take a closer look at how the cross-manipulation performances vary during training, we train the deepfake detectors again with F2F. We test the AUC performances on all target subsets every 50 iterations to produce validation curves in \cref{fig:validation-free}. Our RFFR-based deepfake detector consistently maintains a high performance long after its peaks without serious overfitting. On the contrary, both previous methods compared here overfit quickly after reaching their highest target domain performances. In addition, compared methods exhibit large fluctuations across different evaluations, while our model remains stable. This suggests that with RFFR, our model focuses exclusively on generalizable features which fall outside the distribution of RFFR. Such resistance to overfitting guarantees our model a satisfying performance even when labeled validation sets are not available, which is generally expected in practice. We present more results on validation-free evaluations in Appendix.