\section{Related Work}
\label{sec:related}

We briefly review related works of deepfake detection, representation learning and anomaly detection.

\subsection{Deepfake Detection}
\textbf{Traditional methods.} 
Deepfake detection has drawn much attention since the first emergence of face manipulation algorithms~\cite{deepfakes}. Traditional methods use pre-determined features to spot the imperfections in deepfakes, such as inconsistent headposes~\cite{headposes} and eye-blinking~\cite{blink}. On the other hand, the introduction of large deepfakes datasets, such as Faceforensics++~\cite{ff}, fuels the development of learning-based approaches. With the help of such datasets, it is found that without designating specific features, a deep CNN-based binary classifier performs well enough on recognizing specific manipulations, given the model has been trained on images created with this particular manipulation~\cite{ff}.

\textbf{Cross-manipulation methods.} As a result of drastic differences between various types of manipulations, it is hard for a model to detect the artifacts of manipulations that are not contained in training set~\cite{xray, celeb-df}. Therefore, many works turn to focus on improving the generalization performance of deepfake detectors, most of which are based on the extensions of earlier feature-based methods. They utilize the most common artifacts available in existing datasets, such as inconsistency in videos~\cite{lip}, blending boundaries~\cite{xray}, biological signals~\cite{fake_catcher}, and frequency artifacts~\cite{f3net, SPSL}. Although these features are proven effective, many rely on glitches made by primitive manipulations, which may not be detectable in further improved manipulations. To facilitate generalization to a broader range of manipulations, some studies enrich the distribution of fake data by creating new fake face images~\cite{sladd, sbi}, and bring significant improvements over existing methods. 

\textbf{Reconstruction learning-based methods.} Reconstruction learning for deepfake detection has emerged in some pioneering works. One method~\cite{ocfakedect} trains autoencoders with real samples and directly identify samples with large reconstruction error as deepfakes. Denoising~\cite{recce}, colorization, and super-resolution~\cite{beyondspectrum} have been used as reconstruction targets for real samples as well. Compared to these whole-image reconstruction approaches, our method uses masked image modeling to learn real face representations more effectively and yields better generalization performance.

\subsection{Representation Learning with Unlabeled Data}
Computer vision tasks have greatly benefited from pre-training on large datasets. In recent years, self-supervised pre-training is gaining increasing popularity as they learn effective representations without any labeled data. Earlier methods learn representations with pretext tasks like solving jigsaws~\cite{jigsaw}, predicting rotations~\cite{rotation}, and colorization~\cite{colorization}. More recently, contrastive learning~\cite{simclr, moco} learns to aggregate different views of the same image and disperse different images in the representation space. Masked image modeling (MIM)~\cite{beit, mae, simmim} trains models to predict masked regions of input images, a training mechanism we adopt for RFFR. By learning representations with effective pretext tasks, models for specific vision tasks can achieve significantly better results than learning from scratch.

Besides learning general image representations, learning with data from certain domains can also facilitate specific downstream tasks~\cite{realforensics, voice-face, faceunit}. Among this line of work, RealForensics~\cite{realforensics} is the most similar work to ours. This study uses contrastive learning to learn audiovisual representations of real face videos in the hope of improving deepfake detection. However, learning from static real face images, the direct sources of face manipulations, is still left unexplored. In this work, we use MIM-based representation learning to show that without temporal features or audio correspondence, learning the representation of static faces provides abundant information to facilitate deepfake detection as well.

\begin{figure*}
\begin{center}
\vspace{-1.5em}
   \includegraphics[width=0.95\linewidth]{figs/Main_ICCV_Final.pdf}
\end{center}
\vspace{-2em}
   \caption{Pipeline of our RFFR-based deepfake detection. (a) We use real faces to train a representation learning model by masked image modeling, which learns to reconstruct masked regions of real faces by minimizing reconstruction error $L_{rec}$. We expect this model to encode masked faces to real face foundation representations (RFFR) and decode the RFFRs to faithfully reconstruct masked real images, but fail at fake images. 
   (b) We mask random blocks of a suspected image for the trained inpainter to reconstruct. The original image blocks are subtracted from the output of the model to create residual image blocks, which signals artifacts. We train a dual-branch ViT classifier with $L_{cls}$ to identify deepfakes with both the original image blocks and the residual image blocks. }
\label{fig:pipeline}
\vspace{-1.5em}
\end{figure*}

\subsection{Anomaly Detection}
Anomaly detection is another task closely related to our research, which aims to identify abnormal data that deviate from a specific distribution. One strategy of anomaly detection is implicitly learning the representation of normality by reconstructing normal samples. Anomalies are identified as they can not be properly reconstructed.  ~\cite{ADReview}.

A major problem of this approach is that autoencoders often generalize well enough for both normal and abnormal samples. To avoid learning such identity mappings, some studies equip the autoencoder with a memory~\cite{memae, block_memory} to perform reconstruction based on only limited prototypes. Others~\cite{ocgan} introduce discriminators to adversarially learn distributions that strictly corresponds to the normal data distribution. In this work, we turn to train MIM models, so that local image blocks are predicted based on the neighborhood instead of themselves, thus avoiding identity mappings.