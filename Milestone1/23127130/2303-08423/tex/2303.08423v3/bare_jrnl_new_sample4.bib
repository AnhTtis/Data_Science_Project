
@article{liu2023communication,
  title={Communication-Efficient Design for Quantized Decentralized Federated Learning},
  author={Chen, Li and  Liu, Wei and Chen, Yunfei and Wang, Weidong},
  journal={arXiv preprint arXiv:2303.08423},
  year={{2023. [Online]. Available: }{\color{blue}{https://arxiv.org/abs/2303.08423}}}
}

@article{ang2020robust,
  title={Robust federated learning with noisy communication},
  author={Ang, Fan and Chen, Li and Zhao, Nan and Chen, Yunfei and Wang, Weidong and Yu, F Richard},
  journal={IEEE Trans. Commun.},
  volume={68},
  number={6},
  pages={3452--3464},
  year={2020},
  publisher={IEEE}
}


@article{faghri2020adaptive,
  title={Adaptive gradient quantization for data-parallel {SGD}},
  author={Faghri, Fartash and Tabrizian, Iman and Markov, Ilia and Alistarh, Dan and Roy, Daniel M and Ramezani-Kebrya, Ali},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3174--3185},
  year={2020}
}
@article{max1960quantizing,
  title={Quantizing for minimum distortion},
  author={Max, Joel},
  journal={IRE Transactions on Information Theory},
  volume={6},
  number={1},
  pages={7--12},
  year={1960},
  publisher={IEEE}
}
@article{lloyd1982least,
  title={Least squares quantization in {PCM}},
  author={Lloyd, Stuart},
  journal={IEEE Trans. Inf. Theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}
@article{kieffer1982exponential,
  title={Exponential rate of convergence for Lloyd's method I},
  author={Kieffer, J},
  journal={IEEE Trans. Inf. Theory},
  volume={28},
  number={2},
  pages={205--210},
  year={1982},
  publisher={IEEE}
}
@book{bekkerman2011scaling,
  title={Scaling up machine learning: Parallel and distributed approaches},
  author={Bekkerman, Ron and Bilenko, Mikhail and Langford, John},
  year={2011},
  publisher={Cambridge University Press}
}
@inproceedings{chilimbi2014project,
  title={Project adam: Building an efficient and scalable deep learning training system},
  author={Chilimbi, Trishul and Suzue, Yutaka and Apacible, Johnson and Kalyanaraman, Karthik},
  booktitle={11th USENIX symposium on operating systems design and implementation (OSDI 14)},
  pages={571--582},
  year={2014}
}
@article{recht2011hogwild,
  title={Hogwild!: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
@article{chaturapruek2015asynchronous,
  title={Asynchronous stochastic convex optimization: the noise is in the noise and {SGD} don't care},
  author={Chaturapruek, Sorathan and Duchi, John C and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}
@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth annual conference of the international speech communication association},
  year={2014}
}
@inproceedings{strom2015scalable,
  title={Scalable distributed {DNN} training using commodity {GPU} cloud computing},
  author={Strom, Nikko},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@article{stich2018sparsified,
  title={Sparsified {SGD} with memory},
  author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{aji2017sparse,
  title={Sparse Communication for Distributed Gradient Descent},
  author={Aji, Alham Fikri and Heafield, Kenneth},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={440--445},
  year={2017}
}
@article{wen2017terngrad,
  title={Terngrad: Ternary gradients to reduce communication in distributed deep learning},
  author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{alistarh2017qsgd,
  title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{mishchenko2021intsgd,
  title={{IntSGD}: Adaptive Floatless Compression of Stochastic Gradients},
  author={Mishchenko, Konstantin and Wang, Bokun and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@inproceedings{horvoth2022natural,
  title={Natural compression for distributed deep learning},
  author={Horv{\'o}th, Samuel and Ho, Chen-Yu and Horvath, Ludovit and Sahu, Atal Narayan and Canini, Marco and Richt{\'a}rik, Peter},
  booktitle={Mathematical and Scientific Machine Learning},
  pages={129--141},
  year={2022},
  organization={PMLR}
}
@article{ramezani2021nuqsgd,
  title={{NUQSGD}: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization.},
  author={Ramezani-Kebrya, Ali and Faghri, Fartash and Markov, Ilya and Aksenov, Vitalii and Alistarh, Dan and Roy, Daniel M},
  journal={J. Mach. Learn. Res.},
  volume={22},
  pages={114--1},
  year={2021}
}

@article{qu2021feddq,
  title={{FedDQ}: Communication-Efficient Federated Learning with Descending Quantization},
  author={Qu, Linping and Song, Shenghui and Tsui, Chi-Ying},
  journal={arXiv preprint arXiv:2110.02291},
  year={2021}
}

@article{tang2018communication,
  title={Communication compression for decentralized training},
  author={Tang, Hanlin and Gan, Shaoduo and Zhang, Ce and Zhang, Tong and Liu, Ji},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{koloskova2019decentralized,
  title={Decentralized stochastic optimization and gossip algorithms with compressed communication},
  author={Koloskova, Anastasia and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3478--3487},
  year={2019},
  organization={PMLR}
}
@article{koloskova2019decentralized1,
  title={Decentralized deep learning with arbitrary communication compression},
  author={Koloskova, Anastasia and Lin, Tao and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:1907.09356},
  year={2019}
}
@article{liu2022decentralized,
  title={Decentralized federated learning: Balancing communication and computing costs},
  author={Liu, Wei and Chen, Li and Zhang, Wenyi},
  journal={IEEE Trans. Signal Inf. Process. Networks},
  volume={8},
  pages={131--143},
  year={2022},
  publisher={IEEE}
}
@article{tang2019deepsqueeze,
  title={Deepsqueeze: Decentralization meets error-compensated compression},
  author={Tang, Hanlin and Lian, Xiangru and Qiu, Shuang and Yuan, Lei and Zhang, Ce and Zhang, Tong and Liu, Ji},
  journal={arXiv preprint arXiv:1907.07346},
  year={2019}
}
@article{reisizadeh2019exact,
  title={An exact quantized decentralized gradient descent algorithm},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Pedarsani, Ramtin},
  journal={IEEE Trans. Signal Process.},
  volume={67},
  number={19},
  pages={4934--4947},
  year={2019},
  publisher={IEEE}
}
@inproceedings{kovalev2021linearly,
  title={A linearly convergent algorithm for decentralized optimization: Sending less bits for free!},
  author={Kovalev, Dmitry and Koloskova, Anastasia and Jaggi, Martin and Richtarik, Peter and Stich, Sebastian},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4087--4095},
  year={2021},
  organization={PMLR}
}
@article{wang2021cooperative,
  title={Cooperative {SGD}: A unified framework for the design and analysis of local-update {SGD} algorithms},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={Journal of Machine Learning Research},
  volume={22},
  year={2021}
}
@article{wang2019adaptive,
  title={Adaptive federated learning in resource constrained edge computing systems},
  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
  journal={IEEE J. Sel. Areas Commun.},
  volume={37},
  number={6},
  pages={1205--1221},
  year={2019},
  publisher={IEEE}
}
@inproceedings{reisizadeh2020fedpaq,
  title={Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2021--2031},
  year={2020},
  organization={PMLR}
}
@article{liu2020accelerating,
  title={Accelerating federated learning via momentum gradient descent},
  author={Liu, Wei and Chen, Li and Chen, Yunfei and Zhang, Wenyi},
  journal={IEEE Trans. Parallel Distrib. Syst.},
  volume={31},
  number={8},
  pages={1754--1766},
  year={2020},
  publisher={IEEE}
}

@inproceedings{yu2019parallel,
  title={Parallel restarted {SGD} with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={5693--5700},
  year={2019}
}

@article{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{stich2018local,
  title={Local {SGD} Converges Fast and Communicates Little},
  author={Stich, Sebastian U},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{jiang2018linear,
  title={A linear speedup analysis of distributed deep learning with sparse and quantized communication},
  author={Jiang, Peng and Agrawal, Gagan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{yu2019linear,
  title={On the linear speedup analysis of communication efficient momentum {SGD} for distributed non-convex optimization},
  author={Yu, Hao and Jin, Rong and Yang, Sen},
  booktitle={International Conference on Machine Learning},
  pages={7184--7193},
  year={2019},
  organization={PMLR}
}
@inproceedings{jhunjhunwala2021adaptive,
  title={Adaptive quantization of model updates for communication-efficient federated learning},
  author={Jhunjhunwala, Divyansh and Gadhikar, Advait and Joshi, Gauri and Eldar, Yonina C},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3110--3114},
  year={2021},
  organization={IEEE}
}
@article{mo2022feddq,
  title={{FedDQ}: A communication-efficient federated learning approach for Internet of Vehicles},
  author={Mo, Zijia and Gao, Zhipeng and Zhao, Chen and Lin, Yijing},
  journal={Journal of Systems Architecture},
  volume={131},
  pages={102690},
  year={2022},
  publisher={Elsevier}
}
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proc. IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{chiang2016fog,
  title={{Fog and IoT}: An overview of research opportunities},
  author={Chiang, Mung and Zhang, Tao},
  journal={IEEE Internet Things J.},
  volume={3},
  number={6},
  pages={854--864},
  year={2016},
  publisher={IEEE}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{hard2018federated,
  title={Federated learning for mobile keyboard prediction},
  author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Fran{\c{c}}oise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chlo{\'e} and Ramage, Daniel},
  journal={arXiv preprint arXiv:1811.03604},
  year={2018}
}
@article{samarakoon2019distributed,
  title={Distributed federated learning for ultra-reliable low-latency vehicular communications},
  author={Samarakoon, Sumudu and Bennis, Mehdi and Saad, Walid and Debbah, M{\'e}rouane},
  journal={IEEE Trans. Commun.},
  volume={68},
  number={2},
  pages={1146--1159},
  year={2019},
  publisher={IEEE}
}
@inproceedings{liu2020federated,
  title={Federated learning for vision-and-language grounding problems},
  author={Liu, Fenglin and Wu, Xian and Ge, Shen and Fan, Wei and Zou, Yuexian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11572--11579},
  year={2020}
}
@inproceedings{vanhaesebrouck2017decentralized,
  title={Decentralized collaborative learning of personalized models over networks},
  author={Vanhaesebrouck, Paul and Bellet, Aur{\'e}lien and Tommasi, Marc},
  booktitle={Artificial Intelligence and Statistics},
  pages={509--517},
  year={2017},
  organization={PMLR}
}

@INPROCEEDINGS{9154332,
  author={Xing, Hong and Simeone, Osvaldo and Bi, Suzhi},
  booktitle={2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, 
  title={Decentralized Federated Learning via {SGD} over Wireless {D2D} Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/SPAWC48557.2020.9154332}}

@inproceedings{lalitha2018fully,
  title={Fully decentralized federated learning},
  author={Lalitha, Anusha and Shekhar, Shubhanshu and Javidi, Tara and Koushanfar, Farinaz},
  booktitle={Third workshop on bayesian deep learning (NeurIPS)},
  volume={2},
  year={2018}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}

@article{oh2022communication,
  title={Communication-efficient federated learning via quantized compressed sensing},
  author={Oh, Yongjeong and Lee, Namyoon and Jeon, Yo-Seb and Poor, H Vincent},
  journal={IEEE Trans. Wireless Commun.},
  volume={22},
  number={2},
  pages={1087--1100},
  year={2022},
  publisher={IEEE}
}

@inproceedings{vargaftik2022eden,
  title={Eden: Communication-efficient and robust distributed mean estimation for federated learning},
  author={Vargaftik, Shay and Basat, Ran Ben and Portnoy, Amit and Mendelson, Gal and Itzhak, Yaniv Ben and Mitzenmacher, Michael},
  booktitle={International Conference on Machine Learning},
  pages={21984--22014},
  year={2022},
  organization={PMLR}
}