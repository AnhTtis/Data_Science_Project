@article{faghri2020adaptive,
  title={Adaptive gradient quantization for data-parallel sgd},
  author={Faghri, Fartash and Tabrizian, Iman and Markov, Ilia and Alistarh, Dan and Roy, Daniel M and Ramezani-Kebrya, Ali},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3174--3185},
  year={2020}
}
@article{max1960quantizing,
  title={Quantizing for minimum distortion},
  author={Max, Joel},
  journal={IRE Transactions on Information Theory},
  volume={6},
  number={1},
  pages={7--12},
  year={1960},
  publisher={IEEE}
}
@article{lloyd1982least,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}
@article{kieffer1982exponential,
  title={Exponential rate of convergence for Lloyd's method I},
  author={Kieffer, J},
  journal={IEEE Transactions on Information Theory},
  volume={28},
  number={2},
  pages={205--210},
  year={1982},
  publisher={IEEE}
}
@book{bekkerman2011scaling,
  title={Scaling up machine learning: Parallel and distributed approaches},
  author={Bekkerman, Ron and Bilenko, Mikhail and Langford, John},
  year={2011},
  publisher={Cambridge University Press}
}
@inproceedings{chilimbi2014project,
  title={Project adam: Building an efficient and scalable deep learning training system},
  author={Chilimbi, Trishul and Suzue, Yutaka and Apacible, Johnson and Kalyanaraman, Karthik},
  booktitle={11th USENIX symposium on operating systems design and implementation (OSDI 14)},
  pages={571--582},
  year={2014}
}
@article{recht2011hogwild,
  title={Hogwild!: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
@article{chaturapruek2015asynchronous,
  title={Asynchronous stochastic convex optimization: the noise is in the noise and SGD don't care},
  author={Chaturapruek, Sorathan and Duchi, John C and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}
@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth annual conference of the international speech communication association},
  year={2014}
}
@inproceedings{strom2015scalable,
  title={Scalable distributed DNN training using commodity GPU cloud computing},
  author={Strom, Nikko},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}
@article{stich2018sparsified,
  title={Sparsified SGD with memory},
  author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{aji2017sparse,
  title={Sparse Communication for Distributed Gradient Descent},
  author={Aji, Alham Fikri and Heafield, Kenneth},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={440--445},
  year={2017}
}
@article{wen2017terngrad,
  title={Terngrad: Ternary gradients to reduce communication in distributed deep learning},
  author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{alistarh2017qsgd,
  title={QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{mishchenko2021intsgd,
  title={IntSGD: Adaptive Floatless Compression of Stochastic Gradients},
  author={Mishchenko, Konstantin and Wang, Bokun and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@inproceedings{horvoth2022natural,
  title={Natural compression for distributed deep learning},
  author={Horv{\'o}th, Samuel and Ho, Chen-Yu and Horvath, Ludovit and Sahu, Atal Narayan and Canini, Marco and Richt{\'a}rik, Peter},
  booktitle={Mathematical and Scientific Machine Learning},
  pages={129--141},
  year={2022},
  organization={PMLR}
}
@article{ramezani2021nuqsgd,
  title={NUQSGD: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization.},
  author={Ramezani-Kebrya, Ali and Faghri, Fartash and Markov, Ilya and Aksenov, Vitalii and Alistarh, Dan and Roy, Daniel M},
  journal={J. Mach. Learn. Res.},
  volume={22},
  pages={114--1},
  year={2021}
}

@article{qu2021feddq,
  title={FedDQ: Communication-Efficient Federated Learning with Descending Quantization},
  author={Qu, Linping and Song, Shenghui and Tsui, Chi-Ying},
  journal={arXiv preprint arXiv:2110.02291},
  year={2021}
}

@article{tang2018communication,
  title={Communication compression for decentralized training},
  author={Tang, Hanlin and Gan, Shaoduo and Zhang, Ce and Zhang, Tong and Liu, Ji},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{koloskova2019decentralized,
  title={Decentralized stochastic optimization and gossip algorithms with compressed communication},
  author={Koloskova, Anastasia and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3478--3487},
  year={2019},
  organization={PMLR}
}
@article{koloskova2019decentralized1,
  title={Decentralized deep learning with arbitrary communication compression},
  author={Koloskova, Anastasia and Lin, Tao and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:1907.09356},
  year={2019}
}
@article{liu2022decentralized,
  title={Decentralized federated learning: Balancing communication and computing costs},
  author={Liu, Wei and Chen, Li and Zhang, Wenyi},
  journal={IEEE Transactions on Signal and Information Processing over Networks},
  volume={8},
  pages={131--143},
  year={2022},
  publisher={IEEE}
}
@article{tang2019deepsqueeze,
  title={Deepsqueeze: Decentralization meets error-compensated compression},
  author={Tang, Hanlin and Lian, Xiangru and Qiu, Shuang and Yuan, Lei and Zhang, Ce and Zhang, Tong and Liu, Ji},
  journal={arXiv preprint arXiv:1907.07346},
  year={2019}
}
@article{reisizadeh2019exact,
  title={An exact quantized decentralized gradient descent algorithm},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Pedarsani, Ramtin},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={19},
  pages={4934--4947},
  year={2019},
  publisher={IEEE}
}
@inproceedings{kovalev2021linearly,
  title={A linearly convergent algorithm for decentralized optimization: Sending less bits for free!},
  author={Kovalev, Dmitry and Koloskova, Anastasia and Jaggi, Martin and Richtarik, Peter and Stich, Sebastian},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4087--4095},
  year={2021},
  organization={PMLR}
}
@article{wang2021cooperative,
  title={Cooperative SGD: A unified framework for the design and analysis of local-update SGD algorithms},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={Journal of Machine Learning Research},
  volume={22},
  year={2021}
}
@article{wang2019adaptive,
  title={Adaptive federated learning in resource constrained edge computing systems},
  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
  journal={IEEE Journal on Selected Areas in Communications},
  volume={37},
  number={6},
  pages={1205--1221},
  year={2019},
  publisher={IEEE}
}
@inproceedings{reisizadeh2020fedpaq,
  title={Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2021--2031},
  year={2020},
  organization={PMLR}
}
@article{liu2020accelerating,
  title={Accelerating federated learning via momentum gradient descent},
  author={Liu, Wei and Chen, Li and Chen, Yunfei and Zhang, Wenyi},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={31},
  number={8},
  pages={1754--1766},
  year={2020},
  publisher={IEEE}
}
@inproceedings{yu2019parallel,
  title={Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={H. Yu and S. Yang and S. Zhu},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  volume={33},
  pages={5693--5700},
  year={2019}
}
@inproceedings{lian2017can,
	title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
	author={X. Lian and C. Zhang and H. Zhang and C.-J. Hsieh and W. Zhang and J. Liu},
	booktitle={Proc. Adv. Neural Inf. Process. Syst.},
	pages={5336--5346},
	year={2017}
}
@inproceedings{stich2018local,
  title={Local SGD Converges Fast and Communicates Little},
  author={Stich, Sebastian U},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{jiang2018linear,
  title={A linear speedup analysis of distributed deep learning with sparse and quantized communication},
  author={P. Jiang and G. Agrawal},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.,},
  pages={2525--2536},
  year={2018}
}
@inproceedings{yu2019linear,
	title={On the linear speedup analysis of communication efficient momentum SGD for distributed non-convex optimization},
	author={H. Yu and R. Jin and S. Yang},
	booktitle={Proc. 36st Int. Conf. Mach. Learn.},
	pages={7184--7193},
	year={2019},
	organization={PMLR}
}

@inproceedings{jhunjhunwala2021adaptive,
  title={Adaptive quantization of model updates for communication-efficient federated learning},
  author={Jhunjhunwala, Divyansh and Gadhikar, Advait and Joshi, Gauri and Eldar, Yonina C},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3110--3114},
  year={2021},
  organization={IEEE}
}
@article{mo2022feddq,
  title={FedDQ: A communication-efficient federated learning approach for Internet of Vehicles},
  author={Mo, Zijia and Gao, Zhipeng and Zhao, Chen and Lin, Yijing},
  journal={Journal of Systems Architecture},
  volume={131},
  pages={102690},
  year={2022},
  publisher={Elsevier}
}
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={Y. LeCun and L. Bottou and Y. Bengio and P. Haffner},
  journal={Proc. IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={A. Krizhevsky and G. Hinton},
  year={2009},
  publisher={Citeseer}
}
@article{chiang2016fog,
  title={Fog and IoT: An overview of research opportunities},
  author={Chiang, Mung and Zhang, Tao},
  journal={IEEE Internet of things journal},
  volume={3},
  number={6},
  pages={854--864},
  year={2016},
  publisher={IEEE}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{hard2018federated,
  title={Federated learning for mobile keyboard prediction},
  author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Fran{\c{c}}oise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chlo{\'e} and Ramage, Daniel},
  journal={arXiv preprint arXiv:1811.03604},
  year={2018}
}
@article{samarakoon2019distributed,
  title={Distributed federated learning for ultra-reliable low-latency vehicular communications},
  author={Samarakoon, Sumudu and Bennis, Mehdi and Saad, Walid and Debbah, M{\'e}rouane},
  journal={IEEE Transactions on Communications},
  volume={68},
  number={2},
  pages={1146--1159},
  year={2019},
  publisher={IEEE}
}
@inproceedings{liu2020federated,
  title={Federated learning for vision-and-language grounding problems},
  author={Liu, Fenglin and Wu, Xian and Ge, Shen and Fan, Wei and Zou, Yuexian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11572--11579},
  year={2020}
}
@inproceedings{vanhaesebrouck2017decentralized,
	title={Decentralized collaborative learning of personalized models over networks},
	author={P. Vanhaesebrouck and A. Bellet and M. Tommasi},
	booktitle={AISTATS},
	pages={509--517},
	year={2017},
	organization={PMLR}
}