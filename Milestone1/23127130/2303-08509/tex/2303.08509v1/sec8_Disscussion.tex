%\section{Limitations and Future Directions}
%\label{sec:Limitations}
% \subsection{Non-strict black box attack}
% There is a other attack scene  which allows the target black-box classifier give the classification probability instead of the discrete prediction label \cite{DBLP:conf/icml/DaiLTHWZS18,DBLP:journals/corr/abs-2007-02734}. 
% In this case, the classifier can offer more information for {\ourtool} to converge more quickly. To show the effectiveness of our algorithm in this case, we use BagAmmo to attack a same  APK in these two settings(i.e., output the label and output the probability). And we record the perturbation in each iteration to show the convergence speed. We conduct experiments on the MaMaDroid method with DNN classifier and family/package   granularity feature.
% 数据上的迁移性，模型上的迁移性。感觉不够直观。。本质上两者都是为了减少查询量。
%   \textbf{Near-universal perturbations}. % Reduce computational cost   AEs' transferability among data
%Given a large-size APK file, {\ourtool} may suffer relatively high overheads  {in searching desirable perturbations. To further increase efficiency and decrease overhead, we will study how to more quickly find the desired perturbations in the future}. We borrow ideas from existing works on universal perturbation in the domain of image classification such as \cite{DBLP:journals/corr/Moosavi-Dezfooli16,DBLP:journals/corr/abs-2005-08087}. A universal perturbation can be applied to various inputs and induce misclassification. {In practice, it may be extremely hard to find absolutely universal perturbations for all Android malware. As a result, we choose} to obtain near-universal perturbations for Android malware. Then we consider these near-universal perturbations as the starting point of our algorithm, avoid searching from scratch, and hence accelerate algorithm convergence.


% BagAmmo suffers from computational consumption when an APK has a huge FCG.  {\ourtool} will analyze  the FCG and extract the candidate caller  functions and callee functions. If the given APK has a huge function call graph, the candidate solution space will be huge and  consume a lot computational memory. So even BagAmmo offers a convenient to the automated adversarial generation, in exchange, it costs a lot computational consumption. In the feature, to increase the attack efficiency and decrease the  computational consumption. We will study how to cut the candidate  perturbations and Keep the more threatening perturbations. For example, there are some works \cite{DBLP:journals/corr/Moosavi-Dezfooli16,DBLP:journals/corr/abs-2005-08087} study how to generate the universe perturbation which can be applied to various input and lead the misclassification of the model. { So a possible solution is to explore  AEs' transferability among different data and to generate a universe perturbation which can suitable most of the data.}

% \noindent \textbf{Transferring to other targets}. % Further Reduce the number of queries AEs' transferability among classifiers
% % BagAmmo employs a substitute model (i.e., its discriminator) to reduce the number of required queries. 
% {{\ourtool} needs to interact with its target system during attacks. In practice, the transferable attacks are more attractive since they do not require queries}. Recently, some works in the domain of image classification \cite{DBLP:conf/iclr/LiuCLS17,DBLP:conf/cvpr/WuSLK21} study how to generate AEs without requiring queries. These works are motivated by a phenomenon that AEs crafted for one model can also attack other models. {In the future, we will investigate how to leverage the transferability of AEs to attack various target models.}

%\noindent {\textbf{Transfer to other platforms}. The idea and the framework of {\ourtool} are transferable to a certain degree, since malware detection on other platforms can also use semantic features (e.g., FCGs). {\ourtool} should be tailored to the different programming languages used on these platforms. } 

% However, there are still two steps need to be accomplished. One is to change the script of the  try-catch trap into another programming language. The other is to  redefine the individual in {\ourtool} according to the corresponding platform.  }

% it still need to query the target black-box classifier.; And frequency query may cause the alarm of the model owner. So how to generate a adversarial example without the iteration with the target classifier is an important problem in practical application.   Recently, many works \cite{DBLP:conf/iclr/LiuCLS17,DBLP:conf/cvpr/WuSLK21} study how to generate adversarial examples without queries. These works are motivated by a phenomenon that adversarial examples crafted for one model can also attack other models. We  can leverage the transferability of adversarial examples to launch attacks without requiring any interaction with target Android malware detection models.




% \section{ {Limitations and Discussion}}
% \label{sec:Limitations}
% %这里我把结论那一章节去掉了。
%  {In this paper, we propose an effective black-box AE attack {\ourtool} towards the FCG based Android malware detection. {\ourtool} may raise the concern for AE threats on malware detection, and can be used to evaluate the robustness of existing detection
% methods. The limitations and future works are given below.}

% %我不知道为什么罗老师在回复里去掉了这句话，这里需要老师把握下。
%  {\textbf{Potential defenses}. 
% {\ourtool} targets static analysis methods and relies on inserting function calls to change FCG. It does not change the information flow of malware, and hence does not negatively impact dynamic analysis \cite{2017Malton}. We will explore how to construct AEs against dynamic analysis in future work. Another concern is whether a defender can detect {\ourtool} by counting the number of try/catch blocks. Since the number of added try-catch blocks is relatively small, however, it is difficult to find an appropriate detection threshold (i.e., the maximum allowed number of try-catch blocks). More discussions can be found in Appendix \ref{app:trycatch}}. 
 
% \noindent {\textbf{Transfer to other platforms}. The idea and the framework of {\ourtool} are transferable to a certain degree, since malware detection on other platforms can also use semantic features (e.g., FCGs). {\ourtool} should be tailored to the different programming languages used on these platforms. } 

 

% Reduce computational cost   AEs' transferability among data
%Given a large-size APK file, {\ourtool} may suffer relatively high overheads  {in searching desirable perturbations. To further increase efficiency and decrease overhead, we will study how to more quickly find the desired perturbations in the future}. We borrow ideas from existing works on universal perturbation in the domain of image classification such as \cite{DBLP:journals/corr/Moosavi-Dezfooli16,DBLP:journals/corr/abs-2005-08087}. A universal perturbation can be applied to various inputs and induce misclassification. {In practice, it may be extremely hard to find absolutely universal perturbations for all Android malware. As a result, we choose} to obtain near-universal perturbations for Android malware. Then we consider these near-universal perturbations as the starting point of our algorithm, avoid searching from scratch, and hence accelerate algorithm convergence.\textbf{}


\section{ {Limitations and Discussion}}
\label{sec:Limitations}
%这里我把结论那一章节去掉了。
 {In this paper, we propose a black-box AE attack BagAmmo towards the FCG based Android malware detection. We hope that our work has reference value for the
study of Android malware detection, and raises the concern for the threats posed by AE attacks. Moreover, our method can be used to evaluate the robustness of existing Android malware detection
methods. Below we discuss some limitations and future works.}

%我不知道为什么罗老师在回复里去掉了这句话，这里需要老师把握下。
 {\textbf{Dynamic analysis based defense}. 
Our method targets  the static analyse methods.
 It relies on inserting function calls to change FCG. But it does not change the information flow of malware. Therefore, it does not negatively impact dynamic analysis \cite{2017Malton}. We will explore how to construct adversarial examples against dynamic analysis based Android malware detection methods in future work.}

 % {\textbf{Transfer to other platforms}. The idea and the framework of {\ourtool} are transferable to a certain degree, since malware detection on other platforms can also use semantic features (e.g., FCGs). {\ourtool} should be tailored to the different programming languages used on these platforms. } 
 
\textbf{Transfer to other domains}. The idea and the framework of {\ourtool} are transferable to a certain degree, since many domains  use semantic features and graph structured data (e.g., intrusion detection system \cite{DBLP:journals/iotj/ZhouLLYSW22} and trajectory prediction system \cite{wong2022view,xia2022cscnet}).
% {\ourtool} should be tailored to the different programming languages used on these platforms. }


  {\textbf{Try/catch detection based defense}. Another concern is that whether a defender can detect the AEs generated by {\ourtool} by counting the number of try/catch blocks. This defense method requires a detection threshold for the number of try-catch blocks. Through comparing the try-catch block number of original malicious APKs and that of adversarially perturbed APKs, however, we find that the number of try-catch blocks added by our method is relatively small. So it is difficult to find an appropriate threshold for all APKs. Without such a threshold, this defense method may cause a high false positive or false negative rate.\footnote{ {More experimental results can be found in Appendix \ref{app:trycatch}}}} 

  \section{ Acknowledgments
}
This work was supported partially by the  Hong Kong RGC Project  (No.  PolyU15219319), HKPolyU Grant No.ZVG0,   Fundamental Research Funds for the Central Universities (HUST: Grant No. YCJJ202202016 and  2022JYCXJJ035) .