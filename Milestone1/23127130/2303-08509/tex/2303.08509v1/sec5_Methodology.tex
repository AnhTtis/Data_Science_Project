
\section{Adversarial perturbation generation} \label{sec:method}
{ In Subsection \ref{sec:adversarial manipulation method}, we propose the question of how to
 select desirable edges from the candidate edges. To answer this question, we develop a novel GAN model and the algorithm {\ouralgorithm} to find the desired adversarial perturbation. } 

\subsection{Challenges \& Solutions}

{We first introduce the main procedure of {\ourtool} below. }

 (1) Given a pre-selected malware sample, {\ourtool} finds some callers and callees from the smali codes, and uses them to create a set of candidate edges, as discussed in Section \ref{sec:Adversarial manipulation design}. With candidate edges, {\ourtool} generates a variety of samples through manipulating malware, and sends them (i.e., queries) to its target system for malware detection.
 
 (2) The target model sends back a reply for a query. In our strict black-box setting \cite{DBLP:conf/iclr/ZhaoDS18}, every reply contains only the binary classification outcome (i.e., malicious or benign). 
 
 (3) Through learning from the query-reply pairs, {\ourtool} gradually recognizes the most desirable edges that can successfully induce misclassification.

 The main challenges in designing {\ourtool} include: 1) {the feature granularity} of the target model is unknown, 2) a large number of queries are usually required in the strict black-box attack scenario \footnote{{In this scenario, both $\mathcal M_G(\cdot)$ and $\mathcal M_V(\cdot)$ mentioned in Subsection 3.2 are unknown. Moreover, the reply of the   black-box model contains only the
binary classification outcome (e.g., many malware detection websites \cite{VirusTotal} only sends back a binary decision instead of class probabilities). }} \cite{DBLP:conf/icdm/LiYZ18,DBLP:conf/eccv/AndriushchenkoC20}.
%  The first challenge increases the difficulty in selecting edges to perturb FCG, since {\ourtool} does not accurately know how its added edges impact the FCG. The second challenge {requires reducing the number of queries} in order to reduce overheads and avoid being defended. 
Our countermeasures are briefly explained below. 

\textbf{Surmising feature granularity}. {Our adversarial multi-population co-evolution algorithm, i.e., {\ouralgorithm}, uses one population to represent a possible feature granularity}. {The multiple populations, corresponding to multiple possible feature granularities}, cooperatively evolve until the population corresponding to the real feature granularity keeps alive but the others fade away. In this way, {\ourtool} can accurately identify the feature granularity used by its target model, {as will be shown in Subsection \ref{subsection:evolution}}. 

\textbf{Reducing the number of queries}. {\ourtool} constructs a novel \textit{substitute} model to simulate its target model. The substitute model is trained with the samples generated by {\ouralgorithm} and labeled by the target model. {As will be shown in Subsection \ref{subsection: substitute}}, once the substitute model is well trained, {\ourtool} only needs to attack it instead of the target model, {hence greatly reducing} the number of queries. 

\subsection{The overview of {\ourtool}}
{Following the architecture of GANs, {\ourtool} adopts a generator and a discriminator that are cooperatively trained.} 

\textbf{Generator}: The generator is responsible for generating perturbations, i.e., the new edges added into the FCG. It is implemented with an adversarial multi-population co-evolution algorithm (i.e., Apoem).

\textbf{Discriminator}: {The discriminator is introduced to stimulate the generator to improve its perturbations. It is implemented with a GCN, acting as a substitute network \cite{chen2020android} to simulate the target model.}

% As shown in Fig. \ref{fig:bg1}, the generator {leverages a multi-population co-evolution algorithm \ouralgorithm}  to generate perturbations, i.e., the new edges added into the FCG. {The discriminator is introduced to stimulate the generator to improve its perturbations. It is implemented with a graph convolutional network (GCN), which acts as a substitute network \cite{chen2020android} to simulate the target model. }

\textbf{Training}: {In each round of model training}, the generator modifies the malware's code and sends the rebuilt malware to the target model or the substitute model for malware detection. {\ourtool} makes a choice between the target model and the substitute model with a variable probability $p$. After receiving the queries, the target model sends back its replies, i.e., the binary decisions. With the query-reply pairs, {\ourtool} trains the substitute model and guides its generator to {improve its generated perturbations}. {The probability $p$ keeps growing as the number of rounds increases, to decrease the number of queries sent to the target model}.
 
% In the following, we first introduce the multi-population co-evolution mechanism and the substitute model, and then propose the formal description of our algorithm.
 
%  The main challenges in designing {\ourtool} include: 1) the granularity of the features used by the target model is unknown, 2) lots of queries are usually required in the strict black-box attack scenario \cite{DBLP:conf/icdm/LiYZ18,DBLP:conf/eccv/AndriushchenkoC20}. The first challenge increases the difficulty in selecting edges, since {\ourtool} does not accurately know how its function calls impact the API call graph. The second challenge raises an urgent demand for reducing query amount in order to reduce overheads and avoid being defended. Our countermeasures are briefly explained below. 


% \textbf{Surmising feature granularity}. {\ourtool} introduces the mechanism of \textbf{A}dversarial \textbf{M}ulti-\textbf{P}opulation \textbf{C}o-\textbf{E}volution (A-mpce) to overcome the challenge of unknown feature granularity. This mechanism uses multiple populations to represent all possible feature granularities. These populations cooperatively evolve until the population corresponding to the real feature granularity still keeps alive but the others fade away. In this way, {\ourtool} can accurately identify the feature granularity used by its target model. 


% \textbf{Reducing the amount of queries}. {\ourtool} constructs a novel \textit{substitute} model to simulate its target model, which is trained with the samples generated by {\ourtool} and labeled by the target model. Since the substitute model resembles the target model in malware detection, it can be used to help {\ourtool} accelerate its black-box attack. In fact, once the substitute model has been well trained, {\ourtool} only needs to attack it instead of the target model. In this way, {\ourtool} greatly reduces the amount of required queries. Existing substitute models \cite{chen2020android} are often built with MLPs. This is because existing attacks occur in feature space and choose to directly perturb feature vectors. However, {\ourtool} considers a more practical scenario where attacks take place in problem space, and hence it is faced with API call graphs instead of vectors. Under this situation, {\ourtool} builds a graph convolutional network (GCN) based substitute model whose inputs are graph data. As we all know, GCNs \cite{DBLP:conf/iclr/KipfW17} can efficiently extract features from graph data through utilizing the properties of nodes and edges in graph data. And this raises another important problem: how to assign appropriate properties to the nodes in graph data. To our knowledge, this problem has not been thoroughly studied in  existing literature. For the first time, we propose to use degree information as node properties, which can speed up the training of the substitute model.
% \begin{figure} 
% 	\centering   
% 	\includegraphics[width=0.95\linewidth]{overview.pdf}
% 	\caption{The overview of {\ourtool}.}   
% 	\label{fig:motivation_al}   
% \end{figure} 
    
% Now we give an overview of {\ourtool} in Fig. \ref{fig:motivation_al}. This figure shows how to generate a real evasive malware within three steps. First, {\ourtool} obtains the classes.dex file through unpacking an APK file, and then decompiles it into a series of smali files. Second, {\ourtool} extracts an FCG from the smali files, and uses our proposed AE generation algorithm to find the appropriate edges to perturb the API call graph. Third, {\ourtool} adversarially manipulates the Smail files and rebuilds a new APK file. The key module of {\ourtool} is the proposed AE generation algorithm, called Adversarial multi-population co-evolution algorithm ({\ouralgorithm}), which will be discussed in the next subsection.

%As . The GAN model consists of a generator network and a discriminator network. The former is responsible for perturbation generation, and the latter is introduced to stimulate the generator to improve the quality of its generated perturbations. In the initial phase of model training, the generator considers multiple populations corresponding to various feature granularities. Stimulated by the discriminator, the populations cooperate to evolve, until the population representing the real feature granularity thrives and the others become feeble. At this moment, the algorithm succeeds in capturing the real feature granularity and figuring out how to manipulate the input graph.  

\begin{figure*}[htbp]
	\centering
	\includegraphics[scale=0.5]{method1.pdf}
	\caption{The model architecture of {\ourtool}.}
	\label{fig:bg1}
\end{figure*}
% \subsection{The basic idea of {\ouralgorithm} algorithm}



% Given a malware sample $\mathcal{S}$, {\ourtool} aims to derive an evasive malware sample $\mathcal{\bar{S}}$, through adversarially manipulating $\mathcal{S}$. We use $FCG_{S}$ and $FCG_{\mathcal{\bar{S}}}$ to refer to the FCG of $\mathcal{S}$ and $\mathcal{\bar{S}}$, respectively. According to {\ourtool}, we know that $\mathcal{S}$ and $\mathcal{\bar{S}}$ have the same node set but $\mathcal{\bar{S}}$ contains more edges. The main task of our {\ouralgorithm} algorithm is to find these edges and generate $\mathcal{\bar{S}}$. To do it, {\ouralgorithm} trains a specially designed GAN model to generate $FCG_{\mathcal{\bar{S}}}$  based on $FCG_{S}$. According to $\mathcal{\bar{S}}$, {\ourtool} can adversarially manipulate the smali codes of $\mathcal{S}$,  and rebuilds a new APK file, i.e., $\mathcal{\bar{S}}$. %Please find the details on adversarial manipulation and APK rebuilding in Section XXX.

% The GAN model trained by {\ouralgorithm} is shown in Fig. \ref{fig:bg1}. This model consists of two components, i.e., a generator and a discriminator. The generator is responsible for generating perturbations in black-box environment, i.e., the new edges added into API call graph. The discriminator acts as a substitute network that fits or simulates the target classification model. It is introduced to stimulate our generator to improve its perturbations. It is worth noting that our GAN model differs from existing GANs in two respects. First, its generator is a multi-population co-evolution algorithm, instead of a neural network. Second, its discriminator is a GCN, instead of an MLP or CNN.  


% The training procedure of this GAN model consists of multiple rounds. In each round, the generator modifies $\mathcal{S}$ and sends the manipulated malware samples to the target model or the substitute model for malware detection. {\ouralgorithm} makes a choice between the target model and the substitute model with a probability $p$. After receiving these queries, the target model sends back its replies, i.e., the binary decisions. With these query-reply pairs, {\ouralgorithm} trains the substitute model and guides its generator to produce improved malware samples. It is worth noting that the probability $p$ keeps growing as the number of rounds increases. In this way, {\ourtool} can reduce the number of queries to the target model.

% In the following, we first introduce the multi-population co-evolution and substitute model, and then propose the formal description of our {\ouralgorithm} algorithm. 

\subsection{Adversarial Multi-population co-evolution}
\label{subsection:evolution}
\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.6]{ga.pdf}
	\caption{{How multiple populations cooperatively evolve?}}
	\label{fig:GA}
\end{figure}
    { The main challenge faced by the generator is 
  {that the real feature granularity is unknown.} To facilitate the understanding, we consider the case where the target system uses the family-level feature but we perturb the class-level feature. In this case, we will fall into a huge search space, hence prolonging model training time and requiring more queries. To alleviate this problem, {\ourtool} uses the {\ouralgorithm} algorithm to surmise the real feature granularity.} {\ouralgorithm} follows the general framework of evolutionary algorithms, but it introduces  cooperation among multiple populations to speed up convergence. Along with the evolution, the population corresponding to the real feature granularity gradually stands out from the crowd. In the following, we first describe the main components of {\ouralgorithm} depicted in the red block of Fig. \ref{fig:bg1}, and then discuss how to use these components {to generate the desired perturbation}. 
 
\textbf{(1) Population \& Individual}. 
{A population represents  a collection of generated AEs under a certain feature granularity. For example, the family-level population consists of the AEs generated under the assumption that the target classifier uses a family-level FCG as its input. {\ouralgorithm} adopts multiple populations, each of which corresponds to one possible feature granularity (i.e., family, package and class)}.
Each individual in a population gives a perturbation that can be imposed on the original FCG\footnote{Strictly speaking, an individual refers to an adversarial example in a population. However, the difference between adversarial example and malicious example is perturbation. Hence we use the perturbation to represent an individual.}, i.e., the set of edges added into the FCG. As shown in Fig. \ref{fig:GA} (a), the above graph denotes the original FCG, and the below graph represents an adversarial example. Accordingly, the perturbation, i.e., the edge set $(A\rightarrow E, B \rightarrow D)$, is considered as an individual. {We use $x_r^{(i,j)}$ to refer to the $j$-th individual of the $i$-th population in the $r$-th generation of {\ouralgorithm}. We have $x_r^{(i,j)} = \{ e_1^{(i,j)},e_2^{(i,j)},...,e_{n}^{(i,j)}\}$, where $e_{k}^{(i,j)}$ ($1\leq k\leq n$) is the added edge.}
	In the initial phase, we need to collect sufficient individuals to build the populations. Therefore, we randomly perturb the original FCG, and get a set of individuals for each population.
	
 \textbf{(2) Fitness \& Selection}.
	{{\ouralgorithm} employs the metric fitness to select superior individuals and eliminate inferior individuals.}
	{This metric reflects the aggressivity and the invisibility of an AE. Its calculation takes into account two factors:} threat degree $T$ and perturbation amount $L$. The threat degree is measured according to the output of the target model $F(\cdot)$ or the substitute model $S(\cdot)$\footnote{{For the target or substitute model, the input is detected to be malicious when its output $F(x)$ or $S(x)$ equals to or approaches 1.  }}. For an individual $x$, the threat degree is defined as:
		{
	\begin{equation}
	 T =\left\{\begin{array}{l}
1-F(x) \quad\text{if target model is used} \\
1-S(x) \quad\text{if substitute model is used}
\end{array}\right. 	    
	\end{equation}}
The perturbation amount is calculated as the number of added edges.
%  {
% 	\begin{equation}	
% 	L= len(\{ e_1^{(i,j)},e_2^{(i,j)},...,e_{n}^{(i,j)}\}) = n
% 	\end{equation}}
	{Furthermore, {\ouralgorithm} introduces the \textit{elitist} selection strategy \cite{2012Genetic}} to pass on the good genes of individuals to the next generation, { through retaining the fittest individuals and eliminating the others.} %Therefore, the individuals whose adversarial examples are detected to be benign by the target model or have the highest benign probability outputted by the substitute model are selected and survive.
%	It is worth noting that with the increase of rounds, the substitute network will be more similar to the target black-box classifier. It is more likely to take  substitute  network's output as threat level $T$, thus reducing the number of queries of the black-box model.

\textbf{ (3) Immigration}. {In general, the individuals with high fitness have a greater chance of producing better offsprings. To produce more high-quality individuals, {\ouralgorithm} leverages the immigration operation to transfer individuals with high fitness within one population into other populations. Accordingly, the superior individuals immigrate to different populations, making all populations cooperatively evolve to generate better AEs.}
{There exist two kinds of immigration in {\ouralgorithm}: fine-to-coarse (e.g., from class level to family level) and coarse-to-fine (e.g., from family level to class level), as shown in Fig. \ref{fig:GA} (b). We first consider the fine-to-coarse case where one individual in the class-level population is immigrated into the package-level population. In this case, the name of the packages related to the perturbation (e.g., java.lang.StrictMath->java.lang) is retained and the individual containing only package names is then put into the package-level population. Now we consider the coarse-to-fine case where the individual from the package-level population is injected into the class-level population. Since a package may contain multiple classes, we randomly select one class used by malware code to replace the package and then put the individual containing class names into the class-level population.}


\textbf{(4) Crossover}. 
{{\ouralgorithm} leverages crossover to randomly swap genes from two parents to produce offsprings. More specifically, $K$ pairs of individuals are randomly chosen from a population as parents, and half of the perturbation in every pair is exchanged to produce two offsprings, as shown in Fig. \ref{fig:GA} (c).} { Suppose the parents are $	 x_r^{(i,j_1)} =\{e_1^{(i,j_1)},e_2^{(i,j_1)},e_3^{(i,j_1)},e_4^{(i,j_1)}\}$ and $ x_r^{(i,j_2)} = \{e_1^{(i,j_2)},e_2^{(i,j_2)},e_3^{(i,j_2)},e_4^{(i,j_2)}\}$, where  $e_{k}^{(i,j)}$ is an added edge (e.g., A->E)  in Fig. \ref{fig:GA} (c) . The offsprings derived by crossover are $x_{r+1}^{(i,j_1)} = \{e_1^{(i,j_1)},e_2^{(i,j_1)},e_3^{(i,j_2)},e_4^{(i,j_2)}\}$ and $x_{r+1}^{(i,j_2)} = \{e_1^{(i,j_2)},e_2^{(i,j_2)},,e_3^{(i,j_1)},e_4^{(i,j_1)}\}$, respectively. }

	 
 \textbf{(5) Mutation}. 
{{\ouralgorithm} employs mutation to bring new changes to a population.} As depicted in Fig.  \ref{fig:GA} (d), there are three possible mutation modes: 1) randomly adding function calls on the existing perturbation, 2) randomly reducing existing perturbation, and 3) randomly exchanging existing  perturbations. {They can be mathematically expressed as $x_{r+1}^{(i,j)}=\{e_1^{(i,j)},  ... ,e_{n}^{(i,j)},e_{n+1}^{(i,j)}\}$, $	x_{r+1}^{(i,j)}=\{e_1^{(i,j)},  ... ,e_{n-1}^{(i,j)}\}$, and $x_{r+1}^{(i,j)}=\{e_1^{(i,j)},  ... ,e_{n-1}^{(i,j)},e_{n+1}^{(i,j)}\}$, respectively.}


 
%  Then our immigration operation can be defined by
	 
% 	 \begin{align} 
% 	 	x_{r+1}^{(i+1,k)}  &=  Immigration(\{x_r^{(i,j)}\}) \\
% 	 	&=\{e_1^{(i+1,k)},  ... ,e_{n}^{(i+1,k)}\}
% 	 \end{align}
	 

\subsection{Substitute model}
\label{subsection: substitute}
{{\ouralgorithm} only knows the binary decision of its target model, making it hard to accurately evaluate individuals. To overcome this challenge, we design a novel substitute model to simulate the target model, and provide {\ouralgorithm} with approximate class probabilities.}

The inputs of our substitute model are \textit{function-level} FCGs generated according to the perturbation produced by the generator. 
% Here our algorithm does not choose FCGs as inputs because the type of FCGs used by the target model is actually unknown in the scenario of incomplete feature information. 
% To fasten its training, the substitute model should efficiently and sufficiently extract features from its inputs. 
{We use a GCN  {(i.e., Graph Convolutional Network)} to extract features from the substitute model}, as shown in the green block in  Fig. \ref{fig:bg1}. GCNs extend convolution to graph data, and they are good at utilizing structural information and node information to fulfill graph-related machine learning tasks. However, the main obstacle of applying GCNs to our task is the absence of node property. That is, FCGs do not provide property information for their nodes. To alleviate this problem, we propose to use \textbf{out degree} and \textbf{in degree} of a node as its features.
% Accordingly, we can build a substitute model that leverages a GCN to extract features from FCGs and uses a fully-connected neural network for classification.


Now we briefly explain {how to use a GCN to extract} features from the inputs. The GCN has multiple convolutional layers. Each layer aggregates node properties using a propagation rule, and the aggregated features are then processed by the next layer. {Accordingly, we can obtain a feature vector to represent the FCG using iterative computation. 
% The details can be found in Appendix \ref{appendix: gcn}}. 


% We use an adjacent matrix $\textbf{A}$ and a node feature matrix $\textbf{X}$ to characterize every FCG inputted to our substitute model. Here the adjacent matrix reflects the topology information of a FCG, and the node feature matrix provides the node property information. We use $\mathbf{H}^{l}$ ($0\leq l \leq L$) to refer to the features obtained at layer $l$. When $l=0$ holds, $\mathbf{H}^{l}$ reduces to the node feature matrix. 
% The features obtained at layer $l+1$ are derived from the features at layer $l$ by  

% \begin{equation}\label{eq:gcn_propgation_rule}
% 	\mathbf{H}^{(l+1)} = \sigma (\tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} \mathbf{H}^{l}\mathbf{W}^{l}),
% \end{equation}
% where $\sigma (\cdot)$ is the activation function, $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I}$, $\mathbf{I}$ represents an Identity Matrix, $\tilde{\mathbf{D}}$ is the degree matrix of $\tilde{\mathbf{A}}$ and $\mathbf{W}^{l}$ denotes the weights of layer $l$. 

% To well train the substitute model, we design a loss function defined as

% \begin{equation}\label{eq:loss}
% 	\mathcal{L}=-\mathbf{E}(\sum_{i} y_{i}^{\prime} \log \left(y_{i}\right))+ \lambda \sum_{i}|w_i^2|,
% \end{equation}
% where  $y_i^{\prime}$ is the true label labeled by the target model, $y_i$  is the prediction output, $w_i$ is the weights need to learn. In this loss function, the first term is binary-classification cross-entropy, and the second term is introduced to reduce overfitting.

\subsection{Algorithm design} 
{{\ouralgorithm} aims to conglutinate multi-population co-evolution mechanism and substitute model to cooperatively generate adversarial perturbations. Its main procedure is given in Algorithm 1.} In this algorithm, $F$ is the target classifier, $N$ is the maximum number of individuals in a population, and $r_ {max}$ denotes the maximum number of generations. {In every iteration, {\ouralgorithm} first randomly selects the target or the substitute model (lines 3-6),  calculates fitness for every individual (lines 8-12), then retains high-rate individuals based on fitness (line 13), and finally conducts immigration, crossover and mutation (line 14). In addition, the substitute model should be trained when it is selected, as denoted by lines 15-17. The individual with the highest fitness is outputted when {\ouralgorithm} terminates. Below we summarize the important considerations for {\ouralgorithm}}.
% , and provide theoretical analyses in Appendix \ref{appendix: theoretical analyses}. 
\begin{algorithm}[h]
	    \LinesNumbered
	\caption{The {\ouralgorithm} Algorithm}
	\label{algorithm ga}
	 \KwIn{The FCG $G$ of a given APP}%输入参数

% 	\textbf{Stage I: Preparation}

% 		 Given  a black-box classifier $F$;
		 
		 
		 
% 		 Set the maximum number of a population $N$;
		 
% 		 Set the maximum generation of the GA $r_ {max}$;
		 
    Population initialization;

	
% 	\textbf{Stage II: Training}
	
	\For{$r$ in $r_ {max}$ }{
		\uIf {$ (r-3)/r_ {max} > random(0, 1)$ }{
			Is\_substitute = 1;	}  
		\Else{Is\_substitute = 0;}

		\For{each $P^i$ }{
			\uIf {Is\_substitute = 1 }{Get fitness $T(x_r^{(i,j)})$ from substitute model;	}
			\Else{Get fitness $T(x_r^{(i,j)})$ from target model;}	
							
		 	Get  $L(x_r^{(i,j)})$ for every individuals;
		 
	     	Select top $N$ individuals according to  $T(x_r^{(i,j)})$ and $L(x_r^{(i,j)})$ in turn ; 
	     	
	     	Immigration(); Crossover();	Mutation();
	}
	
	\If {Is\_substitute = 1 }{
		Get the result from the target model $F(x_r^{(i,j)})$;
		
		Train substitute model with $F(x_r^{(i,j)})$ and $x_r^{(i,j)}$;}	
	
        Determine whether algorithm should terminates;
		
}
% 	\textbf{Stage III: Output}
	

   % \textbf{Output:}  The individual with highest fitness;

\end{algorithm}

% (1) \textit{How to prepare data?} \\
% \hspace*{0.5cm}Before {\ouralgorithm} starts, we select a malicious app, obtain its FCG, and take out its functions for creating candidate function calls. After {\ouralgorithm} starts, it uses the generator to generate candidate adversarial examples, employs the detection outcomes of target model to label them, and employs the labeled data to train the substitute model.  

\noindent (1) \textit{{How to implement co-evolution in {\ouralgorithm}?}}\\
{ The co-evolution in {\ouralgorithm} is two-fold. On one hand, the generator and the discriminator cooperate with each other to improve the generated perturbation. On the other hand, multiple populations cooperatively evolve through immigration.}


% \footnote{{This is the first reason why {\ouralgorithm} has the advantage of co-evolution. Another reason is {\ouralgorithm} indeed benefits from the cooperation between generator and discriminator in the GAN model.} }

% \noindent (2) \textit{How to reduce the  {number} of  queries?} \\
% { The substitute model provides approximate class probabilities for adversarial perturbation generation, which helps reduce the number of queries sent to the target model.} 
% As shown in line $3$ of Algorithm 1, {\ouralgorithm} determines whether or not to use the substitute model based on a probability. This probability is small in the beginning, since the substitute model has not been sufficiently trained at the moment. 
% The probability then keeps arising from the fourth round of {\ouralgorithm}, making the substitute model frequently selected and hence significantly decreasing the number of queries. 

\noindent (2) \textit{How to avoid premature convergence?}\\
{ When the genes of some high-rate individuals quickly dominate the population \cite{1997Degree}, premature convergence occurs and evolutionary algorithms converge to a local optimum. {\ouralgorithm} can mitigate premature convergence owing to the cooperation among populations.} Through immigration, different populations share their good genes and further promote their evolution. Meanwhile, immigration also helps the populations jump out from local optimum traps. {Our  theoretical analyses are given in Appendix \ref{appendix: theoretical analyses}}.

\noindent (3) \textit{When to terminate our algorithm?}\\
There are three stopping criteria for {\ouralgorithm}. First, all the offsprings cannot induce misclassification on the target model anymore. Second, the perturbation amount does not decrease within several continuous rounds. Third, the maximum number of rounds is reached. 

\noindent (4)  {\textit{How to modify the APK according to the output?}\\
The output of our algorithm is the caller-callee function pairs. According to the output, we use the try-catch trap mentioned in Section \ref{sec:Adversarial manipulation design} to insert the callee function into the caller function, in order to implement adversarial perturbation. The  implementation details can be found in Appendix \ref{appendix:smali}.}

 

% \begin{algorithm}
% \caption{algorithm caption}%算法名字
% \LinesNumbered %要求显示行号
% \KwIn{input parameters A, B, C}%输入参数
% \KwOut{output result}%输出
% some description\; %\;用于换行
% \For{condition}{
% 　　only if\;
% 　　\If{condition}{
% 　　　　1\;
% 　　}
% }
% \While{not at end of this document}{
% 　　if and else\;
% 　　\eIf{condition}{
% 　　　　1\;
% 　　}{
% 　　　　2\;
% 　　}
% }
% \ForEach{condition}{
% 　　\If{condition}{
% 　　　　1\;
% 　　}
% }
% \end{algorithm}