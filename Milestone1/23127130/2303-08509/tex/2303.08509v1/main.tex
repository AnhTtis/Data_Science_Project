


\documentclass[letterpaper,twocolumn,10pt]{article}

\usepackage[table]{xcolor}
\usepackage{float}
\usepackage{usenix2019_v3}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{amsmath}
% \usepackage{algorithmic}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{amsmath}
\usepackage{soul}
\usepackage{comment}
\usepackage{tabularx}
\usepackage{array}
%\usepackage{longtable}
\usepackage{rotating}
\usepackage{booktabs}
\usepackage{overpic}
% \setlength{\dbltextfloatsep}{4pt}
\usepackage{float}
\usepackage{setspace}
% \def\bibfont{ \small}
% \def\bibfont{\fontsize{4.5}{10}\selectfont}


	\newcommand{\ourtool}{BagAmmo}
%	\newcommand{\ourevolution}{MPCE}
	\newcommand{\ouralgorithm}{Apoem}
	% \title{Black-box Adversarial Example Attack towards {FCG} Based Android Malware Detection under Incomplete Feature Information}


\begin{document}
\date{}

\title{\Large \bf Black-box Adversarial Example Attack towards {FCG} Based Android Malware \\ Detection under Incomplete Feature Information}




\author{Heng Li$^1$,
	 Zhang Cheng$^1,3$,
	 Bang Wu$^1$,
	 Liheng Yuan$^1$,
	 Cuiying Gao$^1$,
	 Wei Yuan$^1$,
	 Xiapu Luo$^2$ \\
	 $^1$ Huazhong University of Science and Technology\\
	 $^2$ The Hong Kong Polytechnic University\\
	 $^3$ NSFOCUS Technologies Group Co., Ltd\\
 }


\maketitle

\begin{abstract}
The {function call graph (FCG) } based Android malware detection methods have recently attracted increasing attention due to their promising performance. However, these methods are susceptible to adversarial examples (AEs). In this paper, we design a novel \textit{black-box} AE attack towards the {FCG} based malware detection system, called {\ourtool}. {To mislead its target system, {\ourtool} purposefully perturbs the FCG feature of malware through inserting "never-executed" function calls into malware code. The main challenges are two-fold. First, the malware functionality should not be changed by adversarial perturbation. Second, the information of the target system (e.g., the graph feature granularity and the output probabilities) is absent.}

{To preserve malware functionality, {\ourtool} employs the \textit{try-catch trap} to insert function calls to perturb the FCG of malware. Without the knowledge about feature granularity and output probabilities, {\ourtool} adopts the architecture of generative adversarial network (GAN), and leverages a multi-population co-evolution algorithm (i.e., {\ouralgorithm}) to generate the desired perturbation. Every population in {\ouralgorithm} represents a possible feature granularity, and the real feature granularity can be achieved when {\ouralgorithm} converges. }
	
{Through extensive experiments on over 44k Android apps and 32 target models, we evaluate the effectiveness, efficiency and resilience of {\ourtool}.  {\ourtool} achieves an average attack success rate of over 99.9\% on MaMaDroid, APIGraph and GCN, and still performs well in the scenario of concept drift and data imbalance.} {Moreover, {\ourtool} outperforms the state-of-the-art attack SRL in attack success rate.} 
	
	\end{abstract}
	
	\input{sec1_Introduction}
	\input{sec2_Preliminaries}
	\input{sec3_Problem_formulation}
	\input{sec4_Manipulation}
	\input{sec5_Methodology}
	\input{sec6_Experiments}
	\input{sec7_Related_work}
	\input{sec8_Disscussion}
	\input{sec9_Conclusion}


\bibliographystyle{unsrt}

\bibliography{ref}{}

	
\input{sec10_appendix} 

\end{document}
\endinput



