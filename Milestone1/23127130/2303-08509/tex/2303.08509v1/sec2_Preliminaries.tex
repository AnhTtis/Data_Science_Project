\section{Preliminaries} \label{subsec: Preliminaries}
% In this section, we introduce the necessary knowledge about the features used in Android malware detection and the graph based Android malware detection methods. 
%用两个mapping

\subsection{Features for Android malware detection}\label{subsec: features}
% Existing Android malware detection systems classify apps based on dynamic or static features of apps. Extracting dynamic features requires monitoring the execution of apps, inevitably incurring significant overheads. Different from dynamic features, static features can be obtained prior to app execution, and hence have been widely used in Android malware detection. 

 {In this subsection, we focus on the static features that are obtained prior to app execution and widely used in Android malware detection.} Earlier studies devote more attention to syntax features, e.g., requested permissions \cite{DBLP:journals/tii/LiSYLSY18,DBLP:conf/ndss/ZhouWZJ12,DBLP:conf/ccs/EnckOM09} , intent actions \cite{DBLP:journals/tsmc/YuanJLC21,DBLP:conf/uss/OcteauMJBBKT13,DBLP:conf/ntms/FereidooniCYS16}, Inter-Component 
Communications (ICCs) \cite{DBLP:conf/ndss/FengBMDA17,DBLP:conf/icse/BaiX00M20} and API calls \cite{DBLP:conf/ndss/ArpSHGR14,DBLP:journals/jnca/Seo0SBY14}. Recently, semantic features \cite{DBLP:conf/ccs/ZhangZZDCZZY20,DBLP:conf/ndss/MaricontiOACRS17,DBLP:conf/kbse/WuLZYZ019} (e.g., FCGs) have attracted increasing attention. They can characterize the behavior and functionality of apps, and hence achieve promising performance.

{ As the most common semantic feature, FCGs are often constructed based on smali files}. { A function or an \textit{abstracted} function denoted by its function name (e.g., java.lang.StrictMath: max()), class name (e.g., java.lang.StrictMath), package name (e.g., java.lang), or family name (e.g., java) can be used to represent a node in an FCG.}  Therefore, there exist four feature granularities in FCGs , i.e., function level, class level, package level and family level, as shown in Fig. \ref{fig:granularities}. 
{The features with finer granularities (e.g., class level)  usually have a more complex graph structure, causing heavier computational overhead and requiring dimensionality reduction \cite{DBLP:conf/ndss/MaricontiOACRS17}.}
% The features with coarser granularities (e.g., family level) are usually more resilient to API changes, and cause smaller computation and storage overheads, although they suffer less accuracy in characterizing the behavior and functionality of apps.
% \textcolor{green}{Furthermore, it is worth noting that the FCGs with the same feature granularity may differ in their node set. That is, they may adopt different functions or abstracted functions. For example, the frequent subgraphs proposed in \cite{DBLP:journals/tifs/Fan0LCTZL18} only use the sensitive APIs as their nodes, but a classical FCG can contain all Android APIs and user-defined functions.} 
\begin{figure}[bhtp]   
	\centering   
	\includegraphics[width=0.9\linewidth]{granularity.pdf}
	\put(-150,66){${G}_{family}$}
    \put(-128,28){${G}_{package}$}
	\put(-43,75){${G}_{function}$}
    \put(-35,8){${G}_{class}$}
	\caption{Different granularities of the FCG.}   
	\label{fig:granularities}   
\end{figure} 
%怎么构建图特征

% The process of obtaining a predetermined-granularity FCG from an app consists of three steps. First, one gets the classes.dex file through unpacking the corresponding APK file. Second, the classes.dex file is further decompiled into a series of smali files, which reveal the information of function calls in the app. Thrid, one can build an FCG with a required granularity based on the function call information. 
 
{Clearly, the knowledge about the feature granularity of the target system is helpful for adversaries to generate AEs. However, this prior knowledge is hard to obtain in practice. Hence, we put forward the incomplete feature information assumption, assuming that adversaries do not know the feature granularity of the target system. }

\subsection{{FCG} based Android malware detection}

%这里是举例子
%It is only recently that researchers have turned their attention to the graph based Android malware detection. 

% The {FCG} based detection methods choose some types of FCGs as feature and translate them into feature vectors for processing, as depicted in the second box in Fig. \ref{fig:motivation}. 

Here we introduce three state-of-the-art {FCG} based detection methods, which will act as the target detection systems in our experiments.  

\noindent \textbf{Mamadroid}. Mamadroid \cite{DBLP:conf/ndss/MaricontiOACRS17} considers the package-level or family-level FCGs as its features. More specifically, it adopts $340$ packages and $11$ families. To extract a feature vector from an FCG, Mamadroid constructs a Markov chain with the transition probabilities among packages or families. The extracted feature vectors are then used to train a classifier (e.g., KNN and SVM) for app classification. 

% \textbf{Malscan}. Malscan [] is another sate-of-the-art graph based Android malware detection method. It chooses sensitive APIs as the nodes in its FCGs, and then uses their centrality (e.g., degree centrality, Katz centrality and closeness centrality) as the feature vectors for classification.

\noindent \textbf{APIGraph}. Different from Mamadroid, APIGraph \cite{DBLP:conf/ccs/ZhangZZDCZZY20} is a general framework {for} further enhancing the performance of the graph based Android malware detection methods. It employs a clustering algorithm (e.g., K-means) to aggregate the nodes (i.e., functions) of an FCG, based on the similarity among their semantics. It then uses a specific function to represent all functions in every cluster. Finally, APIGraph builds a new FCG with coarser granularity, in which every node denotes a cluster of functions and every edge indicates the call between two clusters. Experiments show that the new FCG can result in better classification performance. 

% \noindent {
% \textbf{SRL}. SRL is a Semantics-preserving (i.e. functionality-preserving) Reinforcement Learning adversarial example attack against black-box GNNs (Graph Neural Networks) for Windows malware detection \cite{DBLP:journals/corr/abs-2009-05602}. This method uses semantic Nops injection to manipulate malware, and leverages reinforcement learning to select the
% appropriate semantic Nops and their corresponding basic blocks. It is noted that SRL is extensible to Android malware.
% }

\noindent {
 \textbf{GCN}. 
Graph Convolutional Network (GCN) is a powerful graph embedding method, which can be utilized to detect malware. For instance, the GCN is used to convert the control flow graph into a feature vector for malware detection in \cite{DBLP:journals/corr/abs-2009-05602}\footnote{ {\cite{DBLP:journals/corr/abs-2009-05602} mainly studies how to attack malware detectors, although it proposes a GCN based malware detection method.} }. In Section \ref{SEC:EXP}, we will apply the GCN to the FCG based Android malware detection. } %In our experiments, the GAN acts as the target model of {\ourtool}.    }
 

 
% \textcolor{green}{ While these methods have achieved impressive results, their network architectures suffer from an machine learning inherent shortcoming: adversarial example attack. Although there have been many works \cite{DBLP:journals/corr/GoodfellowSS14,DBLP:journals/corr/TanayG16,DBLP:conf/icml/PangLYZY22} study the reason of the adversarial example, few of them focus on the Android malware detection. In our opinion, there are two more reasons for adversarial example in Android malware detection. One is that the dataset in Android malware detection are likely be to a gathered state(e.g., a same Android malware family may have the similar code structure) which may increase the blind spots \cite{DBLP:journals/corr/SzegedyZSBEGF13} of the dataset. Second, the existing Android malware detection methods (especially the static detection method) cannot precisely  model the malware behavior (e.g., cannot analyse various conditional statement statically). Due to the above reasons, the existing Android malicious detection system is not really secure\cite{277204}. }

% \textcolor{green}{ While these methods have achieved impressive results, their network architectures suffer from an machine learning inherent shortcoming: adversarial example attack. Although there have been many works \cite{DBLP:journals/corr/GoodfellowSS14,DBLP:journals/corr/TanayG16,DBLP:conf/icml/PangLYZY22} study the reason of the adversarial example, few of them focus on the Android malware detection. In our opinion, there are two more reasons for adversarial example in Android malware detection. One is that the dataset in Android malware detection are likely be to a gathered state(e.g., a same Android malware family may have the similar code structure) which may increase the blind spots \cite{DBLP:journals/corr/SzegedyZSBEGF13} of the dataset. Second, the existing Android malware detection methods (especially the static detection method) cannot precisely  model the malware behavior (e.g., cannot analyse various conditional statement statically). Due to the above reasons, the existing Android malicious detection system is not really secure\cite{277204}. }



% \textcolor{green}{ While these methods have achieved impressive results, their network architectures suffer from an machine learning inherent shortcoming: adversarial example attack.  Although there have been many works  attribute the exist of the adversarial example to the misalignment  of the decision boundary  between the  classifier and real dataset \cite{DBLP:journals/corr/TanayG16,HU2022108824}, few of them focus on the Android malware detection. In our opinion, different from the image domain, in Android malware detection,  existing Android malware detection methods (especially the static detection method) cannot precisely  model the malware behavior (e.g., cannot analyse various conditional statement statically) which aggravates this misalignment, hence the existing Android malicious detection system is not really secure\cite{277204}.}

{ While these methods have achieved impressive results, they are susceptible to adversarial examples. The existence of adversarial examples is attributed to the problem that the decision boundaries of classification models are non-ideal \cite{DBLP:journals/corr/TanayG16,HU2022108824}. This problem becomes more serious in Android malware detection since the static analysis methods cannot precisely model the malware behavior. Therefore, the existing Android malware detection systems are not really secure\cite{277204}.}