\section{Appendix}

\subsection{The limitations in callee selection} \label{sec:callees' limitation}
As shown in Section \ref{sec:adversarial manipulation method}, we choose the leaf nodes as candidate callees. However, not all leaf nodes can be chosen as callees. There exist two limitations:
\begin{itemize}
\item \textit{Access modifier}. Some leaf-node functions are not allowed to be invoked at all. Therefore, we only consider those leaf-node functions whose access modifier is \textit{public}. 
\item \textit{Parameter type}. The arguments of some leaf-node functions are the instances of classes. Under this situation, invoking these functions will incur instantiating a class, hence generating an unintended edge. To avoid this problem, we propose to choose the leaf-node functions whose arguments are void or belong to the category of primitive data types (e.g., int and short) and the \text{String} class. 
\end{itemize}
 
 
% \subsection{Examples of invocation types in smali} \label{appendix: smali example}
% As shown in Section \ref{sec:adversarial manipulation method}, different invocation types require different smali manipulation. There are 5 invocation types in smali code, i.e., \textit{invoke-direct}, \textit{invoke-virtual}, \textit{invoke-static}, \textit{invoke-super} and  \textit{invoke-interface}. Fig. \ref{fig:direct} shows an example for every invocation type.  
% 	\begin{figure}[htbp]
% 		\centering
% 		\includegraphics[scale=0.6]{direct.pdf}
% 		\caption{The examples of smali code with different invocation types.}
% 		\label{fig:direct}
% 	\end{figure}

% \subsection{{Extracting features from an FCG}}
% \label{appendix: gcn}
% {
% As mentioned in Subsection \ref{subsection: substitute}, we employ a GCN model to extract features from an input, i.e., an FCG. The details are given below. We use an adjacent matrix $\textbf{A}$ and a node feature matrix $\textbf{X}$ to characterize every FCG inputted to our substitute model. Here the adjacent matrix reflects the topology information of an FCG, and the node feature matrix provides the node property information. We use $\mathbf{H}^{l}$ ($0\leq l \leq L$) to refer to the features obtained at layer $l$. When $l=0$ holds, $\mathbf{H}^{l}$ reduces to the node feature matrix. 
% The features obtained at layer $l+1$ are derived from the features at layer $l$ by  
% \begin{equation}\label{eq:gcn_propgation_rule}
% 	\mathbf{H}^{(l+1)} = \sigma (\tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} \mathbf{H}^{l}\mathbf{W}^{l}),
% \end{equation}
% where $\sigma (\cdot)$ is the activation function, $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I}$, $\mathbf{I}$ represents an Identity Matrix, $\tilde{\mathbf{D}}$ is the degree matrix of $\tilde{\mathbf{A}}$ and $\mathbf{W}^{l}$ denotes the weights of layer $l$. }

% {To well train the substitute model, we design a loss function defined as
% \begin{equation}\label{eq:loss}
% 	\mathcal{L}=-\mathbf{E}(\sum_{i} y_{i}^{\prime} \log \left(y_{i}\right))+ \lambda \sum_{i}|w_i^2|,
% \end{equation}
% where  $y_i^{\prime}$ is the true label labeled by the target model, $y_i$  is the prediction output, $w_i$ is the weights that need to learn. In this loss function, the first term is binary-classification cross-entropy, and the second term is introduced to reduce overfitting.}


\subsection{Theoretical Analyses for our method} \label{appendix: theoretical analyses}

% \textcolor{red}{
Our method {\ourtool} utilizes the algorithm {\ouralgorithm} to find the desired perturbation for a given malware sample. Since {\ouralgorithm} is an evolutionary algorithm, how to mitigate premature convergence is an important issue. Here, premature convergence or prematurity is a common phenomenon that leads an evolutionary algorithm to converge quickly to a local optimum. For evolutionary algorithms, prematurity is often caused by the lack of gene diversity.

% there exists one important issue for {\ouralgorithm} that is  the mitigation of premature convergence. }


%However, {\ouralgorithm} effectively mitigates this problem by introducing multiple populations and immigration among populations. 


% \subsubsection{The convergence of {\ouralgorithm}}

% We assume two individuals $x^i$ and $x^j$. Then we define $\delta(\cdot)$ as a metric function that defines the distance between two individuals, i.e., 

% \begin{equation}
% 	\resizebox{.8\hsize}{!}{
% 		$\delta\left(x^i, x^j\right)= \begin{cases}0 &x^i=x^j \\ \left|1+M-F\left(x^i\right)\right|+\left|1+M-F\left(x^j\right)\right| & x^i \neq x^j\end{cases}$
% 	}
% \end{equation}
% where   $F$ is the fitness function and $M$ is the upper bound  of the $F$.


% %	 Note that, the $F$ can be further more defined as the sum of the  fitness in different populations (because the immigration operate, the individual will interact between different populations).

% %	\begin{equation}
% %		F = \sum_{m=1}^l{F_m}
% %	\end{equation}
% %	where l is the number of populations.

% We define the generator as a function $g$ and use $r$ to represent the evolutionary generation in {\ouralgorithm}. According to the selection strategy of {\ouralgorithm},  we have $F(g(x^i_{r+1})) \geq F(g(x^i_{r}))$. It means the fitness of the surviving offsprings are always {equal to} or higher than the parents.

% So we have

% \begin{equation}
% 	\resizebox{.9\hsize}{!}{$
% 		\begin{aligned}
% 			\delta\left(g\left(x^i_r\right),g\left(x^j_r\right)\right)&=\left|1+M-F\left(g\left(x^i_r\right)\right)\right|+\left|1+M-F\left(g\left(x^j_r\right)\right)\right| \\
% 			&\leq\varepsilon \cdot\left(\left|1+M-F\left(x^i_r\right)\right|+\left|1+M-F\left(x^j_r\right)\right|\right) \\
% 			&=\varepsilon \cdot \delta\left(x^i_r, x^j_r\right)(0<\varepsilon<1)
% 		\end{aligned}$}
% \end{equation}


% According to the Banach compression mapping principle, {\ouralgorithm} converges on a single fixed point $x^{*}$, i.e., 
% \begin{equation}
% 	x^{*}=\lim _{r \rightarrow \infty} g^{r}(x_0)
% \end{equation}
% where $ r$ gives how many rounds of iteration have been taken by {\ouralgorithm}.


%According to above analyses, we can draw the conclusion that with sufficient iterations, {\ouralgorithm} will finally converge to a point.

% \subsubsection{ \textbf{Mitigating prematurity using multiple populations }}
 In the following, we analyze how multiple populations introduced in {\ouralgorithm} mitigate the problem of premature convergence.

Due to the introduction of multiple populations, there exist a local optimal solution in each {population}. We define this locally optimal solution as $x^{*}_{p}$, where $p=1,2,...,l$ is the index of the population.

Then, the individuals that can achieve  the local optimal solutions with the {\ouralgorithm} $G$ are termed as:
\begin{equation}
	A_{p}^{*}=\left\{x \in A: G(x)=x^{*}_{p}\right\}
\end{equation}
where $A$ is the solution space.

Then, the probability {that an} individual $x\in A$ {belongs} to set $A_{p}^{*}$ can be represented as $\theta_{p}=P\left(A_{p}^{*}\right)$. It is clear that $\theta_{p}>0$ for $p=1, \ldots, l$ and $\sum_{p=1}^{l} \theta_{p}=1$.


The size of the set  $A_{p}^{*}$ can be termed as $n_{p}$.
According to the definition, we have $n_{p} \geq 0\ (p=1, \ldots, l)$, the random vector $\left(N_{1}, \ldots, N_{l}\right)$ follows the multinomial distribution and $\sum_{p=1}^{l} N_{p}=N$.
\begin{equation}
	\operatorname{Pr}\left\{n_{1}=N_{1}, \ldots, n_{l}=N_{l}\right\}=\left(\begin{array}{c}
		N \\
		N_{1}, \ldots, N_{l}
	\end{array}\right) \theta_{1}^{N_{1}} \ldots \theta_{l}^{N_{l}}
\end{equation}
where
\begin{equation}
	\quad\left(\begin{array}{c}
		N \\
		N_{1}, \ldots, N_{l}
	\end{array}\right)=\frac{N !}{N_{1} ! \ldots N_{l} !}, \quad N_{p} \geq 0 \quad(p=1, \ldots, l)
\end{equation}

We define $W$ as the number of  locally  optimal solutions found by {\ouralgorithm}. Then the probability of   $l$ locally  optimal solutions being found can be termed  as %${Pr}\{W=l \mid \theta\}$:
\begin{equation}
	\operatorname{Pr}\{W=l \mid \theta\}=\sum_{N_{1}+\cdots+N_{l}=N} \left(\begin{array}{c}
		N \\
		N_{1}, \ldots, N_{l}
	\end{array}\right) \theta_{{1}}^{N_{1}} \ldots \theta_{{l}}^{N_{l}} 
\end{equation}
where
\begin{equation}
	\theta=\left(\theta_{1}, \ldots, \theta_{l}\right).
\end{equation}


For the sake of analyzing the limit, we define
\begin{equation}	
	\delta=\min \left\{\theta_{1}, \ldots, \theta_{l}\right\} \leq 1 / l
\end{equation}

Then we have
\begin{equation}
	\begin{aligned}
		\operatorname{Pr}\{W=l \mid \theta\} & \geq \sum_{N_{1}+\ldots+N_{l}=N}\left(\begin{array}{c}
			N \\
			N_{1}, \ldots, N_{l}
		\end{array}\right) \delta^{N} \\
		&=(\delta l)^{N} \operatorname{Pr}\left\{W=l \mid\left(\frac{1}{l}, \ldots, \frac{1}{l}\right)\right\}
	\end{aligned}
\end{equation}

For any $l$ and $\theta$, we can find the least evaluation number $n^*$ such that for any given $\gamma \in(0,1)$, we will have $\operatorname{Pr}\{W=l \mid \theta\} \geq \gamma$ 
for all $n \geq n^{*}$.
Finding $n^{*}=n^{*}(\gamma, \theta)$ is the problem of finding  the 
(minimal) number of points in $A$ such that the probability that
all local minimizers will be found is at least $\gamma$.

We analyze the extreme cases that $\theta^{*}=\left(l^{-1}, \ldots, l^{-1}\right)$. Hence the problem of finding $n^{*}(\gamma, \theta)$ is reduced to that of finding $n^{*}\left(\gamma, \theta^{*}\right)$. For a large $N$, $n^{*}(\gamma, \theta)$ can be approximated as 

\begin{equation}
	\begin{aligned}
		\operatorname{Pr}\left\{W=l \mid \theta^{*}\right\}&=l^{-N}  \sum_{N_{1}+\cdots+N_{l}=N}\left(\begin{array}{c}
			N \\
			N_{1}, \ldots, N_{l}
		\end{array}\right) \\
		&= \sum_{p=0}^{l}(-1)^{p}\left(\begin{array}{c}
			l \\
			p
		\end{array}\right)(1-p / l)^{N} \\
		& \sim \exp \{-l \exp \{-N / l\}\}, \quad N \rightarrow \infty
	\end{aligned}
\end{equation}

By solving the equation $\exp (-l \exp (-N / l))=\gamma$ with respect to $N$, we obtain
the approximation

\begin{equation}
	n^{*}\left(\gamma, \theta^{*}\right) \simeq l \ln l+l \ln (-\ln \gamma) \label{muti-p}
\end{equation}

% \textbf{Analysis 1:}
% It can be concluded that a larger $l$ will cause a larger query number (i.e., query number) of BagAmmo, which means decrease the convergence rate.

With Eq. \eqref{muti-p}, we analyze the relationship between the number of required queries and the population number as follows. We can see that multiple populations ( i.e., $l>1$ ) help to slow down the convergence rate of the algorithm. As we all know, prematurity is a common  phenomenon in which an evolutionary algorithm early converges to a poor local optimum. However, {\ouralgorithm} begins its search in multi start $l$ which  makes the algorithm can find a better solution with a higher probability. Our algorithm effectively relieves this problem by introducing multiple populations, and prevents the algorithm from wasting many efforts on repeatedly finding the same local optimum.

% , and  avoid the algorithm wasting much effort on repeated finding a same local optimum.
% However, our algorithm effectively relieve this  phenomenon through multi-population.


% \subsubsection{ \textbf{The queried count analysis}}
% The purpose of BagAmmo is to find the global optimal solution $x^*$. 
% We define a set $B$, and if a individual falls in this set then this  individual is a global optimal solution. The set $B$ can be defined as:
% \begin{equation}
% 	\label{eq:a}
% 	B = B(x^*,\epsilon,\rho)=\{ x\in A:\rho(x,x^*) \leq \epsilon \}
% \end{equation}
% where the $A$ is the solution space and $x$ is a individual,  $\epsilon \textgreater 0$ is a infinitesimal  constant. $\rho$ is a metric function that defines the distance between two points in $A$.


% So given a individual $x^j$, we define the probability of this individual being the optimal solution as:


% \begin{equation}
% 	Pr\{x^i \in B \}  =  g_B(F(x^i))             
% \end{equation}
% where $F$ is the fitness function, and $g_B$  is a  {function with positive correlation.} 

% %	For  convenience, we term the $g_B(f) $ as $P_B$


% What's more, the  probability of this individual  being not the optimal solution as:

% \begin{equation}
% 	Pr\{x^i \notin B \} = 1- g_B(F(x^i)) 
% \end{equation}	

% %jump out of partial optimization

% % \quad for \quad  all \quad j
% %	therefore,


% For  convenience, we assume all individuals are independent identically distributed (i.e., IID), so probability of any one individual   being  the optimal solution $g_B(F(x^j))$ can be written as $P_B$.
% The probability of all the individuals  being not the global optimal solution can be termed as:  

% \begin{equation}
% 	Pr\{x^1 \notin B,\ldots, x^n \notin B\}  = (1-P_B)^n
% \end{equation}

% Therefore we can define the probability of finding the global optimal solution:

% \begin{equation}
% 	\resizebox{.85\hsize}{!}{
% 		$	Pr\{x^j \in B\  for\  at\  least\  one\ j, 1 \leq j\leq n\}  = 1-(1-P_B)^n $
% 	}
% \end{equation}

% Let us assume that we are required to reach the set B with probability at least $1-\gamma$ for some $0<\gamma<1$.
% This gives the following inequality for $n$:
% \begin{equation}
% 	1-(1-P(B))^{n} \geq 1-\gamma
% \end{equation}

% Solving it we have:
% \begin{equation}
% 	n \geq n(\gamma)=\frac{\ln \gamma}{\ln (1-P(B))}
% \end{equation}

% We assume that $P(B)$ is small:
% \begin{equation} 
% 	\ln(1-P(B)) \cong-P(B)
% \end{equation}

% We have:
% \begin{equation} 
% 	n \geq-\frac{\ln \gamma}{P(B)}
% \end{equation}

% \textbf{Conclusion:} That is, we need to make at least $\lceil-\ln \gamma / P(B)\rceil$ queries in BagAmmo to reach the set $B$ with probability $1-\gamma$.






% \begin{table*}[]
% 	\caption{{Performance of target models.}}
% 	\centering
% 	\label{tab:performance of target}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{cc|cccccccc|cccc}
% \hline
% \multicolumn{2}{c|}{\multirow{2}{*}{Classifier\textbackslash{}Level}} & \multicolumn{4}{c|}{Family level} & \multicolumn{4}{c|}{Package level} & \multicolumn{4}{c}{Class level} \\ \cline{3-14} 
% \multicolumn{2}{c|}{} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{Accuracy} \\ \hline
% \multicolumn{1}{c|}{\multirow{5}{*}{MaMaDroid}} & \cellcolor{cyan!60!gray!10}RF & \cellcolor{cyan!60!gray!10}0.9400 & \cellcolor{cyan!60!gray!10}0.9397 & \cellcolor{cyan!60!gray!10}0.9398 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.9397} & \cellcolor{cyan!60!gray!10}0.9514 & \cellcolor{cyan!60!gray!10}0.9507 & \cellcolor{cyan!60!gray!10}0.9511 & \cellcolor{cyan!60!gray!10}0.9507 & \cellcolor{cyan!60!gray!10}0.9409 & \cellcolor{cyan!60!gray!10}0.9407 & \cellcolor{cyan!60!gray!10}0.9408 & \cellcolor{cyan!60!gray!10}0.9407 \\

% \multicolumn{1}{c|}{} & DNN & 0.8935 & 0.8925 & 0.8930 & \multicolumn{1}{c|}{0.8925} & 0.9296 & 0.9294 & 0.9295 & 0.9294 & 0.8794 & 0.8766 & 0.8780 & 0.8765 \\

% \multicolumn{1}{c|}{} & \cellcolor{cyan!60!gray!10}AB & \cellcolor{cyan!60!gray!10}0.8855 & \cellcolor{cyan!60!gray!10}0.8854 & \cellcolor{cyan!60!gray!10}0.8854 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.8854} & \cellcolor{cyan!60!gray!10}0.9088 & \cellcolor{cyan!60!gray!10}0.9087 & \cellcolor{cyan!60!gray!10}0.9088 & \cellcolor{cyan!60!gray!10}0.9087 & \cellcolor{cyan!60!gray!10}0.8823 & \cellcolor{cyan!60!gray!10}0.8823 & \cellcolor{cyan!60!gray!10}0.8823 & \cellcolor{cyan!60!gray!10}0.8823 \\

% \multicolumn{1}{c|}{} & 1-NN & 0.9112 & 0.9108 & 0.9117 & \multicolumn{1}{c|}{0.9108} & 0.9272 & 0.9266 & 0.9269 & 0.9266 & 0.9151 & 0.9146 & 0.9148 & 0.9146 \\

% \multicolumn{1}{c|}{} & \cellcolor{cyan!60!gray!10}3-NN & \cellcolor{cyan!60!gray!10}0.9059 & \cellcolor{cyan!60!gray!10}0.9057 & \cellcolor{cyan!60!gray!10}0.9058 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.9057} & \cellcolor{cyan!60!gray!10}0.9193 & \cellcolor{cyan!60!gray!10}0.9191 & \cellcolor{cyan!60!gray!10}0.9192 & \cellcolor{cyan!60!gray!10}0.9190 & \cellcolor{cyan!60!gray!10}0.9054 & \cellcolor{cyan!60!gray!10}0.9052 & \cellcolor{cyan!60!gray!10}0.9053 & \cellcolor{cyan!60!gray!10}0.9052 \\ \hline

% \multicolumn{1}{c|}{\multirow{5}{*}{APIGraph}} & RF & 0.9406 & 0.9401 & 0.9404 & \multicolumn{1}{c|}{0.9401} & 0.9421 & 0.9416 & 0.9418 & 0.9416 & 0.9324 & 0.9323 & 0.9324 & 0.9323 \\

% \multicolumn{1}{c|}{} & \cellcolor{cyan!60!gray!10}DNN & \cellcolor{cyan!60!gray!10}0.8963 & \cellcolor{cyan!60!gray!10}0.8959 & \cellcolor{cyan!60!gray!10}0.8961 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.8960} & \cellcolor{cyan!60!gray!10}0.8999 & \cellcolor{cyan!60!gray!10}0.8992 & \cellcolor{cyan!60!gray!10}0.8995 & \cellcolor{cyan!60!gray!10}0.8992 & \cellcolor{cyan!60!gray!10}0.8137 & \cellcolor{cyan!60!gray!10}0.8073 & \cellcolor{cyan!60!gray!10}0.8105 & \cellcolor{cyan!60!gray!10}0.8073 \\

% \multicolumn{1}{c|}{} & AB & 0.8842 & 0.8842 & 0.8842 & \multicolumn{1}{c|}{0.8842} & 0.8874 & 0.8873 & 0.8874 & 0.8873 & 0.8659 & 0.8659 & 0.8659 & 0.8659 \\

% \multicolumn{1}{c|}{} & \cellcolor{cyan!60!gray!10}1-NN & \cellcolor{cyan!60!gray!10}0.9110 & \cellcolor{cyan!60!gray!10}0.9104 & \cellcolor{cyan!60!gray!10}0.9107 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.9104} & \cellcolor{cyan!60!gray!10}0.9184 & \cellcolor{cyan!60!gray!10}0.9179 & \cellcolor{cyan!60!gray!10}0.9181 & \cellcolor{cyan!60!gray!10}0.9179 & \cellcolor{cyan!60!gray!10}0.9090 & \cellcolor{cyan!60!gray!10}0.9086 & \cellcolor{cyan!60!gray!10}0.9088 & \cellcolor{cyan!60!gray!10}0.9086 \\

% \multicolumn{1}{c|}{} & 3-NN & 0.9033 & 0.9029 & 0.9031 & \multicolumn{1}{c|}{0.9029} & 0.9097 & 0.9094 & 0.9095 & 0.9094 & 0.8972 & 0.8970 & 0.8971 & 0.8970 \\ \hline

% \multicolumn{1}{c|}{GCN} & \cellcolor{cyan!60!gray!10}DNN & \cellcolor{cyan!60!gray!10}0.8362 & \cellcolor{cyan!60!gray!10}0.8324 & \cellcolor{cyan!60!gray!10}0.8339 & \multicolumn{1}{c|}{\cellcolor{cyan!60!gray!10}0.8351} & \cellcolor{cyan!60!gray!10}0.9283 & \cellcolor{cyan!60!gray!10}0.9433 & \cellcolor{cyan!60!gray!10}0.9356 & \cellcolor{cyan!60!gray!10}0.9363 & \cellcolor{cyan!60!gray!10}- & \cellcolor{cyan!60!gray!10}- & \cellcolor{cyan!60!gray!10}- & \cellcolor{cyan!60!gray!10}- \\ \hline
% \end{tabular}%
% }
% \end{table*}


% \subsection{An instance of adversarial example}
% \label{appendix:instance}
% \begin{figure}[h]
% 	\centering
% 	\includegraphics[scale=0.4]{sangji.pdf}
% 	\caption{Visualization of the perturbation.}
% 	\label{fig:sangji}
% \end{figure}

% {Here we visualize the perturbation derived by our method. To this end, we randomly select } a malware sample and then use {\ourtool} to modify this malware to attack MaMaDroid which chooses package feature granularity and uses a DNN as its classifier. After the attack succeeds, we collect the inserted caller and callee, which are shown in Fig. \ref{fig:sangji}.

% In this figure, the left is the callers and the right is the callees. The connection between a caller and the corresponding callee means the inserted function call between them. The thickness degree of the line between the caller and the callee reflects the number of times that the function call is inserted by {\ourtool}. In other words, the thicker the line is, the more calls between the caller and the callee are added. 


% {In this figure, the thick lines indicate that if we perturb the corresponding nodes, the influence on classification outcome will be large. It can be seen } that the thickest line is connected with Ljava/util package. Hence, adding more APIs in Ljava/util package helps induce misclassification. 




\subsection{ {Implementation details and an instance of the smali code}}
\label{appendix:smali}


	\begin{figure}[!h]
		\centering
		\includegraphics[scale=0.6]{direct.pdf}
		\caption{The examples of smali code with different invocation types.}
		\label{fig:direct}
	\end{figure}

 {
In this section, we first provide the implementation details of the transformation from the generator’s output to the perturbation on the malware samples. Then we give an instance of the samli code.}
 {The output of the generator is pairs of caller-callee functions. There are three steps to implement output-to-perturbation transformation. First, for every function pair, we find the smali file related to the selected caller, according to the latter's full name. }
 {Second, we insert statements into the smali file to implement a try-catch trap. Here we can use five types of function invocation, including invoke-direct, invoke-virtual, invoke-static, invoke-super and invoke-interface. Different invocation types require different smali manipulation. Fig. \ref{fig:direct} shows an example for every invocation type.  }
 {Third, we use \textit{Apktool} to rebuild the modified smali files to APK file. The above operations are automatically conducted by a Python script. }




\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.45]{smali_code.pdf}
	\caption{An instance of the smali code.}
	\label{fig:smali}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=1]{retraining.pdf}
	\caption{{Attack success rate after retraining.}}
	\label{fig:retraining}
\end{figure}


 \begin{figure}[!h]
	\centering
	\includegraphics[scale=0.65]{ration_ori_adv.pdf}
	\caption{ {The detection success ratio on VirusTotal}.}
	\label{fig:ratio}
\end{figure}

 \begin{figure*}[!h]
	\centering
	\includegraphics[scale=0.9]{try_catch_count.pdf}
	\caption{ {The number of try-catch blocks before and after {\ourtool} attack.}}
	\label{fig:try_catch}
\end{figure*}

%  {The output-to-perturbation transformation consists of three steps. First, we find the smali file related to the selected caller, according to the latter's full name. 
% Second, we insert statements into the smali file to implement a try-catch trap. Here we can use five types of function invocation, including invoke-direct, invoke-virtual, invoke-static, invoke-super and invoke-interface. These invocation types result in different smali manipulations, due to their various requirements for register usage. To facilitate the understanding, we provide several examples of invocation types in Fig. 15 in Appendix 10.2. We also show how to modify the smali codes in Appendix 10.7.
% Third, we use \textit{Apktool} to rebuild the modified smali files to APK file. The above operations are automatically conducted by a Python script. }


To show how {\ourtool}  manipulates the smali code, we supply a  practical manipulation instance in Fig. \ref{fig:smali}. From line 6 to line 11, {we can find} a runtime exception. To be specific, we initialize an array with length 3 and employ an opaque method to visit the 4-th element of this array. Then it will throw an exception \textit{java.lang.ArrayIndexOutOfBoundsException} and skip the inserted callee functions. In this way, our method can effectively insert calls and preserve the malware's original functionality.





% \begin{figure}[h]
% 	\centering
% 	\includegraphics[scale=1.1]{retrain_recall.pdf}
% 	\caption{{Recall of the benign samples after retraining.}}
% 	\label{fig:retraining_recall}
% \end{figure}

{It is worth noting that the statements added into a try block are not fixed. Hence {\ourtool} can resist the whitelist-based defense. For example, suppose we want to trigger the exception of \textit{IndexOutOfBoundsException} by inducing array access violation. For this purpose, we access the array index that exceeds the array length. {\ourtool} can generate countless variable names and variable values for such an array index. Therefore, it is impossible to build a white list to rule out the statements added by {\ourtool}.}

% since our program can automatically produce unlimited number of variants to trigger
% any selected exception, 
% \subsection{{Detection performance of target models}}
% \label{appendix:performance}
% {
% We use the 10-fold cross-validation to evaluate the detection performance of target models (i.e., MaMaDroid, APIGraph, and GCN). The results are given in Table \ref{tab:performance of target}. This table shows that the target models perform well on our dataset. Consequently, they are qualified for evaluating {\ourtool}. Moreover, Table \ref{tab:performance of target} does not provide the results of GCN under the class-level feature granularity. This is because under the class-level feature granularity, the property vector of nodes in FCG is high-dimensional and extremely sparse, making the performance of GCN significantly degrade. Therefore, the GCN under the class-level feature granularity is not used as our target model.   }

% {For convenience, here we give the hyper-parameters of these baselines. The network structure of the DNN is shown as follows: one input layer, four hidden layers (all with 300 neurons) and one output layer (with 1 dimension). The hidden layers use the relu activation function. The output layer uses the sigmoid activation. The GCN's structure is described as follows: one input layer, a graph convolution layer with 256 neurons, a graph convolution layer with 512 neurons, an average pooling layer, a full connection layer with 256 neurons, a full connection layer with 128 neurons and one output layer. All the hidden layers adopt the relu activation function, and the output layer uses the sigmoid activation function. The base model of the Adaboost corresponds to a decision tree, and the maximum depth is 3. Finally, KNN-1, KNN-3 and RF all use their default parameters in the scikit-learn. }

% Second, it is noted that under the package-level feature granularity, the target models usually perform best. This is because that the package-level feature granularity is coarser and may lose some useful information and the class-level feature granularity is too 

% Note that in family granularity's FCG, many information  will lose and cause lower detection performance than  package granularity's FCG. However, in  class granularity's FCG, every function will be described in too much detail. It causes that the feature  be so sparse and  some  redundant information be introduced. So, the classifiers with package granularity's FCG  have a higher overall Android malware detection performance. }

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}



\subsection{\textbf{Dataset in our experiments}} \label{appendix: dataset}
{ Our dataset includes 44375 Android APKs released from 2010 to 2020, which are collected from AndroZoo, FalDroid,and Drebin. Table \ref{tab:dataset} gives the source, count,and years of APKs in our dataset. }

%Note that the APKs that cannot be successfully uncompressed are not included in our dataset. }

% Note that, the count of the sample is those APKs can be successfully decoded and  extracted feature, so it may be a little less than the count in original paper.

% \begin{table}[H] 
% 	\caption{Dataset used in our experiments.}
% 	\centering
% 	\label{tab:dataset}
% 	%\rowcolors{1}{white}{blue!5}
% 	\scalebox{0.9}{
% 		\begin{tabular}{cccc}
% 			\hline
% 			\multicolumn{1}{c}{Label} & Year & Count & Avg. Size (KB) \\ \hline
% 			\multirow{5}{*}{Malicious} & \cellcolor{cyan!60!gray!10}2016 & \cellcolor{cyan!60!gray!10}1530  & \cellcolor{cyan!60!gray!10}4259.48                    \\
% 			& 2017 & 1870  & 4120.43                \\
% 			& \cellcolor{cyan!60!gray!10}2018 & \cellcolor{cyan!60!gray!10}1893  & \cellcolor{cyan!60!gray!10}4112.36                \\
% 			& 2019 & 1604  & 4539.50                \\
% 			& \cellcolor{cyan!60!gray!10}2020 & \cellcolor{cyan!60!gray!10}1120  & \cellcolor{cyan!60!gray!10}4545.07             \\ \hline
% 			\multirow{5}{*}{Benign}    & 2016 & 1662  & 4479.19              \\
% 			& \cellcolor{cyan!60!gray!10}2017 & \cellcolor{cyan!60!gray!10}1920  & \cellcolor{cyan!60!gray!10}4949.94               \\
% 			& 2018 & 2043  & 5215.32                \\
% 			& \cellcolor{cyan!60!gray!10}2019 & \cellcolor{cyan!60!gray!10}2272  & \cellcolor{cyan!60!gray!10}6002.58               \\
% 			& 2020 & 1771  & 6528.78               \\ \hline
% 			Total & \cellcolor{cyan!60!gray!10}- & \cellcolor{cyan!60!gray!10}17685  & \cellcolor{cyan!60!gray!10}4929.72             \\ \hline			
% 			\hiderowcolors
% 		\end{tabular}%
% 	}
% \end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[H]
	\caption{{Dataset used in our experiments.}}
	\centering
	\label{tab:dataset}
\scalebox{1}{%
\begin{tabular}{c|ccc}
\hline
\textbf{Source} & Label & Years & Count \\ \hline
\multirow{2}{*}{Androdzoo} & \cellcolor{cyan!60!gray!10}Benign & \cellcolor{cyan!60!gray!10}2010-2020 & \cellcolor{cyan!60!gray!10}21399 \\
 & Malicious & 2015-2020 & 9668 \\ \hline
FalDroid & \cellcolor{cyan!60!gray!10}Malicious & \cellcolor{cyan!60!gray!10}2013-2014 & \cellcolor{cyan!60!gray!10}8407 \\ \hline
Drebin & Malicious & 2010-2012 & 4900 \\ \hline
Total & \cellcolor{cyan!60!gray!10}- & \cellcolor{cyan!60!gray!10}2010-2020 & \cellcolor{cyan!60!gray!10}44374 \\ \hline
\end{tabular}%
}
\end{table}




\subsection{Resistance to adversarial retraining.}
\label{app:ar}
% Adversarial retraining is regarded as the most effective defense method against AE attacks. In this section, we test our {\ourtool} with adversarial retraining. We randomly select 100 adversarial examples that can deceive target systems and divide them into training and testing set. We use different ratios of training samples to retraining the target classifier, in order to evaluate attack success ratio (ASR) on the testing set \textcolor{green}{ and the recall of benign samples.}



% %为什么要增加recall的实验？感觉对我们不利
% %能不能从fig 18推出一些对我们有利的东西

% \textcolor{green}{Our results are given in Fig. \ref{fig:retraining} and Fig. \ref{fig:retraining_recall}, respectively. In Fig. \ref{fig:retraining}, the vertical axis is ASR of {\ourtool} and  the horizontal axis is the ratio of AEs used in adversarial retraining. Not surprisingly, the ASR decreases with the increase of the AEs adopted by adversarial retraining. When the ratio exceeds 40\%, adversarial retraining becomes effective in resisting {\ourtool}. In Fig. \ref{fig:retraining_recall}, the vertical axis reflects the recall of benign samples. This figure shows that adversarial retraining does not markedly decrease the recall of benign samples. This is because that the number of AEs is much smaller than that of clean samples (about 40K). In fact, if we add more AEs or the clones of the original AEs into adversarial retraining, the recall will decrease to a very low level. This indicates the model gets overfitted over the AEs. Finally, it should be pointed out that {\ourtool} can be used to improve the robustness of existing malware detection models. More specifically, one just needs to use {\ourtool} to generate an appropriate number of AEs, and employes the latter to adversarially training his model.}
 
%  What's more, it is extremely difficult to collect so many adversarial examples for adversarial retraining. 
 
%  Finally, model owners can improve their models' defense capability through adversarially retraining their models.   } 



Adversarial retraining is regarded as the most effective defense method against AE attacks. In this section, we test {\ourtool} with adversarial retraining. We randomly select 100 adversarial examples that are generated by {\ourtool} and can deceive target systems. We divide these adversarial examples into a training and a test set. {Under various training sample proportions, we retrain the target classifier in order to evaluate ASR on the test set.}



%为什么要增加recall的实验？感觉对我们不利
%能不能从fig 18推出一些对我们有利的东西

{Our results are given in Fig. \ref{fig:retraining}, whose vertical axis is the ASR of {\ourtool} and the horizontal axis is the proportion of AEs used in adversarial retraining. Not surprisingly, the ASR decreases with the increase of the AEs adopted by adversarial retraining. When the ratio exceeds 40\%, adversarial retraining becomes effective in resisting {\ourtool}. 
In practice, however, it is extremely difficult to collect sufficient adversarial examples for adversarial retraining. On the other hand, it is also noted that aided by {\ourtool}, model owners can improve their models’ defense capability with adversarial retraining.
}





\subsection{  {Attack performance on VirusTotal}}
\label{app:virustotal}

We  evaluate the  performance of {\ourtool} on  VirusTotal. 
 To be specific, we use {\ourtool} to generate AEs (adversarial examples) through querying the MaMadroid detector, and upload them to VirusTotal for malware detection.  
 VirusTotal uses about 60 malware detection methods unknown to us. We then record the ratio of the successful detection methods to all the methods, denoted by R\_adv. For comparison, we also conduct the same setting for the original sample, and the corresponding ratio is termed as R\_ori. 
 What's more, we calculate the difference between the R\_adv and R\_ori, which termed as R\_ori - R\_adv.
 The results are shown in Fig. \ref{fig:ratio}.  The horizontal axis of this figure shows different APKs, and the vertical axis gives the ratios R\_adv (denoted by the red line) and R\_ori (denoted by the blue line). The yellow line shows the decreasing ratio of the successful detection methods. It can be seen that {\ourtool} can effectively reduce the probability of malware being detected, owing to the transferability of AEs \cite{DBLP:conf/iclr/LiuCLS17}. It is worth noting that this attack effect is achieved under the scenario where no queries are conducted and no prior knowledge about detection methods can be obtained. 



\subsection{  {The number of added try-catch blocks}}\label{app:trycatch}

 {Since {\ourtool} inserts try-catch blocks into malware code, a defender may choose to detect it through judging whether the number of try-catch blocks exceeds a predetermined threshold. However, it is difficult to find an appropriate threshold for all APKs. Without such a threshold, this defense method may cause a high false positive or false negative rate.}

 {To verify it, we record the ratio of try-catch block number to the function-calls number in 50 malicious APKs and the corresponding adversarially perturbed APKs, termed as R\_ORI and R\_AE, respectively. The results are shown in Fig. \ref{fig:try_catch}.
The horizontal axis of this figure shows the IDs of these APKs, and the vertical axis gives the count ratio of try-catch blocks. The orange and green bars mean the original APK and the  corresponding modified APK, respectively. We can draw two conclusions from this figure. First, the number of try-catch blocks added by our method is relatively small compared to that of existing try-catch blocks. Therefore it is hard to find a threshold to 
 clearly distinguish the original APK and the perturbed APK. Second, the number of try-catch blocks drastically fluctuates among various APKs. Thus, it is also difficult to set a fixed threshold  for all APKs. }


