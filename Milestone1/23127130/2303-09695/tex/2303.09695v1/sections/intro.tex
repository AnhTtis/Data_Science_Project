\section{Introduction}

Converting a scanned model of a garment from a 3D point cloud to 2D panels and their sewing structure is termed \emph{pattern design}~\cite{pietroni2022computational,igarashi2005rigid,bartle2016physics}. Such a procedure allows simpler modeling, duplication and adjustments of existing garments in fashion,
because the 2D panels are necessary
for production with real fabric in the manufacturing process. 
%Garment fabrication aims to extract the 2D panels and their sewing structure associated with a given 3D point cloud \cite{igarashi2005rigid,bartle2016physics}.
%This capability is critical in fashion domain, where the 2D panels are necessary for production with real fabric in the manufacturing process.
Earlier works either modify predefined pattern templates to fit a particular body shape \cite{bartle2016physics,li2018foldsketch,yang2018physics,wang2018rule}, or flatten the surface subject to minimising surface cutting and flattening energy \cite{igarashi2005rigid,sharp2018variational,wang2003feature}.
% and to fabrication-specific distortion energy \cite{pietroni2022computational}.  
To avoid such heuristics and rigid assumptions, recently learning based methods have emerged~\cite{korosteleva2022neuraltailor}, leveraging annotated data samples~\cite{korosteleva2021generating}.
%
% The key idea is to regress hand-crafted edge features (\eg, edge vector and curvature coordinates) and xxx. 
The key idea in learning-based methods is to represent the garment shape as the garment sewing pattern (a set of panels) and predict each panel by regressing their hand-crafted edge features (\eg, edge vector and curvature coordinates). While being more general, such methods still lack the ability to presonalize the resulting garment. 
%
%While being a more elegant and scalable direction, their method is limited due to lacking the ability of panel personalization in fabrication.
However, personalization has increasing demand in modern retails \cite{FP} and ready-made clothes cannot  satisfy the growing needs of individual customers.
%
% they are limited to a single determinate sewing structure per garment, disregarding that a garment could be fabricated by varying sewing structures with different topologies, varying panel numbers and shapes.


In this work, we introduce a method for 
\emph{personalized} 2D pattern fabrication with sketch and language.
%In this work, we introduce a realistic problem setting-- {\bf \em personalizing 3D garment fabrication with language}.
The objective is to
infer the underlying 2D panels and their sewing structure from a 3D point cloud of a garment, following specific user-defined panel requirements (see Fig. \ref{fig:teaser}).
%
This is possible since a single garment could be fabricated by varying sewing structures with different topologies, varying panel numbers and shapes.
%
We choose language and sketches as the means of interaction
due to their simplicity and flexibility.
%
This problem is non-trivial
due to the extra need for fine-grained cross-modal alignment between language/sketch and point clouds,
along with the original 3D-to-2D mapping challenges.



To overcome these challenges, we propose 
{\bf\em PersonalTailor:} a novel method with two key components:
(1) A multi-modal panel embedding module 
that allows panel level association and information fusion across text/sketch and
point cloud;
%
(2) A binary panel mask prediction module
that decodes accurately the stitching panel masks.
In particular, personalization can be achieved 
by specifying flexible configurations of individual panel embeddings according to the user's prompt.
The first module is based on unsupervised association between  point cloud local features and semantic features of user's prompt, and attentive fusion of the associated features,
yielding a semantic multi-modal panel embedding space.
%
%
Conditioned on the point cloud global representation, 
the second module then decodes each semantic embedding into
a binary panel 2D mask respectively in a transformer decoder design.
% \saura{While the former solves the problem using a cross-modal local association module where the panel embeddings gets infused with  structural information from the point cloud. The later uses this multi-modal panel embeddings which are indexed by their respective positional embeddings and then passed as queries to a transformer decoder where the each query output embedding is characterized by position aware 2-D binary mask head. The decoder decodes the optimal panel mask combination using self-attention among the multi-modal panel embeddings and also cross-attending with the global structure from the garment point cloud.}
We further design  a StitchGraph module for 
more accurate stitch matching without exhaustive pairing.

% {\bf Attribute-Part Alignment} method.
% % for cross-modal fashion design.
% By learning a cross-modal matching module, it can accomplish diverse sewing pattern predictions according to the control signals from user prompts,
% thanks to the underlying ability of semantically aligning the panel attributes with the 3D garment geometry structure.
% To decode accurately the stitching panel masks,
% we consider the query as instance-aware kernels that
% can filter out the panel masks from point-cloud feature maps.
% Under this idea, the transformer-decoder can be naturally adopted with the benefit of position aware sewing panels by the global knowledge of other mask predictions. 
% The textual semantics in the cross-modal codebook enable the model to predict more reasonable codes for control signals
% For exploiting the panel-level stitch priors (\eg, edges in the sleeves panel never be stitched with that of the pants panel), we propose a StitchGraph module that can encode the sewing information for all panels in a unified graph for more accurate stitch matching prediction. 
% Compared to classifying whether two edges are stitched together \cite{korosteleva2022neuraltailor}, our design is more elegant and expressive.



Our {\bf contributions} are summarized as follows:
(I) We introduce the novel problem of personalizing 2D pattern fabrication from 3D point clouds. (II) We propose {\bf\em PersonalTailor}, a method with two key components: {\em multi-modal panel embedding} for enabling panel-level personalization, and {\em binary panel mask prediction} for simple yet superior fabrication. PersonalTailor supports both standard and personalized garment fabrication. Extensive experiments show the superiority of our method over the state-of-the-art alternatives in both standard and personalization settings.


% Our contributions are summarized as follows:
% (I) A novel problem of personalizing garment fabrication with 3D point cloud is introduced.
% % We for the first time propose the personalized 3D garment fabrication problem in order to facilitate personalized fashion design applications.
% %
% % using cross-modal code-book representation learning.
% (II) We propose a {\bf\em PersonalTailor} method with two key components: {\em multi-modal panel embedding} and 
% {\em panel mask prediction}.
% It supports both standard and personalized garment fabrication.
% % characterized by {\em Attribute-level Garment-Text Alignment} method characterized by cross-modal codebook learning and panel mask prediction
% % In particular, this latter can address the symmetry problem of garment fabrication by converting the regression based panel vertex prediction into position-aware panel mask prediction problem.
% %
% % (III) We encode the sew panels information into one graph structure so that GCN can be naturally leveraged for better stitch matching prediction.
% %
% (IV) Extensive experiments show the superiority of our method over the state-of-the-art 
% %sewing pattern structure reconstruction methods 
% in both standard and personalization settings.
