\section{Related Works}

\textbf{Differentiable DTW Layers}\hspace{0.3cm} Earlier approaches to learning with DTW involve for each iteration, alternating between first, computing the optimal alignment using DTW and then given the fixed alignment, optimising the underlying features input into DTW. \cite{zhouctw09, pmlr-v97-su19b, zhou12gtw} analytically solve for a linear transformation of raw observations. More recent work such as DTW-Net~\citep{cai2019dtwnet} and DP-DTW~\citep{chang2021dpdtw} instead take a single gradient step at each iteration to optimise a non-linear feature extractor. All aforementioned methods are not able to directly use path information within a downstream loss function.

\textbf{Differentiable Temporal Alignment Paths}\hspace{0.3cm}  Soft-DTW~\citep{cuturi17a} is a differentiable relaxation of the classic DTW problem, achieved by replacing the $\min$ step in the DP recursion with a differentiable \textit{soft-min}. The Soft-DTW discrepancy is the expected alignment cost under a Gibbs distribution over alignments, induced by the pairwise cost matrix $\Delta$ and smoothing parameter $\gamma>0$. Path information is encoded through the expected alignment matrix, $A^\ast_\gamma = \mathbb{E}_\gamma[A]=\nabla_{\Delta}\textbf{dtw}_\gamma(\bX, \bY)$~\citep{cuturi17a}. While $A^\ast_\gamma$ is recovered during the Soft-DTW backward pass, differentiating through $A^\ast_\gamma$, involves computing Hessian $\nabla^2_{\Delta}\textbf{dtw}_\gamma(\bX, \bY)$. \cite{leguen19dilate} proposed an efficient custom backward pass to achieve this. A loss can be specified over paths through a penalty matrix $\bOmega$, which for instance, can encode the error between the expected predicted path and ground truth. Note, at inference time, the original DTW problem (i.e., $\gamma=0$) is solved to generate predicted alignments, leaving a disconnect between the training loss and inference task.

In contrast, DecDTW deviates from the original DTW problem formulation entirely, and uses a continuous-time DTW variant adapted from GDTW~\citep{deriso2019general}. The GDTW problem computes a minimum cost, \textit{continuous} alignment path between two \textit{continuous time signals}. We will provide a detailed explanation of GDTW in Section~\ref{sec:gdtwvariational}. DecDTW allows the \textit{optimal alignment path} $\phi^\ast$ to be differentiable (w.r.t. layer inputs), as opposed to a soft approximation from Soft-DTW. As a result, the gap between training loss and inference task found in Soft-DTW is not present under DecDTW. In our experiments, we show that using DecDTW to train deep networks to reduce alignment error using ground truth path information greatly improves over Soft-DTW. Figure \ref{fig:systemfigure} compares Soft-DTW and DecDTW for learning with path information.
%Furthermore, we observe that using continuous-time alignments in and of is beneficial for real-world alignment tasks. 

% \begin{figure}[t]
% % \begin{wrapfigure}{l}{0.70\textwidth}
% \centering
% \noindent\includegraphics[width=0.83\textwidth]{figs/gdtw_example.pdf}
% \caption{Classic DTW (a) is a discrete optimisation problem which finds the minimum cost warping path through a pairwise cost matrix (b). DecDTW uses a continuous time variant of classic DTW (GDTW) (c) and finds an optimal time warp \textit{function} between two continuous time signals (d). }\label{fig:gdtwvsdtw}
% % \end{wrapfigure}
% \end{figure}

\begin{figure}[t!]
\centering
\noindent\includegraphics[width=0.99\textwidth]{figs/declarative_dtw_system.pdf}
\caption{Learning with path information. \textbf{Left:} Using Soft-DTW, one can define a loss between the soft, (i.e., $\gamma>0$) \textit{expected} alignment path against a penalty matrix $\bOmega$. During inference, DTW (i.e., $\gamma=0$) must be used to produce a predicted alignment. \textbf{Right:} Our DecDTW outputs the \textit{optimal} warping path $\bphi$ using GDTW at both train \textit{and inference} time, removing the disconnect present in Soft-DTW. DecDTW also allows the regularisation and constraint values to be learnable parameters.}\label{fig:systemfigure}
\end{figure}


\textbf{Deep Declarative Networks}\hspace{0.3cm} The declarative framework that allows us to incorporate differentiable optimisation algorithms into a deep network is described in~\citet{Gould:PAMI2021}. They present theoretical results and analyses on how to differentiate constrained optimization problems via implicit differentiation. Differentiable convex problems have also been studied recently, including quadratic programs~\citep{amos2017optnet} and cone programs~\citep{cvxpylayers2019a, diffcp2019b}. This technique has been applied to various application domains including optimisation-based control~\citep{amos2018differentiable}, video classification~\citep{fernando16rankpool, Fernando2017ijcv}, action recognition~\citep{Cherian2017}, visual attribute ranking~\citep{Cruz18}, few-shot learning for visual recognition~\citep{Lee_2019_CVPR}, and camera pose estimation~\citep{campbell2020solving, Chen_2020_CVPR}. To the best of our knowledge, this is the first embedding of an inequality constrained NLP within a declarative layer.
