\section{Experiments}\label{sec:experiments}

Our experiments involve two distinct application areas and utilise real-world datasets. For both applications, the goal is to use learning to improve the accuracy of predicted temporal alignments using a training set of labelled ground truth alignments. We will show that DecDTW yields state-of-the-art performance on these tasks. We have implemented DecDTW in PyTorch~\citep{torch} with open source code available to reproduce all experiments at \href{https://github.com/mingu6/declarativedtw.git}{https://github.com/mingu6/declarativedtw.git}.

\subsection{Learning Features for Audio-to-Score Alignment}\label{ssec:audioexper}

% \paragraph{Problem Formulation} 

\textbf{Problem Formulation}\hspace{0.3cm} Our first experiment relates to audio-to-score alignment, which is a fundamental problem in music information retrieval~\citep{thickstun2020rethinking, ewert09align, orio01alignmusic, shwartz04align}, with applications ranging from score following to music transcription~\citep{thickstun2020rethinking}. The goal of this task is to align an audio recording of a music performance to its corresponding musical score/sheet music. We use the mathematical formulation proposed in~\cite{thickstun2020rethinking} for evaluating predicted audio-to-score alignments against a ground truth alignment, which we will now summarise. An alignment is a monotonic function $\phi:[0, S) \rightarrow [0, T)$ which maps positions in a score (measured in beats) to a corresponding position in the performance recording (measured in seconds). Two evaluation metrics between a predicted alignment $\phi$ and a ground truth alignment $\phi^\text{gt}$ are proposed, namely the temporal average error ($\timerr$) and temporal standard deviation ($\timedev$), given formally by
\begin{equation}\label{eq:audioeval}
    \timerr(\phi, \phi^\text{gt}) = \frac{1}{S} \! \int_0^S \!\! | \phi(s) - \phi^\text{gt}(s) | \text{d}s, \quad \timedev(\phi, \phi^\text{gt}) = \sqrt{\frac{1}{S} \! \int_0^S \!\! ( \phi(s) - \phi^\text{gt}(s) )^2 \text{d}s}.
\end{equation}
\cite{thickstun2020rethinking} assumes alignments are piecewise linear in between changepoints (where the set of notes being played changes) within the score, allowing Equation~\ref{eq:audioeval} to be analytically tractable.

% \paragraph{Methodology} 
\textbf{Methodology}\hspace{0.3cm} \cite{thickstun2020rethinking} provide a method for generating candidate alignments between a performance recording and a musical score as follows: First, synthesize the musical score (using a MIDI file) to an audio recording. Second, extract audio features from the raw audio for both the synthesised score and performance. Third, use DTW to align the two sets of features. Last, use Equation~\ref{eq:audioeval} to evaluate the predicted alignment. In these experiments, we learn a feature extractor on top of the base audio features with the goal of improving the alignment accuracy from DTW.


% \paragraph{Experimental Setup}

\textbf{Experimental Setup}\hspace{0.3cm} We use the dataset in~\cite{thickstun2020rethinking}, which is comprised of 193 piano performances of 64 scores with ground truth alignments taken from a subset of the MAESTRO~\citep{hawthorne2018enabling} and Kernscores~\citep{sapp01kernscores} datasets. We extract three types of base frequency-domain features from the raw audio; constant-Q transform (CQT), (log-)chromagram (chroma) and (log-)mel spectrogram (melspec). The CQT and chroma features are already highly optimised for pitch compared to melspec features. However, melspec features retain more information from the raw audio compared to CQT and chroma. We evaluated six different methods, described as follows: \emph{1-2)} use base features (no learning) and both DTW (D) and GDTW (G) for alignments. For the remaining methods (3-6), each learns a feature extractor given by a Gated Recurrent Unit (GRU)~\citep{cho14gru}, on top of the base features. The learned features are then used to compute the corresponding loss, described as follows: \emph{3)} Soft-DTW~\citep{cuturi17a} discrepancy loss; \emph{4)} feature matching cost along ground truth alignment path (Along GT); \emph{5)} DILATE~\cite{leguen19dilate}, which uses path information through the soft expected alignment under Soft-DTW; and \emph{6)} $\timerr$ loss training (DecDTW only). For DILATE, we encode the deviation from the ground truth alignment in the path penalty matrix $\bOmega$. The full set of hyperparameters, including dataset generation and further information on comparison methods are provided in the Appendix.

\begin{table}[h]
\centering
\caption{Summary of results for the audio-to-score alignment experiments}
\begin{tabular}{l|cccccc} 
\toprule
\multicolumn{7}{c}{Reported metrics are TimeErr / TimeDev (ms)}                                       \\ 
\hline
Feature Type & Base (D) & Base (G) & Soft-DTW  & Along GT & DILATE   & DecDTW                     \\ 
\hline
CQT          & 35 / 90    & 19 / 30     & 49 / 130 & 49 / 130 & 29 / 45  & \textbf{17} / \textbf{27}  \\
Chroma       & 50 / 115   & 24 / 39     & 59 / 142 & 59 / 142 & 28 / 41  & \textbf{19} / \textbf{31}  \\
Melspec      & 122 / 235  & 56 / 81     & 55 / 153 & 52 / 145 & 26 / 40 & \textbf{16} / \textbf{27}  \\
\hline
\end{tabular}\label{tab:audiosummary}
\end{table}

\textbf{Results}\hspace{0.3cm} A summary of results is presented in Table~\ref{tab:audiosummary}. DTW is used for alignments in Base (D), Soft-DTW, Along GT and DILATE, while GDTW is used for alignments for Base (G) and DecDTW. Training using Soft-DTW fails to improve alignment performance over the validation set, measured by $\timerr$, because the ground truth alignment is not used during training\footnote{The randomly initialised GRU feature extractor also degrades alignment accuracy compared to base features.}. Similarly, minimising the feature matching cost along the ground truth alignment path fails to improve alignment accuracy, since the predicted alignment is not used during training. DILATE, however, significantly improves on Base (D) since it incorporates predicted and ground truth path information during training.

% \begin{wrapfigure}{r}{0.6\textwidth}
\begin{figure}[t]
\begin{subfigure}{0.49\textwidth}
\centering
% \noindent\includegraphics[width=0.98\textwidth]{figs/audio_main.pdf}
\noindent\includegraphics[width=0.98\textwidth]{figs/audio_main.pdf}
\subcaption{}
\label{fig:qualaudio}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
\noindent\includegraphics[width=0.98\textwidth]{figs/vpr_main.pdf}
\subcaption{}
\label{fig:qualvpr}
\end{subfigure}
\caption{\textbf{(a)} Example audio-to-score alignment. Red (resp. yellow) identifies notes indicated by audio feature (resp. ground truth) alignments, but not by the ground truth (resp. audio features). DecDTW training yields dramatic improvements for melspec features, even surpassing highly optimised CQT features (38ms $\timerr$). \textbf{(b)} Example VPR alignment. Query images are aligned to a database sequence using learned image embeddings. Magenta (resp. green) illustrates where the pre-trained (resp. fine-tuned) system estimates the query poses using database geotags. The max (resp. mean) error is reduced from 7.8m to 2.7m (resp. 4.6m to 1.5m) after fine-tuning.}\label{fig:qualmain}
\end{figure}
% \end{wrapfigure}

Similarly to DILATE, training using the $\timerr$ loss with DecDTW significantly improves the alignment accuracy compared to Base (G), effectively utilising both predicted and ground truth path information. DecDTW yields state-of-the-art results overall for all base feature types by a large margin. Note the already the strong performance of Base (G) over both Base (D) and even DILATE (for CQT and chroma); this demonstrates the benefit of using continuous time GDTW alignments. Finally, it is interesting to note that both DILATE and DecDTW are able to utilise the more expressive (versus CQT and chroma) melspec features to surpass the performance of base CQT and chroma. Figure~\ref{fig:qualaudio} illustrates an example test alignment, with more examples provided in the Appendix. 


\subsection{Transfer Learning for Sequence-based Visual Place Recognition}\label{ssec:vprexper}

Our second experiment relates to the Visual Place Recognition (VPR) problem, which is an active area of research in computer vision~\citep{berton2022deep,arandjelovic2016netvlad} and robotics~\citep{garg2021your,lowry2015visual,cummins2011appearance} and is often an important component of the navigation systems found in mobile robots and autonomous cars. The VPR task involves recognising the approximate geographic location where an image is captured, typically to a tolerance of a few meters~\citep{zaffar2021vpr,berton2022deep}  and is commonly formulated as image retrieval, where a query image is compared to a database of geo-tagged reference images. VPR using image sequences has been shown to improve retrieval performance over single image methods~\citep{garg2021seqnet, xu2020probabilistic, stenborg2020using}. In this experiment we first formulate sequence-based VPR as a temporal alignment problem and then fine-tune a deep feature extractor for this alignment task. 

\textbf{Problem formulation}\hspace{0.3cm} Let $\{I_i^r\}_{i=1}^N$, $\bt^r\in\bbR^N$ and $\{\bx_i^r\}_{i=1}^N$ be a reference image sequence, associated (sorted) timestamps and geotags, respectively. Similarly, let $\{I_i^q\}_{i=1}^M$, $\bt^q\in\bbR^M$ and $\bX^q = \{\bx_i^q\}_{i=1}^N$ be the equivalent for a query sequence, noting that query geotags are used only for training and evaluation. Furthermore, when using deep networks for VPR, we have a feature extractor $f_\theta$ with weights $\theta$ that is used to extract embeddings $\bZ^r = \{f_\theta(I_i^r)\}_{i=1}^N \in \bbR^{N\times d}$ and $\bZ^q = \{f_\theta(I_i^q)\}_{i=1}^M \in \bbR^{M\times d}$ from reference and query images, respectively. Finally, let $\bx^r$, $\bx^q$, $\bz^r$, $\bz^q$ be continuous time signals built from geotags and image embeddings using associated timestamps.

We can formulate sequence-based VPR as a temporal alignment problem, where the objective is to minimise the discrepancy between the predicted alignment derived from the query and reference image embeddings and the optimal alignment derived from the geotags. Concretely, the goal of our learning problem is to minimise w.r.t.~network weights $\theta$, a measure of localisation error $G(\bx^r(\bphi), \bX^q)$, where $\bphi = \text{DTW}(\bz^r, \bz^q; \theta)$ defined as $\phi_i = \phi(t_i^q)$ is the estimated alignment which maps query images to positions in the reference sequence and $\bx^r(\bphi) = \{\bx^r(\phi_i)\}_{i=1}^M$. We select $G$ as the (squared) maximum error over the queries, given by $G(\bX^1, \bX^2) = \max\{\|\bx_i^1 - \bx_i^2\|_2^2: i=1,\dots,M\}$.

\textbf{Experimental setup}\hspace{0.3cm} We source images and geotags from the Oxford RobotCar dataset~\citep{maddern20171}, commonly used as a benchmark to evaluate VPR methods. This dataset is comprised of autonomous vehicle traverses of the same route captured over two years across varying times of day and environmental conditions. We use a subset of $\thicksim$1M images captured across 50+ traverses provided by~\cite{thoma20soft} with geotags taken from RTK GPS~\citep{maddern2020real} where available, accurate to 15cm. These images are split into training, validation and test sets, which are used to train a base network for single image retrieval as well as our sequence-based methods. The train and validation sets are captured in the same geographic areas on distinct dates whereas the test set is captured in an area geographically disjoint from validation and training. %Query/reference pairs can exhibit large levels of appearance change between them in all splits.

Paired sequences are generated using the GPS ground truth; reference sequences have 25 images spaced $\thicksim$5m apart and query sequences have 10 images sampled at $\thicksim$1Hz. This setup is close to a deployment scenario where geotags are available for the reference images and query images exhibit large changes in velocity compared to the reference. Subsequence GDTW is used to align queries to the reference sequence. In total, we use $\thicksim$22k, $\thicksim$4k, $\thicksim$1.7k sequence pairs for training, validation and testing, respectively. Our test set contains a diverse set of sequences over a large geographic area, and exhibits lighting, seasonal and structural change between reference and query. We provide our paired sequence dataset in the supplementary material. Finally, for feature extraction, we use a VGG backbone with NetVLAD aggregation layer~\citep{arandjelovic2016netvlad} (yields 32k-dim embeddings) and train the single image network using triplet margin loss. We fine-tune the conv5 and NetVLAD layers for sequence training. See the Appendix for a detailed description of the training setup.

\textbf{Results}\hspace{0.3cm} We evaluate all methods by measuring the proportion of test sequences where the maximum error is below predefined distance thresholds; these metrics are commonly used for single image methods~\citep{garg2021your, berton2022deep}. Results are split into three different environmental conditions including overcast, sunny and snow. We present results for two methods using the base single image network (1-2) and four methods which perform fine-tuning of the base network for sequence VPR (3-6): \emph{1-2)} Base features (no sequence fine-tuning) with DTW (D) and GDTW (G) alignment, \emph{3)} OTAM~\cite{Cao_2020_CVPR} (Soft-DTW w/subsequence alignment) discrepancy, \emph{4)} Feature cost along the ATE minimising alignment (Along GT), \emph{5)} DILATE loss and \emph{6)} max error loss (DecDTW). Similar to the audio experiments, DTW was used to produce alignments for methods (3-5) and GDTW was used for (6). For DILATE, we again modified the path penalty matrix $\bOmega$ to encode the deviation from the ground truth path.  Table~\ref{tab:vprsummary} summarises the results.

\begin{table}[h]
\centering
\caption{VPR experiment results (maximum error): Test Accuracy @2/3/5/10m}
\label{tab:vprsummary}
\begin{tabular}{lccc} 
\toprule
Method        & Overcast                                       & Sunny                                          & Snow                                             \\ 
\midrule
Base (D)      & 0.7/12.3/44.3/73.8                             & 0.5/8.7/40.2/62.2                              & 1.6/11.1/44.3/62.3                               \\
Base (G)      & 10.2/31.7/65.6/\textbf{\textbf{90.3}}          & 9.0/33.2/75.1/\textbf{\textbf{99.3}}           & 6.2/25.7/73.2/\textbf{\textbf{100.0}}            \\
OTAM/Along GT & 0.7/12.3/44.3/73.8                             & 0.5/8.7/40.2/62.2                              & 1.6/11.1/44.3/62.3                               \\
DILATE        & 0.7/14.5/54.5/80.0                             & 1.5/11.9/40.9/69.7                             & 1.3/12.2/44.6/68.7                                        \\
DecDTW        & \textbf{25.4}/\textbf{45.0}/\textbf{68.3}/90.1 & \textbf{22.8}/\textbf{50.4}/\textbf{84.3}/98.3 & \textbf{13.5}/\textbf{44.8}/\textbf{88.0}/\textbf{100.0}  \\
\bottomrule
\end{tabular}
\end{table}

We found that fine-tuning with the OTAM and Along GT losses is not able to reduce localisation error over the validation set compared to using base features. This is because the OTAM loss does not use GPS ground truth and the Along GT loss does not use the predicted alignment. DILATE, which utilises path information, improves over Base (D), especially for the 5-10m error tolerances. However, training with DecDTW to directly reduce the maximum GPS error between predicted and ground truth yields \textit{significant} improvements compared to Base (G) across tighter ($\leq 5$m) error tolerances. Similar to the audio experiments, we see the benefit of using GDTW alignments over DTW when comparing Base (G) to Base (D) and DILATE. However, DecDTW improves over Base (G) substantially more compared to DILATE over Base (D) when compared to the audio experiments. We provide more results and analysis for the VPR task in the Appendix. Figure~\ref{fig:qualvpr} illustrates an example of a test sequence before and after fine-tuning, with more examples provided in the Appendix.

\subsection{Scalability}

\begin{wrapfigure}{r}{0.32\textwidth}
\centering
\noindent\includegraphics[width=0.32\textwidth]{figs/scalability_inference.pdf}
\caption{Test time scalability}\label{fig:scaletest}
\vspace{-0.7cm}
\end{wrapfigure}
%The added compute time of DecDTW is attributed to the fine-grained warp estimation in the forward pass.

Figure~\ref{fig:scaletest} illustrates how inference at test time scales with time series length $n$ for GDTW (required for DecDTW) compared to DTW. Timings are evaluated on an Nvidia GeForce GTX 1080Ti 11Gb. GDTW is between 15-50 times slower than DTW, with the gap increasing with length $n$. The additional computation is due in large part to the additional discretisation required to solve for the finer-grained continuous time problem defined in Section~\ref{sec:dtwnlp}. DTW solves a DP with $O(mn)$ nodes and $O(mn)$ edges, whereas GDTW solves a DP with $O(mM)$ edges and $O(mM^2)$ edges (we set $M=n$). However, by removing iterations of warp refinement, we can reduce this gap to a 4-12x slowdown with an mean accuracy loss of only 0.5\%. Further discussion and a comparison of train-time scalability is provided in the Appendix.

