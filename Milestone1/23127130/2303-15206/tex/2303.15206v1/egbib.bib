
@misc{Authors14,
 author = {Full Author Name},
 title = {The Frobnicatable Foo Filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@article{diff_sdf,
    title   = {Differentiable Signed Distance Function Rendering},
    author  = {Delio Vicini and Sébastien Speierer and Wenzel Jakob},
    year    = 2022,
    month   = jul,
    journal = {Transactions on Graphics (Proceedings of SIGGRAPH)},
    volume  = 41,
    number  = 4,
    pages   = {125:1--125:18},
    doi     = {10.1145/3528223.3530139}
}

@article{idr,
title={Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance},
author={Yariv, Lior and Kasten, Yoni and Moran, Dror and Galun, Meirav and Atzmon, Matan and Ronen, Basri and Lipman, Yaron},
journal={Advances in Neural Information Processing Systems},
volume={33},
year={2020}
}

@misc{Authors14b,
 author = {Full Author Name},
 title = {Frobnication Tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {Alvin Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe},
title = {Frobnication Revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}
@inproceedings{wang2003msssim,
  author={Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
  booktitle={The Thrity-Seventh Asilomar Conference on Signals, Systems   Computers, 2003},
  title={Multiscale structural similarity for image quality assessment},
  year={2003},
  volume={2},
  number={},
  pages={1398-1402 Vol.2},
  doi={10.1109/ACSSC.2003.1292216}
}
@article{wang2004ssim,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  doi={10.1109/TIP.2003.819861}
}
@inproceedings{mipnerf360,
  title={Mip-nerf 360: Unbounded anti-aliased neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Verbin, Dor and Srinivasan, Pratul P and Hedman, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5470--5479},
  year={2022}
}
@inproceedings{chen1993view,
  title={View interpolation for image synthesis},
  author={Chen, Shenchang Eric and Williams, Lance},
  booktitle={Proceedings of the 20th annual conference on Computer graphics and interactive techniques},
  pages={279--288},
  year={1993}
}
@inproceedings{shade1998layered,
  title={Layered depth images},
  author={Shade, Jonathan and Gortler, Steven and He, Li-wei and Szeliski, Richard},
  booktitle={Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
  pages={231--242},
  year={1998}
}
@inproceedings{shum2000review,
  title={Review of image-based rendering techniques},
  author={Shum, Harry and Kang, Sing Bing},
  booktitle={Visual Communications and Image Processing 2000},
  volume={4067},
  pages={2--13},
  year={2000},
  organization={SPIE}
}
@inproceedings{suhail2022generalizable,
  title={Generalizable patch-based neural rendering},
  author={Suhail, Mohammed and Esteves, Carlos and Sigal, Leonid and Makadia, Ameesh},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXII},
  pages={156--174},
  year={2022},
  organization={Springer}
}
@article{brisque,
  author={Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan Conrad},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Image Quality Assessment in the Spatial Domain}, 
  year={2012},
  volume={21},
  number={12},
  pages={4695-4708},
  doi={10.1109/TIP.2012.2214050}
}
@article{niqe,
  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C.},
  journal={IEEE Signal Processing Letters}, 
  title={Making a “Completely Blind” Image Quality Analyzer}, 
  year={2013},
  volume={20},
  number={3},
  pages={209-212},
  doi={10.1109/LSP.2012.2227726}
}
@book{Mooney1993,
author = {Mooney, Christopher Z. and {Robert D. Duval}},
isbn = {9780803953819},
mendeley-groups = {Books},
publisher = {Sage},
title = {{Bootstrapping: A Nonparametric Approach to Statistical Inference}},
year = {1993}
}

@article{Olkin1958unbiased,
author = {Ingram Olkin and John W. Pratt},
title = {{Unbiased Estimation of Certain Correlation Coefficients}},
volume = {29},
journal = {The Annals of Mathematical Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {201 -- 211},
year = {1958},
doi = {10.1214/aoms/1177706717},
URL = {https://doi.org/10.1214/aoms/1177706717}
}


@inproceedings{hanji2022comparison,
  title={Comparison of single image HDR reconstruction methods --- the caveats of quality assessment},
  author={Hanji, Param and Mantiuk, Rafal and Eilertsen, Gabriel and Hajisharif, Saghi and Unger, Jonas},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--8},
  year={2022}
}

@article{berardino2017eigen,
  title={Eigen-distortions of hierarchical representations},
  author={Berardino, Alexander and Laparra, Valero and Ball{\'e}, Johannes and Simoncelli, Eero},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{Ponomarenko2015,
author = {Ponomarenko, Nikolay and Jin, Lina and Ieremeiev, Oleg and Lukin, Vladimir and Egiazarian, Karen and Astola, Jaakko and Vozel, Benoit and Chehdi, Kacem and Carli, Marco and Battisti, Federica and {Jay Kuo}, C.-C.},
doi = {10.1016/j.image.2014.10.009},
issn = {09235965},
journal = {Signal Processing: Image Communication},
mendeley-groups = {Subjective quality},
month = {jan},
pages = {57--77},
title = {{Image database TID2013: Peculiarities, results and perspectives}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0923596514001490},
volume = {30},
year = {2015}
}

@article{dists,
  title={Image quality assessment: Unifying structure and texture similarity},
  author={Ding, Keyan and Ma, Kede and Wang, Shiqi and Simoncelli, Eero P},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={5},
  pages={2567--2581},
  year={2020},
  publisher={IEEE}
}
@article{piqe,
  author={{Venkatanath N} and Praneeth D and Maruthi Chandrasekhar Bh and Channappayya, Sumohana S. and Medasani, Swarup S.},
  booktitle={2015 Twenty First National Conference on Communications (NCC)}, 
  title={Blind image quality evaluation using perception based features}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/NCC.2015.7084843}
}
@article{Mantiuk2011,
  title={{HDR-VDP-2}: A calibrated visual metric for visibility and quality predictions in all luminance conditions},
  author={Mantiuk, Rafa{\l} and Kim, Kil Joong and Rempel, Allan G and Heidrich, Wolfgang},
  journal={ACM Transactions on graphics (TOG)},
  volume={30},
  number={4},
  pages={1--14},
  year={2011},
  publisher={ACM New York, NY, USA}
}


@article{sheikh2006vif,
  author={Sheikh, H.R. and Bovik, A.C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image information and visual quality}, 
  year={2006},
  volume={15},
  number={2},
  pages={430-444},
  doi={10.1109/TIP.2005.859378}
}

@article{unbiased,
  title={Unbiased estimation of certain correlation coefficients},
  author={Olkin, Ingram and Pratt, John W},
  journal={The annals of mathematical statistics},
  pages={201--211},
  year={1958},
  publisher={JSTOR}
}

@article{Alpher04,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe and Gavin Gamow},
title = {Can a Machine Frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

@inproceedings{original_nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year={2020},
  booktitle={ECCV},
}

@article{ngp,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Trans. Graph.},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    url = {https://doi.org/10.1145/3528223.3530127},
    doi = {10.1145/3528223.3530127},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@article{FastNeRF,
	Archiveprefix = {arXiv},
	Author = {Stephan J. Garbin and Marek Kowalski and Matthew Johnson and Jamie Shotton and Julien Valentin},
	Journal = {https://arxiv.org/abs/2103.10380},
	Title = {FastNeRF: High-Fidelity Neural Rendering at 200FPS},
	Year = {2021}
}
@article{simoncelli1996foundations,
  title={Foundations of vision},
  author={Simoncelli, E},
  year={1996}
}
@article{eyediagram,
  title={Labeled eye diagram},
  author={Mikrora.},
  journal={https://www.mikrora.com/
labeled-eye-diagram/},
  year={Jun 2019},
}
@article{Colorblindness,
  title={Color blindness simulation research},
  author={Jim Schmitz.},
  journal={https://ixora.io/
projects/colorblindness/color-blindness-simulation-research/},
  year={Aug 2016},
}
@article{lofgrenlaser,
  title={Laser pointers and Eye injuries},
  author={L{\"o}fgren, Stefan and Thaung, J{\"o}rgen and Lopes, Cesar},
  journal={An analysis of reported cases. Swedish Radiation Safety Authority. Report},
  number={2013},
  pages={30}
}
@article{livingstone1988segregation,
  title={Segregation of form, color, movement, and depth: anatomy, physiology, and perception},
  author={Livingstone, Margaret and Hubel, David},
  journal={Science},
  volume={240},
  number={4853},
  pages={740--749},
  year={1988},
  publisher={American Association for the Advancement of Science}
}

@article{watson2013high,
  title={High frame rates and human vision: A view through the window of visibility},
  author={Watson, Andrew B},
  journal={SMPTE Motion Imaging Journal},
  volume={122},
  number={2},
  pages={18--32},
  year={2013},
  publisher={SMPTE}
}

@article{mobilenerf,
  title={MobileNeRF: Exploiting the Polygon Rasterization Pipeline
	for Efficient Neural Field Rendering on Mobile Architectures},
  author={Zhiqin Chen and Thomas Funkhouser
	and Peter Hedman and Andrea Tagliasacchi},
  journal={arXiv preprint arXiv:2208.00277},
  year={2022}
}

@article{llff,
  title={Local light field fusion: Practical view synthesis with prescriptive sampling guidelines},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Ortiz-Cayon, Rodrigo and Kalantari, Nima Khademi and Ramamoorthi, Ravi and Ng, Ren and Kar, Abhishek},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={4},
  pages={1--14},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@inproceedings{deepview,
  title={Deepview: View synthesis with learned gradient descent},
  author={Flynn, John and Broxton, Michael and Debevec, Paul and DuVall, Matthew and Fyffe, Graham and Overbeck, Ryan and Snavely, Noah and Tucker, Richard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2367--2376},
  year={2019}
}
 
@article{snerg,
    title={Baking Neural Radiance Fields for
           Real-Time View Synthesis},
    author={Peter Hedman and Pratul P. Srinivasan and
            Ben Mildenhall and Jonathan T. Barron and
            Paul Debevec},
    journal={ICCV},
    year={2021}
}

@inproceedings{plenoctrees,
      title={{PlenOctrees} for Real-time Rendering of Neural Radiance Fields},
      author={Alex Yu and Ruilong Li and Matthew Tancik and Hao Li and Ren Ng and Angjoo Kanazawa},
      year={2021},
      booktitle={ICCV},
}

@article{derf,
  author    = {Daniel Rebain and
               Wei Jiang and
               Soroosh Yazdani and
               Ke Li and
               Kwang Moo Yi and
               Andrea Tagliasacchi},
  title     = {DeRF: Decomposed Radiance Fields},
  journal   = {CoRR},
  volume    = {abs/2011.12490},
  year      = {2020},
  url       = {https://arxiv.org/abs/2011.12490},
  eprinttype = {arXiv},
  eprint    = {2011.12490},
  timestamp = {Tue, 01 Dec 2020 14:59:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-12490.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{diver,
      title={DIVeR: Real-time and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering}, 
      author={Liwen Wu and Jae Yong Lee and Anand Bhattad and Yuxiong Wang and David Forsyth},
      year={2021},
      eprint={2111.10427},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{neusample,
    title={NeuSample: Neural Sample Field for Efficient View Synthesis},
    author={Jiemin Fang and Lingxi Xie and Xinggang Wang and Xiaopeng Zhang and Wenyu Liu and Qi Tian},
    journal={arXiv:2111.15552},
    year={2021}
}

@inproceedings{autoint,
  title={AutoInt: Automatic Integration for Fast Neural Volume Rendering},
  author={Lindell, D. B.* and Martel, J. N. P.* and Wetzstein, G.},
  booktitle={Proc. CVPR},
  year={2021},
}

@inproceedings{olson2011apriltag,
  title={AprilTag: A robust and flexible visual fiducial system},
  author={Olson, Edwin},
  booktitle={2011 IEEE international conference on robotics and automation},
  pages={3400--3407},
  year={2011},
  organization={IEEE}
}

@inproceedings{hanji2020noise,
  title={Noise-aware merging of high dynamic range image stacks without camera calibration},
  author={Hanji, Param and Zhong, Fangcheng and Mantiuk, Rafa{\l} K},
  booktitle={European Conference on Computer Vision},
  pages={376--391},
  year={2020},
  organization={Springer}
}

@article{zhang2000flexible,
  title={A flexible new technique for camera calibration},
  author={Zhang, Zhengyou},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={22},
  number={11},
  pages={1330--1334},
  year={2000},
  publisher={IEEE}
}

@article {donerf,
  journal = {Computer Graphics Forum},
  title = {{DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks}},
  author = {Neff, Thomas and Stadlbauer, Pascal and Parger, Mathias and Kurz, Andreas and Mueller, Joerg H. and Chaitanya, Chakravarty R. Alla and Kaplanyan, Anton S. and Steinberger, Markus},
  year = {2021},
  publisher = {The Eurographics Association and John Wiley \& Sons Ltd.},
  ISSN = {1467-8659},
  DOI = {10.1111/cgf.14340},
  url = {https://doi.org/10.1111/cgf.14340},
  volume = {40},
  number = {4},
}


@inproceedings{Barron+2021,
  author    = {Jonathan T. Barron and
               Ben Mildenhall and
               Matthew Tancik and
               Peter Hedman and
               Ricardo Martin{-}Brualla and
               Pratul P. Srinivasan},
  title     = {Mip-NeRF: {A} Multiscale Representation for Anti-Aliasing Neural Radiance
               Fields},
  booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2021, Montreal, QC, Canada, October 10-17, 2021},
  pages     = {5835--5844},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.00580},
  doi       = {10.1109/ICCV48922.2021.00580},
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{Barron+2021b,
  author    = {Jonathan T. Barron and
               Ben Mildenhall and
               Dor Verbin and
               Pratul P. Srinivasan and
               Peter Hedman},
  title     = {Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
  journal   = {CoRR},
  volume    = {abs/2111.12077},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.12077},
  eprinttype = {arXiv},
  eprint    = {2111.12077},
}



@inproceedings{Reiser+2021,
  author    = {Christian Reiser and
               Songyou Peng and
               Yiyi Liao and
               Andreas Geiger},
  title     = {KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny
               MLPs},
  booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2021, Montreal, QC, Canada, October 10-17, 2021},
  pages     = {14315--14325},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.01407},
  doi       = {10.1109/ICCV48922.2021.01407},
  timestamp = {Fri, 11 Mar 2022 10:01:59 +0100},
  biburl    = {https://dblp.org/rec/conf/iccv/ReiserPL021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{DLM,
  author={Li, Songnan and Zhang, Fan and Ma, Lin and Ngan, King Ngi},
  journal={IEEE Transactions on Multimedia}, 
  title={Image Quality Assessment by Separately Evaluating Detail Losses and Additive Impairments}, 
  year={2011},
  volume={13},
  number={5},
  pages={935-949},
  doi={10.1109/TMM.2011.2152382}}

@ARTICLE{VIF,
  author={Sheikh, H.R. and Bovik, A.C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image information and visual quality}, 
  year={2006},
  volume={15},
  number={2},
  pages={430-444},
  doi={10.1109/TIP.2005.859378}}

@article{gnt,
  title={Is Attention All NeRF Needs?},
  author={Wang, Peihao and Chen, Xuxi and Chen, Tianlong and Venugopalan, Subhashini and Wang, Zhangyang and others},
  journal={arXiv preprint arXiv:2207.13298},
  year={2022}
}
@misc{cuda,
  author={NVIDIA and Vingelmann, Péter and Fitzek, Frank H.P.},
  title={CUDA, release: 10.2.89},
  year={2020},
  url={https://developer.nvidia.com/cuda-toolkit},
}
@inproceedings{ibrnet,
  author    = {Qianqian Wang and
               Zhicheng Wang and
               Kyle Genova and
               Pratul P. Srinivasan and
               Howard Zhou and
               Jonathan T. Barron and
               Ricardo Martin{-}Brualla and
               Noah Snavely and
               Thomas A. Funkhouser},
  title     = {IBRNet: Learning Multi-View Image-Based Rendering},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2021, virtual, June 19-25, 2021},
  pages     = {4690--4699},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2021},
  url       = {https://openaccess.thecvf.com/content/CVPR2021/html/Wang\_IBRNet\_Learning\_Multi-View\_Image-Based\_Rendering\_CVPR\_2021\_paper.html},
  doi       = {10.1109/CVPR46437.2021.00466},
}
@article{Rmsprop,
  title={Rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={Coursera: Neural Networks for Machine Learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@article{transformer,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{plenoxel,
  author    = {Sara Fridovich{-}Keil and
               Alex Yu and
               Matthew Tancik and
               Qinhong Chen and
               Benjamin Recht and
               Angjoo Kanazawa},
  title     = {Plenoxels: Radiance Fields without Neural Networks},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages     = {5491--5500},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.00542},
  doi       = {10.1109/CVPR52688.2022.00542},
}

@article{Liu+2020,
  author    = {Lingjie Liu and
               Jiatao Gu and
               Kyaw Zaw Lin and
               Tat{-}Seng Chua and
               Christian Theobalt},
  title     = {Neural Sparse Voxel Fields},
  journal   = {CoRR},
  volume    = {abs/2007.11571},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.11571},
  eprinttype = {arXiv},
  eprint    = {2007.11571},
  timestamp = {Wed, 29 Jul 2020 15:36:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-11571.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article {Tewari+2020,
journal = {Computer Graphics Forum},
title = {{State of the Art on Neural Rendering}},
author = {Tewari, Ayush and Fried, Ohad and Thies, Justus and Sitzmann, Vincent and Lombardi, Stephen and Sunkavalli, Kalyan and Martin-Brualla, Ricardo and Simon, Tomas and Saragih, Jason and Nießner, Matthias and Pandey, Rohit and Fanello, Sean and Wetzstein, Gordon and Zhu, Jun-Yan and Theobalt, Christian and Agrawala, Maneesh and Shechtman, Eli and Goldman, Dan B. and Zollhöfer, Michael},
year = {2020},
publisher = {The Eurographics Association and John Wiley \& Sons Ltd.},
ISSN = {1467-8659},
DOI = {10.1111/cgf.14022}
}

@article{pwcmp,
  title={A practical guide and software for analysing pairwise comparison experiments},
  author={Perez-Ortiz, Maria and Mantiuk, Rafal K},
  journal={arXiv preprint arXiv:1712.03686},
  year={2017}
}


@article{NSVF,
  title={Neural sparse voxel fields},
  author={Liu, Lingjie and Gu, Jiatao and Zaw Lin, Kyaw and Chua, Tat-Seng and Theobalt, Christian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15651--15663},
  year={2020}
}
@inproceedings{blendedmvs,
  title={Blendedmvs: A large-scale dataset for generalized multi-view stereo networks},
  author={Yao, Yao and Luo, Zixin and Li, Shiwei and Zhang, Jingyang and Ren, Yufan and Zhou, Lei and Fang, Tian and Quan, Long},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1790--1799},
  year={2020}
}
@inproceedings{NeX,
  author    = {Suttisak Wizadwongsa and
               Pakkapon Phongthawee and
               Jiraphon Yenphraphai and
               Supasorn Suwajanakorn},
  title     = {NeX: Real-Time View Synthesis With Neural Basis Expansion},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2021, virtual, June 19-25, 2021},
  pages     = {8534--8543},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2021},
  doi       = {10.1109/CVPR46437.2021.00843},
}

@article{Tewari+2022,
  author    = {Ayush Tewari and
               Justus Thies and
               Ben Mildenhall and
               Pratul P. Srinivasan and
               Edgar Tretschk and
               Yifan Wang and
               Christoph Lassner and
               Vincent Sitzmann and
               Ricardo Martin{-}Brualla and
               Stephen Lombardi and
               Tomas Simon and
               Christian Theobalt and
               Matthias Nie{\ss}ner and
               Jonathan T. Barron and
               Gordon Wetzstein and
               Michael Zollh{\"{o}}fer and
               Vladislav Golyanik},
  title     = {Advances in Neural Rendering},
  journal   = {Comput. Graph. Forum},
  volume    = {41},
  number    = {2},
  pages     = {703--735},
  year      = {2022},
  url       = {https://doi.org/10.1111/cgf.14507},
  doi       = {10.1111/cgf.14507},
}

%other nerf
@article{Park+2021,
  author    = {Keunhong Park and
               Utkarsh Sinha and
               Peter Hedman and
               Jonathan T. Barron and
               Sofien Bouaziz and
               Dan B. Goldman and
               Ricardo Martin{-}Brualla and
               Steven M. Seitz},
  title     = {HyperNeRF: a higher-dimensional representation for topologically varying
               neural radiance fields},
  journal   = {{ACM} Trans. Graph.},
  volume    = {40},
  number    = {6},
  pages     = {238:1--238:12},
  year      = {2021},
  url       = {https://doi.org/10.1145/3478513.3480487},
  doi       = {10.1145/3478513.3480487},
}

@misc{lin2020nerfpytorch,
  title={NeRF-pytorch},
  author={Yen-Chen, Lin},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished={\url{https://github.com/yenchenlin/nerf-pytorch/}},
  year={2020}
}

@inproceedings{varma2022attention,
  title={Is Attention All That NeRF Needs?},
  author={Varma, Mukund and Wang, Peihao and Chen, Xuxi and Chen, Tianlong and Venugopalan, Subhashini and Wang, Zhangyang},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{Karnewar+2022,
      author    = {Karnewar, Animesh and Ritschel, Tobias and Wang, Oliver and Mitra, Niloy J.},
      title     = {ReLU Fields: The Little Non-linearity That Could},
      journal   = {Transactions on Graphics (Proceedings of SIGGRAPH)},
      volume    = {41},
      number    = {4},
      year      = {2022},
      month     = {july},
      pages     = {13:1--13:8},
      doi       = {10.1145/3528233.3530707},
}

@article{hypernerf,
  author = {Park, Keunhong and Sinha, Utkarsh and Hedman, Peter and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Martin-Brualla, Ricardo and Seitz, Steven M.},
  title = {HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields},
  journal = {ACM Trans. Graph.},
  issue_date = {December 2021},
  publisher = {ACM},
  volume = {40},
  number = {6},
  month = {dec},
  year = {2021},
  articleno = {238},
}

@inproceedings{lpips,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}

@InProceedings{SinNeRF,
    author = {Xu, Dejia and Jiang, Yifan and Wang, Peihao and Fan, Zhiwen and Shi, Humphrey and Wang, Zhangyang},
    title = {SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image},
    journal={arXiv preprint arXiv:2204.00928},
    year={2022}
}

@inproceedings{DietNeRF,
author = {Jain, Ajay and Tancik, Matthew and Abbeel, Pieter},
year = {2021},
month = {10},
pages = {5865-5874},
title = {Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis},
doi = {10.1109/ICCV48922.2021.00583}
}

@inproceedings{pixelnerf,
      title={{pixelNeRF}: Neural Radiance Fields from One or Few Images},
      author={Alex Yu and Vickie Ye and Matthew Tancik and Angjoo Kanazawa},
      year={2021},
      booktitle={CVPR},
}

@misc{lolnerf,
  title={LOLNeRF: Learn from One Look},
  author={Daniel Rebain and Mark Matthews and Kwang Moo Yi and Dmitry Lagun and Andrea Tagliasacchi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1558--1567},
  year={2022}
}

@inproceedings{dirctvoxgo,
  author    = {Cheng Sun and Min Sun and Hwann{-}Tzong Chen},
  title     = {Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction},
  booktitle = {{IEEE/CVF Conference on Computer Vision and Pattern Recognition,
               CVPR 2022, New Orleans, LA, USA, June 18-24, 2022}},
  pages     = {5449--5459},
  publisher = {IEEE},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.00538},
  doi       = {10.1109/CVPR52688.2022.00538},
}

@article{10.1145/964965.808594,
author = {Kajiya, James T. and Von Herzen, Brian P},
title = {Ray Tracing Volume Densities},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/964965.808594},
doi = {10.1145/964965.808594},
journal = {SIGGRAPH Comput. Graph.},
month = {jan},
pages = {165–174},
numpages = {10},
keywords = {Raster graphics, Simulation of natural phenomena, Computer graphics, Ray tracing, Radiative transport, Clouds, Stochastic modeling, Particle systems, Light scattering}
}

@inproceedings{lfnr,
  title={Light field neural rendering},
  author={Suhail, Mohammed and Esteves, Carlos and Sigal, Leonid and Makadia, Ameesh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8269--8279},
  year={2022}
}

@inproceedings{Kajiya+1984,
author = {Kajiya, James T. and Von Herzen, Brian P},
title = {Ray Tracing Volume Densities},
year = {1984},
isbn = {0897911385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800031.808594},
doi = {10.1145/800031.808594},
pages = {165–174},
numpages = {10},
keywords = {Clouds, Stochastic modeling, Raster graphics, Radiative transport, Ray tracing, Light scattering, Computer graphics, Particle systems, Simulation of natural phenomena},
series = {SIGGRAPH '84}
}

  
@article{Zhou+2018,
author = {Zhou, Tinghui and Tucker, Richard and Flynn, John and Fyffe, Graham and Snavely, Noah},
title = {Stereo Magnification: Learning View Synthesis Using Multiplane Images},
year = {2018},
issue_date = {August 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3197517.3201323},
doi = {10.1145/3197517.3201323},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {65},
numpages = {12},
keywords = {deep learning, view extrapolation}
}

  


@inproceedings{mipnerf,
  author    = {Jonathan T. Barron and
               Ben Mildenhall and
               Dor Verbin and
               Pratul P. Srinivasan and
               Peter Hedman},
  title     = {Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages     = {5460--5469},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.00539},
  doi       = {10.1109/CVPR52688.2022.00539},
}


@article{judder,
author = {Chapiro, Alexandre and Atkins, Robin and Daly, Scott},
title = {A Luminance-Aware Model of Judder Perception},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {5},
issn = {0730-0301},
url = {https://doi.org/10.1145/3338696},
doi = {10.1145/3338696},
abstract = {The perceived discrepancy between continuous motion as seen in nature and frame-by-frame exhibition on a display, sometimes termed judder, is an integral part of video presentation. Over time, content creators have developed a set of rules and guidelines for maintaining a desirable cinematic look under the restrictions placed by display technology without incurring prohibitive judder. With the advent of novel displays capable of high brightness, contrast, and frame rates, these guidelines are no longer sufficient to present audiences with a uniform viewing experience. In this work, we analyze the main factors for perceptual motion artifacts in digital presentation and gather psychophysical data to generate a model of judder perception. Our model enables applications like matching perceived motion artifacts to a traditionally desirable level and maintain a cinematic motion look.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {142},
numpages = {10},
keywords = {speed perception, contrast, high dynamic range, brightness, display technologies, motion perception, judder, Frame rate}
}

@article{deepfovea,
author = {Kaplanyan, Anton S. and Sochenov, Anton and Leimk\"{u}hler, Thomas and Okunev, Mikhail and Goodall, Todd and Rufo, Gizem},
title = {DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression Using Learned Statistics of Natural Videos},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356557},
doi = {10.1145/3355089.3356557},
abstract = {In order to provide an immersive visual experience, modern displays require head mounting, high image resolution, low latency, as well as high refresh rate. This poses a challenging computational problem. On the other hand, the human visual system can consume only a tiny fraction of this video stream due to the drastic acuity loss in the peripheral vision. Foveated rendering and compression can save computations by reducing the image quality in the peripheral vision. However, this can cause noticeable artifacts in the periphery, or, if done conservatively, would provide only modest savings. In this work, we explore a novel foveated reconstruction method that employs the recent advances in generative adversarial neural networks. We reconstruct a plausible peripheral video from a small fraction of pixels provided every frame. The reconstruction is done by finding the closest matching video to this sparse input stream of pixels on the learned manifold of natural videos. Our method is more efficient than the state-of-the-art foveated rendering, while providing the visual experience with no noticeable quality degradation. We conducted a user study to validate our reconstruction method and compare it against existing foveated rendering and video compression techniques. Our method is fast enough to drive gaze-contingent head-mounted displays in real time on modern hardware. We plan to publish the trained network to establish a new quality bar for foveated rendering and compression as well as encourage follow-up research.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {212},
numpages = {13},
keywords = {virtual reality, video generation, generative networks, video compression, foveated rendering, deep learning, gaze-contingent rendering, perceptual rendering}
}

@article{fvvdp,
author = {Mantiuk, Rafa\l{} K. and Denes, Gyorgy and Chapiro, Alexandre and Kaplanyan, Anton and Rufo, Gizem and Bachy, Romain and Lian, Trisha and Patney, Anjul},
title = {FovVideoVDP: A Visible Difference Predictor for Wide Field-of-View Video},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459831},
doi = {10.1145/3450626.3459831},
abstract = {FovVideoVDP is a video difference metric that models the spatial, temporal, and peripheral aspects of perception. While many other metrics are available, our work provides the first practical treatment of these three central aspects of vision simultaneously. The complex interplay between spatial and temporal sensitivity across retinal locations is especially important for displays that cover a large field-of-view, such as Virtual and Augmented Reality displays, and associated methods, such as foveated rendering. Our metric is derived from psychophysical studies of the early visual system, which model spatio-temporal contrast sensitivity, cortical magnification and contrast masking. It accounts for physical specification of the display (luminance, size, resolution) and viewing distance. To validate the metric, we collected a novel foveated rendering dataset which captures quality degradation due to sampling and reconstruction. To demonstrate our algorithm's generality, we test it on 3 independent foveated video datasets, and on a large image quality dataset, achieving the best performance across all datasets when compared to the state-of-the-art.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {49},
numpages = {19},
keywords = {video quality, perceptual metric, foveated rendering, VDP}
}

@inproceedings{Yu+2021,
  author    = {Alex Yu and
               Ruilong Li and
               Matthew Tancik and
               Hao Li and
               Ren Ng and
               Angjoo Kanazawa},
  title     = {PlenOctrees for Real-time Rendering of Neural Radiance Fields},
  booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2021, Montreal, QC, Canada, October 10-17, 2021},
  pages     = {5732--5741},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.00570},
  doi       = {10.1109/ICCV48922.2021.00570},
}

@inproceedings{Bemana+2022,
author = {Bemana, Mojtaba and Myszkowski, Karol and Revall Frisvad, Jeppe and Seidel, Hans-Peter and Ritschel, Tobias},
title = {Eikonal Fields for Refractive Novel-View Synthesis},
year = {2022},
isbn = {9781450393379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528233.3530706},
doi = {10.1145/3528233.3530706},
booktitle = {ACM SIGGRAPH 2022 Conference Proceedings},
articleno = {39},
numpages = {9},
keywords = {eikonal rendering, deep learning, refraction},
location = {Vancouver, BC, Canada},
series = {SIGGRAPH '22}
}

@article{fovvdp,
author = {Mantiuk, Rafa\l{} K. and Denes, Gyorgy and Chapiro, Alexandre and Kaplanyan, Anton and Rufo, Gizem and Bachy, Romain and Lian, Trisha and Patney, Anjul},
title = {FovVideoVDP: A Visible Difference Predictor for Wide Field-of-View Video},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459831},
doi = {10.1145/3450626.3459831},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {49},
numpages = {19},
keywords = {foveated rendering, perceptual metric, video quality, VDP}
}

@misc{nerf_robust_benchmark,
  doi = {10.48550/ARXIV.2301.04075},
  
  url = {https://arxiv.org/abs/2301.04075},
  
  author = {Wang, Chen and Wang, Angtian and Li, Junbo and Yuille, Alan and Xie, Cihang},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Benchmarking Robustness in Neural Radiance Fields},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@INPROCEEDINGS{light_field_bench,
  author={Yue, Dingcheng and Khan Gul, Muhammad Shahzeb and Bätz, Michel and Keinert, Joachim and Mantiuk, Rafał},
  booktitle={2020 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW)}, 
  title={A Benchmark of Light Field View Interpolation Methods}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICMEW46912.2020.9106041}}

@inproceedings{vmaf0,
  author    = {Joe Yuchieh Lin and
               Tsung{-}Jung Liu and
               Eddy Chi{-}Hao Wu and
               C.{-}C. Jay Kuo},
  title     = {A fusion-based video quality assessment (fvqa) index},
  booktitle = {Asia-Pacific Signal and Information Processing Association Annual
               Summit and Conference, {APSIPA} 2014, Chiang Mai, Thailand, December
               9-12, 2014},
  pages     = {1--5},
  publisher = {{IEEE}},
  year      = {2014},
  url       = {https://doi.org/10.1109/APSIPA.2014.7041705},
  doi       = {10.1109/APSIPA.2014.7041705},
  }

  @Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2018},
   url = {http://www.blender.org},
 }

@inproceedings{dtu,
  title={Large scale multi-view stereopsis evaluation},
  author={Jensen, Rasmus and Dahl, Anders and Vogiatzis, George and Tola, Engil and Aan{\ae}s, Henrik},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={406--413},
  year={2014},
  organization={IEEE}
}

@INPROCEEDINGS{scannerf,
  author={De Luigi, Luca and Bolognini, Damiano and Domeniconi, Federico and Gregorio, Daniele De and Poggi, Matteo and Stefano, Luigi Di},
  booktitle={2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={ScanNeRF: a Scalable Benchmark for Neural Radiance Fields}, 
  year={2023},
  volume={},
  number={},
  pages={816-825},
  doi={10.1109/WACV56688.2023.00088}}


@ARTICLE{pair_comparison,  author={Pérez-Ortiz, María and Mikhailiuk, Aliaksei and Zerman, Emin and Hulusic, Vedad and Valenzise, Giuseppe and Mantiuk, Rafał K.},  journal={IEEE Transactions on Image Processing},   title={From Pairwise Comparisons and Rating to a Unified Quality Scale},   year={2020},  volume={29},  number={},  pages={1139-1151},  doi={10.1109/TIP.2019.2936103}}

@ARTICLE{fsim,
  author={Zhang, Lin and Zhang, Lei and Mou, Xuanqin and Zhang, David},
  journal={IEEE Transactions on Image Processing}, 
  title={FSIM: A Feature Similarity Index for Image Quality Assessment}, 
  year={2011},
  volume={20},
  number={8},
  pages={2378-2386},
  doi={10.1109/TIP.2011.2109730}}

@article{flip,
author = {Andersson, Pontus and Nilsson, Jim and Akenine-M\"{o}ller, Tomas and Oskarsson, Magnus and \r{A}str\"{o}m, Kalle and Fairchild, Mark D.},
title = {FLIP: A Difference Evaluator for Alternating Images},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3406183},
doi = {10.1145/3406183},
abstract = {Image quality measures are becoming increasingly important in the field of computer graphics. For example, there is currently a major focus on generating photorealistic images in real time by combining path tracing with denoising, for which such quality assessment is integral. We present FLIP, which is a difference evaluator with a particular focus on the differences between rendered images and corresponding ground truths. Our algorithm produces a map that approximates the difference perceived by humans when alternating between two images. FLIP is a combination of modified existing building blocks, and the net result is surprisingly powerful. We have compared our work against a wide range of existing image difference algorithms and we have visually inspected over a thousand image pairs that were either retrieved from image databases or generated in-house. We also present results of a user study which indicate that our method performs substantially better, on average, than the other algorithms. To facilitate the use of FLIP, we provide source code in C++, MATLAB, NumPy/SciPy, and PyTorch.},
journal = {Proc. ACM Comput. Graph. Interact. Tech.},
month = {aug},
articleno = {15},
numpages = {23},
keywords = {image metric, image difference}
}

@article{hdrvqm,
author = {Narwaria, Manish and Perreira Da Silva, Matthieu and Le Callet, Patrick},
year = {2015},
month = {05},
pages = {},
title = {HDR-VQM: An objective quality measure for high dynamic range video},
volume = {35},
journal = {Signal Processing: Image Communication},
doi = {10.1016/j.image.2015.04.009}
}

@article{strred,
author = {Soundararajan, Rajiv and Bovik, Alan},
year = {2013},
month = {04},
pages = {684-694},
title = {Video Quality Assessment by Reduced Reference Spatio-Temporal Entropic Differencing},
volume = {23},
journal = {Circuits and Systems for Video Technology, IEEE Transactions on},
doi = {10.1109/TCSVT.2012.2214933}
}


@misc{vmaf1,
title={Toward A Practical Perceptual Video Quality Metric},
author={Zhi Li and Anne Aaron and Ioannis Katsavounidis and Anush Moorthy and Megha Manohara},
publisher={Netflix},
url={https://netflixtechblog.com/toward-a-practical-perceptual-video-quality-metric-653f208b9652},
year={2016},
month={June},
}

@misc{vmaf2,
title={VMAF: The Journey Continues},
author={Zhi Li and Christos Bampis and Julie Novak, Anne Aaron and Kyle Swanson and Anush Moorthy and Jan De Cock},
publisher={Netflix},
url={https://netflixtechblog.com/vmaf-the-journey-continues-44b51ee9ed12},
year={2018},
month={October},
}

  @article{ssim,
  author    = {Zhou Wang and
               Alan C. Bovik and
               Hamid R. Sheikh and
               Eero P. Simoncelli},
  title     = {Image quality assessment: from error visibility to structural similarity},
  journal   = {{IEEE} Trans. Image Process.},
  volume    = {13},
  number    = {4},
  pages     = {600--612},
  year      = {2004},
  url       = {https://doi.org/10.1109/TIP.2003.819861},
  doi       = {10.1109/TIP.2003.819861},
  timestamp = {Fri, 30 Jul 2021 13:45:25 +0200},
  biburl    = {https://dblp.org/rec/journals/tip/WangBSS04.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hdr-vqm,
author = {Narwaria, Manish and Perreira Da Silva, Matthieu and Le Callet, Patrick},
title = {HDR-VQM},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {35},
number = {C},
issn = {0923-5965},
url = {https://doi.org/10.1016/j.image.2015.04.009},
doi = {10.1016/j.image.2015.04.009},
journal = {Image Commun.},
month = {jul},
pages = {46–60},
numpages = {15},
keywords = {Objective quality, Spatio-temporal analysis, High dynamic range (HDR) video quality}
}

  
@inproceedings{Liu21editing,
      title={Editing Conditional Radiance Fields},
      author={Steven Liu and Xiuming Zhang and Zhoutong Zhang and Richard Zhang and Jun-Yan Zhu and Bryan Russell},
      booktitle = {Proceedings of the International Conference on Computer Vision (ICCV)},
      year={2021}
}

@inproceedings{Yuan22editing,
  author    = {Yu{-}Jie Yuan and
               Yang{-}Tian Sun and
               Yu{-}Kun Lai and
               Yuewen Ma and
               Rongfei Jia and
               Lin Gao},
  title     = {NeRF-Editing: Geometry Editing of Neural Radiance Fields},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages     = {18332--18343},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.01781},
  doi       = {10.1109/CVPR52688.2022.01781},
  timestamp = {Wed, 05 Oct 2022 16:31:19 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/YuanSLMJ022.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Tancick22city,
  title={{Block-NeRF}: Scalable Large Scene Neural View Synthesis},
  author={Matthew Tancik and Vincent Casser and Xinchen Yan and Sabeek Pradhan and Ben Mildenhall and Pratul Srinivasan and Jonathan T. Barron and Henrik Kretzschmar},
  journal={arXiv},
  year={2022}
}

@article{Xiangli22city,
  author    = {Yuanbo Xiangli and
               Linning Xu and
               Xingang Pan and
               Nanxuan Zhao and
               Anyi Rao and
               Christian Theobalt and
               Bo Dai and
               Dahua Lin},
  title     = {CityNeRF: Building NeRF at City Scale},
  journal   = {CoRR},
  volume    = {abs/2112.05504},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.05504},
  eprinttype = {arXiv},
  eprint    = {2112.05504},
  }

@InProceedings{Weng22Human,
    title     = {Human{N}e{RF}: Free-Viewpoint Rendering of Moving People From Monocular Video},
    author    = {Weng, Chung-Yi and 
                 Curless, Brian and 
                 Srinivasan, Pratul P. and 
                 Barron, Jonathan T. and 
                 Kemelmacher-Shlizerman, Ira},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16210-16220}
}

@inproceedings{Sun22Face,
  author    = {Jingxiang Sun and
               Xuan Wang and
               Yong Zhang and
               Xiaoyu Li and
               Qi Zhang and
               Yebin Liu and
               Jue Wang},
  title     = {FENeRF: Face Editing in Neural Radiance Fields},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages     = {7662--7672},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/CVPR52688.2022.00752},
  doi       = {10.1109/CVPR52688.2022.00752},
  }
  
  @InProceedings{Pumarola_2021_CVPR,
    author    = {Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
    title     = {D-NeRF: Neural Radiance Fields for Dynamic Scenes},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {10318-10327}
}

@inproceedings{NEURIPS2021_7d62a275,
 author = {Xu, Hongyi and Alldieck, Thiemo and Sminchisescu, Cristian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {14955--14966},
 publisher = {Curran Associates, Inc.},
 title = {H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion},
 url = {https://proceedings.neurips.cc/paper/2021/file/7d62a275027741d98073d42b8f735c68-Paper.pdf},
 volume = {34},
 year = {2021}
}

@InProceedings{Mildenhall22HDR,
    author    = {Mildenhall, Ben and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P. and Barron, Jonathan T.},
    title     = {NeRF in the Dark: High Dynamic Range View Synthesis From Noisy Raw Images},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16190-16199}
}

@InProceedings{Turki22city,
    author    = {Turki, Haithem and Ramanan, Deva and Satyanarayanan, Mahadev},
    title     = {Mega-NERF: Scalable Construction of Large-Scale NeRFs for Virtual Fly-Throughs},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {12922-12931}
}

@article{mueller2022instant,
	author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
	title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
	journal = {ACM Trans. Graph.},
	issue_date = {July 2022},
	volume = {41},
	number = {4},
	month = jul,
	year = {2022},
	pages = {102:1--102:15},
	articleno = {102},
	numpages = {15},
	url = {https://doi.org/10.1145/3528223.3530127},
	doi = {10.1145/3528223.3530127},
	publisher = {ACM},
	address = {New York, NY, USA},
}


@article{Karsh14,
author = {Karsch, Kevin and Sunkavalli, Kalyan and Hadap, Sunil and Carr, Nathan and Jin, Hailin and Fonte, Rafael and Sittig, Michael and Forsyth, David},
title = {Automatic Scene Inference for 3D Object Compositing},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/2602146},
doi = {10.1145/2602146},
journal = {ACM Trans. Graph.},
month = {jun},
articleno = {32},
numpages = {15},
keywords = {image-based rendering, depth estimation, physically grounded, image-based editing, scene reconstruction, Illumination inference}
}

@INPROCEEDINGS{mikhailiuk2020active,
    title={Active Sampling for Pairwise Comparisons via Approximate Message Passing and Information Gain Maximization},
    author={Aliaksei Mikhailiuk and Clifford Wilmot and Maria Perez-Ortiz and Dingcheng Yue and Rafal Mantiuk},
    booktitle={2020 IEEE International Conference on Pattern Recognition (ICPR)}, 
    year={2021},
    month={Jan},
}
  
@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@book{BasicVisionBook,
title={Basic Vision: An Introduction to Visual Perception},
author={ Robert Snowden and Peter Thompson and Tom Troscianko},
publisher ={Oxford University Press},
isbn={978-0199572021},
year={2012},
month={April},
}



@inproceedings{Lin2019,
booktitle = {2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)},
author={Lin, Hanhe and Hosu, Vlad and Saupe, Dietmar},
doi = {10.1109/QoMEX.2019.8743252},
isbn = {978-1-5386-8212-8},
keywords = {Crowdsourcing,Image quality assessment,Image quality dataset},
mendeley-groups = {Quality/Datasets},
month = {jun},
pages = {1--3},
publisher = {IEEE},
title = {{KADID-10k: A Large-scale Artificially Distorted IQA Database}},
url = {https://ieeexplore.ieee.org/document/8743252/},
volume = {161},
year = {2019}
}

@article{Tariq+2022,
author = {Tariq, Taimoor and Tursun, Cara and Didyk, Piotr},
title = {Noise-Based Enhancement for Foveated Rendering},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3528223.3530101},
doi = {10.1145/3528223.3530101},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {143},
numpages = {14},
keywords = {image enhancement, foveated rendering}
}


@article{Eilertsen+2013,
  author    = {Gabriel Eilertsen and
               Robert Wanat and
               Rafal K. Mantiuk and
               Jonas Unger},
  title     = {Evaluation of Tone Mapping Operators for HDR-Video},
  journal   = {Comput. Graph. Forum},
  volume    = {32},
  number    = {7},
  pages     = {275--284},
  year      = {2013},
  url       = {https://doi.org/10.1111/cgf.12235},
  doi       = {10.1111/cgf.12235},
  timestamp = {Mon, 05 Jun 2017 20:49:28 +0200},
  biburl    = {https://dblp.org/rec/journals/cgf/EilertsenWMU13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Artusi+2016,
  author    = {Alessandro Artusi and
               Rafal K. Mantiuk and
               Thomas Richter and
               Pavel Korshunov and
               Philippe Hanhart and
               Touradj Ebrahimi and
               Massimiliano Agostinelli},
  title     = {{JPEG} {XT:} {A} Compression Standard for {HDR} and {WCG} Images [Standards
               in a Nutshell]},
  journal   = {{IEEE} Signal Process. Mag.},
  volume    = {33},
  number    = {2},
  pages     = {118--124},
  year      = {2016},
  url       = {https://doi.org/10.1109/MSP.2015.2506199},
  doi       = {10.1109/MSP.2015.2506199},
  timestamp = {Fri, 26 May 2017 22:53:36 +0200},
  biburl    = {https://dblp.org/rec/journals/spm/ArtusiMRKHEA16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Serrano+2019,
author = {Ana Serrano and
Incheol Kim and
Zhili Chen and
Stephen DiVerdi and
Diego Gutierrez and			  
Aaron Hertzmann and
Belen Masia},
title     = {Motion parallax for 360$^{\circ}$ RGBD video},
journal   = {IEEE Transactions on Visualization and Computer Graphics},
year      = {2019},
}


@article{Eilertsen+2015,
  author    = {Gabriel Eilertsen and
               Rafal K. Mantiuk and
               Jonas Unger},
  title     = {Real-time noise-aware tone mapping},
  journal   = {{ACM} Trans. Graph.},
  volume    = {34},
  number    = {6},
  pages     = {198:1--198:15},
  year      = {2015},
  url       = {https://doi.org/10.1145/2816795.2818092},
  doi       = {10.1145/2816795.2818092},
  timestamp = {Tue, 06 Nov 2018 12:51:26 +0100},
  biburl    = {https://dblp.org/rec/journals/tog/EilertsenMU15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Ledda+2005,
  author    = {Patrick Ledda and
               Alan Chalmers and
               Tom Troscianko and
               Helge Seetzen},
  title     = {Evaluation of tone mapping operators using a High Dynamic Range display},
  journal   = {{ACM} Trans. Graph.},
  volume    = {24},
  number    = {3},
  pages     = {640--648},
  year      = {2005},
  url       = {https://doi.org/10.1145/1073204.1073242},
  doi       = {10.1145/1073204.1073242},
}


@article {Denes2020flicker,
title = "Predicting visible flicker in temporally changing images",
journal = "Electronic Imaging",
parent_itemid = "infobike://ist/ei",
publishercode ="ist",
year = "2020",
volume = "2020",
number = "11",
pages = "233-1-233-8",
itemtype = "ARTICLE",
issn = "2470-1173",
eissn = "2470-1173",
url = "https://www.ingentaconnect.com/content/ist/ei/2020/00002020/00000011/art00012",
doi = "doi:10.2352/ISSN.2470-1173.2020.11.HVEI-233",
keyword = "perception, flicker, visual model",
author = "Denes, Gyorgy and Mantiuk, Rafa K.",
abstract = "
Novel display algorithms such as low-persistence displays, black frame insertion, and temporal resolution multiplexing introduce temporal change into images at 40-180 Hz, on the boundary of the temporal integration of the visual system. This can lead to flicker, a highly-objectionable
artifact known to induce viewer discomfort. The critical flicker frequency (CFF) alone does not model this phenomenon well, as flicker sensitivity varies with contrast, and spatial frequency; a content-aware model is required. In this paper, we introduce a visual model for predicting flicker
visibility in temporally changing images. The model performs a multi-scale analysis on the difference between consecutive frames, normalizing values with the spatio-temporal contrast sensitivity function as approximated by the pyramid of visibility. The output of the model is a 2D detection
probability map. We ran a subjective flicker marking experiment to fit the model parameters, then analyze the difference between two display algorithms, black frame insertion and temporal resolution multiplexing, to demonstrate the application of our model.
",
}

@article{Cadik2012a,
author = {{\v{C}}ad{\'{i}}k, Martin and Herzog, Robert and Mantiuk, Rafa{\l} K. and Myszkowski, Karol and Seidel, Hans-Peter},
doi = {10.1145/2366145.2366166},
journal = {ACM Transactions on Graphics (proc. of SIGGRAPH Asia)},
keywords = {global illumination,image quality metrics,iqm,noticeable and objectionable distortions,perceptual experiments},
mendeley-groups = {Quality/CNN / machine learning},
number = {6},
pages = {147},
title = {{New Measurements Reveal Weaknesses of Image Quality Metrics in Evaluating Graphics Artifacts}},
volume = {31},
year = {2012}
}
