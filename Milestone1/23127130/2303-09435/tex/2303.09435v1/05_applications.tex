\section{Implication to Early Exiting}
\label{sec:applications}


The fact that it is often possible to approximate the final prediction already from early layers in the network has important implications to efficiency. Concretely, applying our linear mapping instead of executing transformer blocks of quadratic time complexity, could potentially save a substantial portion of the computation. In this section, we demonstrate this in the context of early exiting.

When performing transformer model inference under an early exit strategy \cite{schwartz-etal-2020-right, xin-etal-2020-deebert, schuster2022confident}, one aims at deciding dynamically at which layer, during inference, to stop the computation and ``read'' the prediction from the hidden representation of that layer.
More precisely, under the confidence measure paradigm, one decides to stop the computation for a position $i$ at layer $\ell$ based on a confidence criterion, that is derived from casting the hidden representation $h_i^\ell$ as a final-layer representation and converting it to an output probability distribution. Specifically, following \citet{schuster2022confident}, a decision to stop the computation is made if the difference between the highest and the second highest probabilities is bigger than $$ 0.9 \cdot \lambda + 0.1 \cdot {\rm exp} (-4 i / N),$$
where $N$ is the average length of the input until position $i_s$ for $s \in \mathcal{V}$, and $\lambda$ is a confidence hyper-parameter.


\paragraph{Experiment.}
We assess the utility of our mapping $\matlL{}$ for early exit as a plug-and-play replacement for the $\idlL{}$ mapping, through which intermediate representations are cast into final-layer representations.
In our experiments, we use both ($24$-layered) \gpt{} for the next token prediction and ($24$-layered) \bert{} for masked token prediction.
We run each of the models over the validation set examples, while varying the confidence parameter $\lambda$ (see the exact values in \S\ref{subsec:exp_set_lambda}) and using either $\idlL{}$ or $\matlL{}$ for casting intermediate representations.
Furthermore, we compare these early exit variants to the ``fixed exit'' strategy from \S\ref{sec:prediction}, where the computation is stopped after a pre-defined number of layers rather than relying on a dynamic decision.

We evaluate each variant in terms of both prediction's accuracy, using the Precision@$1$ metric (see \S\ref{sec:prediction}), and efficiency, measured as the average number of layers processed during inference.

\paragraph{Results.}
Figs.~\ref{fig:ee_pre1} and~\ref{fig:bertmask_ee_pre1} plot the average Precision@$1$ score against the average number of layers processed, for $24$-layered \gpt{} and $24$-layered \bert{}, respectively. For both models, under an early exit strategy our mapping \mat{} again provides a substantial improvement over the baseline \id{}.
For example, aiming at $95\%$ average precision, \mat{} saves $\sim3.3$ ($13.8$\%) layers in \gpt{} compared to only $\sim1.4$ ($5.9$\%) layers by \id{}, and $\sim4.8$ ($20$\%) layers in \bert{} versus $\sim3.5$ ($14.6$\%) layers by \id{}.
These results highlight to potential gains prominent early exit methods can obtain by using our method.
Notably, in both models and using each of the two mapping methods, early exit obtains better results than fixed layer exit, as expected. 

\begin{figure}[t]
\centering
\includegraphics[scale=0.4]{figs/ee_pre1_24.pdf}
\caption{Precision@$1$ for the various early exit methods, and previous ``fixed exit'' methods for comparison ($24$-layered \gpt{} next token prediction task). Varying the confidence parameter $\lambda$, the $x$-coordinate is the average number of layers processed before an early exit decision is reached.}
\label{fig:ee_pre1}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[scale=0.4]{figs/bertmask_ee_pre1_24.pdf}
\caption{Precision@$1$ for the various early exit methods, and previous fixed exit methods for comparison ($24$-layered \bert{} masked token prediction task). Varying the confidence parameter $\lambda$, the $x$-coordinate is the average number of layers processed before an early exit decision is reached.}
\label{fig:bertmask_ee_pre1}
\end{figure}