\abstract{
Transformer-based language models create hidden representations of their inputs at every layer, but only use final-layer representations for prediction. This obscures the internal decision-making process of the model and the utility of its intermediate representations. One way to elucidate this is to cast the hidden representations as final representations, bypassing the transformer computation in-between.
In this work, we suggest a simple method for such casting, using linear transformations. This approximation far exceeds the prevailing practice of inspecting hidden representations from all layers, in the space of the final layer. 
% Moreover, in the context of language modeling, our method allows ``peeking'' into early layer representations of \gpt{} and \bert{}, showing that often LMs already predict the final output in early layers.
Moreover, in the context of language modeling, our method produces more accurate predictions from hidden layers, across various model scales, architectures, and data distributions. This allows ``peeking'' into intermediate representations, showing that \gpt{} and \bert{} often predict the final output already in early layers.
% \sy{We also test modes of inference alternating between transformer blocks and our mappings, finding that some of them out-perform the mere application of our mapping from a given layer to the final layer.} \sy{We validate the robustness of our method by varying model size and training data source.}
We then demonstrate the practicality of our method to recent early exit strategies, showing that when aiming, for example, at retention of 95\% accuracy, our approach saves additional 7.9\% layers for \gpt{} and 5.4\% layers for \bert{}.
% \footnote{Our code and learned mappings are publicly available at \url{https://anonymized}.
% on top of the savings of the original approach.
Last, we extend our method to linearly approximate sub-modules, finding that attention is most tolerant to this change. Our code and learned mappings are publicly available at \url{https://github.com/sashayd/mat}.
\\ \newline \Keywords{interpretability, language models, efficiency, logitlens, linear lense, linear, early exit, shortcut, layer jump}
}