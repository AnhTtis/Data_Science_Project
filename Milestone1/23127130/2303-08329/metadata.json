{
    "arxiv_id": "2303.08329",
    "paper_title": "Cross-speaker Emotion Transfer by Manipulating Speech Style Latents",
    "authors": [
        "Suhee Jo",
        "Younggun Lee",
        "Yookyung Shin",
        "Yeongtae Hwang",
        "Taesu Kim"
    ],
    "submission_date": "2023-03-15",
    "revised_dates": [
        "2023-03-16"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SD",
        "cs.CL",
        "eess.AS"
    ],
    "abstract": "In recent years, emotional text-to-speech has shown considerable progress. However, it requires a large amount of labeled data, which is not easily accessible. Even if it is possible to acquire an emotional speech dataset, there is still a limitation in controlling emotion intensity. In this work, we propose a novel method for cross-speaker emotion transfer and manipulation using vector arithmetic in latent style space. By leveraging only a few labeled samples, we generate emotional speech from reading-style speech without losing the speaker identity. Furthermore, emotion strength is readily controllable using a scalar value, providing an intuitive way for users to manipulate speech. Experimental results show the proposed method affords superior performance in terms of expressiveness, naturalness, and controllability, preserving speaker identity.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08329v1"
    ],
    "publication_venue": "accepted to ICASSP 2023"
}