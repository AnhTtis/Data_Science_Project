\vspace{-2pt}
\section{Conclusion}
\label{sec:conclusion}
\vspace{-2pt}

This work proposes \textit{MoTok}, a unified architecture that leverages motion-guided tokenization for object discovery. By jointly training the slot representation with motion cues and vector quantization, our model enables the emergence of interpretable mid-level features which simplifies the problem of object discovery. Comprehensive evaluation on both synthetic and real-world benchmarks shows that with sufficient capacity of the slot decoder, motion guidance alleviates the need for labels, optical flow, or depth decoding, thanks to tokenization, achieving state-of-the-art results.

\smallsec{Acknowledgements.}
We thank Dian Chen, Alexei Efros, and Andrew Owens for their valuable comments. This research was supported by Toyota Research Institute. YXW was supported in part by NSF Grant 2106825, NIFA Award 2020-67021-32799, and the NCSA Fellows program. 

