\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{figures/guidance.pdf}
\end{center}
\vspace{-0.2in}
   \caption{\textbf{Guidance Scale Ablation:} For a given mask, we generate images using different values of the guidance scale, $s$. The FID and IS metrics are computed by generating images for all masks in the test set at $20\times$ magnification.}
\vspace{-0.2in}
\label{fig:guidance}
\end{figure}

In this section, we first describe our implementation details and training procedure. Further, we establish the robustness of our model by performing an ablative study over objective magnification and classifier-guidance scale. We then perform quantitative and qualitative assessments to demonstrate the efficacy of our nuclei-aware semantic histopathology generation model. In all following experiments, we first synthesize images using the semantic masks of the held-out dataset at the concerned objective magnification. We then compute Fr\'echet  Inception Distance (FID) and Inception Score (IS) metrics between the synthetic and real images in the held-out set. 

% We quantitatively assess the generative prowess of the model using standard generative metrics like Fr\'echet  Inception Distance (FID) metrics and Inception Score (IS) against existing histopathological generative models. The qualitative analysis explores our model's proficiency in generating different types of nuclei. 

\subsection{Implementation Details}
Our diffusion model is implemented using a semantic UNet architecture (Section~\ref{sec:cond_on_mask}), trained using the objective in~\eqref{eq:objective}. Following previous works~\cite{nichol2021improved}, we set the trade-off parameter $\lambda$ as $0.001$. We use the AdamW optimizer to train our model. Additionally, we adopt an exponential moving average (EMA) of the denoising network weights with $0.999$ decay. Following DDPM~\cite{ho2020denoising}, we set the total number of diffusion steps as $1000$ and use a linear noising schedule with respect to timestep $t$ for the forward process. After normal training with a learning rate of $1e-4$, we decay the learning rate to $2e-5$ to further finetune the model with a drop rate of $0.2$ to enhance the classifier-free guidance capability during sampling. The whole framework is implemented using Pytorch and trained on $4$ NVIDIA Tesla A100 GPUs with a batch-size of $40$ per GPU. Code will be made public on publication or request. 

% Frozen backbone table
\begin{table}[t]
% \renewcommand{\arraystretch}{1.2}
\begin{center}
\setlength\tabcolsep{3pt}
% \renewcommand{\arraystretch}{1.1}
\caption{\textbf{Quantitative Assesment:} We report the performance of our method using standard generative metrics Fr\'echet  Inception Distance (FID) metrics and Inception Score (IS) with the metrics reported in existing works. (-) denotes that the corresponding information was not reported in the original work.}
\label{tab:quant}
% \small
% \vspace{-0.1in}
% \resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccc}
    \toprule
    \textbf{Method} & \textbf{Tissue type} & \textbf{Conditioning} & \textbf{FID($\downarrow$)}  & \textbf{IS($\uparrow$)} \\ 
    \midrule
    BigGAN~\cite{brock2018large} & bladder & none & 158.4 & -           \\
    AttributeGAN~\cite{ye2021multi} & bladder & attributes & 53.6 & -           \\
    ProGAN~\cite{karras2017progressive} & glioma & morphology & 53.8 & 1.7           \\
    Morph-Diffusion~\cite{moghadam2023morphology} & glioma & morphology & 20.1 & 2.1 \\
    \midrule
    % Ours (10$\times$ mag.) & colon & semantic mask &  &  \\
    NASDM (Ours)  & colon & semantic mask & \textbf{15.7} & \textbf{2.7} \\
    \bottomrule
\vspace{-0.2in}
\end{tabular}
\end{center}
\end{table}

\subsection{Ablation over Guidance Scale ($s$)}
In this study, we test the effectiveness of the classifier-free guidance strategy. We consider the variant without guidance as our baseline. As seen in Figure~\ref{fig:guidance}, increase in guidance scale initially results in better image quality as more detail is added to visual structures of nuclei. However, with further increase, the image quality degrades as the model overemphasizes the nuclei and staining textures. 

\subsection{Ablation over Objective Magnification}

\begin{wraptable}{}{0.3\columnwidth}
\vspace{-0.3in}
\centering	
 \resizebox{0.3\columnwidth}{!}{%
    \begin{tabular}{ccc}
    \toprule
    \textbf{Obj. Mag.} &  \textbf{FID($\downarrow$)}  & \textbf{IS($\uparrow$)} \\ 
    \midrule
    10$\times$ & 38.1 & 2.3           \\
    20$\times$ & \textbf{15.7} & \textbf{2.7} \\
    \bottomrule
    \end{tabular}
}
\vspace{-0.3in}
\end{wraptable}


As described in Section~\ref{sec:data_process}, we generate patches at two different objective magnifications of $10\times$ and $20\times$. In this section, we contrast the generative performance of the models trained on these magnification levels respectively. From the table on right, we observe that the model trained at $20\times$ objective magnification produces better generative metrics. However, we hypothesize that the loss of expressiveness of the model at a lower magnification of $10\times$ could be because of the reduction in the training data at this magnification scale.

\begin{figure}[t] 
\begin{center}
\includegraphics[width=\linewidth]{figures/qualitative.pdf}
\end{center}
\vspace{-0.2in}
   \caption{\textbf{Qualitative Analysis:} We generate synthetic images given masks with each type of nuclei in different environments to demonstrate the proficiency of the model to generate realistic nuclei arrangements. Legend at bottom denotes the mask color for each type of nuclei.}
\label{fig:qualitative}
\vspace{-0.2in}
\end{figure}

\subsection{Quantitative Analysis}
We compare the performance of our framework with existing histopathology generative models. To the best of our knowledge, ours is the only work that is able to synthesize histology images given a semantic mask, making a direct quantitative comparison tricky. However, the standard generative metric Fr\'echet Inception Distance (FID) measures the distance between distributions of generated and real images in the Inception-V3~\cite{kynkaanniemi2022role} latent space, where a lower FID indicates that the model is able to generate images that are very similar to real data. Therefore, we compare FID and IS metrics with the values reported in existing works~\cite{ye2021multi, moghadam2023morphology} (ref. Table~\ref{tab:quant}) in their own settings. We can observe that our method outperforms all existing methods including both GANs-based methods as well as the recently proposed morphology-focused generative diffusion model. 


\subsection{Qualitative Analysis}
We now qualitatively discuss the proficiency of our model in generating realistic visual patterns in synthetic histopathology images (refer Fig.~\ref{fig:qualitative}). We demonstrate synthetic images with each type of nuclei in different environments. We can see that the model is able to capture convincing visual structure for each type of nuclei. In the synthetic images, we can see that the lymphocytes are accurately circular, while neutrophils and eosinophils have a more lobed structure. We also observe that the model is able to mimic correct nucleus-to-cytoplasm ratios for each type of nuclei. Epithelial cells are less dense, have a distinct chromatin structure, and are larger compared to other white blood cells. Due to their structure, epithelial cells are most difficult to generate in a convincing manner, however, we can see that model is able to capture the nuances well and generates accurate chromatin distributions. 

% \section{Conclusion And Future Works}



% Plasma cells are essentially lymphocytes. Neutrophil and eosinophil nuclei are lobed and plasma cell and lymphocytes are circular, epithelial is different shape the cromatin is not dense and is larger compared to other white blood cells. 

% Ecpect epithelial and connective other are WBC. Epithelial is difficult to generate, it can generate accurate cromatin distribution. is important for colon cancer diagnosis. Ratio to nucleus to cytoplasm is different for different cell types. 