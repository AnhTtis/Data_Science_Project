Histopathology relies on hematoxylin and eosin (H\&E) stained biopsies for microscopic inspection to identify visual evidence of diseases. Hematoxylin has a deep blue-purple color and stains acidic structures such as DNA in cell nuclei. Eosin, alternatively, is red-pink and stains nonspecific proteins in the cytoplasm and the stromal matrix. Pathologists then examine highlighted tissue characteristics to diagnose diseases, including different cancers. A correct diagnosis, therefore, is dependent on the pathologist's training and prior exposure to a wide variety of disease subtypes~\cite{xie2020integrating}. This presents a challenge, as some disease variants are extremely rare, making visual identification difficult. In recent years, deep learning methods have aimed to alleviate this problem by designing discriminative frameworks that aid diagnosis~\cite{van2021deep, wu2022recent}. Segmentation models find applications in spatial identification of different nuclei types~\cite{graham2019hover} or directly detecting visual aberrations like breast cancer metastasis.

However, generative modeling in histopathology is relatively unexplored. Generative models can generate realistic synthetic images unconditionally or given a conditioning signal. They can be used to generate histopathology images with specific characteristics, such as visual patterns identifying rare cancer subtypes~\cite{fajardo2021oversampling}. As such, generative models can be sampled to emphasize each disease subtype equally and generate more balanced datasets, thus preventing dataset biases getting amplified by the models~\cite{hall2022systematic}. Generative models have the potential to improve the pedagogy, trustworthiness, generalization, and coverage of disease diagnosis in the field of histology by aiding both deep learning models and human pathologists. Synthetic datasets can also tackle privacy concerns surrounding medical data sharing. Additionally, conditional generation of annotated data adds even further value to the proposition as labeling medical images involves tremendous time, labor, and training costs. Recently, denoising diffusion probabilistic models (DDPMs)~\cite{ho2020denoising} have achieved tremendous success in conditional and unconditional generation of real-world images~\cite{dhariwal2021diffusion}. Further, the semantic diffusion model (SDM) demonstrated the use of DDPMs for generating images given semantic layout~\cite{wang2022semantic}. In this work, (1) we leverage recently discovered capabilities of DDPMs to design a first-of-its-kind nuclei-aware semantic diffusion model (NASDM) that can generate realistic tissue patches given a semantic mask comprising of multiple nuclei types, (2) we train our framework on the Lizard dataset~\cite{graham2021lizard} consisting of colon histology images and achieve state-of-the-art generation capabilities, and (3) we perform extensive ablative, qualitative, and quantitative analyses to establish the proficiency of our framework on this tissue generation task.  



