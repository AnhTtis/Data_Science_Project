\section{DL Advocate}

\subsection{DL Advocate linear programming (DLA-LP)}
\label{app:DL_Linear_Programming}

The formal definition of the optimization algorithm.

\begin{algorithm}
\caption{DL Advocate: linear programming optimisation.}\label{alg:training}
\begin{algorithmic}[1]
\Require{dataset $D=\{(x_i,y_i)\}_{i=1}^N$, efficiency bounds $B=\{(e_j^l, e_j^u)\}_{j=1}^k$, NN $f(x;\theta)$}
\Require{Learning rate $\eta$, gradient penalty $p$, numeric differentiation step $\xi$}
\State{$h(x;\theta) \equiv \operatorname{softmax}(f(x;\theta))$}
\State{$\theta\gets\arg\min_\theta\sum_{(x,y)\in D}\operatorname{crossentropy loss}(y,h(x;\theta))$}
\While{not converged}
    \State{$\partial\ell \gets 0$}
    \ForAll{$i, y \in 1 \dots k$}
    \State{$H_{i,y} \gets \frac{1}{N_y}\sum_{j: y_j=y}h_i(x_j;\theta)$}
    \EndFor
    \State{$H^+ \gets \operatorname{inverse}(H)$}
    \State{$\alpha \gets \operatorname{solve LP}(H, B)$}
    \State{$E \gets \operatorname{estimator}(H, B, \alpha)$}
    \For{$(x,y) \in D$}
    \State{$\partial\ell_{sd} \gets \frac{1}{N_y}\sum_{i=1}^k(E_{y,i}-H^+_{y,i}) \frac\partial{\partial\theta}h_i(x;\theta)$}
    \State{$\partial\ell \gets \partial\ell + \partial\ell_{sd}$}
    \If{GP is enabled}
        \ForAll{$i \in 1 \dots k$}
        \State{$\partial x_i \gets \frac\partial{\partial x}h_i(x;\theta)$}
        \State{$L_i \gets \frac{h_i(x+\xi\partial x_i;\theta)-h_i(x-\xi\partial x_i;\theta))}{2\xi\left\Vert \partial x_i\right\Vert}$}
        \EndFor
        \State{$\partial\ell_g \gets \frac1N \frac\partial{\partial\theta}\left(\frac1k\sum_{i=1}^k\left(\frac{L_i}{p}-1\right)^2\right)$}
        \State{$\partial\ell \gets \partial\ell + \partial\ell_g$}
    \EndIf
    \EndFor
    \State{$\theta\gets\theta - \eta \partial\ell$}
\EndWhile
\ForAll{$i, y \in 1 \dots k$}
\State{$H_{i,y} \gets \frac{1}{N_y}\sum_{j: y_j=y}h_i(x_j;\theta)$}
\EndFor
\State{$\alpha \gets \operatorname{solve LP}(H, B)$}
% \State{$w \gets \alpha^Th(\cdot;\theta)$}
\State{\Return{$\alpha, \theta$}}
\end{algorithmic}
\end{algorithm}

\subsection{Neural network training}
\label{app:NN}

Training procedure is implemented using PyTorch framework \cite{pytorch}.
The neural network $f(x;\theta)$ is composed of three internal linear layers
with 20 outputs each and $\operatorname{softplus}$ activations.
The final linear layer has the number of outputs necessary to match the measurement shape.
This network is rather simple but it is sufficient to represent
non-trivial interpretable weightings. Softplus activations are used
to keep resulting function smooth in the domain.
%The network is trained for 5000 iterations after initialisation. The best value on target metric is used to produce final values.
Optimisation is performed using gradient descent with learning rate $\eta$ set to \num{0.0001}.
Input data is normalized before training to have same scale between features, while the gradient penalty term is computed after feature normalization.
Parameter $\xi$ for numeric gradient estimation is set to \num{0.001}, and the gradient penalty value $p$ is set to \num{0.5} when enabled.


\endinput
