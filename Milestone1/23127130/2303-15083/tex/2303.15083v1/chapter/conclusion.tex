\section{Conclusion}
In this work, we propose a universal cross-modality knowledge distillation framework~(UniDistill) to improve the performance of single-modality 3D object detectors in BEV. UniDistill projects the features of  both the teacher and student into a unified BEV domain and then calculates three distillation losses to align the features for knowledge transfer. Taking advantage of the similar detection paradigm in BEV, UniDistill supports LiDAR-to-camera, camera-to-LiDAR, fusion-to-LiDAR and fusion-to-camera distillation paths. Furthermore, the proposed three distillation losses sparsely align foreground features to filter the misaligned background information and balance between objects of different sizes. Extensive experiments demonstrate that UniDistill is effective to improve the performance of student detectors. Inspired by block-wise distillation, we plan to leverage the distillation losses in a block-wise manner for acceleration, to further explore the potential of UniDistill.