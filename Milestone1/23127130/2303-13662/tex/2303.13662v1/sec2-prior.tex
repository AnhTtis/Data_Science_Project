\Section{Related Work}
\label{sec:related}
\vspace{\segsep}

\Paragraph{Face Anti-Spoofing} 
Face anti-spoofing attracts growing attention in several thriving directions.
%
Early works exploit spontaneous human behaviors (\eg, eye blinking, head motion)~\cite{kollreider2007real, pan2007eyeblink} or predefined movements (\eg, head-turning, expression changes)~\cite{chetty2010biometric}. %These behavior-based strategy requires user interaction and are vulnerable to the video replaying attacks. 
%(2) Another line of approaches evolve into modeling material properties (\ie, texture). 
Later, hand-crafted features are utilized to describe spoof patterns, \eg, LBP~\cite{boulkenafet2015face, freitas2012lbp}, HoG ~\cite{freitas2012lbp,yang2013face}
and SIFT~\cite{patel2016secure} features. 
%, and train a live/spoof classifier using support vector machines or linear discriminant analysis. 
Recently, deep neural networks have been applied to face anti-spoofing.
There are classification-based methods~\cite{yang2014learn,liu2019deep,wang2022patchnet}, regression-based methods~\cite{atoum2017face,liu2018learning,yu2020face, kim2019basn}, and generative models~\cite{jourabloo2018face,liu2020disentangling,wang2022ssan,liu2022spoof}. 
In addition, the vision transformer also shows promising performance in tackling FAS~\cite{george2021effectiveness,huang2022adaptive}.
%and achieved state-of-the-art performance than conventional methods~\cite{yang2014learn,feng2016integration,li2016original,patel2016cross}.

% domain generalization
\Paragraph{Cross-domain FAS} 
 Recently, several works explore learning FAS models from multiple domains that generalize to unseen ones. 
Some methods~\cite{zhou2022generative, li2018unsupervised, wang2020unsupervised, guo2022multi,unified-detection-of-digital-and-physical-face-attacks} require data from the target domain to adapt the model (\ie, domain adaptation), while others~\cite{shao2019multi,kim2021suppressing,saha2020domain,jia2020ssdg,wang2022ssan,noise-modeling-synthesis-and-classification-for-generic-object-anti-spoofing} learn shared features based on adversarial training and triplet loss (\ie, domain generalization).
%
A few methods~\cite{shao2020regularized,chen2021generalizable,wang2021self} explore meta-learning to simulate the domain shift at training time. 
%
Most previous works regard the domain-specific signals as a negative impact. Contrastively, our paper first systematically exploits the explicit usage of domain-specific signals by invariant risk minimization in cross-domain FAS.

\Paragraph{Domain-invariant Classifier}
Learning a domain-invariant classifier has always been the focus of machine learning for decades~\cite{van2018cpc,chen2020simclr,caron2020swav,he2019moco} and is also one of the keys to the success of domain generalization. Along this line, kernel-based methods~\cite{blanchard2021domain,muandet2013domain,grubinger2015domain,gan2016learning,li2018domain,ghifary2016scatter} propose to learn a domain-invariant kernel from the training data. Domain adversarial learning~\cite{li2018domain,ganin2015unsupervised,ganin2016domain,gong2019dlow,li2018deep,shao2019multi,mahfujur2019correlation,wang2022ssan,jia2020ssdg} adversarially trains the generator and discriminator while the generator is trained to fool the discriminator to learn domain invariant feature representations. Recently, Invariant Risk Minimization (IRM) and its variants~\cite{arjovsky2019irm,ahuja2021ibirm,krueger2021rex,mahfujur2019correlation,mitrovic2020representation,choe2020empirical,sonar2021invariant} seek to directly enforce the optimal classifier on top of the representation space to be the same across all domains. However, IRM is known to be hard to optimize and can fail in non-linear optimization~\cite{kamath2021doesirm,rosenfeld2020riskirm}. In this paper, we propose an equivalent objective (PG-IRM) which is easier to optimize and achieve strong performance. % as shown in Sec.~\ref{sec:exp}.


%\paragraph{Invariant Risk Minimization (IRM)} 