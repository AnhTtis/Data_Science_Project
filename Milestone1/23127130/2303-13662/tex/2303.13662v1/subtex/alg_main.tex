\begin{algorithm}[t]
\begin{algorithmic}[1]
  \State {\textbf{Input:}} Training data $\mathcal{D}=\{(\*x_i,y_i, e_i)\}_{i=1}^N$, network encoder $\phi$, classifiers $\beta_{e^{(1)}}, ... , \beta_{e^{(E)}}$, learning rate $\gamma$, alignment parameter $\alpha$, alignment starting epoch $T_a$.
        \For{$\text{t in 0, 1, ..., T}$}
        \State \textbf{Data Prep.}: Sample and augment a mini-batch.
        % of labeled data and apply augmentation as $\{\tilde{\*x}_i, \tilde{y}_i, \tilde{e}_i\}_{i=1}^{2b}$.
        \State \textbf{Forward/Backward}:  Calculate gradient by $\mathcal{L}_{all}$.
        
        \For{$e \in \mathcal{E}$}
            \State $\tilde{\beta}^{t+1}_e = \beta^{t}_e - \gamma \nabla_{\beta^{t}_e} \mathcal{L}_{\textit{all}}$ \Comment{\textcolor{blue}{SGD}}
            \State select $\beta^{t}_{\bar{e}}$ with $\bar{e}  = \underset{e' \in \mathcal{E}  \backslash e }{\text{argmax}} \|\tilde{\beta}^{t+1}_e - \beta^{t}_{e'}\|_2$
            \State $\alpha' = 1 - \mathbf{1}_{t > T_a} (1 - \alpha)$ \Comment{\textcolor{blue}{$\alpha'$ is 1 when $t \le T_a$}}
            \State $\beta^{t+1}_e = \alpha'
            \tilde{\beta}^{t+1}_e + (1 - \alpha')  \beta^t_{\bar{e}}$ \Comment{\textcolor{blue}{Interpolation}}
        \EndFor
        \State Update $\phi^{t+1} = \phi^{t} - \gamma \nabla_{\phi^t}  \mathcal{L}_{\textit{all}}$. \Comment{\textcolor{blue}{Update encoder}} 
    \EndFor
\end{algorithmic}
\caption{Training pipeline for SA-FAS}
\label{alg:main}
\end{algorithm}