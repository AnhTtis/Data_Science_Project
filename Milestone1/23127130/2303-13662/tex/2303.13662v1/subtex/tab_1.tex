\begin{table*}[t]
    \begin{minipage}[c]{0.72\textwidth}
        
        \small\centering
        \scalebox{0.85}{
            \begin{tabular}{rrrrrrrrr} \toprule
            \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Method ($\%$)}}} & \multicolumn{2}{c}{\textbf{OCI$\rightarrow$M}} & \multicolumn{2}{c}{\textbf{OMI$\rightarrow$C}} & \multicolumn{2}{c}{\textbf{OCM$\rightarrow$I}} & \multicolumn{2}{c}{\textbf{ICM$\rightarrow$O}} \\
            \multicolumn{1}{c}{} & \multicolumn{1}{c}{\textbf{HTER }$\downarrow$} & \multicolumn{1}{c}{\textbf{AUC} $\uparrow$} & \multicolumn{1}{c}{\textbf{HTER  $\downarrow$}} & \multicolumn{1}{c}{\textbf{AUC $\uparrow$}} & \multicolumn{1}{c}{\textbf{HTER}  $\downarrow$} & \multicolumn{1}{c}{\textbf{AUC} $\uparrow$} & \multicolumn{1}{c}{\textbf{HTER}  $\downarrow$} & \multicolumn{1}{c}{\textbf{AUC}  $\uparrow$}
             \\ \midrule
            MMD-AAE~\cite{li2018domain} & 27.08 & 83.19 & 44.59 & 58.29 & 31.58 & 75.18 & 40.98 & 63.08 \\
            MADDG~\cite{shao2019multi} & 17.69 & 88.06 & 24.50 & 84.51 & 22.19 & 84.99 & 27.98 & 80.02 \\
            SSDG-M~\cite{jia2020ssdg} & 16.67 & 90.47 & 23.11 & 85.45 & 18.21 & 94.61 & 25.17 & 81.83 \\
            DR-MD-Net~\cite{wang2020cross} & 17.02 & 90.10 & 19.68 & 87.43 & 20.87 & 86.72 & 25.02 & 81.47 \\
            RFMeta~\cite{shao2020regularized} & 13.89 & 93.98 & 20.27 & 88.16 & 17.30 & 90.48 & 16.45 & 91.16 \\
            NAS-FAS~\cite{yu2020fas} & 19.53 & 88.63 & 16.54 & 90.18 & 14.51 & 93.84 & 13.80 & 93.43 \\
            D2AM~\cite{chen2021generalizable} & 12.70 & 95.66 & 20.98 & 85.58 & 15.43 & 91.22 & 15.27 & 90.87 \\
            SDA~\cite{wang2021self} & 15.40 & 91.80 & 24.50 & 84.40 & 15.60 & 90.10 & 23.10 & 84.30 \\
            DRDG~\cite{liu2021dual} & 12.43 & 95.81 & 19.05 & 88.79 & 15.56 & 91.79 & 15.63 & 91.75 \\
            ANRL~\cite{liu2021adaptive} & 10.83 & 96.75 & 17.83 & 89.26 & 16.03 & 91.04 & 15.67 & 91.90 \\
            SSAN-M~\cite{wang2022ssan} & 10.42 & 94.76 & 16.47 & 90.81 & 14.00 & 94.58 & 19.51 & 88.17 \\
            SSDG-R~\cite{jia2020ssdg} & 7.38 & 97.17 & 10.44 & 95.94 & 11.71 & 96.59 & 15.61 & 91.54 \\
            SSAN-R~\cite{wang2022ssan} & 6.67 & \textbf{98.75} & 10.00 & \textbf{96.67} & 8.88 & 96.79 & 13.72 & 93.63 \\
            PatchNet~\cite{wang2022patchnet} & 7.10 & 98.46 & 11.33 & 94.58 & 13.40 & 95.67 & 11.82 & 95.07 \\
            % Ours (ImageNet) & 6.67 & 97 & 9.67 & 93.84 & 10.15 & 96.16 & 11.64 & 94.92 \\
            \methodname (Ours) & \textbf{5.95} & 96.55 & \textbf{8.78} & 95.37 & \textbf{6.58}  & \textbf{97.54} & \textbf{10.00} & \textbf{96.23}  \\ \bottomrule
            \end{tabular}
        }
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.28\textwidth}
        \vspace*{-40pt}
        \caption{
            \small 
            {\bf Comparisons with SoTA methods:} 
            Cross-domain face anti-spoofing is evaluated among four popular benchmark datasets: CASIA (\textbf{C}), Idiap Replay (\textbf{I}), MSU-MFSD (\textbf{M}), and Oulu-NPU (\textbf{O}). 
            Methods are compared at their best performance following the commonly used evaluation process \cite{jia2020ssdg}. 
            $\uparrow$ indicates larger values are better, and $\downarrow$ indicates smaller values are better.
        }
        \label{tab:best}
    \end{minipage}
    \vspace{-1ex}
\end{table*}

