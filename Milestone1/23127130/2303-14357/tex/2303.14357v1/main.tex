\documentclass{article}

\usepackage{spconf}




\usepackage{amsmath,graphicx}
\usepackage{amssymb}
\usepackage{latexsym}

\usepackage{algorithm}
\usepackage{algpseudocode}
\algblockdefx{ForAllP}{EndForAllP}[1]%
  {\textbf{for all }#1 \textbf{do in parallel}}%
  {\textbf{end for}} 
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
% Following three lines are needed for this document.
% If you are not loading colors or url, then these are
% not required. 
\usepackage[hyphens]{url}
\usepackage[colorlinks,urlcolor=blue]{hyperref}

\usepackage{xcolor}

% \usepackage{hyperref}

% \definecolor{newcolor}{rgb}{.8,.349,.1}

% \journal{Medical Image Analysis}

\begin{document}

% \verso{Given-name Surname \textit{et~al.}}

% \begin{frontmatter}

% % \title{Type the title of your paper, only capitalize first
% % word and proper nouns\tnoteref{tnote1}}%
% \tnotetext[tnote1]{This is an example for title footnote coding.}

% \author[1]{Given-name1 \snm{Surname1}\corref{cor1}}
% \cortext[cor1]{Corresponding author: 
%   Tel.: +0-000-000-0000;  
%   fax: +0-000-000-0000;}
% \author[1]{Given-name2 \snm{Surname2}\fnref{fn1}}
% \fntext[fn1]{This is author footnote for second author.}
% \author[2]{Given-name3 \snm{Surname3}}
% %% Third author's email
% \ead{author3@author.com}
% \author[2]{Given-name4 \snm{Surname4}}

% \address[1]{Affiliation 1, Address, City and Postal Code, Country}
% \address[2]{Affiliation 2, Address, City and Postal Code, Country}

% \received{1 May 2013}
% \finalform{10 May 2013}
% \accepted{13 May 2013}
% \availableonline{15 May 2013}
% \communicated{S. Sarkar}


% Title.
% ------
\title{Dealing with heterogeneous 3D MR Knee images: A Federated Few-Shot Learning method with dual knowledge distillation} %Do we need few-shot here? 

%Dealing with heterogeneous images: A two-stage Distillation-based Federated Few-Shot Cartilage Segmentation Method
%

\name{\parbox{\linewidth}{\centering{Xiaoxiao He$^{1}$, Chaowei Tan$^{2}$, Bo Liu$^{3}$, Liping Si$^{4,5}$, Weiwu Yao$^{4}$, Liang Zhao$^{6}$, Di Liu$^{1}$, Qilong Zhangli$^{1}$, Qi Chang$^{1}$, Kang Li$^{2}$ and Dimitris N. Metaxas$^{1}$}}}
\address{$^{1}$Department of Computer Science, Rutgers University, USA\\
$^{2}$West China Biomedical Big Data Center, Sichuan University West China Hospital, China\\
$^{3}$Walmart Global Tech, USA\\
$^{4}$Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of Medicine, China\\
$^{5}$Department of Radiology, Zhongshan Hospital, Fudan University, Shanghai, China.\\
$^{6}$SenseTime Research, China
}%限制到knee
\maketitle
\begin{abstract}
%The effectiveness of deep learning (DL) models has been demonstrated in medical imaging analysis. % into a central dataset. 
Federated Learning has gained popularity among medical institutions since it enables collaborative training between clients (e.g., hospitals) without aggregating data. However, due to the high cost associated with creating annotations, especially for large 3D image datasets, clinical institutions do not have enough supervised data for training locally. Thus, the performance of the collaborative model is subpar under limited supervision. 
%Deep learning (DL) has been a promising method for improving healthcare efficiency through automation. However, to help clinical workflow, DL model needs to be trained on local dataset due to performance drop caused by the gap in imaging quality and parameters. 
%, otherwise the accuracy will drop due to gap in imaging quality and parameters.
%Thus, clinical institutions need the ability to train DL model with their own data, which often requires sizable amount of labeled data. However, individual hospital doesn't have enough training data due to the high cost of producing high-resolution images and annotations, especially for large-sized 3D images. %Thus, the performance of DL can not reach its full potential. 
%Training a fully supervised DL model often requires gathering a sizable amount of annotated training data. 
%However, it is expensive and time-consuming for medical institutions to produce high-resolution images and annotations, especially for large-sized 3D images. 
%Furthermore, it is difficult to share private data due to privacy regulations (e.g., HIPAA, GDPR, etc.). %Therefore, a collaborative training method that preserve patients' privacy is needed.%{Thus, a novel solution that mitigates the shortage of annotated clinical images while preserving patients' privacy is needed.}%个体医疗机构视角解决问题    
On the other hand, large institutions have the resources to compile data repositories with high-resolution images and labels. Therefore, individual clients can utilize the knowledge acquired in the public data repositories to mitigate the shortage of private annotated images. In this paper, we propose a federated few-shot learning method with dual knowledge distillation. This method allows joint training with limited annotations across clients without jeopardizing privacy. The supervised learning of the proposed method extracts features from limited labeled data in each client, while the unsupervised data is used to distill both feature and response-based knowledge from a national data repository to further improve the accuracy of the collaborative model and reduce the communication cost. Extensive evaluations are conducted on 3D magnetic resonance knee images from a private clinical dataset. Our proposed method shows superior performance and less training time than other semi-supervised federated learning methods.
%Through federated learning, we eliminate the need for exchanging patient data and safeguard privacy.
% Also, we reduced the effect of inconsistent imaging parameters across datasets.
\blfootnote{Codes and additional visualization results are available at \url{https://github.com/hexiaoxiao-cs/fedml-knee}.}
\end{abstract}

\begin{keywords}
Federated Learning, Few-shot Learning, Knowledge Distillation
\end{keywords}

\section{Introduction}
\label{sec:intro}
\begin{figure}[t]
    \centering    \includegraphics[width=0.90\linewidth]{Fig-1-22.png}
    \caption{Overview of the proposed federated few-shot learning framework. We adopted the FL workflow from \cite{FedAVG}. The dual knowledge acquired from Osteoarthritis Initiative (OAI) training repository (top) is distributed to each client during initialization. Each client trains with local low-resolution support images (bottom) and returns the trained student model to the server. Both OAI and local knee MR data contain red, green, and blue annotations for femoral cartilage (FC), tibial cartilage (TC), and patellar cartilage (PC).}%不需要client round 5的backward领出来，直接caption解释
    \label{fig:overview}
    \vspace{-0.5cm}
    %After 6 rounds of server aggregation, the client will update student back to teacher.
    %  Training images contains more annotations than support images.
\end{figure}
%联邦学习的作用，直接讲
%然后搬出来半监督（对比）
%图一和图二融合 把OAI数据demonstration
%图3字小
% Deep learning method show promise in assisting medical image analysis, but they require massive training data to be widely useful. However, due to the lack of training data in clinical institution, collaboration between multiple hospitals has been increasingly popular for increasing training data, reducing the distribution bias and improving task performance \cite{Cov19Dayan,Dou:2021wd}. %Since medical data is located sporadically across multiple hospitals and relying only on the data of one site usually results the trained network performs poorly. 
% One way of collaboration is to aggregate the sporadic data into a centralized dataset so that all data can be utilized at the same time. But health data is generally considered sensitive and various regulations \cite{doi:10.1056/NEJMlim035027,gostin2009beyond,regulation2018general} raises concerns about collecting data. Aside from regulation challenges, hospitals usually do not have enough annotations on those data, since they require large amount of resources, especially for 3D images. %What challenges posed by privacy laws?
% In order to solve the challenges above, 
Federated Learning (FL) \cite{FedAVG} was introduced as a privacy-aware framework that utilizes isolated datasets without aggregating data into one location. It uses a client-server architecture where each client performs training on the local dataset, and the server aggregates models submitted by clients as indicated in Fig.~\ref{fig:overview}. This framework is suitable for medical analysis applications \cite{Cov19Dayan,Dou:2021wd}, since it enables the cooperation between medical institutions to train the same model while preserving privacy. Although FL is beneficial for ensuring privacy during collaboration, each client model still needs to be accurate for the joint model to become useful in clinical applications \cite{chang2022deeprecon, liu2022transfusion, zhangli2022region}. However, medical institutions usually lack labeled data due to insufficient annotation resources, especially for 3D images. For example, our private dataset only contains 20 labeled images per client. %, but over 1000 unlabeled data
Previously, Zhang et al. \cite{SSFL} tackled the problem of lacking annotated data by performing semi-supervised training on all clients by maximizing the expectation of pseudo labels among unlabeled data. Yang et al. \cite{FedSemiSupervised} employed the FixMatch consistency regularization among unlabeled data for better training. However, these semi-supervised methods struggle to produce an accurate segmentation network due to limited annotations. They also require more communication between clients and the server, which is challenging for institutions in remote areas. Therefore, more supervision during training is needed to reduce data traffic and improve accuracy.
% This results in a higher data traffic and subpar accuracy.
%However, with such little annotations, all these semi-supervised methods suffers from both need for more collaboration rounds to obtain a segmentation network, which is challenging for the medical institutions in the remote area, and the accuracy of the collaborative model. This results in a higher data traffic and often subpar performance. Thus, more supervision during training can help.
%Since medical institutions in the remote area have limited network access, less aggregation round is favorable.

Few-shot learning (FSL) utilizes prior knowledge acquired from a training set with sufficient annotations to guide training on the support set with limited labels for improving the accuracy of the client model. %and reducing the communication traffic %In order to extract information from the unsupervised data while reducing information exchange between client and server, a few-shot learning with prior knowledge distillation is used. 
%Also, the study contains multiple mechanism for quality control so that the imaging parameters are regulated.
%In FSL settings, we have a training set, support set and testing set. 
In our federated FSL approach, the support set located on each client utilizes our private dataset with limited supervision. The training set on the server uses the OAI repository that is heterogeneous in resolution and imaging parameters, while containing significantly more images with annotations compared to the support set. %The training set contains significantly more images with annotations. %The data repository is compiled by National Institution of Health (NIH) through a cohort study on knee-related diseases with the ability to produce abundance annotations. %NIH has enough resources to annotate the data and carry out strict quality control. 
%Deep learning-based research can benefit from the large supervision and data consistency.
Therefore, high-quality OAI data can be used to improve the accuracy of clients on their local datasets. Instead of distributing the data repository to each client for training, a pre-trained model based on OAI data is created at the server and sent to clients to reduce data traffic.
%In Fig.~\ref{fig:overview}, we demonstrate the workflow of the federated FSL and the two datasets we use. 
As shown as the 3D images in Fig.~\ref{fig:overview}, the knee cartilages are thin tissues, thus posing challenges to local training with limited supervision. Also, the image resolution of our private dataset (bottom) is significantly lower than the data repository (top), because coarse scanned images are more commonly used in clinical applications.
%Directly training with both datasets by distributing to multiple clients is not possible due to the large bandwidth requirement.
%\textcolor{brown}{One straight way of utilizing the large training set is to distributing large data repository to multiple client. However, large communication occurred in this process will slow down the FL training.}
%acquiring high resolution MR images are often time-consuming and very costly compared to coarsed scanned images. 
Such heterogeneity in resolution between the clinical dataset and the repository prohibits applying the model trained on OAI repository to the local dataset.

%However, the disparity in parameters between data repository and hospital data makes FSL favorable.
%Since the distribution of patient's characteristics could hardly be identical across medical institutions, this collaborative training is categorized as a not independent and identical distribution (non-IID) problem \cite{arxiv.2102.02079}.
% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{Fig1-3.png}
%     \caption{(a) and (b) show two 3D MR knee data from the Osteoarthritis Initiative (high resolution) and a hospital (low resolution). The red, green and blue labels indicate the femoral cartilage (FC), tibial cartilage (TC) and patellar cartilage (PC), respectively.} %解释高精度与低精度（医疗机构）的区别（想让读者get到什么点）
%     \label{fig:data-demo}
% \end{figure}


%Although FL is beneficial for collaborating between clients, each client still need to train a relatively accurate model. \cite{FedSemiSupervised} proposed a semi-supervised learning based FL framework. However, a significant portion of their data has annotations. In our private dataset, the ratio between labeled data and unlabeled data can be as high as 1:100 and contains only 20 labeled data per client. Having not enough supervised data will degrade the performance of the model. \cite{UA-MT} introduced a teacher-student framework that maximize consistency between teacher model to train the student model. The initialized teacher network requires more training to provide useful knowledge. Therefore, teacher network should have prior knowledge on the features of the target to help the training of student network.       

 %Few-shot based method has been increasingly popular for dealing dataset with limited supervision\cite{10.1007/978-3-030-87237-3_10}.  %Accordingly, we utilize a few-shot based method to extract information from the unsupervised data through prior knowledge. The prior knowledge is acquired from data repositories. %The prior knowledge is usually acquired from open data repositories. 
 %Consistency among data directly affect the performance of model performance. 

%For example, Fig.\ref{fig:data-demo} demonstrates two datasets that we use in our experiment. 
%(a) is one image from the public data repository called Osteoarthritis Initiative (OAI) \cite{doi:10.1007/s11420-011-9235-y} together with its corresponding 3D label of human knee meniscus, and (b) is from our private dataset collected by a local hospital. 

%在提前蒸馏概念

Instead of directly applying the pre-trained model, we can distill the knowledge of knee cartilages from the OAI repository to accelerate collaborative training. As illustrated in Fig.~\ref{fig:local}, our few-shot learning method contains a teacher-student architecture \cite{UA-MT} to distill the dual knowledge that consists of the response and feature-based \cite{gou2021knowledge} knowledge of the target from the pre-trained teacher model to the local student models. The response-based knowledge refers to the soft label created by the teacher network. The representation of knee cartilages produced by the encoder from the teacher network is used as feature-based knowledge. %Compared to the hard label we use as ground truth, the soft label contains the probability distribution across different class, which provides more information regarding the shape of three cartilages. 
Then offline distillation is used to transfer the dual knowledge from the pre-trained model to the client-side model through unlabeled local data. The distillation process helps each client to extract a more general feature that is not bounded to the quality of data \cite{Nguyen:2022tx,mai2021few} and reduces the time and data transfer between clients and server through dual knowledge. In parallel, supervised learning adapts the collaborative model to the local dataset through the labeled data. %Through using  , the communication cost including time and bandwidth requirement between clients and server are reduced.
% By utilizing the output of encoder from teacher model as soft label to guide the training of the student model,

%黑色部分得double check

In this paper, we propose a FL-based few-shot learning framework with dual knowledge distillation for improved segmentation of knee cartilages from 3D MR data. %We formulate our method in two parts: inter-institutional federated learning and on-premise knowledge distillation-based few-shot learning. We carried out a comprehensive analysis of our method and were able to obtain an equal or superior result with much less training time. 
%we propose a federated learning-based few-shot segmentation framework, (ii)
%we investigate a novel health-care application where prior knowledge from data repository is used to  
Our contributions are: (i) we identified the problem of limited local annotations among medical institutions and propose a few-shot learning method that utilize prior knowledge from well-annotated open data repository to train a collaborative deep learning model with few local annotations, (ii) we address the data heterogeneity problem of using Non-IID \cite{ZHU2021371} sources and a large disparity in imaging parameters between repository and local clinical data, and (iii) we identify the problem of massive data transfer associated with utilizing data repository in FL settings and solved it through prior feature extraction of the data repository.
%to reduce the time and communication cost while improving the performance and safeguard privacy, try to do
%Our method was implemented and evaluated on a private dataset.
Two state-of-the-art methods have been selected and compared to our method. Our method has shown superior performance.%拆开来
%, SSFL\cite{SSFL} and Fed-Semi\cite{FedSemiSupervised}
\vspace{-0.2cm}
\section{Methods}
\begin{figure}
    \centering
    \includegraphics[width=0.90\linewidth]{Fig-2-23.png}
    \caption{Our few-shot learning method with dual knowledge distillation in each client. The unsupervised images are used to gain response and feature-based knowledge from the teacher network and distill it to the student network. The student network is also optimized on the supervised images.}
    \label{fig:local}
\end{figure}
\label{sec:methods}
%Fig.~\ref{fig:overview} demonstrates the workflow of our federated-learning based few-shot segmentation framework with knowledge distillation. It contains inter-institutional Federated Learning and on-premise distillation-based few-shot learning.  
%, which will be implemented as leveraging the device id information from OAI DICOM files to reconstruct the imaging center dataset. 

% Then, the trained network is used to guide the training of new model with our private dataset in a knowledge transfer\cite{xie2018improving} fashion, which is indicated at the bottom of Fig.~\ref{fig:overview}. Also, because of the scarcity of manually produced labels, we took advantage of our on-premise semi-supervised learning to better train our model. Before diving into the details of the proposed method, we need to define the notations for the rest of the section. Let $C_k$ be the $k-th$ client and $A_k$ be the dataset in the $k-th$ client, and $D_k=(L_k,U_k)$ be the dataset on client $k$ with $L_k$, $U_k$ be the labeled and unlabeled data respectively. 

%理解重点
% 
%In each training round, the model received both labeled and unlabeled data. Given model input: $(x,y)\in D_l$ and $x'\in D_u$ as labeled and unlabeled data. Teacher and student network as $\mathbf{T},\mathbf{S}$, respectively. We want to minimize the loss representing the quality of the network with supervision, the response-based knowledge regularization and feature-based knowledge 
%The few-shot method utilize both unsupervised branch and supervised branch on all available images located on client.      
\textbf{Few-shot Learning with Dual Knowledge Distillation.} Fig.~\ref{fig:local} shows our client-side few-shot learning framework with supervised and dual knowledge distillation loss terms. The supervised loss consists of the cross-entropy loss and the dice loss between the segmentation of the student network $\mathbf{S}$ and the ground truth to provide feedback, defined as $L_S(\mathbf{S})$. %is distilled from the teacher network to the student network.
%In practice, hospitals may not have a lot of annotated images because of the high cost associated with annotations.
%The can be used to accelerated the training of clients.  ,

Since the private dataset is heavily unlabeled, our method guides the training on unlabeled images in the support set by exploiting the dual knowledge acquired from the training set. This helps alleviate the label shortage during training of the student network with the local images. We define the dual knowledge distillation loss $L_{DKD}$ using the response-based $L_R$ and feature-based knowledge distillation loss $L_F$.
%%In this fashion, our unsupervised branch distills a pretrained teacher network as the prior knowledge extracted from OAI data repository.

The response-based knowledge is extracted using the soft label produced by the teacher model $\mathbf{T}$. The soft label contains the probability distribution of each voxel. Thus, it contains more information compared to the binary-encoded hard label. However, the teacher may produce incorrect labels because the teacher model is trained on the OAI repository, which is different from the private data. Such incorrect segmentation needs to be identified and excluded. Inspired by \cite{UA-MT}, we estimate the uncertainty of the teacher-produced soft label by utilizing multiple scholastic passes via random dropout and adding noise to the unsupervised data to get multiple soft labels. Then predictive entropy on the soft labels is utilized to assess the uncertainty of the teacher network. The score is then used to filter unreliable predictions and select confident labels for the student to learn. This process constitutes the response-based distillation loss $L_{R}(\mathbf{T},\mathbf{S})$.

% In order to gain additional knowledge from the unlabeled images and transfer the response-based knolwedge from the pretrained network, we utilize the consistency loss $l_s(\mathbf{T},\mathbf{S};x')$。 by following the work from \cite{UA-MT}. The idea is to evaluate the uncertainty of teacher produced labels and then select teacher's most confident response to guide the training for the student model. This is achieved by using several stochastic passes on the teacher model under Monte Carlo dropouts together with input Gaussian noise for each input volume. Then the uncertainty score is estimated by predictive entropy and then used for filtering unreliable predictions while selecting only certain labels for the student to learn. 
% \begin{equation}
%     S= -\Sigma_c(\frac{1}{T}\Sigma_t(f(\mathbf{T};x')_t^c)\log(\frac{1}{T}\Sigma_t(f(\mathbf{T};x')_t^c)))
% \end{equation}
% is for calculating the predictive entropy, where $c,t$ stands for the class and the time of prediction respectively, $f(\mathbf{T};x')$ means the output of teacher network with input $x'$. The consistency loss is defined as
% \begin{align}
%     L_c(\textbf{T},\textbf{S};x')=\frac{\Sigma_{v\in x'} T(v)||f(\textbf{T};v)-f(\textbf{S};v)||^2}{\Sigma_{v\in x'}T(v)}
% \end{align}
% \begin{equation}
%     T(v)=
%     \begin{cases}
%     1 & \text{iff} ~S_v>H\\
%     0 & \text{otherwise}
%     \end{cases}
% \end{equation}
% in which $T(v)$ stands for the threshold function for filtering the uncertainty of a single vertex that is lower than the given threshold $H$.

%Here for Knowledge Distillation, we need to write why we want to have KL loss at the feature space oppose to the 
%representing the high-level feature abstraction
To further accelerate training and improve the accuracy of the collaborative model, feature-based knowledge of the teacher model is used. The idea is to capture the high-level representation of the target from the teacher network trained on the data repository. Since the teacher network is a pre-trained model, the feature maps of the teacher model are better than the randomly initialized student model. Therefore, the goal is to let the student network produce a similar set of feature vectors with the same cartilage as the teacher network to expedite the training process. %encoder of the student network will extract the semantic features that is source-independent. 
%\textcolor{red}{To fulfill this, the input image of teacher network will be weakly distorted by gaussian noise, but under this disturbance, the morphology of the cartilages remains the same.} Thus, the student network can learn generalizable features. 
With this in mind, we distill the feature-based knowledge by utilizing the KL divergence on the latent code produced by the encoder network in both the teacher and student networks. Let $\text{E}_{\mathbf{T}}$ and $\text{E}_{\mathbf{S}}$ be the encoder of teacher and student network, then $L_F(\mathbf{T},\mathbf{S})$, which is the feature-based distillation loss with input $x$, is:
\vspace{-0.2cm}
\begin{equation}
    L_F(\mathbf{T},\mathbf{S})=\sum_{j\in x}\text{E}_{\mathbf{T}}(j)\log{\frac{\text{E}_{\mathbf{T}}(j)}{\text{E}_{\mathbf{S}}(j)}}
    \vspace{-0.2cm}
\end{equation}
Therefore, the loss function $L$ of our few-shot learning is
\vspace{-0.2cm}
\begin{align}
    L(\mathbf{T},\mathbf{S})&=L_{S}(\mathbf{S})+\lambda L_{DKD}(\textbf{T},\textbf{S)} \\&= L_{S}(\mathbf{S})+\lambda(L_{R}(\mathbf{T},\mathbf{S})+L_{F}(\mathbf{T},\mathbf{S}))
    \vspace{-0.3cm}
\end{align}
where $L_S, L_{DKD}, L_R, L_F$ stands for supervised loss, dual knowledge distillation loss, response-based distillation loss, and feature-based distillation loss, respectively. $\lambda$ regularizes the supervised and dual knowledge distillation losses.

Although the teacher network can provide valuable insights in the first few rounds of training, the effectiveness of the knowledge distillation diminishes with the student model performing better on the private dataset. Eventually, the teacher model will hold back the performance of the student model. However, during the first few communication round, the student model barely contains any knowledge regarding the morphology of the cartilages. Updating the teacher network from the student network will undermine the accuracy of the teacher network. Thus, a delayed exponential moving average (EMA) update from student to teacher is applied.
%The framework contains a central server and several clients. The server is used for managing training settings, distributing and aggregating model parameters across different clients, while clients are the medical institutions which performs the knowledge distillation-based few-shot learning on the local dataset.

\noindent\textbf{Inter-institutional Federated Learning.} To share the knowledge gained from each client, we integrate our proposed few-shot learning method into the federated learning framework. No patient data will be transferred in any part of the training process. In our paper, we facilitate the federated learning framework similarly to FedAVG \cite{FedAVG} as indicated in Fig.~\ref{fig:overview}. %During training, the server collects student model from all clients and averages it to get an aggregated student model. Then the server redistributes the aggregated student model to clients and the clients perform next round training locally. 
The federated learning process is outlined in Alg.~\ref{alg:fedavg}: Let $\mathbf{S}^c_t$ be the student model weights from $c\in C$ in the synchronization round $t$:
% \vspace{-0.3cm}
\begin{algorithm} 
	\caption{In the cluster, there are $N=|C|$ clients in total, each with a learning rate of $\alpha$. The set containing all clients is denoted as $C$. The communication interval is denoted as $E$.}
	\label{alg:fedavg} 
	\begin{algorithmic}[1] 
	    \item[\textbf{Central server do:}]
	        \State Initialize student model with random weights $\mathbf{S}_0$
	        \State Load and distribute the pre-trained teacher model $\mathbf{T}$
	        \For {each communication rounds $t \in {1, ..., rounds}$}
	            \ForAllP {each client $c \in C$}
	               % \State \# Get clients improved model.
	                \State $\mathbf{S}_{t}^{c} \leftarrow$ TrainLocally$(c, \mathbf{S}_t)$ \# Collect models
	            \EndForAllP
	           % \State \# Update the global model.
	            \State $\mathbf{S}_{t+1} \leftarrow \sum_{c=0}^{N} p_{c}\mathbf{S}^{c}_t$ \# Aggregate client models
	        \EndFor 
	\item[\textbf{TrainLocally($\mathbf{S}_0$):}]
	    \For {each client iteration $e \in {1, ..., E}$}
	       % \State \# Do local model training.
	        \State $\mathbf{S}_{e} \leftarrow \mathbf{S}_{e-1} - \eta \nabla L(\mathbf{T},\mathbf{S}_{e-1})$ \# Perform local training
	    \EndFor
	    \If {$t\geq 6$}
	        \State $\mathbf{T}\leftarrow $ UpdateEMA($\mathbf{T},\mathbf{S_E}$) \# Delayed EMA update
	    \EndIf
	    \State \Return $\mathbf{S}_{E}$
	\end{algorithmic} 
\end{algorithm}
\vspace{-0.5cm}
\section{Experiments}
\begin{table*}[t]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
 & \multicolumn{3}{c|}{All Cartilages} & \multicolumn{3}{c|}{Femoral Cartilage} & \multicolumn{3}{c|}{Tibial Cartilage} & \multicolumn{3}{c}{Patellar Cartilage}\\
 \cline{2-13}
 & DSC & VOE & ASSD & DSC & VOE & ASSD & DSC & VOE & ASSD & DSC & VOE & ASSD\\
  \hline
  Local & 0.713 & 43.981 & 1.228 & 0.727 & 42.193 & 1.297 & 0.710 & 44.647 & 0.822 & 0.566 & 58.029 & 2.646\\
    \hline
Semi & 0.744 & 40.199 & 1.182 & 0.767 & 37.397 & 1.287 & 0.757 & 38.803 & 0.794 & 0.622 & 52.560 & 2.367\\
\hline
SSFL & 0.746 & 39.973 & 1.100 & 0.740 & 40.344 & 1.608 & 0.754 & 39.236 & 0.631 & 0.654 & 50.152 & 1.464\\
\hline
Fed-Semi & 0.762 & 38.310 & 0.902 & 0.763 & 38.125 & 1.022 & 0.756 & 39.063 & 0.629 & 0.673 & 48.158 & 1.500\\
\hline
Ours & \textbf{0.789} & \textbf{34.529} & \textbf{0.643} & \textbf{0.796} & \textbf{33.386} & \textbf{0.632} & \textbf{0.777} & \textbf{36.309} & \textbf{0.523} & \textbf{0.690} & \textbf{45.464} & \textbf{1.441}
    \end{tabular}
    \caption{Quantitative comparison of methods on our private dataset. The best results have been highlighted in the chart.}
    \label{tab:Comparison_btw_methods}
\end{table*}
\begin{figure*}
    \centering
    \includegraphics[width=0.83\linewidth]{Fig-3-15.png}
    \caption{Visual results of subject 1. (a) and (f) shows the GT labels; (b) and (g) are from local training; (c) and (h) are from SSFL; (d) and (i) are Fed-Semi; (e) and (j) are from our proposed method in 3D and sagittal views, respectively.}
    \label{fig:10006}
    \vspace{-0.5cm}
\end{figure*}
% Visualization results of the ground truth (a), our proposed method (b,f), local training (c,g), Fed-Semi (d,h) and SSFL (e) are shown here.      

% \begin{table*}[t]
%     \centering
%     \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
%  & \multicolumn{3}{c|}{All Cartilages} & \multicolumn{3}{c|}{Femoral Cartilage} & \multicolumn{3}{c|}{Tibial Cartilage} & \multicolumn{3}{c}{Patellar Cartilage}\\
%  \cline{2-13}
%  & Dice & VOE & ASSD & Dice & VOE & ASSD & Dice & VOE & ASSD & Dice & VOE & ASSD\\

% \hline
% Ours & \textbf{0.789} & \textbf{34.529} & \textbf{0.643} & \textbf{0.796} & \textbf{33.386} & \textbf{0.632} & \textbf{0.777} & \textbf{36.309} & \textbf{0.523} & \textbf{0.690} & \textbf{45.464} & \textbf{1.441}
%     \end{tabular}
%     \caption{Ablation Study}
%     \label{tab:ablation}
% \end{table*}
\textbf{Experiment settings.} We evaluate our method on a private dataset, which contains $20$ labeled and $1000$ unlabeled 3D MR knee images in each of the 4 clients. The voxel size (mm) of the images ranges from $(0.303, 0.303, 3.5)$ to $(0.3125, 0.3125, 4.5)$. 
%Our dataset is split into 20 supervised images and 1200 unsupervised images across 4 clients. 
The dual knowledge is extracted from the OAI repository with voxel size of $(0.365,0.365,0.7)$. % which contains five research centers. Through investigation of the study, 4 of 6 imaging device ids are used, where the MRI machines are located in site A\&E, B, C and D. Each site contains 43/4964, 28/3636, 41/4394, 26/3748 supervised/unsupervised images, respectively. 
All images are resized to $352\times 288\times 16$, and their pixel intensity has been normalized to $[0,1]$. All datasets have been split into $6:2:2$ for training, validation, and testing. We utilize U-net \cite{HeUnet} as the segmentation network. %Need Site ID here for identifying which sites we are using
%Need ST data information

Two state-of-the-art federated semi-supervised segmentation approaches, SSFL \cite{SSFL} and Fed-Semi \cite{FedSemiSupervised}, are compared. We also evaluated the performance without federated learning (Local) and without knowledge distillation (Semi). To measure accuracy and spatial correctness, dice similarity coefficient (DSC), volumetric overlap error (VOE) (mm$^3$), and average symmetric surface distance (ASSD) (mm) between the GT labels and segmentation are reported.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.70\linewidth]{Fig-4-2.png}
    %\vspace{-0.1cm}
    \caption{Visual result for subject 2. (a) SSFL and (b) Ours.}
    \label{fig:hc}
    \vspace{-0.5cm}
\end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{10636_5.png}
%     \caption{3D Visualization Results of subject 2. The ground truth (a), our proposed method (b), local training (c), Fed-Semi (d), SSFL (e) and raw image (f) are shown here.}
%     \label{fig:10636}
% \end{figure}
%We compare our method with recent federated semi-supervised methods, including SSFL\cite{SSFL}, which performs semi-supervised training on all clients by maximizing expectation of pseudo label among unlabeled data, and Fed-Semi\cite{FedSemiSupervised}, which employs the FixMatch consistency regularization among unlabeled data for better training.

\noindent \textbf{Experiment results.} As observed in Table~\ref{tab:Comparison_btw_methods}, our method outperforms both SSFL and Fed-Semi, with a DSC increase of $5.7\%$ and $3.6\%$, respectively.  %which are two state-of-the-art federated learning based method that deals with unsupervised data.
%, which reflects the benefit to utilize additional knowledge gained from data repository to help training. 
%The overall accuracy of our method as DSC is  better than the SSFL and $3.6\%$ better than Fed-Semi.
This indicates that the additional knowledge improved the training in the FL scenario. Furthermore, our 3D surface is more accurate, since the ASSD is reduced by $41\%$. By comparing our method to local training, federated learning improves DSC by $10.6\%$ for all cartilages. Prior knowledge is advantageous in small target segmentation since it provides additional information about it. For example, PC is a small cartilage, and segmenting PC is challenging since there are fewer voxels representing that cartilage. Our method has shown an increase of $11\%$ in DSC score on PC compared to those without prior knowledge. For efficiency, our method utilizes 19 communication rounds compared to 28 rounds needed by other methods, which amounts to a $32\%$ decrease in data transfer and training time. 

Fig. \ref{fig:10006} shows three cartilages of one subject with the above-mentioned methods. Comparing the white circled region, local training (b) under segments PC compared to our method (e), which confirms that the dual knowledge helps the small cartilage segmentation. Meanwhile, as indicated in the yellow circled area of Fig. \ref{fig:10006}, our method produced the most accurate result compared to other methods, which all failed to discover parts of FC. In particular, about one-third of FC produced by local training (g) is missing. This provides evidence that clients with limited labels cannot train a usable network, and collaboration between medical institutions is needed. In addition, both SSFL (h) and Fed-Semi (i) methods show discontinuous labels of FC indicating insufficient knowledge of cartilage shape compared to the proposed method. % Also, such finding indicates the improvement by using additional knowledge.
%Also, both SSFL (h) and Fed-Semi (i) failed to create continuous cartilage surface while ours (j) does not have such issue. This indicates the improvement of few-shot based learning method with additional knowledge. 
To show the stability of our method, Fig.~\ref{fig:hc} demonstrates a hard case in our dataset. The label produced by SSFL missed a significant portion of FC compared to our method, which is not acceptable for medical applications. However, our method maintains high accuracy throughout the test cases because of the additional knowledge distilled from the OAI repository.  %(e), (b), we can see the SSFL failed to create label for the majority of the FC, while our method successfully reconstruct the FC with high accuracy. %Need Speed demonstration
% EXTRA SPACE for adding analysis. Two state-of-the-art federated semi-supervised segmentation approaches are evaluated with our method. One is SSFL\cite{SSFL}, and the second is Fed-Semi\cite{FedSemiSupervised}. To evaluate accuracy and spatial correctness, dice similarity coefficient (DSC), volumetric overlap error (VOE) (mm$^3$) and average symmetric surface distance (ASSD) (mm) between the GT labels and segmentation are reported.
\vspace{-0.2cm}
\section{Conclusion}
\label{sec:conclusion}
In this work, we proposed a few-shot FL framework with dual knowledge distillation. %The prior knowledge is acquired from utilizing the OAI data repository. 
The dual knowledge, including the response and feature-based knowledge extracted from the data repository on the server side, is used to accelerate and guide the training of the student model locally using the private dataset. Our few-shot learning reduces annotation requirements in each client, and knowledge distillation mitigates the challenge of dissimilarity in imaging resolution and parameters of the training and support set. We carried out a comprehensive analysis of our method and obtained superior results. %In the future, we will explore different federated learning aggregation methods and will deploy the proposed method to large-scale studies. Aside from the knee cartilage, the proposed method could also be used on other organs or imaging modality.
\section{Compliance with Ethical Standards}
\label{sec:CES}
This research study was conducted retrospectively using human subject data including open access dataset by National Institution of Health through the Osteoarthritis Initiative and private dataset from Shanghai Sixth People's Hospital. The studies involving human participants were reviewed and approved by Ethics Committee of Shanghai Sixth People's Hospital. Written informed consent to participate in this study was provided by the participants’ legal guardian/next of kin. 
%We formulate our method in two parts: inter-institutional federated learning and on-premise knowledge distillation-based few-shot learning.  with much less training time. 

% \textbf{Pretraining with Federated Learning} In order to simulate the scenario of an intrainstitutional

% \section{Experiments}
% \label{sec:experiments}
% \textbf{Datasets} There are two knee joint dataset used in this work: 

% The public available dataset, Osteoarthritis Initiative (OAI), contains MR data from four imaging facilities. In our experiment, we will use the baseline (bl) and 12 month (12m) 3D double-echo steady-state MR images captured along the sagittal plane. There are all $9494$ images from bl dataset and $8189$ images from 12m dataset, in which $170$ of those are labeled. In order to recreate the real workflow in research institution, we separate the bl dataset into $6$ subsets and the 12m dataset into $4$ subset by the device id embedded in the DICOM files. For training, we will use 4 device ids that exists in both bl and 12m datasets for semi-supervised training, validation and testing.

% The private dataset we use to simulate individual hospital scenario contains 6100 cases where 100 of the images are labeled by experts.
% %Major headings, for example, "1. Introduction", should appear in all capital
% %ldetters, bold face if possible, centered in the column, with one blank line
% %before, and one blank line after. Use a period (".") after the heading number,
% %not a colon.

% \textbf{Evaluation Metrics} In order to evaluate the performance of our proposed method, we need to measure the quality of the produced label and compare it with the ground truth. In our experiments, dice similarity coefficient (DSC), volumetric overlap error (VOE), volumetric distance (VD), average surface distance (ASD), Hausdorff distance (HD) and average symmetric surface distance (ASSD) between the GT labels and segmented results are reported for evaluating both accuracy and spatial correctness. 

% \textbf{Implementation Details} In order to assess our framework against regular training without federated learning and other scenarios, we used the same parameters across all experiments. The segmentation network is VNet\cite{HeUnet,CTUnet} with random initialization. We used the Adam optimizer with initial learning rate $0.001$ and weight decay of $10^{-7}$. Our batch size for semi-supervised learning is 2, which contains one labeled image and one unlabeled. All labeled data will be split into training, testing and validation set with a ratio of 8:1:1.

% We train our OAI based model in a federated learning fashion by separating the dataset into four subsets according to the device ID. We assume that each of the device ID is associated with one OAI research center where the imaging machine belongs. Then, without the exchange of data, we simulated the scenario where the four research centers collaborated to train the segmentation network so that we can show the ability of our pipeline to improve both accuracy of the segmentation and the training speed by transferring the model trained in public dataset to more hospitals with different imaging quality and settings. 

% All baseline experiments are trained from scratch, and our method utilizes the OAI pretrained model. For all federated learning based experiments, we have an architecture of one server with FedAVG as the model aggregation method and four clients each running the previously stated backbone. All methods are implemented and tested with PyTorch on NVIDIA Quadro RTX 8000. We adopted the federated learning platform by He et al.\cite{chaoyanghe2020fedml}. In our semi-supervised experiments, only the student network is being aggregated while all teacher network in clients remain unchanged. For each communication round, every client will perform 20 epochs of training locally before submitting the model for aggregation. 

% \begin{table*}[]
%     \centering
%     \begin{tabular}{c|c|c|c|c|c|c}
%       & Dice & VOE & VD & ASD & HD & ASSD \\
% \hline
% OF & 0.8120 & 31.2017 & 4.6128 & 0.4145 & 20.7577 & 0.4104\\
%         \hline
% O & 0.8655 & 23.6517 & 2.1433 & 0.3103 & 17.4385 & 0.3201\\
% \hline
% \hline
% PF & 0.7832 & 35.4014 & -4.3290 & 0.5247 & 34.6097 & 0.7220 \\ 
% \hline
% P & 0.7921 & 34.1495 & -2.1026 & 0.6698 & 62.0698 & 0.7313\\
% \hline
% PL&0.6798&47.9698&29.4048&31.9941&201.6799&16.3582\\
% \hline
% \textbf{OPF}& \textbf{0.7935}&\textbf{33.8684}&-6.2912&\textbf{0.4850}&\textbf{33.1804}&\textbf{0.6160}\\
% \hline
% OPL& 0.7750&36.4307&\textbf{-0.3296}&0.9090&81.0089&0.8287\\

%     \end{tabular}
%     \caption{Quantitative segmentation performance for approaches with different datasets. Best results under each metric are highlighted.}
%     \label{tab:1}
% \end{table*}
% % across OAI with Federated learning (OF), OAI without Federated Learning (using all data) (O), Private dataset with Federated learning (\textbf{PF}), Private dataset without Federated learning (using all data) (\textbf{P}), Private dataset using only local data, OAI$\rightarrow$Private with Fed(erated learning), which is OAI model knowledge accelerated to the private dataset, and OAI$\rightarrow$ Private dataset using only local data. 
% \textbf{Results} In Tab.~\ref{tab:1}, we demonstrated the overall accuracy of the produced labels under different scenarios quantitatively. \textit{PF} denotes the results using only our private dataset with federated learning, and \textit{P} denotes the results without using federated learning. \textit{PL} stands for the experiments where the model is trained locally with our private dataset. We also presented the results that are trained utilizing prior knowledge with federated learning (\textit{\textbf{OPF}}) and locally(\textit{OPL}). For completeness, we exhibited the results of the prior knowledge acquisition on OAI dataset with (\textit{OF}) and without federated learning (\textit{O}). 

% From the Tab.~\ref{tab:1}, we can see that the proposed method(\textit{\textbf{OPF}}) achieves the best performance. Our method significantly improves the baseline \textit{PL}, where all training data is seperated and there is no collaboration between any of the sites, in about $16.7\%$. Moreover, with federated learning that aggregates model parameters from all clients, the result(\textit{\textbf{OPF}}) is higher than its offline training counterpart(\textit{OPL}). The offline training with prior knowledge(\textit{OPL}) has a performance drop compared to the centralized training(\textit{P}) while our method(\textit{\textbf{OPF}}) is equal or slightly better than the centralized training(\textit{P}), which indicates that our privacy preserved method yield equivalent result to collecting data in a centralized dataset, thus such sharing of data is not necessary. Moreover, the proposed method is slightly better than the one without knowledge transfer(\textit{PF}) but is significantly faster in training time. \textit{PF} uses about 2 days in 4 Quatro RTX 8000 GPUs while our method uses roughly 4 hours to achieve a similar result. It is worth mentioning that we see a performance dip by comparing the performance utilizing federated learning(\textit{OF}) and the one without federated learning(\textit{O}) with the OAI dataset, we noticed that there is a slight drop in dice score, which may be caused by the reduced training sample in each of the client compared to the aggregated settings. However, by utlizing our method in our private dataset, such performance drop ceases to exist. This shows that with the prior knowledge from another dataset and knowledge transfer, we can compensate the performance gap between federated learning and centralized learning.
% %Moreover, the method we used for aggregating the models from the client might not reflect the optimal point where the model converge. 

% %The proposed 
% %However, if we compare the knowledge transfer from OAI dataset to the private dataset with the one without utilizing any prior knowledge, we can see an increase in performance and also a significant drop in training time since our method only requires two communication rounds between clients to reach plateau. Comparing our method with the one without federated learning, we can see that the gap between federated learning and centralized learning is reduced compared to the OAI One and OAI with Federated learning. 
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=\linewidth]{Figure-4-3.png}
%     \caption{Comparison of 3D visualization result}
%     \label{fig:4}
% \end{figure}

% In Fig.~\ref{fig:4}, we demonstrated the 3D visualization of the segmentation result between (b) ground truth (GT), (c) locally trained model on private dataset(\textit{PL}) and (d) our prior knowledge accelerated method(\textit{\textbf{OPF}}). (a) is the MR image of all three labels and is exhibited in 3D fashion. Our method (d) generated a more similar label to the ground truth (b) than (c). As indicated in red circle of (c) and (d), the \textit{PL} method failed to segment the patellar cartilage correctly due to the uneven spike at the top of the cartilage. However, our method correctly produced the PC label and generated a smoothier boundary compared to (c).
% %Moreover,  Our method yielded a similar or even better result compared to the one training from scratch. On the left of Fig.~\ref{fig:4}, our method (red) is able to approximate the ground truth (green) at the end of the cartillage (yellow) between tibia bone and femur bone when comparing to the right. 

% \section{Conclusion}
% \label{sec:conclusion}
% In this paper, we presented a novel federated learning-based semi-supervised method that utilize public dataset for prior knowledge acceleration to segment three knee cartilage in 3D MR images. The prior knowledge is acquired from public dataset split by the location and trained distributively by utilizing semi-supervised learning in a teacher-student fashion. Because of the transferred knowledge gained from the previous model, we are able to train a more robust and accurate model on our private dataset and speed up the whole training process while reduce communication cost between the client and the server. Our on-premise semi-supervised learning enables individual institution with little label to develop segmentation model that is tailored to their data. In our experiments, our proposed method achieved accurate segmentation for all three knee cartilages with reduced training cost in each client. In the future, we will explore different federated learning aggregation methods and will deploy the proposed method to large-scale studies. Aside from the knee cartilage, the proposed method could also be used on other organs or imaging modality.
% \subsection{Subheadings}
% \label{ssec:subhead}

% Subheadings should appear in lower case (initial word capitalized) in
% boldface.  They should start at the left margin on a separate line.
 
% \subsubsection{Sub-subheadings}
% \label{sssec:subsubhead}

% Sub-subheadings, as in this paragraph, are discouraged. However, if you
% must use them, they should appear in lower case (initial word
% capitalized) and start at the left margin on a separate line, with paragraph
% text beginning on the following line.  They should be in italics.

% \section{Printing your paper}
% \label{sec:print}

% Print your properly formatted text on high-quality, 8.5 x 11-inch white printer
% paper. A4 paper is also acceptable, but please leave the extra 0.5 inch (12 mm)
% empty at the BOTTOM of the page and follow the top and left margins as
% specified.  If the last page of your paper is only partially filled, arrange
% the columns so that they are evenly balanced if possible, rather than having
% one long column.

% In \LaTeX, to start a new column (but not a new page) and help balance the
% last-page column lengths, you can use the command ``$\backslash$pagebreak'' as
% demonstrated on this page (see the \LaTeX\ source below).

% \section{Page numbering}
% \label{sec:page}

% Please do {\bf not} paginate your paper.  Page numbers, session numbers, and
% conference identification will be inserted when the paper is included in the
% proceedings.

% \section{Illustrations, graphs, and photographs}
% \label{sec:illust}

% Illustrations must appear within the designated margins.  They may span the two
% columns.  If possible, position illustrations at the top of columns, rather
% than in the middle or at the bottom.  Caption and number every illustration.
% All halftone illustrations must be clear black and white prints.  If you use
% color, make sure that the color figures are clear when printed on a black-only
% printer.

% Since there are many ways, often incompatible, of including images (e.g., with
% experimental results) in a \LaTeX\ document, below is an example of how to do
% this \cite{Lamp86}.

% % Below is an example of how to insert images. Delete the ``\vspace'' line,
% % uncomment the preceding line ``\centerline...'' and replace ``imageX.ps''
% % with a suitable PostScript file name.
% % -------------------------------------------------------------------------
% \begin{figure}[htb]

% \begin{minipage}[b]{1.0\linewidth}
%   \centering
%   \centerline{\includegraphics[width=8.5cm]{example-image}}
% %  \vspace{2.0cm}
%   \centerline{(a) Result 1}\medskip
% \end{minipage}
% %
% \begin{minipage}[b]{.48\linewidth}
%   \centering
%   \centerline{\includegraphics[width=4.0cm]{example-image}}
% %  \vspace{1.5cm}
%   \centerline{(b) Results 3}\medskip
% \end{minipage}
% \hfill
% \begin{minipage}[b]{0.48\linewidth}
%   \centering
%   \centerline{\includegraphics[width=4.0cm]{example-image}}
% %  \vspace{1.5cm}
%   \centerline{(c) Result 4}\medskip
% \end{minipage}
% %
% \caption{Example of placing a figure with experimental results.}
% \label{fig:res}
% %
% \end{figure}

% % To start a new column (but not a new page) and help balance the last-page
% % column length use \vfill\pagebreak.
% % -------------------------------------------------------------------------
% \vfill
% \pagebreak


% \section{Footnotes}
% \label{sec:foot}

% Use footnotes sparingly (or not at all!) and place them at the bottom of the
% column on the page on which they are referenced. Use Times 9-point type,
% single-spaced. To help your readers, avoid using footnotes altogether and
% include necessary peripheral observations in the text (within parentheses, if
% you prefer, as in this sentence).


% \section{Copyright forms}
% \label{sec:copyright}

% You must include your fully completed, signed IEEE copyright release form when
% you submit your paper. We {\bf must} have this form before your paper can be
% published in the proceedings.  The copyright form is available as a Word file,
% a PDF file, and an HTML file. You can also use the form sent with your author
% kit.

% \section{Referencing}
% \label{sec:ref}

% List and number all bibliographical references at the end of the
% paper.  The references can be numbered in alphabetic order or in order
% of appearance in the document.  When referring to them in the text,
% type the corresponding reference number in square brackets as shown at
% the end of this sentence \cite{C2}.

% \section{Compliance with ethical standards}
% \label{sec:ethics}

% IEEE-ISBI supports the standard requirements on the use of animal and
% human subjects for scientific and biomedical research. For all IEEE
% ISBI papers reporting data from studies involving human and/or
% animal subjects, formal review and approval, or formal review and
% waiver, by an appropriate institutional review board or ethics
% committee is required and should be stated in the papers. For those
% investigators whose Institutions do not have formal ethics review
% committees, the principles  outlined in the Helsinki Declaration of
% 1975, as revised in 2000, should be followed.

% Reporting on compliance with ethical standards is required
% (irrespective of whether ethical approval was needed for the study) in
% the paper. Authors are responsible for correctness of the statements
% provided in the manuscript. Examples of appropriate statements
% include:
% \begin{itemize}
%   \item ``This is a numerical simulation study for which no ethical
%     approval was required.'' 
%   \item ``This research study was conducted retrospectively using
%     human subject data made available in open access by (Source
%     information). Ethical approval was not required as confirmed by
%     the license attached with the open access data.''
%     \item ``This study was performed in line with the principles of
%       the Declaration of Helsinki. Approval was granted by the Ethics
%       Committee of University B (Date.../No. ...).''
% \end{itemize}


% \section{Acknowledgments}
% \label{sec:acknowledgments}

% IEEE-ISBI supports the disclosure of financial support for the project
% as well as any financial and personal relationships of the author that
% could create even the appearance of bias in the published work. The
% authors must disclose any agency or individual that provided financial
% support for the work as well as any personal or financial or
% employment relationship between any author and the sources of
% financial support for the work.

% Other types of acknowledgements can also be listed in this section.

% Reporting on real or potential conflicts of interests, or the absence
% thereof, is required in the paper. Authors are responsible for
% correctness of the statements provided in the manuscript. Examples of
% appropriate statements include:
% \begin{itemize}
%   \item ``No funding was received for conducting this study. The
%     authors have no relevant financial or non-financial interests to
%     disclose.'' 
%   \item ``This work was supported by […] (Grant numbers) and
%     […]. Author X has served on advisory boards for Company Y.'' 
%   \item ``Author X is partially funded by Y. Author Z is a Founder and
%     Director for Company C.''
% \end{itemize}

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% ------------------------------------------------------------------------- 
\bibliographystyle{IEEEbib}
% \bibliographystyle{model2-names.bst}
% \biboptions{authoryear}
\bibliography{refs.bib}

\end{document}
