{
    "arxiv_id": "2303.08964",
    "paper_title": "CS-TGN: Community Search via Temporal Graph Neural Networks",
    "authors": [
        "Farnoosh Hashemi",
        "Ali Behrouz",
        "Milad Rezaei Hajidehi"
    ],
    "submission_date": "2023-03-15",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SI",
        "cs.LG"
    ],
    "abstract": "Searching for local communities is an important research challenge that allows for personalized community discovery and supports advanced data analysis in various complex networks, such as the World Wide Web, social networks, and brain networks. The evolution of these networks over time has motivated several recent studies to identify local communities in temporal networks. Given any query nodes, Community Search aims to find a densely connected subgraph containing query nodes. However, existing community search approaches in temporal networks have two main limitations: (1) they adopt pre-defined subgraph patterns to model communities, which cannot find communities that do not conform to these patterns in real-world networks, and (2) they only use the aggregation of disjoint structural information to measure quality, missing the dynamic of connections and temporal properties. In this paper, we propose a query-driven Temporal Graph Convolutional Network (CS-TGN) that can capture flexible community structures by learning from the ground-truth communities in a data-driven manner. CS-TGN first combines the local query-dependent structure and the global graph embedding in each snapshot of the network and then uses a GRU cell with contextual attention to learn the dynamics of interactions and update node embeddings over time. We demonstrate how this model can be used for interactive community search in an online setting, allowing users to evaluate the found communities and provide feedback. Experiments on real-world temporal graphs with ground-truth communities validate the superior quality of the solutions obtained and the efficiency of our model in both temporal and interactive static settings.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08964v1"
    ],
    "publication_venue": "This is the author's version of the paper. Published in companion proceedings of the ACM Web Conference 2023 (WWW '23 Companion)",
    "doi": "10.1145/3543873.3587654"
}