@article{lim1990two,
  title={Two-dimensional signal and image processing},
  author={Lim, Jae S},
  journal={Englewood Cliffs},
  year={1990}
}

@book{schalkoff1989digital,
  title={Digital Image Processing and Computer Vision: An Introduction to Theory and Implementations},
  author={Schalkoff, Robert J},
  year={1989},
  publisher={John Wiley \& Sons, Inc.}
}

@book{jain1989fundamentals,
  title={Fundamentals of digital image processing},
  author={Jain, Anil K},
  year={1989},
  publisher={Prentice-Hall, Inc.}
}

% temporal wiener
@inproceedings{ozkan1992motion,
  title={Motion-adaptive weighted averaging for temporal filtering of noisy image sequences},
  author={Ozkan, Mehmet K and Sezan, M Ibrahim and Tekalp, A Murat},
  booktitle={Image Processing Algorithms and Techniques III},
  volume={1657},
  pages={201--212},
  year={1992},
  organization={International Society for Optics and Photonics}
}

@inproceedings{sezan1991temporally,
  title={Temporally adaptive filtering of noisy image sequences using a robust motion estimation algorithm},
  author={Sezan, M Ibrahim and Ozkan, Mehmet K and Fogel, Sergei V},
  booktitle={Acoustics, Speech, and Signal Processing, IEEE International Conference on},
  pages={2429--2430},
  year={1991},
  organization={IEEE Computer Society}
}

@inproceedings{ozkan1991lmmse,
  title={LMMSE restoration of blurred and noisy image sequences},
  author={Ozkan, Mehmet K and Sezan, M Ibrahim and Erdem, A Tanju and Tekalp, A Murat},
  booktitle={Visual Communications and Image Processing'91: Image Processing},
  volume={1606},
  pages={743--754},
  year={1991},
  organization={International Society for Optics and Photonics}
}

%ANIL
@inproceedings{van1998noise,
  title={Noise reduction of image sequences as preprocessing for mpeg2 encoding},
  author={van Roosmalen, Peter MB and Kokaram, Anil C and Biemond, Jan},
  booktitle={9th European Signal Processing Conference (EUSIPCO 1998)},
  pages={1--4},
  year={1998},
  organization={IEEE}
}

@article{kokaram19943d,
  title={3D Wiener filtering for noise suppression in motion picture sequences using overlapped processing},
  author={Kokaram, AC},
  journal={Signal Processing VII, Vol3},
  pages={1780--1783},
  year={1994}
}

@book{anilbook,
author = {Kokaram, Anil C.},
title = {Motion Picture Restoration: Digital Algorithms for Artefact Suppression in Degraded Motion Picture Film and Video},
year = {1998},
isbn = {3540760407},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
edition = {1st},
}


@inproceedings{
Mohan2020Robust,
title={Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks},
author={Sreyas Mohan and Zahra Kadkhodaie and Eero P. Simoncelli and Carlos Fernandez-Granda},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJlSmC4FPS}
}

@article{ozkan1992efficient,
  title={Efficient multiframe Wiener restoration of blurred and noisy image sequences},
  author={Ozkan, Mehmet K and Erdem, A Tanju and Sezan, M Ibrahim and Tekalp, A Murat},
  journal={IEEE Transactions on Image Processing},
  volume={1},
  number={4},
  pages={453--476},
  year={1992},
  publisher={IEEE}
}


% ########## CLASSIC TECHNIQUES ###############
@book{wiener1949extrapolation,
  title={Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications},
  author={Wiener, Norbert and Wiener, Norbert and Mathematician, Cyberneticist and Wiener, Norbert and Wiener, Norbert and Math{\'e}maticien, Cybern{\'e}ticien},
  volume={113},
  number={21},
  year={1949},
  publisher={MIT press Cambridge, MA}
}


@article{lindenbaum1994gabor,
  title={On Gabor's contribution to image enhancement},
  author={Lindenbaum, Michael and Fischer, M and Bruckstein, A},
  journal={Pattern recognition},
  volume={27},
  number={1},
  pages={1--8},
  year={1994},
  publisher={Elsevier}
}

% Wiener

@inproceedings{dekeyser2000spatio,
  title={Spatio-temporal Wiener filtering of image sequences using a parametric motion model},
  author={Dekeyser, Fabien and Bouthemy, Patrick and P{\'e}rez, Patrick},
  booktitle={Proceedings 2000 International Conference on Image Processing (Cat. No. 00CH37101)},
  volume={1},
  pages={208--211},
  year={2000},
  organization={IEEE}
}


@phdthesis{vaseghi1988algorithms,
  title={Algorithms for restoration of archived gramophone recordings.},
  author={Vaseghi, Saeed V},
  year={1988},
  school={University of Cambridge}
}

%wiener images only
@article{king1983wiener,
  title={A Wiener filter for nuclear medicine images},
  author={King, Michael A and Doherty, Paul W and Schwinger, Ronald B and Penney, Bill C},
  journal={Medical physics},
  volume={10},
  number={6},
  pages={876--880},
  year={1983},
  publisher={Wiley Online Library}
}

@article{giger1984investigation,
  title={Investigation of basic imaging properties in digital radiography. 2. Noise Wiener spectrum},
  author={Giger, Maryellen Lissak and Doi, Kunio and Metz, Charles E},
  journal={Medical physics},
  volume={11},
  number={6},
  pages={797--805},
  year={1984},
  publisher={Wiley Online Library}
}

% General spatial filtering: mean 
@article{pratt1972generalized,
  title={Generalized Wiener filtering computation techniques},
  author={Pratt, William K},
  journal={IEEE Transactions on Computers},
  volume={100},
  number={7},
  pages={636--641},
  year={1972},
  publisher={IEEE}
}

@book{gonzalez2009digital,
  title={Digital image processing},
  author={Gonzalez, Rafael C},
  year={2009},
  publisher={Pearson education india}
}

% bilateral
@inproceedings{tomasi1998bilateral,
  title={Bilateral filtering for gray and color images},
  author={Tomasi, Carlo and Manduchi, Roberto},
  booktitle={Sixth international conference on computer vision (IEEE Cat. No. 98CH36271)},
  pages={839--846},
  year={1998},
  organization={IEEE}
}
%anisiotropic filtering
@article{yang1996structure,
  title={Structure adaptive anisotropic image filtering},
  author={Yang, Guang-Zhong and Burger, Peter and Firmin, David N and Underwood, SR},
  journal={Image and Vision Computing},
  volume={14},
  number={2},
  pages={135--145},
  year={1996},
  publisher={Elsevier}
}

% kerel regression
@article{takeda2007kernel,
  title={Kernel regression for image processing and reconstruction},
  author={Takeda, Hiroyuki and Farsiu, Sina and Milanfar, Peyman},
  journal={IEEE Transactions on image processing},
  volume={16},
  number={2},
  pages={349--366},
  year={2007},
  publisher={IEEE}
}

@article{bouboulis2010adaptive,
  title={Adaptive kernel-based image denoising employing semi-parametric regularization},
  author={Bouboulis, Pantelis and Slavakis, Konstantinos and Theodoridis, Sergios},
  journal={IEEE Transactions on Image Processing},
  volume={19},
  number={6},
  pages={1465--1479},
  year={2010},
  publisher={IEEE}
}

% medical tomorgraphy summary
@article{zohair2015latest,
  title={Latest methods of image enhancement and restoration for computed tomography: a concise review},
  author={Zohair, AL-AMEEN and Shamil, AL-AMEEN and Sulong, Ghazali},
  journal={Applied Medical Informatics.},
  volume={36},
  number={1},
  pages={1--12},
  year={2015}
}
% wiener
@inproceedings{benesty2010study,
  title={Study of the widely linear Wiener filter for noise reduction},
  author={Benesty, Jacob and Chen, Jingdong and Huang, Yiteng},
  booktitle={2010 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={205--208},
  year={2010},
  organization={IEEE}
}

% Median filter
@article{yang1995optimal,
  title={Optimal weighted median filtering under structural constraints},
  author={Yang, Ruikang and Yin, Lin and Gabbouj, Moncef and Astola, Jaakko and Neuvo, Yrj{\"o}},
  journal={IEEE transactions on signal processing},
  volume={43},
  number={3},
  pages={591--604},
  year={1995},
  publisher={IEEE}
}

%nonlineear filter book ioannis
@book{pitas2013nonlinear,
  title={Nonlinear digital filters: principles and applications},
  author={Pitas, Ioannis and Venetsanopoulos, Anastasios N},
  volume={84},
  year={2013},
  publisher={Springer Science \& Business Media}
}

% tv reluariser
@article{rudin1992nonlinear,
  title={Nonlinear total variation based noise removal algorithms},
  author={Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
  journal={Physica D: nonlinear phenomena},
  volume={60},
  number={1-4},
  pages={259--268},
  year={1992},
  publisher={Elsevier}
}

% artefacts
@article{chambolle2011first,
  title={A first-order primal-dual algorithm for convex problems with applications to imaging},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Journal of mathematical imaging and vision},
  volume={40},
  number={1},
  pages={120--145},
  year={2011},
  publisher={Springer}
}

@inproceedings{rudin1994total,
  title={Total variation based image restoration with free local constraints},
  author={Rudin, Leonid I and Osher, Stanley},
  booktitle={Proceedings of 1st international conference on image processing},
  volume={1},
  pages={31--35},
  year={1994},
  organization={IEEE}
}

@article{vogel1996iterative,
  title={Iterative methods for total variation denoising},
  author={Vogel, Curtis R and Oman, Mary E},
  journal={SIAM Journal on Scientific Computing},
  volume={17},
  number={1},
  pages={227--238},
  year={1996},
  publisher={SIAM}
}

%new tv reg

@article{lou2015weighted,
  title={A weighted difference of anisotropic and isotropic total variation model for image processing},
  author={Lou, Yifei and Zeng, Tieyong and Osher, Stanley and Xin, Jack},
  journal={SIAM Journal on Imaging Sciences},
  volume={8},
  number={3},
  pages={1798--1823},
  year={2015},
  publisher={SIAM}
}

@article{hu2012higher,
  title={Higher degree total variation (HDTV) regularization for image recovery},
  author={Hu, Yue and Jacob, Mathews},
  journal={IEEE Transactions on Image Processing},
  volume={21},
  number={5},
  pages={2559--2571},
  year={2012},
  publisher={IEEE}
}

@article{beck2009fast,
  title={Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems},
  author={Beck, Amir and Teboulle, Marc},
  journal={IEEE transactions on image processing},
  volume={18},
  number={11},
  pages={2419--2434},
  year={2009},
  publisher={IEEE}
}

%NSS
@article{gilboa2009nonlocal,
  title={Nonlocal operators with applications to image processing},
  author={Gilboa, Guy and Osher, Stanley},
  journal={Multiscale Modeling \& Simulation},
  volume={7},
  number={3},
  pages={1005--1028},
  year={2009},
  publisher={SIAM}
}

@inproceedings{buades2005non,
  title={A non-local algorithm for image denoising},
  author={Buades, Antoni and Coll, Bartomeu and Morel, J-M},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={60--65},
  year={2005},
  organization={IEEE}
}

% NSS performance - speed
@article{mahmoudi2005fast,
  title={Fast image and video denoising via nonlocal means of similar neighborhoods},
  author={Mahmoudi, Mona and Sapiro, Guillermo},
  journal={IEEE signal processing letters},
  volume={12},
  number={12},
  pages={839--842},
  year={2005},
  publisher={IEEE}
}

@article{coupe2008optimized,
  title={An optimized blockwise nonlocal means denoising filter for 3-D magnetic resonance images},
  author={Coup{\'e}, Pierrick and Yger, Pierre and Prima, Sylvain and Hellier, Pierre and Kervrann, Charles and Barillot, Christian},
  journal={IEEE transactions on medical imaging},
  volume={27},
  number={4},
  pages={425--441},
  year={2008},
  publisher={IEEE}
}

@article{thaipanich2010improved,
  title={Improved image denoising with adaptive nonlocal means (ANL-means) algorithm},
  author={Thaipanich, Tanaphol and Oh, Byung Tae and Wu, Ping-Hao and Xu, Daru and Kuo, C-C Jay},
  journal={IEEE Transactions on Consumer Electronics},
  volume={56},
  number={4},
  pages={2623--2630},
  year={2010},
  publisher={IEEE}
}

@inproceedings{goossens2008improved,
  title={An improved non-local denoising algorithm},
  author={Goossens, Bart and Luong, Hi{\^e}p and Pizurica, Aleksandra and Philips, Wilfried},
  booktitle={2008 International Workshop on Local and Non-Local Approximation in Image Processing (LNLA 2008)},
  pages={143--156},
  year={2008}
}
@inproceedings{pang2009fast,
  title={A fast NL-means method in image denoising based on the similarity of spatially sampled pixels},
  author={Pang, Chao and Au, Oscar C and Dai, Jingjing and Yang, Wen and Zou, Feng},
  booktitle={2009 IEEE International Workshop on Multimedia Signal Processing},
  pages={1--4},
  year={2009},
  organization={IEEE}
}

@inproceedings{wang2006fast,
  title={Fast non-local algorithm for image denoising},
  author={Wang, Jin and Guo, Yanwen and Ying, Yiting and Liu, Yanli and Peng, Qunsheng},
  booktitle={2006 International Conference on Image Processing},
  pages={1429--1432},
  year={2006},
  organization={IEEE}
}
% NSS performance - performance
@inproceedings{tschumperle2009non,
  title={Non-local image smoothing by applying anisotropic diffusion PDE's in the space of patches},
  author={Tschumperl{\'e}, David and Brun, Luc},
  booktitle={2009 16th IEEE International Conference on Image Processing (ICIP)},
  pages={2957--2960},
  year={2009},
  organization={IEEE}
}

@article{grewenig2011rotationally,
  title={Rotationally invariant similarity measures for nonlocal image denoising},
  author={Grewenig, Sven and Zimmer, Sebastian and Weickert, Joachim},
  journal={Journal of Visual Communication and Image Representation},
  volume={22},
  number={2},
  pages={117--130},
  year={2011},
  publisher={Elsevier}
}

@article{fan2018nonlocal,
  title={Nonlocal image denoising using edge-based similarity metric and adaptive parameter selection.},
  author={Fan, Linwei and Li, Xuemei and Guo, Qiang and Zhang, Caiming},
  journal={Sci. China Inf. Sci.},
  volume={61},
  number={4},
  pages={049101--1},
  year={2018}
}

%
% low rank minimisation
@book{markovsky2012low,
  title={Low rank approximation: algorithms, implementation, applications},
  author={Markovsky, Ivan},
  volume={906},
  year={2012},
  publisher={Springer}
}
@inproceedings{liu2010robust,
  title={Robust subspace segmentation by low-rank representation.},
  author={Liu, Guangcan and Lin, Zhouchen and Yu, Yong and others},
  booktitle={Icml},
  volume={1},
  pages={8},
  year={2010},
  organization={Citeseer}
}

@inproceedings{ji2010robust,
  title={Robust video denoising using low rank matrix completion},
  author={Ji, Hui and Liu, Chaoqiang and Shen, Zuowei and Xu, Yuhong},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={1791--1798},
  year={2010},
  organization={IEEE}
}

@article{ji2011robust,
  title={Robust video restoration by joint sparse and low rank matrix approximation},
  author={Ji, Hui and Huang, Sibin and Shen, Zuowei and Xu, Yuhong},
  journal={SIAM Journal on Imaging Sciences},
  volume={4},
  number={4},
  pages={1122--1142},
  year={2011},
  publisher={SIAM}
}

@article{xinyan2014image,
  title={Image denoising of low-rank matrix recovery via joint frobenius norm},
  author={Xinyan, Liu and Jie, Ma and Xiaomei, Zhang and Zhaozheng, Hu},
  journal={J. Image Graph.},
  volume={19},
  number={4},
  pages={502--511},
  year={2014}
}

@article{yuan2013lse,
  title={The LSE model to denoise mixed noise in images},
  author={Yuan, Zhen and Lin, XB and Wang, XN},
  journal={J Signal Process},
  volume={29},
  number={10},
  pages={1329--1335},
  year={2013}
}

@article{dong2012nonlocal,
  title={Nonlocal image restoration with bilateral variance estimation: a low-rank approach},
  author={Dong, Weisheng and Shi, Guangming and Li, Xin},
  journal={IEEE transactions on image processing},
  volume={22},
  number={2},
  pages={700--711},
  year={2012},
  publisher={IEEE}
}

@article{eriksson2012efficient,
  title={Efficient computation of robust weighted low-rank matrix approximations using the L\_1 norm},
  author={Eriksson, Anders and Van Den Hengel, Anton},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={34},
  number={9},
  pages={1681--1690},
  year={2012},
  publisher={IEEE}
}

@inproceedings{liu2012fixed,
  title={Fixed-rank representation for unsupervised visual learning},
  author={Liu, Risheng and Lin, Zhouchen and De la Torre, Fernando and Su, Zhixun},
  booktitle={2012 ieee conference on computer vision and pattern recognition},
  pages={598--605},
  year={2012},
  organization={IEEE}
}

@article{guo2015efficient,
  title={An efficient SVD-based method for image denoising},
  author={Guo, Qiang and Zhang, Caiming and Zhang, Yunfeng and Liu, Hui},
  journal={IEEE transactions on Circuits and Systems for Video Technology},
  volume={26},
  number={5},
  pages={868--880},
  year={2015},
  publisher={IEEE}
}

@article{cai2010singular,
  title={A singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and Cand{\`e}s, Emmanuel J and Shen, Zuowei},
  journal={SIAM Journal on optimization},
  volume={20},
  number={4},
  pages={1956--1982},
  year={2010},
  publisher={SIAM}
}

@article{gu2017weighted,
  title={Weighted nuclear norm minimization and its applications to low level vision},
  author={Gu, Shuhang and Xie, Qi and Meng, Deyu and Zuo, Wangmeng and Feng, Xiangchu and Zhang, Lei},
  journal={International journal of computer vision},
  volume={121},
  number={2},
  pages={183--208},
  year={2017},
  publisher={Springer}
}


@inproceedings{gu2014weighted,
  title={Weighted nuclear norm minimization with application to image denoising},
  author={Gu, Shuhang and Zhang, Lei and Zuo, Wangmeng and Feng, Xiangchu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2862--2869},
  year={2014}
}

@inproceedings{jung2001introduction,
  title={An introduction to a new data analysis tool: Independent component analysis},
  author={Jung, Andreas},
  booktitle={Proceedings of Workshop GK" Nonlinearity"-Regensburg},
  year={2001}
}

@inproceedings{hyvarinen1998image,
  title={Image feature extraction by sparse coding and independent component analysis},
  author={Hyvarinen, Aapo and Oja, Erkki and Hoyer, Patrik and Hurri, Jarmo},
  booktitle={Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No. 98EX170)},
  volume={2},
  pages={1268--1273},
  year={1998},
  organization={IEEE}
}

@article{zhang2010two,
  title={Two-stage image denoising by principal component analysis with local pixel grouping},
  author={Zhang, Lei and Dong, Weisheng and Zhang, David and Shi, Guangming},
  journal={Pattern recognition},
  volume={43},
  number={4},
  pages={1531--1549},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{muresan2003adaptive,
  title={Adaptive principal components and image denoising},
  author={Muresan, D Darian and Parks, Thomas W},
  booktitle={Proceedings 2003 International Conference on Image Processing (Cat. No. 03CH37429)},
  volume={1},
  pages={I--101},
  year={2003},
  organization={IEEE}
}

% wavelet
@article{mallat1989theory,
  title={A theory for multiresolution signal decomposition: the wavelet representation},
  author={Mallat, Stephane G},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={11},
  number={7},
  pages={674--693},
  year={1989},
  publisher={Ieee}
}

@article{combettes2004wavelet,
  title={Wavelet-constrained image restoration},
  author={Combettes, Patrick L and Pesquet, Jean-Christophe},
  journal={International Journal of Wavelets, Multiresolution and Information Processing},
  volume={2},
  number={04},
  pages={371--389},
  year={2004},
  publisher={World Scientific}
}

@article{da2013adaptive,
  title={Adaptive edge-preserving image denoising using wavelet transforms},
  author={Da Silva, Ricardo Dutra and Minetto, Rodrigo and Schwartz, William Robson and Pedrini, Helio},
  journal={Pattern analysis and applications},
  volume={16},
  number={4},
  pages={567--580},
  year={2013},
  publisher={Springer}
}

@article{malfait1997wavelet,
  title={Wavelet-based image denoising using a Markov random field a priori model},
  author={Malfait, Maurits and Roose, Dirk},
  journal={IEEE Transactions on image processing},
  volume={6},
  number={4},
  pages={549--565},
  year={1997},
  publisher={IEEE}
}

@article{portilla2003image,
  title={Image denoising using scale mixtures of Gaussians in the wavelet domain},
  author={Portilla, Javier and Strela, Vasily and Wainwright, Martin J and Simoncelli, Eero P},
  journal={IEEE Transactions on Image processing},
  volume={12},
  number={11},
  pages={1338--1351},
  year={2003},
  publisher={IEEE}
}

@inproceedings{strela2001denoising,
  title={Denoising via block Wiener filtering in wavelet domain},
  author={Strela, Vasily},
  booktitle={European Congress of Mathematics},
  pages={619--625},
  year={2001},
  organization={Springer}
}

@book{haar1909theorie,
  title={Zur theorie der orthogonalen funktionensysteme},
  author={Haar, Alfred},
  year={1909},
  publisher={Georg-August-Universitat, Gottingen.}
}

% bm3d
@article{dabov2007image,
  title={Image denoising by sparse 3-D transform-domain collaborative filtering},
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  journal={IEEE Transactions on image processing},
  volume={16},
  number={8},
  pages={2080--2095},
  year={2007},
  publisher={IEEE}
}

@inproceedings{dabov2009bm3d,
  title={BM3D image denoising with shape-adaptive principal component analysis},
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  booktitle={SPARS'09-Signal Processing with Adaptive Sparse Structured Representations},
  year={2009}
}

@article{maggioni2012nonlocal,
  title={Nonlocal transform-domain filter for volumetric data denoising and reconstruction},
  author={Maggioni, Matteo and Katkovnik, Vladimir and Egiazarian, Karen and Foi, Alessandro},
  journal={IEEE transactions on image processing},
  volume={22},
  number={1},
  pages={119--133},
  year={2012},
  publisher={IEEE}
}

@misc{WinNT,
  title = {{Image and video denoising by sparse 3D transform-domain collaborative filtering} Kernel Description},
  howpublished = {\url{https://webpages.tuni.fi/foi/GCF-BM3D/index.html\#ref_papers}},
  note = {Accessed: 2022-05-30}
}


% references from ml section of last report 
@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@misc{lehtinen2018noise2noise,
    title={Noise2Noise: Learning Image Restoration without Clean Data},
    author={Jaakko Lehtinen and Jacob Munkberg and Jon Hasselgren and Samuli Laine and Tero Karras and Miika Aittala and Timo Aila},
    year={2018},
    eprint={1803.04189},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}
        
@misc{noauthor_cmos/ccd_nodate,
	title = {{CMOS}/{CCD} {Sensors} and {Camera} {Systems}, {Second} {Edition} {\textbar} (2011) {\textbar} {Holst} {\textbar} {Publications} {\textbar} {Spie}},
	url = {https://spie.org/Publications/Book/890909},
	urldate = {2019-12-02},
	file = {CMOS/CCD Sensors and Camera Systems, Second Edition | (2011) | Holst | Publications | Spie:C\:\\Users\\Clement\\Zotero\\storage\\QDZCAWNU\\890909.html:text/html}
}
@misc{burkimsher_2018, title={Noteworth - The Journal Blog}, url={https://blog.usejournal.com/making-of-a-chinese-characters-dataset-92d4065cc7cc}, journal={Noteworth - The Journal Blog}, author={Burkimsher, Peter Burkimsher Peter}, year={2018}, month={6}}

@inproceedings{szegedy_inception-v4_2017,
	title = {Inception-v4, {Inception}-{ResNet} and the {Impact} of {Residual} {Connections} on {Learning}},
	copyright = {Authors who publish a paper in this conference agree to the following terms:   Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.  Author(s) retain all proprietary rights other than copyright (such as patent rights).  Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.  Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14806},
	abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08\% top-5 error on the test set of the ImageNet classification (CLS) challenge.},
	language = {en},
	urldate = {2019-11-12},
	booktitle = {Thirty-{First} {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A.},
	month = feb,
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\Clement\\Zotero\\storage\\WU6SWTF3\\Szegedy et al. - 2017 - Inception-v4, Inception-ResNet and the Impact of R.pdf:application/pdf;Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\GAJSX3YG\\14806.html:text/html}
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html},
	urldate = {2019-11-12},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2016},
	pages = {770--778},
	file = {Full Text PDF:C\:\\Users\\Clement\\Zotero\\storage\\L3LF7BWX\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf;Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\YIKQM3LC\\He_Deep_Residual_Learning_CVPR_2016_paper.html:text/html}
}

@article{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2019-11-12},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Clement\\Zotero\\storage\\6DIFQ4C4\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\V39CCBNU\\1409.html:text/html}
}

@article{heinrich_residual_2018,
	title = {Residual {U}-{Net} {Convolutional} {Neural} {Network} {Architecture} for {Low}-{Dose} {CT} {Denoising}},
	volume = {4},
	issn = {2364-5504},
	url = {http://www.degruyter.com/view/j/cdbme.2018.4.issue-1/cdbme-2018-0072/cdbme-2018-0072.xml},
	doi = {10.1515/cdbme-2018-0072},
	abstract = {Low-dose CT has received increasing attention in the recent years and is considered a promising method to reduce the risk of cancer in patients. However, the reduction of the dosage leads to quantum noise in the raw data, which is carried on in the reconstructed images. Two different multilayer convolutional neural network (CNN) architectures for the denoising of CT images are investigated. ResFCN is based on a fully-convolutional network that consists of three blocks of 5 × 5 convolutions filters and a ResUNet that is trained with 10 convolutional blocks that are arranged in a multi-scale fashion. Both architectures feature a residual connection of the input image to ease learning. Training images are based on realistic simulations by using the XCAT phantom. The ResUNet approach shows the most promising results with a peak signal to noise ratio of 44.00 compared to ResFCN with 41.79.},
	language = {en},
	number = {1},
	urldate = {2019-11-12},
	journal = {Current Directions in Biomedical Engineering},
	author = {Heinrich, Mattias P. and Stille, Maik and Buzug, Thorsten M.},
	month = sep,
	year = {2018},
	pages = {297--300},
	file = {Heinrich et al. - 2018 - Residual U-Net Convolutional Neural Network Archit.pdf:C\:\\Users\\Clement\\Zotero\\storage\\LVVYXTQ6\\Heinrich et al. - 2018 - Residual U-Net Convolutional Neural Network Archit.pdf:application/pdf}
}

@article{ronneberger_u-net:_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more eﬃciently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caﬀe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	urldate = {2019-11-12},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:C\:\\Users\\Clement\\Zotero\\storage\\NI9FTTAI\\Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf}
}

@incollection{ciresan_deep_2012,
	title = {Deep {Neural} {Networks} {Segment} {Neuronal} {Membranes} in {Electron} {Microscopy} {Images}},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	urldate = {2019-11-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Ciresan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {2843--2851},
	file = {NIPS Full Text PDF:C\:\\Users\\Clement\\Zotero\\storage\\YGCU25FF\\Ciresan et al. - 2012 - Deep Neural Networks Segment Neuronal Membranes in.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\3WQIC524\\4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.html:text/html}
}

@article{long_fully_nodate,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixelsto-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efﬁcient inference and learning. We deﬁne and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classiﬁcation networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by ﬁne-tuning [3] to the segmentation task. We then deﬁne a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, ﬁne layer to produce accurate and detailed segmentations. Our fully convolutional network achieves stateof-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one ﬁfth of a second for a typical image.},
	language = {en},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	pages = {10},
	file = {Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:C\:\\Users\\Clement\\Zotero\\storage\\4MEXAWUL\\Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf}
}

@article{xie_holistically-nested_nodate,
	title = {Holistically-{Nested} {Edge} {Detection}},
	abstract = {We develop a new edge detection algorithm that addresses two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning. Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets. HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to resolve the challenging ambiguity in edge and object boundary detection. We signiﬁcantly advance the state-of-the-art on the BSD500 dataset (ODS F-score of .782) and the NYU Depth dataset (ODS F-score of .746), and do so with an improved speed (0.4s per image) that is orders of magnitude faster than some recent CNN-based edge detection algorithms.},
	language = {en},
	author = {Xie, Saining and Tu, Zhuowen},
	pages = {9},
	file = {Xie and Tu - Holistically-Nested Edge Detection.pdf:C\:\\Users\\Clement\\Zotero\\storage\\T2VINDBT\\Xie and Tu - Holistically-Nested Edge Detection.pdf:application/pdf}
}

@article{zhang_beyond_2017,
	title = {Beyond a {Gaussian} {Denoiser}: {Residual} {Learning} of {Deep} {CNN} for {Image} {Denoising}},
	volume = {26},
	issn = {1057-7149, 1941-0042},
	shorttitle = {Beyond a {Gaussian} {Denoiser}},
	url = {http://arxiv.org/abs/1608.03981},
	doi = {10.1109/TIP.2017.2662206},
	abstract = {Discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise (AWGN) at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks such as Gaussian denoising, single image super-resolution and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.},
	number = {7},
	urldate = {2019-11-16},
	journal = {IEEE Transactions on Image Processing},
	author = {Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},
	month = jul,
	year = {2017},
	note = {arXiv: 1608.03981
version: 1},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {3142--3155},
	file = {arXiv Fulltext PDF:C\:\\Users\\Clement\\Zotero\\storage\\446T8DYX\\Zhang et al. - 2017 - Beyond a Gaussian Denoiser Residual Learning of D.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\AGXWL2UY\\1608.html:text/html}
}

@article{chen_trainable_2017,
	title = {Trainable {Nonlinear} {Reaction} {Diffusion}: {A} {Flexible} {Framework} for {Fast} and {Effective} {Image} {Restoration}},
	volume = {39},
	issn = {0162-8828, 2160-9292},
	shorttitle = {Trainable {Nonlinear} {Reaction} {Diffusion}},
	url = {http://arxiv.org/abs/1508.02848},
	doi = {10.1109/TPAMI.2016.2596743},
	abstract = {Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters ({\textbackslash}ie, linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD -- {\textbackslash}textit\{Trainable Nonlinear Reaction Diffusion\}. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.},
	number = {6},
	urldate = {2019-11-16},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, Yunjin and Pock, Thomas},
	month = jun,
	year = {2017},
	note = {arXiv: 1508.02848},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {1256--1272},
	file = {arXiv Fulltext PDF:C\:\\Users\\Clement\\Zotero\\storage\\IWPWN7JF\\Chen and Pock - 2017 - Trainable Nonlinear Reaction Diffusion A Flexible.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\QZWGJKZ4\\1508.html:text/html}
}

@article{boyat_review_2015,
	title = {A {Review} {Paper} : {Noise} {Models} in {Digital} {Image} {Processing}},
	volume = {6},
	issn = {22293922, 0976710X},
	shorttitle = {A {Review} {Paper}},
	url = {http://www.aircconline.com/sipij/V6N2/6215sipij06.pdf},
	doi = {10.5121/sipij.2015.6206},
	abstract = {Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps. Noise is very difficult to remove it from the digital images without the prior knowledge of noise model. That is why, review of noise models are essential in the study of image denoising techniques. In this paper, we express a brief overview of various noise models. These noise models can be selected by analysis of their origin. In this way, we present a complete and quantitative analysis of noise models available in digital images.},
	language = {en},
	number = {2},
	urldate = {2019-11-19},
	journal = {Signal \& Image Processing : An International Journal},
	author = {Boyat, Ajay Kumar and Joshi, Brijendra Kumar},
	month = apr,
	year = {2015},
	pages = {63--75},
	file = {Boyat and Joshi - 2015 - A Review Paper  Noise Models in Digital Image Pro.pdf:C\:\\Users\\Clement\\Zotero\\storage\\XP4BAID9\\Boyat and Joshi - 2015 - A Review Paper  Noise Models in Digital Image Pro.pdf:application/pdf}
}

@article{liu_multi-level_2018,
	title = {Multi-level {Wavelet}-{CNN} for {Image} {Restoration}},
	url = {http://arxiv.org/abs/1805.07071},
	abstract = {The tradeoff between receptive field size and efficiency is a crucial issue in low level vision. Plain convolutional networks (CNNs) generally enlarge the receptive field at the expense of computational cost. Recently, dilated filtering has been adopted to address this issue. But it suffers from gridding effect, and the resulting receptive field is only a sparse sampling of input image with checkerboard patterns. In this paper, we present a novel multi-level wavelet CNN (MWCNN) model for better tradeoff between receptive field size and computational efficiency. With the modified U-Net architecture, wavelet transform is introduced to reduce the size of feature maps in the contracting subnetwork. Furthermore, another convolutional layer is further used to decrease the channels of feature maps. In the expanding subnetwork, inverse wavelet transform is then deployed to reconstruct the high resolution feature maps. Our MWCNN can also be explained as the generalization of dilated filtering and subsampling, and can be applied to many image restoration tasks. The experimental results clearly show the effectiveness of MWCNN for image denoising, single image super-resolution, and JPEG image artifacts removal.},
	urldate = {2019-11-19},
	journal = {arXiv:1805.07071 [cs]},
	author = {Liu, Pengju and Zhang, Hongzhi and Zhang, Kai and Lin, Liang and Zuo, Wangmeng},
	month = may,
	year = {2018},
	note = {arXiv: 1805.07071
version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Clement\\Zotero\\storage\\B2BSAJYV\\Liu et al. - 2018 - Multi-level Wavelet-CNN for Image Restoration.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\6N7IV69K\\1805.html:text/html}
}

@article{brooks_unprocessing_2018,
	title = {Unprocessing {Images} for {Learned} {Raw} {Denoising}},
	url = {http://arxiv.org/abs/1811.11127},
	abstract = {Machine learning techniques work best when the data used for training resembles the data used for evaluation. This holds true for learned single-image denoising algorithms, which are applied to real raw camera sensor readings but, due to practical constraints, are often trained on synthetic image data. Though it is understood that generalizing from synthetic to real images requires careful consideration of the noise properties of camera sensors, the other aspects of an image processing pipeline (such as gain, color correction, and tone mapping) are often overlooked, despite their signiﬁcant effect on how raw measurements are transformed into ﬁnished images. To address this, we present a technique to “unprocess” images by inverting each step of an image processing pipeline, thereby allowing us to synthesize realistic raw sensor measurements from commonly available Internet photos. We additionally model the relevant components of an image processing pipeline when evaluating our loss function, which allows training to be aware of all relevant photometric processing that will occur after denoising. By unprocessing and processing training data and model outputs in this way, we are able to train a simple convolutional neural network that has 14\%-38\% lower error rates and is 9×-18× faster than the previous state of the art on the Darmstadt Noise Dataset [30], and generalizes to sensors outside of that dataset as well.},
	language = {en},
	urldate = {2019-11-19},
	journal = {arXiv:1811.11127 [cs]},
	author = {Brooks, Tim and Mildenhall, Ben and Xue, Tianfan and Chen, Jiawen and Sharlet, Dillon and Barron, Jonathan T.},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.11127},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Brooks et al. - 2018 - Unprocessing Images for Learned Raw Denoising.pdf:C\:\\Users\\Clement\\Zotero\\storage\\G8TKQ8N5\\Brooks et al. - 2018 - Unprocessing Images for Learned Raw Denoising.pdf:application/pdf}
}

@article{zhang_residual_2018,
	title = {Residual {Dense} {Network} for {Image} {Restoration}},
	url = {http://arxiv.org/abs/1812.10477},
	abstract = {Convolutional neural network has recently achieved great success for image restoration (IR) and also offered hierarchical features. However, most deep CNN based IR models do not make full use of the hierarchical features from the original low-quality images, thereby achieving relatively-low performance. In this paper, we propose a novel residual dense network (RDN) to address this problem in IR. We fully exploit the hierarchical features from all the convolutional layers. Speciﬁcally, we propose residual dense block (RDB) to extract abundant local features via densely connected convolutional layers. RDB further allows direct connections from the state of preceding RDB to all the layers of current RDB, leading to a contiguous memory mechanism. To adaptively learn more effective features from preceding and current local features and stabilize the training of wider network, we proposed local feature fusion in RDB. After fully obtaining dense local features, we use global feature fusion to jointly and adaptively learn global hierarchical features in a holistic way. We demonstrate the effectiveness of RDN with three representative IR applications, single image super-resolution, Gaussian image denoising, and image compression artifact reduction. Experiments on benchmark datasets show that our RDN achieves favorable performance against state-of-the-art methods for each IR task.},
	language = {en},
	urldate = {2019-11-19},
	journal = {arXiv:1812.10477 [cs]},
	author = {Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.10477},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhang et al. - 2018 - Residual Dense Network for Image Restoration.pdf:C\:\\Users\\Clement\\Zotero\\storage\\8B59NWGV\\Zhang et al. - 2018 - Residual Dense Network for Image Restoration.pdf:application/pdf}
}

@article{li_h-denseunet:_2018,
	title = {H-{DenseUNet}: {Hybrid} {Densely} {Connected} {UNet} for {Liver} and {Tumor} {Segmentation} from {CT} {Volumes}},
	shorttitle = {H-{DenseUNet}},
	url = {http://arxiv.org/abs/1709.07330},
	abstract = {Liver cancer is one of the leading causes of cancer death. To assist doctors in hepatocellular carcinoma diagnosis and treatment planning, an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice. Recently, fully convolutional neural networks (FCNs), including 2D and 3D FCNs, serve as the back-bone in many volumetric image segmentation. However, 2D convolutions can not fully leverage the spatial information along the third dimension while 3D convolutions suffer from high computational cost and GPU memory consumption. To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2D DenseUNet for efficiently extracting intra-slice features and a 3D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation. We formulate the learning process of H-DenseUNet in an end-to-end manner, where the intra-slice representations and inter-slice features can be jointly optimized through a hybrid feature fusion (HFF) layer. We extensively evaluated our method on the dataset of MICCAI 2017 Liver Tumor Segmentation (LiTS) Challenge and 3DIRCADb Dataset. Our method outperformed other state-of-the-arts on the segmentation results of tumors and achieved very competitive performance for liver segmentation even with a single model.},
	urldate = {2019-11-19},
	journal = {arXiv:1709.07330 [cs]},
	author = {Li, Xiaomeng and Chen, Hao and Qi, Xiaojuan and Dou, Qi and Fu, Chi-Wing and Heng, Pheng Ann},
	month = jul,
	year = {2018},
	note = {arXiv: 1709.07330},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Clement\\Zotero\\storage\\P8K2I3IE\\Li et al. - 2018 - H-DenseUNet Hybrid Densely Connected UNet for Liv.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\JLZJEYNS\\1709.html:text/html}
}

@incollection{mao_image_2016,
	title = {Image {Restoration} {Using} {Very} {Deep} {Convolutional} {Encoder}-{Decoder} {Networks} with {Symmetric} {Skip} {Connections}},
	url = {http://papers.nips.cc/paper/6172-image-restoration-using-very-deep-convolutional-encoder-decoder-networks-with-symmetric-skip-connections.pdf},
	urldate = {2019-11-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Mao, Xiaojiao and Shen, Chunhua and Yang, Yu-Bin},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {2802--2810},
	file = {NIPS Full Text PDF:C\:\\Users\\Clement\\Zotero\\storage\\98IAJLBB\\Mao et al. - 2016 - Image Restoration Using Very Deep Convolutional En.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\QVAF88TB\\6172-image-restoration-using-very-deep-convolutional-encoder-decoder-networks-with-symmetric-sk.html:text/html}
}

@book{autoencoders_references_2008,
	title = {References},
	abstract = {The problem Building good predictors on complex domains means learning complicated functions. These are best represented by multiple levels of non-linear operations i.e. deep architectures. Deep architectures are an old idea: multi-layer perceptrons. Learning the parameters of deep architectures proved to be challenging!},
	author = {Autoencoders, Denoising and Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-antoine and Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Extracting, Pierre-antoine Manzagol and Robust, Composing and Autoencoders, Features Denoising},
	year = {2008},
	file = {Citeseer - Full Text PDF:C\:\\Users\\Clement\\Zotero\\storage\\KMI2C4Q6\\Autoencoders et al. - 2008 - References.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\Clement\\Zotero\\storage\\GGPQ6SWW\\summary.html:text/html}
}

@incollection{honkela_stacked_2011,
	address = {Berlin, Heidelberg},
	title = {Stacked {Convolutional} {Auto}-{Encoders} for {Hierarchical} {Feature} {Extraction}},
	volume = {6791},
	isbn = {978-3-642-21734-0 978-3-642-21735-7},
	url = {http://link.springer.com/10.1007/978-3-642-21735-7_7},
	abstract = {We present a novel convolutional auto-encoder (CAE) for unsupervised feature learning. A stack of CAEs forms a convolutional neural network (CNN). Each CAE is trained using conventional on-line gradient descent without additional regularization terms. A max-pooling layer is essential to learn biologically plausible features consistent with those found by previous approaches. Initializing a CNN with ﬁlters of a trained CAE stack yields superior performance on a digit (MNIST) and an object recognition (CIFAR10) benchmark.},
	language = {en},
	urldate = {2019-11-19},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Masci, Jonathan and Meier, Ueli and Cireşan, Dan and Schmidhuber, Jürgen},
	editor = {Honkela, Timo and Duch, Włodzisław and Girolami, Mark and Kaski, Samuel},
	year = {2011},
	doi = {10.1007/978-3-642-21735-7_7},
	pages = {52--59},
	file = {Masci et al. - 2011 - Stacked Convolutional Auto-Encoders for Hierarchic.pdf:C\:\\Users\\Clement\\Zotero\\storage\\I5QFY4A8\\Masci et al. - 2011 - Stacked Convolutional Auto-Encoders for Hierarchic.pdf:application/pdf}
}

@article{claus_videnn:_nodate,
	title = {{ViDeNN}: {Deep} {Blind} {Video} {Denoising}},
	abstract = {We propose ViDeNN: a CNN for Video Denoising without prior knowledge on the noise distribution (blind denoising). The CNN architecture uses a combination of spatial and temporal ﬁltering, learning to spatially denoise the frames ﬁrst and at the same time how to combine their temporal information, handling objects motion, brightness changes, low-light conditions and temporal inconsistencies. We demonstrate the importance of the data used for CNNs training, creating for this purpose a speciﬁc dataset for lowlight conditions. We test ViDeNN on common benchmarks and on self-collected data, achieving good results comparable with the state-of-the-art.},
	language = {en},
	author = {Claus, Michele},
	pages = {10},
	file = {Claus - ViDeNN Deep Blind Video Denoising.pdf:C\:\\Users\\Clement\\Zotero\\storage\\J7KX7KNB\\Claus - ViDeNN Deep Blind Video Denoising.pdf:application/pdf}
}

@article{gharbi_deep_2016,
	title = {Deep joint demosaicking and denoising},
	volume = {35},
	issn = {07300301},
	url = {http://dl.acm.org/citation.cfm?doid=2980179.2982399},
	doi = {10.1145/2980179.2982399},
	abstract = {Demosaicking and denoising are the key ﬁrst stages of the digital imaging pipeline but they are also a severely ill-posed problem that infers three color values per pixel from a single noisy measurement. Earlier methods rely on hand-crafted ﬁlters or priors and still exhibit disturbing visual artifacts in hard cases such as moire´ or thin edges. We introduce a new data-driven approach for these challenges: we train a deep neural network on a large corpus of images instead of using hand-tuned ﬁlters. While deep learning has shown great success, its naive application using existing training datasets does not give satisfactory results for our problem because these datasets lack hard cases. To create a better training set, we present metrics to identify difﬁcult patches and techniques for mining community photographs for such patches. Our experiments show that this network and training procedure outperform state-of-the-art both on noisy and noise-free data. Furthermore, our algorithm is an order of magnitude faster than the previous best performing techniques.},
	language = {en},
	number = {6},
	urldate = {2019-11-20},
	journal = {ACM Transactions on Graphics},
	author = {Gharbi, Michaël and Chaurasia, Gaurav and Paris, Sylvain and Durand, Frédo},
	month = nov,
	year = {2016},
	pages = {1--12},
	file = {Gharbi et al. - 2016 - Deep joint demosaicking and denoising.pdf:C\:\\Users\\Clement\\Zotero\\storage\\SNCVL3VT\\Gharbi et al. - 2016 - Deep joint demosaicking and denoising.pdf:application/pdf}
}

@article{guo_toward_nodate,
	title = {Toward {Convolutional} {Blind} {Denoising} of {Real} {Photographs}},
	abstract = {While deep convolutional neural networks (CNNs) have achieved impressive success in image denoising with additive white Gaussian noise (AWGN), their performance remains limited on real-world noisy photographs. The main reason is that their learned models are easy to overﬁt on the simpliﬁed AWGN model which deviates severely from the complicated real-world noise model. In order to improve the generalization ability of deep CNN denoisers, we suggest training a convolutional blind denoising network (CBDNet) with more realistic noise model and real-world noisy-clean image pairs. On the one hand, both signaldependent noise and in-camera signal processing pipeline is considered to synthesize realistic noisy images. On the other hand, real-world noisy photographs and their nearly noise-free counterparts are also included to train our CBDNet. To further provide an interactive strategy to rectify denoising result conveniently, a noise estimation subnetwork with asymmetric learning to suppress under-estimation of noise level is embedded into CBDNet. Extensive experimental results on three datasets of real-world noisy photographs clearly demonstrate the superior performance of CBDNet over state-of-the-arts in terms of quantitative metrics and visual quality. The code has been made available at https://github.com/GuoShi28/CBDNet.},
	language = {en},
	author = {Guo, Shi and Yan, Zifei and Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},
	pages = {11},
	file = {Guo et al. - Toward Convolutional Blind Denoising of Real Photo.pdf:C\:\\Users\\Clement\\Zotero\\storage\\SV9IBS88\\Guo et al. - Toward Convolutional Blind Denoising of Real Photo.pdf:application/pdf}
}

@article{ce_liu_automatic_2008,
	title = {Automatic {Estimation} and {Removal} of {Noise} from a {Single} {Image}},
	volume = {30},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/4359321/},
	doi = {10.1109/TPAMI.2007.1176},
	abstract = {Image denoising algorithms often assume an additive white Gaussian noise (AWGN) process that is independent of the actual RGB values. Such approaches cannot effectively remove color noise produced by today’s CCD digital camera. In this paper, we propose a unified framework for two tasks: automatic estimation and removal of color noise from a single image using piecewise smooth image models. We introduce the noise level function (NLF), which is a continuous function describing the noise level as a function of image brightness. We then estimate an upper bound of the real NLF by fitting a lower envelope to the standard deviations of per-segment image variances. For denoising, the chrominance of color noise is significantly removed by projecting pixel values onto a line fit to the RGB values in each segment. Then, a Gaussian conditional random field (GCRF) is constructed to obtain the underlying clean image from the noisy input. Extensive experiments are conducted to test the proposed algorithm, which is shown to outperform state-of-the-art denoising algorithms.},
	language = {en},
	number = {2},
	urldate = {2019-11-20},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Ce Liu} and Szeliski, R. and {Sing Bing Kang} and Zitnick, C.L. and Freeman, W.T.},
	month = feb,
	year = {2008},
	pages = {299--314},
	file = {Ce Liu et al. - 2008 - Automatic Estimation and Removal of Noise from a S.pdf:C\:\\Users\\Clement\\Zotero\\storage\\GP4RQ4XG\\Ce Liu et al. - 2008 - Automatic Estimation and Removal of Noise from a S.pdf:application/pdf}
}

@incollection{ikeuchi_photon_2014,
	address = {Boston, MA},
	title = {Photon, {Poisson} {Noise}},
	isbn = {978-0-387-30771-8 978-0-387-31439-6},
	url = {http://link.springer.com/10.1007/978-0-387-31439-6_482},
	language = {en},
	urldate = {2019-11-20},
	booktitle = {Computer {Vision}},
	publisher = {Springer US},
	author = {Hasinoff, Samuel W.},
	editor = {Ikeuchi, Katsushi},
	year = {2014},
	doi = {10.1007/978-0-387-31439-6_482},
	pages = {608--610},
	file = {Hasinoff - 2014 - Photon, Poisson Noise.pdf:C\:\\Users\\Clement\\Zotero\\storage\\W9HGJWXX\\Hasinoff - 2014 - Photon, Poisson Noise.pdf:application/pdf}
}

@inproceedings{huiskes_new_2010,
	address = {Philadelphia, Pennsylvania, USA},
	title = {New trends and ideas in visual concept detection: the {MIR} flickr retrieval evaluation initiative},
	isbn = {978-1-60558-815-5},
	shorttitle = {New trends and ideas in visual concept detection},
	url = {http://portal.acm.org/citation.cfm?doid=1743384.1743475},
	doi = {10.1145/1743384.1743475},
	abstract = {The MIR Flickr collection consists of 25000 high-quality photographic images of thousands of Flickr users, made available under the Creative Commons license. The database includes all the original user tags and EXIF metadata. Additionally, detailed and accurate annotations are provided for topics corresponding to the most prominent visual concepts in the user tag data. The rich metadata allow for a wide variety of image retrieval benchmarking scenarios.},
	language = {en},
	urldate = {2019-11-20},
	booktitle = {Proceedings of the international conference on {Multimedia} information retrieval - {MIR} '10},
	publisher = {ACM Press},
	author = {Huiskes, Mark J. and Thomee, Bart and Lew, Michael S.},
	year = {2010},
	pages = {527},
	file = {Huiskes et al. - 2010 - New trends and ideas in visual concept detection .pdf:C\:\\Users\\Clement\\Zotero\\storage\\CGKQIUBH\\Huiskes et al. - 2010 - New trends and ideas in visual concept detection .pdf:application/pdf}
}

@article{cho_learning_2014,
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1406.1078},
	abstract = {In this paper, we propose a novel neural network model called RNN Encoder–Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a ﬁxedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder–Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
	language = {en},
	urldate = {2019-11-22},
	journal = {arXiv:1406.1078 [cs, stat]},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {arXiv: 1406.1078},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-.pdf:C\:\\Users\\Clement\\Zotero\\storage\\BUHCX4QF\\Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-.pdf:application/pdf}
}

@article{chaitanya_interactive_2017,
	title = {Interactive reconstruction of {Monte} {Carlo} image sequences using a recurrent denoising autoencoder},
	volume = {36},
	issn = {07300301},
	url = {http://dl.acm.org/citation.cfm?doid=3072959.3073601},
	doi = {10.1145/3072959.3073601},
	language = {en},
	number = {4},
	urldate = {2019-11-22},
	journal = {ACM Transactions on Graphics},
	author = {Chaitanya, Chakravarty R. Alla and Kaplanyan, Anton S. and Schied, Christoph and Salvi, Marco and Lefohn, Aaron and Nowrouzezahrai, Derek and Aila, Timo},
	month = jul,
	year = {2017},
	pages = {1--12},
	file = {Chaitanya et al. - 2017 - Interactive reconstruction of Monte Carlo image se.pdf:C\:\\Users\\Clement\\Zotero\\storage\\P7TSI9HU\\Chaitanya et al. - 2017 - Interactive reconstruction of Monte Carlo image se.pdf:application/pdf}
}

@inproceedings{burger_image_2012,
	address = {Providence, RI},
	title = {Image denoising: {Can} plain neural networks compete with {BM3D}?},
	isbn = {978-1-4673-1228-8 978-1-4673-1226-4 978-1-4673-1227-1},
	shorttitle = {Image denoising},
	url = {http://ieeexplore.ieee.org/document/6247952/},
	doi = {10.1109/CVPR.2012.6247952},
	abstract = {Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this mapping directly with a plain multi layer perceptron (MLP) applied to image patches. While this has been done before, we will show that by training on large image databases we are able to compete with the current state-of-the-art image denoising methods. Furthermore, our approach is easily adapted to less extensively studied types of noise (by merely exchanging the training data), for which we achieve excellent results as well.},
	language = {en},
	urldate = {2020-03-25},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Burger, H. C. and Schuler, C. J. and Harmeling, S.},
	month = jun,
	year = {2012},
	pages = {2392--2399},
	file = {Burger et al. - 2012 - Image denoising Can plain neural networks compete.pdf:C\:\\Users\\Clement\\Zotero\\storage\\9YNC7SDD\\Burger et al. - 2012 - Image denoising Can plain neural networks compete.pdf:application/pdf}
}

@article{lehtinen_noise2noise_2018,
	title = {{Noise2Noise}: {Learning} {Image} {Restoration} without {Clean} {Data}},
	shorttitle = {{Noise2Noise}},
	url = {http://arxiv.org/abs/1803.04189},
	abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning – learning to map corrupted observations to clean signals – with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans – all corrupted by different processes – based on noisy data only.},
	language = {en},
	urldate = {2020-04-11},
	journal = {arXiv:1803.04189 [cs, stat]},
	author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
	month = oct,
	year = {2018},
	note = {arXiv: 1803.04189},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Lehtinen et al. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf:C\:\\Users\\Clement\\Zotero\\storage\\UMIXEY9L\\Lehtinen et al. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf:application/pdf}
}


@article{peng2020progressive,
  title={Progressive training of multi-level wavelet residual networks for image denoising},
  author={Peng, Yali and Cao, Yue and Liu, Shigang and Yang, Jian and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2010.12422},
  year={2020}
}

@inproceedings{zamir2021multi,
  title={Multi-stage progressive image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14821--14831},
  year={2021}
}

@inproceedings{guo2019toward,
  title={Toward convolutional blind denoising of real photographs},
  author={Guo, Shi and Yan, Zifei and Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1712--1722},
  year={2019}
}

@article{Liu2019MWCNN,
title={Multi-Level Wavelet Convolutional Neural Networks},
author={Liu, Pengju and Zhang, Hongzhi and Lian Wei and Zuo, Wangmeng},
journal={IEEE Access},
volume={7},
pages={74973-74985},
year={2019},
publisher={IEEE}
}

@inproceedings{liu2018multi,
  title={Multi-level wavelet-CNN for image restoration},
  author={Liu, Pengju and Zhang, Hongzhi and Zhang, Kai and Lin, Liang and Zuo, Wangmeng},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={773--782},
  year={2018}
}

% pseudoisp
@article{cao2021pseudo,
  title={Pseudo-ISP: learning pseudo in-camera signal processing pipeline from a color image denoiser},
  author={Cao, Yue and Wu, Xiaohe and Qi, Shuran and Liu, Xiao and Wu, Zhongqin and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2103.10234},
  year={2021}
}

@inproceedings{zamir2020cycleisp,
  title={Cycleisp: Real image restoration via improved data synthesis},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2696--2705},
  year={2020}
}

@article{brownrigg1984weighted,
  title={The weighted median filter},
  author={Brownrigg, David RK},
  journal={Communications of the ACM},
  volume={27},
  number={8},
  pages={807--818},
  year={1984},
  publisher={ACM New York, NY, USA}
}

@book{dougherty1994introduction,
  title={An introduction to nonlinear image processing},
  author={Dougherty, Edward R and Astola, Jaakko},
  volume={16},
  year={1994},
  publisher={SPIE press}
}

@article{tukey1974nonlinear,
  title={Nonlinear (nonsuperposable) methods for smoothing data},
  author={Tukey, JW},
  journal={Proc. Cong. Rec. EASCOM'74},
  pages={673--681},
  year={1974}
}

@article{hwang1995adaptive,
  title={Adaptive median filters: new algorithms and results},
  author={Hwang, Humor and Haddad, Richard A},
  journal={IEEE Transactions on image processing},
  volume={4},
  number={4},
  pages={499--502},
  year={1995},
  publisher={IEEE}
}

@article{king1984two,
  title={Two-dimensional filtering of SPECT images using the Metz and Wiener filters},
  author={King, Michael A and Schwinger, Ronald B and Doherty, Paul W and Penney, Bill C},
  journal={Journal of Nuclear Medicine},
  volume={25},
  number={11},
  pages={1234--1240},
  year={1984},
  publisher={Soc Nuclear Med}
}

@inproceedings{simoncelli1996noise,
  title={Noise removal via Bayesian wavelet coring},
  author={Simoncelli, Eero P and Adelson, Edward H},
  booktitle={Proceedings of 3rd IEEE International Conference on Image Processing},
  volume={1},
  pages={379--382},
  year={1996},
  organization={IEEE}
}

@article{lina1997image,
  title={Image processing with complex Daubechies wavelets},
  author={Lina, Jean-Marc},
  journal={Journal of Mathematical Imaging and Vision},
  volume={7},
  number={3},
  pages={211--223},
  year={1997},
  publisher={Springer}
}

@inproceedings{yadav2015noising,
  title={De-noising of ultrasound image using discrete wavelet transform by symlet wavelet and filters},
  author={Yadav, Ashwani Kumar and Roy, R and Kumar, Archek Parveen and Kumar, Ch Sandesh and Dhakad, Shailendra Kr},
  booktitle={2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
  pages={1204--1208},
  year={2015},
  organization={IEEE}
}

@article{dixit2013comparative,
  title={Comparative analysis of coiflet and daubechies wavelets using global threshold for image denoising},
  author={Dixit, Abhinav and Majumdar, Swatilekha},
  journal={International Journal of Advances in Engineering \& Technology},
  volume={6},
  number={5},
  pages={2247},
  year={2013},
  publisher={Citeseer}
}

@article{hewitt1979gibbs,
  title={The Gibbs-Wilbraham phenomenon: an episode in Fourier analysis},
  author={Hewitt, Edwin and Hewitt, Robert E},
  journal={Archive for history of Exact Sciences},
  pages={129--160},
  year={1979},
  publisher={JSTOR}
}


@misc{noauthor_neat_nodate,
	title = {Neat {Video} - best noise reduction for digital video},
	url = {https://www.neatvideo.com/},
	abstract = {Neat Video noise reduction plug-in reduces visible noise and grain in digital video sequences produced by digital video cameras, camcorders, TV-tuners, film or analog video digitizers.},
	language = {en},
	urldate = {2022-05-10},
	file = {Snapshot:/home/bledc/Zotero/storage/8KN9QZ9L/www.neatvideo.com.html:text/html},
}


@misc{noauthor_nuke_nodate,
	title = {Nuke {\textbar} {VFX} and {Film} {Editing} {Software}},
	url = {https://www.foundry.com/products/nuke-family/nuke},
	abstract = {Create binge-worthy films with the Nuke Software - offering among the best video editing software in compositing, editorial, and film editing for pixel-perfect results.},
	language = {en},
	urldate = {2022-05-10},
	file = {Snapshot:/home/bledc/Zotero/storage/G6PEJXLM/nuke.html:text/html},
}

@article{willoughby1979solutions,
  title={Solutions of ill-posed problems (AN Tikhonov and VY Arsenin)},
  author={Willoughby, Ralph A},
  journal={SIAM Review},
  volume={21},
  number={2},
  pages={266},
  year={1979},
  publisher={Society for Industrial and Applied Mathematics}
}

@article{catte1992image,
  title={Image selective smoothing and edge detection by nonlinear diffusion},
  author={Catt{\'e}, Francine and Lions, Pierre-Louis and Morel, Jean-Michel and Coll, Tomeu},
  journal={SIAM Journal on Numerical analysis},
  volume={29},
  number={1},
  pages={182--193},
  year={1992},
  publisher={SIAM}
}

@article{chong2013speckle,
  title={Speckle reduction in optical coherence tomography images of human finger skin by wavelet modified BM3D filter},
  author={Chong, Bo and Zhu, Yong-Kai},
  journal={Optics Communications},
  volume={291},
  pages={461--469},
  year={2013},
  publisher={Elsevier}
}

@article{lebrun2012analysis,
  title={An analysis and implementation of the BM3D image denoising method},
  author={Lebrun, Marc},
  journal={Image Processing On Line},
  volume={2012},
  pages={175--213},
  year={2012}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}


@inproceedings{plotz2017benchmarking,
  title={Benchmarking denoising algorithms with real photographs},
  author={Plotz, Tobias and Roth, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1586--1595},
  year={2017}
}

@inproceedings{abdelhamed2018high,
  title={A high-quality denoising dataset for smartphone cameras},
  author={Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1692--1700},
  year={2018}
}

@inproceedings{tassano2019dvdnet,
  title={Dvdnet: A fast network for deep video denoising},
  author={Tassano, Matias and Delon, Julie and Veit, Thomas},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)},
  pages={1805--1809},
  year={2019},
  organization={IEEE}
}

@article{anaya2018renoir,
  title={Renoir--a dataset for real low-light image noise reduction},
  author={Anaya, Josue and Barbu, Adrian},
  journal={Journal of Visual Communication and Image Representation},
  volume={51},
  pages={144--154},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{anwar2019real,
  title={Real image denoising with feature attention},
  author={Anwar, Saeed and Barnes, Nick},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3155--3164},
  year={2019}
}

@inproceedings{zhang2020deep,
  title={Deep unfolding network for image super-resolution},
  author={Zhang, Kai and Gool, Luc Van and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3217--3226},
  year={2020}
}

@inproceedings{zhao2019pyramid,
  title={Pyramid real image denoising network},
  author={Zhao, Yiyun and Jiang, Zhuqing and Men, Aidong and Ju, Guodong},
  booktitle={2019 IEEE Visual Communications and Image Processing (VCIP)},
  pages={1--4},
  year={2019},
  organization={IEEE}
}

@article{aharon2006k,
  title={K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation},
  author={Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
  journal={IEEE Transactions on signal processing},
  volume={54},
  number={11},
  pages={4311--4322},
  year={2006},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@ARTICLE{1323796,  author={Grossberg, M.D. and Nayar, S.K.},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   title={Modeling the space of camera response functions},   year={2004},  volume={26},  number={10},  pages={1272-1282},  doi={10.1109/TPAMI.2004.88}}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@article{yu2015multi,
  title={Multi-scale context aggregation by dilated convolutions},
  author={Yu, Fisher and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1511.07122},
  year={2015}
}

@article{he2015spatial,
  title={Spatial pyramid pooling in deep convolutional networks for visual recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={37},
  number={9},
  pages={1904--1916},
  year={2015},
  publisher={IEEE}
}

@inproceedings{zhao2017pyramid,
  title={Pyramid scene parsing network},
  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2881--2890},
  year={2017}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}
@article{zamir2021restormer,
  title={Restormer: Efficient Transformer for High-Resolution Image Restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2111.09881},
  year={2021}
}

@InProceedings{MartinFTM01,
  author = {D. Martin and C. Fowlkes and D. Tal and J. Malik},
  title = {A Database of Human Segmented Natural Images and its
           Application to Evaluating Segmentation Algorithms and
           Measuring Ecological Statistics},
  booktitle = {Proc. 8th Int'l Conf. Computer Vision},
  year = {2001},
  month = {July},
  volume = {2},
  pages = {416--423}
}

@article{zhao2016loss,
  title={Loss functions for image restoration with neural networks},
  author={Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
  journal={IEEE Transactions on computational imaging},
  volume={3},
  number={1},
  pages={47--57},
  year={2016},
  publisher={IEEE}
}

@article{ma2017waterloo,
	author    = {Ma, Kede and Duanmu, Zhengfang and Wu, Qingbo and Wang, Zhou and Yong, Hongwei and Li, Hongliang and Zhang, Lei}, 
	title     = {{Waterloo Exploration Database}: New Challenges for Image Quality Assessment Models}, 
	journal   = {IEEE Transactions on Image Processing},
	volume    = {26},
	number    = {2},
	pages     = {1004--1016},
	month	  = {Feb.},
	year      = {2017}
}
	
@ARTICLE{9069265,
  author={Aizawa, Kiyoharu and Fujimoto, Azuma and Otsubo, Atsushi and Ogawa, Toru and Matsui, Yusuke and Tsubota, Koki and Ikuta, Hikaru},
  journal={IEEE MultiMedia}, 
  title={Building a Manga Dataset “Manga109” With Annotations for Multimedia Applications}, 
  year={2020},
  volume={27},
  number={2},
  pages={8-18},
  doi={10.1109/MMUL.2020.2987895}
  }
  
  @inproceedings{huang2015single,
  title={Single image super-resolution from transformed self-exemplars},
  author={Huang, Jia-Bin and Singh, Abhishek and Ahuja, Narendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5197--5206},
  year={2015}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{timofte2016seven,
  title={Seven ways to improve example-based single image super resolution},
  author={Timofte, Radu and Rothe, Rasmus and Van Gool, Luc},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1865--1873},
  year={2016}
}

@InProceedings{Agustsson_2017_CVPR_Workshops,
	author = {Agustsson, Eirikur and Timofte, Radu},
	title = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
	month = {July},
	year = {2017}
} 

@inproceedings{fivek,
	author = "Vladimir Bychkovsky and Sylvain Paris and Eric Chan and Fr{\'e}do Durand",
	title = "Learning Photographic Global Tonal Adjustment with a Database of Input / Output Image Pairs",
	booktitle = "The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition",
	year = "2011"
}

@InProceedings{SIDD_2018_CVPR,
author = {Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S.},
title = {A High-Quality Denoising Dataset for Smartphone Cameras},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@techreport{sandvine_corporation_global_2022,
	address = {Waterloo, Ontario},
	title = {The {Global} {Internet} {Phenomena} {Report}},
	url = {https://www.sandvine.com/global-internet-phenomena-report-2022?hs_preview=khpPseNo-62343537839},
	language = {English},
	author = {{Sandvine Corporation}},
	month = jan,
	year = {2022},
	pages = {24},
}

@techreport{camera_and_imaging_products_association_total_2021,
	address = {Japan},
	title = {Total {Shipments} of {Digital} {Still} {Cameras}},
	url = {https://www.cipa.jp/e/stats/report.html},
	institution = {CIPA},
	author = {{Camera \& Imaging Products Association}},
	year = {2021},
}

@article{lebrun2013nonlocal,
  title={A nonlocal Bayesian image denoising algorithm},
  author={Lebrun, Marc and Buades, Antoni and Morel, Jean-Michel},
  journal={SIAM Journal on Imaging Sciences},
  volume={6},
  number={3},
  pages={1665--1688},
  year={2013},
  publisher={SIAM}
}

@inproceedings{nam2016holistic,
  title={A holistic approach to cross-channel image noise modeling and its application to image denoising},
  author={Nam, Seonghyeon and Hwang, Youngbae and Matsushita, Yasuyuki and Kim, Seon Joo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1683--1691},
  year={2016}
}

@article{qin2020u2,
  title={U2-Net: Going deeper with nested U-structure for salient object detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal={Pattern recognition},
  volume={106},
  pages={107404},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@INPROCEEDINGS{8416572,  author={Norkin, Andrey and Birkbeck, Neil},  booktitle={2018 Data Compression Conference},   title={Film Grain Synthesis for AV1 Video Codec},   year={2018},  volume={},  number={},  pages={3-12},  doi={10.1109/DCC.2018.00008}}

@article{arias2018video,
  title={Video denoising via empirical Bayesian estimation of space-time patches},
  author={Arias, Pablo and Morel, Jean-Michel},
  journal={Journal of Mathematical Imaging and Vision},
  volume={60},
  number={1},
  pages={70--93},
  year={2018},
  publisher={Springer}
}

@article{maggioni2012nonlocal,
  title={Nonlocal transform-domain filter for volumetric data denoising and reconstruction},
  author={Maggioni, Matteo and Katkovnik, Vladimir and Egiazarian, Karen and Foi, Alessandro},
  journal={IEEE transactions on image processing},
  volume={22},
  number={1},
  pages={119--133},
  year={2012},
  publisher={IEEE}
}


@misc{noauthor_topaz_nodate,
	title = {Topaz {Labs}: {AI} {Image} {Quality} {Software}},
	shorttitle = {Topaz {Labs}},
	url = {https://www.topazlabs.com/},
	abstract = {Photo and video enhancement software powered by deep learning gets you the best image quality available for noise reduction, sharpening, upscaling, and more.},
	urldate = {2022-06-21},
}


@misc{noauthor_neat_nodate,
	title = {Neat {Video} - best noise reduction for digital video},
	url = {https://www.neatvideo.com/},
	abstract = {Neat Video noise reduction plug-in reduces visible noise and grain in digital video sequences produced by digital video cameras, camcorders, TV-tuners, film or analog video digitizers.},
	language = {en},
	urldate = {2022-06-21},
}


@article{gomila2003sei,
  title={SEI message for film grain encoding},
  author={Gomila, Christina},
  journal={JVT document, May 2003},
  year={2003}
}

@inproceedings{dai2010film,
  title={Film grain noise removal and synthesis in video coding},
  author={Dai, Jingjing and Au, Oscar C and Pang, Chao and Yang, Wen and Zou, Feng},
  booktitle={2010 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={890--893},
  year={2010},
  organization={IEEE}
}

@inproceedings{hwang2013enhanced,
  title={Enhanced film grain noise removal for high fidelity video coding},
  author={Hwang, Inseong and Jeong, Jinwoo and Choi, Jangwon and Choe, Yoonsik},
  booktitle={2013 International Conference on Information Science and Cloud Computing Companion},
  pages={668--674},
  year={2013},
  organization={IEEE}
}

@article{chen2016trainable,
  title={Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration},
  author={Chen, Yunjin and Pock, Thomas},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={6},
  pages={1256--1272},
  year={2016},
  publisher={IEEE}
}

@inproceedings{liang2021swinir,
  title={Swinir: Image restoration using swin transformer},
  author={Liang, Jingyun and Cao, Jiezhang and Sun, Guolei and Zhang, Kai and Van Gool, Luc and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1833--1844},
  year={2021}
}

@article{hirakawa2005adaptive,
  title={Adaptive homogeneity-directed demosaicing algorithm},
  author={Hirakawa, Keigo and Parks, Thomas W},
  journal={Ieee transactions on image processing},
  volume={14},
  number={3},
  pages={360--369},
  year={2005},
  publisher={IEEE}
}

@misc{chuan-kai__pixel_2016,
	type = {Archive},
	title = {Pixel grouping for color filter array demosaicing},
	url = {https://web.archive.org/web/20160923211135/https://sites.google.com/site/chklin/demosaic/},
	urldate = {2022-06-24},
	journal = {Demosaic},
	author = {Chuan-kai , Lin},
	month = sep,
	year = {2016},
	note = {Archived from the original on 2016-09-23},
}

@article{qin2020u2,
  title={U2-Net: Going deeper with nested U-structure for salient object detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal={Pattern recognition},
  volume={106},
  pages={107404},
  year={2020},
  publisher={Elsevier}
}

@article{TIAN2020117,
title = {Attention-guided CNN for image denoising},
journal = {Neural Networks},
volume = {124},
pages = {117-129},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019304241},
author = {Chunwei Tian and Yong Xu and Zuoyong Li and Wangmeng Zuo and Lunke Fei and Hong Liu},
keywords = {Image denoising, CNN, Sparse block, Feature enhancement block, Attention block},
abstract = {Deep convolutional neural networks (CNNs) have attracted considerable interest in low-level computer vision. Researches are usually devoted to improving the performance via very deep CNNs. However, as the depth increases, influences of the shallow layers on deep layers are weakened. Inspired by the fact, we propose an attention-guided denoising convolutional neural network (ADNet), mainly including a sparse block (SB), a feature enhancement block (FEB), an attention block (AB) and a reconstruction block (RB) for image denoising. Specifically, the SB makes a tradeoff between performance and efficiency by using dilated and common convolutions to remove the noise. The FEB integrates global and local features information via a long path to enhance the expressive ability of the denoising model. The AB is used to finely extract the noise information hidden in the complex background, which is very effective for complex noisy images, especially real noisy images and bind denoising. Also, the FEB is integrated with the AB to improve the efficiency and reduce the complexity for training a denoising model. Finally, a RB aims to construct the clean image through the obtained noise mapping and the given noisy image. Additionally, comprehensive experiments show that the proposed ADNet performs very well in three tasks (i.e. synthetic and real noisy images, and blind denoising) in terms of both quantitative and qualitative evaluations. The code of ADNet is accessible at https://github.com/hellloxiaotian/ADNet.}
}

@article{yue2019variational,
  title={Variational denoising network: Toward blind noise modeling and removal},
  author={Yue, Zongsheng and Yong, Hongwei and Zhao, Qian and Meng, Deyu and Zhang, Lei},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{jin2019channel,
  title={Channel estimation for mmWave massive MIMO with convolutional blind denoising network},
  author={Jin, Yu and Zhang, Jiayi and Ai, Bo and Zhang, Xiaodan},
  journal={IEEE Communications Letters},
  volume={24},
  number={1},
  pages={95--98},
  year={2019},
  publisher={IEEE}
}

@article{zhang2018ffdnet,
  title={FFDNet: Toward a fast and flexible solution for CNN-based image denoising},
  author={Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={9},
  pages={4608--4622},
  year={2018},
  publisher={IEEE}
}

@article{mohan2019robust,
  title={Robust and interpretable blind image denoising via bias-free convolutional neural networks},
  author={Mohan, Sreyas and Kadkhodaie, Zahra and Simoncelli, Eero P and Fernandez-Granda, Carlos},
  journal={arXiv preprint arXiv:1906.05478},
  year={2019}
}

@article{zhang2017beyond,
  title={Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising},
  author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},
  journal={IEEE transactions on image processing},
  volume={26},
  number={7},
  pages={3142--3155},
  year={2017},
  publisher={IEEE}
}

@inproceedings{zamir2022restormer,
  title={Restormer: Efficient transformer for high-resolution image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5728--5739},
  year={2022}
}