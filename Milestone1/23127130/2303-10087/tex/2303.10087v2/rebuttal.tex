\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% Import additional packages in the preamble file, before hyperref
\input{preamble}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\usepackage[dvipsnames]{xcolor}
\newcommand{\R}[0]{\textcolor{BrickRed}{\textbf{R1}}}
\newcommand{\G}[0]{\textcolor{OliveGreen}{\textbf{R2}}}
\newcommand{\B}[0]{\textcolor{NavyBlue}{\textbf{R3}}}
% \newcommand{\cs}[2]{{\textcolor{red}{[cs: #1]}}} % already defined
\newcommand{\yb}[2]{{\textcolor{green}{[YB: #1]}}}
% \newcommand{\red}[1]{\textcolor{red}{#1}} % already defined
% \setlength{\parindent}{0pt} % no indentation allowed

% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{5729} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2024}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Neural Refinement for Absolute Pose Regression with Feature Synthesis}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}
\appendix

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
We thank all reviewers for their valuable feedback. Reviewers appreciated our (i) well-structured test-time refinement method (\G{}-n7Jn) and (ii) novel combination of proposed techniques, leading to advancements in APR and SOTA performance (\R-TZKE,\B-SXSZ), (iii) thorough ablations validating each architectural component (\R,\G,\B), (iv) highlighting its potential impact on the localization community (\R).

\noindent\textbf{\R{}: Proposed method updates APR network rather than optimizing poses directly. APR benefit.}
We empirically found that updating poses parameterized by a network (i.e. APR backbone) leads to consistently better refinement than optimizing poses directly. We aimed to discuss this in Section 4.4 and Table 5 which shows that this finding is consistent across both indoor (7Scenes) and outdoor (Cambridge) scenes. We will further expand and highlight these interesting findings in the revised paper. 
% \zirui{``As discussed in sec 4.4 ... (Cambridge) scenes": these look like empirical findings to me. If no deeper reasons, I would put something like "we emprically found updating network is superior than updating poses."}

\noindent\textbf{\R{}: Sec 4.7 and Fig 6 contradict L404-405.} We apologize that this writing is unintentionally confusing in L404-405. In Fig 6, we show that, while 50 steps suffice to converge to an optimal performance, the most effective error reduction occurs within the first 10-20 steps. Hence, given a computational budget, an operating point can be chosen w.r.t.\ the performance-time trade-off. We will correct the wording of L404-405 in the revised paper by clarifying that the method is not constrained by the number of optimization steps.

\noindent\textbf{\R{}: Supp Tab 1 shows limit to the refinement. Is this tied to pose initialization? What puts such a limit on reÔ¨Ånement?} We believe
% there are multiple causes for this limit. 
the initial pose error does influence the final accuracy. If the initial pose error is too large, the frustum overlap is small. Hence, in our direct matching (DM) formulation (akin to other SLAM works e.g.\ DSO [18]), 
% due to limited matching pixels in the query and NeRF-rendered images, 
the optimization is prone to linger longer in a local minimum. This leads to limited improvement in pose error (e.g. pose error can be improved from 10\degree~to 1\degree, but an error of 1\degree~can be improved to 0.5\degree). This issue is not particularly due to NeFeS/APR, but in general with any DM formulation.

\noindent\textbf{\R{}: Ablation on other types of features (vs DFNet features). What other candidate models' features can be used?} We experimented with PixLoc features in our refinement pipeline. While we did find positive results, performance didn't reach that of DFNet features. This is because DFNet is trained to close the domain gap between features extracted from natural query images and features rendered by NeRF. We will include this ablation in the revised paper.

\noindent\textbf{\R{}: NeFeS requires additional constraints. Feature matching such as HLoc may scale and generalize better to unseen scenes.}
% We agree with \R{} that feature matching models like Hloc have their merits. One difference, though, is that HLoc requires the SfM point clouds to operate which are not needed by NeFeS. For example, we can achieve comparable results (supp. table 2.\yb{cite table/section from paper that shows this}~) \cs{Not sure it's comparable, we can achieve the SOTA result compare to other APR trained on SLAM poses, but the precision is definitely worse than sfm poses.}~with NeFeS trained using SLAM poses, which are cheaper to obtain but slight inferior in accuracy than SfM. But we do agree that a more efficient and generalized training scheme could be investigated, and we plan to solve these issues in future works.
We agree with \R{} that feature matching models like Hloc have their merits. One difference, though, is that HLoc requires the reconstructed point clouds to operate, which is not needed by NeFeS. For example, NeFeS can achieve SOTA APR performance (supp.Tab.2.) even with SLAM poses,
% we can achieve SOTA APR results on SLAM poses (supp.Tab.2.) with NeFeS trained using SLAM poses, 
which are cheaper to obtain but slightly inferior in accuracy than SfM poses. Even so, more efficient and generalized training schemes based on explicit point clouds \& matching would be an interesting future direction.

%we agree that a more efficient and generalized training scheme could be investigated, and we plan to solve these issues in future works.

% \cs{victor: If we want to keep using APR backend... but refine with an explicit point cloud representation based on feature extraction}~

% \cs{victor: This will require large amount of complexity and effort for training. But is of course, expand a lot deeper in the current literature.}~

\noindent\textbf{\G{}: The prerequisite of a well-trained NeRF module for novel view rendering and feature extraction, limits the usage with other camera localization methods.}
This paper focuses on enhancing performance of APR methods that lack geometry-awareness. However, as shown in Tab.4\&5 of the paper, our method is not limited to APR backbones. Instead, an initial pose provided by a non-differentiable or black-box pose estimator can be optimized by our method.
% \cs{This question may refer to the fact that nerf constraints the localization method's usage only to scenes that could train a well-trained nerf. Is there a better response?}~

\noindent\textbf{\G{}: Run-time cost. Indoor and outdoor datasets.} The run-time cost analysis is provided in the supplementary material Sec 1.8. The indoor or outdoor setting does not affect the inference and refinement speed of our approach.

%The indoor or outdoor setting doesn't affect the inference or refinement speed of our approach.
% showing that our method is equally fast in indoor and outdoor settings.

\noindent\textbf{\G{}: Does image quality of NeRF influence final pose refinement?} 
While NeRF rendering quality does matter, as discussed in our response to \R, our method is relatively robust due to the use of DFNet's features. Our requirements for rendering quality are not as high as standard NeRF tasks focused on visualization.
%While NeRF rendering quality does matter, we do, however, show that our method is robust to rendering artifacts to some extent. As shown in Fig 4 and suppmat Table 2, we achieve optimal results even when the NeRF is optimized on noisy SLAM poses.
% We will include further robustness studies in the final paper. 
Also, in suppmat Table 4, we show that our feature-matching-based method is more robust than a photometric matching NeRF approach.

% \cs{While NeRF rendering quality does matter, as discussed in our response to \R, our method is relatively robust due to the use of DFNet's features. Our expectations for rendering quality are not as high as standard NeRF for visualization.}~

\noindent\textbf{\B{}: DFNet [11] and LENS [13] also use NeRF to improve pose.}
Our method is certainly inspired by [11,13]. Yet, we improve several drawbacks present in [11,13]. First, [11,13] require careful data augmentation for comprehensive scene coverage and extra hyperparameter tuning for dataset-specific sampling. Second, [11,13] use photometric NeRF, whereas NeFeS encodes accurate 3D features into the neural feature fields. Finally, while DFNet (akin to other APR methods) is tied to a specific architecture, our method (as shown in Table 3) is architecture-agnostic. Once a NeFeS model is trained, it can be directly applied to different APR backbones, which amortizes the training cost.

\vspace{2pt}

\noindent\textbf{\B{}: Figure 2, why not add a Pose Loss?} 
We thank R3 for this great suggestion. 
% We think this is an awesome idea to further improve the performance. 
We believe that, in cases when initial pose error is quite large, we can use the reference poses of the nearest-neighbor training images to constrain the optimization. We will investigate this in future work.

\vspace{2pt}

\noindent\textbf{\B{}: Adjust description on usage of 3D info. Clarify there's no explicit 3D.} 
%Thank you for pointing this out. We indeed don't use 3D info explicitly, and perform matching implicitly with NeFeS. We will clarify this in revised paper.
Thanks for pointing this out. NeRF is an implicit 3D method, we will clarify this in the paper.

\vspace{2pt}

\noindent\textbf{\B{}: Brief analysis on supp. Fig.2.} In supp. Fig.2, the 4th column shows poses that are refined from the DFNet predictions (3rd column).
% results are optimized from the 3rd column DFNet predictions.
Generally, when initial pose error is too high (3rd column), the NeFeS optimization may linger at a local minimum due to limited frustum overlap between the query and rendered views, leading to limited refinement.

% \textbf{\R{}: typo} We appreciate \R{} for pointing out our typo.  We will fix it in the final submission.





% %%%%%%%%% REFERENCES
% {
%     \small
%     \bibliographystyle{ieeenat_fullname}
%     \bibliography{main}
% }

\end{document}
