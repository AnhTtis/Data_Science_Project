\section{Related Work} \label{sec:related_work}

\textbf{Absolute Pose Regression (APR).} APR methods have been widely studied due to their simple and lightweight formulation that allows the camera pose to be directly regressed using an end-to-end neural network. PoseNet \cite{Kendall15, Kendall16, Kendall17} introduced the first APR solution using GoogLeNet-backbone, followed by various architectures like the hourglass network \cite{Melekhov17}, attention layers \cite{atloc,Shavit21multiscene,Shavit21}, separated translation and rotation prediction \cite{Wu17,Naseer17}, or LSTM \cite{Walch17}.

To further improve APR accuracy, some works utilize sequential information. These approaches incorporate temporal constraints such as visual odometry \cite{Brahmbhatt18, Valada18, Radwan18}, motion \cite{moreau2022coordinet}, temporal  filtering \cite{clark2017vidloc}, and multi-tasking \cite{Radwan18}. Recent APR methods also benefit from novel view synthesis, where one line of approaches focuses on generating large amounts of extra photo-realistic synthetic data \cite{Purkait18, Moreau21, chen2022dfnet} via randomly sampled virtual camera poses. However, generating high-quality offline synthetic data may take up to several days \cite{Moreau21} for each scene. Other approaches \cite{chen21, chen2022dfnet} use NeRF \cite{Mildenhall20,martinbrualla2020nerfw} as a direct matching module to perform unlabeled finetuning \cite{Brahmbhatt18} using extra images without ground-truth pose annotation. However, finetuning usually takes significant time and assumes that extra unlabeled data can be easily obtained.

While the aforementioned works enhance APR training, we focus on improving generic APR methods during test time. 
Unlike prior works that only exam means for test-time refinement on a single specific APR architecture, such as extended Kalman filters \cite{moreau2022coordinet}, pose graph optimization \cite{Brahmbhatt18}, or pose auto-encoders \cite{Shavit22PAE}, our method exhibits strong flexibility to be adapted to a wide range of APR architectures on both camera positions and orientations, achieving state-of-the-art results without extra unlabeled data.

Notably, classical geometry-based techniques \cite{Sattler12, Sattler17, sarlin21pixloc, sarlin2019HFNet, Lindenberger21, Brachmann17, Brachmann18, brachmann2020dsacstar} that require explicit feature correspondence search \cite{DeTone18, Sarlin20, Taira18, sun2021loftr, Li20, dusmanu2019d2} also employ test-time refinement to improve localization accuracy. For example, \cite{sarlin2019HFNet,sarlin21pixloc, Lindenberger21} build upon image retrievals and pre-computed SfM model to perform standard geometric refinement via neural network-based feature matcher, PnP+RANSAC, or dense featuremetric-alignment. Our method, however, offers end-to-end neural feature refinement via implicit representation, enhancing existing APR models without external storage, pre-computed data, or manual tuning.
% On the contrary, our proposed method is end-to-end neural feature refinement via implicit representation, operating on top of existing APR models without the need to store reference images or pre-computed 3D information on a remote server or an end device, or manual tunning the classical components.

\input{fig_tex/figure1_pipeline}
\textbf{Neural Radiance and Feature Fields.} Neural Radiance Fields (NeRF) \cite{Mildenhall20} revolutionized novel view image synthesis and 3D surface reconstruction. NeRF's implicit 3D representation and differentiable volume rendering enable self-supervised optimization from RGB images, avoiding costly 3D annotations. iNeRF \cite{yen2020inerf} showed that NeRF can be inverted for pose optimization. Recent approaches such as BARF \cite{lin21barf} and its counterparts \cite{wang2021nerfmm,Chng22garf,bian22nope} simultaneously train NeRF by treating camera poses as learnable parameters in simple, non-360\degree scenes. Parallel works,  NICE-SLAM \cite{niceslam} and iMAP \cite{imap}, use NeRF for dense geometry and real-time camera tracking. Direct-PN \cite{chen21} uses NeRF as a direct matching module to compute the photometric errors and propagate the error gradients back to the pose regression network. DFNet \cite{chen2022dfnet} extends this method to outdoor scenarios with robust feature extraction. LENS \cite{Moreau21} uses NeRF to generate a synthetic training dataset based on manually tuned scene bounds and parameters.

Recently, NeRF models have been extended to directly predict and render \textit{feature fields} alongside density and appearance fields. Typically, these feature fields are learned by supervision from a 2D feature extractor using volumetric rendering. \cite{neff,Kobayashi22,bhalgat2023contrastive} showed that these 3D feature fields outperform 2D baselines \cite{dino,clip_lseg,cheng2021mask2former} on downstream tasks such as 2D object retrieval or 3D segmentation. CLIP-Fields \cite{clip_fields} established feature fields as scene memory for robot navigation. This work explores distilled neural feature fields for camera relocalization, highlighting their role in test-time pose refinement.
