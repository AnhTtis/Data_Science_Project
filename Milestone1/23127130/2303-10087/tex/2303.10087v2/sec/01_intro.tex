\section{Introduction}
% \cs{1. briefly introduce apr\\
% 2. current ARP and limitations
% 3. there are geometric-based methods which use 3D principles
% 4. our solution is add 3D for ARP at inference\\
% put geometry to related work}~

Camera relocalization is a crucial task that allows machines to understand their position and orientation in 3D space. It is an essential prerequisite for applications such as augmented reality, robotics, and autonomous driving, where the accuracy and efficiency of pose estimation are important.
% Classical methods for solving this problem rely on geometry-based techniques \cite{Sattler12, Sattler17, sarlin21pixloc, sarlin2019HFNet, Lindenberger21, Brachmann17, Brachmann18, brachmann2020dsacstar} that require explicit feature correspondence search \cite{DeTone18, Sarlin20, Taira18, sun2021loftr, Li20, dusmanu2019d2}, which are typically multi-stage pipelines. 
Recently, Absolute Pose Regression (APR) methods \cite{Kendall15,Kendall16,Kendall17} have been shown to be effective in directly estimating camera pose from RGB images using convolutional neural networks. The simplicity of APR's architecture offers several potential advantages over classical geometry-based methods \cite{Sattler17, sarlin21pixloc, brachmann2020dsacstar}, involving end-to-end training, cheap computation cost, and low memory demand. %However, the inferior pose estimation accuracy have become a major painpoint for APR methods \cite{Sattler19}.

Latest advances in APR, particularly the use of novel view synthesis (NVS) \cite{Mildenhall20, martinbrualla2020nerfw, Shavit22PAE, chen21, chen2022dfnet, Moreau21} to generate new images from random viewpoints as data augmentation during training, have significantly improved the pose regression performance.
Despite this, state-of-the-art (SOTA) APRs still have the following limitations: 
(i) 
% While geometry-based methods estimate camera poses by minimizing some cost functions based on multi-view geometry, APR 
They predict the pose of a query image by passing it through a CNN, which typically disregards geometry at inference time.
% One major disadvantage of not taking geometry into account is that the
This causes APR networks to struggle to generalize to viewpoints that the training data fails to cover \cite{Sattler19};
(ii) The unlabeled data, often sampled from the validation/testing set, used for finetuning the APR network~\cite{Brahmbhatt18, chen21, chen2022dfnet} may not be universally available in real-life circumstances, and this semi-supervised finetuning is also time-consuming.
\input{fig_tex/figure0_teaser}

To address these limitations, we propose a novel test-time refinement pipeline for APR methods. Unlike prior works that
explore extended Kalman filters \cite{moreau2022coordinet}, pose graph optimization \cite{Brahmbhatt18}, or pose auto-encoders \cite{Shavit22PAE}, our method integrates an \textit{implicit} representation based geometric refinement into an end-to-end learning framework, where gradients can be backpropagated to the APR network. We test our proposed method across different APR architectures to demonstrate its robustness and effectiveness. 
Furthermore, we propose a Neural Feature Synthesizer (NeFeS) network to encode the 3D geometry of a scene into an MLP. NeFeS render dense features from novel viewpoints for refinement. To ensure the robustness of feature rendering, we introduce a Feature Fusion module into NeFeS that combines the rendered color and features and is trained in a progressive manner.
Our method leverages prior literature on volume rendering to inherently constrain geometric consistency during test time using implicit 3D neural feature fields. As such, our approach occupies a middle ground between APR and methods informed by geometry.

We summarize our main contributions as follows:
\textbf{First}, we propose a test-time refinement pipeline that greatly improves the pose-estimation accuracy of any APR model without using additional unlabeled data and exhibits a new \textit{single-frame} APR SOTA performance on standard benchmarks.
\textbf{Second}, we propose a Neural Feature Synthesizer (NeFeS) network that encodes 3D geometric features. NeFeS refines an initial pose by rendering a dense feature map and making the comparison with the query image feature.
\textbf{Third}, we propose a progressive training strategy and a Feature Fusion module to improve the robustness of the rendering ability of the NeFeS model. 

