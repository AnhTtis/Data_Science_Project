\begin{table}[t]
\caption{We compare the proposed refinement method using 7-Scene dSLAM GT pose \cite{Shotton13} with prior single-frame APR methods, in average of median translation error (m) and rotation error (\degree). Numbers in \boldred{bold} represent the best performance.}
\label{supp:table:7scene_dslam}
\centering
% \resizebox{0.65\linewidth}{!}{
\begin{tabular}{lc}
\toprule
Methods & Average \\

\midrule
PoseNet(PN)\cite{Kendall15}         & 0.44/10.4 \\
PN Learn $\sigma^2$\cite{Kendall17}   & 0.24/7.87 \\
geo. PN\cite{Kendall17}              & 0.23/8.12 \\
LSTM PN\cite{Walch17}               & 0.31/9.85 \\
Hourglass PN\cite{Melekhov17}     & 0.23/9.53 \\
BranchNet\cite{Wu17}            & 0.29/8.30 \\
MapNet\cite{Brahmbhatt18}        & 0.21/7.77 \\
Direct-PN\cite{chen21}           & 0.20/7.26 \\
TransPoseNet\cite{Shavit21}       & 0.18/7.78 \\
MS-Transformer\cite{Shavit21multiscene}      & 0.18/7.28 \\
\cite{Shavit21multiscene}+PAE \cite{Shavit22PAE}        & 0.15/7.28 \\
DFNet \cite{chen2022dfnet}          & 0.12/3.71 \\

\textbf{DFNet + }$\textbf{NeFeS}_{\textbf{50}}$ (dSLAM)  & \boldred{0.08}/\boldred{2.83} \\

\bottomrule
\end{tabular}
% }
\end{table}


% \begin{table}[t]
% \caption{\textbf{Comparison on 7-Scenes dSLAM GT Pose.} We compare the proposed refinement method using less accurate dSLAM GT pose with prior single-frame APR methods, in average of median translation error (m) and rotation error (\degree). Numbers in \boldred{bold} represent the best performance.}
% \label{table:99}
% \centering
% \resizebox{0.85\linewidth}{!}{
% \begin{tabular}{l|c}
% \\toprule
% Methods & Average \\

% \midrule
% PoseNet(PN)\cite{Kendall15}         & 0.44/10.4 \\
% PN Learn $\sigma^2$\cite{Kendall17}   & 0.24/7.87 \\
% geo. PN\cite{Kendall17}              & 0.23/8.12 \\
% LSTM PN\cite{Walch17}               & 0.31/9.85 \\
% Hourglass PN\cite{Melekhov17}     & 0.23/9.53 \\
% BranchNet\cite{Wu17}            & 0.29/8.30 \\
% MapNet\cite{Brahmbhatt18}        & 0.21/7.77 \\
% Direct-PN\cite{chen21}           & 0.20/7.26 \\
% TransPoseNet\cite{Shavit21}       & 0.18/7.78 \\
% MS-Transformer\cite{Shavit21multiscene}      & 0.18/7.28 \\
% \cite{Shavit21multiscene}+PAE \cite{}        & 0.15/7.28 \\
% DFNet \cite{}          & 0.12/3.71 \\

% DFNet + \textbf{NeFeS_{50} (ours)}  & \boldred{0.08}/\boldred{2.83} \\
% \bottomrule
% \end{tabular}
% }
% \end{table}