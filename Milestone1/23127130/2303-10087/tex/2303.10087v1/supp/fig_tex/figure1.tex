\begin{figure*}[ht]
  \centering
    \begin{tabular}{cccc}
      \includegraphics[width=0.24\linewidth]{supp/fig/PoseNet.pdf} &
      \includegraphics[width=0.24\linewidth]{supp/fig/MsTransformer.pdf}&
      \includegraphics[width=0.24\linewidth]{supp/fig/DFNet.pdf}&
      \includegraphics[width=0.24\linewidth]{supp/fig/DFNet_NeFeS.pdf}\\
      (a) PoseNet\cite{Kendall15,Kendall16,Kendall17} & (b) MS-Transformer\cite{Shavit21multiscene} & (c) DFNet\cite{chen2022dfnet} & (d) \textbf{DFNet+NeFeS$_{50}$}
    \end{tabular}
\caption{Qualitative comparison on the 7-Scenes dataset. The 3D plots show the camera positions: \textcolor{green}{green} for ground truth and \textcolor{red}{red} for predictions. The bottom color bar represents rotational errors for each subplot, where yellow means large error and blue means small error for each test sequence. Sequence names from top to bottom are: fire [$1000$-$1500$], office [$2500$-$3000$], pumpkin [$500$-$1000$], kitchen [$1000$-$1500$], kitchen [$1500$-$2000$].
Since each scene has different numbers of frame, we select $500$ frames from each of them and append the range after scene's name.
% The sequence names \textit{scene-n} denote that the $n^{th}$ $500$ frames are used as the testing sequence for the \textit{scene}.
}
\label{fig:7scenes_qualitative}
\end{figure*}