\section{Introduction}
% Camera relocalization is a fundamental problem in computer vision, which aims to estimate the camera pose with respect to a known 3D scene. 
% The accurate and efficient pose estimation is crucial for a range of applications, including augmented and virtual reality, robotics, and autonomous driving, as it significantly impacts the overall performance of higher-level applications. 
Camera relocalization is a crucial task that allows machines to understand their position and orientation in 3D space. 
It is an essential prerequisite for applications such as augmented reality, robotics, and autonomous driving, where the accuracy and efficiency of pose estimation is important. 

\input{fig_tex/figure0_teaser}

Classical methods for solving this problem rely on geometry-based techniques \cite{Sattler12, Sattler17, sarlin21pixloc, sarlin2019HFNet, Lindenberger21, Brachmann17, Brachmann18, brachmann2020dsacstar} that require explicit feature correspondence search \cite{DeTone18, Sarlin20, Taira18, sun2021loftr, Li20, dusmanu2019d2}, which is a challenging task in itself. Recent Absolute Pose Regression (APR) methods \cite{Kendall15,Kendall16,Kendall17} have been shown to be effective in estimating camera pose from RGB images by using convolutional neural networks. They use direct regression and hence offer advantages such as fast inference speed, low memory requirements, and end-to-end training. However, their accuracy is still lower than that of geometry-based techniques \cite{Sattler19, Shavit19}.


Recent advances in APR \cite{Shavit21multiscene, Shavit21, Shavit22PAE, chen21, chen2022dfnet, Moreau21}, particularly the use of novel view synthesis (NVS) \cite{Mildenhall20, martinbrualla2020nerfw, Shavit22PAE, chen21, chen2022dfnet, Moreau21} to generate new images from random viewpoints as data augmentation, have significantly improved the performance. 
Despite this, state-of-the-art (SOTA) APRs still have the following limitations: 
i) While the geometry-based methods estimate camera poses by minimizing some cost functions based on multi-view geometry, APR predicts the pose of a query image by passing it through the CNN, which typically disregards geometry in inference time. 
One of the disadvantages of not taking geometry into account is that the APR network struggles to generalize to viewpoints that the training data fail to cover;
% i) The accuracy of the APRs depends on how well the NVS generated synthetic training data \cite{chen2022dfnet, Moreau21} cover the testing sequences, which can result in poorer pose accuracy for testing regions that are not sufficiently covered during training;
ii) The unlabeled data, often sampled from the validation/testing set, used for finetuning the APR network~\cite{Brahmbhatt18, chen21, chen2022dfnet} may not be universally available in real-life circumstances, and this semi-supervised finetuning is time-consuming. 
% iii) The reliance on 2D convolution backbones in the forward process of APRs means that the network predictions are not constrained by any geometry.

% To address these limitations, we propose a novel method called Neural Feature Synthesizer (NFS),
% which can encode 3-D geometry features during training and render dense novel view features at test time.
% We use the rendered features to refine estimated camera poses by APRs.
% While previous studies have used novel view rendering on additional unlabeled data in an extra training stage, our test-time refinement by dense feature rendering eliminates the need for additional unlabeled training and enforces geometry constraints in inference.
% % Unlike existing approaches that require finetuning of Absolute Pose Regression (APR) models with unlabeled data, our method is solely focused on test-time refinement, eliminating the need for additional unlabelled training. While previous studies have used explicit novel view rendering to enhance APR methods during training, the use of test-time direct dense feature rendering is a novel contribution of our work. 
% Thanks to volume rendering, our 3D neural feature fields inherently constrain geometry consistency, so the proposed method obviates the need for an explicit 3D model.
% In addition, we explore a new black-box scenario where we refine camera pose estimation from black-box pose estimators beyond APR approaches, \eg, image retrieval methods.
% The results show that our post-processing method works well with arbitrary pose estimators,
% and we provide an in-depth analysis of the performance bound of our method.

% To address these limitations, we propose a novel method called Neural Feature Synthesizer (NFS), which can encode 3-D geometry features during training and render dense novel view features at test time. 
To address these limitations, we propose a novel test-time refinement pipeline for APR methods. 
While traditional geometry-based methods commonly use test-time refinement for improving localization accuracy \cite{cavallari2017fly,sarlin21pixloc, Lindenberger21}, 
our post-processing method is the first to integrate a geometric refinement into an end-to-end neural network-based framework.
To this end, we design a Neural Feature Synthesizer (NeFeS), which is trained to encode robust 3D geometric features of a scene into an MLP. 
The NeFeS can render dense feature maps from novel viewpoints for refinement during testing.
% This direct dense feature rendering approach, compared with previous studies that used rendered RGB images in an extra training stage, eliminates the need for additional unlabeled data and enforces geometry constraints in inference.
% While previous studies have used RGB-based novel view rendering on additional unlabeled data in an extra training stage, our test-time refinement approach by direct dense feature rendering eliminates the need for additional unlabeled training and enforces geometry constraints in inference.
To ensure the robustness of the rendered features, we devise a feature fusion module that fuses both color and features, and propose a progressive training strategy for the NeFeS model. Our method leverages the prior literature on volume rendering to inherently constrain geometric consistency during test time using implicit 3D neural feature fields, without relying on an explicit 3D model like most 3D structure-based methods. As such, our approach occupies a middle ground between APR and methods informed by geometry. 

%\cs{Remove last section?}~
%Furthermore, our method can decouple pose refinement from specific pose estimators, enabling us to explore a new \textit{black-box} scenario where our method could refine poses from unknown pose estimators or methods beyond APR approaches, such as image retrieval. The results show that our post-processing method works well with multiple APR and non-APR pose estimation architectures, and we provide an in-depth analysis of the performance bounds of our method.

% We summarize our main contributions as follows:
% \begin{enumerate}[leftmargin=*]
%     % \item We propose a Neural Feature Synthesizer (NFS) network for test-time refinement of APRs predicted poses.
%     \item We propose a test-time refinement pipeline that greatly improves the accuracy of the estimated pose from APR methods without using additional unlabeled data.
    
%     % \item We propose a progressive learning strategy and a feature fusion module that fuses color and dense feature maps for robust feature rendering.
%     \item We propose a Neural Feature Synthesizer (NFS) network that encodes 3-D geometry features. Given an initial pose, the NFS refines it by rendering a dense feature map, comparing it with the query image features, and back-propagating the error. 
    
%     \item We propose a progressive learning strategy and a feature fusion module to improve the robustness of the NFS model's rendering ability. 
    
%     \item We show that our method can be used in black-box scenarios where the type of pose estimators is unknown.
    
% \end{enumerate}


We summarize our main contributions as follows:
% \item We propose a Neural Feature Synthesizer (NFS) network for test-time refinement of APRs predicted poses.
\textbf{First}, we propose a test-time refinement pipeline that greatly improves the accuracy of the estimated pose from APR methods without using additional unlabeled data, and produces a new \textit{single-frame} APR SOTA on standard benchmarks.
% \item We propose a progressive learning strategy and a feature fusion module that fuses color and dense feature maps for robust feature rendering.
\textbf{Second}, we propose a Neural Feature Synthesizer (NeFeS) network that encodes 3D geometric features. Given an initial pose, the NeFeS refines it by rendering a dense feature map, comparing it with the query image features, and back-propagating the error. 
\textbf{Third}, we propose a progressive learning strategy and a feature fusion module to improve the robustness of the rendering ability of the NeFeS model. 
%\textbf{Finally}, we show that our method can be used in black-box scenarios where the type of pose estimators is unknown.


% We demonstrate our method's effectiveness on both indoor 7-Scenes \cite{Glocker13,Shotton13} and outdoor Cambridge Landmarks \cite{Kendall15} datasets. As a result, our approach achieves \textit{single-frame} APR state-of-the-art performance without leveraging additional unlabeled training data.


% The proposed method provides a promising direction for improving the accuracy and efficiency of APR methods in real-world applications, where limited resources and time are often critical factors. Our results show that the proposed NFS model is advantageous in improving APR performance, providing a more effective means of bridging the gap between APR and geometry-based approaches.

% \cs{Things we left over:\\
% 1. Improve Abstract\\
% 4. Finish up Related work\\
% 5. merge 3.2 into 3.3 and making subsections in 3.3.1\\
% 6. 4.7, 4.8 exp.\\
% 7. improve figure 1.\\
% 8. qualitative comparisons before and after NFS refinement\\
% 9. conclusion\\
% 10. Final scheme over the whole paper make sure things are consistent and clearly written \\
% }~

%%%%%%%%%%%%%%%%%%%%%%%%%%% NFF Pitch %%%%%%%%%%%%%%%%%%%%%%%%%
% The Neural Radiance Fields (NeRF) has attracted many Computer Vision researchers' interest in recent years and has significantly advanced novel view image synthesis and 3D surface reconstruction. 
% The core of the Neural Radiance Field is an implicit 3D representation and differentiable volume rendering that allow self-supervised optimization from only RGB images without expensive 3D ground-truth annotations. 
% The existing methods mainly explore color rendering, and based on their success, we hypothesize that the image features can also be encoded in the implicit representations. This is a very promising research question because image features are wide-used in computer vision tasks such as semantic segmentation, object detection, and dense correspondence. 
% In this paper, we study the volume rending of CNN-learned image features, called Neural Feature Field (NFF), and demonstrate the potential use of rendered 3D features for camera relocalization

% The relocalization problem was mainly addressed by using geometry-based methods that rely on explicitly searching for feature correspondences,
% while the correspondence problem is challenging in itself and the drawback of this classic pipeline has been known. 
% In recent years, many researchers pay attention to the Absolute Pose Regression (APR)~\cite{} methods that enable directly regressing pose by using convolutional neural networks. The APR methods have many distinctive advantages, involving fast inference speed, low memory requirements, and end-to-end training, although their accuracy is still lower than geometry-based methods. We follow this line of work and propose Neural Feature Field to boost performance.

% Thanks to NeRF~\cite{}, which provides the implicit 3D representation with volume rendering, the problem of novel view synthesis has been significantly boosted. Although using the rendered novel view images to improve camera relocalization is not new~\cite{}, we are the first to attempt direct dense feature rendering in this problem. 
% Specifically, we propose to encode the CNN-learned geometry features in the training stage, and we render novel view features for refining camera poses that are regressed by APR methods. 
% Our method is a plug-and-play model that only needs to be trained once and can be adapted to different APR architectures without further finetuning. This bridges the gap between APR methods and the geometry-based approaches since the 3D feature fields are inherently geometric constrained without building an explicit 3D model.

% A crucial component of our method is a feature fusion architecture that improves the robustness of NFF and can be trained end-to-end using a progressive training strategy. In addition, we propose a test-time refinement setup, thus to completely get rid of the need for further finetuning APR models with unlabeled data to obtain high accuracy pose estimation, which for: (i) the data may not be universally available in real-life circumstances, and (ii) the unlabeled training process often takes tens of hours for additional training time. Furthermore, we explore a new black-box scenario for making our post-processing method more versatile. Specifically, our method is able to refine camera pose estimation beyond APR approaches, such as image retrieval methods.  

% We demonstrate its effectiveness on several benchmark datasets. Our approach achieves \textit{single-frame} APR SOTA performance without leveraging unlabeled training data. Our method provides a promising direction for improving the accuracy and efficiency of APR methods in real-world applications, where limited resources and time are often critical factors.

% We summarize our main contributions as follows:
% \begin{enumerate}[leftmargin=*]
%     \item We introduce a test-time post-processing method for APRs, which iteratively refine poses using direct novel feature synthesis.

%     \item We propose a neural feature field (NFF) network that is customized for camera relocalization tasks. To obtain robust novel feature views, we devise a feature fusion module to fuse color and dense feature maps and introduce a progressive learning strategy.
    
%     \item We further demonstrate that our method can be expanded to support pose refinement over non-APR methods such as image retrievals or optimize in scenarios where the pose estimator is a black box.
% \end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Traditional relocalization approaches rely on multi-view geometry by matching 2D image pixels to 3D world coordinates first, then solving a Perspective-n-Point (PnP) problem within a robust outlier rejection scheme (cite RANSAC...). Although recent deep 3D-based methods have shown state-of-the-art accuracy by learning better feature representations, training more accurate scene coordinate regressions, or incorporating differentiable outlier filtering, many constraints, such as the requirement of tuning the classical components and the often need for building and storing an accurate 3D model of the scene. On the other hand, an alternative end-to-end neural network-based approach known as Absolute Pose Regression (APR) has recently been quickly catching up in attention, where the absolute pose of the camera is directly regressed from input images without using prior knowledge of the 3D environment. Although the APR methods require longer training time and sometimes achieve inferior accuracy compared to 3D-based methods, it trades off with much faster inference time ($<6ms$) and low-storage memory, even in large-scale environments.

% Recent APR approaches have been quickly catching up in performance. One approach that has significantly improved APR accuracy is using novel view synthesis (NVS) to explicitly render RGB color views given camera poses during APR training \cite{chen21,Moreau21,chen2022dfnet,Shavit22PAE}. This technique generates new scene views from arbitrary camera viewpoints by combining information from multiple input views. However, state-of-the-art APRs still have several major limitations: (1) NeRF can be used to generate large amounts of high-fidelity synthetic training sets based on randomly generated scene poses. However, the accuracy of the APRs highly correlates to how well the generated training poses cover the testing sequences. It is likely to produce poorer pose estimation for test views that are not sufficiently covered during the training process  (2) Several methods \cite{Brahmbhatt18,chen21,chen2022dfnet} show that it is able to boost the APR's performance further by finetuning the APR method using additional unlabeled data without ground truth poses. However, such data may not be universally available in real-life circumstances, and the unlabeled training process often takes tens of hours for additional training time. (3) The forward process of the APRs has been heavily relying on 2D convolutions, and the network predictions are not constrained by any geometry.

% To address these limitations, we propose a novel test-time post-processing method that uses a Neural Feature Field to encode dense feature descriptors of 3D scenes and refine estimated camera poses at the test time. Our method is a plug-and-play model that only needs to be trained once and can be adapted to different APR architectures without further finetuning. We also bridge the gap between APR inference and the geometry-based approaches since the 3D feature fields are inherently geometric constrained without building an explicit 3D model. A crucial component of our method is an RGB-feature fusion architecture that improves the robustness of NFF and can be trained end-to-end using a progressive training strategy. Furthermore, we explore a new black-box scenario for making our post-processing method more versatile. Specifically, our method is able to refine camera pose estimation beyond APR approaches, such as image retrieval methods. 

% We demonstrate its effectiveness on several benchmark datasets. Our approach achieves \textit{single-frame} APR SOTA performance without leveraging unlabeled training data. Our method provides a promising direction for improving the accuracy and efficiency of APR methods in real-world applications, where limited resources and time are often critical factors.

% \cs{considering combining paragraph 2,3. Better writing on the last part. How we did it. What results}~\\
% Summarize:
% 1. generic black box/white box
% 2. get rid of unlabeled training
% 3. test-time + 3D geomtry -> solve APR formulation without 3D

% \clearpage

% Camera pose estimation is a fundamental problem in Computer Vision and has practical applications in augmented and virtual reality, robotics, and autonomous driving.
% % The problem is also known as Camera Relocalization and 
% The accuracy and efficiency of pose estimation are critical because they heavily influence the overall performance of higher-level applications. 
% Traditional methods rely on multi-view geometry that addresses the challenge by matching sparse feature points first~\cite{},
% followed by solving a Perspective-n-Point (PnP) problem~\cite{} within a robust outlier rejection scheme~\cite{Fischler81Ransac,magsac,magsac++}. 
% % \kejie{long sequence:}~Geometric methods that rely on hand-crafted features may not be robust to changes in lighting, texture, or occlusion. 
% A main bottleneck of this pipeline is hand-crafted features that are sensitive to changes in lighting, texture, and occlusion.
% To address the challenge, deep learning-based methods~\cite{} have been proposed to learn better feature representations and have shown significant improvement.
% However, these methods still suffer from the drawbacks of the classical pipelines and cannot be optimized end-to-end.

% In recent years, deep learning-based methods have made significant progress in this area through an end-to-end neural network approach known as Absolute Pose Regression (APR), where the absolute pose of the camera is directly regressed from input images without using prior knowledge of the 3D environment. Compared to the classical geometric methods, APR methods are much faster during inference but require longer training times and sometimes achieve inferior accuracy. One of the primary challenges with APR is to develop methods that can handle a wide range of camera poses and environmental conditions. One approach that has shown significant improvement in APR accuracy is using novel view synthesis (NVS) to explicitly render RGB views given a camera pose. This technique involves generating new views of a scene from arbitrary camera viewpoints by combining information from multiple input views. Several recent APR methods, including Direct-PN, LENS, DFNet, and PAE, have leveraged this technique to improve pose accuracy.

% Despite these advancements, some of these methods have certain limitations. For example, the prior state-of-the-art network DFNet uses a direct feature-matching formulation that extracts features from a CNN network. While this method achieves state-of-the-art accuracy, it requires additional unlabeled data beyond the training set, which may not be universally available in real-life circumstances. Additionally, the method takes tens of hours to train with fine-tuning of unlabeled data and is fixed to specific types of APR methods that contain DFNet's backbone.

% \YB{Can we add some more limitations here?} \\

% \kejie{Why the fintuning in DF-Net cannot generalise to other methods? What about the limitations of other approaches (i.e. PAE, LENS)}\\

% \cs{Direct-PN does not work on outdoor scene}\\
% \cs{DFNet works fine but still distance from 3D based methods. the direct matching model DFNet$_{dm}$ requires extra unlabeled data to train for tens of hours}\\
% \cs{PAE only refines translation, not rotation. Also the improvement is extremely small}\\
% \cs{LENS is seq. APR. that use NeRF to generate synthetic datasets. Does not refine on test set.}\\

% \kejie{The fundamental limitation of APR is the network predictions are not constrained by any geometry. The proposed test-time fintuning can solve this problem, and bridging the gap to geometry-based approach.}\\
% \cs{Agreed}\\

% To address these limitations, we propose a novel post-processing method that uses a Neural Feature Field (NFF) to encode feature descriptors of 3D scenes and refine estimated camera poses at the test time. Our method is a plug-and-play model that only needs to be trained once and can be adapted to different APR architectures without further fine-tuning. A crucial component of our method is a RGB+feature fusion architecture that improves the robustness of NFF and can be trained end-to-end using a 2-stage optimization. In summary, we present our method and demonstrate its effectiveness on several benchmark datasets. We show that our approach achieves \textit{single-frame} APR SOTA performance without leveraging unlabeled training data. Our method provides a promising direction for improving the accuracy and efficiency of APR methods in real-world applications, where limited resources and time are often a critical factor.


