% \section{IntroductionV2}

% The Neural Radiance Field has attracted many Computer Vision researchers' interest in recent years and has significantly advanced novel view image synthesis~\cite{} and 3D surface reconstruction~\cite{}.
% The core of the Neural Radiance Field is an implicit 3D representation and differentiable volume rendering that allow self-supervised optimization from only RGB images without expensive 3D ground-truth annotations.
% The existing methods mainly explore colour rendering,
% and based on their success, we hypothesize that the image features can also be encoded in the implicit representations.
% This is a very promising research question because image features are wide-used in computer vision tasks such as semantic segmentation, object detection, and dense correspondence.
% In this paper, we study the volume rending of CNN-learned image features, called Neural Feature Field (NFF), 
% and we demonstrate the potential use of rendered features for Camera Relocalization.

% The relocalization problem was mainly approached by using traditional geometric methods,
% while in recent years, researchers have shifted attention to end-to-end learning-based methods,
% known as Absolute Pose Regression (APR).
% In this new method, the absolute pose of the camera is directly regressed from input images without using prior knowledge of the 3D environment. 
% Compared to the classical geometric methods, APR methods are much faster during inference but require longer training times and sometimes achieve inferior accuracy. 
% One of the primary challenges with APR is to develop methods that can handle a wide range of camera poses and environmental conditions.



% One approach that has shown significant improvement in APR accuracy is using novel view synthesis (NVS) to explicitly render RGB views given a camera pose. This technique involves generating new views of a scene from arbitrary camera viewpoints by combining information from multiple input views. Several recent APR methods, including Direct-PN, LENS, DFNet, and PAE, have leveraged this technique to improve pose accuracy.


% 1. NeRF -> RGB -> NFF -> Relocalization\\

% 2. Camera relocalization -> APR -> choose Feature -> 3D + robustness outdoor (high-level advantage). No unlabel data \\

% 3. How we did. 1. Test-time refinement APR or unknown relocalizer pose. 2. Feature field -> Fusion block, progressive training, Adaptive ACT. 

% Summarize:
% 1. generic black box/white box
% 2. get rid of unlabeled training
% 3. test-time + 3D geomtry -> solve APR formulation without 3D

% Related work:
% 1. background


