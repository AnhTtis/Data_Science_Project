\begin{figure*}[ht]
    \centering
    \includegraphics[width=.9\linewidth]{pdf/NFS_arch.pdf}
    \caption{The architecture of our proposed NeFeS model. The query 3D position $\mathbf{x}$ is fed to the network after positional encoding $PE(\cdot)$. The network then splits into two heads: the static head and the transient head. Given a viewing direction $\mathbf{d}$, the rendered color map is generated by fusing static RGB value $c^{(s)}_{i}$, the transient RGB value $c^{\tau}_{i}$ and their corresponding density values $\sigma^{(s)}_{i}$ and $\sigma^{\tau}_{i}$, while the rendered feature map is formed only by static features $\mathbf{f}_{i}$ and density $\sigma^{(s)}_{i}$. In addition, the color map adopts exposure-adaptive ACT to compensate for exposure differences between images. The final feature map $\hat{\mathbf{F}}_{fusion}$ is the concatenation of rendered RGB and feature map processed by the convolutional fusing layer.}
    \label{fig:NFS_arch}
\end{figure*}