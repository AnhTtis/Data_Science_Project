 \begin{figure}[t]
\centering
\includegraphics[width=1.0\columnwidth]{figures/intro_case_fig.pdf}
\vspace{-2em}
\caption{
A sample tweet with its image on the left. On the right,  the tweet text is shown on the top, followed by the comments retrieved from similar tweets.
The word ``\textcolor{blue}{snow}''  (in blue) in comments helpfully hint the implicitly shared semantics between image and text.
% \jing{We may boldface the titles, i.e., ``Text'' and ``Retreved Comments''. And color the keyword ``snow'' in comments with blue.} \xu{replace the case}
%The proposed retrieval-based comment-aware self-training framework.
%representations encoded from texts (bottom), captions (upper left), and images (upper right).
%The encoded captions and texts are compared at output layer in visual-textual contexts.
%Multi-head attentions are employed to explore text-caption and image-text interactions. 
%The attended images, captions, and max-pooled texts are integrated to predict the discourse labels.
}
\vspace{-1em}
\label{fig:intro}
\end{figure}