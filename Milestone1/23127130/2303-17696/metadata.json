{
    "arxiv_id": "2303.17696",
    "paper_title": "Dual Cross-Attention for Medical Image Segmentation",
    "authors": [
        "Gorkem Can Ates",
        "Prasoon Mohan",
        "Emrah Celik"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2024-08-02"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
    ],
    "abstract": "We propose Dual Cross-Attention (DCA), a simple yet effective attention module that is able to enhance skip-connections in U-Net-based architectures for medical image segmentation. DCA addresses the semantic gap between encoder and decoder features by sequentially capturing channel and spatial dependencies across multi-scale encoder features. First, the Channel Cross-Attention (CCA) extracts global channel-wise dependencies by utilizing cross-attention across channel tokens of multi-scale encoder features. Then, the Spatial Cross-Attention (SCA) module performs cross-attention to capture spatial dependencies across spatial tokens. Finally, these fine-grained encoder features are up-sampled and connected to their corresponding decoder parts to form the skip-connection scheme. Our proposed DCA module can be integrated into any encoder-decoder architecture with skip-connections such as U-Net and its variants. We test our DCA module by integrating it into six U-Net-based architectures such as U-Net, V-Net, R2Unet, ResUnet++, DoubleUnet and MultiResUnet. Our DCA module shows Dice Score improvements up to 2.05% on GlaS, 2.74% on MoNuSeg, 1.37% on CVC-ClinicDB, 1.12% on Kvasir-Seg and 1.44% on Synapse datasets. Our codes are available at: https://github.com/gorkemcanates/Dual-Cross-Attention",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17696v1"
    ],
    "publication_venue": "Code: https://github.com/gorkemcanates/Dual-Cross-Attention",
    "doi": "10.1016/j.engappai.2023.107139"
}