{
    "arxiv_id": "2303.10865",
    "paper_title": "Rotating Objects via In-Hand Pivoting using Vision, Force and Touch",
    "authors": [
        "Shiyu Xu",
        "Tianyuan Liu",
        "Michael Wong",
        "Dana KuliÄ‡",
        "Akansel Cosgun"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 2,
    "categories": [
        "cs.RO"
    ],
    "abstract": "We propose a robotic manipulation system that can pivot objects on a surface using vision, wrist force and tactile sensing. We aim to control the rotation of an object around the grip point of a parallel gripper by allowing rotational slip, while maintaining a desired wrist force profile. Our approach runs an end-effector position controller and a gripper width controller concurrently in a closed loop. The position controller maintains a desired force using vision and wrist force. The gripper controller uses tactile sensing to keep the grip firm enough to prevent translational slip, but loose enough to induce rotational slip. Our sensor-based control approach relies on matching a desired force profile derived from object dimensions and weight and vision-based monitoring of the object pose. The gripper controller uses tactile sensors to detect and prevent translational slip by tightening the grip when needed. Experimental results where the robot was tasked with rotating cuboid objects 90 degrees show that the multi-modal pivoting approach was able to rotate the objects without causing lift or slip, and was more energy-efficient compared to using a single sensor modality and to pick-and-place. While our work demonstrated the benefit of multi-modal sensing for the pivoting task, further work is needed to generalize our approach to any given object.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10865v1",
        "http://arxiv.org/pdf/2303.10865v2"
    ],
    "publication_venue": "8 pages, 7 figures, 4 tables"
}