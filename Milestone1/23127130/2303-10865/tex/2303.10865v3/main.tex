\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts
\usepackage{float}
\usepackage{hyperref}

\usepackage[percent]{overpic}

\usepackage{gensymb}
% \usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{comment}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[super]{nth}
\usepackage{textcomp}
%\usepackage{xcolor}
\usepackage[font=smaller]{caption}
\usepackage{subcaption}
% \usepackage{refcheck}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage{algcompatible}

%--------- Akan Defined ---------------%
\def\ua{\uparrow}
\def\da{\downarrow}
\usepackage{color, colortbl}
%\definecolor{name}{system}{definition}
\definecolor{LightGray}{gray}{0.85}
\definecolor{LightCyan}{rgb}{0.88,1,1}

% More defined colors
%\usepackage[dvipsnames]{xcolor}
\setlength{\tabcolsep}{4pt}
\usepackage{todonotes}

\newcommand{\mytodo}[1]{\todo[inline,color=yellow!60]{\textbf{TODO:} #1}}
\usepackage{balance}
\setlength{\tabcolsep}{3pt}
\usepackage{xcolor}
\usepackage[export]{adjustbox}
%---------------------------------------------%

%----Akan's Space ninja stuff----
\usepackage{titlesec}
\titlespacing{\section}{0pt}{*0.25}{*0.25}
\titlespacing{\subsection}{0pt}{*0.25}{*0.25}
\setlength{\textfloatsep}{1pt}
\setlength{\intextsep}{7pt}
\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{2pt}
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\captionsetup[subfigure]{aboveskip=2pt,belowskip=2pt}
\captionsetup[figure]{aboveskip=2pt,belowskip=2pt}
%---

\usepackage{geometry}
 \geometry{
 letterpaper,
 top=54pt,
 left=54pt,
 right=54pt,
 bottom=54pt,
 }

\begin{document}

\newgeometry{
 letterpaper,
 top=72pt,
 left=54pt,
 right=54pt,
 bottom=54pt,
 }

%\title{\LARGE \bf Robotic manipulation via dragging and pivoting using multi-modal contact state estimation}
%\title{\LARGE \bf Pivoting objects via in-hand manipulation using multi-modal sensing}
%\title{\LARGE \bf Pivoting Objects via In-Hand Manipulation using Vision, Force and Touch}
\title{\LARGE \bf Rotating Objects via In-Hand Pivoting using \\Vision, Force and Touch}
%\title{\LARGE \bf Reorienting Objects via In-Hand Pivoting using Vision, Force and Touch}
 
\author{Shiyu Xu$^{1}$, Tianyuan Liu$^{1}$, Michael Wong$^{1}$, Dana KuliÄ‡$^{1}$, Akansel Cosgun$^{2}$
\thanks{\hspace*{-1em}$^{1}$Monash University, Australia\newline
$^{2}$Deakin University, Australia}
\thanks{This work was supported in part by D. Kuli\'c's Australian Research Council Future Fellowship (FT200100761).}}
\maketitle

%\include{dump.tex}
\begin{abstract}

%We propose a robotic manipulation system that can reorient objects laying on a surface by employing sensor-based control using vision, force and touch sensing.
%We study r
We propose a robotic manipulation method that can pivot objects on a surface using vision, wrist force and tactile sensing. We aim to control the rotation of an object around the grip point of a parallel gripper by allowing rotational slip, while maintaining a desired wrist force profile. Our approach runs an end-effector position controller and a gripper width controller concurrently in a closed loop. The position controller maintains a desired force using vision and wrist force. The gripper controller uses tactile sensing to keep the grip firm enough to prevent translational slip, but loose enough to allow rotational slip. Our sensor-based control approach relies on matching a desired force profile derived from object dimensions and weight, as well as vision-based monitoring of the object pose. The gripper controller uses tactile sensors to detect and prevent translational slip by tightening the grip when needed. Experimental results where the robot was tasked with rotating cuboid objects 90 degrees show that the multi-modal pivoting approach was able to rotate the objects without causing lift or translational slip, and was more energy-efficient compared to using a single sensor modality or pick-and-place.

\end{abstract}
\section{Introduction}
% \vspace{-0.01cm}

Robotic manipulation can be prehensile or non-prehensile. Prehensile manipulation involves capturing the object (e.g., via grasping) and requires achieving stable control over the grasped object. During object transport, prehensile manipulation requires the object to be lifted and held stably in the grasp. Non-prehensile manipulation, on the other hand, is a type of manipulation where objects are manipulated without grasping them. Non-prehensile manipulation allows a robot to perform a wider range of tasks than prehensile manipulation and can be more energy-efficient than prehensile manipulation because it does not require the robot to use as much force to move the object. In this study, we focus on performing pivoting actions on objects grasped by a parallel gripper. As shown in Fig.\ref{fig:intro}, this action takes an interesting middle ground between non-prehensile and prehensile manipulation. On the one hand, it requires the object to be grasped and gives the robot more stable control over the pose of the object. On the other hand, the action does not require the target object to be lifted, requiring much less effort than performing a full pick and place \cite{aiyama1993pivoting}. With less force exerted, this approach allows the manipulation of objects heavier than the maximum payload of a robot \cite{saeedvand2021hierarchical}.

% \begin{figure}[ht!]
%     \centering
%     %\def\figheight{5cm}
%     \begin{subfigure}[t]{0.49\columnwidth}
%     \centering
%     \includegraphics[trim={1500 400 300 250}, clip, width=\columnwidth,angle=270]{Pics/final pivoting 1.jpg}
%     \label{subfig: new pivoting1}
%     \end{subfigure}
%     %\hfill
%     %
%     \begin{subfigure}[t]{0.49\columnwidth}
%     \centering
%     \includegraphics[trim={1500 400 300 250}, clip, width=\columnwidth,angle=270]{Pics/final pivoting 2.jpg}
%     \label{subfig: new pivoting2}
%     \end{subfigure}
    
%     \caption{The robot pivots a box by 90 degrees. Our approach uses end-effector position control and gripper width control in a closed loop. Vision and wrist force are used to maintain a desired force profile using position control. A gripper-width controller, which is running concurrently, uses tactile sensing to keep the grip firm enough to prevent translational slip, but loose enough to induce rotational slip.}
%     \label{fig: new pivoting}
    
% \end{figure}



\begin{figure}[t!]
    \centering
    \includegraphics[trim={5 20 0 30}, clip, width=0.32\linewidth]{Pics/new_pics/heavy_long_pivot_1.png} 
    \includegraphics[trim={10 0 0 0}, clip, width=0.32\linewidth]{Pics/new_pics/heavy_long_pivot_2.png}
    \includegraphics[trim={60 15 10 0}, clip, width=0.32\linewidth]{Pics/new_pics/heavy_long_pivot_3.png}
    \caption{The robot pivots a box by 90 degrees in one motion while maintaining contact between the box and the surface. The end effector position is controlled using vision and wrist force sensing while the gripper width is controlled using tactile sensing.}
    \label{fig:intro}
\end{figure}



This study investigates reorienting an object grasped by a parallel gripper using pivoting actions. To achieve in-hand manipulation with a simple parallel gripper with no dexterous capabilities, we make use of extrinsic environmental factors \cite{dafle2014extrinsic}. Specifically, once the object is grasped, gravity is used to induce slip and rotate the object in-hand when lifting the gripper. Meanwhile, friction with the surface provides an opposing force to fully pivot the object. Thus, to allow this friction, the object must also be kept in contact with the surface during the motion. 

As shown in Fig.\ref{fig:intro}, to avoid the need to turn the gripper along with the box, which introduces additional kinematic constraints on the robot, the box is allowed to rotate around the grasp point. Enabling slip in the grasp of the object is a non-trivial problem. To achieve the desired slip, the appropriate gripper force or finger width needs to be chosen in accordance to the properties of the object. To gain better insight into the forces that can induce in-hand slip, we follow other works on slip detection \cite{costanzo2018slipping, huh2020dynamically, meier2016tactile} in differentiating slip into two types, rotational slip and translational or linear slip. As shown in Fig.\ref{fig: slip types}, in rotational slip, the object is allowed to rotate while remaining grasped, with its centre of rotation at the grasp point and remaining in place as the object moves. Translational or linear slip involves the object moving away from the original grasping point. These two types of slip can occur on their own or simultaneously. For an in-hand pivoting task, the goal is to avoid translational slip, while allowing rotational slip \cite{toskov2022hand}.

Similarly, the trajectory of the pivoting motion also needs to be adjusted to ensure the object remains in contact with the surface. Visual information may be used to determine the object's pose, but contact with the surface may be challenging to estimate visually. On the other hand, force data can be used to derive whether the object is lifted by the robot, but otherwise would provide little information about the object's pose. 

We propose using multi-modal sensing in closed-loop control that can adjust both the robot arm trajectory and the gripper width to complete a pivoting action. The object state 

% page splitting shenanigans for geometry and margins
\restoregeometry

\begin{figure}[t!]
    \centering
    \includegraphics[trim={0 50 0 50}, clip, width=0.8\linewidth]{Pics/slip_types.png}
    \caption{The two types of slip. The dotted outline describes the original position, and solid shape is the position after slip. The blue object is the gripper fingers.}
    \label{fig: slip types}
\end{figure}

\noindent will be continuously detected through force/torque data at the parallel fingers and wrist of the gripper, as well as visual information from an RGB-D camera. Pivoting of the grasped object will then be achieved through motion planning with the arm's end-effector coupled with a position controller, while slip will be managed by adjusting the gripper width. 
Overall, the main contributions of this study are: 
\begin{itemize}
    %\item A slip detection algorithm using tactile force data as input, capable of differentiating translational and rotational slip
    \item A vision and force-based position controller for the arm trajectory that integrates an analytical force profile and object pose information
    \item A tactile sensor-based gripper width controller for parallel grippers that tightens based on detected slip
    %\item Experiments that validate both the slip detection algorithm and the vision and force-based position controller
    \item Experiments on a real robot that validate the effectiveness of multi-modal sensing for the pivoting task
    %\item A controller for the gripper finger width that utilises tactile sensor data
    %\item Evaluation metrics includes success rate, work consumption, slip off rate and lift up rate are used to validate the performance of our proposed approach.
\end{itemize}


\section{Related Works}

Pivoting provides an alternative to pick-and-place methods for reorienting the pose of an object. 
% Previous works involve both single arm \cite{toskov2022hand, antonova2017reinforcement, raessa2021planning} and dual arm \cite{zhang2021manipulation, shi2020aerial, yoshida2010pivoting} implementations to perform this task. 
A significant advantage of the pivoting motion is the ability to extend manipulation to reorienting heavy, large and/or long objects \cite{raessa2021planning, zhang2021manipulation, shi2020aerial, yoshida2010pivoting} that cannot be picked up by robot.  
Previous works focus on in-hand pivoting where the object is held in air \cite{toskov2022hand, antonova2017reinforcement} while others target pivoting using a surface to support the motion \cite{raessa2021planning, zhang2021manipulation, shi2020aerial, yoshida2010pivoting}. For our purposes, we will focus on pivoting with the assistance of a surface.

To achieve pivoting, planning based approaches are frequently adopted \cite{raessa2021planning, zhang2021manipulation, yoshida2010pivoting, hou2018fast, hou2019reorienting}. Closed loop control is also common, such as using impedance and admittance control to optimise a force planner \cite{shi2020aerial}. Machine learning methods are also used to control robot behaviour using complex input data \cite{toskov2022hand, antonova2017reinforcement}. Our solution aims at a learning-free control algorithm for the gripper width as well as end effector position during a pre-planned pivoting motion.

% Pivoting provides an alternative to pick-and-place methods for reorienting the pose of an object. Previous works involve both single arm \cite{toskov2022hand, antonova2017reinforcement, raessa2021planning} and dual arm \cite{zhang2021manipulation, shi2020aerial, yoshida2010pivoting} implementations to perform this task. Some of these works focus on in-hand pivoting where the object is suspended in air \cite{toskov2022hand, antonova2017reinforcement} while others target pivoting using a surface to support the motion \cite{raessa2021planning, zhang2021manipulation, shi2020aerial, yoshida2010pivoting}. For our purposes, we will focus on pivoting with the assistance of a surface. Many of these papers focus on reorienting heavy, large and/or long objects \cite{raessa2021planning, zhang2021manipulation, shi2020aerial, yoshida2010pivoting} with the intention of improving the dexterity of the robot, however we consider pivoting smaller and lighter objects that a robot can easily handle. As opposed to learning based methods \cite{toskov2022hand, antonova2017reinforcement} and path planning based approaches \cite{raessa2021planning, zhang2021manipulation, yoshida2010pivoting} our solution focuses on using a control algorithm to accomplish the set goal \cite{shi2020aerial}. However, the control algorithm we will develop is aimed at controlling the gripper width as well as position control from the set goal, whereas Shi \textit{et al.} concentrates on impedance and admittance control to optimise the force planner they designed for their aerial robot.

\subsection{Contact Control}

Adopting a purely open loop approach can often be limiting as the robot only considers the environment's initial states and is unaware how its interactions influence them \cite{siciliano1999robot}. In terms of the pivoting action, the motion of the robot needs to be updated based on the object's contact with the surface to induce friction and complete a full pivot. 

For similar tasks, force and torque data is often used to estimate the state of the robot held object's contact with its surroundings. Ma \textit{et al.} detected extrinsic contact between a grasped object and the environment using tactile sensors mounted to a parallel gripper \cite{ma2021extrinsic}. Molchanov \textit{et al.} used a data-driven approach, training machine learning models with tactile data to perform regression and classification for the presence and location of contact between object and environment \cite{molchanov2016contact}. Doshi \textit{et al.} used force/torque data to estimate how a wrench applied to an object would affect its motion using a contact model \cite{doshi2022manipulation}. Hogan \textit{et al.} used high-resolution tactile sensors to localise the pose of held object and estimate contact and slip status. Both \cite{doshi2022manipulation} and \cite{hogan2020tactile} also developed and experimentally tested closed loop controllers for manipulation.

Vision inputs are also used to compliment tactile data. Yu \textit{et al.} trained a model with visually detected pose estimates for an object of known geometry, as well as tactile data from a wrist force/torque sensor and robot encoders \cite{yu2018realtime}. The model was used to detect the contact arrangement of a held object, and achieved more accurate estimates than using vision alone. 

We take a multi-modal approach to maintain extrinsic contact, using vision-based pose estimation and force-based position control compared with a simpler vision-only method.
% 
% Adopting a purely position control approach can often be limiting as the robot is only provided with information on where it is, therefore, it is unaware of how it is interaction with the environment \cite{siciliano1999robot}. Robotic force control is especially useful in sensitive environments where disturbances or damage to the environment and/or the object that is being manipulated could be catastrophic. As a result, many works have researched the practicality of utilising a robotic force control in surgical settings \cite{xie2010force, zemiti2007mechatronic, davies1997active, federspil2003development}. Robots have the advantage of being more precise than humans are which is essential when performing surgery \cite{federspil2003development}. While our work does not involve a robot manipulating objects in a sensitive environment, force control does assist our research by preserving the objects we use, as well as reducing the risk of damaging the robot. Xie \textit{et al.} employs a hybrid position-force control architecture that starts with position control to move the needle till it initiates contact with the cell before switching to force control \cite{xie2010force}. Our approach adopts a similar methodology, which is detailed further in Section IV. However, our approach utilises vision sensors to control the robot as well. 

% \begin{figure*}[!ht]
%     \centering\includegraphics[trim={180 180 100 180}, clip, width=1\linewidth]{Pics/new_Module diagram.drawio-1-compressed.pdf}
%     \caption{System diagram }
%     \label{fig: module}
% \end{figure*}




\subsection{Slip Control}       % slip, estimation of translational/rotational
To achieve an angled pivoting position with relatively simple motions, gravity is used to induce slippage at the fingertips of the gripper, allowing change of pose without having to regrasp an object. To detect slip, tactile sensing at the contact with the object is often used \cite{li2020review}. Costanzo \textit{et al.}'s line of work investigated, separately, the prevention of both rotational and translational slip, as well as enabling rotation while preventing linear slip \cite{costanzo2018slipping, costanzo2019two, costanzo2023detecting}. They input force and torque data into an analytical friction model to estimate slippage, and develop a controller that prevents undesired slip with minimum force \cite{costanzo2023detecting}. Wang \textit{et al.} similarly used a friction model to develop a slip estimation algorithm and a gripper controller \cite{wang2021status}.
Data-based approaches are also prominent, with Toskov \textit{et al.} and Chen \textit{et al.} both training machine learning models to enable slip under gravity, with Toskov \textit{et al.} focusing on rotational slip \cite{toskov2022hand} and Chen \textit{et al.} focusing on translational slip \cite{chen2021tactile}.
While existing works predominantly pivot the objects in the air \cite{costanzo2023detecting, wang2021status, toskov2022hand, chen2021tactile}, we will attempt to detect and control slip while maintaining contact between the object and the surface it rests on, which allows the robot to reorient objects without needing to pick up and lift them, reducing effort required.



% \section{Problem Statement}
% \input{Statement.tex}




\section{Approach}
\input{Approach.tex}


\section{Experiments}
\input{Results}


\section{Discussion}
\subsection{Highest Performance and Robustness}
\textbf{Performance:} The combined approach of vision, force-based position and gripper control had the highest success rate and lowest work among all approaches. It was able to adjust both the gripper width and the movement path so that the object was not lifted off the ground. However, the long completion time of 27.4 seconds on average is the disadvantage of our approach. This is due to the motion planning of each subsequent end-effector waypoint when applying the control offset, which requires more time than other approaches. The fastest approach was the open loop method with an average completion time of 10.3 seconds, as it only plans once for the entire trajectory. On the other hand, this also indicates that the pivoting action is capable of faster completion than the traditional pick-and-place method (16.8 seconds on average). If a more responsive control methodology such as pure joint velocity control without planning was implemented, the closed loop solution may also achieve speeds approaching the open loop method. 

The lift and slip rates indicate the importance of the gripper controller. For methods that do not use gripper controller, closing the gripper as hard as possible avoids translational slip. This is reflected in the very low slip rate across all methods, even when the boxes have been lifted off the surface. Meanwhile, without the gripper controller, rotational slip could not be achieved consistently, and was prone to influences by other factors such as the box's mass, shape and mass distribution. Without rotating in the gripper, the pivot point would lose contact with the surface as the box cannot maintain a pose that keeps its diagonal in line with the radius of the trajectory. This corresponds to higher lift rates compared to methods with gripper controller.

\textbf{Robustness:} To test robustness, noise was intentionally added into the system in the form of a 5cm offset to one of the box dimensions. This had the effect of increasing the radius of the initial planned arc trajectory. As expected, the open loop approach always failed in this case. The single-modal closed loop approaches were still capable of completing full pivots in many cases, with success rates of 67.5-83.3\%, despite high lift rates of 55-99.2\%, corresponding to a frequent deviation from the ideal planned trajectory, but a recovery to complete the pivot. Out of all methods, the combined approach was the most robust, succeeding in all tests. 

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{Pics/new_pics/heavy_long_closed_without_line_small.png}
        \caption{Force, without noise}
        \label{fig:force_plot_without}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{Pics/new_pics/heavy_long_closed_with_line_small.png}
        \caption{Force, with noise}
        \label{fig:force_plot_with}
    \end{subfigure}
%     \caption{The position in the z direction vs. the position in the x direction. Data from 10 trials are shown with each trial in a different colour, in addition to the ideal force profile specified in Equation \ref{eq:pivot_force}. The setup uses the long box performing long-to-short pivots using combined modalities.}
%     \label{fig:force_plot}
% \end{figure}

% \begin{figure}[t!]
%     \centering
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{Pics/new_pics/heavy_long_closed_without_traj_zvx_line_small.png}
        \caption{Trajectory, without noise}
        \label{fig:pos_plot_without}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{Pics/new_pics/heavy_long_closed_with_traj_zvx_line_small.png}
        \caption{Trajectory, with noise}
        \label{fig:pos_plot_with}
    \end{subfigure}
    \caption{The vertical force and end effector trajectory plots of 20 pivot trials (10 with noise, 10 without). Each trial is shown in a different colour, in addition to the ideal force profile from Equation \ref{eq:pivot_force} and ideal trajectory from Equations \ref{eq:path_x} and \ref{eq:path_z}. The position values are relative to point P as illustrated in Fig. \ref{fig:arc}. The setup uses the long box performing long-to-short pivots using combined modalities.}
    \label{fig:plots}
\end{figure}

To examine the performance and robustness of our position controller in further detail, we plot the wrist force in the z-direction, as well as the pivot path in Fig. \ref{fig:plots}. In Fig. \ref{fig:force_plot_without}, the measured force profile followed the targeted ideal profile closely. The large negative peaks at the beginning and end of the pivot are due to the initial grasp of the box, and slight overshooting which pushed the box into the surface, respectively. It can be seen in Fig. \ref{fig:pos_plot_without} that the pivot could easily adhere to the ideal trajectory in all but  one trial. 

However, when noise is added to the initial planned path, the system can no longer track the force profile as cleanly. In Fig. \ref{fig:force_plot_with}, the measured force profile diverted from the calculated ideal, and large fluctuations are also present. This is due to the frequent vertical adjustments that the gripper needs to make in its path to compensate for the applied noise. As compared to the noise-free case when the gripper moved in a relatively smooth motion, the assumption of constant speed is less valid. Between the peaks, during the stop in motion of the robot arm, the force profiles remain close to ideal predictions. Despite diversions from the ideal force profile, the pivot path as shown in Fig. \ref{fig:pos_plot_with} remained very close to the ideal plan. Influenced by the increased base dimension of the box, an increase to the radius of the path is observed as pivoting begins, corresponding to the large difference in the force plot. The controller then begins acting and the movement converges back to the ideal path, allowing all trials to pivot successfully. If larger forces are involved when handling heavier or larger objects, however, it may be necessary to also consider the dynamic effects of the robot movement, or otherwise implement smoother movement for the gripper. 



\subsection{Effects of different objects}
\textbf{Mass:} During our experiments, it was observed that the mass of the box could directly affect the success rate. For the force-based position and vision control methods performing short-to-long pivots, pivoting the large box was always unsuccessful. The failed cases were caused by the low weight of the large box, which is the lightest out of all three boxes. This could not generate enough torque around the gripper fingers to induce rotational slip for the purpose of pivoting. Sufficient torque about the gripper fingers is necessary to create rotational slip as the the box is more capable of overcoming the friction force generated by the grasp. 
On the contrary, the long box showed a 0\% success rate in terms of the pick\&place method. During those experiments, the mass was the main reason for failure as the weight of the box caused too much slip for the robot to rotate the box 90$\degree$.

\textbf{Object shape and Mass distribution:} Besides the mass, the shape of the objects and their mass distributions also affect the gravitational torque around the gripper fingers. The long-to-short pivoting case has a higher torque than the short-to-long case, since the grasp point is further from the centre of mass, roughly at the centre of the box. This helps to induce rotational slip at the grasp point and complete the pivot action. As seen in Table \ref{table:box_1_results}, the success rates for the long-to-short pivots were generally higher for all methods, and the lift rates were generally lower. This was especially significant for the single-modal approaches without gripper control, as they lack the means to regulate the extrinsic influence of gravitational torque by varying gripper width.

However, the iron weights used to manually adjust the weight of the boxes would not have been perfectly distributed around the centre, making the estimation of the torque around the fingers less accurate.


\subsection{Artificial Markers for Pose Estimation}
In the vision component of our system, the ArUco marker plays an important role in detecting the object's pose and further tracking the angle between the surface and the box's lowest edge among all approaches. More generalisable methods for pose estimation may include point cloud clustering and feature matching in the 3D space \cite{guo2021efficient}. Such algorithms can also be used to derive the dimensions of the object. Although this may introduce inaccuracies to the vision component, our tests have shown that by using closed loop approaches, the system can succeed in the face of such inaccuracies.

\subsection{Single vs Multi-modal}
In our combined approach, all three modules are necessary for the "perfect" pivoting. Based on the results in Table \ref{table:all_results}, each single-modal controller was not able to pivot the box with 100\% success rate.
Both vision and force-based position controllers have higher success rate than the gripper module, as our chosen challenge scenario introduced noise to the ideal arc trajectory, which could only be amended by those two controllers. For some specific scenarios (i.e. light weight box), the box can easily be lifted without inducing enough rotational slip, and the gripper controller can be more important to complete pivoting. In the case of vision control, the robot only begins to offset the trajectory after the box has been lifted, causing a high lift rate of 99.2\%. 









% A series of experiments are designed to verify the validity of our approach. These experiments will represent increasing levels of difficulty for the robot. A baseline method will also be performed to compare our approach. This baseline approach will use an open loop system that plans the entire pivot and drag motion and doesn't use any state estimation as feedback. Both methods will perform the same experiments. 

% \begin{enumerate}
%     \item The robot is asked to pivot a box from one face to another. This pivoting action will involve a 90 degree rotation. The goal will only be the orientation of the box and not the position. 
%     \item Using a similar pivoting action, the robot will rotate the object twice for a total of 180 degrees movement. Similarly, only the orientation of the box is important. 
%     \item Lastly, the robot will need to pivot the box a certain angle and then drag the box to a specified location while maintaining that angle. The box will be dragged in a straight line. 
% \end{enumerate}


% \subsection{Quantitative Measures} 

% To assess the performance of the robot in each experiment, three quantitative measures are established. 

% \begin{enumerate}
%     \item Success Rate: The percentage of all attempts where the robot fully completes the task it was set. 
%     \item Accuracy: This measure would only apply to experiment 3. Accuracy will represent how close the robot was to moving the box to its goal pose. This will be determined by calculating the distance and orientation error margin from the designated goal pose.
%     \item Time Taken: The total time it takes the robot to move the object from the start to end position as soon as the goal pose is known.
%     \item Effort: The amount of work done applied by the robot on the object to move the object from the start to goal pose. Work is defined as the energy transferred to or from an object via the application of force along a displacement. The measurements required to determine work done will be retrieved from the PapillArray tactile sensors and the FT-300 Force/Torque sensor. This criteria will demonstrate how much effort is required of the robot to complete the task.
% \end{enumerate}





% \begin{figure}[ht]
%     \centering
%     %\def\figheight{5cm}
%     \begin{subfigure}[t]{0.48\columnwidth}
%     \centering
%     \includegraphics[trim={1100 400 300 100}, clip, width=\columnwidth, angle=270]{final dragging 1.jpg}
%     \caption{Stage 1: Robot grasps the object and move into a certain pose}
%     \label{subfig: dragging1}
%     \end{subfigure}
%     \hfill
%     %
%     \begin{subfigure}[t]{0.48\columnwidth}
%     \centering
%     \includegraphics[trim={1100 400 300 100}, clip, width=\columnwidth, angle=270]{final dragging 2.jpg}
%     \caption{Stage 2: Robot drags the object without changing the orientation}
%     \label{subfig: dragging2}
%     \end{subfigure}
    
%     \caption{Dragging Action}
%     \label{fig: dragging}
% \end{figure}

% \begin{figure}[ht]
%     \centering
%     %\def\figheight{5cm}
%     \begin{subfigure}[t]{0.48\columnwidth}
%     \centering
%     \includegraphics[trim={1100 400 300 100}, clip, width=\columnwidth,angle=270]{final pivoting 1.jpg}
%     \caption{Stage 1: Robot grasps the object and move into a certain pose, make sure the box contact with the table}
%     \label{subfig: new pivoting1}
%     \end{subfigure}
%     \hfill
%     %
%     \begin{subfigure}[t]{0.48\columnwidth}
%     \centering
%     \includegraphics[trim={1100 400 300 100}, clip, width=\columnwidth,angle=270]{final pivoting 2.jpg}
%     \caption{The robot pivots the box at one edge/point without changing the position}
%     \label{subfig: new pivoting2}
%     \end{subfigure}
    
%     \caption{Pivoting Action}
%     \label{fig: new pivoting}
    
% \end{figure}

    
% \begin{figure*}[ht]
%     \centering
%     %\def\figheight{5cm}
%         \begin{subfigure}[t]{0.3\linewidth}
%         \centering
%         \includegraphics[width=5cm,angle=180]{Pics/pivoting1.jpg}
%     \caption{Stage 1: Robot grasps the object and move into a certain pose, make sure the box contact with the table}
%     \label{subfig: pivoting1}
%     \end{subfigure}
%     \begin{subfigure}[t]{0.3\linewidth}
%         \includegraphics[width=5cm,angle=180]{Pics/pivoting2.jpg}
%     \caption{Stage 2: The robot pivots the box at one edge/point without changing the position}
%        \label{subfig: pivoting2}
%     \end{subfigure}
%         \begin{subfigure}[t]{0.3\linewidth}
%         \includegraphics[width=5cm,angle=180]{Pics/pivoting3.jpg}
%     \caption{Stage 3: The robot pivots the box again }
%        \label{subfig: pivoting3}
%     \end{subfigure}
%        \caption{Pivoting Action}
%     \label{fig: pivoting}
%     \end{figure*}

\section{Conclusions and Future Work} 

We present a closed loop, multi-modal solution utilising vision, force/torque and tactile sensors for manipulating objects via pivoting. The system is able to control the robot to maintain contact with the surface, and modulate the gripper width to induce the desired type of slip. 
% The box is first detected via the ArUco marker attached to one of its faces, which we can then estimate the box's pose. A grasp pose is then generated based off a user input which provides the robot with instructions on which direction to pivot the box. As the gripper closes on the box, it will adjust itself to apply an adequate amount of force to pivot the box. The force controller will then adjust the robot arm by finding the difference of the measured and predicted force at each point throughout its trajectory to determine what adjustment needs to be made. The gripper controller will actively adjust by evaluating if the box is experiencing translational slip or if the gripper is applying excessive force to the box. 

Based on the experiments conducted, we observe a clear advantage of our approach in terms of success rate, robustness, as well as the work done in pivoting the box compared to the open loop and pick-and-place method. The limitations of our approach are its slow execution speed. For future works, we will consider implementing joint velocity control, as well as removing the use of markers for object detection and generalising this approach for many different shapes of objects. Additionally, using learning to perform force-based position and gripper width control will be considered. 

This paper should be considered as a proof-of-concept that demonstrates the feasibility of our pivoting approach by taking advantage of multi-modal sensing. While our work featured only cubic objects tracked via fiducial markers, we believe that our approach can be generalised to rigid objects with modifications. The marker-based pose detection can be swapped with a model-based 6D pose detector \cite{xiang2018posecnn}. A model-based \cite{tremblay2018corl:dope} or model-free grasp synthesis approach \cite{mousavian20196} can be used for obtaining a robust 6D grasp pose. In our work, pivoting on an edge of the box was obvious, however, to generalise it to any given object, further geometric reasoning would be needed for finding a suitable pivot point or edge on the object. Furthermore, a more sophisticated control approach might be needed for contact configuration regulation \cite{doshi2022manipulation}.

\bibliographystyle{ieeetr}
\bibliography{references.bib}
\balance
\end{document}

