%%%% kr-instructions.tex -- version 1.3 (11-Jan-2021)

\typeout{KR2023 Instructions for Authors}

% These are the instructions for authors for KR-23.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

\usepackage{kr}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bbding}
\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{knowledge}{Knowledge}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.
%PDF Info Is REQUIRED.
\pdfinfo{
/TemplateVersion (KR.2022.0, KR.2023.0)
}



\title{Commonsense Knowledge Assisted Deep Learning for\\ Resource-constrained and Fine-grained Object Detection}

% Single author syntax
\iffalse % (remove the multiple-author syntax below and \iffalse ... \fi here)
\author{%
    Author name
    \affiliations
    Affiliation
    \emails
    email@example.com    % email
}
\fi
% Multiple author syntax
\author{%
Pu Zhang$^1$\and
Bin Liu$^1$$^($\Envelope $^)$
\\
\affiliations
$^1$Research Center for Applied Mathematics and Machine Intelligence,\\Zhejiang Lab, Hangzhou 311121, China\\
\emails
\{puz, liubin\}@zhejianglab.com
}

\begin{document}

\maketitle

\begin{abstract}
In this paper, we consider fine-grained image object detection in resource-constrained cases such as edge computing. Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection. To achieve accurate fine-grained detection, one needs to employ a large enough DNN model and a vast amount of data annotations, which brings a challenge for using modern DL object detectors in resource-constrained cases. To this end, we propose an approach, which leverages commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detection results. Specifically, we introduce a commonsense knowledge inference module (CKIM) to process coarse-grained lables given by a benchmark DL detector to produce fine-grained lables. We consider both crisp-rule and fuzzy-rule based inference in our CKIM; the latter is used to handle ambiguity in the target semantic labels. We implement our method based on several modern DL detectors, namely YOLOv4, Mobilenetv3-SSD and YOLOv7-tiny. Experiment results show that our approach outperforms benchmark detectors remarkably in terms of accuracy, model size and processing latency.

\end{abstract}

\section{Introduction}


Object detection is a typical class of computer vision tasks aimed at locating and classifying objects in images or videos. Fine-grained object detection is an important branch of object detection, which is used to detect objects of fine-grained categories (such as bird species, dog breeds and car brands). Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection, since it can significantly improve the detection accuracy. Typical DNN based object detectors include e.g., YOLO \cite{redmon2018yolov3} and Faster R-CNN \cite{ren2015faster}. Yet, this advancement comes with the added cost of utilizing substantial computational and storage resources, along with a vast quantity of annotated data. This situation can be exacerbated for a fine-grained object detection task, which requires more annotated data, bigger model, and more computational budget to train and store the model \cite{zaidi2022survey}. Thus, fine-grained object detectors are typically deployed on cloud servers that have sufficient computing resources and labeled data.

In this paper, we examine a challenging scenario which involves performing DNN based fine-grained object detection on edge devices, such as smartphones and driving assistance systems, which are resource-constrained. Edge computing in the context of Internet of Things (IoT) has made significant progress in recent years. The quantity of high-dimensional data produced by edge devices, especially images and videos, has been ever-increasing. Fine-grained object detection is required in various applications that involve processing images or videos in real-time at the edge, such as autonomous vehicles \cite{zhang2021fairmot} and tracking multiple objects \cite{li2019gs3d}. Transmitting such data to the remote cloud server for data labeling and processing is not feasible due to the unacceptable latency in response, consumption of the bandwidth and privacy concerns \cite{chen2019deep}. Thus training and deploying object detection models on edge devices has become a significant trend. However, typical edge devices only have limited computing capabilities and memory resources, which can not meet the resource demand for running modern DNN based object detectors. Some network compression techniques have been proposed, such as network pruning \cite{hassibi1993optimal}, knowledge distillation \cite{hinton2015distilling}, and depthwise convolution \cite{howard2017mobilenets,8578814}, for designing lightweight models.

Here, we propose an alternative, yet unexplored avenue for DNN-based fine-grained object detection on resource-constrained edge devices. The basic idea is to leverage commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detections. Specifically, we introduce a commonsense knowledge inference module (CKIM) to a backbone coarse-grained object detector. This CKIM can infer fine-grained object labels from the output of the backbone
coarse-grained detector. The relationship between the working mechanism of typical fine-grained detectors and that of our method can be obtained by comparing Figure \ref{fig:general_model} and Figure \ref{fig:CKIM}.
%As the example shown in Figure \ref{fig:general_model}, performing fine-grained object detection usually require more labelled data and a larger model size. Excessive images with fine-grained data annotations are typically required to train an effective deep model. The acquisition of such data may be particularly expensive or even impossible in specialized fields, as annotations need to be labeled by experts with specific knowledge and images of a certain rare category are difficult to obtain. Additionally, it is noticed in practice that the number of object categories significantly affects the performance of models under the condition of constrained resources. Such problems can not be avoided by manipulating the structure of the model.


\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{figures/FG_detector.png}
\caption{An example show of the working mechanism of a typical fine-grained object detector. Vast amount of images with fine-grained labels and a large enough model are required for getting accurate detection results.}
\label{fig:general_model}
\end{figure}

%To address these limitations, this paper presents a commonsense knowledge inference module (CKIM) to assist the object detection model to complete fine-grained classification.
%Commonsense knowledge generally contains advanced reasoning abilities to distinguish the differences between species in the same class \cite{dasiopoulou2005knowledge}, which may help reduce the complexity of fine-grained object detection tasks, thereby decreasing the scale of the deep models and the recourse requirements for edge computing environments.

%CKIM works by identifying the associations between fine-grained and coarse-grained categories according to semantic analysis and commonsense knowledge. The discovered associations are then utilised to establish an inference mechanism implemented by a CKIM. As a result, only coarse-grained categories will be learned as the output of the benchmark Deep Learning (DL) detector, whereas fine-grained labels will be reasoned by the CKIM and the coarse-grained conclusions given by the trained detector.

As shown in Figure \ref{fig:general_model}, to detect adults and children, a fine-grained detector requires vast amount of images with labels `adult' or `child' to train a large enough model.  According to commonsense knowledge, `adult' and `child' are two subcategories of the same coarse-grained class, `person'. Normally, a `person' is recognized as an `adult' if the object size is large and a `child' if it is small. Our method, as shown in Figure \ref{fig:CKIM}, introduces a CKIM to leverage such type of commonsense knowledge, where the DNN detector is only responsible for generating coarse-grained outputs, namely the detection of `person'-type objects and their positions.
%In particular, by grasping the commonsense knowledge, 'everything seems smaller further away and larger closer up', this article proposes an CKIM to determine the fine-grained results related to the object size through the size of bounding boxes detected by the coarse-grained model and their distance to the camera. Such an inference mechanism is implemented by supervised data-driven learning approaches.

%\begin{knowledge}
%Everything seems smaller further away and larger closer up’
%\end{knowledge}

%The size of the detected objects is then determined by the CKIM based on the obtained bounding box and the distance to the camera.

Our contributions can be summarized as follows.
\begin{itemize}
    \item First, we propose a commonsense knowledge assisted deep learning method for resource-constrained and fine-grained object detection. Our method uses a coarse-grained object detector and a commonsense knowledge inference module (CKIM) to translate coarse-grained outputs of the detector into fine-grained predictions.
     \item We showcase two types of CKIM next, one using crisp-rule based inference and another with fuzzy-rule based inference, with the latter being employed to address any semantic ambiguity associated with the fine-grained labels.
     \item Finally, we integrate CKIM into modern object detectors including MobilenetV3-SSD \cite{howard2019searching}, Yolov7-tiny \cite{wang2022yolov7}), and Yolov4 \cite{bochkovskiy2020yolov4}, and demonstrate the performance of our method via experiments. Results show that our method outperforms baseline detectors remarkably in terms of detection accuracy, model size and processing latency.
\end{itemize}

%Both crisp and fuzzy rules are learned via supervised data-driven approaches with .
The remainder of this paper is structured as follows. Section II briefly introduces related work. Section III details the proposed CKIM based detector, especially the crisp-rule and fuzzy-rule based implementations of the CKIM. Section VI presents the experimental setting and the experiment results. Finally, Section V concludes the paper.

\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{figures/CKIM.png}
\caption{An example show of the working mechanism of our proposed method. Our method only uses a coarse-grained object detector that requires much less labeled data for model training, and much less memory for model storage, compared with that shown in Figure 1. A commonsense knowledge inference module (CKIM) is introduced, which maps coarse-grained outputs of the coarse-grained object detector to fine-grained predictions.
%Small sized deep models and a limited amount of data with coarse-grained labels is sufficient for model training. Fine-grained label inference is performed by CKIM, which is derived from commonsense knowledge.
}
\label{fig:CKIM}
\end{figure}



\section{Related Works}

We briefly introduce related works on DNN based visual object detection and rule-based inference.

\subsection{Modern DNNs for Visual Object Detection}

The architecture of DNNs for object detection can be briefly divided into two types. Networks which have separate modules for candidate region generation and classification, e.g., faster R-CNN \cite{ren2015faster}, are termed as two-stage detectors. Single-stage detectors directly produce object categories and their bounding boxes in one step, including pre-defined, differently sized boxes for locating objects. Single-stage detectors are appropriate for situations that require real-time performance and have limited resources, such as edge computing, because they have lightweight designs and require less time to make predictions. Therefore, they are employed as benchmark object detectors in this paper.

\subsubsection{YOLO}, the abbreviation of You Only Look Once \cite{redmon2016you}, is one of the most widely used single-stage object detectors. With YOLO, the input image is divided into a grid with $S \times S$ cells. Each grid cell predicts bounding boxes and the corresponding class probabilities. Later versions of YOLO have been proposed to improve inference speed and reduce the model scale. For example, YOLOv4 \cite{bochkovskiy2020yolov4} achieved a state-of-the-art (SOTA) performance for real-time object detection. YOLOv7 is a more advanced SOTA real-time object detector. Both YOLOv4 and YOLOv7 have lightweight versions, namely YOLOv4-tiny and YOLOv7-tiny, that employ smaller model architectures \cite{wang2021scaled,wang2022yolov7}, which are more suitable for edge computing cases. Here we employ YOLOv4 and YOLOv7-tiny as baseline methods in our experiments. % Compared with YOLOv4-tiny, YOLOv7-tiny achieves higher accuracy and less resources consumption.

\subsubsection{MobileNet-SSD} is an efficient DL method for object detection in mobile computing cases. It utilises a Single Shot MultiBox Detector (SSD) \cite{liu2016ssd} as the decoder and MobileNet \cite{howard2017mobilenets} as the feature extractor. SSD was the first single-stage detector that performed comparably as two-stage detectors. MobileNet was particularly designed for vision applications on mobile phones. In MobileNet, traditional convolution layers are replaced by depthwise separable and pointwise convolution layers to reduce the scale of the model \cite{sandler2018mobilenetv2}. An advanced version of MobileNet, MobileNetV3, adopts a search algorithm to optimize the network architecture \cite{howard2019searching}. In this work, we include MobileNetv3-SSD as a baseline method in our experiments.

\subsection{Rule-based Inference}

Rule-based inference is one of conventional methodologies to implement knowledge reasoning, in which knowledge is represented by a collection of  “IF–THEN” rules. Its reasoning mechanism is that, if a novel instance matches the antecedent of any rule in the rule base, the result will be the corresponding rule consequent \cite{Grosan2011}. In the context of this work, the association between fine-grained and coarse-grained categories may involve semantic imprecision and ambiguity in terms of size, distance, age and color of the objects. So only using crisp rules is not enough. We resort to fuzzy logic and fuzzy set theory \cite{2010Fuzzy,ZADEH1965338} here. Fuzzy rule-based systems (FRBS) allow such terms to be precisely described by fuzzy sets, enabling the inference process to resemble human reasoning.
Fuzzy sets can be generally defined by:
\begin{equation}
M = {(a,\mu_M(a)|a\in A,\mu_M(a) \in [0,1])}
\end{equation}
where $a$ denotes an instance, $A$ a collection of instances, $\mu_A(x)$ the membership function which describes the partial degrees to which an instance $a$ is judged to belong to the fuzzy set $M$.
Mamdani models \cite{Scherer2012} are widely used in FRBS. They use fuzzy sets as rule antecedents and consequent. As presented in Figure \ref{fig:mamdani}, they perform inference by integrating conclusions of individual rules that the input overlaps with. The weight of a certain rule is determined by the match degree between the input instance and the rule antecedent.

\begin{figure}[h]
\centering
\includegraphics[width=0.45\textwidth]{figures/mamdani.png}
\caption{Illustrative example of the inference process with a Mamdani model. $R_{i},R_{j}$ represent two fuzzy rules, $(A_i, B_i), (A_j, B_j) $ are the corresponding antecedents and $C_i, C_j$ are their consequent for fuzzy rule, respectively. $(x,y)$ is the input instance. $\alpha_i, \alpha_j$ stand for matching degrees between the input and the two rules.}
\label{fig:mamdani}
\end{figure}

\section{Commonsense Knowledge Inference Module Assisted Object Detection}

%\begin{knowledge}
%Everything seems smaller further away and larger closer up’
%\end{knowledge}

In this section, we present our CKIM based approach to fine-grained object detection in detail. In particular, we describe how to specify CKIM based on commonsense knowledge, and how to use CKIM to assist a coarse-grained deep detector to do fine-grained object detection.

An example show of the our method's working mechanism is presented in Figure \ref{fig:CKIM}. It consists of two parts, a coarse-grained object detector and the CKIM. The former part outputs coarse-grained labels and a bounding box for each object. The bounding box can be represented by:
\begin{equation}
box(C,X,Y,W,H)
\end{equation}
where $C$ denotes the coarse-grained label, $(X,Y)$ the coordinates of the centre of the bounding box, $W$ and $H$ the width and height of the bounding box, respectively.

For ease of presentation, we focus on size-related fine-grained labels in this work. The real size of an object is naturally closely related to the size of the object's bounding box, which can be produced by a qualified object detector.
Besides, according to commonsense knowledge as follows:
\begin{knowledge}
An object appears to decrease in size as it moves distant, while it appears to enlarge as it moves closer
\end{knowledge}

\noindent
the real size of an object is also related to its distance to the camera. For an object in an image, its real distance to the camera can be gauged by another commonsense knowledge:
\begin{knowledge}
The object's distance to the camera (DtoC) is strongly connected to the distance from the center of its bounding box to the bottom of the image (CtoB)
\end{knowledge}

\noindent The connection between CtoB to DtoC is illustrated in Figure \ref{fig:distance}.
\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{figures/distance.png}
\caption{An example image to show the connection between an object's distance to the camera (DtoC) to the distance from the center of the object to the bottom of the image (CtoB). As shown here, CtoB of object A, denoted by CtoB$_A$, is larger than CtoB$_B$. This information can be used to infer that DtoC of object A, denoted by DtoC$_A$, is larger than DtoC$_B$, which is clearly true as shown in the picture.}
\label{fig:distance}
\end{figure}

The aforementioned commonsense knowledge provides us an opportunity to reason size-related fine-grained labels from outputs of a coarse-grained object detector, such as the coarse-grained labels and bounding boxes of the objects.
%Thereby, in the training process, the amount of size-related fine-grained classes can be merged to several coarse-grained categories, the coarse-grained labels together with corresponding training data are applied to train a deep object detection model.
The purpose of CKIM is to infer fine-grained labels based on the size of the objects' bounding boxes (BoxS) and their distances to the camera (DtoC). We normalize values of $X$, $Y$, $W$, $H$ according to the width and height of the image, define the size of the bounding box (BoxS) as its area, and define DtoC as CtoB. Then we calculate BoxS and DtoC as follows:
\begin{equation}
\begin{aligned}
BoxS &= W \times H \\
DtoC &= 1-Y
\end{aligned}
\end{equation}
%While reasoning on testing images, coarse-grained outputs together with bounding boxes will be produced by the trained detector. Thereafter, the derived CKIM is responsible for implementing the inference of object real sizes from the size of object bounding boxes and their distance to the camera.
We develop two types of CKIM, corresponding to crisp-rule and fuzzy-rule based inference.
%To ease the presentation, suppose that only two size-related labels, large and small, are involved here.
\subsection{Crisp-rule based CKIM}

Crisp rule-based system follows Boolean logic, one object can only belong to or not belong to a certain class. We model the relationship between the real size of an object and its attributes given by a coarse-grained object detector by a logistic regression function \cite{lavalley2008logistic} .

To ease the presentation, we consider size-related object labels, 'large', 'middle' and 'small'. We use one-vs-rest method to perform crisp rule inference. The decision function of the crisp rule is defined as follows,
\begin{equation}
\begin{aligned}
f_{ml}(BoxS, DtoC) &= \frac{1}{1+e^{w_{ml}^{T}x}}, x \triangleq (BoxS, DtoC)\\
f_{sm}(BoxS, DtoC) &= \frac{1}{1+e^{w_{sm}^{T}x}}, \\
\end{aligned}
\end{equation}
where $f_{sm}$ denotes the decision function for small sized and middle sized objects, and $f_{ml}$ the decision function for middle sized and large sized objects. $w^T$ is a set of parameters optimized by minimizing a cost function in the same way as in typical logistic regression.


Accordingly, the CKIM is defined by:
\\

If $f_{ml}(BoxS, DtoC) > 0$,

\hspace{2em} then the object's fine-grained label is `large';

If $f_{ml}(BoxS, DtoC) < 0$ and $f_{sm}(BoxS, DtoC) > 0$,

\hspace{2em} then the fine-grained label is `middle';

If $f_{sm}(BoxS, DtoC) < 0$,

\hspace{2em} then the fine-grained label is `small'.
\\


\subsection{Fuzzy-rule based CKIM}

In real-life cases, there may be continuous-valued attributes (e.g., size, distance, age) which are difficult to classify with discrete semantic descriptions (e.g., large or small, near or far, young or old), resulting in semantic vagueness  or uncertainty. Fuzzy logic provides a multi-value logic, in which such vague semantics can be strictly formulated and precisely studied.

In order to adapt our method to more general scenarios, we propose a fuzzy-rule based approach to implementing CKIM. Fuzzy rule-based systems allow an object to match different categories with different memberships. We adopt the aforementioned Mamdani model for this task, which use fuzzy sets as rule antecedents and consequent. Two main categories of membership functions are typically used in constructing fuzzy sets \cite{2021Approximate}, namely:

(1) Polygonal functions, such as triangular shaped and trapezoidal shaped functions;

(2) Nonlinear functions, including Gaussian shaped and generalised bell shaped functions.

Here we adopt the Gaussian shaped membership function \cite{kreinovich1992gaussian}.
The same as before, we consider size-related object labels, namely ’large’, ’middle’ and ’small’, here.

In our fuzzy rule inference module, the antecedents of rules are defined as follows:
\begin{equation}
\begin{aligned}
M_L(x) &= \mathcal{N}(x|\mu_L,\Sigma_L)\\
&=\frac{1}{2\pi|\Sigma_L|^{1/2}} \exp \left\{- \frac{1}{2} \left(x-\mu_L\right)^{'} \Sigma_L^{-1} \left(x-\mu_L \right)  \right\}\\
M_M(x) &= \mathcal{N}(x|\mu_M,\Sigma_M)\\
&=\frac{1}{2\pi |\Sigma_M|^{1/2}} \exp \left\{- \frac{1}{2} \left(x-\mu_M\right)^{'} \Sigma_M^{-1} \left(x-\mu_M \right)  \right\}\\
M_S(x) &= \mathcal{N}(x|\mu_S,\Sigma_S)\\
&=\frac{1}{2\pi |\Sigma_S|^{1/2}} \exp \left\{- \frac{1}{2} \left(x-\mu_S\right)^{'} \Sigma_S^{-1} \left(x-\mu_S \right)  \right\}\\
\end{aligned}
\end{equation}
where $x\triangleq(BoxS, DtoC)$ the same as before, $S$, $M$ and $L$ in the subscripts denote 'small', 'middle', and 'large', respectively, $\mu$ and $\Sigma$ denote the mean and covariance matrix of the data distribution.

The fuzzy-rule based CKIM is designed as follows:\\
If $x$ matches $M_L$, then object's label is 'large' with degree $M_L(x)$;\\
If $x$ matches $M_M$, then object's label is 'middle' with degree $M_M(x)$;\\
If $x$ matches $M_S$, then object's label is 'small' with degree $M_S(x)$.

A crisp output is then calculated by a defuzzification approach to integrate membership degrees between the object and all rules.
Accordingly, the fine-grained result is determined by the $\arg\max$ function defined as follows:

\begin{equation}
\begin{aligned}
Label &=\underset{i\in\{S,M,L\}}{{\arg\max}\, M_i(x)} \\
&x \triangleq (BoxS, DtoC)
\end{aligned}
\end{equation}

Note that, since these two types of CKIM have few parameters to be optimized, the amount of data required to train them are almost negligible, compared to those required to train a DNN model.

\section{Experiments}

The performance of our proposed commonsense knowledge assisted DNN detector is experimentally evaluated. We compared our method against SOTA methods including the aforementioned YOLOv7-tiny, MobileNetv3-SSD and YOLOv4. The former two methods are specially developed for resource-constrained scenarios, while YOLOv4 is not. So the model size of YOLOv4 is much larger than the others. We integrate CKIM with each of them and assess if it results in improved performance.

\subsection{Experimental Setup}

\subsubsection{CLEVR Dataset} \cite{johnson2017clevr} is a benchmark dataset for Vision Question Answering (VQA) models. It consists of pictures containing objects and questions related to them. The objects' attributes include size (big, small), color (brown, blue, cyan, gray, green, purple, red, yellow), material (metal, rubber), and shape (cube, cylinder, sphere). According to these attributes, objects are divided into 96 fine-grained categories. So we term the original dataset as CLEVR-96. Figure \ref{fig:CLEVR1} shows an example of this dataset.
In our experiment, we remove the size attribute to train the coarse-grained object detector that considers $96/2=48$ coarse-grained labels, then predict fine-grained size labels with our CKIM. The other involved fine-grained object detectors, namely YOLOv7-tiny, MobileNetv3-SSD and YOLOv4, are all trained with the original datasets that have 96 labels.

To simulate complex environments in the real world, we construct a new dataset by introducing a collection of objects of middle size, as shown in Figure \ref{fig:CLEVR2}. It has 144 fine-grained classes. We term it as CLEVR-144 in what follows.

Both CLEVR-96 and CLEVR-144 contain 16000 images as the training set, 2000 images as the validation set, and the other 2000 images as test set.
%To simulate a Given that devices with limited resources typically have insufficient data to train models, two new datasets are created by randomly selecting 5000 images from each of the datasets mentioned earlier.

\begin{figure}[h]
\centering
\includegraphics[width=0.3\textwidth]{figures/CLEVR_Ori.png}
\caption{An example image in the CLEVR-96 dataset, where the object size is large or small.}
\label{fig:CLEVR1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.3\textwidth]{figures/CLEVR_new.png}
\caption{An example image in the CLEVR-144 dataset, where the object size can be large, middle, or small.}
\label{fig:CLEVR2}
\end{figure}

\subsection{Performance Metrics}

Considering resource-constrained edge computing scenarios, we evaluate each method from three different perspectives, namely detection accuracy, model size, and processing latency: \\
(1) Detection Accuracy is measured according to the mean Average Precision while IoU=0.5 (mAP@0.5), which is a commonly used metric for evaluating object detectors. It calculates the mean of the average precision over all classifications for every bounding box with an IoU greater than 0.5. Larger mAP@0.5 means higher accuracy.\\
(2) Model Size is measured according to the memory space this model consumes. \\
(3) Latency is defined as the averaged time a method takes to process one image. In our experiments, the time unit is set as millisecond (ms) .

%Pictures per second (P/s) is usually used to assess the latency of the detector.  Larger P/s means shorter latency.



\begin{table}[hb]
\begin{center}
\begin{tabular}{lrlr}
\toprule
%& \multicolumn{3}{c}{CLEVR-96} \\
%\cline{2-4}
 & Accuracy $\uparrow$ & Model Size $\downarrow$ & Latency $\downarrow$\\
\hline
Y4 & \textbf{0.998}& 246.35MB& \textbf{176} \\
Y4+crisp  & \textbf{0.998}& \textbf{245.37MB+2KB}& 179\\
\hline
MS & 0.9675& 87.61MB& 82\\
MS+crisp &\textbf{0.978} &\textbf{49.63MB+2KB} & 60\\
\hline
Y7t &0.972 &23.31MB& 70 \\%\\
Y7t+crisp &\textbf{0.983} &\textbf{22.89MB+2KB} & 62\\%\\

\bottomrule
\end{tabular}
\end{center}
\caption{Fine-grained object detection performance on the CLEVR-96 dataset with all 16000 images being used for model training. Since this dataset only has two fine-grained labels, namely 'small' and 'large', there is no label ambiguity issue involved. So only crisp-rule based inference is considered in our method. Here Y4, MS, and Y7t denote YOLOv4, MobileNetv3\_SSD, and YOLOv7-tiny respectively.}
\label{tab:full1}
\end{table}

\begin{table}[ht]
\begin{center}
\begin{tabular}{lrlr}
\toprule
%& \multicolumn{3}{c}{CLEVR-144} \\
%\cline{2-4}
 &Accuracy $\uparrow$ & Model Size $\downarrow$  & Latency $\downarrow$\\
\hline
Y4 &\textbf{0.998}& 247.34MB & 183 \\%5.45\\

Y4+crisp & 0.996 &\textbf{245.37MB+2KB} & 179 \\%5.57\\

Y4+fuzzy & 0.997 &\textbf{245.37MB+2KB} &\textbf{174}\\%5.73\\
\hline

MS & 0.970& 125.59MB& 84\\%11.87\\

MS+crisp & 0.968 &\textbf{49.63MB+2KB} & \textbf{61}\\%16.41\\

MS+fuzzy &\textbf{0.978} &\textbf{49.63MB+2KB} & 62 \\%15.98\\
\hline

Y7t &0.965& 23.73MB & 75\\%13.22\\

Y7t+crisp & 0.971 &\textbf{22.89MB+2KB} & 64\\%15.66\\

Y7t+fuzzy &\textbf{0.980} &\textbf{22.89MB+2KB} & \textbf{62}\\

\bottomrule
\end{tabular}
\end{center}
\caption{Fine-grained object detection performance on the CLEVR-144 dataset with all 16000 images being used for model training. Here Y4, MS, and Y7t denote YOLOv4, MobileNetv3\_SSD, and YOLOv7-tiny respectively.}
\label{tab:full2}
\end{table}
\subsection{Experimental Results}
%In the following presentation of experimental results, the outcomes of models on different benchmark datasets are summarised in tabular form, where the best results are shown in bold.
\subsubsection{On experiments with all 16000 images being used for model training}
First we train all involved models using all 16000 images in the training set. Their performance on dataset CLEVR-96 and CLEVR-144 are shown in Tables \ref{tab:full1} and \ref{tab:full2}, respectively. We see that YOLOv4 gets the best accuracy score on both datasets, while its scores on model size and latency are the worst. It also shows that our method has significantly decreased the model size thanks to that it only applies a lightweight coarse-grained object detector and then perform fine-grained detection with crisp-rule or fuzzy-rule based commonsense knowledge reasoning. In addition, we find that on dataset CLEVR-144 which involves three fine-grained labels, namely 'small', 'middle', and 'large', fuzzy-rule based method is preferable to the crisp-rule based method. It demonstrates the ability of fuzzy method to deal with semantic ambiguity in the fine-grained labels.

\begin{table}[h]
\centering
\begin{tabular}{lrlr}
\toprule

 & Accuracy $\uparrow$ & Model Size $\downarrow$  & Latency $\downarrow$ \\
\hline
Y4 &0.972& 246.35MB &178\\

Y4+crisp &\textbf{0.987}& \textbf{245.37MB+2KB} & \textbf{173}\\


\hline

MS &0.902& 87.61MB & 82\\

MS+crisp &\textbf{0.912}& \textbf{49.63MB+2KB}& \textbf{60}\\

\hline
Y7t &0.928& 23.31MB& 71 \\
Y7t+crisp &\textbf{0.984}& \textbf{22.89MB+2KB} & \textbf{61} \\

\bottomrule
\end{tabular}
\caption{Fine-grained object detection performance on the CLEVR-96 dataset with 5000 randomly selected images being used for model training. Since this dataset only has two fine-grained labels, namely 'small' and 'large', there is no label ambiguity issue involved. So only crisp-rule based inference is considered in our method. Here Y4, MS, and Y7t denote YOLOv4, MobileNetv3\_SSD, and YOLOv7-tiny respectively.}
\label{tab:50001}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{lrlrrlr}
\toprule

 & Accuracy $\uparrow$  & Model Size $\downarrow$  & Latency $\downarrow$\\
\hline
Y4 & 0.957& 247.34MB& 175\\

Y4+crisp & 0.962& \textbf{245.37MB+2KB}& 182\\

Y4+fuzzy &\textbf{0.972} &\textbf{245.37MB+2KB}& \textbf{173}\\

\hline
MS & 0.857& 125.59MB & 83\\

MS+crisp & 0.862& \textbf{49.63MB}+2KB & 60\\

MS+fuzzy  &\textbf{0.877} &\textbf{49.63MB}+2KB & \textbf{59}\\

\hline
Y7t &0.865& 23.73MB& 72\\

Y7t+crisp 8 &0.892 &\textbf{22.89MB+2KB} & 65\\

Y7t+fuzzy & \textbf{0.914} &\textbf{22.89MB+2KB}& \textbf{62}\\

\bottomrule
\end{tabular}
\caption{Fine-grained object detection performance on the CLEVR-144 dataset with 5000 randomly selected images being used for model training. Here Y4, MS, and Y7t denote YOLOv4, MobileNetv3\_SSD, and YOLOv7-tiny respectively.}
\label{tab:50002}
\end{table}

\subsubsection{On experiments with 5000 randomly selected images being used for model training}
To simulate cases where the edge device do not have enough memory space to store all training data, we conduct experiments where we randomly selected 5000 images from the training set for model training. Experimental results on datasets CLEVR-96 and CLEVR-144 are presented in Tables \ref{tab:50001} and \ref{tab:50002}, respectively.
As is shown, for the case with less training data, the benefits given by our method is more remarkable. It beats all baseline methods according to all performance metrics. In addition, we again find the benefits given by fuzzy inference on dataset CLEVR-144. As is shown, the fuzzy based method outperforms the crisp-rule based method significantly in terms of the detection accuracy.
%As reflected by these experimental outcomes, in the case of insufficient training data, the assistance of CKIM resulted in better performance for coarse-grained detectors compared to fine-grained detectors, and they are also effective on larger models. In particular, in the dataset with 96 labels, the CKIM-assisted model achieves the same results as the model trained on the dataset with all images. This can be expected as converting fine-grained labels to coarse-grained labels leads to augments the quantity of training data per category, which in turn enhances the accuracy of the model.

\subsubsection{Training process comparison for fine-grained and coarse-grained object detectors}

We conducted an experiment to investigate the difference in the training process between a pair of fine-grained and coarse-grained object detectors. We selected the YOLOv7-tiny model for use. That says we compared a YOLOv7-tiny based fine-grained detector and a YOLOv7-tiny based coarse-grained detector. As shown in Figure \ref{fig:train_5000}, on both CLEVR-96 and CLEVR-144, the coarse-grained detector converges much faster than its fine-grained counterpart. Since our proposed fine-grained object detector consists of a coarse-grained detector and a much lightweight commonsense knowledge inference module (CKIM), the converge speed of our method is almost the same as the coarse-grained detector it employs. It indicates that the convergence speed of our proposed fine-grained detector is much faster than its counterpart fine-grained detector.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figures/train_5000.png}
\caption{Training process of a pair of fine-grained and coarse-grained object detectors}
\label{fig:train_5000}
\end{figure}

\section{Conclusions}

Fine-grained object detection on resource-constrained edge devices remains a challenge for applications of modern deep learning (DL) models. To address this challenge, we proposed a method that combines DL and commonsense knowledge reasoning. Specifically, we introduced a commonsense knowledge inference module (CKIM) to map coarse-grained labels to fine-grained ones. The CKIM is lightweight; it only consumes a negligible 2-3KB memory space in our experiments. Thus, when integrating it with a coarse-grained object detector, we get a model whose size is almost the same as a coarse-grained detector, while it can do fine-grained object detection well. For the design of the CKIM, we identified two pieces of commonsense knowledge for use in our task. The first one is that an object appears to decrease in size as it moves distant, while it appears to enlarge as it moves closer. The second one is that the distance between an object and the camera is strongly connected to the distance between this object's center to the bottom of the image (see Figure 4). Our experiments demonstrated that our technique results in a noticeable decrease in the model size and inference latency, as well as superior detection accuracy compared to all other baseline methods involved.
%This article has presented a CKIM to facilitate the deployment of object detection models on edge devices. This work has been inspired by the discovery that commonsense knowledge contains high-level reasoning abilities, such potential accompanied with  coarse-grained labels may help the inference on fine-grained categories. It makes the following two particular contributions to the object detection: (1) Reducing the expense of acquiring professional data annotations. Fine-grained classes could be generated by the proposed CKIM and coarse-grained labels automatically instead of manually marked by experts. (2) Minimizing requirement for vast data annotations, computation and storage resources on edge devices. Edge devices can now conduct more complex tasks. Experimental studies over the CLEVR datasets have demonstrated the effectiveness of the proposed model in terms of accuracy, latency and model size.

%The proposed work offers many opportunities for further development. For instance, parameters of rules in the CKIM are learned from explicit features. However, including this learning process in the deep model training process remains a challenge. This paper only deal with commonsense knowledge, while using domain knowledge may enhance the fine-grained categorization in the related area. Another interesting issue is how to discover knowledge from raw data and apply it in different assignments.

%Meanwhile, due to the multi-value logic it follows, fuzzy rule inference has the potential to contribute semantic loss for the training of DNNs. Thus, the deep model can learn not only from data, but also from semantic constraints.


%% The file kr.bst is a bibliography style file for BibTeX 0.99c
\section*{Acknowledgment}
This work was supported by Exploratory Research Project (No.2022RC0AN02) of Zhejiang Lab.
\bibliographystyle{kr}
\bibliography{kr-sample}

\end{document}

