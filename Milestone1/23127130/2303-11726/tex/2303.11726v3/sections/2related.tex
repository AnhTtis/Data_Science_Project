\section{Related work}
\label{sec:related}

\subsection{Optimization-based mesh estimation}
Before deep learning dominates this field, 3D human mesh estimation \cite{loper2014mosh,bogo2016keep, lassner2017unite, pavlakos2019expressive, zanfir2018monocular}  is mainly optimization-based, which optimizes the parameters of the human mesh models to match the observations. For example, Loper \etal \cite{loper2014mosh} propose MoSh that optimizes the SMPL \cite{loper2015smpl} parameters to align the mesh with the 3D marker positions. It is usually used to get GT 3D meshes for benchmark datasets because of its high accuracy. Later works propose to optimize the model parameters or mesh vertices based on 2D image cues \cite{bogo2016keep, lassner2017unite, pavlakos2019expressive, zanfir2018monocular, corona2022learned}. They extract intermediate representations such as 2D skeletons from the images and optimize the mesh model by minimizing the discrepancy between the model projection and the intermediate representations such as the 2D skeletons. These methods are usually sensitive to initialization and suffer from local optimum.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{imgs/body_aa.pdf}
    \caption{\textbf{Left:} The learned virtual markers (blue balls) in the back and front views. The grey balls mean they are invisible in the front view. The virtual markers act similarly to physical body markers and approximately outline the body shape. \textbf{Right:} Mesh estimation results by our approach \vmname, from left to right are input image, estimated 3D mesh overlayed on the image, and three different viewpoints showing the estimated 3D mesh with our intermediate predicted virtual markers (blue balls), respectively. }
    \label{fig:body_arche}
\end{figure*}

\subsection{Learning-based mesh estimation}
Recently, most studies follow the learning-based framework and achieve promising results. Existing learning-based methods can roughly be divided into two categories: \textbf{deterministic mesh estimation} and \textbf{probabilistic mesh estimation}. A considerable amount of deterministic estimation work \cite{NIPS2017_ab452534, kanazawa2018end, kolotouros2019learning, xu2019denserac, zhang2020densepose2smpl, luan2021pc, moon2020i2l, zhang2021pymaf, zeng20203d, omran2018neural, zanfir2021thundr, li2021hybrik, choi2020pose2mesh} aims at estimating a single 3D human mesh from a monocular image. However, considering the inherent depth ambiguity in monocular settings, an increasing number of works propose the probabilistic modeling framework which estimates multiple feasible solutions \cite{biggs2020multibodies, fang2023learning, Sengupta_2023_CVPR, Kolotouros_2021_ICCV, Foo_2023_ICCV} to enhance the robustness of the model.

\subsubsection{Deterministic mesh estimation}
% global features -> intermediate representation (IUV image, skeleton, body marker) -> ours
Pioneer works propose to use deep networks \cite{NIPS2017_ab452534, kanazawa2018end, kolotouros2019learning, luan2021pc} to regress the SMPL \cite{loper2015smpl} parameters from image features. However, learning the mapping from the image space to the parameter space is highly non-linear \cite{moon2020i2l}. In addition, they suffer from the misalignment between the meshes and image pixels \cite{zeng20203d}. These problems make it difficult to learn an accurate yet generalizable model. 

Some works propose to introduce proxy tasks to get intermediate representations first, hoping to alleviate the learning difficulty. In particular, intermediate representations of physical markers \cite{zanfir2021thundr}, IUV images \cite{xu2019denserac, zeng20203d, zhang2021pymaf, zhang2020densepose2smpl}, body part segmentation masks \cite{varol2018bodynet, Kocabas_2021_ICCV, lassner2017unite, omran2018neural} and body skeletons \cite{sun2019human, choi2020pose2mesh, li2021hybrik, wan2021encoder} have been proposed. In particular, THUNDR \cite{zanfir2021thundr} first estimates the 3D locations of physical markers from images and then reconstructs the mesh from the 3D markers. The physical markers can be interpreted as a simplified representation of body shape and pose. Although it is very accurate, it cannot be applied to wild images without markers. In contrast, body skeleton is a popular human representation that can be robustly detected from wild images. Choi \etal \cite{choi2020pose2mesh} propose to first estimate the 3D skeletons, and then estimate the intact mesh from them. However, accurate body shapes are difficult to be recovered from the oversimplified 3D skeletons.


\subsubsection{Probabilistic mesh estimation}
Despite the extensive exploration of multi-hypothesis 3D pose estimation \cite{li2019generating, li2020weakly, sharma2019monocular, holmquist2023diffpose, ci2023gfpose, shan2023diffusion, li2022mhformer}, research on probabilistic 3D human mesh estimation remains relatively underdeveloped. Most recent approaches \cite{biggs2020multibodies,sengupta2021hierarchical,fang2023learning,Kolotouros_2021_ICCV,Foo_2023_ICCV} predict distributions over SMPL \cite{loper2015smpl} parameters conditioned on a 2D image. Biggs \etal \cite{biggs2020multibodies} expand upon HMR \cite{kanazawa2018end} to predict a categorical distribution over SMPL parameters and obtain multiple hypotheses discreetly. Sengupta \etal \cite{sengupta2021hierarchical} and ProPose \cite{fang2023learning} utilize the matrix Fisher distribution to model body pose rotation distributions. ProHMR \cite{Kolotouros_2021_ICCV} and HuManiFlow \cite{Sengupta_2023_CVPR} employ Normalizing Flows \cite{rezende2015variational, kingma2016improved} to model the feasible 3D human model parameter distribution. More recently, HMDiff \cite{Foo_2023_ICCV} adopts diffusion models \cite{ho2020denoising} to generate multiple plausible human meshes.

Our work belongs to the learning-based class, offering both deterministic and probabilistic approaches. The deterministic approach, \vmname, introduces \textit{virtual markers} as a novel intermediate representation, improving upon traditional physical markers or skeletons to better disambiguate pose and shape with more expressiveness. Our probabilistic framework, \vmproname, employs diffusion models to produce diverse and plausible virtual marker estimates, from which multiple full mesh estimates that align with the image cues can be obtained. 


\subsection{Diffusion models}
Denoising Diffusion Probabilistic Models (DDPMs) \cite{sohl2015deep,ho2020denoising} are a class of generative models that garner attention for their ability to generate high-quality images \cite{ho2020denoising}. DDPMs employ a forward process where noise is incrementally added to the data until a noise distribution is reached, paired with a reverse process that incrementally denoises to generate data from noise. The strength of DDPMs lies in their iterative refinement, effectively capturing the target data distribution and enabling the synthesis of new samples. With the development of acceleration \cite{ho2020denoising, song2021denoising} and enhancement \cite{nichol2021improved, austin2021structured}, the versatility of DDPMs has been demonstrated across various tasks beyond image generation \cite{ho2020denoising, song2021denoising}, contributing to innovations in video generation \cite{luo2023videofusion, harvey2022flexible, yang2023diffusion}, semantic segmentation \cite{xu2023open}, motion generation \cite{karunratanakul2023guided, tevet2023human, kim2023flame}, \etc

In the realm of 3D mesh estimation, existing methods \cite{Foo_2023_ICCV} apply DDPMs to model a set of downsampled mesh vertices, which is hard to detect from images \cite{moon2020i2l,ma20233d}. Our approach utilizes DDPMs to model the distribution of virtual markers, an efficient and expressive intermediate representation. This reduces the complexity of the modeling, resulting in more robust and accurate estimations.

