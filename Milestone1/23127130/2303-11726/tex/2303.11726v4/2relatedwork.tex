\label{sec:related}

\subsection{Optimization-based mesh estimation}
Before deep learning dominates this field, 3D human mesh estimation \cite{loper2014mosh,bogo2016keep, lassner2017unite, pavlakos2019expressive, zanfir2018monocular}  is mainly optimization-based, which optimizes the parameters of the human mesh models to match the observations. For example, Loper \etal \cite{loper2014mosh} propose MoSh that optimizes the SMPL parameters to align the mesh with the 3D marker positions. It is usually used to get GT 3D meshes for benchmark datasets because of its high accuracy. Later works propose to optimize the model parameters or mesh vertices based on 2D image cues \cite{bogo2016keep, lassner2017unite, pavlakos2019expressive, zanfir2018monocular, corona2022learned}. They extract intermediate representations such as 2D skeletons from the images and optimize the mesh model by minimizing the discrepancy between the model projection and the intermediate representations such as the 2D skeletons. These methods are usually sensitive to initialization and suffer from local optimum.


\begin{figure*}[t]
    \centering
    \includegraphics[width=6.3in]{imgs/body_aa.pdf}
    \caption{\textbf{Left:} The learned virtual markers (blue balls) in the back and front views. The grey balls mean they are invisible in the front view. The virtual markers act similarly to physical body markers and approximately outline the body shape. \textbf{Right:} Mesh estimation results by our approach, from left to right are input image, estimated 3D mesh overlayed on the image, and three different viewpoints showing the estimated 3D mesh with our intermediate predicted virtual markers (blue balls), respectively. }
    \label{fig:body_arche}
    \vspace{-0.4cm}
\end{figure*}

\subsection{Learning-based mesh estimation}
% global features -> intermediate representation (IUV image, skeleton, body marker) -> ours
Recently, most works follow the learning-based framework and have achieved promising results. Deep networks \cite{NIPS2017_ab452534, kanazawa2018end, kolotouros2019learning, luan2021pc, Kolotouros_2021_ICCV} are used to regress the SMPL parameters from image features. However, learning the mapping from the image space to the parameter space is highly non-linear \cite{moon2020i2l}. In addition, they suffer from the misalignment between the meshes and image pixels \cite{zeng20203d}. These problems make it difficult to learn an accurate yet generalizable model. 

Some works propose to introduce proxy tasks to get intermediate representations first, hoping to alleviate the learning difficulty. In particular, intermediate representations of physical markers \cite{zanfir2021thundr}, IUV images \cite{xu2019denserac, zeng20203d, zhang2021pymaf, zhang2020densepose2smpl}, body part segmentation masks \cite{varol2018bodynet, Kocabas_2021_ICCV, lassner2017unite, omran2018neural} and body skeletons \cite{sun2019human, choi2020pose2mesh, li2021hybrik, wan2021encoder} have been proposed. In particular, THUNDR \cite{zanfir2021thundr} first estimates the 3D locations of physical markers from images and then reconstructs the mesh from the 3D markers. The physical markers can be interpreted as a simplified representation of body shape and pose. Although it is very accurate, it cannot be applied to wild images without markers. In contrast, body skeleton is a popular human representation that can be robustly detected from wild images. Choi \etal \cite{choi2020pose2mesh} propose to first estimate the 3D skeletons, and then estimate the intact mesh from them. However, accurate body shapes are difficult to be recovered from the oversimplified 3D skeletons.




Our work belongs to the learning-based class and is related to works that use physical markers or skeletons as intermediate representations. But different from them, we propose a novel intermediate representation, named \textit{virtual markers}, which is more expressive to reduce the ambiguity in pose and shape estimation than body skeletons and can be applied to wild images.

