\label{sec:intro}


\begin{figure}[t]
    \centering
    \includegraphics[width=3in]{imgs/surreal.pdf}
    \caption{Mesh estimation results on four examples with different body shapes. Pose2Mesh \cite{choi2020pose2mesh} which uses 3D skeletons as the intermediate representation fails to predict accurate shapes. Our virtual marker-based method obtains accurate estimates.}
    \label{fig:surreal_shape}
    \vspace{-0.5cm}
\end{figure}

3D human mesh estimation aims to estimate the 3D positions of the mesh vertices that are on the body surface. The task has attracted a lot of attention from the computer vision and computer graphics communities \cite{boulic1997integration, presti20163d, li2020pastanet,loper2014mosh,NIPS2017_ab452534, kanazawa2018end, kolotouros2019learning, luan2021pc, Kolotouros_2021_ICCV, ci2022gfpose} because it can benefit many applications such as virtual reality \cite{huang2017towards}. Recently, the deep learning-based methods \cite{kanazawa2018end,choi2020pose2mesh,li2021hybrik} have significantly advanced the accuracy on the benchmark datasets.

The pioneer methods \cite{NIPS2017_ab452534, kanazawa2018end} propose to regress the pose and shape parameters of the mesh models such as SMPL \cite{loper2015smpl} directly from images. While straightforward, their accuracy is usually lower than the state-of-the-arts. The first reason is that the mapping from the image features to the model parameters is highly non-linear and suffers from image-model misalignment \cite{li2021hybrik}. Besides, existing mesh datasets \cite{h36m_pami,vonMarcard2018,mehta2017monocular,lassner2017unite} are small and limited to simple laboratory environments due to the complex capturing process. The lack of sufficient training data severely limits its performance. 






Recently, some works \cite{kolotouros2019convolutional, moon2020i2l} begin to formulate mesh estimation as a dense 3D keypoint detection task inspired by the success of volumetric pose estimation \cite{sun2018integral,tu2020voxelpose,zhang2022voxeltrack,qiu2019cross,ye2022faster,su2022virtualpose}. For example, in \cite{kolotouros2019convolutional, moon2020i2l}, the authors propose to regress the 3D positions of all vertices. However, it is computationally expensive because it has more than several thousand vertices. Moon and Lee \cite{moon2020i2l} improve the efficiency by decomposing the 3D heatmaps into multiple 1D heatmaps at the cost of mediocre accuracy. Choi \etal \cite{choi2020pose2mesh} propose to first detect a sparser set of skeleton joints in the images,
% using the volumetric representations (they use fcn to directly regress 3d pose
from which the dense 3D meshes are regressed by exploiting the mesh topology. The methods along this direction have attracted increasing attention \cite{choi2020pose2mesh,li2021hybrik, wan2021encoder} due to two reasons. First, the proxy task of 3D skeleton estimation can leverage the abundant 2D pose datasets which notably improves the accuracy. Second, mesh regression from the skeletons is efficient. However, important information about the body shapes is lost in extracting the 3D skeletons, which is largely overlooked previously.  As a result, different types of body shapes, such as lean or obese, cannot be accurately estimated (see Figure \ref{fig:surreal_shape}).

The professional marker-based motion capture (mocap) method MoSh \cite{loper2014mosh} places physical markers on the body surface and explore their subtle non-rigid motions to extract meshes with accurate shapes. However, the physical markers limit the approach to be used in laboratory environments. We are inspired to think whether we can identify a set of landmarks on the mesh as virtual markers, \eg, elbow and wrist, that can be detected from wild images, and allow to recover accurate body shapes? The desired virtual markers should satisfy several requirements. First, the number of markers should be much smaller than that of the mesh vertices so that we can use volumetric representations to efficiently estimate their 3D positions. Second, the markers should capture the mesh topology so that the intact mesh can be accurately regressed from them. Third, the virtual markers have distinguishable visual patterns so that they can be detected from images. 


In this work, we present a learning algorithm based on archetypal analysis \cite{cutler1994archetypal} to identify a subset of mesh vertices as the virtual markers that try to satisfy the above requirements to the best extent. Figure \ref{fig:body_arche} shows that the learned virtual markers coarsely outline the body shape and pose which paves the way for estimating meshes with accurate shapes. Then we present a simple framework for 3D mesh estimation on top of the representation as shown in Figure \ref{fig:pipeline}. It first learns a 3D keypoint estimation network based on \cite{sun2018integral} to detect the 3D positions of the virtual markers. Then we recover the intact mesh simply by interpolating them. The interpolation weights are pre-trained in the representation learning step and will be adjusted by a light network based on the prediction confidences of the virtual markers for each image. 

We extensively evaluate our approach on three benchmark datasets. It consistently outperforms the state-of-the-art methods on all of them. In particular, it achieves a significant gain on the SURREAL dataset \cite{varol2017learning} which has a variety of body shapes. Our ablation study also validates the advantages of the virtual marker representation in terms of recovering accurate shapes. Finally, the method shows decent generalization ability and generates visually appealing results for the wild images. 








