\vspace{-1em}
\section{Related Work}
\label{sec:related}

The LOS prediction problem can be stated in different ways varying in the required resolution of the prediction, applied methods, and structure of patient data.
Iwase et al.~\cite{iwase2022prediction} investigate the use of Machine Learning (ML) methods for LOS prediction of intensive care unit patients (ICU). Using Random Forest (RF), Gradient Boosting (GB), and Artificial Neural Networks (ANN) technologies, on binary stratification of patient admissions into long (more than one week) and short (less than one week) stays. RF showed high predictive performance. In contrast to the tabular structure of their data, we instead attempt to utilize the temporal dependencies within the data by structuring the patient data as medical event sequences. In Batista et al.~\cite{batista2020methodology}, patients are stratified into three categories (LOS $< 3$, $3 <$ LOS $< 10$, LOS $>= 10$) using RF and Support Vector Machines (SVM). The highest performance was achieved for RF models. While the nature of their ML models requires manual feature selection and missing data imputation, our method does not require any feature selection for in-hospital measurements, nor does it rely on data imputation. 

The most challenging LOS prediction task is regression-based LOS, where the precise hospitalization LOS as a real value is to be predicted. Barsasella et al.~\cite{barsasella2022machine} investigated a range of classical AI models, such as Decision Trees (DTs), RFs, Logistic Regression (LR), and SVMs for real-valued LOS prediction. While standard ML models work for tabular structured patient data, they neglect the important temporal dependencies between in-hospital patient events. While much work has been done in LOS prediction and regression using standard ML methods, only a few works attempt the usage of sequence models.

Seminal work in the area of transformer models for patient sequence data includes that of Li et al.~\cite{li2020behrt} and Rasmy et al.~\cite{rasmy2021med}, where sequences of diagnosis codes for consecutive hospitalizations are used as input to a BERT like transformer model for diagnosis code prediction tasks. While Rasmy et al.~\cite{rasmy2021med} investigate prolonged LOS $> 7$ days event prediction as a model pre-training task, they do not predict future LOS for new patients. Furthermore, while their approaches are only investigated for sequences consisting of diagnosis codes, we evaluate sequences consisting of multiple patient event types. 

In Meng el al.~\cite{meng2021bidirectional}, a transformer model is used to predict the onset of depression. They integrate various medical types for patient event sequences, including diagnosis and medication events. While their sequences include code-based medical events, we extend with medical measurement events, such as laboratory tests and vital measures while encoding the event value as part of the event token.

The work closest to ours is that of Song et al.~\cite{song2018attend}, where an attention model is used to predict categorical LOS based on patient sequences. Whereas their approach targets dense time-series data, where the same measurements are present at every timestep, instead, we investigate a learned embedding approach where the input sequences consist of codes with different types of medical events.       

%\begin{itemize}
%    \item Integrates patient history in a new way
%    \item Integrates more modalities
%    \item Integrates measurement values
%\end{itemize}

%\begin{itemize}
%    \item BRLTM
%    \item Song et al. 
%\end{itemize}
%Here we present the current work on the utilization of sequence models for Length of Stay prediction. Introduce BEHRT~\cite{li2020behrt}, Med-BERT~\cite{rasmy2021med} and BRLTM~\cite{meng2021bidirectional}. Perhaps also Hi-BEHRT~\cite{li2021hi}.

%\begin{itemize}
%    \item They are all limited in the number of visits patients must have to be part of training. It does not extrapolate to new patients. We %do not have this limitation.
%\end{itemize}
