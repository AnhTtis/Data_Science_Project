{
    "arxiv_id": "2303.11816",
    "paper_title": "Personalized Lightweight Text-to-Speech: Voice Cloning with Adaptive Structured Pruning",
    "authors": [
        "Sung-Feng Huang",
        "Chia-ping Chen",
        "Zhi-Sheng Chen",
        "Yu-Pao Tsai",
        "Hung-yi Lee"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SD",
        "eess.AS"
    ],
    "abstract": "Personalized TTS is an exciting and highly desired application that allows users to train their TTS voice using only a few recordings. However, TTS training typically requires many hours of recording and a large model, making it unsuitable for deployment on mobile devices. To overcome this limitation, related works typically require fine-tuning a pre-trained TTS model to preserve its ability to generate high-quality audio samples while adapting to the target speaker's voice. This process is commonly referred to as ``voice cloning.'' Although related works have achieved significant success in changing the TTS model's voice, they are still required to fine-tune from a large pre-trained model, resulting in a significant size for the voice-cloned model. In this paper, we propose applying trainable structured pruning to voice cloning. By training the structured pruning masks with voice-cloning data, we can produce a unique pruned model for each target speaker. Our experiments demonstrate that using learnable structured pruning, we can compress the model size to 7 times smaller while achieving comparable voice-cloning performance.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11816v1"
    ],
    "publication_venue": "ICASSP 2023"
}