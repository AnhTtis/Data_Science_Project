\ifarXiv
\newcommand{\rem}{Results}
\else
\newcommand{\rem}{Methods}
\fi

\subsection{Trading nonlinearity for degrees of freedom}
\label{sec:trading}

The first step in our process of adapting nonlinear fluid dynamics to the requirements of
quantum algorithms is to use 
the lattice Boltzmann form of the NSE (see \rem).  The lattice
Boltzmann equation (LBE) is a nondimensionalized form of the Boltzmann equation
with discrete velocities and a collision term that often follows the Bhatnagar--Gross--Krook form
\cite{Bhatnagar1954ASystems}.  It is called ``lattice'' 
because it yields Lagrangian-like solutions when solved with first-order spatial
and temporal discretization with upwind advection \cite{Chen1998LatticeFlows} in
which the discrete-velocity particles arrive at neighboring grid points after
exactly one time step. This solution method is referred to as the lattice
Boltzmann method (LBM).
For our purpose, the essential characteristics of the LBE are the linear advection term
(inherent to the Boltzmann formulation) and the manifest form of the degree of nonlinearity
in the collision term (due to the nondimensionalization).

The advection term is linear in the kinetic-theory-motivated LBE because the discrete velocity distributions are advected in space by
constant lattice velocities, the analogue of which in the kinetic theory of
fluids is the speed of sound.  
The collision-term nonlinearity is instead $O(\text{Ma}^2)$, where $\text{Ma}$
is the Mach number, defined as the ratio between the characteristic
fluid velocity and the speed of sound.  This is because the fluid velocity $\bm{u}$ is proportional to the first moment
of the particle distribution function.  In nearly incompressible flows, $\bm{u}$
is always small relative to the speed of sound.  The nondimensional velocities,
which are scaled by the lattice velocity, make the $\vert \vec{u} \vert =
O(\ma)$ scaling explicit.

Thus, the character of the nonlinearity is fundamentally changed between the NSE
and LBE. The
nonlinearity of the NSE stems from the term $\bm{u}\cdot \nabla
\bm{u}$, and this nonlinearity is characterized by $\text{Re}$. In contrast, the
nonlinearity in the LBE stems from $\vert\bm{u}\vert^2$, and this nonlinearity is characterized
by $\text{Ma}^2$.  This change is advantageous for high-Re, low-Ma flows, the
situation in most geophysical and many engineering applications.  
However, it comes at the expense of using a large number of discrete lattice
velocities to form the quadrature ($Q$) that simulates the molecular
velocity distribution. For instance, to use LBM to simulate three-dimensional NSE,
the number of degrees of freedom must be increased by a factor of 27 in the D3Q27 formulation. Here, the number after \textit{D} stands for the dimension of the system, and that after \textit{Q} represents the number of discrete lattice velocities in the quadrature.
For $n$ grid points, the number of LBE degrees of freedom increases $Q$-fold to
$nQ$. 

The second step in our process of adapting nonlinear fluid dynamics to the requirements of
quantum algorithms is to eliminate the weakened 
  nonlinearity in the lattice Boltzmann formalism using Carleman linearization \citep{Carleman1932,Forets2017} (see \rem).
Carleman linearization leads to an infinite-dimensional system of linear
differential equations.  The system is truncated at a finite degree for
practical implementation, resulting in a  truncation
error.  In work that has pursued this avenue \citep{Liu21,
  Lloyd2020QuantumEquations}, the truncation error depends on the degree of
nonlinearity in the original equation \citep{Forets2017, Liu21}.  For turbulent
flows, \citet{Liu21} find that the Carleman-linearized Burgers' equation is
intractable for quantum algorithms at $R \ge 1$.  We show, in
contrast, that the truncation error for the Carleman-linearized
LBE is a power series in Ma, as 
expected for a system of equations whose nonlinearity is characterized by Ma; therefore, the truncation error is strongly suppressed for weakly compressible flow and becomes independent of Re (see \rem).

As discussed in the \rem, the lowest Carleman linearization degree that can
be used for the LBE is 3 (i.e., terms up to cubic degree in the distribution
functions appear in the truncated equations).  This degree is also sufficient,
as the associated truncation error is of the same order (i.e., $\ma^2$) as the LBE error in
reproducing the NSE \citep{Chen1998LatticeFlows}.

We note one further difference between our analysis and the truncation error analyses of \citet{Liu21} and
\citet{Forets2017}.  These prior analyses provide error bounds for arbitrary nonlinear differential equations
based on the coefficient-matrix norms for the linear and nonlinear terms.  Our
results provide much tighter error bounds due to two specific properties of the
LBE.  First, the symmetries of the lattice lead to exact
cancellation of certain terms, which makes the truncation error for powers of $u$
identically zero.  Second, we benefit from the velocity rescaling on the lattice, which, as discussed earlier, suppresses the nonlinear terms by $O(\text{Ma})$ relative to the linear terms \citep{LALLEMAND2021109713}.

After Carleman linearization, the final number of degrees of freedom in the
LBE is $N=n^3Q^3 + n^2Q^2 + nQ = O(n^3Q^3)$.  This is a dramatic
increase over the $n$ degrees of freedom required for NSE at the
same resolution.  However, this is a polynomial increase; if it permits us to take
advantage of $O(\log N)$ scaling, then this is a trade-off well worth making.

\subsection{Quantum speedup for turbulence}

Accurate linear approximation of the LBE in hand, we now need to determine whether the $\O(\poly\log N)$ scaling of quantum linear systems solvers can be achieved for our particular system of equations \cite{Aaronson2015,Berry2017QuantumPrecision}.

First, it must be possible to load the initial state and extract the final state
in at most $\O(\poly\log N)$ time. This constraint precludes applying this method to
initial-value sensitive problems (e.g., numerical weather prediction).  However, a vast class of
interesting physical applications (e.g., climate projections) are 
boundary-value sensitive problems; for these problems, the
initial distribution can be highly idealized (e.g., as a Gaussian distribution),
and the turbulent features can be allowed to spin up over time.  Such
an initial state can be prepared
in the required time using methods such as
\citet{kitaev2008wavefunction,grover2002creating}.
The information extracted from the final state needs to fit into a single scalar
that results from measuring the expectation value of an operator on the final
state.  This is because of the infamous output problem in quantum
computing~\cite{Aaronson2015} wherein the cost of reading the solution from a
quantum algorithm is exponentially greater than the cost of finding the quantum
solution.  This usually occurs when one wishes to learn the entire solution as a
quantum state and, thus, is forced to perform quantum state
tomography~\cite{cramer2010efficient}.  Expectation values can typically be
learned at modest cost by sampling quantities such as the domain-mean flux
across a boundary. This is a meaningful quantity that can be extracted from
sampling the state and that does not incur the exponential overhead if one is willing
to accept errors that are inverse polynomial in the system
size. We remark that our algorithm produces a state vector $\ket{\mathcal V}$ that encodes the solution without providing a detailed procedure of extracting the solution from $\ket{\mathcal V}$. Developing an efficient measurement method to ensure the end-to-end quanutm advantage will be explored in future studies.
  
Second, the quantum solver needs to be able to evolve the initial state to the final state (i.e., the state after an evolution time $\tilde T$) in at most $\O(\poly\log N)$ time.  Here, we make use of the known complexity of state-of-the-art quantum algorithms for ODEs from \citet{Berry2017QuantumPrecision}; we eschew existing approaches to nonlinear differential equations that only use forward-Euler discretizations because of our specialized analysis of the error in Carleman linearization.  
Expressing each factor in the \citet{Berry2017QuantumPrecision} complexity
formula (\Eq{eq:ca}) in terms of the properties of the Carleman-linearized LBE
results in \Eq{eq:complong}. 
The system parameters that determine the complexity are the 
number of discrete lattice velocities $Q$, the LBE collision time scale $t_c$, 
the evolution time $\tilde T$, and the number of grid points $n$. 

The number of discrete velocities is fixed and independent
of other system parameters; as discussed, $Q\leq 27 \ll n$ is widely used in three-dimensional LBM simulations.  
Evolution time is an external requirement that is determined by the
physics problem being solved. Collision time is associated with the
molecular nature of the fluid that can be decoupled from
the smallest turbulent time scale (here, the Kolmogorov time scale). The resulting complexity scales as $\poly\log(n)$.  This opens the possibility of simulating enormous domains while resolving a complex interplay between physics ranging from Kolmogorov to integral scales.

The overall complexity, therefore, can be set to be independent of the NSE nonlinearity (i.e., the Reynolds number).
This conclusion is aligned with a fundamental assumption of the NSE: the continuum assumption that the infinitesimal volume of fluid is much larger than that associated with molecules, which allows the molecular details of the fluid to be dropped. Because of this assumption, the degree of nonlinearity in the LBE formulation can be adjusted independently of that in the NSE. 
This remarkable result comes from the fundamental difference, discussed above, between the Reynolds-type nonlinearity in the original NSE and the Mach-type nonlinearity in their LBE form.  


\ifarXiv
\section{Conclusion and outlook}
\else
\subsection{Resolving complex science problems}
\fi

We have shown how to use quantum solvers to simulate turbulence.
The resulting logarithmic scaling in number of degrees of freedom compares to the polynomial scaling of the gold-standard
classical algorithms \cite{Orszag1970,Exascale2017}.  (We make no claim that the
best known classical algorithms are, in fact, the best possible \cite{Tang21}.)
This marks an important
milestone in understanding turbulence through numerical
simulations.  Much ground remains to be covered before reaching the ultimate destination
of applying this tool
to actual complex physical
systems; at the same time, previously unthinkable possibilities are now
visible on the horizon.

The specific manifestation of turbulence depends sensitively on boundary
conditions.  We have not considered these in our idealized derivations, but work on doing so 
is urgently needed.  Furthermore, many complex physical systems are
heterogeneous, consisting of multiple coupled subsystems and multiple species or thermodynamic phases.
There are well-established ways to impose complex boundary
conditions and to add phases, phase interactions, phase change, and reactions in
the LBM \citep{Zou97, Ladd2001, Guo02}.
Such schemes, combined with further development based on our results, can be
applied to challenging multiphase or reactive flow problems, such as droplet
coalescence under turbulence \cite{Chun2005,Li2018EffectDroplets} and nanoparticle
assembly under an external field that involves a fluid flow \citep{Saville1977,Boles2016}.
In essence, our method will need to be extended by further increasing the number of degrees of freedom until
not just the Kolmogorov scales but even the solid-particle or liquid-droplet microscale is
explicitly resolved. 
  A large number of applications have already been simulated using the LBM \citep{Martys01, Ladd2001,  CHEN2014210, LI201662,Liu16, HE2019160,Petersen21, SAMANTA2022111288, NOURGALIEV2003117, Aidun10, Bernaschi2019}, and these could immediately benefit from such work. 
  
More generally, many systems besides the NSE do not meet the linear and
nondissipative requirements of quantum algorithms at first glance. There is
often a trade-off between linearity and the number of explicit degrees of
freedom sampled. The full dimensionality of a molecular dynamics simulation versus
the reduced dimensionality of the nonlinear NSE hydrodynamics is a canonical example.
Based on our LBE method, it is plausible that---and it should be urgently
tested whether---many of the nonlinear multiscale transport phenomena
described by the Boltzmann transport equation would also benefit from a quantum speedup.
