\ifarXiv
Complex systems exhibiting multiscale dynamics are ubiquitous in
nature. Developing the ability to understand, predict, or modify these systems
ranks among the ``grand challenges'' of science and engineering
\citep{Omenn2006,WCRP,NASEM2016}. 
Areas of application for this knowledge
include the Earth's ocean and atmosphere
\cite{Hasselmann1976,Majda2003,Bony2015,Ghil2020,Gupta2022}, 
biological
systems \cite{Bernaschi2019}, and synthesis of advanced materials
\cite{Boles2016,Salzmann2021,DeYoreo2015,DeYoreo2022,Russel}.  
The dynamics of these systems admits no analytic solution, but numerical
simulation needs to either parameterize the small-scale processes---which
introduces large uncertainties---or explicitly resolve the smallest
scales---which is prohibitively expensive. 
\fi

Turbulent fluid dynamics embodies a defining feature of complex systems: the
lack of scale separation \cite{pope2000turbulent, Bodenschatz2010}. As all
scales interact with each other, they cannot be investigated individually.
Turbulence contributes to the multiscale behavior of many of the complex systems
mentioned above, including geophysical  \cite{Sherwood2014,Bretherton2015,Donner2016}, astrophysical, and many engineering
fluid dynamics applications.  Because the length and time
scales of the constituent processes can be a minute fraction of the integral
scale of the system (e.g., the turbulent length scale range is $\sim 10^{7}$ for
atmospheric flows), outright scale range-resolving simulations are simply not
feasible on classical computers \cite{Exascale2017,Schneider2017ClimateClouds}.  

Attempts to understand turbulence have centered on the Navier--Stokes equations
(NSE).  These equations describe the macroscopic momentum and density evolution
of fluids; multiscale interactions arise from the nonlinear advection term
$\vec{u}\cdot\nabla\vec{u}$ for the fluid velocity field $\vec{u(\vec{x},t)}$
in space $\vec{x}$ and time $t$ (see Methods).  Approaches to solving the NSE
numerically include using ``reduced'' models that are based on
a proper orthogonal decomposition with key representative modes to mimic the
dynamics of the full spectrum \citep{berkooz1993proper,podvin2017few} and averaging over those scales not explicitly
resolved (e.g., with Reynolds averaging) and using a constitutive relation (e.g., eddy
viscosity) to close the Reynolds-averaged NSE
\citep{tennekes1972first, Durbin18}. Such
approaches parameterize the small-scale behavior based on the resolved-scale
state of the model, which produces tractable simulations at the expense of an
artificial scale separation.  This unavoidable model defect results in
persistent uncertainty in projections
of complex systems' emergent behaviors
\cite{Artime2022,Hasselmann1976,Feingold2016}, e.g., the sensitivity of the
climate to anthropogenic perturbations \cite{Wheatcraft1991,Carslaw2018,Muelmenstaedt2018,Ge2019,Sherwood2020,Bellouin2020,Moum2021}. 
%Other recently developed structure-resolving methods inspired by quantum many-body physics also suffers from multiscale interactions \citep{gourianov22}.  

A structurally different formulation of fluid dynamics exists in the form of the
Boltzmann equation.  This formulation describes the evolution of particle
distribution functions $f(\vec{x},\vec{v},t)$ in space and particle velocity
$\vec{v}$ (see \Eq{eq:LBMs} and \Eq{eq:feq} in Methods).  These distribution functions are mesoscopic objects that comprise sufficiently large
numbers of molecules for a statistical-mechanics treatment but that are smaller
than the macroscopic fluid elements.  The Boltzmann equation is still nonlinear (see
below), but in an important difference from the NSE, its
nonlinearity does not reside in the advection term \cite{Chen1998LatticeFlows}.
In classical time-marching spectral or spatial discretization algorithms, the
Boltzmann equation is even more prohibitively expensive than the NSE
\cite{Orszag1986}; in quantum computing algorithms, as we will show, the
trade-off goes the other way, largely due to the linear
Boltzmann advection term.

\leavevmode
\begin{figure}[t!]
% trim=left bottom right top  
\begin{overpic}[width=0.75\textwidth]{PCSD_0590_ILLUS.3}\put(20,97){(a)}\put(49,91){(b)}\put(30,49){(c)}\put(20,15){(d)}\end{overpic}
\caption{Illustration of the complexity of solving Navier--Stokes equations
using quantum algorithms: (a) Reynolds number-determined strongly nonlinear
Navier--Stokes equations; (b) Mach number-determined weak nonlinear
lattice Boltzmann form of Navier--Stokes equations; (c) Carleman-linearized lattice Boltzmann equation; (d) exponential quantum advantage in solving the Carleman-linearized lattice Boltzmann equation.
}
\label{PCSD_0590_ILLUS.3}
\end{figure}


\subsection*{Requirements for Quantum Algorithm}
Whether the NSE or Boltzmann equation is chosen, explicit simulation of
turbulence requires large numbers of degrees of freedom $N$.  In both spatial
and spectral discretization, $N$ reflects the ratio between the largest
and smallest scales, i.e., the integral system scale and the Kolmogorov scale.  
As quantum computers inherently grant the ability to manipulate vectors in
exponentially large vector spaces in polynomial time, one may ask whether such
methods could be used to solve the turbulence problem.

Harrow, Hassidim, and Lloyd~\cite{Harrow09} answer this question in
the affirmative for generic linear systems.  This vector manipulation
approach naturally leads to a strategy for achieving a potential
exponential speedup when solving systems of coupled ordinary differential equations~\cite{berry2014high, Berry2017QuantumPrecision}
\ifarXiv
.
\input{qlsa}
\else
(see Methods).
\fi
%Specifically, these algorithms can yield a state $\ket{x}$ for any $\ket{b}$ solved for a sparse Hermitian matrix $A$ such that the equation\begin{equation}
%A\ket{x} = \ket{b}
%\end{equation}
%is satisfied up to a constant of proportionality.  The method works by constructing a unitary matrix that encodes $A$ within a block of the original matrix, specifically, $(\bra{0}\otimes I) U_{A^{-1}} (\ket{0} \otimes I) \ket{0}\ket{b} \propto A^{-1} \ket{b}$, with $I$ being the identity matrix. 
% Such a representation is known as a block encoding.  The performance cost scales as $O(d\kappa\log(1/\epsilon))$ accesses to the matrix elements of the $d$-sparse matrix $A$, which we further assume is invertible and has condition number $\kappa$ and desired solution error $\epsilon$~\cite{childs2017quantum}.
%
%The simplest strategy that can be employed for solving systems of differential equations involves using a forward-Euler approach to discretize a differential equation of the form $\partial_t x(t) = A x(t) + b(t)$ and then solve the resulting equation using the quantum linear systems algorithm.  The resulting difference equation takes the form $x(t_{i+1}) = x(t_i) + h Ax(t_i) +hb(t)$ for stepsize $h$.  The central idea behind this approach is to construct a quantum state over both the solution space and the time that the system is evaluated at.  Specifically, if we let our solution be $x(t)$, then we encode our solution as $\sum_i c_i \ket{t_i} \ket{\psi_i}$, where $\ket{\psi_i}$ is the solution at time $t_i$, and $c_i$ is arbitrary constants.  Given a state of this form, we can find the solution state by measuring the $t_i$ register (or using amplitude amplification) to achieve a value that is $t_f$, which is the final time desired for the algorithm.  In practice, the probability of measuring this result is low, so the standard approach to this problem is to extend (typically double) the simulation time but turn off the differential equation to ensure that the solutions are merely copied on all subsequent times.  Since the solution is the same at all such times, this serves to raise the probability of success to a constant without requiring substantial computational overhead.
%Specifically,  the solution for a two-time-step result with two further time steps used for padding then reads~\cite{berry2014high}
%\begin{equation}
%\begin{bmatrix} I &0 &0 &0 &0\\ 
%-(I + hA) & I &0&0&0\\
%0 &-(I + hA) & I &0&0\\
%0&0&-I&I&0\\
%0&0&0&-I&I\end{bmatrix} \begin{bmatrix} x(0) \\ x(h) \\x(2h) \\ x(3h) \\ x(4h) \end{bmatrix} = \begin{bmatrix} x_{\text{init}} \\ bh \\ bh \\ 0 \\0 \end{bmatrix}
%\end{equation}
%In this form, the solution vector over all times can be found by inverting the above matrix.  In practice, this approach is not favorable in classical computing, as it requires a substantial overhead due to the dimension of the space. But, as the cost of the quantum linear systems algorithms does not directly depend on the dimension, this approach can be surprisingly effective in quantum settings.

Taking the algorithm of \citet{Berry2017QuantumPrecision} as an example, the
overall algorithm complexity, as measured by the number of two-qubit quantum gates and oracle queries, depends on $\log N$, but also on numerous other
properties of the system of equations being solved (expressed through the
$N\times N$ coefficient matrix $\mathcal C$):
\begin{equation}
  \label{eq:ca}
  \text{gate complexity}=O(\Vert \mathcal C\Vert \kappa_J g T s\cdot \text{poly}(\log{(\kappa_J s g \beta T \Vert \mathcal C \Vert N/\epsilon)})).
\end{equation}
These properties include the spectral norm of the coefficient matrix $\|\mathcal C\|$, the condition
number $\kappa_J$ of the eigenvectors of $\mathcal C$, the dissipation parameter $g$, the
evolution time $T$, the sparsity $s$, the norm of the initial state $\beta$, and
the desired solution error $\epsilon$.  If any of $\|\mathcal C\|$, $\kappa_J$, $g$, $T$,
or $s$ has implicit
polynomial (or worse) dependence on $N$, or if
$\beta$ or $\epsilon$ has exponential (or worse) dependence on $N$, the
headline exponential advantage is negated.  

When the underlying system of equations is nonlinear, the requirements for
efficient solution become more stringent still.  There is no known quantum
algorithm that is directly applicable to nonlinear differential equations;
instead, the nonlinear system first needs to be approximated by a (larger)
system of linear equations \cite{Lloyd2020QuantumEquations,Liu21}.  Whether the
quantum algorithm is still efficient after this approximation depends on the degree of nonlinearity
\cite{Liu21}.  The
nonlinearity of NSE is characterized by the Reynolds number (see Methods).
    Quantum algorithms are unable to simulate NSE \citep{Liu21} with $\re \ge \sqrt{2}$,
which is far from the values in relevant cases (e.g., atmospheric turbulence \citep{Siebert06, Grabowski2013GrowthEnvironment} with $\re \approx 10^7$). 

We will now analyze whether the Boltzmann form of fluid dynamics, after
linearization, can take advantage of quantum algorithms' efficient handling of large $N$
without violating these algorithms' strict requirements.
Our aim in this manuscript is not quantum algorithm development but, rather, 
showing that turbulent fluid dynamics is tractable with existing quantum algorithms,
provided the Boltzmann formulation, rather than the NSE formulation, is used.


