\section{Discussion}
\label{sec:findings}

This section overviews the main characteristics of the taxonomy and maps our observations to state-of-the-art and industry practices. We conclude the section with a brief summary of the main aspects that contribute to the overall quality of the taxonomy.

\subsection{Mapping the taxonomy to the state of the art}

Table \ref{tab:tax-overview} summarizes the distribution of the number of vulnerabilities per each of the main categories present in our taxonomy. As we can see, the distribution is dominated by 'Bad Programming Practices \& Language Weaknesses', which account for almost half of the defects. Most of the remaining defects show relatively similar numbers among themselves.

\begin{table}[h!]
\centering
\caption{Vulnerability  distribution per taxonomy's main categories}
\label{tab:tax-overview}
\begin{tabular}{|l|c|}
\hline
\textbf{Category} & \textbf{\# Vulnerabilities} \\ \hline
Unsafe External Calls & 9 \\ \hline
Mishandled Events & 5 \\ \hline
Gas Depletion & 2 \\ \hline
Bad Programming Practices \& Language Weaknesses & 36 \\ \hline
Incorrect Control Flow & 9 \\ \hline
Arithmetic Issues & 6 \\ \hline
Improper Access Control & 9 \\ \hline
\end{tabular}
\end{table}

Figure \ref{fig:odc-qualifier} further characterizes the identified vulnerabilities, namely by identifying the different \textit{defect types} (in the y-axis) and specifying the number of OpenSCV vulnerabilities per each defect type (between parenthesis, in the y-axis). The plot then shows the prevalence of the \textit{qualifier} values. Notice that the sum of the qualifier values exceeds the vulnerability count between parenthesis in the y-axis, as a certain defect  may be associated with more than one qualifier.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.60]{img/figure7.pdf}
    \caption{Vulnerabilities per ODC defect type and qualifier.}
    \label{fig:odc-qualifier}
\end{figure}


As we can see in Figure \ref{fig:odc-qualifier}, the top \textit{defect types} fit in 'Assignment/Initialization' 'Checking', and 'Algorithm/Method', which is closely followed by 'Interface/O-O Messages'. The top three defect types account for nearly two-thirds of the defects, with the top four accounting for more than 80\% of the 76 vulnerabilities.

Table \ref{tab:combination} summarizes the \textit{qualifier} prevalence. It also shows the prevalence of qualifier combinations, which represent vulnerabilities whose correction may be related to more than one qualifier (e.g., a certain vulnerability may be due to a 'missing' or due to a 'wrong' 'assignment'). The 'wrong' qualifier is the most frequent one, followed by 'missing'. In terms of combinations, 'missing' and 'wrong' are the most frequent case.


\begin{table}[h!]
\centering
\caption{ODC qualifier distribution.}
\label{tab:combination}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Qualifier} & \textbf{Extraneous} & \textbf{Missing} & \textbf{Wrong} \\ \hline
Extraneous         & 10                  & 1                & 3              \\ \hline
Missing            & 1                   & 30               & 19             \\ \hline
Wrong              & 3                   & 19               & 58             \\ \hline
\end{tabular}
\end{table}


We selected three different cases of classification schemes for comparison with OpenSCV. In particular, we selected SWC \cite{swc} for frequently appearing in the literature, we also selected the classification by \cite{Rameder2022} for being the most extensive one found in the state of the art, and we also selected the list of vulnerabilities used in \cite{Hu2023} for being the most recent vulnerability detection work in our list. Figure \ref{fig:swc-dasp} shows to what extent these classifications map the vulnerabilities identified in our taxonomy and overall shows their reach and practical limitations.

\begin{figure}[h]
    \centering
   \includegraphics[scale=0.50]{img/figure8-comparison.pdf}
    \caption{Mapping of the identified vulnerabilities to other classifications.}
    \label{fig:swc-dasp}
\end{figure}

The first observation from Figure \ref{fig:swc-dasp} is that the number of distinct vulnerabilities currently captured by OpenSCV exceeds the remaining classifications in the plot. SWC has seen its 37 vulnerabilities unfold into 49 different cases. We also map all 48 vulnerabilities in \cite{Rameder2022}, in this case in a one-to-one mapping (notice that the work reports a total 54 defects, of which we excluded 6 that do not represent security vulnerabilities). Finally, 18 vulnerabilities in \cite{Hu2023} are mapped into 19 in OpenSCV (one of the vulnerabilities unfolds in two in OpenSCV). We must mention that \cite{Hu2023} actually identifies a total of 20 vulnerabilities, although, for two of them, there are no sufficient details to allow an understanding of what exactly the defect represents.


We now analyze the state of the practice (in terms of tools) by analyzing their announced vulnerability detection capabilities facing the identified vulnerabilities in our taxonomy. Figure \ref{fig:tool-coverage}.a) shows the practical distance of the 49 identified works in vulnerability detection to our current state of knowledge in what concerns smart contract vulnerabilities. Figure \ref{fig:tool-coverage}.b) shows, from the perspective of each individual vulnerability, how many tools are being designed to detect it. 

\begin{figure}[h]
    \centering\includegraphics[scale=0.70]{img/figure9boxplots.pdf}
    \caption{Announced detection capabilities of current tools: a) average number of vulnerabilities detected per tool; b) average number of tools per vulnerability.}
    \label{fig:tool-coverage}
\end{figure}



As we can see in Figure \ref{fig:tool-coverage}.a), current tools are being designed to detect in average 7  of the vulnerabilities in OpenSCV. If we consider the first quartile we see that tools are projected to detect from 3 to 8.5 different vulnerabilities. The best three vulnerability detection works (in terms of projected detection capabilities) are: Securify \cite{Tsankov2018} covering 44.8\% of OpenSCV vulnerabilities (34 out of 76); Neucheck \cite{lu_neucheck_2019} with 36\%, (20 out of 76) and; SoliDetector \cite{Hu2023} which is projected to detect 25\% of the vulnerabilities in OpenSCV (19 out of 76). We can see that, event in terms of design for detection, the room for improvement is huge and the plain combination of the different tools capabilities in itself is a clear possibility for the creation of a better tool. Figure \ref{fig:tool-coverage}.b) shows that a single vulnerability is being targeted, in average, by 5.1tools, with the first quartile  being between 2 and 6 tools.

Figure \ref{fig:toolVscategories} shows the focus of the different classes of tools per each of the top categories in our taxonomy.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.65]{img/figure10.pdf}
    \caption{Announced detection capabilities for each of the taxonomy top categories.}
    \label{fig:toolVscategories}
\end{figure}

Figure \ref{fig:toolVscategories} shows that the category in which there is a larger focus from vulnerability detection approaches is "1. Unsafe External Calls", which is dominated by software testing approaches. Another aspect to mention is that, although "4. Bad Programming Practices \& Language Weaknesses" is the category that groups the largest set of vulnerabilities (i.e., 36 vulnerabilities), proportionally it is far from gathering the same attention as other categories (e.g., "6. Arithmetic Issues" is being targeted by 27 tools, although it groups only 6 types of vulnerabilities). The last aspect that is worthwhile mentioning is that software testing tends to be the most frequent technique across all categories of vulnerabilities, with the exception of "7. Improper Access Control", where static analysis has the lead. Indeed several vulnerabilities in this group easily fit the detection capabilities of static analysis techniques (e.g, cryptography misuse vulnerabilities). The top 5 vulnerabilities (in terms of presence in the different papers) are  "1.1.1 Unsafe Credit Changes" (36), "5.1.1 Incorrect Use of Event Blockchain Variables for Time" (28), "6.1.1 Integer Underflow" (21), "6.1.2 Integer Overflow" (21), "4.7.1 Unreachable Payable Function" (18). Detailed information and further data (e.g., code examples) can be quickly viewed at the OpenSCV website \cite{openscvSite}.

\subsection{Main contributors to the overall quality of the taxonomy}

We now summarize the main aspects which we believe are the main contributors to the general quality of the taxonomy, which we are making publicly available at \url{http://openscv.dei.uc.pt} \cite{openscvSite}. In terms of organization, we opted for a \textit{hierarchical structure}, as it may be useful from a defect prevention perspective. From a language designer's perspective, understanding that there is a certain group of defects that are related to, for instance, gas depletion may be helpful for designing effective protection mechanisms against those defects. Such mechanisms may share common strategies. 

A taxonomic structure of this kind allows setting \textit{homogeneous levels of abstraction} in an easier manner, which we iteratively tried to achieve, although this kind of goal is quite difficult as it should  be balanced with the number of items and overall tree complexity (and in some cases, due to the specificity of the problem, this may not even be possible). We tried to, as much as possible, \textit{reuse existing terminology} although many times we converged to the use of new terms (adapted from the literature), for clarity purposes. The required nomemclature adaptations integrated into our taxonomy were carried out mostly with the goal of making the items \textit{non-ambiguous} (and \textit{uniquely identifiable} also) and also fostering the \textit{determinism of the classification} process by clarifying the meaning of each vulnerability. We complemented this with the available information from DASP, SWC, \cite{Rameder2022}, and CWE, targeting to make the taxonomy further \textit{comprehensible} and \textit{non-ambiguous} (multiple perspectives will dissipate standing doubts, fostering \textit{repeatability}).

The taxonomy construction process involved the analysis of a relatively large number of papers, tools, and other classifications, with the main goal of fostering \textit{completeness} (i.e., good coverage), which in the end makes it also more \textit{useful} as we end up forming a unified view of the landscape of smart contract vulnerabilities. As previously mentioned, we found that the number of papers and respective vulnerabilities analyzed (i.e., an initial set of 357 vulnerabilities collected from 49 papers) was actually a main contributor to the overall quality of the taxonomy, with a few late additions becoming trivial to map. It is worthwhile mentioning that the created structure is non-ridig in the sense that we make it \textit{open to the community} and, in particular, open to community contributions, which can be carried out by submitting issue requests at the OpenSCV Github repository \cite{openscvGithub}.

