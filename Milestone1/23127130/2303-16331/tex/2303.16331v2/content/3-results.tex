\section{Results}

We focus on Ethereum data analysis under PoW in this section. Analysis of Celo data is included in the appendix as a first look at a PoS system. There is not yet enough historical data to analyze Ethereum PoS but would be a next step.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Feature Analysis}

We find that a large amount of off-chain pricing information is contained in on-chain data and that the various features are connected in some strong but complicated ways.

Figure~\ref{fig:graphical-model} and Appendix Figure~\ref{fig:partial-corr} show the results of sparse inverse covariance modeling for a selection of the feature set. 
The graphical structure depicted is the consistent structure over time as smoothed over the outputs of many $k$-fold subsets. The partial correlation matrix shows the graphical structure in matrix form.
The features that are most directly connected with ETH/USD price, as measured by partial correlations in the graphical model, include number of active to and from addresses sending transactions, block difficulty, and number of transactions per block.
Several of these variables appear to contain information relevant to price as well, as measured by mutual information in the next analysis. The graphical model suggests that these are indirect relationships, though it is worth noting that the process is unlikely Gaussian, and so the partial correlations do not necessarily translate to conditional dependencies.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{figures/graphical_model.png}
	\caption{Graphical network visualization. Variables defined in Table~\ref{table:feature-defs}.}
	\label{fig:graphical-model}
\end{figure}






Figure~\ref{fig:mutual-info} shows the mutual information between ETH/USD prices and other features, meaning the amount of information (reduction of uncertainty) obtained about price by observing each other variable individually. We find that across the top 10 features, a large amount of information about off-chain price is contained in on-chain data. We also find that the mutual information decreases with $\alpha$, the exponential moving average memory factor for smoothing, indicating that the smoothed data is generally less informative than the most up-to-date data.


\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{figures/mutual-info-better}
	\caption{Mutual information of price data and feature variables, with memory parameter (or smoothing factor) $\alpha$ applied to the feature variables (see \ref{sec:feature-analysis}). Variables defined in Table~\ref{table:feature-defs}.}
	\label{fig:mutual-info}
\end{figure}


We also analyze the full feature set, including the transformed economic factors and Uniswap pool liquidity factors. Perhaps unsurprisingly, since the transformed features contain the same underlying information, they do not exhibit stronger relationships than the raw features. More surprising is that the Uniswap pool factors also did not present strong relationships with price. We then arrived at the above version of the analysis excluding Uniswap factors enabling us to use the entire data history (as Uniswap was launched later than the start of the dataset).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Recovering Off-chain Prices from On-chain Data}

Random forest and gradient boost both outperformed the other two simpler ML algorithms. We selected Random Forest as the candidate model in the end as it is in principle simpler to be implemented on-chain compared to the gradient boost model (theoretically, a random forest model could be implemented as one big mapping table in a smart contract).

We tested the model performance over different lengths of period - the length of time duration between time t and time t+c. As would be expected with nonstationary time series, we observed that the longer the time duration that a single trained model is used for price estimation, the less accurate is price estimation. The degree to which time between retrainings affects accuracy is informative, however.

Figure~\ref{fig:pred-retrainings} shows the random forest model performances, Estimated vs Actual ETH/USD price, for 1-day ahead, 1-week ahead and 1-month ahead of retrainings. While none of the models provide high accuracy of recovering ETH prices, they do demonstrate that a good signal of the general price level can be recovered, particularly in the 1-day and somewhat in the 1-week retraining cases.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{figures/pred-retrainings-better}
	\caption{Recovered price vs actual for random forest with given retraining periods.}
	\label{fig:pred-retrainings}
\end{figure}

The deviation between estimated price and actual price is bigger for higher ETH prices. This is a combination of both having less data in the dataset for these prices and the fact that the same relative error scales with the absolute price, and so deviations measured absolutely are expected to be greater.


We run the models on the full feature set, including transformed economic factors and Uniswap pool factors. The economic factors provide little new information vs the raw features, perhaps a consequence of the flexibility of the tree models. Uniswap pool factors similarly do not improve accuracy. The final analysis excludes Uniswap factors enabling the entire data history to be used.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Performance of Price Recovery}\label{sec:performance}

To measure performance of the price recovery models, we compare against a simple martingale benchmark. This benchmark supposes that the last observed price in the last retraining period is the best estimate of the next price in expectation, barring any new information, which would follow in an efficient market. By comparing against this benchmark, we evaluate how well the on-chain feature variables, the only source of new information to the model, recover price vs the best guess without this information.

We evaluate the squared error between a prediction (either the model or benchmark price) at time $t$ and the actual price as
$$SE = (\text{predicted}/\text{actual} -1)^2.$$
We then consider the mean squared error (MSE) over different times $t$. The square root of the MSE (RMSE) then gives a measure of error that can be interpreted as a percentage of the price level.

We compare model errors with benchmark errors using these measures. We first consider the difference in squared errors between the model and the benchmark as
$$DSE = (\text{benchmark}/\text{actual}-1)^2 - (\text{model}/\text{actual}-1)^2.$$
This quantity will be positive when the model performs better than the benchmark and negative otherwise.
Table~\ref{table:DSEs} summarizes how frequently the models have lower squared error than the benchmarks and by how much the squared error is reduced (as a percentage of price level) when this happens. Note that most of the time, the models perform worse than the benchmarks over the dataset. However, they may be able to provide useful information in addition to the benchmarks in some settings.

\begin{table}
	\centering
	\begin{tabular}{c | c  c  c}
		\textbf{Model retraining periods:} & \textbf{1-day} & \textbf{7-day} & \textbf{30-day} \\
		\hline
		How often model beats benchmark & 12.4\% & 26.9\% & 32.4\% \\
            Gain over benchmark when model is better & 0.65\% & 3.56\% & 7.10\% \\
		\hline
	\end{tabular}
	\caption{Summary of DSEs between models and benchmarks for different retraining periods evaluated on the whole dataset (2016-2022). Row 1 is the frequency that $DSE > 0$. Row 2 is the root mean DSE at the times that $DSE > 0$.}
	\label{table:DSEs}
\end{table}

In line with Table~\ref{table:DSEs}, the MSE of the models is greater than the MSE of the benchmarks when taken over the entire dataset. A limitation with this measure is that, for data points early in the dataset, there is relatively less training data for the rolling models. We might expect the models to do better toward the end of the dataset where there is more training data to work with.

In Table~\ref{table:RMSEs}, we calculate RMSEs restricted to the last year of the dataset, when the models can theoretically be best. In addition to RMSE over this time period, we also compute RMSE during the top 10\% most volatile days, as measured by rolling 24 hour volatility calculated on hourly returns.

Table~\ref{table:RMSEs} shows some limited situations where a model makes improvements over the benchmark as measured in less RMSE compared to the benchmark. This happens for the 30-day retraining model, which also tends to perform better for the most volatile days. In general, the model error is usually larger than the benchmark error, however, and the outperformance of the 30-day model is somewhat sensitive to the restriction to the final year, which is further explored in Appendix~\ref{appendix:performance}.

\begin{table}
	\centering
	\begin{tabular}{c | c  c  c}
		\textbf{Model retraining periods:} & \textbf{1-day} & \textbf{7-day} & \textbf{30-day} \\
		\hline
		Model RMSE & 7.82\% & 18.83\% & 18.98\% \\
            Benchmark RMSE & 3.77\% & 9.39\% & 19.80\% \\
            \hline
            Model (top 10\% vol) RMSE & 15.41\% & 23.15\% & 29.84\% \\
            Benchmark (top 10\% vol) RMSE & 7.5\% & 12.13\% & 36.61\% \\
		\hline
	\end{tabular}
	\caption{RMSEs of the models compared to benchmarks over the last year of the dataset (May 2021 - May 2022).}
	\label{table:RMSEs}
\end{table}

While the current models hint that on-chain information could be useful in reducing error, in practice they are not precise enough. In particular, an application could get most of the utility of the current models by checking that oracle prices don't change too quickly (i.e., implement a check of current oracle prices against the benchmark estimate of a previously observed price). Note that the last observed price in the last retraining period is not an input variable to the price recovery model other than as part of training. A next step in improving model performance could be to incorporate this last training price or to train the model to predict how current price deviates from the last training price. More refined methods could find ways of extracting better information from the on-chain data.





