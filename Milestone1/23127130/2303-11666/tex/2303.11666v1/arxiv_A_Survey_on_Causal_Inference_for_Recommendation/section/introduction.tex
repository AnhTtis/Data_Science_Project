\section{Introduction}
\label{sec:intro}
% Introduction
% 因果推断最近成为新的研究热点，已经有许多领域上的应用。因果推断的含义和主要作用（常用于评估效果）。
%  推荐系统是其中一个重要的应用场景，虽然在评估效果的uplift modeling上已经广泛使用了，但是在模型训练上的使用是最近才兴起的。推荐场景可以抽象成因果问题，使用因果推荐系统的好处（分点）
% 优点1：model cause and effect -> debias, controllable (control variables)
% 优点2：answer counterfactual problems -> policy evaluation, data augmentation, OOD generalization (find invariable/unchangable invariables or relationship, reuse across different distributions)
%  本文对因果推荐系统的工作做一个全面的总结，首先介绍recommendation的基础知识和causal inference 的基础知识（定义符号，两种体系），而后提供两种分类角度RS Training Scenario（尽可能全面但是与causal相关）；Causal Technique （POF和SCM两种框架下的方法以及一些对因果的概念应用）
%  每个分类下有表格，参考GNN（Causal Methods, Model, Key Role of Causal Inference, Venue, Year）
%paper collection
Recommender systems (RS), working as filtering systems to present personalized information to users and alleviate information overload, have been widely deployed in various online applications, including e-commerce, social networks, and multimedia services. Recently, an emerging research direction has attracted increasing attention from RS researchers, which explores the synergies of advanced machine learning with a traditional statistics field, causal inference. Causal inference~\cite{gelman2011causality, imbens2015causal} works to analyze the relationship between a cause and its effect~\cite{pearl2009causality}, which has a wide range of real-world applications in both academic and industrial domains, such as medicine~\cite{kessler2019machine, shalit2020can}, political science~\cite{schlotter2011econometric}, and online advertising evaluation~\cite{li2016matching, fong2018covariate}. Treatment effect estimation is a fundamental problem in causal inference, often applied in policy evaluation. For example, in pharmaceutical research, where we are interested in the effect of a drug on lifespan, we need to answer a causal question involving a so-called intervention or treatment: What is the probability that a typical patient would survive in $L$ years if made to take the drug? A large-scale randomized controlled trial is the golden solution but it may suffer from the expense and even ethical issues. Therefore, in most cases, we can only estimate the effect from non-randomized observational data, where the correlation between the drug and survival does not imply causation, because factors including age, gender, and severity of the disease may affect the outcomes. 
%Although problems like this which consider treatment effect estimation has been intensively studied in statistics for decades, most of traditional causal methods are limited to small-scale data.

Causality for recommendation has been widely used in uplift modeling for policy effect evaluation~\cite{radcliffe2007using, gutierrez2017causal}, but it was not until the last few years that research has tended to focus on applying it to model training. Common recommendation scenarios in practice, including click-through rate (CTR) prediction and post-click metric prediction, etc., can be abstracted into causal problems, and causal inference can be applied in different stages of the entire RS project, such as preliminary data collection~\cite{ wang2021counterfactual}, representations learning of users and items embeddings~\cite{ liu2021mitigating, he2022causpref, wang2022causal}, objective optimization~\cite{ mehrotra2018towards, mcinerney2020counterfactual, bonner2018causal}, and policy evaluation offline and online~\cite{ sato2019uplift, saito2021counterfactual, sato2021online}. The ability of causal recommender systems to outperform traditional approaches due to the following two strengths (Fig. \ref{fig:strength}):

\begin{figure}[t!]
\centering
\vspace{-1mm}
\includegraphics[height=0.28\textheight,trim=100 0 100 0 ,clip]{pic/strength.pdf} %l b r t
\vspace{-1mm}
\caption{Strengths of causal inference for recommendation.}
\vspace{-6mm}
\label{fig:strength}
\end{figure}

1) \textbf{Model cause and effect.} Current machine learning systems, including RS, operate almost exclusively in a statistical mode~\cite{pearl2018theoretical}, which focuses on the correlation between variables. However, in applications, we care more about causality rather than correlation, and it is well known that “Correlation is not causation”. For example, a movie recommendation platform recorded a female user who has finished watching an action movie, so it concludes that she likes action movies and makes many recommendations for related action movies. Nevertheless, the user may have watched the movie due to its popularity rather than her inherent preference for action movies in fact. Therefore, the spurious correlation between user interest and movie genres learned by traditional recommender systems may lead to a degraded user experience. In contrast, causal recommendation systems can learn the causal effects of users' individual interest as well as conformity on the interaction outcome (i.e., watching), respectively, so that action movies will not be incorrectly recommended later. Modeling cause and effect enables causality-based recommender systems to 1) measure the causal effects on user interaction of source variables of a wide range of bias, such as popularity~\cite{zhang2021causal, wei2021model} and exposure~\cite{liang2016modeling, wang2021clicks}, thus performing effective debiasing, which is currently the most common application of causal inference for recommendation; 2) better control of RS due to decomposition and inference of the causal effect of variables, for example, leveraging the causal effect of certain bias to improve recommendation accuracy~\cite{zhang2021causal}.
% ; 3) adapt fast to a transfer distribution without prior access to test data. 
% Analysis of causal relationships helps separate stable pieces of knowledge from unstable ones. Then
% With a correct causal mechanism, a model that is well-trained on the training distribution only needs to change very few mechanisms and parameters and remains robust when transferred to a new but related distribution~\cite{bengio2019meta}, which is natural in industrial recommendation due to new users, new items or new trends.
% 这里的transfer distribution是指在test阶段与训练阶段的数据分布不同，不需要人为地完成transfer，而是依赖模型自身的鲁棒性来完成自适应的过程。（Don’t access to test distributions）

2) \textbf{Answer counterfactual questions.} Many recommender system problems, including data augmentation, out-of-distribution (OOD) generalization, and policy evaluation, are essentially counterfactual problems, that is, the situation where the values of some causal variables are different from reality. In terms of the data augment problem, as a significant complementary resource of the observed data~\cite{ wang2021counterfactual}, the counterfactual data needs to answer questions such as "What would be the user’s interaction if the recommended items had been different?" or "What would be the probability of click if an item had been recommended to a user who has not been recommended before?”. The OOD problem refers to the recommendation which violates the Independent and Identically Distributed (IID) assumption of the interactions between training and testing periods~\cite{he2022causpref}. Traditional recommendation may learn false associations between users and items, while causal recommender systems adopt the counterfactual means to find invariant or unchangeable variables or causal relationships in the recommendation task and reuse them to generalize when the distribution changes. For example, if a pregnant female user had purchased red high heels before pregnancy, a traditional recommendation system might continue to make recommendations of high heels, but a causal inference system can learn the causal relationship between high heels and pregnancy status through causal tools like causal graph. Therefore, when the user's status shifts (identified from the user's behavior like purchasing baby products), the causal recommender system no longer recommends high-heeled shoes but retains the user's preference for the red color and recommends red clothing instead. Uplift modeling estimates the increase, or uplift, in user interactions caused by recommendations, which is a counterfactual problem because one needs to estimate the difference between two mutually exclusive outcomes for an item (either item $i$ is recommender or not for a specific user). In addition to the above issues, counterfactuals can also optimize beyond-accuracy objectives such as fairness and explainability. For example, to ensure fairness, sensitive features like sex and race can be modified and removed in the counterfactual world~\cite{li2021towards}, and explainability can be attained by comparing the real world with the counterfactual world to search for user interactions that affect recommendation results\cite{ ghazimatin2020prince, tan2021counterfactual}.



It is worth mentioning that there are some existing surveys~\cite {wu2022opportunity, gao2022causal,zhu2023causal} of causal inference for recommender systems. However, they are limited due to the following reasons. First, they do not provide a comprehensive taxonomy of causal recommender systems. Specifically, ~\cite{wu2022opportunity} only discusses recommendation methods of potential outcome framework~\cite{rubin1974estimating}, and approaches investigated in ~\cite{gao2022causal,zhu2023causal} are mainly classified from the application perspectives, i.e., issues of recommender systems, but our work provides a taxonomy of the existing methods of both two causal frameworks, involving the Neyman-Rubin potential outcome (PO) framework ~\cite{ splawa1990application, rubin1974estimating} and the Pearl structural causal model (SCM) framework~\cite{pearl1995causal, pearl1988probabilistic, pearl2009causality}, from the perspective of causal inference theory systematically, more helpful for readers to apply causal methods to recommender systems in follow-up studies. Second, since this area is increasingly popular, our survey also introduces a lot of recently published papers not covered by~\cite{wu2022opportunity, gao2022causal,zhu2023causal}. We collect the papers related to causal inference-based recommender alpgorithms on renowned conference proceedings and journals and visualize the statistics of them concerning the published year and causal inference framework in Fig. \ref{fig:statistics}.


This paper provides a comprehensive summary of the work on causal recommender systems. The rest of this survey is organized into six sections. Section \ref{sec:related} introduces the Related Work, which clarifies the difference between causal inference for recommendation and other related causal techniques. Section \ref{sec:foundation} introduces the basic concepts within recommendation and causal inference of both frameworks and the notations used in this survey. Sections \ref{sec:po_based}, \ref{sec:scm_based}, and \ref{sec:general_counterfactual} interpret causal recommendation approaches from the perspective of causal techniques: PO-based, SCM-based, and general counterfactuals-based, respectively. Future research directions are openly discussed in Section \ref{sec:discuss}. The last section concludes this survey. The main contributions of this survey are summarized below.

\begin{itemize}
    \item Novel taxonomy: We separate various causal recommendation methods into three major categories based on the causal framework they adopt, which may be more instructive than existing taxonomies for the readers to integrate causal inference with recommender systems and propose new approaches in practice (see Section \ref{sec:exist_cate}).

    \item Comprehensive review: Over one hundred and twenty causal recommendation papers from the last century to 2023 are introduced, explained, and summarized, which might give readers a comprehensive overview of causality for recommendation.

    \item Open discussion: Research directions for applying causality to improve recommendation methods in the academic and industrial areas are openly discussed. 
\end{itemize}

% 补一个figure
\begin{figure}[t!]
\centering
\vspace{-3mm}
\includegraphics[height=0.22\textheight,trim=0 0 145 -10 ,clip]{pic/paper_year_cate.pdf} %l b r t
\vspace{-2mm}
\caption{Statistics of the publications related to causal recommendations, grouped by the publication year and causal inference framework. Only work concerning specific industrial algorithms is used in visualization, which means many articles discussing fundamental theories are not involved.}
\vspace{-5mm}
\label{fig:statistics}
\end{figure}