
\section{Experiments and Results}

In this section, we present and evaluate the experimental results for
the proposed models. 
%
% \subsection{Evaluation Metrics}
\subsection{Object localization}
 {\it Intersection over Union} (IoU) is used to evaluate the object
 localization networks.
% To use this metric, the ground-truth bounding boxes and the
% predicted bounding boxes are needed.  IoU is defined as the area of
% overlap divided by the area of union between the ground-truth and
% predicted coordinates.
IoU measures how closely two sets of elements overlap, and it is
defined as the ratio of the overlap area to the combined area of
prediction and ground-truth.
% The higher the IoU of two
% boxes the more similar they are said to be with an IoU of 1.0 being
% a perfect overlap of the two bounding boxes.
% 

Three network models are compared in this experiment. The first is the
{\it pure ANN} (LocNet) model, which is built and trained with
standard CNN components. The second is the SNN directly converted from
the ANN ({\it converted SNN}).  The third one is our {\it hybrid SNN},
which is fine-tuned upon the converted SNN with our hybrid training
approach. The three models use the same hyperparameters. For SNN
models, the soft LIF rate neurons are switched to spiking LIF neurons
during testing. {\it Firing rate regularization} is used to identify
optimal firing rate for the two SNN models.
%Additionally, the synaptic smoothing parameter was set to 0.005 and
%each testing sample was tiledfor 30 time steps. Each time step was
%set to 0.001 seconds.

%Table \ref{rcnn_table} shows the results of the three different
%training and testing procedures on the R-CNN network. The "Training"
%and "Testing" columns refer to the type of network that was used to
%carry out those tasks. When testing the network as an SNN, the same
%hyperparameters were used. The soft LIF rate neurons are swapped to
%spiking LIF neurons during testing. Additionally, the synaptic
%smoothing parameter was set to 0.005 and each testing sample was tiled
%for 30 time steps. Each time step was set to 0.001 seconds.


\begin{table}[h]
\centering
\begin{tabular}{ |c|c|c| } 
  \hline Model & Mean IoU & Avg. Firing Rate \\ \hline \hline {\it
  pure ANN} (LocNet) & 0.8945 & N/A \\ \hline {\it converted SNN} & 0.7431 &
  174.5583 Hz \\ \hline {\it hybrid SNN} & \textbf{0.8253}
  & \textbf{137.5238} Hz \\ \hline
\end{tabular}
\caption{Results from the three localization models.}
\label{rcnn_table}
\end{table}

%\begin{table}[h]
%\centering
%\begin{tabular}{ |c|c|c|c| } 
% \hline Training & Testing & Mean IoU & Mean Firing Rate \\ \hline ANN
% & ANN & 0.8945 & N/A \\ \hline ANN & SNN & 0.7278 & 371.1789 Hz
% \\ \hline Hybrid SNN & SNN & \textbf{0.7459} & \textbf{94.5391} Hz
% \\ \hline
%\end{tabular}
%\caption{Mean IoU and Mean Firing Rate (Hz) for Localization}
%\label{rcnn_table}
%\end{table}

Table \ref{rcnn_table} shows the results obtained from the three
models. The baseline ANN model achieves a mean IoU of 0.8945. When
converted to SNN, the network accuracy drops to 0.7278. Our hybrid
fine-tuning procedure is able to improve the performance, measured by
IoU, to 0.8253. In addition, our hybrid SNN obtains a slightly smaller
average firing rate than the converted version, which poses an
advantage from the energy consumption perspective.  We believe this is
partly due to the weighted regularization terms that are added to the
loss function for each layer in the network. The regularization urges
the network to implicitly learn the scaling factor to the weights
instead of applying a post-scaling in the inference stage for the
SNN. Learning an optimized scaling factor for each layer results in
optimizing the firing rates.
%This demonstrates
%that, if the firing rate can be properly regularized, our hybrid
%ANN-SNN model could pose an advantage from the energy consumption
%perspective.

%A possible explanation for the lower firing rates

%During the hyrbid co-training step, the output layer's loss increases
%due to the swapping of the soft LIF neurons and the hyrbid LIF
%neurons. Because of this increase in loss and the loss weights
%applied to each layer, the firing rates decrease due to the model
%attempting to correct the output's loss before focusing on
%regularizing the firing rates. This in turn causes them to steadily
%decrease from the 500 Hz regularization point as the output layer's
%loss decreases. In our case, it worked out well for the model because
%the mean IoU increased and the firing rates decreased for the hybrid
%SNN. However, if the original value of 500 Hz that was chosen
%happened to be too low it could be the case that the firing rates
%drop too substantially during the hybrid co-training phase and cause
%the SNN's overall accuracy to decrease.

%Using the mean IoU metric for evaluation, the baseline ANN model for
%the R-CNN obtained a mean IoU of 0.8945. The SNN model with
%regularization applied to the firing rates was able to achieve a mean
%IoU of 0.7278. Applying the hybrid training technique to the ANN gave
%a slight increase in the mean IoU for the test data with that value
%being 0.7459. This shows this model with LIF neurons and firing rate
%regularization was able to increase the mean IoU on the test data
% after applying the hybrid co-training procedure.


% An important result from Table \ref{rcnn_table} to understand would
% be the difference in the mean firing rates between the SNN and the
% hybrid SNN. During the hyrbid co-training step, the output layer's
% loss increases due to the swapping of the soft LIF neurons and the
% hyrbid LIF neurons. Because of this increase in loss and the loss
% weights applied to each layer, the firing rates decrease due to the model
% attempting to correct the output's loss before focusing on
% regularizing the firing rates. This in turn causes them to steadily
% decrease from the 500 Hz regularization point as the output layer's
% loss decreases. In our case, it worked out well for the model because
% the mean IoU increased and the firing rates decreased for the hybrid
% SNN. However, if the original value of 500 Hz that was chosen happened
% to be too low it could be the case that the firing rates drop too
% substantially during the hybrid co-training phase and cause the SNN's
% overall accuracy to decrease.

%An important result from Table \ref{rcnn_table} to understand would be
%the difference between the firing rates of the SNN model compared to
%those of the hybrid model. The reason there was a drop in firing rates
%was due to the loss weights of the model. Each layer in the model was
%assigned a regularization term, or "loss weight", on its loss
%function. This essentially determines how important that layer's loss
%is to the entire loss of the model. Since the output layer's loss of
%the model is the most important its loss weight was set to one. The
%other layers whose activity was regularized had a loss weight set to
%0.01. When switching to the hybrid model for training, swapping out
%the old activations for the new hybrid ones causes the output's loss
%to increase. Since it's loss weight is one, the model first tries to
%fix that loss before attempting to continue regularizing the firing
%rates of the other layers. Since the firing rate regularization layers
%aren't as important compared to the output layer's loss, the firing
%rates decrease as the output layer's loss decreases as well. In this
%case, it worked out well for our model. However, if the original 500
%Hz regularization term was too low it could be the case that the
%firing rates dropped too substantially during the hybrid training
%phase and cause the SNN's overall accuracy to decrease.



\subsection{Hippocampus segmentation}

%Dice coefficient from the BCE-Dice loss was used as the metric to
%evaluate the CAE model. This metric measures the similarity between two
%sets of data. In our case, it measures how similar the predicted mask
%of the hippocampus is to its ground-truth. Similar to the IoU metric,
%a higher Dice coefficient correlates to two images being more similar
%to each other.

Dice ratio is used as the performance metric to measure the overlap
between the automatic segmentation and the ground truth mask. The
results of the competing models are shown in
Table~\ref{cae_table}. Similar to the previous experiment, we have
{\it pure ANN}, {\it converted SNN}, and {\it hybrid SNN} as the
competing models.  All networks use the same set of
hyper-parameters. For the firing rates, we use the {\it post-training
scaling} approach and empirically set the same scaling factor of 1000
for all neurons. We chose not to use {\it firing rate regularization}
due to the difficulty of setting up appropriate contribution weights.
% is not used as the
% neuron activities are difficult to optimize over {\bf
% transpose/deconvolution convolution} layers.
%We did not use {\it firing rate
%  regularization}, as the loss weights for this network are
%non-trivial and setting them all equal does not work easily as in the
%R-CNN network. So we instead empirecally set the same scaling factor
% of 1000 for all neurons. 
%would have to manually go through and check
%different loss weights which would be very time consuming
%The Rectified Linear neurons are
%swapped for their spiking equivalent. The same scaling factor of 1000
%was applied to all neurons.
%A synapse of 0.005 seconds was added to all connections and each
%testing sample was presented for 50 time steps with a one time step
%being 0.01 seconds.


%The dice coefficient that was explained previously was used as a
% metric to evaluate this model.
The baseline {\it pure ANN} model was able to achieve a Dice
coefficient of 0.8221. The converted model, however, suffers from a
large performance loss, only achieving a Dice score of 0.4859. After
going through the hybrid fine-tuning process, the hybrid SNN model was
able to bring the Dice score back to 0.7648.
% This shows that with the
% addition of the hybrid training step, the model was much more
% accurately able to create a mask of the Hippocampus when compared to
% the model without the hybrid step.
This clearly demonstrates the effectiveness of the proposed hybrid
fine-tuning strategy.
% The fine-tuned SNN was able to match the
% ground-truth masks much better in generating more accurate
% segmentation masks for the Hippocampus slices.
% It should be noted that the results we obtained from the ANN model is
% worse than one of our previous work \cite{chen2017ensemble}. This is
% mostly due to the implemention constraints, as the current ANN models
% is implemented using the LIF neurons under NengoDL.


\begin{table}[h]
\centering
\begin{tabular}{ |c|c|c| } 
  \hline Model & Dice & Avg. Firing Rate \\ \hline \hline {\it
  pure ANN} (\textrm{CAE}) & 0.8221 & N/A \\ \hline {\it converted SNN} & 0.4859 &
  708.2347 Hz \\ \hline {\it hybrid SNN} & \textbf{0.7648} & 731.3800
  Hz \\ \hline
\end{tabular}
%\caption{Dice Coefficient and average Firing Rate (Hz) for Segmentation}
\caption{Results from the three segmentation models. }
\label{cae_table}
\end{table}

To visualize the effects of hybrid fine-tuning, we look into a number
of slices and compare the masks generated from the three
models. Fig.~\ref{fig:masks} shows a typical example, where (a) and
(b) are the input slice and the ground-truth
mask. Fig~\ref{fig:masks}.(c), (d) and (e) show the network outputs
(probabilistic masks) for ANN, converted SNN and hybrid SNN,
respectively. The mask from the ANN matches the ground-truth rather
well. The mask from converted SNN, however, contains many artifacts,
leading to a poor Dice score after thresholding. The hybrid
fine-tuning is able to correct the artifacts and significantly improve
the segmentation performance for the SNN model.

%The results for the S-CAE network are shown in Table
%\ref{cae_table}. Similar to the previous table, the "Training" and
%"Testing" columns determine what type of network was used during that
%section. The SNN networks of the Testing columns all use the same
%hyperparameters. The Rectified Linear neurons are swapped for their
%spiking equivalent. The same scaling factor of 1000 was applied to
%all neurons.  A synapse of 0.005 seconds was added to all connections
%and each testing sample was presented for 50 time steps with a one
%time step being 0.01 seconds.


%\begin{table}[h]
%\centering
%\begin{tabular}{ |c|c|c|c| } 
% \hline Training & Testing & Dice & Mean Firing Rate \\ \hline ANN &
% ANN & 0.8221 & N/A \\ \hline ANN & SNN & 0.4107 & 708.2347 Hz
% \\ \hline Hybrid SNN & SNN & \textbf{0.7416} & 722.7422 Hz \\ \hline
%\end{tabular}
%\caption{Dice Coefficient and Mean Firing Rate (Hz) for Segmentation}
%\label{cae_table}
%\end{table}

%The dice coefficient that was explained previously was used as a
%metric to evaluate this model.  The baseline ANN model was able to
%achieve a dice coefficient of 0.8221. The equivalent SNN model only
%attained a dice coefficient of 0.4107. After going through the hybrid
%training process, the SNN model was able to increase the dice ratio
%to 0.7416. This shows that with the addition of the hybrid training
%step, the model was much more accurately able to create a mask of the
%hippocampus when compared to the model without the hybrid step.

\begin{figure}
  
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \centerline{\includegraphics[width=3.5cm]{original_image}}
  \centerline{(a) Input slice}\medskip
\end{minipage}
%
\begin{minipage}[b]{0.48\linewidth}
\centering
  \centerline{\includegraphics[width=3.5cm]{ground_truth}}
  \centerline{(b)  Ground-truth}\medskip
\end{minipage}
%
\begin{minipage}[b]{.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.7cm]{ann_predicted}}
  \centerline{(c)  ANN}\medskip
\end{minipage}
\hfill
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.7cm]{snn_predicted}}
  \centerline{(d) Converted SNN}\medskip
\end{minipage}
%
\hfill
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.7cm]{hybrid_predicted}}
  \centerline{(e) Hybrid SNN}\medskip
\end{minipage}
%
\caption{An example of input slice and segmentation results. }
\label{fig:masks}
%
\end{figure}


%\algdef{SE}% flags used internally to indicate we're defining a new block statement
%[STRUCT]% new block type, not to be confused with loops or if-statements
%{Struct}% "\Struct{name}" will indicate the start of the struct declaration
%{EndStruct}% "\EndStruct" ends the block indent
%[1]% There is one argument, which is the name of the data structure
%{\textbf{class} \textsc{#1}}% typesetting of the start of a struct
%{\textbf{}}% typesetting the end of the struct

%\begin{algorithm}
%\caption{Hybrid neuron pseudocode}
%\begin{algorithmic}%[1] % uncomment for line numbers
%\Struct{HybridNeuron(\text{RateNeuron})}
%  	\State $spiking$ : True
%  	\vspace{0.3cm} \\
%  	
%    \hspace{0.5cm}\textit{\# calculate output, voltage using spiking activation} 
%  	\Function{step}{self, J, dt, voltage} \\
%  		\hspace{0.8cm} \Return $out, voltage$
%  	\EndFunction
%  	\vspace{0.3cm}\\
%  	
%	\hspace{0.5cm}\textit{\# returns the neuron output during the training step}
%  	\Function{training\_step}{self, J, dt, voltage}
%  		\State $forward, voltage$ : self.step(J, dt, voltage)
%  		\State $backward$ : RateNeuron.step(self, J, dt)\\
%  		\hspace{0.8cm} \Return $backward$ + tf.stop\_gradient$(forward - backward)$
%  	\EndFunction
%\EndStruct
%\end{algorithmic}
%\end{algorithm}

