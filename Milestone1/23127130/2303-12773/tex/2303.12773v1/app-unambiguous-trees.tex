\newcommand{\nodes}[1]{\mathsf{nodes}(#1)}
\newcommand{\edges}[1]{\mathsf{edges}(#1)}
\newcommand{\atomtotuple}[1]{\langle #1 \rangle}
\def\curnode{\mathsf{CurNode}}
\def\hedge{\mathsf{HEdge}}

\section{Unambiguous Proof Trees}\label{appsec:unambiguous-trees}
In this section, we provide proofs for all claims of Section~\ref{sec:unambiguous-trees}, and provide further details on our experimental evaluation.

\subsection{Proof of Theorem~\ref{the:complexity-unambiguous-proof-trees}}
We start by proving Theorem~\ref{the:complexity-unambiguous-proof-trees}, which we recall here for convenience:

\begin{manualtheorem}{\ref{the:complexity-unambiguous-proof-trees}}
	\theunambiguouscomplexity
\end{manualtheorem}
We prove item~(1) and item~(2) of Theorem~\ref{the:complexity-unambiguous-proof-trees} separately. We start by focusing on item~(1).


\medskip
\noindent
\underline{\textbf{Proof of Item~(1)}}
\smallskip

\noindent Our main task is to show that $\mathsf{Why\text {-}Provenance_{UN}[\DAT]}$ is in \NP. The \NP-hardness of $\mathsf{Why\text {-}Provenance_{UN}[\LDAT]}$ follows from the $\NP$-hardness of $\mathsf{Why\text {-}Provenance_{NR}[\LDAT]}$, which we have already shown in Section~\ref{appsec:refined-trees}. The latter follows from the observation that, in the case of linear Datalog programs, non-recursive proof trees and unambiguous proof trees coincide.
%
We now show the \NP~upper bound. 

This result relies on a characterization of the existence of an unambiguous proof tree of a fact $\alpha$ w.r.t.~a database $D$ and a Datalog program $\dep$ with $\support{T} = D' \subseteq D$ via the existence of a so-called {\em unambiguous proof DAG} $G$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{G} = D'$ of polynomial size. This in turn allows us to devise a guess-and-check algorithm that runs in polynomial time We proceed to formalize the above  high-level description.


For a rooted DAG $G=(V,E,\lambda)$ and a node $v \in V$, we use $G[v]$ to denote the subDAG of $G$ rooted at $v$. Moreover, two rooted DAGs $G=(V,E,\lambda)$ and $G'=(V',E',\lambda')$ are \emph{isomorphic}, denoted $G \eqtree G'$, if there is a bijection $h : V \ra V'$ such that , for each node $v \in V$, $\lambda(v) = \lambda(h(v))$, and for each two nodes $u,v \in V$,  $(u,v) \in E$ iff $(h(u),h(v)) \in E'$. With the above definitions  in place, we can now introduce the key notion of unambiguous proof DAG.

\begin{definition}[\textbf{Unambiguous Proof DAG}]\label{def:u-proof-dag}
	Consider a Datalog program $\dep$, a database $D$ over $\esch{\dep}$, and a fact $\alpha$ over $\sch{\dep}$. An \emph{unambiguous proof DAG of $\alpha$ w.r.t.\ $D$ and $\dep$} is a proof DAG $G=(V,E,\lambda)$ of $\alpha$ w.r.t.\ $D$ and $\dep$ such that, for all $v,u \in V$, $\lambda(u)=\lambda(v)$ implies $G[u] \eqtree G[v]$.\hfill\markfull
\end{definition}

We are now ready to present our characterization.

\begin{proposition}\label{pro:characterization-u-trees}
	For a Datalog program $\dep$, there is a polynomial $f$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and $D' \subseteq D$, the following are equivalent:
	\begin{enumerate}
		\item There exists an unambiguous proof tree $T$ of $\alpha$ w.r.t.\ $D$ and $\dep$ such that $\support{T} = D'$.
		\item There is an unambiguous proof DAG $G=(V,E,\lambda)$ of $\alpha$ w.r.t.\ $D$ and $\dep$ with $\support{G}=D'$ and $|V| \le f(|D|)$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	We first prove (1) implies (2). Let $T$ be an unambiguous proof tree of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$. 
	%We first observe that the depth of $T$ is polynomial in $|D|$. This holds since no two nodes on a path have the same label $\alpha$ (otherwise, their subtrees belong to two different equivalence classes of $\quot{T[\alpha]}$); hence, the length of a path in $T$ is bounded by the number of labels, that is, by $|\base{D,\dep}|$. 
	By definition, the subtree count of $T$ is ``small''; in fact, for every label $\alpha$ of $T$, $|\quot{T[\alpha]}|=1$. We then employ the construction underlying Lemma~\ref{lem:from-trees-to-dags}, which converts a proof tree of ``small'' subtree count into proof DAG of polynomial size with the same support, since it {\em preserves unambiguity}.
	
	For (2) implies (1), we employ the ``unravelling'' construction used to prove that (2) implies (1) in Proposition~\ref{pro:characterization-all-trees} since it also {\em preserves unambiguity}. 
	%In fact, consider an unambiguous proof DAG $G=(V,E,\lambda)$ of $\alpha$ w.r.t.\ $D$ and $\dep$, such that $\support{G}=D'$. The proof tree $T' =(V',E',\lambda')$ of $\alpha$ w.r.t.\ $D$ and $\dep$, with $\support{T'}=D'$, obtained as the result of unravelling $G$ is such that, for every edge $(u',v') \in E'$, there is an edge $(u,v) \in E$ with $\lambda'(u')=\lambda(u)$ and $\lambda'(v')=\lambda(v)$, and for every edge $(u,v) \in E$, there is an edge $(u',v') \in E'$ such that $\lambda(u) = \lambda'(u')$ and $\lambda(v)=\lambda'(v')$. Hence, if $G$ is unambiguous, $T'$ must necessarily be unambiguous as well.
	%As in the case of arbitrary trees, the fact that (1) implies (2) follows from the combination of these two results (see the proof of Lemma~\ref{lem:from-trees-to-dags}). Indeed, it is easy to verify that the procedure for converting a proof tree into a proof DAG shown in the proof of Lemma~\ref{lem:from-trees-to-dags} preserves unambiguity.
	%This holds since for every $\alpha$, there is a single equivalence class $C$ in $\quot{T[\alpha]}$; hence, by the construction of the DAG, there is a single node $v_C^\alpha$ in the DAG labeled with $\alpha$. Moreover, if for every label $\alpha$, there is a single node in the DAG labeled with $\alpha$, then there is a single subDAG with a root labeled with $\alpha$, and all the subtrees that we obtain from it (and will appear under the nodes labeled with $\alpha$ in the proof tree) will have the same structure and same label (hence, will belong to the same equivalence class).
	%\textcolor{red}{Proof strategy: Here it is actually just the one used all over again in Theorems~\ref{thm:characterization-all-trees},\ref{thm:characterization-nr-trees}, we do not need any additional lemma, since unambiguous proof trees are already of the shape we need.}
\end{proof}


\noindent
\textbf{Finalize the Proof.}
With Proposition~\ref{pro:characterization-u-trees} in place, proving item~(1) of Theorem~\ref{the:complexity-unambiguous-proof-trees} is straightforward. Indeed, we can employ a guess-and-check algorithm similar in spirit to the one employed to prove the $\NP$ upper bound of Theorem~\ref{the:recursive-complexity}. The key difference is that here we also need to verify that the guessed DAG $G$ is unambiguous. This can be easily done by guessing, together with the graph $G$, for every pair $u,v$ of nodes of $G$ with the same label, a bijection $h_{(u,v)}$ from the nodes of $G[u]$ to the nodes of $G[v]$. The number of nodes of $G$ is polynomial w.r.t.\ $|D|$, by Proposition~\ref{pro:characterization-u-trees}, and thus the number of bijections to guess is polynomial w.r.t.\ $|D|$. With the above bijections in place, it is enough to verify that each bijection $h_{(u,v)}$ witnesses that $G[u] \eqtree G[v]$. The latter check can be easily performed in polynomial time.

\medskip
\noindent
\underline{\textbf{Proof of Item~(2)}}
\smallskip

\noindent 
This is shown via first-order rewritability as done for Theorem~\ref{the:non-recursive-complexity}. In fact, the construction of the target FO query is exactly the same as in the proof of Theorem~\ref{the:non-recursive-complexity} with the key difference that, for a Datalog query $Q$, the set of CQs $\cq{Q}$ is defined by considering only unambiguous proof trees, i.e., is the set $\{\cq{T} \mid T \text{ is a {\em unambiguous} $Q$-tree}\}$.

%To prove this item, it is enough to observe that the the same machinery we employed for arbitrary trees can be applied to unambiguous proof trees. The key difference is in the family of trees we consider while collecting the CQs in the set $\cq{Q}$, for a Datalog query $Q$. That is, we define $\cq{Q}$ as the set $\{\cq{T} \mid T \text{ is an unmabiguous } Q\text{-tree}\}$. With the above definition in place, the same arguments used to prove Theorem~\ref{the:non-recursive-complexity} apply.

\subsection{Proof of Proposition~\ref{pro:why-provenance-sat}}
The goal is to prove Propostion~\ref{pro:why-provenance-sat}. But first we need to introduce some auxiliary notions and results, which will then allow us to formally define the Boolean formula $\phi_{(\bar t,D,Q)}$. We will then proceed with the proof of Propostion~\ref{pro:why-provenance-sat}




\medskip
\noindent
\textbf{A More Refined Characterization.} The Boolean formula in question relines on a more refined characterization than the one provided by Proposition~\ref{pro:characterization-u-trees}. For this, we need to define a new kind of graph that witnesses the existence of an unambiguous proof tree.

\begin{definition}[\textbf{Compressed DAG}]\label{def:compressed-dag}
Consider a Datalog program $\dep$, a database $D$ over $\esch{\dep}$, and a fact $\alpha$ over $\sch{\dep}$. A \emph{compressed DAG} of $\alpha$ w.r.t.\ $D$ and $\dep$ is a rooted DAG $G=(V,E)$, with $V \subseteq \base{D,\dep}$, such that:
\begin{enumerate}
	\item The root of $G$ is $\alpha$.
	\item If $\beta \in V$ is a leaf node, then $\beta \in D$.
	\item If $\beta \in V$ has $n \geq 1$ outgoing edges $(\beta,\gamma_1),\ldots,(\beta,\gamma_n)$, then there is a rule $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_m(\bar x_m) \in \dep$ and a function $h : \bigcup_{i \in [m]} \bar x_i \ra \ins{C}$ such that $\beta = R_0(h(\bar x_0))$, and $\{\gamma_i\}_{i \in [n]} = \{R_i(h(\bar x_i)) \mid i \in [m]\}$. \hfill\markfull
\end{enumerate}
\end{definition}

A compressed DAG can be seen as a proof DAG-like structure where no more than one node is labeled with the same fact.
The above definition allows us to refine the characterization given in Proposition~\ref{pro:characterization-u-trees} as follows; for a non-labeled DAG $G=(V,E)$, with a slight abuse of notation, we denote $\support{G} = \{v \in V \mid v \text{ is a leaf of } G\}$.

%\begin{lemma}\label{lem:from-udags-to-cdags}
%	For a Datalog program $\dep$, there is a polynomial $f$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and $D' \subseteq D$, the following are equivalent:
%	\begin{enumerate}
%		\item There exists an unambiguous proof DAG $G$ of $\alpha$ w.r.t.\ $D$ and $\dep$ such that $\support{G} = D'$.
%		\item There exists a compressed DAG $G'$ of $\alpha$ w.r.t.\ $D$ and $\dep$, such that $\support{G'}=D'$.
%	\end{enumerate}
%\end{lemma}



\begin{proposition}\label{pro:characterization-u-trees-improved}
	For a Datalog program $\dep$, database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and database $D' \subseteq D$, the following are equivalent:
	\begin{enumerate}
		\item There exists an unambiguous proof tree $T$ of $\alpha$ w.r.t.\ $D$ and $\dep$ such that $\support{T} = D'$.
		\item There exists a compressed DAG $G$ of $\alpha$ w.r.t.\ $D$ and $\dep$, such that $\support{G}=D'$.
	\end{enumerate}
\end{proposition}

\begin{proof}
	We first prove that (1) implies (2). Due to Proposition~\ref{pro:characterization-u-trees}, it suffices to show that if there exists an unambiguous proof DAG $G' = (V',E',\lambda')$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{G'}=D'$, then there exists a compressed DAG $G=(V,E)$ of $\alpha$ w.r.t.\ $D$ and $\dep$ with $\support{G}=D'$.
	%
	Assume that $G'=(V',E',\lambda')$ is an unambiguous proof DAG of $\alpha$ w.r.t.\ $D$ and $\dep$ such that $\support{G'}=D'$. Since $G'$ is unambiguous, for every two non-leaf nodes $u,v \in V'$ with $\beta = \lambda'(u)=\lambda'(v)$, we must have that $S= \{\lambda'(u_1),\ldots,\lambda'(u_n)\} = \{\lambda'(v_1),\ldots,\lambda'(v_m)\}$, where $u_1,\ldots,u_n$ and $v_1,\ldots,v_m$ are the children of $u$ and $v$ in $G'$, respectively. So, for each fact $\beta$ labeling a non-leaf node in $G'$, let us call the above (unique) set $S$ the \emph{justification of $\beta$ in $G'$}. Hence, constructing a compressed DAG $G=(V,E)$ for $\alpha$ w.r.t.\ $D$ and $\dep$, with $\support{G}=D'$ is straightforward. That is, the root of $G$ is $\alpha$, and if a node $\beta \in V$, letting $S=\{\gamma_1,\ldots,\gamma_n\}$ be its justification in $G'$, $G$ has nodes $\gamma_1,\ldots,\gamma_n$, and edges $(\beta,\gamma_1),\ldots,(\beta,\gamma_n)$.
	
	For proving (2) implies (1), we use an ``unravelling'' construction, similar to the one employed in the proof of Proposition~\ref{pro:characterization-all-trees} to convert a proof DAG to a proof tree. In particular, consider a compressed DAG $G=(V,E)$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{G}=D'$. By definition of $G$, for each non-leaf node $\beta$ of $G$, its children $\gamma_1,\ldots,\gamma_n$ in $G$ are such that there exists a rule $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_m(\bar x_m) \in \dep$ and a function $h : \bigcup_{i \in [m]} \bar x_i \ra \ins{C}$ such that $\beta = R_0(h(\bar x_0))$, and $\{\gamma_i\}_{i \in [n]} = \{R_i(h(\bar x_i)) \mid i \in [m]\}$; we call $(\sigma,h)$ the \emph{trigger of $\beta$ in $G$}, for some arbitrarily chosen pair $(\sigma,h)$ as described above.
	%
	We unravel $G$ into an unambiguous proof tree $T=(V',E',\lambda')$ of $\alpha$ w.r.t.~$D$ and $\dep$ as follows. We add a node $v$ to $T$ with label $\lambda'(v) = \alpha$. Then, if $v$ is a node of $T$ with some label $\lambda'(v) = \beta$, letting $(\sigma,h)$ be the trigger of $\beta$ in $G$, where $\sigma = R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_m(\bar x_m)$, we add $m$ fresh new nodes $u_1,\ldots,u_m$ to $T$, where $u_i$ has label $\lambda'(u_i)=R_i(h(\bar x_i))$, for $i \in [m]$, and we add edges $(v,u_1),\ldots,(v,u_m)$ to $T$.
	%
	The fact that $T$ is a proof tree of $\alpha$ w.r.t.\ $D$ and $\dep$ follows by construction. To see that $T$ is unambiguous, observe that by the definition of compressed DAG, and by the construction of $T$, for every two non-leaf nodes $u,v$ of $T$ with the same label $\beta$, $u$ and $v$ have the same number of children $u_1,\ldots,u_n$, and $v_1,\ldots,v_n$, with $\lambda'(u_i)=\lambda'(v_i)$, for $i \in [n]$. Clearly, $\support{T}=D'$.
\end{proof}

With the above characterization in place, we are now ready to discuss how we construct our Boolean formula.

\medskip
\noindent
\textbf{Graph of Rule Instances and Downward Closure.} For our purposes, a \emph{(directed) hypergraph} $\mathcal{H}$ is a pair $(V,E)$, where $V$ is the set of \emph{nodes} of $\mathcal{H}$, and $E$ is the set of its \emph{hyperedges}, i.e., pairs of the form $(\alpha,T)$, where $\alpha \in V$, and $\emptyset \subsetneq T \subseteq V$. For two nodes $u,v$ of $\mathcal{H}$, we say that \emph{$u$ reaches $v$ in $\mathcal{H}$}, if either $u=v$, or there exists a sequence of hyperedges of the form $(u_1,T_1),\ldots,(u_n,T_n)$, with $u_1=u$, $v \in T_n$, and $u_i \in T_{i-1}$ for $1 < i \le n$. For $u \in V$, we write $\downof{\mathcal{H}}{u}$ for the hypergraph $(V',E')$ obtained from $\mathcal{H}$, where $V'$ contains $u$ and all nodes reachable from $u$, and the hyperedges are all the hyperedges of $\mathcal{H}$ mentioning a node of $V'$.
%
We can now introduce the notion of graph of rule instances.

\begin{definition}[\textbf{Graph of Rule Instances}]
Consider a Datalog program $\dep$, and a database $D$ over $\esch{\dep}$. 
The \emph{graph of rule instances (GRI) of $D$ and $\dep$} is the hypergraph $\gri{D}{\dep}=(V,E)$, with $V \subseteq \base{D,\dep}$, such that

\begin{enumerate}
	\item For each $\alpha \in D$, $\alpha \in V$.
	\item If there exists a rule $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_n(\bar x_n)$ in $\dep$ and a function $h : \bigcup_{i \in [n]} \bar x_i \ra \ins{C}$ such that $\alpha_i = R_i(h(\bar x_i)) \in V$, for $i \in [n]$, then $\alpha_0 = R_0(h(\bar x_0)) \in V$, and $(\alpha_0,\{\alpha_1,\ldots,\alpha_n\}) \in E$.
\end{enumerate}
\end{definition}


Roughly, $\gri{D}{\dep}$ is a structure that ``contains'' all possible compressed DAGs of $\alpha$ w.r.t.~$D$ and $\dep$.
%
Since we are interested in finding only compressed DAGs of a specific fact $\alpha$, we do not need to consider $\gri{D}{\dep}$ in its entirety, but we only need the sub-hypergraph of $\gri{D}{\dep}$ containing $\alpha$, and all nodes reachable from it.
%
Formally, for a Datalog program $\dep$, a database $D$ over $\esch{\dep}$, and a node (i.e., a fact) $\alpha$ of $\gri{D}{\dep}$, the \emph{downward closure} of $\alpha$ w.r.t.~$D$ and $\dep$ is the hypergraph $\downc{D}{\dep}{\alpha} = \downof{\gri{D}{\dep}}{\alpha}$.
%
In other words, the downward closure keeps from $\gri{D}{\dep}$ only the part that is relevant to derive the fact $\alpha$. It is easy to verify that $\downc{D}{\dep}{\alpha}$ ``contains'' all compressed DAGs of $\alpha$ w.r.t.~$D$ and $\dep$, and the next technical result follows:
%In particular, consider a $k$-ary query $Q=(\dep,P)$, a database $D$ over $\esch{\dep}$, a tuple $\bar t \in \adom{D}^k$, and a proof DAG $G=(V,E,\lambda)$ of $\bar t$ w.r.t.\ $D$ and $\dep$. We say that $G$ is a \emph{subgraph induced by} $\downc{D}{Q}{\bar t}$ if for every node $v \in V$ with outgoing edges $(u,v_1),\ldots,(u,v_n)$ in $G$, we have that $(\lambda(u),\{\lambda(v_1),\ldots,\lambda(v_n)\})$ is a hyperedge of $\downc{D}{Q}{\bar t}$.
%The following lemma is straightforward.

\begin{lemma}\label{lem:dag-in-down}
	Consider a Datalog program $\dep$, a database $D$ over $\esch{\dep}$, a fact $\alpha$ over $\sch{\dep}$, and a compressed DAG $G=(V,E)$ of $\alpha$ w.r.t.\ $D$ and $\dep$. Then, for every node $\beta \in V$ with outgoing edges $(\beta,\gamma_1),\ldots,(\beta,\gamma_n)$ in $G$, we have that $(\beta,\{\gamma_1,\ldots,\gamma_n\})$ is a hyperedge of $\downc{D}{\dep}{\alpha}$.
\end{lemma}

%\begin{proof}
%	The claim follows by definition of compressed DAG, the definition  of GRI, and the definition of downward closure.
%\end{proof}

%The main idea of our reduction is thus to first construct the downward closure of the given tuple $\bar t$ w.r.t.\ $D$ and $Q$, (this is clearly doable in polynomial time w.r.t.\ $D$), and then construct, starting from $\downc{D}{Q}{\bar t}$, a Boolean formula in CNF $\varphi$ whose satisfying truth assignments correspond to the unambiguous proof DAGs of $\bar t$ w.r.t.\ $D$ and $Q$, having $D$ as their support, that can be extracted from $\downc{D}{Q}{\bar t}$.
%%The latter are obtained by letting the formula have access to $\downc{D}{Q}{\bar t}$. 
%
%We point out that if $\bar t \not \in Q(D)$, or not all facts in $D$ occur as nodes in $\downc{D}{Q}{\bar t}$, then, no proof DAG $G$ for $\bar t$ w.r.t.\ $D$ and $Q$ exists that has $\support{G} = D$. So, the interesting case in our reduction is when $\bar t \in Q(D)$, and all facts of $D$ occur in $\downc{D}{Q}{\bar t}$. We will focus on this case for the rest of this section.

%We are now ready to discuss the construction of the Boolean formula.

\smallskip
\noindent
\textbf{The Boolean Formula.} We are now ready to introduce the desired Boolean formula. For a Datalog query $Q = (\dep,R)$, a database $D$ over $\esch{\dep}$, and a tuple $\bar t \in \adom{D}^{\arity{R}}$, we construct in polynomial time in $|D|$ the formula $\phi_{(\bar t,D,Q)}$ such that the why-provenance of $\bar t$ w.r.t.~$D$ and $Q$ relative to unambiguous proof trees can be computed from the truth assignments that make $\phi_{(\bar t,D,Q)}$ true. 
%In particular, $\phi_{(\bar t,D,Q)}$ has the following properties; let $\downc{D}{Q}{R(\bar t)}=(V,E)$.

Let $\downc{D}{Q}{R(\bar t)}=(V,E)$. The set of Boolean variables of $\phi_{(\bar t,D,Q)}$ is composed of four disjoint sets $V_N$, $V_H$, $V_E$, and $V_C$ of variables. Each variable in $V_N$ corresponds to a node of $\downc{D}{Q}{R(\bar t)}$, i.e., $V_N = \{x_\alpha \mid \alpha \in V\}$, each variable in $V_H$ corresponds to a hyperedge of $\downc{D}{Q}{R(\bar t)}$, i.e., $V_H = \{y_e \mid e \in E\}$, and each variable in $V_E$ corresponds to a "standard edge" that can be extracted from a hyperedge of $\downc{D}{Q}{R(\bar t)}$, i.e., $V_E = \{z_{(\alpha,\beta)} \mid (\alpha,T) \in E \text{ with } \beta \in T \}$. The set $V_C$ will be discussed later. 
%
Roughly, the variables in $V_N$ and $V_E$ that will be true via a satisfying assignment of $\phi_{(\bar t,D,Q)}$ will induce the nodes and the edges of a compressed DAG $G$ for $R(\bar t)$ w.r.t.\ $D$ and $Q$, which, by Proposition~\ref{pro:characterization-u-trees-improved}, will imply that $\support{G} \in \unwhy{\bar t}{D}{Q}$.

%The clauses of the formula will force a satisfying truth assignment to assign true to the variables in $V_N \cup V_E$ so that they encoderepresent an unambiguous proof DAG of $\bar t$ w.r.t.\ $D$ and $Q$, and false all the other variables in $V_E$. In such a truth assignment, the value given to the variables in $V_N \cup V_H$ will be uniquely determined by the values assigned to the variables in $V_E$.

The formula $\phi_{(\bar t,D,Q)}$ is of the form
%a conjunction of different formulas:
\[
\phi_{\mi{graph}} \wedge \phi_{\mi{root}} \wedge \phi_{\mi{proof}} \wedge \phi_{\mi{acyclic}}.
\]
We proceed to discuss each of the above formulas. In the following, we use $A \Rightarrow B$ as a shorthand for $\neg A \vee B$.
The first formula $\phi_{\mi{graph}}$ is in charge of guaranteeing consistency between the truth assignments of the variables in $V_N$ and the variables in $V_E$, i.e., if an edge between two nodes is stated to be part of $G$, then the two nodes must belong to G as well:
$$ \phi_{\mi{graph}} = \bigwedge\limits_{z_{(\alpha,\beta)} \in V_E} (z_{(\alpha,\beta)} \Rightarrow x_\alpha) \wedge (z_{(\alpha,\beta)} \Rightarrow x_\beta).$$
%
The second formula $\phi_{\mi{root}}$ guarantees that the atom $R(\bar t)$ is indeed a node of $G$, it is the root of $G$, and no other atom that is a node of $G$ can be the root (i.e., it must always have at least one incoming edge):
\begin{multline*}
	\phi_{\mi{root}} = x_{R(\bar t)} \wedge
	\left(\bigwedge\limits_{z_{(\alpha,R(\bar t))} \in V_E} \neg z_{(\alpha,R(\bar t))} \right)\wedge \\
	\bigwedge\limits_{\substack{x_\alpha \in V_N \\ \text{ with } \alpha \neq R(\bar t)}} \left( x_\alpha \Rightarrow \bigvee\limits_{z_{(\beta,\alpha)} \in V_E} z_{(\beta,\alpha)}\right).
\end{multline*}
%
We now move to the next formula $\phi_{\mi{proof}}$. Roughly, this formula is in charge of ensuring that, whenever an intensional atom $\alpha$ is a node of $G$, then it must have the correct children in $G$. That is, its children are the ones coming from some hyperedge of $\downc{D}{Q}{R(\bar t)}$, and no other nodes are its children (this is needed to guarantee that $G$ is a \emph{compressed} DAG). This is achieved with two sub-formulas. The first part is in charge of choosing some hyperedge $(\alpha,T)$ of $\downc{D}{Q}{R(\bar t)}$, for each intensional atom $\alpha$, while the second guarantees that for each selected hyperedge $(\alpha,T)$ (one per intensional atom $\alpha$), \emph{all and only} the nodes in $T$ are children of $\alpha$ in $G$:
\begin{multline*}
	\phi_{\mi{proof}} = 
	\bigwedge\limits_{\substack{x_\alpha \in V_N \text{ with } \\ \alpha \text{ intensional }}} 
	\left( x_\alpha \Rightarrow \bigvee\limits_{y_{(\alpha,T)} \in V_H} y_{(\alpha,T)} \right) \wedge \\
	\bigwedge\limits_{\substack{y_{e} \in V_H \\ \text{with } e=(\alpha,T)}} \left( \bigwedge\limits_{z_{(\alpha,\beta)} \in V_E} y_{e} \Rightarrow 
	\ell_{e,\beta}
	\right),
\end{multline*}
where, for a hyperedge $e=(\alpha,T)$, $\ell_{e,\beta}$ denotes $z_{(\alpha,\beta)}$ if $\beta \in T$, and $\neg z_{(\alpha,\beta)}$ otherwise.

\medskip
\noindent
\textbf{Remark.} Although we are interested in choosing \emph{exactly one} hyperedge $(\alpha,T)$ for each intensional atom $\alpha$, the above formula uses a simple disjunction rather an exclusive or. This is fine as any truth assignment that makes two variables $y_{(\alpha,T_1)}$ and $y_{(\alpha,T_2)}$ true cannot be a satisfying assignment, since the second subformula in $\phi_{\mi{proof}}$, e.g., requires that the variables $z_{(\alpha,\beta)}$ with $\beta \in T_1$ are true, while all others must be false. Hence, since $T_1 \neq T_2$, when considering the hyperedge $(\alpha,T_2)$, this subformula will not be satisfied.

%\smallskip
%We now discuss the formula $\phi_{\mi{Support}}$. This formula is in charge of verifying that the set of nodes of $G$ corresponding to extensional atoms coincides with the database $D$, i.e., $\support{G}=D$.\footnote{Recall that we assume all the database facts appear in $\downc{D}{Q}{R(\bar t)}$, and so all the variables we use in $\phi_{\mi{Support}}$ are well defined.}
%
%$$ \phi_{\mi{Support}} = \bigwedge\limits_{\alpha \in D} x_\alpha.$$

\medskip
\noindent The remaining formula to discuss is $\phi_{\mi{acyclic}}$. This last formula is in charge of checking that $G$, i.e., the graph whose edges correspond to the true variables in $V_E$, is acyclic. Checking acyclicity of a graph encoded via Boolean variables in a Boolean formula is a well-studied problem in the SAT literature, and thus different encodings exist. For the sake of our construction, it is enough to use the simplest (yet, not very efficient in practice) encoding, which just encodes the transitive closure of the graph. However, for our experimental evaluation, we will implement this formula using a more efficient encoding based on so-called vertex elimination, which reduces by orders of magnitude the size of the formula $\phi_{\mi{acyclic}}$~\cite{RankoohR22}.

To encode the transitive closure, we now need to employ the set of Boolean variables $V_C$, having a variable of the form $t_{(\alpha,\beta)}$, for every two nodes $\alpha,\beta$ of $\downc{D}{Q}{R(\bar t)}$. Intuitively, $t_{(\alpha,\beta)}$ denotes whether a path exists from $\alpha$ to $\beta$ in $G$.
With these variables in place, writing $\phi_{\mi{acyclic}}$ is straightforward: it just encodes the transitive closure of the underlying graph, and then checks whether no cycle exists:
\begin{multline*}
	\phi_{\mi{acyclic}} = \left(\bigwedge\limits_{z_{(\alpha,\beta)} \in V_E} z_{(\alpha,\beta)} \Rightarrow t_{(\alpha,\beta)}\right) \wedge \\
	%
	\left(\bigwedge\limits_{\substack{z_{(\alpha,\beta)} \in V_E, t_{(\beta,\gamma)} \in V_C}} z_{(\alpha,\beta)} \wedge t_{(\beta,\gamma)} \Rightarrow t_{(\alpha,\gamma)}\right) \wedge \\
	\left( \bigwedge\limits_{t_{(\alpha,\alpha)} \in V_C} \neg t_{(\alpha,\alpha)} \right).
\end{multline*}

This completes the construction of our Boolean formula. One can easily verify that the formula is in CNF, and that can be constructed in polynomial time. 
%
We proceed to show its correctness, i.e., Proposition~\ref{pro:why-provenance-sat}.
%Consider a Datalog query $Q = (\dep,R)$, a database $D$ over $\esch{\dep}$, and a tuple $\bar t \in \adom{D}^{\arity{R}}$. 
For a truth assignment $\tau$ from the variables of $\phi_{(\bar t,D,Q)}$ to $\{0,1\}$, we write $\db{\tau}$ for the database $\{\alpha \in D \mid x_\alpha \in V_N \text{ and } \tau(x_\alpha)  =1\}$, i.e., the database collecting all facts having a corresponding variable in $\phi_{(\bar t,D,Q)}$ that is true w.r.t.~$\tau$. Finally, we let $\sem{\phi_{(\bar t,D,Q)}}$ as
\[
\left\{\db{\tau} \mid \tau \text{ is a satisfying assignment of } \phi_{(\bar t,D,Q)}\right\}.
\]

We are now ready to prove Proposition~\ref{pro:why-provenance-sat}, which we report here for convenience:

\begin{manualproposition}{\ref{pro:why-provenance-sat}}
	\prowhyprovenancesat
\end{manualproposition}

\begin{proof}
%Consider a Datalog query $Q = (\dep,R)$, a database $D$ over $\esch{\dep}$, and a tuple $\bar t \in \adom{D}^{\arity{R}}$. 
Due to Proposition~\ref{pro:characterization-u-trees-improved}, it suffices to show that:

\begin{lemma}\label{lem:sat-solutions}
	For every database $S \subseteq D$, the following are equivalent:
	\begin{enumerate}
		\item There exists a compressed DAG $G$ of $R(\bar t)$ w.r.t.~$D$ and $\dep$ with $\support{G}=S$.
		\item There exists a satisfying truth assignment $\tau$ of $\phi_{(\bar t,D,Q)}$ such that $\db{\tau}=S$.
	\end{enumerate}
\end{lemma}

\begin{proof}
	We start with the implication $(1) \Rightarrow (2)$. Assume that $G=(V,E)$ is a compressed DAG for $R(\bar t)$ w.r.t.~$D$ and $\dep$ with $\support{G}=S$. We construct the following truth assignment $\tau$ of $\phi_{(\bar t,D,Q)}$:
	\begin{itemize} 
		\item For each $x_\alpha \in V_N$, $\tau(x_\alpha)=1$ if $\alpha$ is a node of $G$, otherwise $\tau(x_\alpha)=0$. 
		\item For each $z_{(\alpha,\beta)} \in V_E$, $\tau(z_{(\alpha,\beta)})=1$ if there is an edge $(\alpha,\beta)$ in $G$, otherwise $\tau(z_{(\alpha,\beta)})=0$. 
		\item For each $y_{(\alpha,T)} \in V_H$, $\tau(y_{(\alpha,T)}) = 1$ if $\alpha$ is a node in $G$ with outgoing edges $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$ such that $T=\{\beta_1,\ldots,\beta_n\}$, otherwise $\tau(y_{(\alpha,T)})=0$.
		\item For each $t_{(\alpha,\beta)} \in V_C$, $\tau(t_{(\alpha,\beta)}) = 1$ if there is a path from $\alpha$ to $\beta$ in $G$, otherwise $\tau(t_{(\alpha,\beta)})=0$.
	\end{itemize}
	We now claim that $\tau$ makes $\phi_{(\bar t,D,Q)}$ true and $\db{\tau}=S$.
	
	\medskip
	\noindent
	\textbf{Observation 1.} By Lemma~\ref{lem:dag-in-down}, every node $\alpha$ of $G$ has a variable $x_\alpha$ in $\phi_{(\bar t,D,Q)}$. Similarly, if a node $\alpha$ has outgoing edges $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$ in $G$, then $z_{(\alpha,\beta_i)}$ for $i \in [n]$, and $y_{(\alpha,T)}$, with $T=\{\beta_1,\ldots,\beta_n\}$, are all variables of $\phi_{(\bar t,D,Q)}$.
	
	\medskip
	
	From Observation 1, each fact $\alpha \in \support{G}=S$ has a corresponding variable $x_\alpha$ in $\phi_{(\bar t,D,Q)}$. Moreover, by construction of $\tau$, $\tau(x_\alpha)=1$ for each $\alpha \in S$. Furthermore, for all facts $\beta$ of $D$ not in $S$ it means there is no node in $G$ labeled with $\beta$, and thus $\tau(x_\beta)=0$. Hence $\db{\tau}=S$. 
	
	We now show that $\tau$ makes $\phi_{(\bar t,D,Q)}$ true. We proceed by considering its subformulas separately.
	\begin{description}
	%\smallskip
	%\noindent
	\item[\underline{$\phi_\mi{graph}$}.] It is clear that $\tau$ makes this formula true since when $\tau(z_{(\alpha,\beta)}) = 1$, it means that $\alpha$ and $\beta$ are nodes of $G$, and thus, by construction of $\tau$, $\tau(x_\alpha) = \tau(x_\beta)=1$.
	
	%\smallskip
	%\noindent
	\item[\underline{$\phi_\mi{root}$}.] Since $R(\bar t)$ is the root of $G$, by Observation 1 and by construction of $\tau$, $\tau(x_{R(\bar t)}) = 1$. To see why the formula
	\[
	\left(\bigwedge\limits_{z_{(\alpha,R(\bar t))} \in V_E} \neg z_{(\alpha,R(\bar t))} \right)
	\]
	is true, since $R(\bar t)$ is the root, it does not have any incoming edges, and thus, by construction of $\tau$, $\tau(z_{(\alpha,R(\bar t))})=0$, for each $z_{(\alpha,R(\bar t))} \in V_E$. 
	Finally, regarding the formula
	$$\bigwedge\limits_{\substack{x_\alpha \in V_N \\ \text{ with } \alpha \neq R(\bar t)}} \left( x_\alpha \Rightarrow \bigvee\limits_{z_{(\beta,\alpha)} \in V_E} z_{(\beta,\alpha)}\right),$$
	if $\tau(x_\alpha)=1$, for some $\alpha \neq R(\bar t)$, by construction of $\tau$, $\alpha$ is a node of $G$. By Observation 1, for every edge $(\beta,\alpha)$ in $G$, we have that $z_{(\beta,\alpha)}$ is a variable of $\phi_{(\bar t,D,Q)}$, and $\tau(z_{(\beta,\alpha)}) = 1$, hence the disjunction is true.
	
	%\smallskip
	%\noindent
	\item[\underline{$\phi_\mi{proof}$}.] We start by considering the formula
	\[
	\bigwedge\limits_{\substack{x_\alpha \in V_N \text{ with } \\ \alpha \text{ intensional }}} 
	\left( x_\alpha \Rightarrow \bigvee\limits_{y_{(\alpha,T)} \in V_H} y_{(\alpha,T)} \right).
	\]
	If $\tau(x_\alpha)=1$, for some intensional fact $\alpha$, it means that $\alpha$ is a node of $G$. Let $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$ be the outgoind edges of $\alpha$ in $G$. By Observation 1, $y_{(\alpha,T)}$, with $T=\{\beta_1,\ldots,\beta_n\}$, is a variable of $\phi_{(\bar t,D,Q)}$, and by construction of $\tau$, $\tau(y_{(\alpha,T)}) = 1$, hence the disjunction is true.
	%
	We now consider the formula
	\[
	\bigwedge\limits_{\substack{y_{e} \in V_H \\ \text{with } e=(\alpha,T)}} \left( \bigwedge\limits_{z_{(\alpha,\beta)} \in V_E} y_{e} \Rightarrow 
	\ell_{e,\beta}
	\right).
	\]
	If $\tau(y_e)=1$, for $e=(\alpha,T)$, then $\alpha$ is a node of $G$ with outgoing edges $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$, where $T=\{\beta_1,\ldots,\beta_n\}$. By Observation 1, $z_{(\alpha,\beta_i)} \in V_E$, for $i \in [n]$, and by construction of $\tau$, $\tau(z_{(\alpha,\beta_i)})=1$, for $i \in [n]$. Hence, all implications of the form $y_e \Rightarrow \ell_{e,\beta}$, where $\beta \in \{\beta_1,\ldots,\beta_n\}$ are true.
	Regarding the other implications, i.e., when $\beta \not \in \{\beta_1,\ldots,\beta_n\}$, since $\alpha$ has no other outgoing edges in $G$, by construction of $\tau$, $\tau(z_{(\alpha,\beta)})=0$, for all other facts $\beta \not \in \{\beta_1,\ldots,\beta_n\}$. Hence, the whole formula is satisfied.
	
	%\smallskip
	%\noindent
	\item[\underline{$\phi_{\mi{acyclic}}$}.] The fact that the formula is true follows from the acyclicity of $G$, Observation 1, and the construction of $\tau$.
	\end{description}


	%\medskip
	We now proceed with $(2) \Rightarrow (1)$. By hypothesis, there is a truth assignment $\tau$ that makes $\phi_{(\bar t,D,Q)}$ true and $\db{\tau} = S$. We define the auxiliary sets
	\begin{eqnarray*}
		\nodes{\tau} &=& \{\alpha \mid x_\alpha \in V_N \text{ and } \tau(x_{\alpha}) = 1\}\\
		%
		\edges{\tau} &=& \{(\alpha,\beta) \mid z_{(\alpha,\beta)} \in V_E \text{ and } \tau(z_{(\alpha,\beta)})=1\}. 
	\end{eqnarray*}
	%Let us first make some useful observations.
	
	%\medskip
	%\noindent
	%\textbf{Observation 2.} 
	
	\noindent Since $\tau$ makes $\phi_\mi{graph}$ true, every fact occurring in $\edges{\tau}$ also occurrs in $\nodes{\tau}$; hence, $G=(\nodes{\tau},\edges{\tau})$ is a well-defined directed graph. Moreover, since $\db{\tau}=S$, all the nodes without outgoing edges in $G$ are precisely the ones in $S$. Finally, since $\tau$ makes $\phi_{\mi{acyclic}}$ true, $G$ is acyclic, and since $\tau$ satisfies $\phi_\mi{root}$, $R(\bar t)$ is the only node of $G$ without incoming edges. Thus, $G$ is a DAG, its root is $R(\bar t)$, and its leaves is exactly the set $S$. It remains to argue that $G$ is a compressed DAG of $R(\bar t)$ w.r.t.~$D$ and $\dep$.
	
	%\smallskip
	%\noindent
	%\textbf{Observation 3.} 
	Consider a node $\alpha$ of $G$ which is an intensional fact. It is clear that $\tau(x_\alpha)=1$, and thus, the dijunction in $\phi_\mi{proof}$ must be true. Hence, $\tau(y_{(\alpha,T)})=1$, for some hyperedge $(\alpha,T)$ of $\downc{D}{Q}{R(\bar t)}$. In particular, since $\tau$ makes
	\[
	\bigwedge\limits_{\substack{y_{e} \in V_H \\ \text{with } e=(\alpha,T)}} \left( \bigwedge\limits_{z_{(\alpha,\beta)} \in V_E} y_{e} \Rightarrow 
	\ell_{e,\beta}
	\right)\]
	true in $\phi_{\mi{proof}}$, and $\tau(y_{(\alpha,T)})=1$, we must have that $\tau$ assigns $1$ to all variables of the form $z_{(\alpha,\beta)}$ with $\beta \in T$, and $0$ to all other variables of the form $z_{(\alpha,\beta)}$ with $\beta \not \in T$. This means that there is no other variable of the form $y_{(\alpha,T')}$ with $T'=T$ that is assigned $1$ by $\tau$. Hence, 
	for each node $\alpha$ of $G$ which is intensional, $\alpha$ has outgoing edges $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$, and these are such that there exists a hyperedge of $\downc{D}{Q}{R(\bar t)}$ of the form $(\alpha,T)$, with $T=\{\beta_1,\ldots,\beta_n\}$. The latter, by definition of downward closure, implies that for each node $\alpha$ of $G$ which is intensional, $\alpha$ has outgoing edges $(\alpha,\beta_1),\ldots,(\alpha,\beta_n)$, and these are such that there exists a rule $\sigma \in \dep$ of the form $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_m(\bar x_m)$, with $m \ge n$, and a function $h : \bigcup_{i \in [n]} \bar x_i \rightarrow \ins{C}$, such that $R_0(h(\bar x_0))=\alpha$ and $\{R_1(h(\bar x_1)),\ldots,R_m(h(\bar x_m))\} = \{\beta_1,\ldots,\beta_n\}$. Hence, $G$ is a compressed DAG of $R(\bar t)$ w.r.t.~$D$ and $\dep$, as needed.
	%
%	\smallskip
%	We now show how to construct an unambiguous proof DAG $G$ for $\bar t$ w.r.t.\ $D$ and $Q$ with $\support{G}=S$, starting from $G'$.
%	We inductively construct $G=(V,E,\lambda)$ as the following node-labeled graph. There is a node $u \in V$ labeled with $\lambda(u)=g$. Moreover, for every node $u \in V$ labeled with some intensional fact $\alpha = \lambda(u)$ that is a node of $G'$, letting $(\sigma,h)$ be the trigger induced by $\alpha$, with $\sigma = R_1(\bar x_1),\ldots,R_m(\bar x_m) \rightarrow R(\bar x)$, $V$ contains $m$ additional distinct nodes $v_1,\ldots,v_m$ with $\lambda(v_i)=R_i(h(\bar x_i))$, for $i \in [m]$. We claim that $G$ is an unambiguous proof DAG for $\bar t$ w.r.t.\ $D$ and $Q$ with $\support{G}=S$.
%	
%	Indeed, $G$ is acyclic by construction (as at each inductive step, we consider fresh nodes). Moreover, by Observation 1, since only the node $g$ in $G'$ has no incoming edges, There is only one node in $G$ without incoming edges, and this node is labeled with $g$. Hence, $G$ is a node-labeled DAG rooted at a node $u$ with label $g$. We now prove it is actually a proof DAG.
%	For this, note that for every node $u$ of $G$ labeled with an intensional fact $\alpha$, $u$ has $m$ children $v_1,\ldots,v_m$ that are obtained by means of a pair $(\sigma,h)$ of a rule of the form $R_1(\bar x_1),\ldots,R_m(\bar x_m) \rightarrow R(\bar x)$, and function, where the label of $u$ coincides with $R(h(\bar x))$, and $\lambda(v_i)=R_i(h(\bar x_i))$, for $i \in [m]$. This is the very definition of a proof DAG.
%	
%	To see that $G$ is unambiguous, assume, towards a contradiction, that $G$ is not unambiguous. So, there are two nodes $u,v$ in $G$ with $\lambda(u)=\lambda(v)$, but $G[u] \eqtree G[v]$ does not hold. The latter means that there must be two nodes $u'$ and $v'$ in $G[u]$ and $G[v]$ respectively, such that $\alpha=\lambda(u')=\lambda(v')$, but their immediate children are labeled differently. However, this cannot be the case, since for any node in $G$ labeled with an intensional fact $\alpha$, its children are always labeled with facts in $T$, where $(\alpha,T)$ is the (unique) trigger induced by $\alpha$.
%	
%	Finally, the fact that $\support{G}=S$ follows from the fact that the leaves of $G'$ are precisely the ones in $S$, by Observation 2. This concludes our proof.
\end{proof}

Proposition~\ref{pro:why-provenance-sat} immediately follows from Lemma~\ref{lem:sat-solutions}.
\end{proof}

\subsection{Implementation Details}
In this section, we expand on the discussion of our implementation presented in the main body of the paper. In what follows, fix a Datalog query $Q = (\dep,R)$, a database $D$ over $\esch{\dep}$, and a tuple $\bar t \in \adom{D}^{\arity{R}}$.

\medskip
\noindent \textbf{Constructing the Downward Closure.}
Recall that the construction of $\phi_{(\bar t,D,Q)}$ relies on the downward closure of $R(\bar t)$ w.r.t.~$D$ and $\dep$. It turns out that the hyperedges of the downward closure can be computed by executing a slightly modified Datalog query $Q_{\downarrow}$ over a slightly modified database $D_{\downarrow}$. In other words, the answers to $Q_{\downarrow}$ over $D_{\downarrow}$ coincide with the hyperedges of the downward closure.
For this, we are going to adopt a slight modification of an existing approach presented in~\cite{ElKM22}. In that paper, the authors were studying the problem of computing the why-provenance of Datalog queries w.r.t.\ \emph{standard} proof trees. However, except for the construction of $\downc{D}{Q}{R(\bar t)}$, their approach to compute the supports for general trees is fundamentally different from ours, since they employ existential rule-based engines rather than SAT solvers; it is not clear how their approach could be adapted for our purposes, as we require checking whether the underlying trees are unambiguous. Moreover, the approach of~\cite{ElKM22} computes the \emph{whole set} of supports all at once, while our approach based on SAT solvers allows to \emph{enumerate} supports, and thus allows the incremental construction of the why-provenance.
%
Nonetheless, the construction of $\downc{D}{Q}{R(\bar t)}$ is common to both approaches, and thus we borrow the techniques of~\cite{ElKM22} for this task, which we briefly recall in the following.

The main idea is to employ an existing Datalog engine to compute the answers of a query $Q_{\downarrow}$ obtained from $Q$ over a slight modification $D_{\downarrow}$ of $D$; the answers in $Q_{\downarrow}(D_{\downarrow})$ will coincide with all the hyperedges of $\downc{D}{Q}{R(\bar t)}$. 
%
To this end, the rules of $Q_{\downarrow}$ contain all the rules in $\dep$, which will be in charge of deriving all nodes of $\gri{D}{\dep}$, plus an additional set of rules that will be in charge of using such nodes to construct all the hyperedges of $\downc{D}{Q}{R(\bar t)}$. Formally, let $\omega$ be the maximum arity of predicates in $\dep$, and $b$ the maximum number of atoms in the body of a rule of $\dep$. We define two new predicates: 
\begin{itemize}
	\item $\curnode$ of arity $\omega+1$ that stores the current node of $\downc{D}{Q}{R(\bar t)}$ being processed during the evaluation of $Q_{\downarrow}$.
	\item $\hedge$ of arity $(\omega+1)+b\times(\omega+1)$, which stores the hyperedges being constructed during the evaluation of $Q_{\downarrow}$.
\end{itemize}
%
Furthermore, for an atom $\alpha = P(\bar u)$, we denote $\atomtotuple{\alpha}$ as the tuple of length $\omega+1$ of the form $c_P,\bar u,\star,\ldots,\star$, where $c_P$ and $\star$ are constants not in $D$. Intuitively, $\atomtotuple{\alpha}$ encodes the atom $\alpha$ as a tuple of fixed length. Finally, for an atom $\alpha$ and a sequence of atoms $\beta_1,\ldots,\beta_n$, with $n \le b$, we use $\tup{\alpha,\beta_1,\ldots,\beta_n}$ to denote the tuple of length $(\omega+1)+b \times (\omega+1)$ of the form $\tup{\alpha},\tup{\beta_1},\ldots,\tup{\beta_n},\star,\ldots,\star$.
%Similarly, forn an atom $\alpha = R(\bar t)$, and a set of atoms $T= \beta_1,\ldots,\beta_n$, with $\beta_i = R_i(\bar t_i)$, for $i \in [n]$, we use $\edgeatom{\alpha}{T}$ to denote the atom of the form
%$$ hedge()$$  

We define the Datalog query $Q_{\downarrow} = (\dep',\hedge)$, where $\dep' = \dep \cup \dep''$, where, for each rule $\sigma \in \dep$ of the form $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_n(\bar x_n)$, $\dep''$ contains the rules
\begin{multline*}
\sigma_1\ =\ \hedge(\atomtotuple{R_0(\bar x_0),R_1(\bar x_1),\ldots,R_n(\bar x_n)})\ \assign\ \\ \curnode(\atomtotuple{R_0(\bar x_0)}), R_1(\bar x_1),\ldots,R_n(\bar x_n)
\end{multline*}
and, for each $i \in [n]$,
\begin{multline*}
\sigma^{(i)}_2\ =\ \curnode(\atomtotuple{R_i(\bar x_i)})\ \assign\ \\ \curnode(\atomtotuple{R_0(\bar x_0)}),R_1(\bar x_1),\ldots,R_n(\bar x_n).
\end{multline*}
\begin{comment}
\[
\begin{array}{ll}
	\sigma_1: & \hedge(\atomtotuple{R_0(\bar x_0),R_1(\bar x_1),\ldots,R_n(\bar x_n)})\ \assign\ \\
	& \curnode(\atomtotuple{R_0(\bar x_0)}), R_1(\bar x_1),\ldots,R_n(\bar x_n), \\\ \\
	
	\sigma^{(i)}_2: & \curnode(\atomtotuple{R_i(\bar x_i)})\ \assign\ \curnode(\atomtotuple{R_0(\bar x_0)}),\\
	&  R_1(\bar x_1),\ldots,R_n(\bar x_n) \hfill \forall i \in [n].
\end{array}
\]
\end{comment}
Essentially, the rule $\sigma_1$ will construct a hyperedge $(\alpha,T)$ of $\downc{D}{Q}{R(\bar t)}$ whenever it is known that $\alpha$ is a node of $\downc{D}{Q}{R(\bar t)}$, and all the atoms in $T$ are used in $\gri{D}{\dep}$ to generate $\alpha$.
The rules of the form $\sigma^{(i)}_2$ are marking the new nodes as being part of $\downc{D}{Q}{\bar t}$.
%
%\medskip
%\noindent
%\textbf{Remark.} 
Note that the rules of $\dep''$ contain constants, whereas, according to our definition, rules are constant-free. Nevertheless, all existing Datalog engines support rules with constants, and for the sake of keeping the discussion simple, we slightly abuse our definition of rules in this section. It is easy to adapt the above set of rules to a set of rules without constants, by adding some auxiliary facts to the database.

%\medskip

The database $D_{\downarrow}$ is $D \cup \{\curnode(\tup{R(\bar t)})\}$, which simply states that $R(\bar t)$ must be a node of $\downc{D}{Q}{R(\bar t)}$.
One can easily see that each tuple in $Q_{\downarrow}(D_{\downarrow})$ encodes a hyperedge of $\downc{D}{Q}{R(\bar t)}$, and thus, we can construct $\downc{D}{Q}{R(\bar t)}$ by simply asking $Q_{\downarrow}$ over $D_{\downarrow}$.


Let us note that the main differences between our definition of $Q_{\downarrow}$ and $D_{\downarrow}$ w.r.t.\ the ones of~\cite{ElKM22} is that we encode nodes and hyperedges of $\downc{D}{Q}{R(\bar t)}$ as tuples, which allows us to employ the same Datalog engine that is used to answer the original query $Q$, rather than using external engines supporting more expressive languages such as existential rules.

\medskip
\noindent \textbf{Constructing the Formula.} 
Regarding the construction of the formula $\phi_{(\bar t,D,Q)}$, as already discussed before, for efficiency reasons, we consider a different encoding of the subformula $\phi_\mi{acyclic}$. Rather than using the transitive closure, we employ the technique of vertex elimination~\cite{RankoohR22}. The advantage of this approach is that it requires a number of Boolean variables for the encoding of $\phi_\mi{acyclic}$ which is of the order of $O(n \times \delta)$, where $n$ is the number of nodes of the underlying graph, and $\delta$ is the so-called \emph{elimination width} of the graph, which, roughly, is related to how connected the underlying graph is. Hence, we can avoid the costly construction of quadratically many variables whenever the elimination width is low.

\medskip
\noindent \textbf{Incrementally Constructing the Why-Provenance.}
Recall that we are interested in the incremental computation of the why-provenance, which is more useful in practice than computing the whole set at once. To this end, we need a way to enumerate all the members of the why-provenance without repetitions. This is achieved by adapting a standard technique from the SAT literature for enumerating the satisfying assignments of a Boolean formula, called {\em blocking clause}.
%
We initially collect in a set $S$ all the facts of $D$ occurring in the downward closure of $R(\bar t)$ w.r.t.~$D$ and $\dep$. Then, after asking the SAT solver for an arbitrary satisfying assignment $\tau$ of $\phi_{(\bar t,D,Q)}$, we output the database $\db{\tau}$, and then construct the ``blocking'' clause
$
\vee_{\alpha \in S} \ell_\alpha,
$
where $\ell_\alpha = \neg x_\alpha$ if $\alpha \in \db{\tau}$, and $\ell_\alpha = x_\alpha$ otherwise. We then add this clause to the formula, which expresses that no other satisfying assignment $\tau'$ should give rise to the same member of the why-provenance.
%, i.e., $\db{\tau'}=\db{\tau}$. 
This will exclude the previously computed explanations from the computation. We keep adding such blocking clauses each time we get a new member of the why-provenance until the formula is unsatisfiable.


{\footnotesize 
	\begingroup
	\setlength{\tabcolsep}{5pt} % Default value: 6pt
	\renewcommand{\arraystretch}{1.6} % Default value: 1
	\begin{figure*}[t]
		\centering
		\begin{tabular}{cc}
			\multicolumn{2}{c}{\includegraphics[width=135mm]{ground_formula_Doctors}} \\
			\multicolumn{2}{c}{(a) $\mathsf{Doctors}$} \\[6pt]
			\includegraphics[width=65mm, height=53.2mm]{ground_formula_TransClosure} &   \includegraphics[width=65mm]{ground_formula_Galen} \\
			(b) $\mathsf{TransClosure}$ & (c) $\mathsf{Galen}$ \\[6pt]
			\includegraphics[width=65mm]{ground_formula_Andersen_uniform_size} &   \includegraphics[width=65mm]{ground_formula_CSDA} \\
			(d) $\mathsf{Andersen}$ & (e) $\mathsf{CSDA}$
		\end{tabular}
		\caption{Building the downward closure and the Boolean formula (all scenarios).}
		\label{fig:all-task1}
	\end{figure*}
	\endgroup
}

\subsection{Experimental Evaluation}
In this section, we provide further details on the performance of our SAT-based approach, by presenting the results of the experimental evaluation over all the scenarios we considered in the paper; we report again the $\mathsf{Andersen}$ scenario for the sake of completeness. Recall that in our experimental analysis we consider two main tasks separately: (1) construct the downward closure and the Boolean formula, and (2) incrementally compute the why-provenance using the SAT solver.


Concerning task 1, we report in Figure~\ref{fig:all-task1} one plot for each scenario we consider, where in each plot we report the total running time for each database of that scenario. Furthermore, for each plot, and each database considered therein, we have five bars, that correspond to the five randomly chosen tuples. Each such bar shows the time for building the downward closure plus the time for constructing the Boolean formula. To ease the presentation, we grouped the $\mathsf{Doctors}$-based scenarios in one plot (recall that all such scenarios share a single database).

We can see that in most of the scenarios, the running time is in the order of some seconds. This is especially true for the $\mathsf{TransClosure}$ and $\mathsf{Doctors}$-based scenarios, having the simplest queries, while for the $\mathsf{Galen}$ scenario, where the query is more complex, as it involves non-linear recursion, the time is slightly higher for the largest database $D_{4}$. The $\mathsf{Andersen}$ and $\mathsf{CSDA}$ scenarios are the most challenging, since they both contain very large databases. Moreover, although the databases in $\mathsf{Andersen}$ are smaller than those of $\mathsf{CSDA}$, the complexity of its query, which involves non-linear recursion, makes the running time of $\mathsf{Andersen}$ over its largest database (6.8M facts) comparable to $\mathsf{CSDA}$ with the larger database $D_\mathsf{httpd}$ (10M facts). Of course, for the much larger databases $D_\mathsf{postgresql}$ and $D_\mathsf{linux}$, the running time is much higher, going up to 6-7 minutes for some tuples.
Considering the size of the databases at hand, we believe the running times for these last scenarios are quite reasonable.
%
As already discussed in the main body of the paper, we observed that most of the time is spent in building the downward closure.


Concerning task 2, that is, the incremental computation of the why-provenance, we present in Figure~\ref{fig:all-task2} one plot for each scenario we consider, where in each plot of scenario $s$ we report, for each database of $s$, the times required to build an explanation, that is, the time between the current member of the why-provenance and the next one (this time is also known as the delay).
%
Each plot collects the delays of constructing the members of the why-provenance (up to a limit of 10K members or 5 minutes timeout) for each of the five randomly chosen tuples. We use box plots, where the bottom and the top borders of the box represent the first and third quartile, i.e., the delay under which 25\% and 75\% of all delays occur, respectively, and the orange line represents the median delay. Moreover, the bottom and the top whisker represent the minimum and maximum delay, respectively. All times are expressed in milliseconds and we use logarithmic scale. 
%
As we did for task 1, we grouped the $\mathsf{Doctors}$-based scenarios in one plot.

{\footnotesize 
	\begingroup
	\setlength{\tabcolsep}{5pt} % Default value: 6pt
	\renewcommand{\arraystretch}{1.6} % Default value: 1
	\begin{figure*}[t]
		\centering
		\begin{tabular}{cc}
			\multicolumn{2}{c}{\includegraphics[width=135mm]{exptimes_Doctors}} \\
			\multicolumn{2}{c}{(a) $\mathsf{Doctors}$} \\[6pt]
			\includegraphics[width=65mm, height=53.2mm]{exptimes_TransClosure} &   \includegraphics[width=65mm]{exptimes_Galen} \\
			(b) $\mathsf{TransClosure}$ & (c) $\mathsf{Galen}$ \\[6pt]
			\includegraphics[width=65mm]{exptimes_Andersen_uniform_size} &   \includegraphics[width=65mm]{exptimes_CSDA} \\
			(d) $\mathsf{Andersen}$ & (e) $\mathsf{CSDA}$
		\end{tabular}
		\caption{Incremental computation of the why-provenance (all scenarios).}
		\label{fig:all-task2}
	\end{figure*}
	\endgroup
}

As observed in the main body of the paper, most of the delays are even lower than 1 millisecond, with the median in the order of microseconds. Therefore, once we have the Boolean formula in place, incrementally computing the members of the why-provenance is extremely fast. The worst case occurs in the $\mathsf{TransClosure}$ scenario, when considering the Facebook database, where we also have the only two cases where the construction of the supports exceeds the 5 minutes mark before being able to construct 10K supports, i.e., for the third and fifth tuple. Overall, in the $\mathsf{TransClosure}$ scenario w.r.t.~the Facebook database, the average delay is higher, and some supports require up to 10 seconds to be constructed. We believe that this has to do with the fact that the database $D_\text{facebook}$ encodes a graph which is highly connected, and thus the CNF formula, and in particular the formula $\phi_{\mi{acyclic}}$ encoding the acyclicity check, becomes quite large, and thus is much more demanding for the SAT solver. This was somehow expected since the vertex-elimination technique for checking acyclicity performs better the less connected the underlying graph is. We have confirmed this by running some other experiments with databases taken from~\cite{FanMK22}, which contain highly connected, synthetic graphs. In this case, although constructing the downward closure is very efficient (in the order of seconds), the construction of the formula $\phi_\mi{acyclic}$ goes out of memory. Hence, we expect that in applications where highly connected input graphs are common, a different approach for checking acyclicity in a CNF formula would be required. Nonetheless, we can safely conclude that in most cases, computing the members of the why-provenance can be done very efficiently.

\subsection{Comparative Evaluation}
As mentioned in Section~\ref{sec:conclusions}, we have performed a preliminary comparison with~\cite{ElKM22}. We conclude this section by discussing  the details of this comparative evaluation.
%
Let us first clarify that our implementation deals with a different problem. For a Datalog query $Q = (\dep,R)$, a database $D$ over $\esch{\dep}$, and a tuple $\bar t \in \adom{D}^{\arity{R}}$, the approach from~\cite{ElKM22} has been designed and evaluated for building the whole set $\why{\bar t}{D}{Q}$, whereas our approach has been designed and evaluated for incrementally computing $\unwhy{\bar t}{D}{Q}$. However, there is a setting where a reasonable comparison can be performed, which will provide some insights for the two approaches.
%
This is when the Datalog query $Q$ is both linear and non-recursive in which case the sets $\why{\bar t}{D}{Q}$ and $\unwhy{\bar t}{D}{Q}$ coincide since a proof tree of $R(\bar t)$ w.r.t.~$D$ and $\dep$ is trivially unambiguous.
%
Therefore, towards a fair comparison, we are going to consider the scenarios $\mathsf{Doctors}\text{-}i$, for $i \in [7]$, which consist of a Datalog query that is linear and non-recursive, and consider the end-to-end runtime of our approach (not the delays) without, of course, setting a limit on the number of members of why-provenance to build, or on the total runtime.




%We point out that providing a reasonable comparison between our approach and the one above is tricky, since they basically solve different problems. Indeed, while in our case we might have the advantage of needing to construct much less supports, since our proof trees are more refined, in the all-trees case there is no need to check for the unambiguity of the underlying trees. For these reasons, we believe the only reasonable comparison that can be made is over scenarios for which the two notions of trees coincide. This is only the case with the DOCTORS-based scenarios, which employ queries that are both linear and non-recursive. It is easy to verify that for such queries, unmabiguous trees and arbitrary trees coincide.\footnote{In any case, even if we wanted to make a comparison over all scenarios, this would not be possible, since the authors of~\cite{ElhalawatiKM22} did not provide the tools needed to construct the set of existential rules that are able to build the why-provenance. Hence, we have to rely on the pregenerated ones for the scenarios they also consider (i.e., $\mathsf{DOCTORS}$ and $\mathsf{GALEN}$).}

%Since the approach of~\cite{ElhalawatiKM22} can only construct the whole why-provenance, without enumeration, we compare the end-to-end running time of our apprach (i.e., by combining tasks \emph{1)} and \emph{2)}) with the running time of their approach. In this case, of course, we did not specify any limit on the number of supports to build, or on the total running time. Finally, although not strictly necessary for enumerating the supports, our implementation keeps in main memory each support that is produced, so to be fair with the approach of~\cite{ElhalawatiKM22} which keeps all supports in memory by design. 


The comparison is shown in Figure~\ref{fig:comparison-time}. For each scenario, we present the runtime for all five randomly chosen tuples for our approach (in blue) and the approach of~\cite{ElKM22} (in red); if a bar is missing for a certain tuple, then the execution ran out of memory.
%
We observe that for the simple scenarios the two approaches are comparable in the order of a second.
%
Now, concerning the demanding scenarios, i.e., $\mathsf{Doctors}\text{-}i$ for $i \in \{1,5,7\}$, we observe that our approach is, in general, faster. Observe also that for some of the most demanding cases, the approach of~\cite{ElKM22} runs out of memory.
%
We believe that the latter is due to the use of the rule engine VLog, which is intended for materialization-based reasoning with existential rules, whereas our approach relies on a Datalog engine (in particular, DLV), and thus, exploiting all the optimizations that are typically employed for evaluating a Datalog query. For example, the technique of {\em magic-set rewriting}, implemented by DLV, can greatly reduce the memory usage by building much fewer facts during the evaluation of the rules; see, e.g.,~\cite{LAAC+19}.

{\footnotesize 
	\begingroup
	\setlength{\tabcolsep}{5pt} % Default value: 6pt
	\renewcommand{\arraystretch}{1.6} % Default value: 1
\begin{figure*}[t]
	\centering
	\includegraphics[width=135mm]{comparison}
	\caption{Comparison of the end-to-end computation of the why-provenance.}
	\label{fig:comparison-time}
\end{figure*}
\endgroup
}




