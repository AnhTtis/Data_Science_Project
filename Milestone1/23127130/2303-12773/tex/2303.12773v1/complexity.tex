\section{Data Complexity of Why-Provenance}\label{sec:complexity}
%

The goal of this section is to pinpoint the data complexity of $\mathsf{Why\text {-}Provenance[C]}$, for each $\class{C} \in \{\DAT,\LDAT,\NRDAT\}$. As we shall see, the main outcome of our analysis is that  for recursive queries, even if the recursion is linear, the problem is in general intractable, whereas for non-recursive queries it is highly tractable.
%
We first focus on recursive queries.
%and then proceed with non-recursive ones.


\subsection{Recursive Queries}\label{sec:recursive-complexity}
%

We show the following complexity result:
% concerning the data complexity of why-provenance for recursive queries:


\def\therecursivecomplexity{
$\mathsf{Why\text {-}Provenance[C]}$ is \NP-complete in data complexity, for each class $\class{C} \in \{\DAT,\LDAT\}$.
}

\begin{theorem}\label{the:recursive-complexity}
\therecursivecomplexity
\end{theorem}


Note that there is a striking difference between the problem of why-provenance and the problem of query evaluation, which is known to be in \PTIME~in data complexity; in fact, for linear Datalog queries it is in \NL~\cite{DEGV01}.
%that is, the problem of deciding whether a tuple is an answer to a Datalog query over a database. The former is \NP-hard in data complexity as shown by Theorem~\ref{the:recursive-complexity}, whereas the latter is known to be in \PTIME~in data complexity; in fact, for linear Datalog queries it is in \NL~\cite{DEGV01}. Hence, it is much harder to explain than evaluate recursive queries.
%
To prove Theorem~\ref{the:recursive-complexity}, it suffices to show that:
%$\mathsf{Why\text {-}Provenance[\DAT]}$ is in \NP~in data complexity, and $\mathsf{Why\text {-}Provenance[\LDAT]}$ is \NP-hard in data complexity.
\begin{itemize}
	\item $\mathsf{Why\text {-}Provenance[\DAT]}$ is in \NP~in data complexity.
	\item $\mathsf{Why\text {-}Provenance[\LDAT]}$ is \NP-hard in data complexity.
\end{itemize}
The lower bound is established via a reduction from $\mathsf{3SAT}$. We actually devise a linear Datalog query $Q$, and provide a reduction from $\mathsf{3SAT}$ to $\mathsf{Why\text {-}Provenance}[Q]$.
%To this ends, we need to show that there exists a linear Datalog query $Q = (\dep,R)$ such that the problem $\mathsf{Why\text {-}Provenance}[Q]$ is \NP-hard. The proof is via a reduction from $\mathsf{3SAT}$, which takes as input a Boolean formula $\varphi = C_1 \wedge \ldots \wedge C_m$ in 3CNF, where each clause has exactly 3 literals (a Boolean variable $v$ or its negation $\neg v$), and asks whether $\varphi$ is satisfiable.
%
Let us now discuss the key ingredients underlying the upper bound.
%
%\medskip
%
%\noindent \underline{\textbf{Upper Bound}}
%\smallskip
%
%\noindent 
%
The central property is that whenever there is a proof tree $T$ that witnesses the fact that the given subset of the input database belongs to the why-provenance, then there is always a way to compactly represent $T$ as a polynomially-sized directed acyclic graph. This in turn leads to an easy guess-and-check algorithm that runs in polynomial time. We proceed to give further details for the above crucial property.


\medskip
\noindent
\textbf{Proof DAG.} 
We first introduce the notion of proof directed acyclic graph (DAG) of a fact, which is essentially a generalization of the notion of proof tree. Recall that a DAG $G$ is {\em rooted} if it has exactly one node, the {\em root}, with no incoming edges. A node of $G$ is a {\em leaf} if it has no outgoing edges.


\begin{definition}[\textbf{Proof DAG}]\label{def:proof-dag}
	Consider a Datalog program $\dep$, a database $D$ over $\esch{\dep}$, and a fact $\alpha$ over $\sch{\dep}$. 
	%
	A {\em proof DAG of $\alpha$ w.r.t.~$D$ and $\dep$} is a finite labeled rooted DAG $G=(V,E,\lambda)$, with $\lambda : V \ra \base{D,\dep}$, such that:
	\begin{enumerate}
		\item If $v \in V$ is the root, then $\lambda(v) = \alpha$.
		
		\item If $v \in V$ is a leaf, then $\lambda(v) \in D$.
		
		\item If $v \in V$ has $n \geq 1$ outgoing edges $(v,u_1),\ldots,(v,u_n)$, then there is a rule $R_0(\bar x_0)\ \assign\ R_1(\bar x_1),\ldots,R_n(\bar x_n) \in \dep$ and a function $h : \bigcup_{i \in [n]} \bar x_i \ra \ins{C}$ such that $\lambda(v) = R_0(h(\bar x_0))$, and $\lambda(u_i) = R_i(h(\bar x_i))$ for $i \in [n]$. \hfill\markfull
	\end{enumerate} 
\end{definition}


The key difference between a proof tree and a proof DAG is that a proof DAG might reuse nodes to compactly represent a proof tree. This is shown by the following example.

%\footnote{This is analogous to the compact representation Boolean formulas using circuits, where the latter factorizes subformulas in order to compactly encode the original Boolean expression.}


\begin{example}\label{exa:proof-dag}
	Let $Q = (\dep,A)$, where $\dep$ is the program given in Example~\ref{exa:proof-tree}, and let $D$ be the database from Example~\ref{exa:proof-tree}. 
	%
	A simple proof DAG of the fact $A(d)$ w.r.t.~$D$ and $\dep$ is
	
	\centerline{\includegraphics[width=.25\textwidth]{proof-dag-1.pdf}}
	
	\noindent which compactly represents the first proof tree given in Example~\ref{exa:proof-tree}.
	%
	The following is another, slightly more complex, proof DAG of the fact $A(d)$ w.r.t.~$D$ and $\dep$:
	
	\centerline{
		\includegraphics[width=.25\textwidth]{proof-dag-2.pdf}}
	
	\noindent It clearly represents the second proof tree from Example~\ref{exa:proof-tree}. \hfill\markfull
\end{example}


\medskip
\noindent
\textbf{Compact Representation of Proof Trees.} 
%We can now show that a proof tree can be represented as a polynomially-sized proof DAG. 
%Similarly to proof trees, 
Given a proof DAG $G$ (of some fact w.r.t.~some database and Datalog program), we define its {\em support}, denoted $\support{G}$, as the set of facts that label the leaves of $G$. The key result follows:



\begin{comment}
\begin{proposition}\label{pro:characterization-all-trees}
	For every Datalog program $\dep$, there exists a polynomial function $\mathsf{pol}$ such that, for every database $D$ over $\esch{\dep}$ and fact $\alpha$ over $\sch{\dep}$, if there is a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\lfacts{T} = D$, then there is a proof DAG $G = (V,E,\lambda)$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\lfacts{G} = D$ and $|V| \leq \mathsf{pol}(|D|)$.
\end{proposition}
\end{comment}

\def\procharacterizationalltrees{
For a Datalog program $\dep$, there is a polynomial $f$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and $D' \subseteq D$, the following are equivalent:
	\begin{enumerate}
		\item There exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D'$.
		\item There exists a proof DAG $G = (V,E,\lambda)$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{G} = D'$ and $|V| \leq f(|D|)$.
	\end{enumerate}
}

\begin{proposition}\label{pro:characterization-all-trees}
	\procharacterizationalltrees
\end{proposition}


It is easy to show that $(2)$ implies $(1)$ by ``unravelling'' the proof DAG $G$ of $\alpha$ w.r.t.~$D$ and $\dep$ into a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = \support{G}$. 
%More precisely, we go over the nodes of $G$ starting from its root and ending at its leaves using breadth-first search. Whenever we encounter a node $v$ that has $k$ incoming edges, we create $k$ copies of its subDAG. The subDAG of a node $v$ contains $v$ itself and every node reachable from $v$, and an edge $(u_1,u_2)$ if there is an edge $(w_1,w_2)$ in $G$, where $u_1$ is a copy of $w_1$ and $u_2$ is a copy of $w_2$. Note that these copies preserve the labels of the nodes. We then replace each incoming edge of $v$ with an edge to the root of a distinct copy of its subDAG. Note that since $G$ is acyclic, the above operation on $v$ has no impact on the nodes that have been processed before $v$.
%
Now, the direction $(1)$ implies $(2)$ is rather non-trivial and requires a careful construction that converts a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ into a compact proof DAG $G$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = \support{G}$. This construction proceeds in three main steps captured by Lemmas~\ref{lem:depth-reduction},~\ref{lem:scount-reduction}, and~\ref{lem:from-trees-to-dags}.

%whose essence is captured by three technical lemmas (Lemma~\ref{lem:depth-reduction},~\ref{lem:scount-reduction}, and~\ref{lem:from-trees-to-dags}).

\medskip 

$\bullet$ The \textbf{\textit{first step}} is to show that a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$ can be converted into a proof tree $T'$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T'} = D'$ that has ``small'' depth. Let us recall that the {\em depth} of a rooted tree $T$, denoted $\depth{T}$, is the length of the longest path from its root to a leaf node. The corresponding lemma follows:


\def\lemmadepthreduction{
	For each Datalog program $\dep$, there is a polynomial $f$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and $D' \subseteq D$, if there exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$, then there exists also such a proof tree $T'$ with $\depth{T'} \leq f(|D|)$.
}

\begin{lemma}\label{lem:depth-reduction}
\lemmadepthreduction
\end{lemma}

\begin{comment}
\begin{lemma}\label{lem:depth-reduction}
	For a Datalog program $\dep$, there is a polynomial function $f$ such that, for every database $D$ over $\esch{\dep}$ and fact $\alpha$ over $\sch{\dep}$, the following are equivalent:
	\begin{enumerate}
		\item There exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D$.
		
		\item There exists a proof tree $T'$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T'} = D$ and $\depth{T'} \leq f(|D|)$.
	\end{enumerate}
\end{lemma}
\end{comment}

\smallskip 

$\bullet$ The \textbf{\textit{second step}} consists of proving that a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$ of ``small'' depth can be converted into a proof tree $T'$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T'} = D'$ of ``small'' subtree count.
%
Roughly speaking, the subtree count of a proof tree $T$ is the maximum number of different (w.r.t.~node-labels) subtrees of $T$ rooted at nodes with the same label. Let us formalize this notion.


Two rooted trees $T=(V,E,\lambda)$ and $T' = (V',E',\lambda')$ are {\em isomorphic}, denoted $T \eqtree T'$, if there is a bijection $h : V \ra V'$ such that, for each node $v \in V$, $\lambda(v) = \lambda'(h(v))$, and for each two nodes $u,v \in V$, $(u,v) \in E$ iff $(h(u),h(v)) \in E'$. It is clear that $\eqtree$ is an equivalence relation over the set of all rooted trees.
%
We further write $T[\alpha]$, for a fact $\alpha$, to denote the set of all subtrees of $T$ whose root is labeled with $\alpha$, i.e., $T[\alpha] = \{T[v] \mid v \in V \text{ and } \lambda(v) = \alpha\}$ with $T[v]$ being the subtree of $T$ rooted at $v$.
%
Let $\quot{T[\alpha]}$ be the quotient set of $T[\alpha]$ w.r.t.~$\eqtree$, i.e., the set of all equivalence classes of $T[\alpha]$ w.r.t.~$\eqtree$. In other words, each member of $\quot{T[\alpha]}$ is a maximal set of trees of $T[\alpha]$ that are labeled in exactly the same way.
%
Then, the {\em subtree count} of $T$, denoted $\scount{T}$, is $\max_{\alpha \in \{\lambda(v) \mid v \in V\}} \{|\quot{T[\alpha]}|\}$.
%
The key lemma follows:
%corresponding technical lemma follows:

\def\lemmascountreduction{
    For each Datalog program $\dep$ and a polynomial $f$, there is a polynomial $g$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$ over $\sch{\dep}$, and $D' \subseteq D$, if there exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D'$ and $\depth{T} \leq f(|D|)$, then there exists also such a proof tree $T'$ with $\scount{T'} \leq g(|D|)$.
}

\begin{lemma}\label{lem:scount-reduction}
	\lemmascountreduction
\end{lemma}

\begin{comment}
\begin{lemma}\label{lem:scount-reduction}
	For a Datalog program $\dep$ and a polynomial function $f$, there exists a polynomial function $g$ such that, for every database $D$ over $\esch{\dep}$ and fact $\alpha$ over $\sch{\dep}$, the following are equivalent:
	\begin{enumerate}
		\item There exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D$ and $\depth{T} \leq f(|D|)$.
		
		\item There exists a proof tree $T'$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T'} = D$ and $\scount{T'} \leq g(|D|)$.
	\end{enumerate}
\end{lemma}
\end{comment}


\smallskip

$\bullet$ The \textbf{\textit{third step}} shows that a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$ of ``small'' subtree count can be converted into a compact proof DAG $G$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{G} = D'$. Here is the corresponding lemma:

\def\lemmafromtreestodags{
	For each Datalog program $\dep$ and a polynomial $f$, there is a polynomial $g$ such that, for every database $D$ over $\esch{\dep}$, fact $\alpha$, and $D' \subseteq D$, if there is a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{T} = D'$ and $\scount{T} \leq f(|D|)$, then there exists a proof DAG $G = (V,E,\lambda)$ of $\alpha$ w.r.t.~$D$ and $\dep$ with $\support{G} = D'$ and $|V| \leq g(|D|)$.
}

\begin{lemma}\label{lem:from-trees-to-dags}
\lemmafromtreestodags
\end{lemma}

\begin{comment}
\begin{lemma}\label{lem:from-trees-to-dags}
	For a Datalog program $\dep$ and a polynomial function $f$, there exists a polynomial function $g$ such that, for every database $D$ over $\esch{\dep}$ and fact $\alpha$ over $\sch{\dep}$, the following are equivalent:
	\begin{enumerate}
		\item There exists a proof tree $T$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D$ and $\scount{T} \leq f(|D|)$.
		
		\item There exists a proof DAG $G = (V,E,\lambda)$ of $\alpha$ w.r.t.~$D$ and $\dep$ such that $\support{G} = D$ and $|V| \leq f(|D|)$.
	\end{enumerate}
\end{lemma}
\end{comment}

\medskip

It is now clear that the direction (1) implies (2) of Proposition~\ref{pro:characterization-all-trees} is an immediate consequence of Lemmas~\ref{lem:depth-reduction},~\ref{lem:scount-reduction} and~\ref{lem:from-trees-to-dags}.
%in fact, we simply need to chain the implications established by those three technical lemmas.


\begin{comment}
\medskip
\noindent
\textbf{Finalize the Proof.} Fix a Datalog query $Q = (\dep,R)$. Given a database $D$ over $\esch{\dep}$, a tuple $\bar t \in \adom{D}^{\arity{R}}$, and a subset $D'$ of $D$, to decide whether $D' \in \why{\bar t}{D}{Q}$ we simply need to check for the existence of a proof tree $T$ of $R(\bar t)$ w.r.t.~$D$ and $\dep$ such that $\support{T} = D'$. By proposition~\ref{pro:characterization-all-trees}, this is tantamount to the existence of a compact proof DAG $G$ of $R(\bar t)$ w.r.t.~$D$ and $\dep$ with $\support{G} = D'$.
%
It is clear that the existence of such a proof DAG can be checked by simply guessing a polynomially-sized (w.r.t.~$|D|$) labeled directed graph $G = (V,E,
\lambda)$, and then checking whether $G$ is acyclic, rooted, and a proof DAG of $R(\bar t)$ w.r.t.~$D$ and $\dep$ with $\support{G} = D'$. Since both steps can be carried out in polynomial time, $\mathsf{Why\text {-}Provenance}[Q]$ is in \NP, and thus, $\mathsf{Why\text {-}Provenance[\DAT]}$ is in \NP~in data complexity.
\end{comment}



\begin{comment}
\medskip

\noindent \underline{\textbf{Lower Bound}}
\smallskip

\noindent We proceed to establish that $\mathsf{Why\text {-}Provenance[\LDAT]}$ is \NP-hard in data complexity. To this ends, we need to show that there exists a linear Datalog query $Q = (\dep,R)$ such that the problem $\mathsf{Why\text {-}Provenance}[Q]$ is \NP-hard. The proof is via a reduction from $\mathsf{3SAT}$, which takes as input a Boolean formula $\varphi = C_1 \wedge \ldots \wedge C_m$ in 3CNF, where each clause has exactly 3 literals (a Boolean variable $v$ or its negation $\neg v$), and asks whether $\varphi$ is satisfiable.


\medskip
\noindent \textbf{The Linear Datalog Query.}
We start by defining the linear Datalog query $Q = (\dep,R)$. If the name of a variable is not important, then we use $\_$ for a fresh variable occurring only once in $\dep$. By abuse of notation, we use semicolons instead of commas in a tuple expression in order to separate terms with a different semantic meaning. The program $\dep$ follows:
\begin{eqnarray*}
\sigma_1 &:& R(x)\,\, \assign\,\, {\rm Var}(x;z,\_),{\rm Assign}(x,z), \\
\sigma_2 &:& R(x)\,\, \assign\,\, {\rm Var}(x;\_,z), {\rm Assign}(x,z),\\
%\\
\sigma_3 &:& {\rm Assign}(x,y)\,\, \assign\,\, C(x,y;\_,\_;\_,\_),{\rm Assign}(x,y), \\
\sigma_4 &:& {\rm Assign}(x,y)\,\, \assign\,\, C(\_,\_;x,y;\_,\_),{\rm Assign}(x,y), \\
\sigma_5 &:& {\rm Assign}(x,y)\,\, \assign\,\, C(\_,\_;\_,\_;x,y),{\rm Assign}(x,y), \\
%\\
\sigma_6 &:& {\rm Assign}(x,z)\,\, \assign\,\, {\rm Next}(x,y;z,\_),R(y), \\
\sigma_7 &:& {\rm Assign}(x,z)\,\, \assign\,\, {\rm Next}(x,y;\_,z),R(y), \\
%\\
\sigma_8 &:& R(x)\,\, \assign\,\, {\rm Last}(x).
\end{eqnarray*}	
It is easy to verify that $\dep$ is indeed a linear Datalog program.
%
The high-level idea underlying the program $\dep$ is, for each variable $v$ occurring in a given Boolean formula $\varphi$, to non-deterministically assign a value ($0$ or $1$) to $v$, and then check whether the global assignment makes $\varphi$ true.
%
The rules $\sigma_1$ and $\sigma_2$ are responsible for assigning $0$ or $1$ to a variable $v$; the last two positions of the relation ${\rm Var}$ always store the values $0$ and $1$, respectively.
%
The rules $\sigma_3$, $\sigma_4$, and $\sigma_5$ are responsible for checking whether an assignment for a certain variable $v$ makes a literal that mentions $v$ in some clause $C$ (and thus, $C$ itself) true.
%
The rules $\sigma_6$ and $\sigma_7$ are responsible, once we are done with a certain variable $v$, to consider the variable $u$ that comes after $v$; the relation ${\rm Next}$ provides an ordering of the variables in the given 3CNF Boolean formula.
%
Finally, once all the variables of the formula have been considered, $\sigma_8$ brings us to the last variable, which is a dummy one, that indicates the end of the above process.




\medskip
\noindent \textbf{From $\mathsf{3SAT}$ to  $\mathsf{Why\text {-}Provenance}[Q]$.} We now establish that $\mathsf{Why\text {-}Provenance}[Q]$ is \NP-hard by reducing from $\mathsf{3SAT}$.
%
Consider a 3CNF Boolean formula $\varphi = C_1 \wedge \cdots \wedge C_m$ with $n$ Boolean variables $v_1,\ldots,v_n$. For a literal $\ell$, we write $\lvar{\ell}$ for the variable occurring in $\ell$, and $\lsign{\ell}$ for the number $1$ (resp., $0$) if $\ell$ is a variable (resp., the negation of a variable).
%
We define $D_\varphi$ as the database over $\esch{\dep}$
\begin{eqnarray*}
	&& \{{\rm Var}(v_i;0,1) \mid i \in [n]\}\\
	&\cup& \{{\rm Next}(v_i,v_{i+1};0,1) \mid i \in [n-1]\}\\
	&\cup& \{{\rm Next}(v_n,\bullet;0,1), {\rm Last}(\bullet)\}\\
	&\cup& \{C(\lvar{\ell_1},\lsign{\ell_1};\lvar{\ell_2},\lsign{\ell_2};\lvar{\ell_3},\lsign{\ell_3}) \mid \\
	&& \hspace{28mm} (\ell_1 \vee \ell_2 \vee \ell_3) \text{ is a clause of } \varphi \},
\end{eqnarray*}
which essentially stores the clauses of $\varphi$ and provides an ordering of the variables occurring in $\varphi$, with $\bullet$ being a dummy one.
%
We can show the next lemma, which essentially states that the above construction leads to a correct polynomial-time reduction from $\mathsf{3SAT}$ to $\mathsf{Why\text {-}Provenance}[Q]$:

\begin{lemma}\label{lem:reduction-from-3sat}
	%The following hold:
	%\begin{enumerate}
		%\item 
		$D_\varphi$ can be constructed in polynomial time in $\varphi$. Furthermore,
		%\item 
		$\varphi$ is satisfiable iff $D_\varphi \in \why{(v_1)}{D_\varphi}{Q}$.
	%\end{enumerate}
\end{lemma}

By Lemma~\ref{lem:reduction-from-3sat}, $\mathsf{Why\text {-}Provenance}[Q]$ is \NP-hard, and thus, $\mathsf{Why\text {-}Provenance[\LDAT]}$ is \NP-hard in data complexity.
\end{comment}


\subsection{Non-Recursive Queries}
%

We now focus on non-recursive Datalog queries, and show the following about the data complexity of why-provenance:

\def\thenonrecursivecomplexity{
	$\mathsf{Why\text {-}Provenance[\NRDAT]}$ is in $\ACZ$ in data complexity.
}

\begin{theorem}\label{the:non-recursive-complexity}
\thenonrecursivecomplexity
\end{theorem}

The above result is shown via {\em first-order rewritability}, i.e., given a non-recursive Datalog query $Q = (\dep,R)$, we construct a first-order query $Q_{\mi{FO}}$ such that, for every input instance of $\mathsf{Why\text {-}Provenance}[Q]$, namely a database $D$ over $\esch{\dep}$, a tuple $\bar t \in \adom{D}^{\arity{R}}$, and a subset $D'$ of $D$, the fact that $D'$ belongs to $\why{\bar t}{D}{Q}$ is equivalent to the fact that $\bar t$ is an answer to the query $Q_{\mi{FO}}$ over $D'$. Since first-order query evaluation is in $\ACZ$ in data complexity~\cite{Vardi95}, Theorem~\ref{the:non-recursive-complexity} follows.
%
Before delving into the details, let us first recall the basics about first-order queries.


\medskip
\noindent
\textbf{First-Order Queries.}
A {\em first-order (FO)} query $Q$ is an expression of the form $\varphi(\bar x)$, where $\varphi$ is an FO formula, $\bar x$ is a tuple of (not necessarily distinct) variables, and the set of variables occurring in $\bar x$ is precisely the set of free variables of $\varphi$.
%
The {\em answer} to $Q$ over a database $D$ is the set of tuples
$
Q(D) = \{\bar t \in \adom{D}^{|\bar x|} \mid D \models \varphi[\bar x/\bar t]\}, 
$
where $|\bar x|$ denotes the length of $\bar x$, $\varphi[\bar x/\bar t]$ is the sentence obtained after replacing the variables of $\bar x$ with the corresponding constants of $\bar t$, and $\models$ denotes the standard FO entailment. Let $\var{\varphi}$ be the set of variables occurring in $\varphi$.
%
A \emph{conjunctive query (CQ)} is an FO query $\varphi(\bar x)$, where $\varphi$ is of the form $\exists \bar y \, (R_1(\bar x_1) \wedge \cdots \wedge R_n(\bar x_n))$ with $\bar x \cap \bar y = \emptyset$ and $\bar x_i \subseteq \bar x \cup \bar y$.


\medskip
\noindent
\textbf{Some Preparation.} Towards the construction of the desired first-order query, we need some auxiliary notions. The {\em canonical form} of a fact $\alpha$, denoted $\can{\alpha}$, is the atom obtained by replacing each constant $c$ in $\alpha$ with a variable $\vr{c}$, i.e., the name of the variable is uniquely determined by the constant $c$.
%
Given a Datalog query $Q = (\dep,R)$, we say that a labeled rooted tree $T = (V,E,\lambda)$ is a {\em $Q$-tree} if it is the proof tree of some fact $R(\bar t)$ w.r.t.~some database $D$ over $\esch{\dep}$ and $\dep$. The notion of the induced CQ by a $Q$-tree follows:

\begin{definition}[\textbf{Induced CQ}]\label{def:induced-cq}
	Consider a Datalog query $Q = (\dep,R)$ and a $Q$-tree $T  = (V,E,\lambda)$, where $v \in V$ is the root node and $\lambda(v) = R(c_1,\ldots,c_n)$. The {\em CQ induced by $T$}, denoted $\cq{T}$, is the CQ $\varphi_{T}(\vr{c_1},\ldots,\vr{c_n})$ with 
	%$\varphi_T$ being the FO formula
	\[
	\varphi_T\ =\ \exists \bar x \left( \bigwedge_{\alpha \in \support{T}} \can{\alpha}\right),
	\]
	where $\bar x$ consists of all $\vr{c}$ for $c \in \adom{\support{T}} \setminus \{c_1,\ldots,c_n\}$. We let $\cq{Q} = \{\cq{T} \mid T \text{ is a $Q$-tree}\}$. \hfill\markfull
\end{definition}

In simple words, $\cq{T}$ is the CQ obtained by taking the conjunction of the facts that label the leaves of $T$ in canonical form, and then existentially quantify all the variables apart from those occurring in the canonical form of the fact that labels the root node of $T$.
%
Now, given two CQs $\varphi(\bar x)$ and $\psi(\bar y)$, we write $\varphi(\bar x) \eqtree \psi(\bar y)$ if they are isomorphic.
%if they are the same up to variable renaming. 
Clearly, $\approx$ is an equivalence relation over the set of CQs.
%
For a Datalog query $Q$, $\cq{Q}_{/\approx}$ is the quotient set of $\cq{Q}$ w.r.t.~$\approx$, i.e., the set of all equivalence classes of $\cq{Q}$ w.r.t.~$\approx$. Let $\cqeq{Q}$ be the set of CQs that keeps one arbitrary representative from each member of $\cq{Q}_{/\approx}$ .
%
Then:
%It is easy to show that:

\begin{lemma}\label{lem:finitely-many-cqs}
	For every non-recursive Datalog query $Q$, it holds that $\cqeq{Q}$ is finite.
\end{lemma}

\medskip
\noindent
\textbf{First-Order Rewriting.} Having $\cqeq{Q}$ in place for a non-recursive Datalog query $Q = (\dep,R)$, we can now proceed with the construction of the desired FO query $Q_{\mi{FO}}$.


We start by constructing, for a CQ $\varphi(\bar y) \in \cqeq{Q}$, an FO query $Q_{\varphi(\bar y)} = \psi_{\varphi(\bar y)}(x_1,\ldots,x_{\arity{R}})$, where $x_1,\ldots,x_{\arity{R}}$ are distinct variables that do not occur in any of the CQs of $\cqeq{Q}$, with the following property: for every database $D$ and tuple $\bar t \in \adom{D}^{\arity{R}}$, $\bar t \in Q_{\varphi(\bar y)}(D)$ iff $\bar t$ is an answer to $\varphi(\bar y)$ over $D$, and, in addition, {\em all} the atoms of $D$ are used in order to entail the sentence $\varphi[\bar y/\bar t]$, i.e., there are no other facts in $D$ besides the ones that have been used as witnesses for the atoms occurring in $\varphi[\bar y/\bar t]$.
%
Assume that $\varphi$ is of the form $\exists \bar z \, (R_1(\bar w_1) \wedge \cdots \wedge R_n(\bar w_n))$. The formula $\psi_{\varphi(\bar y)}$, with free variables $x_1,\ldots,x_{\arity{R}}$, is of the form
\[
\exists \bar y \exists \bar z \left(\varphi_1\ \wedge\ \varphi_2\ \wedge\ \varphi_3\right),
\]
where each conjunct is defined as follows. We write $\bar x$ for the tuple $(x_1,\ldots,x_{\arity{R}})$ and $\bar u_P$, where $P$ is a predicate, for the tuple of  variables $(u_1,\ldots,u_{\arity{P}})$. Furthermore, for two tuples of variables $\bar u = (u_1,\ldots,u_k)$ and $\bar v = (v_1,\ldots,v_k)$, $(\bar u = \bar v)$ is a shortcut for $\bigwedge_{i = 1}^{k} (u_i = v_i)$.
%
The formula $\varphi_1$ is
\[
\bigwedge\limits_{i \in [n]}\, R_i(\bar w_i)\ \wedge\ (\bar x = \bar y)\ \wedge\ \bigwedge\limits_{\substack{u,v \in \var{\varphi}, \\ u \neq v}} \neg (u = v)
\]
which states that each atom in $\varphi$ should be satisfied by assigning different values to different variables of $\varphi$.
%
The formula $\varphi_2$ is defined as
\[
\bigwedge\limits_{P \in \{R_1,\ldots,R_n\}} \neg \left(\exists \bar u_{P} \left(P(\bar u_P)\ \wedge\ \bigwedge\limits_{\substack{i \in [n], \\ R_i = P}}\, \neg(\bar w_i = \bar u_P)\right)\right)
\]
which essentially states that, for each predicate $P$ occurring in $\varphi$, the only atoms in the underlying database with predicate $P$ are those used as witnesses for the atoms of $\varphi$.
%
Finally, the formula $\varphi_3$ is defined as
\[
\bigwedge\limits_{P \in \esch{\dep} \setminus \{R_1,\ldots,R_n\}} \neg \left(\exists \bar u_P \, P(\bar u_P)\right)
\]
which expresses that there are no atoms in the underlying database with a predicate that does not appear in $\varphi$.
%
\begin{comment}
\begin{multline*}
\exists \bar y  \exists \bar z\bigg(\bigwedge\limits_{i \in [n]}\, R_i(\bar w_i)\ \wedge\ (\bar x = \bar y)\ \wedge\ \bigwedge\limits_{\substack{u,v \in \var{\varphi}, \\ u \neq v}} \neg (u = v)\ \wedge\\
%
\bigwedge\limits_{P \in \{R_1,\ldots,R_n\}} \neg \left(\exists \bar u_{P} \bigwedge\limits_{\substack{i \in [n], \\ R_i = P}}\, \left(\neg(\bar w_i = \bar u_P)\ \wedge\ P(\bar u_P)\right)\right)\ \wedge \\
\bigwedge\limits_{P \in \esch{\dep} \setminus \{R_1,\ldots,R_n\}} \neg \left(\exists \bar u_P \, P(\bar u_P)\right)\bigg),
\end{multline*}
where, for two tuples of variables $\bar u = (u_1,\ldots,u_k)$ and $\bar v = (v_1,\ldots,v_k)$, $(\bar u = \bar v)$ is $\bigwedge_{i = 1}^{k} (u_i = v_i)$.
\end{comment}


With the FO query $Q_{\varphi(\bar y)}$ for each CQ $\varphi(\bar y) \in \cqeq{Q}$ in place, it should be clear that the desired FO query $Q_{\mi{FO}}$ is defined as $\Phi(x_1\ldots,x_{\arity{R}})$, where $\Phi = \bigvee_{\varphi(\bar y) \in \cqeq{Q}} \psi_{\varphi(\bar y)}$ and the next technical result follows:


\def\lemmaforewriting{
		Given a non-recursive Datalog query $Q=(\dep,R)$, a database $D$ over $\esch{\dep}$, $\bar t \in \adom{D}^{\arity{R}}$, and $D' \subseteq D$, it holds that $D' \in \why{\bar t}{D}{Q}$ iff $\bar t \in Q_{\mi{FO}}(D')$.
}
\begin{lemma}\label{lem:fo-tree-equiv}
	\lemmaforewriting
\end{lemma}


%Consider a non-recursive Datalog query $Q$. By Lemma~\ref{lem:finitely-many-cqs} we get that $Q_{\mi{FO}}$ is finite, while by Lemma~\ref{lem:fo-tree-equiv} we have that $Q_{\mi{FO}}$ is correct for our purposes. Since FO query evaluation is in $\ACZ$ in data complexity, Theorem~\ref{the:non-recursive-complexity} follows. 


\begin{comment}
\begin{theorem}\label{the:complexity}
	The following hold:
	\begin{enumerate}
		\item $\mathsf{Why\text {-}Provenance[C]}$ is \NP-complete in data complexity, for each class $\class{C} \in \{\DAT,\LDAT\}$.
		
		\item $\mathsf{Why\text {-}Provenance[\NRDAT]}$ is in $\ACZ$ in data complexity.
	\end{enumerate}
\end{theorem}
\end{comment}


\subsection{Refined Proof Trees}\label{sec:refined-trees}
%

The standard notion of why-provenance
%, defined in Section~\ref{sec:why-provenance} and analyzed above, 
relies on arbitrary proof trees without any restriction. 
%Indeed, a subset of the input database $D$ belongs to the why-provenance of a tuple $\bar t$ w.r.t.~$D$ and a Datalog query $Q = (\dep,R)$ as long as it is the support of {\em some} proof tree of $R(\bar t)$ w.r.t.~$D$ and $\dep$.
%
However, as already discussed in the literature (see, e.g., the recent work~\cite{BBPT22}), there are proof trees that are counterintuitive. Such a proof tree, for instance, is the second one in Example~\ref{exa:proof-tree} as the fact $A(a)$ is derived from itself.
%
Now, a member $D'$ of $\why{\bar t}{D}{Q}$, witnessed via such an unnatural proof tree, might be classified as a counterintuitive explanation of $\bar t$ as it does not correspond to an intuitive derivation process, which can be extracted from the proof tree, that leads from $D'$ to the fact $R(\bar t)$.
%
%For instance, coming back to Example~\ref{exa:proof-tree}, the derivation process that starts from the whole database, which belongs to the why-provenance due to the problematic proof tree mentioned above, and leads to the target fact, uses $A(a)$ to derive it self. 
This leads to the need of considering refined classes of proof trees that overcome the conceptual limitations of arbitrary proof trees.
%, which in turn lead to conceptually intuitive explanations.
%
Two well-justified notions considered in the literature are {\em non-recursive proof trees} and {\em minimal-depth proof trees}~\cite{BBPT22}. Roughly, a non-recursive proof tree is a proof tree that does not contain two nodes labeled with the same fact and such that one is the descendant of the other, whereas a minimal-depth proof tree is a proof tree that has the minimum depth among all the proof trees of a certain tuple.
%
We analyzed the data complexity of why-provenance focusing only on proof trees from those refined classes, and proved that it remains unchanged. Due to space constraints, we omit the details that can be found in the extended version of the paper.

