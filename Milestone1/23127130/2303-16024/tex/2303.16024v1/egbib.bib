@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{jiang2022egocentricdeep,
  title={Egocentric Deep Multi-Channel Audio-Visual Active Speaker Localization},
  author={Jiang, Hao and Murdock, Calvin and Ithapu, Vamsi Krishna},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10544--10552},
  year={2022}
}

@inproceedings{Tao2021SomeoneSpeaking,
  title={Is someone speaking? exploring long-term temporal features for audio-visual active speaker detection},
  author={Tao, Ruijie and Pan, Zexu and Das, Rohan Kumar and Qian, Xinyuan and Shou, Mike Zheng and Li, Haizhou},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={3927--3935},
  year={2021}
}

@article{LookWhosTalking,
    title={Look Who's Talking: Active Speaker Detection in the Wild},
  author={Kim, You Jin and Heo, Hee-Soo and Choe, Soyeon and Chung, Soo-Whan and Kwon, Yoohwan and Lee, Bong-Jin and Kwon, Youngki and Chung, Joon Son},
  journal={arXiv preprint arXiv:2108.07640},
  year={2021}
}

@inproceedings{Truong2021RightToTalk,
  title={The right to talk: An audio-visual transformer approach},
  author={Truong, Thanh-Dat and Duong, Chi Nhan and Pham, Hoang Anh and Raj, Bhiksha and Le, Ngan and Luu, Khoa and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1105--1114},
  year={2021}
}

@InProceedings{Alcazar_2020_CVPR,
author = {Alcazar, Juan Leon and Caba, Fabian and Mai, Long and Perazzi, Federico and Lee, Joon-Young and Arbelaez, Pablo and Ghanem, Bernard},
title = {Active Speakers in Context},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{AlcazarMaas,
  title={Maas: Multi-modal assignation for active speaker detection},
  author={Alc{\'a}zar, Juan Le{\'o}n and Caba, Fabian and Thabet, Ali K and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={265--274},
  year={2021}
}

@article{Zhang2019MultiTaskLF,
  title={Multi-task learning for audio-visual active speaker detection},
  author={Zhang, Yuan-Hang and Xiao, Jingyun and Yang, Shuang and Shan, Shiguang},
  journal={The ActivityNet Large-Scale Activity Recognition Challenge},
  pages={1--4},
  year={2019}
}

@inproceedings{GebruClustering,
  title={Audio-visual speaker localization via weighted clustering},
  author={Gebru, Israel D and Alameda-Pineda, Xavier and Horaud, Radu and Forbes, Florence},
  booktitle={2014 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2014},
  organization={IEEE}
}

@article{Min2022LearningLS,
  title={Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection},
  author={Min, Kyle and Roy, Sourya and Tripathi, Subarna and Guha, Tanaya and Majumdar, Somdeb},
  journal={arXiv preprint arXiv:2207.07783},
  year={2022}
}

@article{Xiong2022LookListenMC,
  title={Look\&Listen: Multi-Modal Correlation Learning for Active Speaker Detection and Speech Enhancement},
  author={Jun Xiong and Yu Zhou and Peng Zhang and Lei Xie and Wei Huang and Yufei Zha},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.02216}
}
@article{Alcazar2022EndtoEndAS,
  title={End-to-End Active Speaker Detection},
  author={Alcazar, Juan Leon and Cordes, Moritz and Zhao, Chen and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2203.14250},
  year={2022}
}

@inproceedings{AVAActiveSpeaker,
  title={Ava active speaker: An audio-visual dataset for active speaker detection},
  author={Roth, Joseph and Chaudhuri, Sourish and Klejch, Ondrej and Marvin, Radhika and Gallagher, Andrew and Kaver, Liat and Ramaswamy, Sharadh and Stopczynski, Arkadiusz and Schmid, Cordelia and Xi, Zhonghua and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4492--4496},
  year={2020},
  organization={IEEE}
}

@article{EasyCom,
  title={Easycom: An augmented reality dataset to support algorithms for easy communication in noisy environments},
  author={Donley, Jacob and Tourbabin, Vladimir and Lee, Jung-Suk and Broyles, Mark and Jiang, Hao and Shen, Jie and Pantic, Maja and Ithapu, Vamsi Krishna and Mehra, Ravish},
  journal={arXiv preprint arXiv:2107.04174},
  year={2021}
}

@article{Biesmans2016,
  title={Auditory-inspired speech envelope extraction methods for improved EEG-based auditory attention detection in a cocktail party scenario},
  author={Biesmans, Wouter and Das, Neetha and Francart, Tom and Bertrand, Alexander},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume={25},
  number={5},
  pages={402--412},
  year={2016},
  publisher={IEEE}
}

@article{Bleichner2016,
  title={Identifying auditory attention with ear-EEG: cEEGrid versus high-density cap-EEG comparison},
  author={Bleichner, Martin G and Mirkovic, Bojana and Debener, Stefan},
  journal={Journal of neural engineering},
  volume={13},
  number={6},
  pages={066004},
  year={2016},
  publisher={IOP Publishing}
}

@article{Horton2014,
  title={Envelope responses in single-trial EEG indicate attended speaker in a ‘cocktail party’},
  author={Horton, Cort and Srinivasan, Ramesh and D’Zmura, Michael},
  journal={Journal of neural engineering},
  volume={11},
  number={4},
  pages={046015},
  year={2014},
  publisher={IOP Publishing}
}

@article{Bednar2020,
  title={Where is the cocktail party? Decoding locations of attended and unattended moving sound sources using EEG},
  author={Bednar, Adam and Lalor, Edmund C},
  journal={NeuroImage},
  volume={205},
  pages={116283},
  year={2020},
  publisher={Elsevier}
}

@article{Sahar2015,
  title={Robust decoding of selective auditory attention from MEG in a competing-speaker environment via state-space modeling},
  author={Akram, Sahar and Presacco, Alessandro and Simon, Jonathan Z and Shamma, Shihab A and Babadi, Behtash},
  journal={NeuroImage},
  volume={124},
  pages={906--917},
  year={2016},
  publisher={Elsevier}
}

@article{Kuruvila2021ExtractingTA,
  title={Extracting the auditory attention in a dual-speaker scenario from EEG using a joint CNN-LSTM model},
  author={Kuruvila, Ivine and Muncke, Jan and Fischer, Eghart and Hoppe, Ulrich},
  journal={Frontiers in Physiology},
  volume={12},
  year={2021},
  publisher={Frontiers Media SA}
}

@article{Geravanchizadeh2021,
  title={Dynamic selective auditory attention detection using RNN and reinforcement learning},
  author={Geravanchizadeh, Masoud and Roushan, Hossein},
  journal={Scientific Reports},
  volume={11},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{LuLSTM,
  title={Sound Source Selection Based on Head Movements in Natural Group Conversation},
  author={Lu, Hao and Brimijoin, W Owen},
  journal={Trends in Hearing},
  volume={26},
  pages={23312165221097789},
  year={2022},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{ASDTransformer,
  title={Asd-Transformer: Efficient Active Speaker Detection Using Self And Multimodal Transformers},
  author={Datta, Gourav and Etchart, Tyler and Yadav, Vivek and Hedau, Varsha and Natarajan, Pradeep and Chang, Shih-Fu},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4568--4572},
  year={2022},
  organization={IEEE}
}

  
@article{Ego4D,
  title={Ego4D: Around the World in 3,000 Hours of Egocentric Video},
  author={Kristen Grauman and Andrew Westbury and Eugene Byrne and Zachary Q. Chavis and Antonino Furnari and Rohit Girdhar and Jackson Hamburger and Hao Jiang and Miao Liu and Xingyu Liu and Miguel Martin and Tushar Nagarajan and Ilija Radosavovic and Santhosh K. Ramakrishnan and Fiona Ryan and Jayant Sharma and Michael Wray and Mengmeng Xu and Eric Z. Xu and Chen Zhao and Siddhant Bansal and Dhruv Batra and Vincent Cartillier and Sean Crane and Tien Do and Morrie Doulaty and Akshay Erapalli and Christoph Feichtenhofer and Adriano Fragomeni and Qichen Fu and Christian Fuegen and Abrham Gebreselasie and Cristina Gonz{\'a}lez and James M. Hillis and Xuhua Huang and Yifei Huang and Wenqi Jia and Weslie Yu Heng Khoo and J{\'a}chym Kol{\'a}r and Satwik Kottur and Anurag Kumar and Federico Landini and Chao Li and Yanghao Li and Zhenqiang Li and Karttikeya Mangalam and Raghava Modhugu and Jonathan Munro and Tullie Murrell and Takumi Nishiyasu and Will Price and Paola Ruiz Puentes and Merey Ramazanova and Leda Sari and Kiran K. Somasundaram and Audrey Southerland and Yusuke Sugano and Ruijie Tao and Minh Vo and Yuchen Wang and Xindi Wu and Takuma Yagi and Yunyi Zhu and Pablo Arbel{\'a}ez and David J. Crandall and Dima Damen and Giovanni Maria Farinella and Bernard Ghanem and Vamsi Krishna Ithapu and C. V. Jawahar and Hanbyul Joo and Kris Kitani and Haizhou Li and Richard A. Newcombe and Aude Oliva and Hyun Soo Park and James M. Rehg and Yoichi Sato and Jianbo Shi and Mike Zheng Shou and Antonio Torralba and Lorenzo Torresani and Mingfei Yan and Jitendra Malik},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  pages={18973-18990}
}

@inproceedings{AlNaser2019OGazeGP,
  title={OGaze: Gaze Prediction in Egocentric Videos for Attentional Object Selection},
  author={Al-Naser, Mohammad and Siddiqui, Shoaib Ahmed and Ohashi, Hiroki and Ahmed, Sheraz and Katsuyki, Nakamura and Takuto, Sato and Dengel, Andreas},
  booktitle={2019 Digital Image Computing: Techniques and Applications (DICTA)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{Huang2018PredictingGI,
  title={Predicting gaze in egocentric video by learning task-dependent attention transition},
  author={Huang, Yifei and Cai, Minjie and Li, Zhenqiang and Sato, Yoichi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={754--769},
  year={2018}
}

@article{HuangMutual,
  title={Mutual context network for jointly estimating egocentric gaze and action},
  author={Huang, Yifei and Cai, Minjie and Li, Zhenqiang and Lu, Feng and Sato, Yoichi},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={7795--7806},
  year={2020},
  publisher={IEEE}
}

@inproceedings{LiEgocentric2013,
  title={Learning to predict gaze in egocentric video},
  author={Li, Yin and Fathi, Alireza and Rehg, James M},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3216--3223},
  year={2013}
}

@article{LiBeholder2021,
  title={In the eye of the beholder: Gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, James},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2021},
  publisher={IEEE}
}

@inproceedings{Tavakoli2019DiggingDI,
  title={Digging deeper into egocentric gaze prediction},
  author={Tavakoli, Hamed Rezazadegan and Rahtu, Esa and Kannala, Juho and Borji, Ali},
  booktitle={2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={273--282},
  year={2019},
  organization={IEEE}
}

@inproceedings{Thakur2021,
  title={Predicting Gaze from Egocentric Social Interaction Videos and IMU Data},
  author={Thakur, Sanket Kumar and Beyan, Cigdem and Morerio, Pietro and Del Bue, Alessio},
  booktitle={Proceedings of the 2021 International Conference on Multimodal Interaction},
  pages={717--722},
  year={2021}
}

@article{Lai2022,
  title={In the Eye of Transformer: Global-Local Correlation for Egocentric Gaze Estimation},
  author={Lai, Bolin and Liu, Miao and Ryan, Fiona and Rehg, James},
  journal={arXiv preprint arXiv:2208.04464},
  year={2022}
}

@article{Vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6836--6846},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{ng2022learning,
  title={Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion},
  author={Ng, Evonne and Joo, Hanbyul and Hu, Liwen and Li, Hao and Darrell, Trevor and Kanazawa, Angjoo and Ginosar, Shiry},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20395--20405},
  year={2022}
}

@inproceedings{aghaei2016whom,
  title={With whom do I interact? Detecting social interactions in egocentric photo-streams},
  author={Aghaei, Maedeh and Dimiccoli, Mariella and Radeva, Petia},
  booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
  pages={2959--2964},
  year={2016},
  organization={IEEE}
}

@inproceedings{fathi2012social,
  title={Social interactions: A first-person perspective},
  author={Fathi, Alircza and Hodgins, Jessica K and Rehg, James M},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1226--1233},
  year={2012},
  organization={IEEE}
}

@inproceedings{kopuklu2021design,
  title={How to design a three-stage architecture for audio-visual active speaker detection in the wild},
  author={K{\"o}p{\"u}kl{\"u}, Okan and Taseska, Maja and Rigoll, Gerhard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1193--1203},
  year={2021}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{cutler2000look,
  title={Look who's talking: Speaker detection using video and audio correlation},
  author={Cutler, Ross and Davis, Larry},
  booktitle={2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No. 00TH8532)},
  volume={3},
  pages={1589--1592},
  year={2000},
  organization={IEEE}
}

@inproceedings{saenko2005visual,
  title={Visual speech recognition with loosely synchronized feature streams},
  author={Saenko, Kate and Livescu, Karen and Siracusa, Michael and Wilson, Kevin and Glass, James and Darrell, Trevor},
  booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
  volume={2},
  pages={1424--1431},
  year={2005},
  organization={IEEE}
}

@article{everingham2009taking,
  title={Taking the bite out of automated naming of characters in TV video},
  author={Everingham, Mark and Sivic, Josef and Zisserman, Andrew},
  journal={Image and Vision Computing},
  volume={27},
  number={5},
  pages={545--559},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{chakravarty2015s,
  title={Who's speaking? audio-supervised classification of active speakers in video},
  author={Chakravarty, Punarjay and Mirzaei, Sayeh and Tuytelaars, Tinne and Van hamme, Hugo},
  booktitle={Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  pages={87--90},
  year={2015}
}

@article{pu2020active,
  title={Active Speaker Detection and Localization in Videos Using Low-Rank and Kernelized Sparsity},
  author={Pu, Jie and Panagakis, Yannis and Pantic, Maja},
  journal={IEEE Signal Processing Letters},
  volume={27},
  pages={865--869},
  year={2020},
  publisher={IEEE}
}

@inproceedings{wissing2021data,
  title={Data Fusion for Audiovisual Speaker Localization: Extending Dynamic Stream Weights to the Spatial Domain},
  author={Wissing, Julio and Boenninghoff, Benedikt and Kolossa, Dorothea and Ochiai, Tsubasa and Delcroix, Marc and Kinoshita, Keisuke and Nakatani, Tomohiro and Araki, Shoko and Schymura, Christopher},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4705--4709},
  year={2021},
  organization={IEEE}
}

@article{bano2018multimodal,
  title={Multimodal egocentric analysis of focused interactions},
  author={Bano, Sophia and Suveges, Tamas and Zhang, Jianguo and Mckenna, Stephen J},
  journal={IEEE Access},
  volume={6},
  pages={37493--37505},
  year={2018},
  publisher={IEEE}
}

@article{ban2019variational,
  title={Variational bayesian inference for audio-visual tracking of multiple speakers},
  author={Ban, Yutong and Alameda-Pineda, Xavier and Girin, Laurent and Horaud, Radu},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={5},
  pages={1761--1776},
  year={2019},
  publisher={IEEE}
}

@article{gatica2007audiovisual,
  title={Audiovisual probabilistic tracking of multiple speakers in meetings},
  author={Gatica-Perez, Daniel and Lathoud, Guillaume and Odobez, Jean-Marc and McCowan, Iain},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={15},
  number={2},
  pages={601--616},
  year={2007},
  publisher={IEEE}
}

@article{zhang2008boosting,
  title={Boosting-based multimodal speaker detection for distributed meeting videos},
  author={Zhang, Cha and Yin, Pei and Rui, Yong and Cutler, Ross and Viola, Paul and Sun, Xinding and Pinto, Nelson and Zhang, Zhengyou},
  journal={IEEE Transactions on Multimedia},
  volume={10},
  number={8},
  pages={1541--1552},
  year={2008},
  publisher={IEEE}
}

@inproceedings{haider2012towards,
  title={Towards speaker detection using lips movements for humanmachine multiparty dialogue},
  author={Haider, Fasih and Al Moubayed, Samer},
  booktitle={The XXVth Swedish Phonetics Conference (FONETIK)},
  pages={117--120},
  year={2012},
  organization={Citeseer}
}

@inproceedings{alameda2011finding,
  title={Finding audio-visual events in informal social gatherings},
  author={Alameda-Pineda, Xavier and Khalidov, Vasil and Horaud, Radu and Forbes, Florence},
  booktitle={Proceedings of the 13th international conference on multimodal interfaces},
  pages={247--254},
  year={2011}
}

@article{alickovic2019tutorial,
  title={A tutorial on auditory attention identification methods},
  author={Alickovic, Emina and Lunner, Thomas and Gustafsson, Fredrik and Ljung, Lennart},
  journal={Frontiers in neuroscience},
  pages={153},
  year={2019},
  publisher={Frontiers}
}

@article{ding2012emergence,
  title={Emergence of neural encoding of auditory objects while listening to competing speakers},
  author={Ding, Nai and Simon, Jonathan Z},
  journal={Proceedings of the National Academy of Sciences},
  volume={109},
  number={29},
  pages={11854--11859},
  year={2012},
  publisher={National Acad Sciences}
}

@article{mesgarani2012selective,
  title={Selective cortical representation of attended speaker in multi-talker speech perception},
  author={Mesgarani, Nima and Chang, Edward F},
  journal={Nature},
  volume={485},
  number={7397},
  pages={233--236},
  year={2012},
  publisher={Nature Publishing Group}
}

@article{mirkovic2015decoding,
  title={Decoding the attended speech stream with multi-channel EEG: implications for online, daily-life applications},
  author={Mirkovic, Bojana and Debener, Stefan and Jaeger, Manuela and De Vos, Maarten},
  journal={Journal of neural engineering},
  volume={12},
  number={4},
  pages={046007},
  year={2015},
  publisher={IOP Publishing}
}

@article{o2015attentional,
  title={Attentional selection in a cocktail party environment can be decoded from single-trial EEG},
  author={O'Sullivan, James A and Power, Alan J and Mesgarani, Nima and Rajaram, Siddharth and Foxe, John J and Shinn-Cunningham, Barbara G and Slaney, Malcolm and Shamma, Shihab A and Lalor, Edmund C},
  journal={Cerebral cortex},
  volume={25},
  number={7},
  pages={1697--1706},
  year={2015},
  publisher={Oxford University Press}
}

@article{o2017neural,
  title={Neural decoding of attentional selection in multi-speaker environments without access to clean sources},
  author={O’Sullivan, James and Chen, Zhuo and Herrero, Jose and McKhann, Guy M and Sheth, Sameer A and Mehta, Ashesh D and Mesgarani, Nima},
  journal={Journal of neural engineering},
  volume={14},
  number={5},
  pages={056001},
  year={2017},
  publisher={IOP Publishing}
}

@article{fuglsang2017noise,
  title={Noise-robust cortical tracking of attended speech in real-world acoustic scenes},
  author={Fuglsang, S{\o}ren Asp and Dau, Torsten and Hjortkj{\ae}r, Jens},
  journal={Neuroimage},
  volume={156},
  pages={435--444},
  year={2017},
  publisher={Elsevier}
}

@article{kaya2017modelling,
  title={Modelling auditory attention},
  author={Kaya, Emine Merve and Elhilali, Mounya},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={372},
  number={1714},
  pages={20160101},
  year={2017},
  publisher={The Royal Society}
}

@article{van2016eeg,
  title={EEG-informed attended speaker extraction from recorded speech mixtures with application in neuro-steered hearing prostheses},
  author={Van Eyndhoven, Simon and Francart, Tom and Bertrand, Alexander},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={64},
  number={5},
  pages={1045--1056},
  year={2016},
  publisher={IEEE}
}

@article{haghighi2018eeg,
  title={EEG-assisted modulation of sound sources in the auditory scene},
  author={Haghighi, Marzieh and Moghadamfalahi, Mohammad and Akcakaya, Murat and Erdogmus, Deniz},
  journal={Biomedical signal processing and control},
  volume={39},
  pages={263--270},
  year={2018},
  publisher={Elsevier}
}

@article{akram2016robust,
  title={Robust decoding of selective auditory attention from MEG in a competing-speaker environment via state-space modeling},
  author={Akram, Sahar and Presacco, Alessandro and Simon, Jonathan Z and Shamma, Shihab A and Babadi, Behtash},
  journal={NeuroImage},
  volume={124},
  pages={906--917},
  year={2016},
  publisher={Elsevier}
}
@article{kayser2005mechanisms,
  title={Mechanisms for allocating auditory attention: an auditory saliency map},
  author={Kayser, Christoph and Petkov, Christopher I and Lippert, Michael and Logothetis, Nikos K},
  journal={Current biology},
  volume={15},
  number={21},
  pages={1943--1947},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{kalinli2007saliency,
  title={A saliency-based auditory attention model with applications to unsupervised prominent syllable detection in speech.},
  author={Kalinli, Ozlem and Narayanan, Shrikanth S},
  booktitle={INTERSPEECH},
  pages={1941--1944},
  year={2007}
}

@inproceedings{duangudom2007using,
  title={Using auditory saliency to understand complex auditory scenes},
  author={Duangudom, Varinthira and Anderson, David V},
  booktitle={2007 15th European Signal Processing Conference},
  pages={1206--1210},
  year={2007},
  organization={IEEE}
}

@inproceedings{kaya2012temporal,
  title={A temporal saliency map for modeling auditory attention},
  author={Kaya, Emine Merve and Elhilali, Mounya},
  booktitle={2012 46th Annual Conference on Information Sciences and Systems (CISS)},
  pages={1--6},
  year={2012},
  organization={IEEE}
}

@article{kaya2014investigating,
  title={Investigating bottom-up auditory attention},
  author={Kaya, Emine Merve and Elhilali, Mounya},
  journal={Frontiers in human neuroscience},
  volume={8},
  pages={327},
  year={2014},
  publisher={Frontiers Media SA}
}

@article{kim2014automatic,
  title={Automatic detection of auditory salience with optimized linear filters derived from human annotation},
  author={Kim, Kyungtae and Lin, Kai-Hsiang and Walther, Dirk B and Hasegawa-Johnson, Mark A and Huang, Tomas S},
  journal={Pattern Recognition Letters},
  volume={38},
  pages={78--85},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{tordini2013toward,
  title={Toward an improved model of auditory saliency},
  author={Tordini, Francesco and Bregman, Albert S and Cooperstock, Jeremy R and Ankolekar, Anupryia and Sandholm, Thomas},
  year={2013},
  organization={Georgia Institute of Technology}
}

@inproceedings{tordini2015loud,
  title={The loud bird doesn’t (always) get the worm: Why computational salience also needs brightness and tempo},
  author={Tordini, Francesco and Bregman, Albert S and Cooperstock, Jeremy R},
  year={2015},
  organization={Georgia Institute of Technology}
}

@article{kothinti2021auditory,
  title={Auditory salience using natural scenes: An online study},
  author={Kothinti, Sandeep Reddy and Huang, Nicholas and Elhilali, Mounya},
  journal={The Journal of the Acoustical Society of America},
  volume={150},
  number={4},
  pages={2952--2966},
  year={2021},
  publisher={Acoustical Society of America}
}

@article{chung2020spot,
  title={Spot the conversation: speaker diarisation in the wild},
  author={Chung, Joon Son and Huh, Jaesung and Nagrani, Arsha and Afouras, Triantafyllos and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2007.01216},
  year={2020}
}

@article{kraaij2005ami,
  title={The AMI meeting corpus},
  author={Kraaij, Wessel and Hain, Thomas and Lincoln, Mike and Post, Wilfried},
  year={2005}
}

@article{VTCKveaux2017cstr,
  title={CSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit},
  author={Veaux, Christophe and Yamagishi, Junichi and MacDonald, Kirsten and others},
  journal={University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year={2017}
}


%%%%%%%%%%%% audiovisual representation %%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Jansen2020CoincidenceCA,
  title={Coincidence, Categorization, and Consolidation: Learning to Recognize Sounds with Minimal Supervision},
  author={Aren Jansen and Daniel P. W. Ellis and Shawn Hershey and R. Channing Moore and Manoj Plakal and Ashok Popat and Rif A. Saurous},
  journal={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2020},
  pages={121-125}
}

@inproceedings{owens2016ambient,
  title={Ambient sound provides supervision for visual learning},
  author={Owens, Andrew and Wu, Jiajun and McDermott, Josh H and Freeman, William T and Torralba, Antonio},
  booktitle={European conference on computer vision},
  pages={801--816},
  year={2016},
  organization={Springer}
}

@inproceedings{owens2018audio,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={631--648},
  year={2018}
}

@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24206--24221},
  year={2021}
}

@article{alayrac2020self,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={25--37},
  year={2020}
}

@article{korbar2018cooperative,
  title={Cooperative learning of audio and video models from self-supervised synchronization},
  author={Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{patrick2020multi,
  title={Multi-modal self-supervision from generalized data transformations},
  author={Patrick, Mandela and Asano, Yuki M and Kuznetsova, Polina and Fong, Ruth and Henriques, Joao F and Zweig, Geoffrey and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:2003.04298},
  year={2020}
}

@article{alwassel2020self,
  title={Self-supervised learning by cross-modal audio-video clustering},
  author={Alwassel, Humam and Mahajan, Dhruv and Korbar, Bruno and Torresani, Lorenzo and Ghanem, Bernard and Tran, Du},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9758--9770},
  year={2020}
}

@article{nagrani2021attention,
  title={Attention bottlenecks for multimodal fusion},
  author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14200--14213},
  year={2021}
}


%%%%%%%%%%%%%%% localization %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{hu2019deep,
  title={Deep multimodal clustering for unsupervised audiovisual learning},
  author={Hu, Di and Nie, Feiping and Li, Xuelong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9248--9257},
  year={2019}
}

@article{hu2021class,
  title={Class-aware sounding objects localization via audiovisual correspondence},
  author={Hu, Di and Wei, Yake and Qian, Rui and Lin, Weiyao and Song, Ruihua and Wen, Ji-Rong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@article{liu2022visual,
  title={Visual sound localization in the wild by cross-modal interference erasing},
  author={Liu, Xian and Qian, Rui and Zhou, Hang and Hu, Di and Lin, Weiyao and Liu, Ziwei and Zhou, Bolei and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2202.06406},
  volume={2},
  year={2022}
}

@inproceedings{qian2020multiple,
  title={Multiple sound sources localization from coarse to fine},
  author={Qian, Rui and Hu, Di and Dinkel, Heinrich and Wu, Mengyue and Xu, Ning and Lin, Weiyao},
  booktitle={European Conference on Computer Vision},
  pages={292--308},
  year={2020},
  organization={Springer}
}

@inproceedings{senocak2018learning,
  title={Learning to localize sound source in visual scenes},
  author={Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and Kweon, In So},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4358--4366},
  year={2018}
}

@inproceedings{afouras2020self,
  title={Self-supervised learning of audio-visual objects from video},
  author={Afouras, Triantafyllos and Owens, Andrew and Chung, Joon Son and Zisserman, Andrew},
  booktitle={European Conference on Computer Vision},
  pages={208--224},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2021localizing,
  title={Localizing visual sounds the hard way},
  author={Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16867--16876},
  year={2021}
}

@inproceedings{senocak2022learning,
  title={Learning sound localization better from semantically similar samples},
  author={Senocak, Arda and Ryu, Hyeonggon and Kim, Junsik and Kweon, In So},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4863--4867},
  year={2022},
  organization={IEEE}
}


@InProceedings{Arandjelovic_2018_ECCV,
author = {Arandjelovic, Relja and Zisserman, Andrew},
title = {Objects that Sound},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@article{mo2022localizing,
  title={Localizing Visual Sounds the Easy Way},
  author={Mo, Shentong and Morgado, Pedro},
  journal={arXiv preprint arXiv:2203.09324},
  year={2022}
}

@article{northcutt2020egocom,
  title={Egocom: A multi-person multi-modal egocentric communications dataset},
  author={Northcutt, Curtis and Zha, Shengxin and Lovegrove, Steven and Newcombe, Richard},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}

@inproceedings{ego4dshort,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}


%%%%%%%%%%%%% steerable beamformers %%%%%%%%%%%%%%%%%%%%%%%%
@article{favre2018improving,
  title={Improving speech intelligibility by hearing aid eye-gaze steering: Conditions with head fixated in a multitalker environment},
  author={Favre-Felix, Antoine and Graversen, Carina and Hietkamp, Renskje K and Dau, Torsten and Lunner, Thomas},
  journal={Trends in hearing},
  volume={22},
  pages={2331216518814388},
  year={2018},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{hart2009attentive,
  title={The attentive hearing aid: Eye selection of auditory sources for hearing impaired users},
  author={Hart, Jamie and Onceanu, Dumitru and Sohn, Changuk and Wightman, Doug and Vertegaal, Roel},
  booktitle={IFIP conference on human-computer interaction},
  pages={19--35},
  year={2009},
  organization={Springer}
}

@article{best2017benefit,
  title={The benefit of a visually guided beamformer in a dynamic speech task},
  author={Best, Virginia and Roverud, Elin and Streeter, Timothy and Mason, Christine R and Kidd Jr, Gerald},
  journal={Trends in Hearing},
  volume={21},
  pages={2331216517722304},
  year={2017},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}


@article{kidd2017enhancing,
  title={Enhancing auditory selective attention using a visually guided hearing aid},
  author={Kidd Jr, Gerald},
  journal={Journal of Speech, Language, and Hearing Research},
  volume={60},
  number={10},
  pages={3027--3038},
  year={2017},
  publisher={ASHA}
}

@article{kidd2013design,
  title={Design and preliminary testing of a visually guided hearing aid},
  author={Kidd Jr, Gerald and Favrot, Sylvain and Desloge, Joseph G and Streeter, Timothy M and Mason, Christine R},
  journal={The Journal of the Acoustical Society of America},
  volume={133},
  number={3},
  pages={EL202--EL207},
  year={2013},
  publisher={Acoustical Society of America}
}

@article{ricketts1999comparison,
  title={Comparison of performance across three directional hearing aids},
  author={Ricketts, Todd and Dhar, Sumit},
  journal={Journal of the American Academy of Audiology},
  volume={10},
  number={04},
  pages={180--189},
  year={1999},
  publisher={Thieme Medical Publishers, Inc.}
}

@article{hladek2019interaction,
  title={On the interaction of head and gaze control with acoustic beam width of a simulated beamformer in a two-talker scenario},
  author={Hl{\'a}dek, {\'L}ubo{\v{s}} and Porr, Bernd and Naylor, Graham and Lunner, Thomas and Owen Brimijoin, W},
  journal={Trends in Hearing},
  volume={23},
  pages={2331216519876795},
  year={2019},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{geronazzo2020superhuman,
  title={Superhuman hearing-virtual prototyping of artificial hearing: a case study on interactions and acoustic beamforming},
  author={Geronazzo, Michele and Vieira, Luis S and Nilsson, Niels Christian and Udesen, Jesper and Serafin, Stefania},
  journal={IEEE transactions on visualization and computer graphics},
  volume={26},
  number={5},
  pages={1912--1922},
  year={2020},
  publisher={IEEE}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{adarsh2020yolo,
  title={YOLO v3-Tiny: Object Detection and Recognition using one stage improved model},
  author={Adarsh, Pranav and Rathi, Pratibha and Kumar, Manoj},
  booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)},
  pages={687--694},
  year={2020},
  organization={IEEE}
}

@article{kuznetsova2020open,
  title={The open images dataset v4},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal={International Journal of Computer Vision},
  volume={128},
  number={7},
  pages={1956--1981},
  year={2020},
  publisher={Springer}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{broadbent1956successive,
  title={Successive responses to simultaneous stimuli},
  author={Broadbent, Donald Eric},
  journal={Quarterly Journal of Experimental Psychology},
  volume={8},
  number={4},
  pages={145--152},
  year={1956},
  publisher={Taylor \& Francis}
}
