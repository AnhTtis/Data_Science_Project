\section{Method}



% \subsection{Overview}

% Information visualization uses visual encodings to characterize datasets so that humans can see the visual encodings, comprehend the dataset behind the encodings, and gain further insight from the data~\cite{munzner2008process}. 


% \alexout{Since all mark types occupy a particular region in the 2D visualization in visual perception, we apply a novel masking scheme to these marks to ensure corresponding visual channels remain the same at a close viewing distance. As a result, the visual encodings are preserved because the marks and visual channels are unchanged after the maks processing. Therefore, the processed visualization, namely privacy-preserving visualization, has the same visual encoding as the original visualization. Users in proximity to the visualization are able to comprehend the dataset from the privacy-preserving visualization.}


% Existing mobile visualizations can compromise user privacy by allowing both the data owner (i.e., the user) and potential shoulder surfers to view sensitive data clearly. To address this issue, we propose a privacy-preserved visualization approach consists of two granular levels (Figure~\ref{fig:overiew}). The first level involves manipulating the spatial frequency (Section~\ref{method:sp}) and luminance contrast (Section~\ref{method:luminance}) based on the fundamental principles of the human vision system. It applies a binary mask to visual marks within the visualization to adjust their spatial frequencies, and then reduce their luminance contrast with the visualization background. Building upon this, we take into account the different needs of visual mark types. In other words, we develop customized schemes for visual marks due to their distinct characteristics.
Informed by prior research on human perception in Section~\ref{sec:background}, we propose a novel perception-driven approach to achieve privacy preservation for visualization on mobile devices.
Specifically, we present a masking scheme to process the bitmap image of an input visualization and transform it into a privacy-preserving one.
It consists of two major steps corresponding to two levels of processing granularity (Figure~\ref{fig:overiew}): \textit{coarse-grained masking} and \textit{fine-grained masking}.
Coarse-grained masking adjusts the spatial frequency of visual marks (Section~\ref{method:sp}) and their luminance contrast with the background in a visualization (Section~\ref{method:luminance}), which takes into account the fundamental principles of the human vision system.
Fine-grained masking further enhances the privacy preservation effect for visualizations by considering the distinct characteristics of different visual marks, which is informed by our Study 1 in Section~\ref{study:study1}.
Visual marks, such as circles in a scatter plot and bars in a bar chart, are fundamental elements in visualizations~\cite{munzner2014visualization,satyanarayan2015reactive,senay1994knowledge}. 
The source code for our approach is available online: \url{https://github.com/AlexanderZsh/Privacy-preserving-visualization}.

% ~\cite{satyanarayan2016vega}.
% Prior studies~\cite{munzner2014visualization, satyanarayan2015reactive,senay1994knowledge} classify visual marks as a point (zero dimensions), a line (one dimension), or an area (two dimensions) based on the required number of spatial dimensions. 
% In our case, 
% we regard both point-based marks as area-based marks (e.g., bars) because they occupy specific regions in a visualization.
By considering the areas that different visual marks occupy,
we categorize visual marks into two types: \textit{line-based marks} such as lines, texts, and axes, and \textit{area-based marks} such as bars and circles. We propose adaptive fine-grained masking schemes for them to further improve the privacy preservation of visualizations (Section~\ref{method:improvement}). 

% \yong{pls check my Overleaf comments and check it throughout the whole paper.}
% ~\alex{When will we upload the code}
% . The source code will be available once the paper has been published




% Visual visualizations consist of marks and visual channels.
% Marks are essential elements and refer to geometrically fundamental objects (e.g., points in a scatter plot, bars in a bar chart), and visual channels determine the appearance of marks such as color, size, and position~\cite{satyanarayan2016vega}. As introduced in Section~\ref{background:csf}, a human's ability to perceive a visualization is influenced by the spatial frequency and contrast of stimuli. Inspired by the characteristics of human vision, we developed a masking scheme that can change the spatial frequency (Section~\ref{method:sp}) and luminance contrast (Section~\ref{method:luminance}) of visualizations marks. Specifically, The mask area determines how many of the original pixels of the mark are retained, thereby influencing the spatial frequency of the resultant mark. Luminance contrast determines the visual contrast between the marks and the visualization background. Additionally, according to feedback both from method development and users in Study 1 (Section~\ref{study:study1}, we improve our method by categorizing the masking scheme into two parts, namely area-based and line-based marks, and adding a border (Section~\ref{method:improvement}) in area-based marks . The border can enhance the user's visibility of processed visualizations without compromising their privacy preservation. We will illustrate our method details in the following.

% A privacy-preserving visualization prevents others from viewing a person's visualization in public. In our study, we utilized the knowledge that human vision systems (HVS) display different visual sensitivity levels to information of various spatial frequencies. Regarding the visualization presented as an image on mobile devices, as demonstrated in \ref{fig:csf}, a person's ability to perceive a visualization is influenced by the contrast between its visual elements (e.g., marks) and their backgrounds (e.g., white canvas), as well as the spatial frequencies of the visualization image received by the HVS.
% Therefore, we transfer low spatial frequencies in the visualization to high spatial frequencies in spatial frequency (Section~\ref{method:sp}), because people rarely perceive high spatial frequencies at a distance. Then, since low contrast between visual elements and background can prevent peekers from immediately recognizing critical information, we also adjust  the contrast between the visualization's components and the background (Section~\ref{method:luminance}). Finally, we combine the results from the frequency-based and contrast-based approaches to create a privacy-preserving visualization.


\begin{figure}[ht!]
    \centering
    % \hspace{-2em}
    \includegraphics[width=1\linewidth]{figures/masking_v6.pdf}
    \caption{Area-based masking transforms area-based marks from low to high-frequency. (a) Examples of area-based masks with different mask areas. The pixel at the center of the mask remains unchanged, while the adjacent pixels are transformed to match the background color (e.g., white).
    % As the mask area increases, the visual marks will be transformed to a higher frequency.;
    (b) the effect of applying the area-based masking (Mask area: 5) to a bar chart ($b_1$) to convert it to its high spatial frequency version ($b_2$). (c) the frequency domain representations of ($b_1$) and ($b_2$).
    % which shows that the low-frequency information is transformed to high-frequency content. 
    % \yong{ Pls check my side comments.}
    % \yong{What is area-based masking here? Note: we have restructured the structure of our method!}
    }
    % \caption{It displays the mask example, chart's image, and spatial frequency spectrum before and after applying the masking. (a) It provides two masks with different mask areas. This type of mask works for area-based marks. (b) It displays the visualizations in the spatial domain where b$_1$ is the normal bar chart, and b$_2$ is the privacy-preserving bar chart. (c) It delineates the spatial frequency distribution of two visualizations in the frequency domain where c$_1$ refers to the original visualization and c$_2$ represents the privacy-preserving visualizations.}
    \vspace{-2em}
    \label{fig:masking}
\end{figure}

\subsection{Coarse-grained Masking}

Coarse-grained masking aims to increase the spatial frequency and reduce the luminance contrast of visual marks in an input visualization to prevent shoulder surfers from viewing the visualization at a certain distance and allow visualization owners to see it clearly.

\subsubsection{Increasing Spatial Frequency}\label{method:sp}
% \dm{add some examples of the mask in Figure 4. }

% \dm{1. talk about visulization graphs consist of background, visual marks, and texts. 2. you first need to detect the visual marks. 3. only apply the mask to the visual mark and why. 4. show examples.  }

% Visualizations consist of visual marks, backgrounds, axes, and texts. 
% \yong{Pls check my Overleaf comments.}
% Visual marks refer to geometrically fundamental objects in a visualization (e.g., points in a scatter plot, bars in a bar chart), and their appearance (e.g., color, size, and orientation) represents the visualization underlying data characteristics. Therefore, visual marks are the fundamental elements in visualizations~\cite{satyanarayan2016vega}. If shoulder surfers cannot view the visual marks, they cannot understand the complete visualization. 



Inspired by prior research on human vision (Section~\ref{background:csf}), we intend to increase the visual marks' spatial frequency using a binary mask.
First, we need to identify visual marks in an input visualization image. Given that visualizations usually have a white background, there is a clear color contrast between visual marks and the background of visualizations (Figure~\ref{fig:masking} (b$_1$)). In this paper, we leverage the Li Thresholding algorithm~\cite{li1998iterative}, which determines the color threshold between the background and visual marks. With the color threshold, we can identify visual marks from the background in visualization.
% \yong{what is ``the slope of cross entropy''?}
% First, we must distinguish the visual marks from the visualization background. \alexout{To visually emphasize the marks, the visualization makes a great contrast between its background and the corresponding visual marks.} Because visualization marks and background has a color difference (Figure~\ref{fig:masking} (b$_1$)) in terms of pixel values, we first distinguish the marks from the background using the Li Thresholding algorithm~\cite{li1998iterative}, which leverages the slope of cross entropy to determine the optimal pixel value  threshold between the background and the visual marks. 
% \alexout{Then, we apply the mask to these detected visual marks. Specifically, as shown in Figure~\ref{fig:masking} (a), the mask works on the part of visual marks, retains a pixel value in the center of the mask, and converts the color of the remaining pixels in the mask to the background color. The mask is applied to marks iteratively until it covers the entire mark. \alexin{The mask is tiled to cover the entire mark.} Thus, the visual mark, previously a complete block of one color, is divided into smaller blocks. The background color block separates the visual mark's blocks. As a result, the mask increases the processed visual mark's frequency. For example, there are three visual marks in Figure~\ref{fig:masking} (b$_1$). After processing by a mask with a specific mask area (Figure~\ref{fig:masking} (a)), these visual marks are composed of smaller blocks as shown in Figure~\ref{fig:masking} (b$_2$). The mask converts the spatial frequency of these rectangular visual marks from low spatial frequency (Figure~\ref{fig:masking} (c$_1$)) to high spatial frequency (Figure~\ref{fig:masking} (c$_2$)). Nonetheless, users are able to see the same characteristics (e.g., color, location, and size) of the processed marks (Figure~\ref{fig:masking} b$_2$) as the original mark (Figure~\ref{fig:masking} b$_1$), so the characteristics of the marks' appearance are preserved.}
% \alexin{Then we apply the mask to the detected visual marks. The mask operates on part of the visual marks and retains a pixel value in the center of the mask while converting the remaining pixels' color in the mask to the background color. The mask is tiled to cover the entire mark, effectively dividing the visual mark, which was previously a complete block of one color, into smaller blocks. Because the complete single color block is turned into multiple smaller blocks and these blocks are separated by the background, there exist alternative color changes in the processed visual mark. As a result, the frequency of the processed visual mark changes from low frequency to high frequency. For example, in Figure~\ref{fig:masking} (b$_1$), there are three bars as visual marks. After being operated by a mask with a specific mask area (e.g., mask area is 5 shown in Figure~\ref{fig:masking} (a)), these bars are transformed from a complete block with a single color (i.e., blue in Figure~\ref{fig:masking} (b$_2$)) to smaller blocks with two alternating colors (i.e., white and blue in Figure~\ref{fig:masking} (b$_2$)). Accordingly, in the frequency domain , these bars' frequency changes from low frequency (Figure~\ref{fig:masking} (c$_1$)) to high frequency (Figure~\ref{fig:masking} (c$_2$)). As a result, it is more difficult for attackers to identify the processed bars at a distance. Nonetheless, users are able to see the same characteristics of the processed bars (e.g., color, location, and size) as the original bars at close viewing distance. This means that the characteristics of the marks' appearance are preserved, despite being processed by the mask.}
% \yong{Pls check my Overleaf comments.}

% Then, we use the \textit{area-based} masking to process visual marks,
Then, we propose a masking scheme,
as shown in Figure~\ref{fig:masking}, to process which marks.
% Such a mask scheme is called \textit{area-based mask} in this paper.
Such processing is called \textit{area-based masking} in this paper.
Specifically, we overlay the mask on the areas of visual marks, where the pixel at the center of the mask is retained, and other pixels are converted to the background color (e.g., white). The mask is tiled to cover the entire mark.
Take the bar chart in Figure~\ref{fig:masking} (b$_1$) as an example, the smooth bars will be converted to dotted bars with high spatial frequency (Figure~\ref{fig:masking} (b$_1$)).
The spatial frequency distributions of the bar chart before and after being processed by our masking scheme are shown in Figure~\ref{fig:masking} (c$_1$) and Figure~\ref{fig:masking} (c$_2$) respectively, indicating the increased spatial frequency of the processed visualization.
Accordingly, it makes it difficult for shoulder surfers to see the visualization at a distance, while users at a closer viewing distance can still clearly identify all the information 
% of the original bar chart
from the processed visualization.
As the mask area increases, the bars
% s within the visualization 
become more sparsely dotted, resulting in an increase in spatial frequency and making it harder for shoulder surfers at a distance to identify the processed bars.
% Nonetheless, users who are closer to the visualization will still be able to identify the information.
% \yong{Need to add a few sentences to discuss the influence of the mask size. For example, Figure 6 shows two different masks. Then, which one is better and what is the influence of mask size?? These are the core information we need to talk about.}
% \yong{Important -- need to explicitly mention the core idea of different masks.}





% In an image, spatial frequencies correspond to changes in pixel values. When pixel values do not change significantly in an area of a picture, then that area has low frequencies. In contrast, if there is a change in an area (e.g., two adjacent pixels, one is black and one is white), the area has changed drastically and hence frequency becomes higher~\cite{gonzalez2009digital}. Inspired by the notion, we propose a masking scheme for visualization marks. Specifically, In a sub-region, the scheme retains a pixel value in the center of the mask and converts the color of the remaining masked pixels to the background color.
% Consequently, in the sub-region, a retained pixel has a significantly different color value than its adjacent pixels converted to the background color. Therefore, mark's frequencies improve.
% As a result, the processed visualization mark is no longer a complete geometry wherein all pixels have the same color, but is composed of many discrete pixel points. The processed mark is converted from low to high frequencies in its frequency domain. Figure~\ref{fig:masking} shows an example to explain the masking scheme. Three blue rectangles in Figure~\ref{fig:masking} a$_1$ are visualization marks of a bar chart, and they have strong low-frequency components in the frequency domain shown in Figure~\ref{fig:masking} b$_1$. After the masking scheme, rectangles are constructed with a lot of discrete points in Figure~\ref{fig:masking} a$_2$. In  the corresponding frequency spectrum, the low-frequency components are converted to high-frequency components in Figure~\ref{fig:masking} b$_2$. Nonetheless, users are able to see the same characteristics (e.g., color, location, and size) of the processed mark (Figure~\ref{fig:masking} a$_2$) as the original mark (Figure~\ref{fig:masking} a$_1$), so visual channels of visualization marks are kept as well.

% Figure~\ref{fig:masking}a$_1$) into different dot matrices (e.g., Figure~\ref{fig:masking}a$_2$). As shown in Figure~\ref{fig:masking}b, the bars that originally had low frequency will turn to high frequency in the frequency domain because the previously negligible adjacent pixel value difference in the original area will become significant. 

% visualization comprises marks and visual channels. The marks (e.g., bar, line) enable users to understand the underlying data in the visualization. 
% In particular, a mark is a specific geometric area where pixels have the same value. Our method can apply the masking to the marks and then convert the mark frequency to high frequency while retaining its original visual channels (e.g., size and color). 


% Also, pixels in a geometric mark usually have the same color value to ensure perception uniformity. Based on this assumption, we apply a masking scheme to the marks. Specifically, the scheme keeps the center pixels in the mask and masks the surrounding pixels, making the masked pixels the same color as the background. Therefore, these masked pixels have a considerable color value difference from their adjacent pixels that retain the original color, and then the frequencies in the mark improve. Following the masking, the mark is transformed into a dot matrix composed of the kept pixels, and the dot matrix retains the geometric shape of the mark.
% Additionally, users are able to see the same characteristics (such as color, location, and size) in the processed mask because the scheme only modifies some pixels while leaving the rest unchanged, so visual channels are kept as well. The mask will process a small area within the mark and move along the horizontal or vertical directions until it encounters the border of the mark. As a result of the masking scheme, users can distinguish the processed mark from the background and understand the underlying data from its unaffected visual channel at a close viewing distance. However, others at a distance cannot recognize the processed mark from the background due to its changed frequency. 








% \dm{1. after masking, reduce the luminance of the remaining visual marks. 2. however, convention RGB space does not allow the modification of luminance. 3. we propose to use another color space.... 4. how to adjust...}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/masking_result_v4.pdf}
    \caption{The effect of applying different luminance contrast on the converted high-frequency bar charts. The visibility reduces with the decrease in luminance contrast.
    When the luminance contrast reaches zero,
    % human cannot identify the visual mark from the background.
    we are not able to distinguish visual marks from the white background of a visualization.
    % \yong{It is better to change ``Luminance difference'' to ``luminance contrast'' in the figure.}
    }
    \label{fig:luminance}
    \vspace{-2em}
    
\end{figure}


\subsubsection{Reducing Luminance Contrast}\label{method:luminance}

% In addition to applying the mask on the visual mark, we need to adjust the luminance of the visual mark and the visualization background so that the shoulders surfer hardly perceives the resulting visual mark. 
Besides adjusting the spatial frequency of visual marks, we also decrease their luminance contrast with the visualization background to further prevent shoulder surfers from seeing the visual marks of an input visualization.
Instead of using the commonly-used RGB color space, we employ the CIELAB color space when adjusting the luminance contrast of visualizations.
The major reason is that the RGB color space cannot accurately model how human perceives luminance~\cite{munzner2014visualization}, but the L channel of CIELAB color space aligns well with the actual perception of luminance by human vision system~\cite{hanbury2002mathematical}.
% Therefore, we can change the single luminance channel in the visual marks and background in the CIELAB color space. 
Therefore, by changing the luminance of the pixels of visual marks and background in the CIELAB color space, we can accurately control the luminance contrast between them that will be perceived by users.
Figure~\ref{fig:luminance} illustrates the influence of different luminance contrasts
in terms of CIELAB's L channel on the visibility of visual marks. 
With the decrease in the luminance contrast between the visual marks and the background, it becomes increasingly difficult for humans to distinguish visual marks from the background.
% because their perceived luminance contrast decreases.



% % \yong{Reach here.}
% The contrast is a measurement of the luminance difference between an object and its background~\cite{bertalmio2019vision}. However, conventional RGB color space does not allow the modification of luminance in its space. The RGB color space specifies colors as red, green, and blue triples and is widely used in the computer graphics system. Though the color space is computationally convenient, it cannot match actual human perception~\cite{munzner2014visualization}. The RGB color space's red, green, and blue axes must combine to represent the perception of color. A change in the value of a single axis does not accurately reflect the actual change in the human perception of color. In the literature survey, we discovered that the CIELAB color space is a suitable replacement for RGB. In CIELAB color space, the L channel denotes the amount of luminance perceived by the HVS (human vision system), and the A and B channels indicate the hue in color space ~\cite{hanbury2002mathematical}. CIELAB is most impressive for its ability to model the luminance that humans perceive accurately. The change in the L channel is equal to the change in human perception. Therefore, we can change the single luminance channel in the visual marks and background in the CIELAB color space. The adjusted luminance difference between the visual marks and background corresponds to the actual human perceived luminance contrast. Figure~\ref{fig:luminance} illustrates the luminance difference between the masked visual marks and the background in terms of CIELAB's L channel. As the luminance difference between the visual marks and the background decreases, humans hardly distinguish the marks from the background because their perceived luminance contrast decreases.

% As depicted in Figure~\ref{fig:csf} (a), the spatial frequency determines the required contrast sensitivity in HVS. The lower the contrast sensitivity, the greater the contrast of the stimulus needed to be seen by the HVS~\cite{barten1999contrast}. In addition to pixel values, viewing distance also influences spatial frequency: a greater viewing distance will result in a higher spatial frequency perceived by HVS. Therefore, the significant contrast between the visualization elements and the background (Figure~\ref{fig:mask_result} (a)) is more important to viewers who are at a greater distance from the visualization than to those who are closer to it
% In light of this, we intend to adjust the contrast between the visualization elements and the background to a level that satisfies the relatively low contrast requirements of users but not the relatively high contrast requirements of peekers. In other words, people with high contrast sensitivity are able to recognize the adjusted contrast, but people with low contrast sensitivity cannot do so.

% The contrast is a measurement of the luminance difference between an object and its background~\cite{bertalmio2019vision}. Besides RGB, CIELAB provides a perceptually uniform color space, where the L channel denotes the amount of luminance perceived by the HVS, and the a and b channels indicate the hue in color space ~\cite{hanbury2002mathematical}. Furthermore, L can linearly model the luminance that we humans perceive. In other words, an equal step change of L is consistent with the equal step change of human perception~\cite{munzner2014visualization}. Therefore, we can change the luminance difference between the visual components and background in terms of CIELAB. The changed luminance difference corresponds to the adjusted contrast. As a result, users who are close to the visualization can perceive the luminance difference. In comparison, those far away cannot do so, thus confusing the components with the background as shown in Figure~\ref{fig:mask_result} (b).


\subsection{Fine-grained Masking}\label{method:improvement}
\label{sec: further_improve_area}
% \dm{Typical visualization chart types are..., which can be group as line-based, and area-based. the above mentioned two-stage scheme cannot work well with different types of visualization charts becasue. Thus, for each group, we further design some customized technique to improve the performance.}



The coarse-grained masking discussed above is designed to process all the visualizations without considering their own visual properties.
However, typical data visualization charts such as bar chart, pie chart, scatter plot, and line chart~\cite{battle2018beagle} consist of different visual marks and thus have distinct characteristics.
To further enhance privacy preservation performance, it is necessary for us to consider the unique visual properties of different visualizations.
Thus, building upon the coarse-grained masking, we further propose~\textit{fine-grained masking} to process input visualizations, as shown in Figure~\ref{fig:overiew}.
Specifically, we design adaptive masking schemes for line-based marks and area-based marks.
% \yong{Pls check my Overleaf Chinese comments and add useful comments to your check list.}

% Typical data visualization charts include bar chart, pie chart, scatter plot, and line chart~\cite{battle2018beagle}, whose visual marks can be categorized as line-based and area-based. The aforementioned \alexout{two-stage} masking scheme cannot work well with different visualization types, because \textit{line-based elements}, including line mark, text and axes, and \textit{area-based elements}, including geometric marks (e.g., bar, circle), have distinct characteristics. Thus, we further design customized techniques for each category to improve privacy-preserving visualization effectiveness \alexin{(Figure~\ref{fig:overiew})}. In the paper, the \textit{line-based masking scheme} refers to the masking method on the line-based elements, and the \textit{area-based masking scheme} is used for the area-based elements.


\begin{figure}[ht!]
    \centering
    % \hspace{-1.5em}
    \includegraphics[width=\linewidth]{figures/line_masking_v4.pdf}
    \caption{Line-based masking converts line-based marks from low to high frequency. 
    (a) An area-based mask with a mask area of 5 (a$_1$) and a line-based mask with a mask area of 5 (a$_2$).
    % Examples of the area-based masking whose mask area is 5; (a$_2$) examples of the line-based masking whose mask area is 5 as well; 
    (b) an input line chart. (c) the line chart processed with area-based masking, where the dashed red rectangles highlight the problematic regions in the processing result.
    % . \alexnewin{The region in the line chart enclosed by dashed rectangles refers to the failure result that area-based masking cannot solve well for the line-based marks;} 
    (d) the line chart processed with line-based masking, which retains more text and line information.
    % \yong{1. What is the purpose of Figure 8a here? 2. What is its relation with other subfigures b, c and d? 3. The figure is distorted! }
    }
    % \caption{This figure shows the result of the masking scheme on a line chart. (a) It provides two masks with different mask areas. This type of mask works for line-based marks. (b) It shows the original line chart, which delineates three companies' stock. (c) It shows the resulting visualization by area-based masking, where rectangles with a red dashed line refer to failure from the area-based mask. (d) It presents the resulting visualization by line-based masking.}
    \vspace{-2em}
    \label{fig:line_masking}
\end{figure}

% \subsubsection{Enhancement on the line-based element}

\subsubsection{Adaptive Masking for Line-based Marks}\label{sec-adaptive-mask-for-line}



As discussed above, we categorized visual marks into \textit{line-based marks} and \textit{area-based marks} due to their differences in the occupied areas.
During the development of our approach, we also notice that there is no one-size-fits-all solution that works well for both line-based marks and area-based marks of visualizations.
For example, Figure~\ref{fig:line_masking}(c) is the processed result of the input line chart (Figure~\ref{fig:line_masking}(b)) by using the area-based masking (Figure~\ref{fig:line_masking}(a$_1$)), where the masking scheme keeps only the pixel at the center. 
However, it is difficult to identify the lines and texts due to the obvious discontinuity in a few parts of these line-based marks (as shown within dashed rectangles in Figure~\ref{fig:line_masking}(c)). For some parts of the lines, the line segments are even broken, making it difficult to determine the trend of lines. 
Since the width of line-based marks (e.g., lines, axes, and texts) is often smaller than area-based marks, and it is essential to preserve the orientation of line-based marks,
we propose a new masking scheme for line-based marks, as shown in Figure~\ref{fig:line_masking}(a$_2$).
Figure~\ref{fig:line_masking}(d) shows the processed result of the input line chart by using the new masking scheme. Such processing is called \textit{line-based masking} in this paper.
By keeping more pixels surrounding the center,
it is clear to see that such a new masking scheme can better preserve the visual information of line-based marks while increasing their spatial frequency.

% When developing the method, we found that the coarse-granular masking scheme did not apply to the line-based elements. For example, as shown in Figure~\ref{fig:line_masking} (b,c), it is hard to identify the line marks and text in the line chart after the coarse-granular masking because the masking scheme results in the discontinuity of line marks. Discontinuities affect lines significantly more than other geometries because the direction of change is uncertain. It is difficult for the user to determine a line's trend if a line segment is missing.
% In a 2D visualization, a mark could be classified as a point (zero dimensions), a line (one dimension), or an area (two dimensions) based on the required number of spatial dimensions~\cite{munzner2014visualization, satyanarayan2015reactive,senay1994knowledge}. 
% In our case, we regard both point-based marks as area-based marks (e.g., bars) because they occupy specific regions in a visualization. Then we apply different masking schemes to area-based and line-based elements. 
% In addition to the line marks, the horizontal and vertical axes and text in visualizations on also use a line-based masking scheme because they are naturally made of lines. 
% In addition to the line marks, we apply the line-based masking scheme to the axes and text in visualizations because they are made of lines by nature.
% The line-based masking scheme aims to raise the frequencies of the axes, text, and line marks so that peekers cannot see them from a distance. The reason why we apply masking schemes to axes and text is that they can indicate the essential information of the visualization. For example, the visualization title enables users to immediately understand what the visualization is about by reading it because the title provides a clear overview. In conjunction with the visualization title, axes titles and axes help users quickly recognize the specific information encoded in the data points and associate the data points with values. Therefore, preventing these information leakages from peeking by others is necessary.
% Unlike area-based elements, the line width is small, and some pixel points in the line are more important than others. 
% Therefore, we need to propose a new mask design that keeps more pixels in the line-based mask, as shown in Figure~\ref{fig:line_masking}. Otherwise, users hardly perceive the line. Moreover, the line trend may vary in any orientation. For instance, the line in a line chart represents the underlying data's trend, and the turning points in the line denote a change in trend ~\cite{udagawa2018predicting}.  Line-based masks process a small region of the line at a time and move in the direction of the line. Therefore, the change of line is preserved in the resulting privacy-preserving visualizations.
% \alexout{
% Additionally, since the axes and line marks in visualization are consistent in size, but text font sizes vary, we apply an adaptive mask to the text to ensure that the line-based mask can correctly process texts with varying sizes. Specifically, we use an OCR (Optical Character Recognition) tool, EasyOCR, which leverages a neural network model to detect text region from a visualization~\cite{jaidedai}.
% Following the identification of the text region on the visualization, it is necessary for us to determine the text size in terms of its stroke width. First, we reduced the stroke width of the text to 1px, which is the minimum size for a text~\cite{van2014scikit}. Then we calculated the stroke width difference between the original text  and the minimum-size text~\cite{virtanen2020scipy}. The text stroke was obtained by averaging the stroke width differences.
% Further, we empirically determined the appropriate line-based mask area values for different text sizes.
% Thus, the mask can adjust its area depending on the text size.
% As shown in Figure~\ref{fig:line_masking} (c,d), line-based masking outperforms area-based masking on line-based elements such as axes, texts, and line marks. 
% In Study 2 (Section~\ref{sec:study2}), the text processing operations are applied to the text on the visualization test samples.
% }
Furthermore, we adaptively adjust the size of the line-based masking for line-based marks according to their width. Among all the line-based marks (e.g., lines, axes, and texts), the width of lines and axes in data visualization charts are relatively stable and consistent. However, texts can vary a lot due to different font sizes, which motivates us to adaptively vary the size of the masking scheme to process texts specifically.
To this end, we first employ EasyOCR~\cite{jaided2020easyocr}, a widely used Optical Character Recognition
(OCR) tool to detect texts in the input visualization image.
% Then, we further leverage the Li Thresholding algorithm~\cite{li1998iterative} to extract strokes of texts and determine text stroke width.
% \yong{We change it back to the commented sentence after being finally accepted.}
Then, we further extract strokes of texts and determine text stroke width by 
using the fast parallel thinning algorithm~\cite{zhang1984fast} that has been integrated to the package Scipy~\cite{virtanen2020scipy}. 
The text stroke width is used to guide our empirical configuration on the adaptive mask size of our masking scheme for line-based marks.
% Such adaptive masking for texts consists of two primary steps: text detection and text size determination. First, we employ EasyOCR~\cite{jaided2020easyocr}, a widely used Optical Character Recognition
% (OCR) tool to detect texts in the input visualization image. Once the text regions in the visualization image have been detected, the mask area is adjusted according to the text size,
% which is determined by the stroke width. The stroke width refers to the thickness of each stroke in the text and is calculated by the distance from one edge of the stroke to the other, perpendicularly crossing the centerline of the stroke. To obtain the centerlines of the strokes, we skeletonize~\cite{zhang1984fast} the detected text by reducing the stroke to its centerline. We then calculate the width of each stroke from its centerline to its edge and compute the average width of all strokes in the text to determine the text size. The adaptive masking scheme can adjust its mask area for different text sizes by empirically determining line-based mask area values for different text sizes. 
% \yong{pls check my overleaf comments.}
 
% \yong{Songheng, pls fill it. I totally cannot understand what you have written above.} 




% \subsubsection{Area-based masking with border}


\subsubsection{Customized Masking for Area-based Marks} \label{sec-mask4areamarks}


% \alexout{
% Initially, we only applied a masking scheme on the area-based and line-based elements, respectively, and then conducted Study 1 (Section~\ref{study:study1}) to measure the effects of mask area and luminance contrast on human visibility to resulting visualizations. However, according to Study 1 participants' feedback, they hardly identify detailed information on specific area-based marks. For example, a lack of border lines between slices in a pie chart reduces confidence in the chart's readability. Participants should identify different slices in the pie, but they could not find the border between slices and thus had to speculate the portion of the slice by the area of different colored pixels. The speculation result is subjective and inaccurate. Similarly, participants could identify the processed area-based markers for other visualizations, such as bar charts or scatter plots. However, they requested a reference to help them quickly compare different area-based markers, such as the comparison of bar heights. Based on participants' feedback, in the privacy-preserving visualizations, we applied line-based masking to the border of area-based marks, making them invisible at a distance, but these processed borders provide an additional reference for users to view the area-based marks at close viewing distance.
% }\textbf{}



For the area-based marks like bars and circles, we initially leverage the area-based masking (Figure~\ref{fig:masking}(a)) to process them without specifically handling the borders of area-based visual marks.
As will be introduced in Section~\ref{study:study1}, we follow such a setup to evaluate 
% the effects of mask area and luminance contrast on 
the visibility of visualizations. The participants' feedback shows that the proposed area-based masking approach can achieve a good privacy preservation effect for area-based marks. However, it also makes it difficult for participants to accurately perceive the corresponding data of area-based visualizations due to the overly discretized borders of area-based marks. 
For example, for a processed pie chart, an excessively sparse border between two adjacent slices makes it difficult for human users to accurately identify the boundary between the two adjacent pie slices even at a close viewing distance, as shown in Figure~\ref{fig:study2_sample} (c) of Appendix~\ref{sec:appendix}.
To address this issue, we apply line-based masking,
% the masking scheme for line-based masks,
as introduced in Section~\ref{sec-adaptive-mask-for-line}, to specifically process the borders of area-based marks, enhancing the accurate perception of area-based marks at a close viewing distance and guaranteeing privacy preservation for visualization above a certain viewing distance.
% making them invisible at a distance, but these processed borders provide an additional reference for users to view the area-based marks at close viewing distance.
% \yong{pls check my overleaf comments and do the changes accordingly.}




% According to the study 1 result\alex{add section reference later}, we add a high-frequency auxiliary line along the geometry's perimeter to enhance user efficiency when viewing the privacy-preserving visualization. However, this additional line is invisible to observers at a distance.


% \subsection{Visibility Calculation}

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.6\linewidth]{figures/visibility.jpg}
%     \caption{The figure shows a visualization representation in the 1D spatial frequency spectrum and its visibility result. In the (a), the x-axis refers to the spatial frequencies, and the y-axis refers to their amplitude (i.e., power in the spectrum). In the (b), it indicates how many frequencies in visualization can be seen by the human eye. The red curve represents the reciprocal of the CSF, and black dots above the red curve are the frequencies that the human can perceive in the HVS.}
%     \vspace{-1em}
%     \label{fig:visibility}
% \end{figure}
% Although our method can change the frequencies and luminance contrast of an original visualization to create a privacy-preserving visualization, we cannot determine the obtained visualization's visible and invisible range. Therefore, it is necessary to get a reference about how far the human eye can and cannot perceive the visualization, respectively. Additionally, since the visualization display effect is relevant to the mobile device screen, we aim to develop a formula to give a reference as to the human visibility to the visualization, using the screen resolution, viewing distance, and the resulting frequency domain visualization. In other words, the score can represent how many frequencies in the visualization can be seen by the human eye at a given distance.

% As mentioned in Section~\ref{background:sp}, a visualization image is composed of different frequencies with respect to the frequency domain. With the help of Fourier transformation, we can obtain the visualization representation in the frequency domain as shown in Figure~\ref{fig:masking} (b). Afterward, we should convert the 2D frequency domain representation into a 1D frequency series. The resulting 1D series shows the frequency power spectrum regarding the visualziation~\cite{isenberg2013hybrid}. Different from typical images (e.g., profiles, landscape pictures), the visualization is a simple image because it is composed of simple geometric shapes (e.g., line, bar) and thus there is not always power (i.e., amplitude) at every frequency as shown in Figure~\ref{fig:masking}(b2)~\cite{gircys2019image}. To avoid canceling out significant power frequencies, we sum frequencies out by radii rather than averaging them when converting a 2D frequency domain to a 1D spectrum. We then utilize Formula~\ref{formula:cpd} to transform the unit of spatial frequency from pixel per cycle (ppc) to cycle per degree (cpd). The obtained cpd takes the human viewing distance into account~\cite{isenberg2013hybrid}. We then derive the contrast of spatial frequencies by the following formula~\cite{hess1983contrast}:

% \begin{equation}\label{formula:contrast}
%     C(sp)  =\frac{2A(sp)}{DC}
% \end{equation}

% where \textit{C(sp)} denotes the contrast of a specific spatial frequency, \textit{A(sp)} denotes the amplitude (i.e., power) of the spatial frequencies, and \textit{DC} refers to the zero-frequency component~\cite{nunez2017elegant}.

% With Formula~\ref{formula:contrast}, we can get the contrast with respect to the frequency and know how many frequencies in a visualization image the human eye can see at a given distance. Specifically, since the reciprocal of contrast sensitivity is threshold contrast~\cite{national1985emergent}, we can know how many frequencies in a visualization a human can see at a given distance, as shown in Figure~\ref{fig:visibility}.