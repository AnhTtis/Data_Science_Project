\section{Results and Discussion}
Our main results can be found in \autoref{tab:overall}. Results including Natural Questions can be found in \autoref{tab:natural_questions}. Note that the Natural Questions results have minor variations from published numbers; we ran these baselines ourselves, and it is possible the training setup differed slightly.

\input{tab/nq_results}

\paragraph{T5 and T5-LM} The T5 model sets a relatively high baseline compared to previously reported models. The T5-LM model's extra non-domain-specific pretraining does not help on any task, suggesting extra training steps does not in of itself cause improvements on these tasks.

\paragraph{Entities} The \textsc{Entities} model, which is trained on only non-temporal entity spans, performs better overall than the TSM task. It only does worse on the TimeDIAL dataset, which is almost entirely focused on conversational, non-knowledge based contexts. It still does substantially better than the base T5 model when no finetuning data is available. This high performance is possibly due to the prevalence of temporal spans in the SSM training data. Running \textsc{sutime} on the \textsc{Entities} data reveals that 45\% of its training examples contain at least one date, duration, set, or time.

This suggests that sentences with named entities in general already carry temporal-salient information useful for downstream temporal tasks. See \autoref{app:discussion_appendix} for a full breakdown of the co-occurrences.

\paragraph{SSM} The SSM model is the second best overall. It benefits from both its own date spans as well as the frequent presence of temporal spans in the entities data, suggesting difficult example sentences are more important than the type of masked span. It does worse on TimeDIAL-0, however, where the task is to score the best temporal span.

\paragraph{TSM} The TSM model improves upon the baseline T5 model but is worse overall than the SSM model. However, it is the best on TimeDIAL-0. This is likely because the DailyDialog training dataset is relatively large, which may overcome the need for intermediate pretraining altogether. Note that TSM achieves a mild performance improvement over the baseline T5 model on Natural Questions, but is notably worse than the other intermediate training methods. 

\paragraph{TSM+SSM} The TSM+SSM model improves over TSM but is worse than SSM outside of TimeDIAL-0. One possible reason for the regression is that TSM and SSM have overlapping Date span examples, which may make the intermediate task easier and thus less useful. However, it is slightly better than SSM on Natural Questions.

\paragraph{Entities+TSM} The \textsc{Entities+TSM} model performs the best overall: with and without the extra training data for TimeDIAL. It has the benefit of TSM spans without containing overlapping spans or losing the world knowledge from entity spans. It also performs slightly better than SSM on Natural Questions.

\input{tab/breakdown}

\paragraph{By Type} We analyze model performance by temporal type in \autoref{tab:breakdown}. The main improvement of both \textsc{SSM} and \textsc{Entities+TSM} is in entity and date tasks. Surprisingly, TSM shows a regression on time tasks, and only gets a slight improvement on duration tasks. One possible hypothesis for this is that temporal expressions may be more informative when co-occurring with an entity. Note that these numbers are based on the trained versions of each dataset, excluding Natural Questions. Note that SituatedQA contains further breakdowns based on the scope of the date, but this does not map well to the other datasets.

