\section*{Limitations}
This analysis investigates only the encoder-decoder model architecture: in particular, encoder-only models such as BERT \citep{devlin-etal-2019-bert} and decoder-only models such as GPT-2 \citep{radford2019language} are excluded. Further, large language models, such as PaLM \citep{chowdhery2022palm} or GPT-3 \citep{brown2020language} are also not investigated. See \autoref{app:discussion_appendix} for further discussion.