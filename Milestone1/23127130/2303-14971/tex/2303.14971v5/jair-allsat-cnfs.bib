@misc{masina_cnf_2023,
  title         = {On {CNF} {Conversion} for {SAT} {Enumeration}},
  url           = {http://arxiv.org/abs/2303.14971},
  opt_doi       = {10.48550/arXiv.2303.14971},
  abstract      = {Modern SAT solvers are designed to handle problems expressed in Conjunctive Normal Form (CNF) so that non-CNF problems must be CNF-ized upfront, typically by using variants of either Tseitin or Plaisted\&Greenbaum transformations. When passing from solving to enumeration, however, the capability of producing partial satisfying assignment that are as small as possible becomes crucial, which raises the question of whether such CNF encodings are also effective for enumeration. In this paper, we investigate both theoretically and empirically the effectiveness of CNF conversions for SAT enumeration. On the negative side, we show that: (i) Tseitin transformation prevents the solver from producing short partial assignments, thus seriously affecting the effectiveness of enumeration; (ii) Plaisted\&Greenbaum transformation overcomes this problem only in part. On the positive side, we show that combining Plaisted\&Greenbaum transformation with NNF preprocessing upfront -- which is typically not used in solving -- can fully overcome the problem and can drastically reduce both the number of partial assignments and the execution time.},
  urldate       = {2023-05-26},
  publisher     = {arXiv},
  opteprint     = {2303.14971},
  archiveprefix = {arXiv},
  author        = {Masina, Gabriele and Spallitta, Giuseppe and Sebastiani, Roberto},
  month         = jun,
  year          = {2023},
  opt_note      = {arXiv:2303.14971 [cs]},
  keywords      = {Computer Science - Logic in Computer Science},
  file          = {arXiv Fulltext PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/TNG8DDI3/Masina et al. - 2023 - On CNF Conversion for SAT Enumeration.pdf:application/pdf;arXiv.org Snapshot:/home/gabriele/snap/zotero-snap/common/Zotero/storage/8ZL528E9/2303.html:text/html}
}

@inproceedings{mohle_four_2020,
  opt_address = {Cham},
  series      = {Lecture {Notes} in {Computer} {Science}},
  title       = {Four {Flavors} of {Entailment}},
  isbn        = {978-3-030-51825-7},
  opt_doi     = {10.1007/978-3-030-51825-7_5},
  abstract    = {We present a novel approach for enumerating partial models of a propositional formula, inspired by how theory solvers and the SAT solver interact in lazy SMT. Using various forms of dual reasoning allows our CDCL-based algorithm to enumerate partial models with no need for exploring and shrinking full models. Our focus is on model enumeration without repetition, with potential applications in weighted model counting and weighted model integration for probabilistic inference over Boolean and hybrid domains. Chronological backtracking renders the use of blocking clauses obsolete. We provide a formalization and examples. We further discuss important design choices for a future implementation related to the strength of dual reasoning, including unit propagation, using SAT or QBF oracles.},
  language    = {en},
  booktitle   = {23rd International Conference on Theory and {Applications} of {Satisfiability} {Testing}},
  publisher   = {Springer},
  author      = {M{\"o}hle, Sibylle and Sebastiani, Roberto and Biere, Armin},
  opt_editor  = {Pulina, Luca and Seidl, Martina},
  year        = {2020},
  pages       = {62-71},
  file        = {Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/2WFNBPXZ/Möhle et al. - 2020 - Four Flavors of Entailment.pdf:application/pdf}
}

@article{plaisted1986structure,
  title       = {A {Structure}-preserving {Clause} {Form} {Translation}},
  volume      = {2},
  issn        = {0747-7171},
  opt_url     = {https://www.sciencedirect.com/science/article/pii/S0747717186800281},
  opt_doi     = {10.1016/S0747-7171(86)80028-1},
  abstract    = {Most resolution theorem provers convert a theorem into clause form before attempting to find a proof. The conventional translation of a first-order formula into clause form often obscures the structure of the formula, and may increase the length of the formula by an exponential amount in the worst case. We present a non-standard clause form translation that preserves more of the structure of the formula than the conventional translation. This new translation also avoids the exponential increase in size which may occur with the standard translation. We show how this idea may be combined with the idea of replacing predicates by their definitions before converting to clause form. We give a method of lock resolution which is appropriate for the non-standard clause form translation, and which has yielded a spectacular reduction in search space and time for one example. These techniques should increase the attractiveness of resolution theorem provers for program verification applications, since the theorems that arise in program verification are often simple but tedious for humans to prove.},
  language    = {en},
  number      = {3},
  opt_urldate = {2022-12-19},
  journal     = {Journal of Symbolic Computation},
  author      = {Plaisted, David A. and Greenbaum, Steven},
  opt_month   = sep,
  year        = {1986},
  pages       = {293-304},
  file        = {ScienceDirect Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/ZXY56IRV/Plaisted and Greenbaum - 1986 - A Structure-preserving Clause Form Translation.pdf:application/pdf}
}

@inproceedings{mathsat5_tacas13,
  opt_address = {Berlin, Heidelberg},
  series      = {Lecture {Notes} in {Computer} {Science}},
  title       = {The {MathSAT5} {SMT} {Solver}},
  isbn        = {978-3-642-36742-7},
  opt_doi     = {10.1007/978-3-642-36742-7_7},
  abstract    = {MathSAT is a long-term project, which has been jointly carried on by FBK-IRST and University of Trento, with the aim of developing and maintaining a state-of-the-art SMT tool for formal verification (and other applications). MathSAT5 is the latest version of the tool. It supports most of the SMT-LIB theories and their combinations, and provides many functionalities (like e.g. unsat cores, interpolation, AllSMT). MathSAT5 improves its predecessor MathSAT4 in many ways, also providing novel features: first, a much improved incrementality support, which is vital in SMT applications; second, a full support for the theories of arrays and floating point; third, sound SAT-style Boolean formula preprocessing for SMT formulae; finally, a framework allowing users for plugging their custom tuned SAT solvers. MathSAT5 is freely available, and it is used in numerous internal projects, as well as by a number of industrial partners.},
  language    = {en},
  booktitle   = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
  publisher   = {Springer},
  author      = {Cimatti, Alessandro and Griggio, Alberto and Schaafsma, Bastiaan Joost and Sebastiani, Roberto},
  opt_editor  = {Piterman, Nir and Smolka, Scott A.},
  year        = {2013},
  keywords    = {Bound Model Check, Model Check, Predicate Abstraction, Theory Solver, Variable Elimination},
  pages       = {93-107},
  file        = {Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/P95UI72L/Cimatti et al. - 2013 - The MathSAT5 SMT Solver.pdf:application/pdf}
}

@incollection{tseitin68,
  opt_address = {Berlin, Heidelberg},
  opt_series  = {Symbolic {Computation}},
  title       = {On the {complexity} of {derivation} in {propositional} {calculus}},
  isbn        = {978-3-642-81955-1},
  opt_url     = {https://doi.org/10.1007/978-3-642-81955-1_28},
  abstract    = {The question of the minimum complexity of derivation of a given formula in classical propositional calculus is considered in this article and it is proved that estimates of complexity may vary considerably among the various forms of propositional calculus. The forms of propositional calculus used in the present article are somewhat unusual, † but the results obtained for them can, in principle, be extended to the usual forms of propositional calculus.},
  language    = {en},
  opt_urldate = {2022-12-19},
  booktitle   = {Automation of {Reasoning} 2: {Classical} {Papers} on {Computational} {Logic} 1967-70},
  publisher   = {Springer},
  author      = {Tseitin, G. S.},
  opt_editor  = {Siekmann, Jörg H. and Wrightson, Graham},
  year        = {1983},
  opt_doi     = {10.1007/978-3-642-81955-1_28},
  pages       = {466-483}
}

@inproceedings{morettin-wmi-ijcar17,
  opt_address   = {Melbourne, Australia},
  title         = {Efficient {Weighted} {Model} {Integration} via {SMT}-{Based} {Predicate} {Abstraction}},
  isbn          = {978-0-9992411-0-3},
  opt_url       = {https://www.ijcai.org/proceedings/2017/100},
  opt_doi       = {10.24963/ijcai.2017/100},
  abstract      = {Weighted model integration (WMI) is a recent formalism generalizing weighted model counting (WMC) to run probabilistic inference over hybrid domains, characterized by both discrete and continuous variables and relationships between them. Albeit powerful, the original formulation of WMI suffers from some theoretical limitations, and it is computationally very demanding as it requires to explicitly enumerate all possible models to be integrated over. In this paper we present a novel general notion of WMI, which ﬁxes the theoretical limitations and allows for exploiting the power of SMTbased predicate abstraction techniques. A novel algorithm combines a strong reduction in the number of models to be integrated over with their efﬁcient enumeration. Experimental results on synthetic and real-world data show drastic computational improvements over the original WMI formulation as well as existing alternatives for hybrid inference.},
  language      = {en},
  opt_urldate   = {2022-12-19},
  booktitle     = {Proceedings of the 26th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
  opt_publisher = {International Joint Conferences on Artificial Intelligence Organization},
  author        = {Morettin, Paolo and Passerini, Andrea and Sebastiani, Roberto},
  opt_month     = aug,
  year          = {2017},
  pages         = {720-728},
  file          = {Morettin et al. - 2017 - Efficient Weighted Model Integration via SMT-Based.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/H948A4NZ/Morettin et al. - 2017 - Efficient Weighted Model Integration via SMT-Based.pdf:application/pdf}
}

@article{morettin-wmi-aij19,
  title       = {Advanced {SMT} techniques for {Weighted} {Model} {Integration}},
  volume      = {275},
  issn        = {0004-3702},
  opt_url     = {https://doi.org/10.1016/j.artint.2019.04.003},
  opt_doi     = {10.1016/j.artint.2019.04.003},
  abstract    = {Weighted model integration (WMI) is a recent formalism generalizing weighted model counting (WMC) to run probabilistic inference over hybrid domains, characterized by both discrete and continuous variables and relationships between them. WMI is computationally very demanding as it requires to explicitly enumerate all possible truth assignments to be integrated over. Component caching strategies which proved extremely effective for WMC are difficult to apply in this formalism because of the tight coupling induced by the arithmetic constraints. In this paper we present a novel formulation of WMI, which allows to exploit the power of SMT-based predicate abstraction techniques in designing efficient inference procedures. A novel algorithm combines a strong reduction in the number of models to be integrated over with their efficient enumeration. Experimental results on synthetic and real-world data show drastic computational improvements over the original WMI formulation as well as existing alternatives for hybrid inference.},
  number      = {C},
  opt_urldate = {2022-12-19},
  journal     = {Artificial Intelligence},
  author      = {Morettin, Paolo and Passerini, Andrea and Sebastiani, Roberto},
  opt_month   = oct,
  year        = {2019},
  keywords    = {Probabilistic inference, Satisfiability modulo theories, Weighted model counting, Weighted model integration},
  pages       = {1-27},
  file        = {Morettin et al. - 2019 - Advanced SMT techniques for weighted model integra.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/VJJCJMQ9/Morettin et al. - 2019 - Advanced SMT techniques for weighted model integra.pdf:application/pdf}
}

@inproceedings{kuiter_tseitin_2022,
  opt_address = {Rochester MI USA},
  title       = {Tseitin or not {Tseitin}? {The} {Impact} of {CNF} {Transformations} on {Feature}-{Model} {Analyses}},
  isbn        = {978-1-4503-9475-8},
  shorttitle  = {Tseitin or not {Tseitin}?},
  opt_url     = {https://dl.acm.org/doi/10.1145/3551349.3556938},
  opt_doi     = {10.1145/3551349.3556938},
  abstract    = {Feature modeling is widely used to systematically model features of variant-rich software systems and their dependencies. By translating feature models into propositional formulas and analyzing them with solvers, a wide range of automated analyses across all phases of the software development process become possible. Most solvers only accept formulas in conjunctive normal form (CNF), so an additional transformation of feature models is often necessary. However, it is unclear whether this transformation has a noticeable impact on analyses. In this paper, we compare three transformations (i.e., distributive, Tseitin, and Plaisted-Greenbaum) for bringing featuremodel formulas into CNF. We analyze which transformation can be used to correctly perform feature-model analyses and evaluate three CNF transformation tools (i.e., FeatureIDE, KConfigReader, and Z3) on a corpus of 22 real-world feature models. Our empirical evaluation illustrates that some CNF transformations do not scale to complex feature models or even lead to wrong results for modelcounting analyses. Further, the choice of the CNF transformation can substantially influence the performance of subsequent analyses.},
  language    = {en},
  opt_urldate = {2023-02-01},
  booktitle   = {37th {IEEE}/{ACM} {Int.} {Conference} on {Automated} {Software} {Engineering}},
  publisher   = {ACM},
  author      = {Kuiter, Elias and Krieter, Sebastian and Sundermann, Chico and Thüm, Thomas and Saake, Gunter},
  opt_month   = oct,
  year        = {2022},
  pages       = {1-13},
  file        = {Kuiter et al. - 2022 - Tseitin or not Tseitin The Impact of CNF Transfor.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/6KKKDSZD/Kuiter et al. - 2022 - Tseitin or not Tseitin The Impact of CNF Transfor.pdf:application/pdf}
}

@misc{sebastiani_are_2020,
  title         = {Are {You} {Satisfied} by {This} {Partial} {Assignment}?},
  opt_url       = {http://arxiv.org/abs/2003.04225},
  abstract      = {Many procedures for SAT and SAT-related problems -in particular for those requiring the complete enumeration of satisfying truth assignments-rely their efﬁciency on the detection of partial assignments satisfying an input formula. In this paper we analyze the notion of partial-assignment satisﬁability -in particular when dealing with non-CNF and existentially-quantiﬁed formulas-raising a ﬂag about the ambiguities and subtleties of this concept, and investigating their practical consequences. This may drive the development of more effective assignment-enumeration algorithms.},
  eprint        = {2003.04225},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LO},
  language      = {en},
  opt_urldate   = {2023-02-01},
  opt_publisher = {arXiv},
  author        = {Sebastiani, Roberto},
  opt_month     = feb,
  year          = {2020},
  opt_note      = {arXiv:2003.04225 [cs]},
  howpublished  = {arXiv preprint arXiv:2003.04225 [cs]},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science},
  file          = {Sebastiani - 2020 - Are You Satisfied by This Partial Assignment.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/SMSMIMIM/Sebastiani - 2020 - Are You Satisfied by This Partial Assignment.pdf:application/pdf}
}


@article{biere_aiger_2007,
  title       = {The {AIGER} {And}-{Inverter} {Graph} ({AIG}) {Format} {Version} 20071012},
  opt_url     = {https://epub.jku.at/obvulioa/content/titleinfo/5971910},
  opt_doi     = {10.35011/FMVTR.2007-1},
  abstract    = {This report describes the AIG ﬁle format as used by the AIGER library. The purpose of this report is not only to motivate and document the format, but also to allow independent implementations of writers and readers by giving precise and unambiguous deﬁnitions.},
  language    = {en},
  opt_urldate = {2023-02-28},
  author      = {Biere, Armin},
  year        = {2007},
  note        = {Publisher: Institut for Formal Models and Verification, Johannes Kepler University},
  file        = {Biere - 2007 - The AIGER And-Inverter Graph (AIG) Format Version .pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/VEXTFJU5/Biere - 2007 - The AIGER And-Inverter Graph (AIG) Format Version .pdf:application/pdf}
}

@inproceedings{gario_pysmt_2015,
  title     = {{PySMT}: a solver-agnostic library for fast prototyping of {SMT}-based algorithms},
  booktitle = {{SMT} {Workshop} 2015},
  author    = {Gario, Marco and Micheli, Andrea},
  year      = {2015}
}

@incollection{hutchison_smt_2006,
  opt_address = {Berlin, Heidelberg},
  title       = {{SMT} {Techniques} for {Fast} {Predicate} {Abstraction}},
  volume      = {4144},
  isbn        = {978-3-540-37406-0 978-3-540-37411-4},
  opt_url     = {http://link.springer.com/10.1007/11817963_39},
  abstract    = {Predicate abstraction is a technique for automatically extracting ﬁnite-state abstractions for systems with potentially inﬁnite state space. The fundamental operation in predicate abstraction is to compute the best approximation of a Boolean formula ϕ over a set of predicates P . In this work, we demonstrate the use for this operation of a decision procedure based on the DPLL(T) framework for SAT Modulo Theories (SMT). The new algorithm is based on a careful generation of the set of all satisfying assignments over a set of predicates. It consistently outperforms previous methods by a factor of at least 20, on a diverse set of hardware and software veriﬁcation benchmarks. We report detailed analysis of the results and the impact of a number of variations of the techniques. We also propose and evaluate a scheme for incremental reﬁnement of approximations for predicate abstraction in the above framework.},
  language    = {en},
  opt_urldate = {2023-03-04},
  booktitle   = {Computer {Aided} {Verification}},
  publisher   = {Springer Berlin Heidelberg},
  author      = {Lahiri, Shuvendu K. and Nieuwenhuis, Robert and Oliveras, Albert},
  opt_editor  = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Ball, Thomas and Jones, Robert B.},
  year        = {2006},
  opt_doi     = {10.1007/11817963_39},
  series      = {Lecture Notes in Computer Science},
  pages       = {424-437},
  file        = {Lahiri et al. - 2006 - SMT Techniques for Fast Predicate Abstraction.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/LYT3TFCJ/Lahiri et al. - 2006 - SMT Techniques for Fast Predicate Abstraction.pdf:application/pdf}
}

@inproceedings{brglez_neutral_1985,
  title     = {A {Neutral} {Netlist} of 10 {Combinational} {Benchmark} {Circuits} and a {Target} {Translator} in {Fortran}},
  booktitle = {Proceedings of {IEEE} {International} {Symposium} {Circuits} and {Systems} ({ISCAS} 85)},
  publisher = {IEEE Press},
  author    = {Brglez, F. and Fujiwara, H.},
  year      = {1985},
  pages     = {677-692}
}

@inproceedings{tibebu_augmenting_2018,
  title     = {Augmenting {All} {Solution} {SAT} {Solving} for {Circuits} with {Structural} {Information}},
  opt_doi   = {10.1109/DDECS.2018.00028},
  abstract  = {All solutions SAT (All-SAT) is important in applications where we require enumerating all satisfying assignments of a propositional formula, e.g., when reasoning over many or all possible test patterns in Automatic Test Pattern Generation (ATPG). We applied structural analysis starting from primary inputs or primary outputs to generalize a current total assignment to a partial assignment. This speeds up the determination of all satisfying assignments. The experiments were conducted using a large number of random instances and different available All-SAT solvers. We show that structural analysis techniques can significantly speed up enumeration of all satisfying assignments of combinational circuits and yield the the second largest number of total satisfying assignments from all compared All-SAT solvers.},
  booktitle = {{IEEE} 21st {International} {Symposium} on {Design} and {Diagnostics} of {Electronic} {Circuits} \& {Systems}},
  author    = {Tibebu, Abraham Temesgen and Fey, Goerschwin},
  opt_month = apr,
  year      = {2018},
  opt_note  = {ISSN: 2473-2117},
  keywords  = {All-SAT, Automatic test pattern generation, Binary decision diagrams, blocking clause, Boolean functions, Combinational circuits, Data preprocessing, Logic gates, partial assignment, Periodic structures, primary inputs, primary outputs, structural analysis},
  pages     = {117-122},
  file      = {IEEE Xplore Abstract Record:/home/gabriele/snap/zotero-snap/common/Zotero/storage/K5TRE2P4/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/69FFPTAT/Tibebu and Fey - 2018 - Augmenting All Solution SAT Solving for Circuits w.pdf:application/pdf}
}

@article{hansen_unveiling_1999,
  title      = {Unveiling the {ISCAS}-85 benchmarks: a case study in reverse engineering},
  volume     = {16},
  issn       = {1558-1918},
  shorttitle = {Unveiling the {ISCAS}-85 benchmarks},
  opt_doi    = {10.1109/54.785838},
  abstract   = {Designing at higher levels of abstraction is key to managing the complexity of today's VLSI chips. The authors show how they reverse-engineered the ISCAS-85 benchmarks to add a useful, new high-level tool to the designer's arsenal.},
  number     = {3},
  journal    = {IEEE Design \& Test of Computers},
  author     = {Hansen, M.C. and Yalcin, H. and Hayes, J.P.},
  opt_month  = jul,
  year       = {1999},
  opt_note   = {Conference Name: IEEE Design \& Test of Computers},
  keywords   = {Adders, Benchmark testing, Circuit synthesis, Circuit testing, Data mining, Engineering management, Hardware design languages, Logic circuits, Logic testing, Reverse engineering},
  pages      = {72-80},
  file       = {IEEE Xplore Abstract Record:/home/gabriele/snap/zotero-snap/common/Zotero/storage/22II6843/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/UUJPS4RI/Hansen et al. - 1999 - Unveiling the ISCAS-85 benchmarks a case study in.pdf:application/pdf}
}

@inproceedings{spallitta_smt-based_2022,
  opt_series    = {Proceedings of {Machine} {Learning} {Research}},
  title         = {{SMT}-based {Weighted Model Integration} with {Structure} {Awareness}},
  volume        = {180},
  opt_url       = {https://proceedings.mlr.press/v180/spallitta22a.html},
  booktitle     = {{Proceedings} of the 38th {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
  opt_publisher = {PMLR},
  author        = {Spallitta, Giuseppe and Masina, Gabriele and Morettin, Paolo and Passerini, Andrea and Sebastiani, Roberto},
  opt_editor    = {Cussens, James and Zhang, Kun},
  year          = {2022},
  pages         = {1876-1885}
}

@incollection{hutchison_minimizing_2013,
  opt_address = {Berlin, Heidelberg},
  title       = {Minimizing {Models} for {Tseitin}-{Encoded} {SAT} {Instances}},
  volume      = {7962},
  isbn        = {978-3-642-39070-8 978-3-642-39071-5},
  opt_url     = {http://link.springer.com/10.1007/978-3-642-39071-5_17},
  abstract    = {Many applications of SAT solving can proﬁt from minimal models—a partial variable assignment that is still a witness for satisﬁability. Examples include software veriﬁcation, model checking, and counterexample-guided abstraction reﬁnement. In this paper, we examine how a given model can be minimized for SAT instances that have been obtained by Tseitin encoding of a full propositional logic formula. Our approach uses a SAT solver to eﬃciently minimize a given model, focusing on only the input variables. Experiments show that some models can be reduced by over 50 percent.},
  language    = {en},
  opt_urldate = {2023-04-27},
  booktitle   = {16th International Conference on Theory and Applications of Satisfiability Testing},
  publisher   = {Springer Berlin Heidelberg},
  author      = {Iser, Markus and Sinz, Carsten and Taghdiri, Mana},
  opt_editor  = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Järvisalo, Matti and Van Gelder, Allen},
  year        = {2013},
  opt_doi     = {10.1007/978-3-642-39071-5_17},
  note        = {Series Title: LNCS},
  pages       = {224--232},
  file        = {Iser et al. - 2013 - Minimizing Models for Tseitin-Encoded SAT Instance.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/27NYSK83/Iser et al. - 2013 - Minimizing Models for Tseitin-Encoded SAT Instance.pdf:application/pdf}
}

@article{chistikovApproximateCountingSMT2017,
  title    = {Approximate {{Counting}} in {{SMT}} and {{Value Estimation}} for {{Probabilistic Programs}}},
  author   = {Chistikov, Dmitry and Dimitrova, Rayna and Majumdar, Rupak},
  year     = {2017},
  month    = dec,
  journal  = {Acta Informatica},
  volume   = {54},
  number   = {8},
  pages    = {729--764},
  issn     = {1432-0525},
  doi      = {10.1007/s00236-017-0297-2},
  urldate  = {2023-08-24},
  abstract = {\#SMT, or model counting for logical theories, is a well-known hard problem that generalizes such tasks as counting the number of satisfying assignments to a Boolean formula and computing the volume of a polytope. In the realm of satisfiability modulo theories (SMT) there is a growing need for model counting solvers, coming from several application domains (quantitative information flow, static analysis of probabilistic programs). In this paper, we show a reduction from an approximate version of \#SMT~ to SMT. We focus on the theories of integer arithmetic and linear real arithmetic. We propose model counting algorithms that provide approximate solutions with formal bounds on the approximation error. They run in polynomial time and make a polynomial number of queries to the SMT solver for the underlying theory, exploiting ``for free'' the sophisticated heuristics implemented within modern SMT solvers. We have implemented the algorithms and used them to solve the value problem for a model of loop-free probabilistic programs with nondeterminism.},
  langid   = {english},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/UGXDWZAY/Chistikov et al. - 2015 - Approximate Counting in SMT and Value Estimation f.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/WSJ3YWKB/Chistikov et al. - 2017 - Approximate counting in SMT and value estimation f.pdf}
}


@article{boy_de_la_tour_optimality_1992,
  title    = {An {Optimality} {Result} for {Clause} {Form} {Translation}},
  volume   = {14},
  issn     = {0747-7171},
  opt_url  = {https://www.sciencedirect.com/science/article/pii/074771719290009S},
  opt_doi  = {10.1016/0747-7171(92)90009-S},
  abstract = {The exponential complexity in size of the standard clause form translation is often considered as a serious drawback of the resolution method. Fortunately, a polynomial translation is possible by first introducing definitions, one for each subformula of the conjecture. This exhaustiveness can however be proved inefficient when the length of proofs is considered. In order to improve this interesting technique, we first generalize it to renamings, which consist in introducing definitions only for a subset of subformulas, resulting in a wide set of possible clause forms from a single conjecture. We show how a simple and efficient algorithm yields a renaming which, on equivalence-free conjectures, minimizes the number of clauses among these clause forms. This translation has been tested on the famous challenge problem by P. Andrews, yielding a spectacular reduction in search space and time, and therefore is one of the more simple and general technique to efficiently produce a resolution proof for this problem.},
  language = {en},
  number   = {4},
  urldate  = {2023-05-05},
  journal  = {Journal of Symbolic Computation},
  author   = {Boy de la Tour, Thierry},
  month    = oct,
  year     = {1992},
  pages    = {283--301},
  file     = {ScienceDirect Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/XG8GUIGF/Boy de la Tour - 1992 - An optimality result for clause form translation.pdf:application/pdf;ScienceDirect Snapshot:/home/gabriele/snap/zotero-snap/common/Zotero/storage/L3TVJX9Q/074771719290009S.html:text/html}
}

@article{bjork_successful_2009,
  title    = {Successful {SAT} {Encoding} {Techniques}},
  volume   = {7},
  issn     = {15740617},
  opt_url  = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SAT190085},
  opt_doi  = {10.3233/SAT190085},
  abstract = {This article identiﬁes good practices for SAT encodings by analysing interviews with a number of well known SAT experts. The purpose is both to determine the conﬁdence in diﬀerent encoding strategies, by analysing whether there is consensus among the experts or not, as well as bringing out hidden knowledge to SAT users.},
  language = {en},
  number   = {4},
  urldate  = {2023-05-05},
  journal  = {Journal on Satisfiability, Boolean Modeling and Computation},
  author   = {Björk, Magnus},
  month    = jul,
  year     = {2009},
  pages    = {189--201},
  file     = {Björk - 2009 - Successful SAT Encoding Techniques.pdf:/home/gabriele/snap/zotero-snap/common/Zotero/storage/8F3YBFFZ/Björk - 2009 - Successful SAT Encoding Techniques.pdf:application/pdf}
}

@inproceedings{jacksonClauseFormConversions2005,
  title     = {Clause {{Form Conversions}} for {{Boolean Circuits}}},
  booktitle = {7th {{International Conference}} on {{Theory}} and {{Applications}} of {{Satisfiability Testing}}},
  author    = {Jackson, Paul and Sheridan, Daniel},
  editor    = {Hoos, Holger H. and Mitchell, David G.},
  year      = {2005},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  pages     = {183--198},
  publisher = {{Springer}},
  address   = {{Berlin, Heidelberg}},
  doi       = {10.1007/11527695_15},
  abstract  = {The Boolean circuits is well established as a data structure for building propositional encodings of problems in preparation for satisfiability solving. The standard method for converting Boolean circuits to clause form (naming every vertex) has a number of shortcomings.},
  isbn      = {978-3-540-31580-3},
  langid    = {english}
}


@inproceedings{yu_all-sat_2014,
  title     = {All-{SAT} {Using} {Minimal} {Blocking} {Clauses}},
  doi       = {10.1109/VLSID.2014.22},
  abstract  = {The All-SAT problem deals with determining all the satisfying assignments that exist for a given propositional logic formula. This problem occurs in verification applications including predicate abstraction and unbounded model checking. A typical All-SAT solver is based on iteratively computing satisfying assignments using a traditional Boolean satisfiability (SAT) solver and adding blocking clauses which are the complement of the total/partial assignments. We argue that such an algorithm is doing more work than needed and introduce new algorithms that are more efficient. Experiments show that these algorithms generate solutions with up to 14X fewer partial assignments and are up to three orders of magnitude faster.},
  booktitle = {2014 27th {International} {Conference} on {VLSI} {Design} and 2014 13th {International} {Conference} on {Embedded} {Systems}},
  author    = {Yu, Yinlei and Subramanyan, Pramod and Tsiskaridze, Nestan and Malik, Sharad},
  month     = jan,
  year      = {2014},
  opt_note  = {ISSN: 2380-6923},
  keywords  = {Aggregates, All-SAT, Benchmark testing, Computational modeling, Educational institutions, Minimization, reachability, Reactive power, SAT, SAT solver, verification, Very large scale integration},
  pages     = {86--91},
  file      = {IEEE Xplore Abstract Record:/home/gabriele/snap/zotero-snap/common/Zotero/storage/TVWS94H7/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/gabriele/snap/zotero-snap/common/Zotero/storage/FZ5DW4ZL/Yu et al. - 2014 - All-SAT Using Minimal Blocking Clauses.pdf:application/pdf}
}

@inproceedings{phanAllSolutionSatisfiabilityModulo2015f,
  title       = {All-{{Solution Satisfiability Modulo Theories}}: {{Applications}}, {{Algorithms}} and {{Benchmarks}}},
  shorttitle  = {All-{{Solution Satisfiability Modulo Theories}}},
  booktitle   = {10th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author      = {Phan, Quoc-Sang and Malacaria, Pasquale},
  year        = {2015},
  month       = aug,
  pages       = {100--109},
  publisher   = {{IEEE}},
  opt_address = {{Toulouse, France}},
  doi         = {10.1109/ARES.2015.14},
  urldate     = {2023-07-11},
  abstract    = {Satisfiability Modulo Theories (SMT) is a decision problem for logical formulas over one or more first-order theories. In this paper, we study the problem of finding all solutions of an SMT problem with respect to a set of Boolean variables, henceforth All-SMT. First, we show how an All-SMT solver can benefit various domains of application: Bounded Model Checking, Automated Test Generation, Reliability analysis, and Quantitative Information Flow. Secondly, we then propose algorithms to design an All-SMT solver on top of an existing SMT solver, and implement it into a prototype tool, called aZ3. Thirdly, we create a set of benchmarks for All-SMT in the theory of linear integer arithmetic QF LIA and the theory of bit vectors with arrays and uninterpreted functions QF AUFBV. We compare aZ3 against MathSAT, the only existing All-SMT solver, on our benchmarks. Experimental results show that aZ3 is more precise than MathSAT.},
  isbn        = {978-1-4673-6590-1},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/2QP5PZF3/Phan and Malacaria - 2015 - All-Solution Satisfiability Modulo Theories Appli.pdf}
}

@article{todaImplementingEfficientAll2016,
  title    = {Implementing {{Efficient All Solutions SAT Solvers}}},
  author   = {Toda, Takahisa and Soh, Takehide},
  year     = {2016},
  month    = nov,
  journal  = {ACM Journal of Experimental Algorithmics},
  volume   = {21},
  pages    = {1--44},
  issn     = {1084-6654, 1084-6654},
  doi      = {10.1145/2975585},
  urldate  = {2023-07-12},
  abstract = {All solutions SAT (AllSAT for short) is a variant of the propositional satisfiability problem. AllSAT has been relatively unexplored compared to other variants despite its significance. We thus survey and discuss major techniques of AllSAT solvers. We accurately implemented them and conducted comprehensive experiments using a large number of instances and various types of solvers including a few publicly available software. The experiments revealed the solvers' characteristics. We made our implemented solvers publicly available so that other researchers can easily develop their solvers by modifying our code and comparing it with existing methods.},
  langid   = {english},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/5UZUP7P4/Toda and Soh - 2016 - Implementing Efficient All Solutions SAT Solvers.pdf}
}

@incollection{gebserConflictDrivenAnswerSet2007,
  title       = {Conflict-{{Driven Answer Set Enumeration}}},
  booktitle   = {Logic {{Programming}} and {{Nonmonotonic Reasoning}}},
  author      = {Gebser, Martin and Kaufmann, Benjamin and Neumann, Andr{\'e} and Schaub, Torsten},
  editor      = {Baral, Chitta and Brewka, Gerhard and Schlipf, John},
  year        = {2007},
  volume      = {4483},
  pages       = {136--148},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-72200-7\_13},
  urldate     = {2023-07-13},
  abstract    = {We elaborate upon a recently proposed approach to finding an answer set of a logic program based on concepts from constraint processing and satisfiability checking. We extend this approach and propose a new algorithm for enumerating answer sets. The algorithm, which to our knowledge is novel even in the context of satisfiability checking, is implemented in the clasp answer set solver. We contrast our new approach to alternative systems and different options of clasp, and provide an empirical evaluation.},
  isbn        = {978-3-540-72199-4 978-3-540-72200-7},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9ZBQCGNW/Gebser et al. - 2007 - Conflict-Driven Answer Set Enumeration.pdf}
}

@inproceedings{mohleDualizingProjectedModel2018,
  title     = {Dualizing {{Projected Model Counting}}},
  booktitle = {{{IEEE}} 30th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}}},
  author    = {M{\"o}hle, Sibylle and Biere, Armin},
  year      = {2018},
  month     = nov,
  pages     = {702--709},
  issn      = {2375-0197},
  doi       = {10.1109/ICTAI.2018.00111},
  abstract  = {In many recent applications of model counting not all variables are relevant for a specific problem. For instance redundant variables are added during formula transformation. In projected model counting these redundant variables are ignored by projecting models onto relevant variables. Inspired by dual propagation which has its origin in solving quantified Boolean formulae and jointly works on both the original formula and its negation, we present a novel calculus for dual projected model counting. It allows to capture existing techniques such as blocking clauses, chronological as well as non-chronological backtracking, but also introduces new concepts including discounting and dual conflict analysis to obtain partial models. Experiments demonstrate the benefit of our approach.},
  keywords  = {Analytical models,Calculus,Computational modeling,dual,exact counting,Integrated circuit modeling,model counting,Planning,projection,Reactive power,Task analysis},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/BLVX3N9E/Möhle and Biere - 2018 - Dualizing Projected Model Counting.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/3W6V8BXZ/stamp.html}
}

@misc{mohleEnumeratingShortProjected2021,
  title         = {On {{Enumerating Short Projected Models}}},
  author        = {M{\"o}hle, Sibylle and Sebastiani, Roberto and Biere, Armin},
  year          = {2021},
  month         = dec,
  number        = {arXiv:2110.12924},
  eprint        = {2110.12924},
  primaryclass  = {cs},
  publisher     = {{arXiv}},
  urldate       = {2023-01-25},
  howpublished  = {arXiv:2110.12924 [cs]},
  abstract      = {Propositional model enumeration, or All-SAT, is the task to record all models of a propositional formula. It is a key task in software and hardware verification, system engineering, and predicate abstraction, to mention a few. It also provides a means to convert a CNF formula into DNF, which is relevant in circuit design. While in some applications enumerating models multiple times causes no harm, in others avoiding repetitions is crucial. We therefore present two model enumeration algorithms, which adopt dual reasoning in order to shorten the found models. The first method enumerates pairwise contradicting models. Repetitions are avoided by the use of so-called blocking clauses, for which we provide a dual encoding. In our second approach we relax the uniqueness constraint. We present an adaptation of the standard conflict-driven clause learning procedure to support model enumeration without blocking clauses. Our procedures are expressed by means of a calculus and proofs of correctness are provided.},
  archiveprefix = {arxiv},
  langid        = {english},
  keywords      = {Computer Science - Logic in Computer Science},
  file          = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/LH9U36FX/Möhle et al. - 2021 - On Enumerating Short Projected Models.pdf}
}

@inproceedings{morgadoGoodLearningImplicit2005,
  title     = {Good Learning and Implicit Model Enumeration},
  booktitle = {17th {{IEEE International Conference}} on {{Tools}} with {{Artificial Intelligence}}},
  author    = {Morgado, A. and {Marques-Silva}, J.},
  year      = {2005},
  month     = nov,
  pages     = {6 pp.-136},
  issn      = {2375-0197},
  doi       = {10.1109/ICTAI.2005.69},
  abstract  = {A large number of practical applications rely on effective algorithms for propositional model enumeration and counting. Examples include knowledge compilation, model checking and hybrid solvers. Besides practical applications, the problem of counting propositional models is of key relevancy in computational complexity. In recent years a number of algorithms have been proposed for propositional model enumeration. This paper surveys algorithms for model enumeration, and proposes optimizations to existing algorithms, namely through the learning and simplification of goods. Moreover, the paper also addresses open topics in model counting related with good learning. Experimental results indicate that the proposed techniques are effective for model enumeration},
  keywords  = {Artificial intelligence,Computational complexity,Context modeling,Gold},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/PKUTCDJY/Morgado and Marques-Silva - 2005 - Good learning and implicit model enumeration.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/AINYLF67/1562927.html}
}
@incollection{jinEfficientConflictAnalysis2005,
  title       = {Efficient {{Conflict Analysis}} for {{Finding All Satisfying Assignments}} of a {{Boolean Circuit}}},
  booktitle   = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  author      = {Jin, HoonSang and Han, HyoJung and Somenzi, Fabio},
  editor      = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Halbwachs, Nicolas and Zuck, Lenore D.},
  year        = {2005},
  volume      = {3440},
  pages       = {287--300},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-31980-1\_19},
  urldate     = {2023-07-12},
  abstract    = {Finding all satisfying assignments of a propositional formula has many applications to the synthesis and verification of hardware and software. An approach to this problem that has recently emerged augments a clause-recording propositional satisfiability solver with the ability to add ``blocking clauses.'' One generates a blocking clause from a satisfying assignment by taking its complement. The resulting clause prevents the solver from visiting the same solution again. Every time a blocking clause is added the search is resumed until the instance becomes unsatisfiable. Various optimization techniques are applied to get smaller blocking clauses, since enumerating each satisfying assignment would be very inefficient.},
  isbn        = {978-3-540-25333-4 978-3-540-31980-1},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/BB4FMRAF/Jin et al. - 2005 - Efficient Conflict Analysis for Finding All Satisf.pdf}
}

@incollection{grumbergMemoryEfficientAllSolutions2004,
  title       = {Memory {{Efficient All-Solutions SAT Solver}} and {{Its Application}} for {{Reachability Analysis}}},
  booktitle   = {Formal {{Methods}} in {{Computer-Aided Design}}},
  author      = {Grumberg, Orna and Schuster, Assaf and Yadgar, Avi},
  editor      = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Hu, Alan J. and Martin, Andrew K.},
  year        = {2004},
  volume      = {3312},
  pages       = {275--289},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-30494-4\_20},
  urldate     = {2023-07-13},
  abstract    = {This work presents a memory-efficient All-SAT engine which, given a propositional formula over sets of important and non-important variables, returns the set of all the assignments to the important variables, which can be extended to solutions (satisfying assignments) to the formula. The engine is built using elements of modern SAT solvers, including a scheme for learning conflict clauses and nonchronological backtracking. Re-discovering solutions that were already found is avoided by the search algorithm itself, rather than by adding blocking clauses. As a result, the space requirements of a solved instance do not increase when solutions are found. Finding the next solution is as efficient as finding the first one, making it possible to solve instances for which the number of solutions is larger than the size of the main memory.},
  isbn        = {978-3-540-23738-9 978-3-540-30494-4},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/PUD686MY/Grumberg et al. - 2004 - Memory Efficient All-Solutions SAT Solver and Its .pdf}
}

@article{bierePicoSATEssentials2008b,
  title    = {{{PicoSAT Essentials}}},
  author   = {Biere, Armin},
  editor   = {Speckenmeyer, Ewald and Li, Chu Min and Manquinho, Vasco and Tacchella, Armando},
  year     = {2008},
  month    = may,
  journal  = {Journal on Satisfiability, Boolean Modeling and Computation},
  volume   = {4},
  number   = {2-4},
  pages    = {75--97},
  issn     = {15740617},
  doi      = {10.3233/SAT190039},
  urldate  = {2023-07-13},
  abstract = {In this article we describe and evaluate optimized compact data structures for watching literals. Experiments with our SAT solver PicoSAT show that this low-level optimization not only saves memory, but also turns out to speed up the SAT solver considerably. We also discuss how to store proof traces compactly in memory and further unique features of PicoSAT including an aggressive restart schedule.},
  langid   = {english},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9GQKX2IL/Biere - 2008 - PicoSAT Essentials.pdf}
}

@inproceedings{bayardoUsingCSPLookback1997,
  title       = {Using {{CSP}} Look-Back Techniques to Solve Real-World {{SAT}} Instances},
  booktitle   = {Proceedings of the 14th {{AAAI Conference}} on {{Artificial Intelligence}}},
  author      = {Bayardo, Roberto J. and Schrag, Robert C.},
  year        = {1997},
  month       = jul,
  series      = {{{AAAI}}'97},
  pages       = {203--208},
  publisher   = {{AAAI Press}},
  opt_address = {{Providence, Rhode Island}},
  urldate     = {2024-01-10},
  abstract    = {We report on the performance of an enhanced version of the "Davis-Putnam" (DP) proof procedure for propositional satisfiability (SAT) on large instances derived from real-world problems in planning, scheduling, and circuit diagnosis and synthesis. Our results show that incorporating CSP look-back techniques -- especially the relatively new technique of relevance-bounded learning -- renders easy many problems which otherwise are beyond DP's reach. Frequently they make DP, a systematic algorithm, perform as well or better than stochastic SAT algorithms such as GSAT or WSAT. We recommend that such techniques be included as options in implementations of DP, Just as they are in systematic algorithms for the more general constraint satisfaction problem.},
  isbn        = {978-0-262-51095-0}
}

@inproceedings{liNovelSATAllsolutions2004,
  title     = {A Novel {{SAT}} All-Solutions Solver for Efficient Preimage Computation},
  booktitle = {Automation and {{Test}} in {{Europe Conference}} and {{Exhibition Proceedings Design}}},
  author    = {Li, Bin and Hsiao, M.S. and Sheng, Shuo},
  year      = {2004},
  month     = feb,
  volume    = {1},
  pages     = {272-277},
  issn      = {1530-1591},
  doi       = {10.1109/DATE.2004.1268860},
  abstract  = {In this paper, we present a novel all-solutions preimage SAT solver, SOLALL, with the following features: (1) a new success-driven learning algorithm employing smaller cut sets; (2) a marked CNF database non-trivially combining success/conflict-driven learning; (3) quantified-jump-back dynamically quantifying primary input variables from the preimage; (4) improved free BDD built on the fly, saving memory and avoiding inclusion of PI variables; finally, (5) a practical method of storing all solutions into a canonical OBDD format. Experimental results demonstrated the efficiency of the proposed approach for very large sequential circuits.},
  keywords  = {Automatic test pattern generation,Binary decision diagrams,Boolean functions,Circuit testing,Data structures,Explosions,Graphics,Input variables,Sequential circuits,Spatial databases},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/GPBXJNJ4/Li et al. - 2004 - A novel SAT all-solutions solver for efficient pre.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/AVW8SHH6/1268860.html}
}

@inproceedings{zhangAcceleratingAllSATComputation2020,
  title       = {Accelerating All-{{SAT}} Computation with Short Blocking Clauses},
  booktitle   = {Proceedings of the 35th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  author      = {Zhang, Yueling and Pu, Geguang and Sun, Jun},
  year        = {2020},
  month       = dec,
  pages       = {6--17},
  publisher   = {{ACM}},
  opt_address = {{Virtual Event Australia}},
  doi         = {10.1145/3324884.3416569},
  urldate     = {2023-07-12},
  abstract    = {The All-SAT (All-SATisfiable) problem focuses on finding all satisfiable assignments of a given propositional formula, whose applications include model checking, automata construction, and logic minimization. A typical ALL-SAT solver is normally based on iteratively computing satisfiable assignments of the given formula. In this work, we introduce BASolver, a backbone-based All-SAT solver for propositional formulas. Compared to the existing approaches, BASolver generates shorter blocking clauses by removing backbone variables from the partial assignments and the blocking clauses. We compare BASolver with 4 existing ALL-SAT solvers, namely MBlocking, BC, BDD, and NBC. Experimental results indicate that although finding all the backbone variables consumes additional computing time, BASolver is still more efficient than the existing solvers because of the shorter blocking clauses and the backbone variables used in it. With the 608 formulas, BASolver solves the largest amount of formulas (86), which is 22\%, 36\%, 68\%, 86\% more formulas than MBlocking, BC, NBC, and BDD respectively. For the formulas that are both solved by BASolver and the other solvers, BASolver uses 88.4\% less computing time on average than the other solvers. For the 215 formulas which first 1000 satisfiable assignments are found by at least one of the solvers, BASolver uses 180\% less computing time on average than the other solvers.},
  isbn        = {978-1-4503-6768-4},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/6VC3MTQF/Zhang et al. - 2020 - Accelerating all-SAT computation with short blocki.pdf}
}

@incollection{raviMinimalAssignmentsBounded2004,
  title       = {Minimal {{Assignments}} for {{Bounded Model Checking}}},
  booktitle   = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  author      = {Ravi, Kavita and Somenzi, Fabio},
  editor      = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Jensen, Kurt and Podelski, Andreas},
  year        = {2004},
  volume      = {2988},
  pages       = {31--45},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-24730-2\_3},
  urldate     = {2023-07-17},
  abstract    = {A traditional counterexample to a linear-time safety property shows the values of all signals at all times prior to the error. However, some signals may not be critical to causing the failure. A succinct explanation may help human understanding as well as speed up algorithms that have to analyze many such traces. In Bounded Model Checking (BMC), a counterexample is constructed from a satisfying assignment to a Boolean formula, typically in CNF. Modern SAT solvers usually assign values to all variables when the input formula is satisfiable. Deriving minimal satisfying assignments from such complete assignments does not lead to concise explanations of counterexamples because of how CNF formulae are derived from the models. Hence, we formulate the extraction of a succinct counterexample as the problem of finding a minimal assignment that, together with the Boolean formula describing the model, implies an objective. We present a two-stage algorithm for this problem, such that the result of each stage contributes to identify the ``interesting'' events that cause the failure. We demonstrate the effectiveness of our approach with an example and with experimental results.},
  isbn        = {978-3-540-21299-7 978-3-540-24730-2},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/2BA4NZ65/Ravi and Somenzi - 2004 - Minimal Assignments for Bounded Model Checking.pdf}
}

@inproceedings{jin2005prime,
  title     = {Prime {{Clauses}} for {{Fast Enumeration}} of {{Satisfying Assignments}} to {{Boolean Circuits}}},
  booktitle = {Proceedings of the 42nd Annual Design Automation Conference},
  author    = {Jin, HoonSang and Somenzi, Fabio},
  year      = {2005},
  pages     = {750--753},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/ZSY9X8QK/Jin and Somenzi - Prime Clauses for Fast Enumeration of Satisfying A.pdf}
}

@incollection{huangUsingDPLLEfficient2005,
  title       = {Using {{DPLL}} for {{Efficient OBDD Construction}}},
  booktitle   = {Theory and {{Applications}} of {{Satisfiability Testing}}},
  author      = {Huang, Jinbo and Darwiche, Adnan},
  editor      = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Hoos, Holger H. and Mitchell, David G.},
  year        = {2005},
  volume      = {3542},
  pages       = {157--172},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/11527695\_13},
  urldate     = {2023-07-17},
  abstract    = {The DPLL procedure has found great success in SAT, where search terminates on the first solution discovered. We show that this procedure is equally promising in a problem where exhaustive search is used, given that it is augmented with appropriate caching. Specifically, we propose two DPLL-based algorithms that construct OBDDs for CNF formulas. These algorithms have a worst-case complexity that is linear in the number of variables and size of the CNF, and exponential only in the cutwidth or pathwidth of the variable ordering. We show how modern SAT techniques can be harnessed by implementing the algorithms on top of an existing SAT solver. We discuss the advantage of this new construction method over the traditional approach, where OBDDs for subsets of the CNF formula are built and conjoined. Our experiments indicate that on many CNF benchmarks, the new method runs orders of magnitude faster than a comparable implementation of the traditional method.},
  isbn        = {978-3-540-27829-0 978-3-540-31580-3},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/HBKD4JW6/Huang and Darwiche - 2005 - Using DPLL for Efficient OBDD Construction.pdf}
}

@inproceedings{todaBDDConstructionAll2015,
  title       = {{{BDD}} Construction for All Solutions {{SAT}} and Efficient Caching Mechanism},
  booktitle   = {Proceedings of the 30th {{Annual ACM Symposium}} on {{Applied Computing}}},
  author      = {Toda, Takahisa and Tsuda, Koji},
  year        = {2015},
  month       = apr,
  pages       = {1880--1886},
  publisher   = {{ACM}},
  opt_address = {{Salamanca Spain}},
  doi         = {10.1145/2695664.2695941},
  urldate     = {2023-07-17},
  abstract    = {We improve an existing OBDD-based method of computing all total satisfying assignments of a Boolean formula, where an OBDD means an ordered binary decision diagram that is not necessarily reduced. To do this, we introduce lazy caching and finer caching by effectively using unit propagation. We implement our methods on top of a modern SAT solver, and show by experiments that lazy caching significantly accelerates the original method and finer caching in turn reduces an OBDD size.},
  isbn        = {978-1-4503-3196-8},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/6EMHS6RV/Toda and Tsuda - 2015 - BDD construction for all solutions SAT and efficie.pdf}
}

@inproceedings{liangAllSATCCBoostingAllSAT2022,
  title       = {{{AllSATCC}}: {{Boosting AllSAT Solving}} with {{Efficient Component Analysis}}},
  shorttitle  = {{{AllSATCC}}},
  booktitle   = {Proceedings of the {{31st International Joint Conference}} on {{Artificial Intelligence}}},
  author      = {Liang, Jiaxin and Ma, Feifei and Zhou, Junping and Yin, Minghao},
  year        = {2022},
  month       = jul,
  pages       = {1866--1872},
  publisher   = {{International Joint Conferences on Artificial Intelligence Organization}},
  opt_address = {{Vienna, Austria}},
  doi         = {10.24963/ijcai.2022/259},
  urldate     = {2023-07-12},
  abstract    = {All Solution SAT (AllSAT) is a variant of Propositional Satisfiability, which aims to find all satisfying assignments for a given formula. AllSAT has significant applications in different domains, such as software testing, data mining, and network verification. In this paper, observing that the lack of component analysis may result in more work for algorithms with non-chronological backtracking, we propose a DPLL-based algorithm for solving AllSAT problem, named AllSATCC, which takes advantage of component analysis to reduce work repetition caused by non-chronological backtracking. The experimental results show that our algorithm outperforms the state-of-the-art algorithms on most instances.},
  isbn        = {978-1-956792-00-3},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9QUUDR7E/Liang et al. - 2022 - AllSATCC Boosting AllSAT Solving with Efficient C.pdf}
}

@article{todaExploitingFunctionalDependencies2017,
  title    = {Exploiting {{Functional Dependencies}} of {{Variables}} in {{All Solutions SAT Solvers}}},
  author   = {Toda, Takahisa and Inoue, Takeru},
  year     = {2017},
  journal  = {Journal of Information Processing},
  volume   = {25},
  number   = {0},
  pages    = {459--468},
  issn     = {1882-6652},
  doi      = {10.2197/ipsjjip.25.459},
  urldate  = {2023-07-17},
  abstract = {All solutions SAT (AllSAT) is the problem of generating satisfying assignments to a given conjunctive normal form (CNF) and has been a key issue commonly found in several applications of formal verification including model checking. CNF encoding, which translates original problems for AllSAT solvers, spawns many auxiliary variables and, what is worse, obscures functional dependencies over variables. AllSAT solvers consequently have to deal with unnecessarily larger CNFs, although the original problems might be much more tractable in essence. This paper proposes a novel AllSAT solver along with a CNF encoding technique; our solver extracts functional dependencies through the encoding process, and the dependence is effectively utilized to solve the CNF. Our solver is designed based on the OBDD compilation technique, which allows us to efficiently handle intractable CNFs with a number of solutions in dynamic programming manner. Our proposal is very simple but powerful; experiments with real network instances showed that our solver exhibits a great improvement.},
  langid   = {english},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9UVH5I5Z/Toda and Inoue - 2017 - Exploiting Functional Dependencies of Variables in.pdf}
}

@inproceedings{jabbourEnumeratingPrimeImplicants2014a,
  title       = {Enumerating {{Prime Implicants}} of {{Propositional Formulae}} in {{Conjunctive Normal Form}}},
  booktitle   = {Logics in {{Artificial Intelligence}}},
  author      = {Jabbour, Said and {Marques-Silva}, Joao and Sais, Lakhdar and Salhi, Yakoub},
  editor      = {Ferm{\'e}, Eduardo and Leite, Jo{\~a}o},
  year        = {2014},
  series      = {Lecture {{Notes}} in {{Computer Science}}},
  pages       = {152--165},
  publisher   = {{Springer International Publishing}},
  opt_address = {{Cham}},
  doi         = {10.1007/978-3-319-11558-0\_11},
  abstract    = {In this paper, a new approach for enumerating the set prime implicants (PI) of a Boolean formula in conjunctive normal form (CNF) is proposed. It is based on an encoding of the input formula as a new one whose models correspond to the set of prime implicants of the original theory. This first PI enumeration approach is then enhanced by an original use of the boolean functions or gates usually involved in many CNF instances encoding real-world problems. Experimental evaluation on several classes of CNF instances shows the feasibility of our proposed framework.},
  isbn        = {978-3-319-11558-0},
  langid      = {english},
  keywords    = {Boolean Formula,Boolean Function,Conjunctive Normal Form,Integer Linear Programming,Multiagent System},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/SATEHPMR/Jabbour et al. - 2014 - Enumerating Prime Implicants of Propositional Form.pdf}
}

@inproceedings{luoEfficientTwophaseMethod2021,
  title     = {An {{Efficient Two-phase Method}} for {{Prime Compilation}} of {{Non-clausal Boolean Formulae}}},
  booktitle = {2021 {{IEEE}}/{{ACM International Conference On Computer Aided Design}}},
  author    = {Luo, Weilin and Want, Hai and Zhong, Hongzhen and Wei, Ou and Fang, Biqing and Song, Xiaotong},
  year      = {2021},
  month     = nov,
  pages     = {1--9},
  issn      = {1558-2434},
  doi       = {10.1109/ICCAD51958.2021.9643520},
  abstract  = {Prime compilation aims to generate all prime implicates/implicants of a Boolean formula. Recently, prime compilation of non-clausal formulae has received great attention. Since it is hard for {\textbackslash}Sigma\_2\^P, existing methods have performance issues. We argue that the main performance bottleneck stems from enlarging the search space using dual rail (DR) encoding, and computing a minimal clausal formula as a by-product. To deal with the issue, we propose a two-phase approach, namely CoAPI, for prime compilation of non-clausal formulae. Thanks to the two-phase framework, we construct a clausal formula without using DR encoding. In addition, to improve performance, the key in our work is a novel bounded prime extraction (BPE) method that, interleaving extracting prime implicates with extracting small implicates, enables constructing a succinct clausal formula rather than a minimal one. Following the assessment way of the state-of-the-art (SOTA) work, we show that CoAPI achieves SOTA performance. Particularly, for generating all prime implicates, CoAPI is up to about one order of magnitude faster. Moreover, we evaluate CoAPI on a benchmark sourcing from real-world industries. The results also confirm the outperformance of CoAPI11Our code and benchmarks are publicly available at https://github.com/LuoWeiLinWillam/CoAPI.}
}

@inproceedings{previtiPrimeCompilationNonClausal,
  title     = {Prime {{Compilation}} of {{Non-Clausal Formulae}}},
  author    = {Previti, Alessandro and Ignatiev, Alexey and Morgado, Antonio and {Marques-Silva}, Joao},
  booktitle = {24th International Joint Conference on Artificial Intelligence},
  year      = {2015},
  langid    = {english},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/XQEP45AS/Previti et al. - Prime Compilation of Non-Clausal Formulae.pdf}
}

@inproceedings{boudaneSATbasedApproachMining2016,
  title       = {A {{SAT-based}} Approach for Mining Association Rules},
  booktitle   = {Proceedings of the {{25th International Joint Conference}} on {{Artificial Intelligence}}},
  author      = {Boudane, Abdelhamid and Jabbour, Said and Sais, Lakhdar and Salhi, Yakoub},
  year        = {2016},
  month       = jul,
  series      = {{{IJCAI}}'16},
  pages       = {2472--2478},
  publisher   = {{AAAI Press}},
  opt_address = {{New York, New York, USA}},
  urldate     = {2023-07-18},
  abstract    = {Discovering association rules from transaction databases is one of the most studied data mining task. Many effective techniques have been proposed over the years. All these algorithms share the same two steps methodology: frequent itemsets enumeration followed by effective association rules generation step. In this paper, we propose a new propositional satisfiability based approach to mine association rules in a single step. The task is modeled as a Boolean formula whose models correspond to the rules to be mined. To highlight the flexibility of our proposed framework, we also address two other variants, namely the closed and indirect association rules mining tasks. Experiments on many datasets show that on both closed and indirect association rules mining tasks, our declarative approach achieves better performance than the state-of-the-art specialized techniques.},
  isbn        = {978-1-57735-770-4},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/QNV6RUQP/Boudane et al. - A SAT-Based Approach for Mining Association Rules.pdf}
}

@inproceedings{dlalaComparativeStudySATBased2016,
  title       = {A {{Comparative Study}} of {{SAT-Based Itemsets Mining}}},
  booktitle   = {Research and {{Development}} in {{Intelligent Systems XXXIII}}},
  author      = {Dlala, Imen Ouled and Jabbour, Said and Sais, Lakhdar and Yaghlane, Boutheina Ben},
  editor      = {Bramer, Max and Petridis, Miltos},
  year        = {2016},
  pages       = {37--52},
  publisher   = {{Springer International Publishing}},
  opt_address = {{Cham}},
  doi         = {10.1007/978-3-319-47175-4\_3},
  abstract    = {Mining frequent itemsets from transactional datasets is a well known problem. Thus, various methods have been studied to deal with this issue. Recently, original proposals have emerged from the cross-fertilization between data mining and artificial intelligence. In these declarative approaches, the itemset mining problem is modeled either as a constraint network or a propositional formula whose models correspond to the patterns of interest. In this paper, we focus on the propositional satisfiability based itemset mining framework. Our main goal is to enhance the efficiency of SAT model enumeration algorithms. This issue is particularly crucial for the scalability and competitiveness of such declarative itemset mining approaches. In this context, we deeply analyse the effect of the different SAT solver components on the efficiency of the model enumeration problem. Our analysis includes the main components of modern SAT solvers such as restarts, activity based variable ordering heuristics and clauses learning mechanism. Through extensive experiments, we show that these classical components play an essential role in such procedure to improve the performance by pushing forward the efficiency of SAT solvers. More precisely, our experimental evaluation includes a comparative study in enumerating all the models corresponding to the closed frequent itemsets. Additionally, our experimental analysis is extended to include the Top-k itemset mining problem.},
  isbn        = {978-3-319-47175-4},
  langid      = {english},
  keywords    = {Data Mining,Frequent Itemset Mining,Propositional Satisfiability (SAT) Declarative Approaches},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/VC6FD699/Dlala et al. - 2016 - A Comparative Study of SAT-Based Itemsets Mining.pdf}
}

@inproceedings{khurshidCaseEfficientSolution2004,
  title       = {A {{Case}} for {{Efficient Solution Enumeration}}},
  booktitle   = {Theory and {{Applications}} of {{Satisfiability Testing}}},
  author      = {Khurshid, Sarfraz and Marinov, Darko and Shlyakhter, Ilya and Jackson, Daniel},
  editor      = {Giunchiglia, Enrico and Tacchella, Armando},
  year        = {2004},
  series      = {Lecture {{Notes}} in {{Computer Science}}},
  pages       = {272--286},
  publisher   = {{Springer}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-24605-3\_21},
  abstract    = {SAT solvers have been ranked primarily by the time they take to find a solution or show that none exists. And indeed, for many problems that are reduced to SAT, finding a single solution is what matters. As a result, much less attention has been paid to the problem of efficiently generating all solutions.},
  isbn        = {978-3-540-24605-3},
  langid      = {english},
  keywords    = {Binary Decision Diagram,Fault Tree,Symmetry Breaking,Test Input,Total Order},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/PM8MY3KQ/Khurshid et al. - 2004 - A Case for Efficient Solution Enumeration.pdf}
}

@techreport{jayaraman2014automated,
  title       = {Automated Analysis and Debugging of Network Connectivity Policies},
  author      = {Jayaraman, Karthick and Bj{\o}rner, Nikolaj and Outhred, Geoff and Kaufman, Charlie},
  year        = {2014},
  month       = jul,
  number      = {MSR-TR-2014-102},
  institution = {{Microsoft}},
  abstract    = {Network connectivity policies are crucial for assuring the security and availability of large-scale datacenter. Managing these policies is fraught with complexity and operator errors. The difficulties are exacerbated when deploying large scale offerings of public cloud services where multiple tenants are hosted within customized isolation boundaries. In these large-scale settings it is impractical to depend on human effort or trial and error to maintain the correctness and consistency of policies. We describe an approach for automatically validating network connectivity policies and its implementation in a tool called SecGuru. SecGuru can check selected properties of policies, e.g., is some traffic permitted or denied, and it can compare two policies yielding a semantic diff to summarize drifts. We use bit-vector logic to encode policies and semantic diffs; and the theorem prover Z3 as the underlying solver. A key contribution is a new algorithm for compactly enumerating symbolic diffs. We finally describe the experience of using SecGuru in Azure, a public cloud provider. Azure uses SecGuru for continuously monitoring policy configurations and alerting on errors, and also as a regression test suite to check policies before deployment. As a result of using SecGuru, today Azure proactively detects and avoids policy misconfigurations that lead to security and availability issues.},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/6X56NSXR/Jayaraman et al. - Automated Analysis and Debugging of Network Connec.pdf}
}

@article{lopes2013network,
  title    = {Network {{Verification}} in the {{Light}} of {{Program Verification}}},
  author   = {Lopes, Nuno P. and Bj{\o}rner, Nikolaj and Godefroid, Patrice and Varghese, George},
  year     = {2013},
  month    = sep,
  journal  = {MSR},
  volume   = {Rep},
  abstract = {The fastest tools for network reachability queries use ad-hoc algorithms to compute all packets from a source S that can reach a destination D. This paper examines whether network reachability can be solved efficiently using existing verification tools. While most verification tools only compute reachability (``Can S reach D?''), we efficiently generalize them to compute all reachable packets. Using new and old benchmarks, we compare model checkers, SAT solvers and various Datalog implementations. The only existing verification method that worked competitively on all benchmarks in seconds was Datalog with a new composite Filter-Project operator and a Difference of Cubes representation. While Datalog is slightly slower than the Hassel C tool, it is far more flexible. We also present new results that more precisely characterize the computational complexity of network verification. This paper also provides a gentle introduction to program verification for the networking community. We would like to thank Jim Larus for inspiring this work.},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/A2J6UYKD/Lopes et al. - Network Veriﬁcation in the Light of Program Veriﬁc.pdf}
}

@inproceedings{lopesCheckingBeliefsDynamic2015,
  title     = {Checking {{Beliefs}} in {{Dynamic Networks}}},
  booktitle = {12th {{USENIX Symposium}} on {{Networked Systems Design}} and {{Implementation}}},
  author    = {Lopes, Nuno P. and Bj{\o}rner, Nikolaj and Godefroid, Patrice and Jayaraman, Karthick and Varghese, George},
  year      = {2015},
  pages     = {499--512},
  urldate   = {2023-07-18},
  isbn      = {978-1-931971-21-8},
  langid    = {english},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9KECKKXG/Lopes et al. - 2015 - Checking Beliefs in Dynamic Networks.pdf}
}

@article{clarkePredicateAbstractionANSIC2004,
  title    = {Predicate {{Abstraction}} of {{ANSI-C Programs Using SAT}}},
  author   = {Clarke, Edmund and Kroening, Daniel and Sharygina, Natasha and Yorav, Karen},
  year     = {2004},
  month    = sep,
  journal  = {Formal Methods in System Design},
  volume   = {25},
  number   = {2},
  pages    = {105--127},
  issn     = {1572-8102},
  doi      = {10.1023/B:FORM.0000040025.89719.f3},
  urldate  = {2023-07-18},
  abstract = {Predicate abstraction is a major method for verification of software. However, the generation of the abstract Boolean program from the set of predicates and the original program suffers from an exponential number of theorem prover calls as well as from soundness issues. This paper presents a novel technique that uses an efficient SAT solver for generating the abstract transition relations of ANSI-C programs. The SAT-based approach computes a more precise and safe abstraction compared to existing predicate abstraction techniques.},
  langid   = {english},
  keywords = {ANSI-C,predicate abstraction,SAT},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/U5YJKXVH/Clarke et al. - 2004 - Predicate Abstraction of ANSI-C Programs Using SAT.pdf}
}

@inproceedings{lahiriSymbolicApproachPredicate2003,
  title       = {A {{Symbolic Approach}} to {{Predicate Abstraction}}},
  booktitle   = {Computer {{Aided Verification}}},
  author      = {Lahiri, Shuvendu K. and Bryant, Randal E. and Cook, Byron},
  editor      = {Hunt, Warren A. and Somenzi, Fabio},
  year        = {2003},
  series      = {Lecture {{Notes}} in {{Computer Science}}},
  pages       = {141--153},
  publisher   = {{Springer}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-540-45069-6\_15},
  abstract    = {Predicate abstraction is a useful form of abstraction for the verification of transition systems with large or infinite state spaces. One of the main bottlenecks of this approach is the extremely large number of decision procedures calls that are required to construct the abstract state space. In this paper we propose the use of a symbolic decision procedure and its application for predicate abstraction. The advantage of the approach is that it reduces the number of calls to the decision procedure exponentially and also provides for reducing the re-computations inherent in the current approaches. We provide two implementations of the symbolic decision procedure: one based on BDDs which leverages the current advances in early quantification algorithms, and the other based on SAT-solvers. We also demonstrate our approach with quantified predicates for verifying parameterized systems. We illustrate the effectiveness of this approach on benchmarks from the verification of microprocessors, communication protocols, parameterized systems, and Microsoft Windows device drivers.},
  isbn        = {978-3-540-45069-6},
  langid      = {english},
  keywords    = {Boolean Formula,Boolean Variable,Decision Procedure,Predicate Abstraction,Symbolic Model Check},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/U9WSCFJR/Lahiri et al. - 2003 - A Symbolic Approach to Predicate Abstraction.pdf}
}

@incollection{mcmillanApplyingSATMethods2002b,
  title       = {Applying {{SAT Methods}} in {{Unbounded Symbolic Model Checking}}},
  booktitle   = {Computer {{Aided Verification}}},
  author      = {McMillan, Ken L.},
  editor      = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Brinksma, Ed and Larsen, Kim Guldstrand},
  year        = {2002},
  volume      = {2404},
  pages       = {250--264},
  publisher   = {{Springer Berlin Heidelberg}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/3-540-45657-0\_19},
  urldate     = {2023-07-13},
  abstract    = {A method of symbolic model checking is introduced that uses conjunctive normal form (CNF) rather than binary decision diagrams (BDD's) and uses a SAT-based approach to quantifier elimination. This method is compared to a traditional BDD-based model checking approach using a set of benchmark problems derived from the compositional verification of a commercial microprocessor design.},
  isbn        = {978-3-540-43997-4 978-3-540-45657-5},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/MAWA7TJP/McMillan - 2002 - Applying SAT Methods in Unbounded Symbolic Model C.pdf}
}

@article{bernasconiCompactDSOPPartial2013,
  title    = {Compact {{DSOP}} and {{Partial DSOP Forms}}},
  author   = {Bernasconi, Anna and Ciriani, Valentina and Luccio, Fabrizio and Pagli, Linda},
  year     = {2013},
  month    = nov,
  journal  = {Theory of Computing Systems},
  volume   = {53},
  number   = {4},
  pages    = {583--608},
  issn     = {1433-0490},
  doi      = {10.1007/s00224-013-9447-2},
  urldate  = {2023-07-19},
  abstract = {Given a Boolean function f on n variables, a Disjoint Sum-of-Products (DSOP) of f is a set of products (ANDs) of subsets of literals whose sum (OR) equals~f, such that no two products cover the same minterm of~f. DSOP forms are a special instance of partial DSOPs, i.e. the general case where a subset of minterms must be covered exactly once and the other minterms (typically corresponding to don't care conditions of~f) can be covered any number of times. We discuss finding DSOPs and partial DSOPs with a minimal number of products, a problem theoretically connected with various properties of Boolean functions and practically relevant in the synthesis of digital circuits. Finding an absolute minimum is hard, in fact we prove that the problem of absolute minimization of partial DSOPs is NP-hard. Therefore it is crucial to devise a polynomial time heuristic that compares favorably with the known minimization tools. To this end we develop a further piece of theory starting from the definition of the weight of a cube~c as a functions of the number of fragments induced on other cubes by the selection of~c, and show how cube weights can be exploited for building a class of minimization heuristics for DSOP and partial DSOP synthesis. A~set of experiments conducted on major benchmark functions show that our method, with a family of variants, always generates better results than the ones of previous heuristics, including the method based on a BDD representation of~f.},
  langid   = {english},
  keywords = {Computational complexity,Disjoint sum-of-products,Heuristics,Minimal form,Product weight,Sum-of-products},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/USR6VHLG/Bernasconi et al. - 2013 - Compact DSOP and Partial DSOP Forms.pdf}
}

@article{miltersenConvertingCNFDNF2005,
  title   = {On Converting {{CNF}} to {{DNF}}},
  author  = {Miltersen, Peter Bro and Radhakrishnan, Jaikumar and Wegener, Ingo},
  year    = {2005},
  month   = nov,
  journal = {Theoretical Computer Science},
  volume  = {347},
  number  = {1-2},
  pages   = {325--335},
  issn    = {03043975},
  doi     = {10.1016/j.tcs.2005.07.029},
  urldate = {2023-07-19},
  langid  = {english},
  file    = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/KCM4QEBP/Miltersen et al. - 2005 - On converting CNF to DNF.pdf}
}

@inproceedings{minatoFindingAllSimple1998,
  title     = {Finding {{All Simple Disjunctive Decompositions Using Irredundant Sum-of-Products Forms}}},
  booktitle = {1998 {{IEEE}}/{{ACM International Conference}} on {{Computer-Aided Design}}},
  author    = {Minato, S. and De Micheli, G.},
  year      = {1998},
  month     = nov,
  pages     = {111--117},
  doi       = {10.1145/288548.288586},
  abstract  = {Finding disjunctive decompositions is an important technique to realize compact logic networks. Simple disjunctive decomposition is a basic and useful concept, that extracts a single output subblock function whose input variable set is disjunctive from the other part. The paper presents a method for finding simple disjunctive decompositions by generating irredundant sum-of-products forms and applying factorization. We prove that all simple disjunctive decompositions can be extracted in our method, namely all possible decompositions are included in the factored logic networks. Experimental results show that our method can efficiently extract all the simple disjunctive decompositions of the large scale functions. Our result clarifies the relationship between the functional decomposition method and the two-level logic factorization method.},
  keywords  = {Binary decision diagrams,Logic},
  file      = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/UFPHEQG5/Minato and De Micheli - 1998 - Finding all simple disjunctive decompositions usin.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/5CPZUSV2/742859.html}
}

@incollection{barrettSatisfiabilityModuloTheories2021,
  title     = {Satisfiability {{Modulo Theories}}},
  booktitle = {Handbook of {{Satisfiability}}},
  author    = {Barrett, Clark and Sebastiani, Roberto and Seshia, Sanjit A. and Tinelli, Cesare},
  editor    = {Biere, Armin and Heule, Marijn and van Maaren, Hans and Walsh, Toby},
  year      = {2021},
  series    = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  edition   = {2},
  volume    = {336},
  pages     = {1267--1329},
  publisher = {{IOS Press}},
  doi       = {10.3233/FAIA201017},
  isbn      = {978-1-64368-160-3 978-1-64368-161-0}
}

@incollection{prestwichCNFEncodings2021,
  title     = {{{CNF Encodings}}},
  booktitle = {Handbook of {{Satisfiability}}},
  author    = {Prestwich, Steven},
  editor    = {Biere, Armin and Heule, Marijn and van Maaren, Hans and Walsh, Toby},
  year      = {2021},
  series    = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  edition   = {2},
  volume    = {336},
  pages     = {75--100},
  publisher = {{IOS Press}},
  doi       = {10.3233/FAIA200985},
  urldate   = {2024-01-10},
  isbn      = {978-1-64368-160-3 978-1-64368-161-0}
}

@inproceedings{bryantCOSMOSCompiledSimulator1987,
  title       = {{{COSMOS}}: A Compiled Simulator for {{MOS}} Circuits},
  shorttitle  = {{{COSMOS}}},
  booktitle   = {Proceedings of the 24th {{ACM}}/{{IEEE Design Automation Conference}}},
  author      = {Bryant, R. E. and Beatty, D. and Brace, K. and Cho, K. and Sheffler, T.},
  year        = {1987},
  month       = oct,
  series      = {{{DAC}} '87},
  pages       = {9--16},
  publisher   = {{Association for Computing Machinery}},
  opt_address = {{New York, NY, USA}},
  doi         = {10.1145/37888.37890},
  urldate     = {2023-07-26},
  abstract    = {The COSMOS simulator provides fast and accurate switch-level modeling of MOS digital circuits. It attains high performance by preprocessing the transistor network into a functionally equivalent Boolean representation. This description, produced by the symbolic analyzer ANAMOS, captures all aspects of switch-level networks including bidirectional transistors, stored charge, different signal strengths, and indeterminate (X) logic values. The LGCC program translates the Boolean representation into a set of machine language evaluation procedures and initialized data structures. These procedures and data structures are compiled along with code implementing the simulation kernel and user interface to produce the simulation program. The simulation program runs an order of magnitude faster than our previous simulator MOSSIM II.},
  isbn        = {978-0-8186-0781-3},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/NN33XIX3/Bryant et al. - 1987 - COSMOS a compiled simulator for MOS circuits.pdf}
}

@article{palopoliAlgorithmsSelectiveEnumeration1999,
  title    = {Algorithms for Selective Enumeration of Prime Implicants},
  author   = {Palopoli, Luigi and Pirri, Fiora and Pizzuti, Clara},
  year     = {1999},
  month    = jul,
  journal  = {Artificial Intelligence},
  volume   = {111},
  number   = {1-2},
  pages    = {41--72},
  issn     = {00043702},
  doi      = {10.1016/S0004-3702(99)00035-1},
  urldate  = {2023-07-26},
  abstract = {We present a new approach for selective enumeration of prime implicants of CNF formulae. The method uses a 0\textendash 1 programming schema, having feasible solutions corresponding to prime implicants. Prime implicants are generated one at a time, so that as many of them can be computed as needed by the specific application considered. Selective generation is also supported, whereby preferences on the structure of generated prime implicants can be specified. We present two algorithms for selective enumeration of prime implicants and discuss their properties. The former amounts to solving the basic 0\textendash 1 programming schema first, to obtain an implicant {$\psi$} (not necessarily a prime one), and then generating a prime implicant implied by {$\psi$} . The latter is based on adding a suitable minimization function to the basic 0\textendash 1 programming schema so that finding optimal solutions corresponds one-to-one to generating prime implicants of the original theory. We show that the latter algorithm has wider applicability but is less efficient than the former one. Finally we present experimental results, which confirm the effectiveness of our approach in computing prime implicants of CNF formulae. \textcopyright{} 1999 Elsevier Science B.V. All rights reserved.},
  langid   = {english},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/EGRVRYMQ/Palopoli et al. - 1999 - Algorithms for selective enumeration of prime impl.pdf}
}

@inproceedings{friedAllSATCombinationalCircuits2023,
  title       = {{{AllSAT}} for {{Combinational Circuits}}},
  booktitle   = {26th International Conference on Theory and Applications of Satisfiability Testing},
  author      = {Fried, Dror and Nadel, Alexander and Shalmon, Yogev},
  editor      = {Mahajan, Meena and Slivovsky, Friedrich},
  year        = {2023},
  series      = {Leibniz International Proceedings in Informatics ({{LIPIcs}})},
  volume      = {271},
  pages       = {9:1--9:18},
  publisher   = {{Schloss Dagstuhl \textendash{} Leibniz-Zentrum f\"ur Informatik}},
  opt_address = {{Dagstuhl, Germany}},
  issn        = {1868-8969},
  doi         = {10.4230/LIPIcs.SAT.2023.9},
  isbn        = {978-3-95977-286-0},
  urn         = {urn:nbn:de:0030-drops-184717},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/YPUVUD73/Fried et al. - 2023 - AllSAT for Combinational Circuits.pdf}
}

@inproceedings{masinaCNFConversionDisjoint2023,
  title       = {On {{CNF Conversion}} for {{Disjoint SAT Enumeration}}},
  booktitle   = {26th International Conference on Theory and Applications of Satisfiability Testing},
  author      = {Masina, Gabriele and Spallitta, Giuseppe and Sebastiani, Roberto},
  editor      = {Mahajan, Meena and Slivovsky, Friedrich},
  year        = {2023},
  series      = {Leibniz International Proceedings in Informatics ({{LIPIcs}})},
  volume      = {271},
  pages       = {15:1--15:16},
  publisher   = {{Schloss Dagstuhl \textendash{} Leibniz-Zentrum f\"ur Informatik}},
  opt_address = {{Dagstuhl, Germany}},
  issn        = {1868-8969},
  doi         = {10.4230/LIPIcs.SAT.2023.15},
  isbn        = {978-3-95977-286-0},
  urn         = {urn:nbn:de:0030-drops-184775},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/RAS98B7Q/Masina et al. - 2023 - On CNF Conversion for Disjoint SAT Enumeration.pdf}
}

@article{geComputingEstimatingVolume2018,
  title   = {Computing and Estimating the Volume of the Solution Space of {{SMT}}({{LA}}) Constraints},
  author  = {Ge, Cunjing and Ma, Feifei and Zhang, Peng and Zhang, Jian},
  year    = {2018},
  month   = sep,
  journal = {Theoretical Computer Science},
  volume  = {743},
  pages   = {110--129},
  issn    = {03043975},
  doi     = {10.1016/j.tcs.2016.10.019},
  urldate = {2023-08-24},
  langid  = {english},
  file    = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/BEXI4C6E/Ge et al. - 2018 - Computing and estimating the volume of the solutio.pdf}
}

@inproceedings{maVolumeComputationBoolean2009,
  title       = {Volume {{Computation}} for {{Boolean Combination}} of {{Linear Arithmetic Constraints}}},
  booktitle   = {Automated {{Deduction}}},
  author      = {Ma, Feifei and Liu, Sheng and Zhang, Jian},
  editor      = {Schmidt, Renate A.},
  year        = {2009},
  series      = {Lecture {{Notes}} in {{Computer Science}}},
  pages       = {453--468},
  publisher   = {{Springer}},
  opt_address = {{Berlin, Heidelberg}},
  doi         = {10.1007/978-3-642-02959-2_33},
  abstract    = {There are many works on the satisfiability problem for various logics and constraint languages, such as SAT and Satisfiability Modulo Theories (SMT). On the other hand, the counting version of decision problems is also quite important in automated reasoning. In this paper, we study a counting version of SMT, i.e., how to compute the volume of the solution space, given a set of Boolean combinations of linear constraints. The problem generalizes the model counting problem and the volume computation problem for convex polytopes. It has potential applications to program analysis and verification, as well as approximate reasoning, yet it has received little attention. We first give a straightforward method, and then propose an improved algorithm. We also describe two ways of incorporating theory-level lemma learning technique into the algorithm. They have been implemented, and some experimental results are given. Through an example program, we show that our tool can be used to compute how often a given program path is executed.},
  isbn        = {978-3-642-02959-2},
  langid      = {english},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/9BVZ9HA6/ma2009.pdf}
}

@article{zhouEstimatingVolumeSolution2015,
  title    = {Estimating the {{Volume}} of {{Solution Space}} for {{Satisfiability Modulo Linear Real Arithmetic}}},
  author   = {Zhou, Min and He, Fei and Song, Xiaoyu and He, Shi and Chen, Gangyi and Gu, Ming},
  year     = {2015},
  month    = feb,
  journal  = {Theory of Computing Systems},
  volume   = {56},
  number   = {2},
  pages    = {347--371},
  issn     = {1433-0490},
  doi      = {10.1007/s00224-014-9553-9},
  urldate  = {2023-08-24},
  abstract = {Satisfiability Modulo Theories techniques can check if a formula is satisfiable. In many cases, not only the qualitative judgment (satisfiable or not) but also the quantitative judgment (the dimension and size of the solution space) are of practical interest. For instance, the volume of path condition formula reflects the probability of the corresponding program path being taken. However, existing algorithms are not practical because they only work for small instances. Given a formula with Boolean structures, its volume is typically obtained by first decomposing it to a series of conjunctions (of linear constraints) with disjoint solution spaces and then accumulating the volume of each one. For the former step, we propose a BDD-based search algorithm which sharply reduces the number of conjunctions. For the latter one, we propose a Monte-Carlo integration with a ray-based sampling strategy, which approximates the volume efficiently and accurately. Furthermore, degenerate solution spaces, which are not considered by other algorithms, could be handled properly by ours. Experimental results show that our method can handle formulas with up to 20 variables, which will cover many practical cases in software engineering},
  langid   = {english},
  keywords = {Linear arithmetic,Monte-Carlo integration,Satisfiability modulo theories,Volume estimation},
  file     = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/Y25F5CUM/Zhou et al. - 2015 - Estimating the Volume of Solution Space for Satisf.pdf}
}

@inproceedings{liuProgramAnalysisQualitative2011,
  title      = {Program {{Analysis}}: {{From Qualitative Analysis}} to {{Quantitative Analysis}} ({{NIER Track}})},
  shorttitle = {Program Analysis},
  booktitle  = {33rd {{International Conference}} on {{Software Engineering}}},
  author     = {Liu, Sheng and Zhang, Jian},
  year       = {2011},
  month      = may,
  pages      = {956--959},
  issn       = {1558-1225},
  doi        = {10.1145/1985793.1985957},
  abstract   = {We propose to combine symbolic execution with volume computation to compute the exact execution frequency of program paths and branches. Given a path, we use symbolic execution to obtain the path condition which is a set of constraints; then we use volume computation to obtain the size of the solution space for the constraints. With such a methodology and supporting tools, we can decide which paths in a program are executed more often than the others. We can also generate certain test cases that are related to the execution frequency, e.g., those covering cold paths.},
  keywords   = {Computer science,Concrete,execution probability,Numerical models,program analysis,Semantics,Software,symbolic execution,Syntactics,Testing},
  file       = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/2N3SX39V/Liu and Zhang - 2011 - Program analysis from qualitative analysis to qua.pdf;/home/gabriele/snap/zotero-snap/common/Zotero/storage/3DNTYYTJ/6032561.html}
}

@inproceedings{belleProbabilisticInferenceHybrid2015,
  title       = {Probabilistic {{Inference}} in {{Hybrid Domains}} by {{Weighted Model Integration}}},
  booktitle   = {Proceedings of the {{24th International Joint Conference}} on {{Artificial Intelligence}}},
  author      = {Belle, Vaishak and Passerini, Andrea and den Broeck, Guy Van},
  year        = {2015},
  month       = jun,
  pages       = {2770--2776},
  publisher   = {{AAAI Press}},
  opt_address = {{Buenos Aires, Argentina}},
  urldate     = {2022-12-19},
  abstract    = {Weighted model counting (WMC) on a propositional knowledge base is an effective and general approach to probabilistic inference in a variety of formalisms, including Bayesian and Markov Networks. However, an inherent limitation of WMC is that it only admits the inference of discrete probability distributions. In this paper, we introduce a strict generalization of WMC called weighted model integration that is based on annotating Boolean and arithmetic constraints, and combinations thereof. This methodology is shown to capture discrete, continuous and hybrid Markov networks. We then consider the task of parameter learning for a fragment of the language. An empirical evaluation demonstrates the applicability and promise of the proposal.},
  isbn        = {978-1-57735-738-4},
  langid      = {english},
  keywords    = {conference,selected,strong},
  file        = {/home/gabriele/snap/zotero-snap/common/Zotero/storage/D9EZGZ8A/Belle et al. - 2015 - Probabilistic Inference in Hybrid Domains by Weigh.pdf}
}

@inproceedings{amaruEPFLCombinationalBenchmark2015a,
  title       = {The {{EPFL Combinational Benchmark Suite}}},
  booktitle   = {Proceedings of the 24th {{International Workshop}} on {{Logic}} \& {{Synthesis}}},
  author      = {Amar{\`u}, Luca and Gaillardon, Pierre-Emmanuel and De Micheli, Giovanni},
  year        = {2015},
  opt_address = {{Mountain View, CA}},
  abstract    = {In this paper, we present the EPFL combinational benchmark suite. We aim at completing existing benchmark suites by focusing only on \&lt;i\&gt;natively\&lt;/i\&gt; combinational benchmarks. The EPFL combinational benchmark suite consists of 23 combinational circuits designed to challenge modern logic optimization tools. It is further divided into three parts. The first part includes 10 arithmetic benchmarks, e.g., square-root, hypotenuse, divisor, multiplier etc.. The second part consists of 10 random/control benchmarks, e.g., round-robin arbiter, lookahead XY router, alu control unit, memory controller etc.. The third part contains 3 very large circuits, featuring more than ten million gates each. All benchmarks have a moderate number of inputs/outputs ranging from few tens to about one thousand. The EPFL benchmark suite is available to the public and distributed in all Verilog, VHDL, BLIF and AIGER formats. In addition to providing the benchmarks, we keep track of the best optimization results, mapped into LUT-6, for size and depth metrics. Better logic implementations can be submitted online. After combinational equivalence checking tests, the best LUT-6 realizations will be included in the benchmark suite together with the author's name and affiliation.}
}



@inproceedings{spallittaDisjointPartialEnumeration2024,
  title           = {Disjoint {{Partial Enumeration}} without {{Blocking Clauses}}},
  author          = {Spallitta, Giuseppe and Sebastiani, Roberto and Biere, Armin},
  year            = {2024},
  month           = jan,
  optcrossref     = {},
  optkey          = {},
  booktitle       = {Proc. AAAI 2024. To appear},
  opteditor       = {},
  optvolume       = {},
  optnumber       = {},
  optseries       = {},
  optpages        = {},
  optmonth        = {},
  optaddress      = {},
  optorganization = {},
  optpublisher    = {},
  note            = {Available also as arXiv preprint \url{https://arxiv.org/abs/2306.00461}.},
  abstract        = {A basic algorithm for enumerating disjoint propositional models (disjoint AllSAT) is based on adding blocking clauses incrementally, ruling out previously found models. On the one hand, blocking clauses have the potential to reduce the number of generated models exponentially, as they can handle partial models. On the other hand, the introduction of a large number of blocking clauses affects memory consumption and drastically slows down unit propagation. We propose a new approach that allows for enumerating disjoint partial models with no need for blocking clauses by integrating: Conflict-Driven Clause-Learning (CDCL), Chronological Backtracking (CB), and methods for shrinking models (Implicant Shrinking). Experiments clearly show the benefits of our novel approach.},
  optannote       = {}
}

@article{spallittaEnhancingSMTbasedWeighted2024a,
  title    = {Enhancing {{SMT-based Weighted Model Integration}} by Structure Awareness},
  author   = {Spallitta, Giuseppe and Masina, Gabriele and Morettin, Paolo and Passerini, Andrea and Sebastiani, Roberto},
  year     = {2024},
  month    = mar,
  journal  = {Artificial Intelligence},
  volume   = {328},
  pages    = {104067},
  issn     = {0004-3702},
  doi      = {10.1016/j.artint.2024.104067},
  urldate  = {2024-02-05},
  abstract = {The development of efficient exact and approximate algorithms for probabilistic inference is a long-standing goal of artificial intelligence research. Whereas substantial progress has been made in dealing with purely discrete or purely continuous domains, adapting the developed solutions to tackle hybrid domains, characterized by discrete and continuous variables and their relationships, is highly non-trivial. Weighted Model Integration (WMI) recently emerged as a unifying formalism for probabilistic inference in hybrid domains. Despite a considerable amount of recent work, allowing WMI algorithms to scale with the complexity of the hybrid problem is still a challenge. In this paper we highlight some substantial limitations of existing state-of-the-art solutions, and develop an algorithm that combines SMT-based enumeration, an efficient technique in formal verification, with an effective encoding of the problem structure. This allows our algorithm to avoid generating redundant models, resulting in drastic computational savings. Additionally, we show how SMT-based approaches can seamlessly deal with different integration techniques, both exact and approximate, significantly expanding the set of problems that can be tackled by WMI technology. An extensive experimental evaluation on both synthetic and real-world datasets confirms the substantial advantage of the proposed solution over existing alternatives. The application potential of this technology is further showcased on a prototypical task aimed at verifying the fairness of probabilistic programs.}
}
