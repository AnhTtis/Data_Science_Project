%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% This is a (brief) model paper using the achemso class
%% The document class accepts keyval options, which should include
%% the target journal and optionally the manuscript type. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%reviewer{
%1. Roland Lindh (roland.lindh@kemi.uu.se)
%2. William James Glover (william.glover@nyu.edu )
%3. Bin Jiang (bjiangch@ustc.edu.cn)
%4. Troy Van Voorhis (tvan@mit.edu)
%5. Zhenfei Liu (zfliu@wayne.edu)
%}
\documentclass[journal=jctcce,manuscript=article]{achemso}
\SectionNumbersOn
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Place any additional packages needed here.  Only include packages
%% which are essential, to avoid problems later. Do NOT use any
%% packages which require e-TeX (for example etoolbox): the e-TeX
%% extensions are not currently available on the ACS conversion
%% servers.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
%\usepackage[version=3]{mhchem} % Formula subscripts using \ce{}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage[font=small,labelfont=bf]{subcaption}
\usepackage{threeparttable}
\usepackage{booktabs,siunitx}
\usepackage{physics}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{algorithm}% http://ctan.org/pkg/algorithm
% \usepackage{algorithmic}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
% \usepackage{floatrow}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If issues arise when submitting your manuscript, you may want to
%% un-comment the next line.  This provides information on the
%% version of every file you have used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\listfiles

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Place any additional macros here.  Please use \newcommand* where
%% possible, and avoid layout-changing macros (which are not used
%% when typesetting).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand*\mycommand[1]{\texttt{\emph{#1}}}
\renewcommand{\thesection}{\Roman{section}}
\renewcommand\thesubsection{\Alph{subsection}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Meta-data block
%% ---------------
%% Each author should be given as a separate \author command.
%%
%% Corresponding authors should have an e-mail given after the author
%% name as an \email command. Phone and fax numbers can be given
%% using \phone and \fax, respectively; this information is optional.
%%
%% The affiliation of authors is given after the authors; each
%% \affiliation command applies to all preceding authors not already
%% assigned an affiliation.
%%
%% The affiliation takes an option argument for the short name.  This
%% will typically be something like "University of Somewhere".
%%
%% The \altaffiliation macro should be used for new address, etc.
%% On the other hand, \alsoaffiliation is used on a per author basis
%% when authors are associated with multiple institutions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{Junhan Chen}
\affiliation[Upenn]
{Department of Chemistry, University of Pennsylvania, Philadelphia, Pennsylvania 19104, USA}
\author{Joseph Subotnik}
\email{subotnik@sas.upenn.edu}
\phone{+1 (215) 746-7078}
\affiliation[Upenn]
{Department of Chemistry, University of Pennsylvania, Philadelphia, Pennsylvania 19104, USA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The document title should be given as usual. Some journals require
%% a running title from the author: this should be supplied as an
%% optional argument to \title.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[An \textsf{achemso} demo]
  { A Dynamically Weighted Constrained Complete Active Space Ansatz for Constructing Multiple Potential Energy Surfaces Within the Anderson-Holstein Model }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Some journals require a list of abbreviations or keywords to be
%% supplied. These should be set up here, and will be printed after
%% the title and author information, if needed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \abbreviations{IR,NMR,UV}
% \keywords{Complete Active Space, State Average, Dynamically Weighting, Metal Surface, Constraint}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The manuscript does not need to include \maketitle, which is
%% executed automatically.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\doublespacing
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The "tocentry" environment can be used to create an entry for the
%% graphical table of contents. It is given here as some journals
%% require that it is printed as part of the abstract page. It will
%% be automatically moved as appropriate.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{tocentry}
\begin{center}
\includegraphics[width=7.25cm, height=4.45cm]{images2/jctc_TOC.pdf}
\end{center}
% Some journals require a graphical entry for the Table of Contents.
% This should be laid out ``print ready'' so that the sizing of the
% text is correct.

% Inside the \texttt{tocentry} environment, the font used is Helvetica
% 8\,pt, as required by \emph{Journal of the American Chemical
% Society}.

% The surrounding frame is 9\,cm by 3.5\,cm, which is the maximum
% permitted for  \emph{Journal of the American Chemical Society}
% graphical table of content entries. The box will not resize if the
% content is too big: instead it will overflow the edge of the box.

% This box and the associated title will always be printed on a
% separate page at the end of the document.

\end{tocentry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The abstract environment will automatically gobble the contents
%% if an abstract is not used by the target journal.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We derive and implement the necessary equations for solving a dynamically weighted, state-averaged constrained CASSCF(2,2) wavefunction describing a molecule on a metal surface.  We show that a partial constraint is far more robust than a full constraint. We further calculate the system-bath electronic couplings that arise because, near a metal, there is a continuum (rather than discrete) number of electronic states.  This approach should be very useful for simulating heterogeneous electron transfer going forward.  
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Start the main part of the manuscript here.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

\section{Introduction}
Molecular dynamics at metal surfaces is a fascinating research area. 
From a theoretical perspective, there are just so many processes of interest: fast molecular scattering\cite{waldeck1985nonradiative,wodtke2004electronically,bartels2011energy,kandratsenka2018unified,shenvi2009dynamical}, slow electrochemical dynamics (e.g. molecular junctions\cite{alemani2006electric,danilov2006electron,donarini2006dynamical,henningsen2007inducing,datta1997current,samanta1996electronic,nitzan2003electron,mujica1996current,hsu1997sequential,stipe1998single}), electron transfer\cite{marcus1956theory,hush1961adiabatic,levich1960adiabatic,cukier1998proton,jortner1998charge}, vibrational dissipation\cite{morin1992vibrational, huang2000vibrational}, and electron-hole creation\cite{jiang2016electron,persson1982electron}. Of course, all of these processes can couple to photons (e.g. photo-electrochemistry\cite{de2000photoelectrochemistry}) or to protons (i.e. heterogeneous proton-coupled electron transfer\cite{hammes2015proton}).
%and even more if one allows for  photons. 
From an experimental point of view, all of the above can be studied, even though it is  difficult to separate the different effects. 
%the molecule scattering is one of experiments that attracts a great deal of attention for the interfacial study; \cite{waldeck1985nonradiative,wodtke2004electronically,bartels2011energy,kandratsenka2018unified,shenvi2009dynamical} From a theoretical perspective, 

In the present article, our interest is in the area of non-adiabatic dynamics and the question of how to propagate nuclear dynamics for molecules when electron transfer is possible.   The phenomenon of interfacial electron transfer at a metal surface lies at the heart of Marcus's electrochemical rate theory\cite{marcus1963theory} %and beyond\cite{hush1961adiabatic,levich1960adiabatic,cukier1998proton,jortner1998charge}). What's more, people have also developed some new dynamical techniques,
and in recent years our research group \cite{dou2020nonadiabatic, shenvi2009nonadiabatic, dou2016broadened, jin2021nonadiabatic}
and others have made a broad push to model such dynamics semiclassically (as applicable to large systems).
While quite a bit of progress has been made to date, the inevitable practical problem that arises is not of a {\em dynamical} nature but rather of an {\em electronic structure} nature. How can 
we best (and most quickly) describe the electronic wavefunction of a  molecule at an interface, especially if there is strong molecule-metal coupling?  The usual frameworks would be GW methods\cite{hedin1965new,onida2002electronic, liu2019accelerating}, embedding methods\cite{kluner2002periodic,lahav2007self,mehdaoui2007understanding,martirez2017prediction}, constrained DFT\cite{wu2006extracting,wu2005direct,behler2007nonadiabatic,kaduk2012constrained,meng2022pragmatic,goldey2017charge,ma2020pycdft,souza2013constrained}, and/or $\Delta$SCF\cite{gavnholt2008delta}. That being said, recently\cite{chenunpublish} we introduced an orthogonal approach. Namely, we showed early data suggesting that a small CASSCF(2,2) calculation (if properly constrained) could function as an excellent method, balancing accuracy and computational speed. 
The key insight presented in Ref. \citenum{chenunpublish} is that, when constructing such a CASSCF(2,2) approach, one must be sure  $(i)$ to constrain the two active orbitals so that their total population has some overlap with the molecule on the surface; and $(ii)$ to use state-averaging so as to balance the gap between the ground and excited state and make smooth surfaces. If one implements these guidelines, Ref. \citenum{chenunpublish} demonstrates that the resulting algorithm can seemingly perform quite well (at least for those models tested).


With this background in mind, in the present paper, we have three goals in mind. First,  because  the molecular constraint  just described above [($i$)] is highly non-standard, we will show how to derive the necessary equations (and we will further analyze other possible constraints).  Second, for the sake of completeness, we will then provide step-by-step instructions delineating exactly how to solve the equations just described,  and we will benchmark the convergence of our proposed optimization. Third and finally, going beyond Ref. \citenum{chenunpublish}, we will investigate the couplings to the bath 
that arise from the infinite continuum of states. These couplings are needed if we wish to run fully nonadiabatic dynamics that are compatible with Marcus's electrochemical rate expression and achieve electronic equilibration to the correct temperature, e.g. as in the FSSH-ER \cite{jin2021nonadiabatic} dynamics. 

\section{Theory}
We will now present the relevant equations as far as determining a  constrained CASSCF(2,2) solution for an impurity on a metallic substrate.

\subsection{Review of CASSCF(2,2) Theory}
To implement a constrained CASSCF theory, we must  establish the necessary nomenclature conventions. Henceforward, we let  $i,j$ represent inactive (i.e. fully occupied) orbitals; $t,u,v,w,x,y$ represent active orbitals; $a$ represent an (empty) virtual orbital; and $m,n,p,q,r,s$ represent arbitrary orbitals. 
Clearly, the identity can be resolved as
\begin{equation}
    \hat{I} = \hat{P}_{inactive} + \hat{P}_{active} + \hat{P}_{virtual}
\end{equation}
where $\hat{P}_{inactive}, \hat{P}_{active}$ and $\hat{P}_{virtual}$ are projection operators onto the inactive, active, and virtual orbitals.
Subscripts $\alpha,\beta$ index electronic spin. $p_{\alpha}$ refers to a spin orbital while $p$ refers to a spatial orbital. We index atomic orbitals with greek letters $\mu$ and $\nu$.

We will now give a very brief review of CASSCF following Ref. \citenum{helgaker2013molecular}(Helgaker). The savvy reader familiar with the CASSCF formalism can skip directly to Sec. \ref{subsec:pc}.

We consider a spin-conserving Hamiltonian in second quantization,  %With Eqn.\ref{eqn:Hamiltonian}:
\begin{equation}
\begin{aligned}
\label{eqn:Hamiltonian}    H&=\sum_{pq}\sum_{\alpha}h_{p_{\alpha}q_{\alpha}}p_{\alpha}^{\dagger}q_{\alpha}\\
&+\frac{1}{2}\sum_{pqrs}\sum_{\alpha\beta}g_{p_{\alpha}q_{\alpha}r_{\beta}s_{\beta}}p_{\alpha}^{\dagger}r_{\beta}^{\dagger}s_{\beta}q_{\alpha}\\
\end{aligned}
\end{equation}
Because we do not include spin-orbit coupling, the one electron Hamiltonian does not depend on spin: 
\begin{equation}
     h_{p_{\alpha}q_{\alpha}}  = h_{pq} 
\end{equation}

The two electron integrals are written in chemists' notation
\begin{equation}
\begin{aligned}
&g_{mnpq}=(mn|pq)\\
&=\int\frac{\phi_m^*(\bm{r_1})\phi_n(\bm{r_1})\phi_p^*(\bm{r_2})\phi_q(\bm{r_2})}{|\bm{r_1}-\bm{r_2}|}d\bm{r_1}d\bm{r_2}
\end{aligned}
\end{equation}
with the following symmetries:
\begin{equation}
    g_{pqrs}=g_{p_{\alpha}q_{\alpha}r_{\beta}s_{\beta}}\\
\end{equation}
A simple calculations shows that the total energy (i.e. the expectation value of Hamiltonian) can be written as:
\begin{equation}
\label{eqn:Ecasscf}
    \begin{aligned}
        \expval{H}=\sum_{pq}h_{pq}D_{pq}+\frac{1}{2}\sum_{pqrs}g_{pqrs}\tilde{D}_{pqrs}
    \end{aligned}
\end{equation}
where the one-particle $D_{mn}$ and two-particle $\tilde{D}_{mnpq}$ density matrices are defined as:
\begin{equation}
    \begin{aligned}
        D_{pq}&=\sum_{\alpha}\mel{0}{p_{\alpha}^{\dagger}q_{\alpha}}{0}\\
        \tilde{D}_{pqrs}&=\sum_{\alpha\beta}\mel{0}{p_{\alpha}^{\dagger}r_{\beta}^{\dagger}s_{\beta}q_{\alpha}}{0}\\
    \end{aligned}
\end{equation}
where $\ket{0}$ represents the multi-configurational ground state.


Following Ref. \citenum{helgaker2013molecular}, the total electronic energy can be written using the (non-Hermitian) generalized Fock matrix $F$ and the one electron density matrix $D$:
\begin{equation}
    E=\frac{1}{2}\sum_{pq}(D_{pq}h_{pq}+\delta_{pq}F_{pq}).
\end{equation}
Here,  the generalized Fock matrix is defined as:
\begin{equation}
    F_{mn}=\sum_{\alpha}\mel{0}{m^{\dagger}_{\alpha}[n_{\alpha},\hat{H}]}{0}
\end{equation}

which is equivalent to:
\begin{equation}
    \begin{aligned}
    \label{eqn:gF}
        F_{mn}&=\sum_{q}D_{mq}h_{nq}+\sum_{qrs}\tilde{D}_{mqrs}g_{nqrs}\\
        &=\sum_{q}D_{mq}h_{nq}+\sum_{qrs}\tilde{D}_{rsmq}g_{rsnq},
    \end{aligned}
\end{equation}
In the above equation, the second equality uses the relationship:
\begin{equation}
\begin{aligned}
    \tilde{D}_{mqrs}&=\tilde{D}_{rsmq}\\
    g_{mqrs}&=g_{rsmq}
\end{aligned}
\end{equation}
 For real orbitals, one can switch $\{mn\}$ or $\{pq\}$, i.e.:
\begin{equation}
    g_{mnpq}=g_{nmpq}=g_{mnqp}=g_{nmqp}
\end{equation}

To calculate general Fock matrix $F_{mn}$, there are three different cases for the row index $m$:
\begin{enumerate}
\item If the first index is inactive $i$ and the second index is any orbital $n$:
\begin{equation}
\begin{aligned}
    F_{in}&=\sum_qD_{iq}h_{nq}+\sum_{qrs}\tilde{D}_{rsiq}g_{rsnq}\\
    &=2h_{ni}+\sum_{qrs}(2\delta_{iq}D_{rs}-\delta_{si}D_{rq})g_{rsnq}\\
    &=2h_{ni}+\sum_{rs}D_{rs}(2g_{rsni}-g_{rins})\\
    &=2(^{I}F_{ni}+^{A}F_{ni})
\end{aligned}
\end{equation}
Here the second equality uses the relationship: 
\begin{equation}
    \begin{aligned}
        D_{iq}&=2\delta_{iq}\\
        \tilde{D}_{rsiq}&=2\delta_{iq}D_{rs}-\delta_{si}D_{rq},
    \end{aligned}
\end{equation}
and the so-called inactive $^{I}F$ and active $^{A}F$ Fock matrices are defined as:
\begin{equation}
    \begin{aligned}
        ^{I}F_{mn}&=h_{mn}+\sum_{j}(2g_{mnjj}-g_{mjjn})\\
        ^{A}F_{mn}&=\sum_{vw}D_{vw}(g_{mnvw}-\frac{1}{2}g_{mwvn})
    \end{aligned}
\end{equation}
\item When the first index is active $v$ and the second index is any orbital $n$:
\begin{align}
\label{fvn1}
&F_{vn}=\sum_{q}D_{vq}h_{nq}+\sum_{qrs}\tilde{D}_{vqrs}g_{nqrs}\\
\nonumber&=\sum_{w}D_{vw}h_{nw}\\ \label{fvn2}&+\sum_{iqs}\tilde{D}_{vqis}g_{isnq}+\sum_{wqs}\tilde{D}_{vqws}g_{wsnq}\\  
\nonumber&=\sum_{w}D_{vw}h_{nw}+\sum_{wi}D_{vw}(2g_{iinw}-g_{iwni})\\ 
\label{fvn3}&+\sum_{wxy}\tilde{D}_{vxwy}g_{wynx}\\
\label{fvn4}&=\sum_{w}{^{I}F}_{nw}D_{vw}+Q_{vn}
\end{align}
In going from Eq. \ref{fvn1} to \ref{fvn2}, we change from the arbitrary index $q$ to the active index $w$ because only $D_{vw}$ is non-zero (i.e. $D_{vi}$ and $D_{va}$ are always zero). Between Eq. \ref{fvn1} and \ref{fvn2}, we  separate the sum over an arbitrary index $r$ into a sum over an inactive index $i$ and an active index $w$ as far as the $\tilde{D}_{vqrs}$ term is concerned. Between Eq. \ref{fvn2} and Eq. \ref{fvn3}, we then  recognize that $\tilde{D}_{vqws}$ is nonzero only when $q,s$ are active, so that in Eq. \ref{fvn3}, we have replaced $q,s$ with $x,y$. In Eq. \ref{fvn4}, we have introduced the auxiliary $Q$ matrix:
\begin{equation}
    Q_{vm}=\sum_{wxy}\tilde{D}_{vwxy}g_{mwxy}
\end{equation}
\item Finally, when the first index is virtual $a$, the general Fock matrix vanishes:
\begin{equation}
    F_{an}=0
\end{equation}
\end{enumerate}

Finally, all that remains is calculate the density matrices $D_{vw}$ and $\tilde{D}_{vwxy}$ where all indices are active. Note that, for a CASSCF calculation, we have only two active orbitals, which henceforward we label $t,u$; we envision $t$ to be the orbital with lower energy and $u$ to be the orbital with higher energy. 
Ignoring the core (inactive) orbitals, the CASSCF(2,2) wavefunction  $\ket{\Psi_{0}}$ can be written as: 
\begin{equation}
    \ket{\Psi_{0}}=\alpha\ket{t\bar{t}}+\beta\ket{u\bar{u}}+\gamma(\ket{t\bar{u}}+\ket{u\bar{t}})
\end{equation}
We then can evaluate the  one-particle density matrix (1PDM):
\begin{equation}
\label{eqn:1PDM}
\begin{aligned}
    D_{tt}&=2(\alpha^2+\gamma^2)\\
    D_{tu}&=D_{ut}=2(\alpha+\beta)\gamma\\
    D_{uu}&=2(\beta^2+\gamma^2)
\end{aligned}
\end{equation}
As one would expect, the trace of the 1PDM is the number of active electrons: 
\begin{equation}
    2=D_{uu}+D_{tt}=2(\alpha^2+\beta^2+2\gamma^2)
\end{equation}
Next, for two-particle density matrix (2PDM), we find: 
\begin{equation}
\label{eqn:2PDM}
    \begin{aligned}
        \tilde{D}_{tttt}&=2\alpha^2\\
        \tilde{D}_{tttu}&=\tilde{D}_{ttut}=\tilde{D}_{tutt}=\tilde{D}_{uttt}=2\alpha\gamma\\
        \tilde{D}_{ttuu}&=\tilde{D}_{uutt}=\tilde{D}_{uttu}=\tilde{D}_{tuut}=2\gamma^2\\
        \tilde{D}_{tutu}&=\tilde{D}_{utut}=2\alpha\beta\\
        \tilde{D}_{tuuu}&=\tilde{D}_{utuu}=\tilde{D}_{uutu}=\tilde{D}_{uuut}=2\beta\gamma\\
        \tilde{D}_{uuuu}&=2\beta^2
    \end{aligned}
\end{equation}
\subsubsection{Final Form for the Gradient}
Finally, we can write down the electronic gradient. A CASSCF ansatz is a function of coefficients and orbital rotations. The gradients with respect to coefficients are easy to extract; one merely diagonalizes the Hamiltonian for a fixed set of orbitals. As  far as the optimization of the orbitals is concerned, as for any CASSCF calculation,
%Before getting down to calculate electronic energy gradient, it's necessary to realize that some orbital rotations are redundant when optimizing the CAS electronic energy. T
there are 6 classes of orbital rotations (see a schematic matrix below): 
\begin{equation}
\label{eqn:kappa}
    \begin{bmatrix}
    (\kappa_{ji}) & \kappa_{it} & \kappa_{ia} \\
    \kappa_{ti} & (\kappa_{ut}) & \kappa_{ta} \\
    \kappa_{ai} & \kappa_{at} & (\kappa_{ba}) 
    \end{bmatrix}
\end{equation}
However, 
note that all intraspace rotations (e.g. $\kappa_{ji}$,$\kappa_{ut}$ and $\kappa_{ba}$) are redundant. 
%First, the inactive-inactive and virtual-virtual rotation redundancy may be demonstrated by establishing that $E^-_{ij}\ket{0}$ and $E^-_{ab}\ket{0}$ are zero so that the simple version redundancy condition is satisfied:
%\begin{equation}
%    E_{pq}^-\ket{0}=\sum_ic_i\ket{i}
%\end{equation},
%where $\ket{i}$ is a CAS configuration and $E_{pq}^-$ is an anti-hermitian operator:
%\begin{equation}
%    E_{pq}^-=E_{pq}-E_{qp}=(p_{\alpha}^{\dagger}q_{\alpha}+p_{\beta}^{\dagger}q_{\beta})-(q_{\alpha}^{\dagger}p_{\alpha}+q_{\beta}^{\dagger}p_{\beta})
%\end{equation}. 
%In other words, the rotation $\kappa_{pq}$ is redundant as long as $E_{pq}^-\ket{0}$ can be represented as a linear combination of CAS configurations. Second, for active-active rotations, $E^-_{ut}\ket{0}$ is a linear combination with all inactive orbitals doubly occupied and all virtual orbitals unoccupied. Since all such configurations are represented in the set of CAS configurations $\ket{i}$, the redundancy condition is satisfied. 
Thus,  we need to evaluate the electronic energy gradient only with respect to the inactive-active rotations $\kappa_{it}$, the inactive-virtual rotations $\kappa_{ia}$ and the active-virtual rotations ${\kappa_{ta}}$. 
 Following Ref. \citenum{helgaker2013molecular},  the electronic gradient can be written as
\begin{align}
    B_{mn}=2\mel{0}{[E_{mn},\hat{H}]}{0},
\end{align}
where the orbital excitation operator $E_{mn}$ is defined as:
\begin{equation}  E_{mn}=\sum_{\alpha}m_{\alpha}^{\dagger}n_{\alpha}
\end{equation}
Using basic algebra, $B_{mn}$ can be re-expressed as:
\begin{align}
    \nonumber B_{mn}&=2\sum_{\alpha}[\mel{0}{m^{\dagger}_{\alpha}[n_{\alpha},\hat{H}]}{0}\\
    &-\mel{0}{n^{\dagger}_{\alpha}[m_{\alpha},\hat{H}]}{0}]\\
    &=2(F_{mn}-F_{nm}),
\end{align}

Henceforward, the final electronic energy gradient expression is:
\begin{equation}
\label{eqn:Bit}
\begin{aligned}
        B_{it}&=\frac{\partial E} {\partial \kappa_{it}}\\
        &=2(F_{it}-F_{ti})\\
        &=2(2^{I}F_{ti}+2^{A}F_{ti}-\sum_w{^{I}F}_{iw}D_{tw}-\sum_{wxy}\tilde{D}_{twxy}g_{iwxy})\\
        &=2\{2[h_{ti}+\sum_j(2g_{tijj}-g_{tjji})]+2[\sum_{vw}D_{vw}(g_{tivw}-\frac{1}{2}g_{tvwi})]\\
        &-\sum_w[h_{iw}+\sum_j(2g_{iwjj}-g_{ijjw})]D_{tw}-\sum_{wxy}\tilde{D}_{twxy}g_{iwxy}\}
\end{aligned}
\end{equation}

\begin{equation}
\label{eqn:Bia}
    \begin{aligned}
        B_{ia}&=\frac{\partial E} {\partial \kappa_{ia}}\\
        &= 2(F_{ia}-F_{ai})\\
        &=2(2^{I}F_{ai}+2^{A}F_{ai})\\
        &=2\{2[h_{ai}+\sum_j(2g_{aijj}-g_{ajji})]+2[\sum_{vw}D_{vw}(g_{aivw}-\frac{1}{2}g_{avwi})]\}
    \end{aligned}
\end{equation}
\begin{equation}
\label{eqn:Bta}
    \begin{aligned}
        B_{ta}&=\frac{\partial E} {\partial \kappa_{ta}}\\
        &=2(F_{ta}-F_{at})\\
        &=2(\sum_w{^{I}F}_{aw}D_{tw}+\sum_{wxy}\tilde{D}_{twxy}g_{awxy})\\
        &=2\{\sum_w[h_{aw}+\sum_j(2g_{awjj}-g_{ajjw})]D_{tw}+\sum_{wxy}\tilde{D}_{twxy}g_{awxy}\}
    \end{aligned}
\end{equation}


\subsection{State-Averaged Constrained CASSCF(2,2) Energy and Gradient}
\label{subsec:pc}
In Ref. \citenum{chenunpublish}, we analyzed the Anderson Hamiltonian, which can be written as:
 \begin{equation}
 \begin{aligned}
 \label{eqn:model} 
     &\hat{H}_{el}=\frac{1}{2}m\omega^2x^2+\hat{H}_{one}(x)+\hat{\Pi}\\
     &\hat{H}_{one}(x)=\epsilon_{d_1}(x)\sum_\sigma d_{1\sigma}^{\dagger}d_{1\sigma}+\epsilon_{d_2}(x)\sum_\sigma d_{2\sigma}^{\dagger}d_{2\sigma}\\
     &+t_d\sum_\sigma(d_{1\sigma}^{\dagger}d_{2\sigma}+d_{2\sigma}^{\dagger}d_{1\sigma})\\
     &+ \sum_{k\sigma}\epsilon_{k\sigma}b_{k\sigma}^{\dagger}b_{k\sigma}+\sum_{k\sigma}V_k(d_{1\sigma}^{\dagger}b_{k\sigma}+b_{k\sigma}^{\dagger}d_{1\sigma})\\
     &\hat{\Pi}=U(d_{1\uparrow}^{\dagger}d_{1\uparrow}d_{1\downarrow}^{\dagger}d_{1\downarrow}+d_{2\uparrow}^{\dagger}d_{2\uparrow}d_{2\downarrow}^{\dagger}d_{2\downarrow})\\
     &\epsilon_{d_1}(x)=e_{d_1}-\sqrt{2}gx\\
     &\epsilon_{d_2}(x)=e_{d_2}-\sqrt{2}gx
     \end{aligned}
 \end{equation}
Here, $d_1$ and $d_2$ are impurity atomic orbitals and $b_{k \sigma}$ is a bath atomic orbital with electronic orbital index $k$ and spin $\sigma$. The Hamiltonian above is two-site impurity model (with $d_1$ and $d_2$); if one includes only $d_1$, the Hamiltonian becomes a one-site model. The impurity-bath couplings are characterized by a hybridization function:
\begin{equation}
\label{eqn:Gamma}
    \Gamma(\epsilon)=\sum_k|V_k|^2\delta(\epsilon_k-\epsilon)
\end{equation}
For the results below, we will make the wide band approximation, so that $\Gamma(\epsilon) = \Gamma$ is independent of energy.

To study charge transfer between a molecule and a metal surface, the active space must be chosen carefully. In general, the 2 active orbitals $t,u$ must be well-balanced mixtures of both the impurity atomic orbitals $\{d_\mu\}$ and the bath atomic orbitals $\{b_\nu\}$. We will not be able to recover charge transfer if the active orbitals are exclusively on the impurity or in the bath. Thus, a constraint becomes necessary if we wish to guarantee that we find such a well-balanced mixture of orbitals from a CASSCF solution. 



\subsubsection{Form of the Constraint} 
Let us denote the projection onto the impurity as:
\begin{equation}
\hat{P}_{imp} = \sum_{\mu\in\textbf{impurity}}d_\mu^{\dagger}d_\mu
\end{equation}

and the projection onto the bath as:
\begin{equation}
\hat{P}_{bath} =  \sum_{\nu\in\textbf{bath}}b_\nu^{\dagger}b_\nu.
\end{equation}

Clearly, one can write the identity as:
\begin{equation}
    \hat{I}=\hat{P}_{imp} + \hat{P}_{bath} 
\end{equation}

One possible constraint enforcing this active orbital requirement is insisting on a total population on the impurity for the active space:
\begin{equation}
\label{eqn:constraint1}
\begin{aligned}
    &\Tr_{active}\left(\hat{P}_{imp}\right) \\
    &= \sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}=1
\end{aligned}
\end{equation}
Because
\begin{equation}
    \braket{t}{t}+\braket{u}{u}=2,
\end{equation}
Eq. \ref{eqn:constraint1} is equivalent to
\begin{equation}
\begin{aligned}
    &\Tr_{active}\left(\hat{P}_{bath}\right) \\
    &= \sum_{\mu\in\textbf{bath}}\mel{t}{b_\mu^{\dagger}b_\mu}{t}+\mel{u}{b_\mu^{\dagger}b_\mu}{u}=1
\end{aligned}
\end{equation}
In other words,  constraining  the impurity is equivalent to constraining the bath. Henceforward, we will label this a ``partial constraint'' (``pc'' for short).

Below, we will compare Eqn. \ref{eqn:constraint1} against  a stricter ``full constraint'' (``fc'' for short), where we insist that each of two active orbitals is fully localized on either the impurity or bath (resulting in two [not one] constraints):
\begin{equation}
\begin{aligned}
    \sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}=1 ;\\  \sum_{\mu\in\textbf{impurity}}\mel{u}{d_\mu^{\dagger}d_\mu}{u}=0
    \label{eqn:constraint2}
\end{aligned}
\end{equation}
Although the derivation below is given for the case of a partial constraint, the electronic energy and gradient has a straightforward analogy for the case of the full constraint.


\subsubsection{The Need for State Averaging}
As discussd above, without the constraints above, a CASSCF(2,2) calculation could easily  produce two active orbitals localized to the bath, which would not help in describing the molecule-metal charge transfer problem. Thus, the constraints above are {\em necessary}. That being said, these constraints are not yet {\em sufficient} as far generating a balanced set of active orbitals;   one still must perform a state-average CASSCF(2,2) to get meaningful excited states. 

To see why a state average is absolutely essential, consider a single site Anderson model without the onsite repulsion $U$ and the limiting case where the the impurity site is fully occupied for the ground state, i.e. $\expval{d^{\dagger}d}=\expval{\bar{d}^{\dagger}\bar{d}}=1$.
In such a case, the ground state CASSCF(2,2) $\ket{\Psi_0}$ can be written as (ignoring the core electrons); 
\begin{equation}
    \ket{\Psi_0}=\ket{d\bar{d}},
\end{equation} 
and there is no stable means to identify the corresponding active orbital in the bath, $b$.   In other words, without state averaging, $b$ is chosen as that orbital that most helps to lower the energy of the ground state; however, in this regime, the ground state really does not mix with the bath  and so the choice of $b$ will be numerically unstable. As a result, as we change the fermi level, we will likely see instabilities of the excited states. Indeed, these instabilities will be shown below. Note that this unstable structure can be easily removed, however, if we simply give some weight to the excited state so that the latter is chosen robustly. For this reason, we will perform state-averaging below.


%At this point, w the corresponding $S_1$ and $S_2$ excited states are simply the first and second excited states after diagonalization. By orthogonality to $S_0$, it is clear that 
%these states must be of the form:
%\begin{equation}
%\begin{aligned}
%\ket{S_1}&=\beta_1\ket{b\bar{b}}+\gamma_1\ket{d\bar{b}+b\bar{d}}\\
%\ket{S_2}&=\beta_2\ket{b\bar{b}}+\gamma_2\ket{d\bar{b}+b\bar{d}}
%\end{aligned}
%\end{equation}
%However, there is
%and there is no 
%where $b$ refers to a bath orbital, which cannot be uniquely defined by ground-state-specific CASSCF(2,2) for this limiting case. 
% Recall that the general CASSCF(2,2) wavefunction is written as (ignoring the core electrons configuration): 
% \begin{equation}
%     \alpha\ket{t\bar{t}}+\beta\ket{u\bar{u}}+\gamma\ket{t\bar{u}+u\bar{t}}
% \end{equation}.
% Clearly, $(\alpha,\beta,\gamma)=(1,0,0)$ and $t=d,u\in\text{bath}$ (i.e. $\ket{d\bar{d}}$) is the solution of the ground state CASSCF(2,2) satisfying the constraint. But $u$ is not unique: $u$ can be any bath orbitals. In such case, one cannot extract a meaningful excited state from the constrained CASSCF(2,2) (even though these three states represent different charge states on the impurity). 
%Hence, to obtain a meaningful excited state, one must do state-average by minimizing the energy summation of the ground state and excited states. 

For this reason, we will now explicitly write down the energy and gradient expression for state-averaged constrained CASSCF(2,2). First, we write out the three CASSCF(2,2) states: 
\begin{align}
    \label{eqn:casscf}
    \ket{\Psi_0}&=\alpha_0\ket{t\bar{t}}+\beta_0\ket{u\bar{u}}+\gamma_0\ket{t\bar{u}+u\bar{t}}\\
    \ket{\Psi_1}&=\alpha_1\ket{t\bar{t}}+\beta_1\ket{u\bar{u}}+\gamma_1\ket{t\bar{u}+u\bar{t}}\\
    \ket{\Psi_2}&=\alpha_2\ket{t\bar{t}}+\beta_2\ket{u\bar{u}}+\gamma_2\ket{t\bar{u}+u\bar{t}}
\end{align}
The state-averaged CASSCF(2,2) energy can be written as:
\begin{equation}
    E^{SA-CASSCF(2,2)}=\sum_{I=0}^{2}w_I\mel{I}{H}{I},
\end{equation}
where $w_I$ is the weight for the energy of $I$th CASSCF(2,2) state. For reasonable ground and excited states-- both near and far from crossing regimes -- we employ dynamically weighted weights
%     \item Polynomial form \cite{glover2014communication}:
%     \begin{equation}
%     \begin{aligned}
%         w_0&=\frac{1}{1+q_1+q_2}\\
%         w_1&=\frac{q_1}{1+q_1+q_2}, 
%         q_1=\begin{cases}
%         1-3(\frac{E_1-E_0}{\zeta})^2+2(\frac{E_1-E_0}{\zeta})^3, & \text{if $E_1-E_0<\zeta$}. \\
%         0, & \text{otherwise}.
%         \end{cases}
%         \\ 
%         w_2&=\frac{q_2}{1+q_1+q_2}, 
%         q_2=\begin{cases}
%         1-3(\frac{E_2-E_0}{\zeta})^2+2(\frac{E_2-E_0}{\zeta})^3, & \text{if $E_2-E_0<\zeta$}. \\
%         0, & \text{otherwise}.
%         \end{cases}\\ 
%     \end{aligned}
%     \end{equation}
% \end{itemize}
of the form:
\cite{battaglia2020extended}
    \begin{equation}
    \label{eqn:DW}
    \begin{aligned}
        w_0&=\frac{1}{1+e^{-\zeta (E_1-E_0)}+e^{-\zeta (E_2-E0)}}\\
        w_1&=\frac{e^{-\zeta (E_1-E_0)}}{1+e^{-\zeta (E_1-E_0)}+e^{-\zeta (E_2-E0)}}\\
        w_2&=\frac{e^{-\zeta (E_2-E0)}}{1+e^{-\zeta (E_1-E_0)}+e^{-\zeta (E_2-E0)}}.
    \end{aligned}
    \end{equation}
    For this exponential weighting factors,
 the parameter $\zeta$  controls the mixing strength of the ground state with the excited states. When $\zeta \to 0$, we recover three-state-averaged CASSCF(2,2) with equal weighting $w_I=\frac{1}{3}$; when $\zeta \to \infty$, we recover becomes state-specific CASSCF(2,2). 
    \begin{equation}
    \begin{cases}
      \zeta \to 0 & \text{equal weighting}\\
      \zeta \to \infty & \text{ground-state-specific}\\
    \end{cases}       
\end{equation}
 Compared to the state-specific CASSCF(2,2) energy in Eq. \ref{eqn:Ecasscf}, the state-averaged CASSCF(2,2) energy is  different only in the way we construct the state-averaged 1PDM and 2PDM: 
\begin{equation}
\begin{aligned}
\label{eqn:sa_pdm}    D_{pq}&=\sum_{I=0}^2w_ID_{pq}^{I}\\
    \tilde{D}_{pqrs}&=\sum_{I=0}^2w_I\tilde{D}_{pqrs}^{I}.
\end{aligned}
\end{equation}
Here, the state-specific 1PDM $D_{pq}^{I}$ and 2PDM $\tilde{D}_{pqrs}^{I}$ in the active space basis are calculated in Eqs. \ref{eqn:1PDM} and \ref{eqn:2PDM}. 

\subsubsection{Minimization with Lagrange Multipliers to Find a Solution}

In order to obtain a state-averaged constrained CASSCF(2,2) solution, we look for stationary solutions of a lagrangian representing the state-averaged CASSCF(2,2) energy with the active orbital constraint: 
\begin{equation}
\label{eqn:L}
    \mathcal{L}=E^{SA-CASSCF(2,2)}-\lambda\{\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}-1\},
\end{equation}
% \begin{equation}
% \label{eqn:L}
%     \mathcal{L}=E^{SA-CASSCF(2,2)}+\lambda \{\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}-1\}^2,
% \end{equation}
Here $\lambda$ is the relevant lagrange multiplier for the constraint. Following Eqs. \ref{eqn:Bit}, \ref{eqn:Bia} and \ref{eqn:Bta}), the analogous derivative of the lagrangian with respect to orbital rotations is:
 \begin{equation}
 \label{eqn:Bit_pc}
    \begin{aligned}
        \tilde{B}_{it}&=2\{2[h_{ti}+\sum_j(2g_{tijj}-g_{tjji})]+2[\sum_{vw}D_{vw}(g_{tivw}-\frac{1}{2}g_{tvwi})]\\
        &-\sum_w[h_{iw}+\sum_j(2g_{iwjj}-g_{ijjw})]D_{tw}-\sum_{wxy}\tilde{D}_{twxy}g_{iwxy}\}\\
        &+2\lambda\sum_{\mu\in\textbf{impurity}}\mel{i}{d_\mu^{\dagger}d_\mu}{t}
    \end{aligned}
\end{equation}
%  \begin{equation}
%  \label{eqn:Bit_pc}
%     \begin{aligned}
%         \tilde{B}_{it}&=2\{2[h_{ti}+\sum_j(2g_{tijj}-g_{tjji})]+2[\sum_{vw}D_{vw}(g_{tivw}-\frac{1}{2}g_{tvwi})]\\
%         &-\sum_w[h_{iw}+\sum_j(2g_{iwjj}-g_{ijjw})]D_{tw}-\sum_{wxy}\tilde{D}_{twxy}g_{iwxy}\}\\
%         &-4\lambda\sum_{\mu\in\textbf{impurity}}\mel{i}{d_\mu^{\dagger}d_\mu}{t} \left(\Tr_{active}\left(\hat{P}_{imp}\right) - 1 \right)
%     \end{aligned}
% \end{equation}
\begin{equation}
\label{eqn:Bia_pc}
    \begin{aligned}
        \tilde{B}_{ia}&=2\{2[h_{ai}+\sum_j(2g_{aijj}-g_{ajji})]+2[\sum_{vw}D_{vw}(g_{aivw}-\frac{1}{2}g_{avwi})]\}
    \end{aligned}
\end{equation}
\begin{equation}
\label{eqn:Bta_pc}
    \begin{aligned}
        \tilde{B}_{ta}&=2\{\sum_w[h_{aw}+\sum_j(2g_{awjj}+g_{ajjw})]D_{tw}+\sum_{wxy}\tilde{D}_{twxy}g_{awxy}\}\\
        &-2\lambda\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{a}
    \end{aligned}
\end{equation}
% \begin{equation}
% \label{eqn:Bta_pc}
%     \begin{aligned}
%         \tilde{B}_{ta}&=2\{\sum_w[h_{aw}+\sum_j(2g_{awjj}+g_{ajjw})]D_{tw}+\sum_{wxy}\tilde{D}_{twxy}g_{awxy}\}\\
%         &+4\lambda\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{a}\left(\Tr_{active}\left(\hat{P}_{imp}\right) - 1 \right)
%     \end{aligned}
% \end{equation}
Therefore, applying a variational principle to the lagrangian in Eq. \ref{eqn:L}  is equivalent to solving a set of self-consistent equations given by Eq. \ref{eqn:constraint1} and Eq. \ref{eqn:F}:
\begin{equation}
\label{eqn:F}
    (\hat{B}+\lambda\hat{V})\ket{k}=\epsilon_k\ket{k}
\end{equation}
Here, $\hat{B}$ is the matrix in Eqs. \ref{eqn:Bit}, \ref{eqn:Bia} and \ref{eqn:Bta} and $\hat{V}$ is an operator that arises from the constraint:
\begin{equation}
\begin{aligned}
    \hat{V}&=2\
    \left( \hat{P}_{inact} \hat{P}_{imp} \hat{P}_{active} + 
    \hat{P}_{active} \hat{P}_{imp} \hat{P}_{inact} - \hat{P}_{virt} \hat{P}_{imp} \hat{P}_{active} - \hat{P}_{active} \hat{P}_{imp} \hat{P}_{virt}\right)
\end{aligned}
\end{equation}
% \begin{equation}
% \begin{aligned}
%     \hat{V}&=4\
%     \left( \hat{P}_{virt} \hat{P}_{imp} \hat{P}_{active} + 
%     \hat{P}_{active} \hat{P}_{imp} \hat{P}_{virt} -
%     \hat{P}_{inact} \hat{P}_{imp} \hat{P}_{active} - 
%     \hat{P}_{active} \hat{P}_{imp} \hat{P}_{inact} \right)  \\
% & \; \; \; \; \; \; \; \; \; \; \; \; \; \; \times \left(\Tr_{active}\left(\hat{P}_{imp}\right) - 1 \right)
% \end{aligned}
% \end{equation}

In practice, there are many means by which one can solve the equations above. 
% In this paper, we optimize orbitals with fixed lagrange multiplier $\lambda$ and update $\lambda$ in a brute force way as described below.
% In the present paper, we use a two-step algorithm: First,we generate a reasonable orbital guess by optimizing Eq. \ref{eqn:L} with a quadratic penalty (we will discuss the choice of the penalty parameter in the Appendix \ref{subsec:kkt}); Second, we solve Newton-KKT equation\cite{wright1999numerical}, which optimizes orbitals and lagrange multiplier in one shot:
In the present paper, we  consider the optimization problem above (Eq. \ref{eqn:L}) as an equality-constrained quadratic optimzation problem and following standard optimization approaches\cite{wright1999numerical}, we solve the relevant Newton-Karush–Kuhn–Tucker (Newton-KKT) matrix equations: 
%And we will solve this matrix iteratively by Newton's method:
% with Newton's method, i.e. we solve Newton-KKT equation\cite{wright1999numerical}, which optimizes orbitals and the lagrange multiplier in one shot:
\begin{equation}
\label{eqn:kkt}
    \begin{bmatrix}
        \grad^2_{xx}\mathcal{L}_k & -\grad C(x_k) \\
        \grad C^T(x_k) &0 \\
    \end{bmatrix}
    \begin{bmatrix}
        p_k\\
        \lambda_{k+1}\\
    \end{bmatrix}
    =
    \begin{bmatrix}
        -\grad E^{SA-CASSCF(2,2)}(x_k)\\
        -C(x_k)\\
    \end{bmatrix}
\end{equation}
Here, $C(x_k)$ is the constraint (Eq. \ref{eqn:constraint1}); $x_k$ is a generic variable in the orbital rotation space (Eq. \ref{eqn:kappa}) for the $k$-th optimization cycle; $p_k$ is the walking direction for $x_k$, i.e. $x_{k+1}=x_k+\alpha p_k$ and the step length $\alpha$ is obtained from a line search; $\lambda_{k+1}$ is the lagrange multiplier for the next $(k+1)$-th optimization cycle. To reduce the computational cost, the hessian $\grad^2_{xx}\mathcal{L}$ is  approximated and updated by a BFGS scheme.


% And there is a comparison of the second derivative for cCASSCF(2,2) and cDFT: For cDFT, the second derivative is always nonpositive\cite{wu2005direct}; For cCASSCF(2,2), the second derivative can be either positive or negative.

% In order to improve the convergence for this optimization problem with the constraint, we use an auxiliary penalty function to get an proper initial guess:
% \begin{equation}
% \label{eqn:penalty}  \phi_F=E^{CASSCF(2,2)}+V_c(\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}-1)^2
% \end{equation},
%  where $V_c$ is the penalty parameter for the active orbital constraint and it is set to be $10^4$ in practice. 




\section{Details of the Implementation}
% For our purposes below, we will state that a CASSCF solution satisfies our impurity constraint  if
% \begin{equation}
% \label{eqn:satisfied}
%     \left|\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u} - 1 \right| < 10^{-4}
% \end{equation}
% Over a very broad range of values, we have found that increasing the value of $\lambda$ leads to solutions that satisfy this constraint ever more closely. 

We may summarise our implementation of DW-SA-cCASSCF(2,2) with the algorithm flowchart in Fig. \ref{fig:flowchart}.
Note that this implementation should be valid for any reasonably sized impurity (larger than one site)\cite{onesite}:

\begin{itemize}
\item First, we calculate the 1PDM and 2PDM for our state-average target function (using Eq. \ref{eqn:1PDM}, Eq. \ref{eqn:2PDM} and Eq. \ref{eqn:sa_pdm}) with an initial set of weighting factors ($\omega_0=1,\omega_1=0,\omega_2=0$ in Eq. \ref{eqn:DW}).
\item Second, we solve the Newton-KKT equations \ref{eqn:kkt} in order to optimize orbitals and the lagrange multiplier;
\item Third, we diagonalize the configuration interaction (CI) Hamiltonian ($3 \times 3$ for CAS(2,2)) and recover the CI coefficients. 
\item Finally, we examine the norm of the energy gradient in Eqs. \ref{eqn:Bit_pc}, \ref{eqn:Bia_pc} and \ref{eqn:Bta_pc}: if the gradient is smaller than a target threshold, the calculation has converged; otherwise, we update the weighting factor according to the Eq. \ref{eqn:DW} and repeat the whole procedure. 
% \item Second, we optimize the orbitals with an initial lagrange multiplier $\lambda=0.1$.
% \item Third, we check whether Eq. \ref{eqn:satisfied} is satisfied: If not, we multiply our choice of $\lambda$ by a factor of 2 and re-optimize orbitals.
% \item Fourth, once we reach a value of $\lambda$ that satisfies Eq. \ref{eqn:satisfied}, using a bisection approach, we scan smaller values of $\lambda$ to search for the optimal $\lambda$ that still satisfies our constraint and minimizes the total Lagrangian.
% \item Fifth, after obtaining the optimal $\lambda$, we diagonalize the configuration interaction (CI) Hamiltonian ($3 \times 3$ for CAS(2,2)) and recover the  CI coefficients. 
% \item Finally, we examine the norm of the energy gradient in Eqs. \ref{eqn:Bit_pc}, \ref{eqn:Bia_pc} and \ref{eqn:Bta_pc}: if the gradient is smaller than a target threshold, the calculation has converged; otherwise, we update the weighting factor according to the Eq. \ref{eqn:DW} and repeat the whole procedure. 
\end{itemize}

\begin{figure}[H]
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/flowchart_new.pdf}
\caption{A flowchart of dynamically weighted state-averaged constrained CASSCF(2,2)}
\label{fig:flowchart}
\end{figure}


\section{Results}
We will now present three sets of data that allow for a better understanding of the above calculation (both theoretically and practically). First, we will present data as to  
the convergence performance of DW-SA-cCASSCF(2,2), studying  different $\Gamma$ with and without electron-electron interactions.
%cases ($1\times10^{-2}$ to $1\times10^{-5}$) when we don't include the electron-electron repulsion ($U=0$ in Tbl. \ref{tab:U0}) and when we do ($U=0.1$ in Tbl. \ref{tab:U01}). 
Second, we 
%introduce three metrics (the ground state accuracy, the excited state asymptotic behavior and the surface smoothness) to
will assess the choice of the dynamical weighting parameter $\zeta$ and show how the results vary with $\zeta$. Third, we will compare  results for a partially localized constraint (pc) versus a fully localized constraint (fc). 


\subsection{Convergence}
%% one-site test
For the one-site calculations below, we start with such an initial guess: we use the identity matrix and switch its first column with the $\frac{Ne}{2}$-th column ($Ne$ is the total number of electrons). The parameter set is: $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05$, and we discretize the bath with 101 metallic states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$. We set the dynamical weighting parameter to be $\zeta=40$. And we set the convergence threshold for the norm of gradient to be $1\times10^{-4}$.
%% two-site test
% For the calculations below, we often started our cCASSCF calculations using a finite temperature ($T=1\times10^{-2}$) Hartree-Fock solution as an initial guess; we used such a guess because this ansatz would be the most likely initial guess for an {\em ab initio} calculation.  
% The parameter set is: $m\omega^2=0.001, g=0.0075, e_{d_1}=e_{d_2}=0.06, t_d=0.2$, and we discretize the bath with 101 metallic states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$. We set the dynamical weighting parameter to be $\zeta=10$ with the initial constraint parameter $\lambda=0$.
In Table  \ref{tab:U0} and Table \ref{tab:U01}, 
we report total number of orbital optimization cycles needed to converge the calculation.  We observe that  $(i)$ convergence is harder when $\Gamma$ is large; and $(ii)$ converge is also more difficult when the electron-electron repulsion is finite ($U=0.1$).
Clearly, for $\Gamma=0.01$, our algorithm for finding a cCASSCF solution is suboptimal and can be improved (the number in the bracket is calculated by reading the CI coeffcients for $\Gamma=0.001$). Nevertheless, we have been able to converge the solutions and, as we show below, the final states are illuminating.

\begin{table}[ht]
\centering
\caption{Convergence Results for $U=0$}
\begin{tabular}[t]{ccccc}
\hline
$\Gamma$&$1\times10^{-2}$&$1\times10^{-3}$&$1\times10^{-4}$&$1\times10^{-5}$\\
\hline
Converging cycles&336(52)&3&3&2\\
Time(s)&54(12)&3&3&2\\
\hline
\end{tabular}
\label{tab:U0}
\end{table}%

\begin{table}[ht]
\centering
\caption{Convergence Results for $U=0.1$}
\begin{tabular}[t]{ccccc}
\hline
$\Gamma$&$1\times10^{-2}$&$1\times10^{-3}$&$1\times10^{-4}$&$1\times10^{-5}$\\
\hline
Converging cycles&388(45)&3&3&3\\
Time(s)&117(10)&3&3&3\\
\hline
\end{tabular}
\label{tab:U01}
\end{table}%
% \begin{table}[ht]
% \centering
% \caption{Convergence Results for $U=0$}
% \begin{tabular}[t]{ccccc}
% \hline
% $\Gamma$&$1\times10^{-2}$&$1\times10^{-3}$&$1\times10^{-4}$&$1\times10^{-5}$\\
% \hline
% Converging cycles&249&144&40&22\\
% Time(s)&132&59&12&7\\
% \hline
% \end{tabular}
% \label{tab:U0}
% \end{table}%

% \begin{table}[ht]
% \centering
% \caption{Convergence Results for $U=0.1$}
% \begin{tabular}[t]{ccccc}
% \hline
% $\Gamma$&$1\times10^{-2}$&$1\times10^{-3}$&$1\times10^{-4}$&$1\times10^{-5}$\\
% \hline
% Converging cycles&431&338&114&36\\
% Time(s)&273&209&36&11\\
% \hline
% \end{tabular}
% \label{tab:U01}
% \end{table}%


\subsection{Choice of $\zeta$}
In order to analyze the pros and cons of a given choice of  $\zeta$, we study three different criteria by which we can judge the resulting solutions focusing on the one-site model ($U = 0$):



\begin{enumerate}
    \item 
One criterion is the ground state energy accuracy; for the case of $U=0$, clearly an exact energy can be obtained for us to benchmark against.

\item A second criterion is the excited state energy asymptotic behavior. Here, we expect that a proper excited state should asymptotically approach the relevant  diabatic energy when the impurity onsite energy is far away from the fermi level.

\item A third criterion is  smoothness. For dynamics, it will be essential that we obtain smooth DW-SA-cCASSCF energies and wavefunctions.  
\end{enumerate}


\begin{figure}[H]
\centering

\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/S0_zeta.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/S2_zeta.pdf}
\end{subfigure}
\end{figure}
\begin{figure}\ContinuedFloat
\begin{subfigure}[t]{\textwidth}
\centering
% set the real top as the top
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]
\end{subfigure}
%
\caption{Different metrics for guiding the choice of $\zeta$.
 (a) The ground state energy difference between the DW-SA-pcCASSCF(2,2) state $S_0$ and the exact ground state (the difference is measured at the curve crossing point); in general, we want the most accurate ground state energy possible. (b) The excited state energy difference between the DW-SA-pcCASSCF(2,2) state $S_2$ and the $ne=0$ diabatic state (i.e. the diabatic state whose number of electrons on the impurity is 0).  Far away from the crossing point, the onsite energy $\epsilon_d(x)$ is so much larger energy than the fermi level that for a good algorithm, the  asymptotic behavior of the $S_2$ energy should approach the $ne=0$ diabatic state energy. Note that these two metrics favor opposite $\zeta$ parameters, and so have we chosen $\zeta=40$ as a compromise so as to keep the ground state as accurate as possible without sacrificing the excited state asymptotic behavior entirely. Luckily, the excited states are smooth for all $\zeta$ parameters (not shown here). The parameter set is the one-site model with $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05, U=0$ with 101 metal states evenly distributed with  energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:zeta}

\end{figure}


In practice, picking the optimal $\zeta$ is usually a compromise between the criteria above: we expect that a large $\zeta$ would be  best if we seek ground state accuracy while a smaller $\zeta$ would be best  for achieving the correct excited state asymptotic behavior and smooth surfaces. This intuition is confirmed in Fig. \ref{fig:zeta}.
In Fig. \ref{fig:zeta}(a), we plot the error in the energy of the ground state as a function of $\zeta$. As we would guess, the larger $\zeta$ is, the less mixing there is between $S_0$ and $S_1,S_2$, and therefore the more accurate $S_0$ is. Next, in Fig. \ref{fig:zeta}(b), we plot the asymptotic energy difference between $E(S_2)$ (by DW-SA-cCASSCF(2,2)) and $E(ne=0)$ (the diabatic state whose number of electrons on the impurity is 0) as a function of $\zeta$. We see clearly that $E(S_2)$ is closer to $E(ne=0)$ when $\zeta$ is small and there is more mixing between $S_0$ and $S_1,S_2$ during the orbital optimization. Lastly, as far as the smoothness is concerned, we find that surfaces are all smooth for $\zeta=20,30,40,50$ for the one-site $U=0$ model. 

From the considerations above, in order to maintain reasonable ground state accuracy while keeping the excited state asymptotic behavior as accurate as possible, we chose $\zeta=40$  as a compromise value. (Note that for the two-site model, $\zeta=10$ is a better compromise; See Section \ref{subsec:pcfc}).  
In short, our rule of thumb in picking the proper $\zeta$ is that we will need to sacrifice some ground-state energy accuracy in order to recover a smooth and qualitatively correct surface suitable for nonadiabatic dynamics.

\subsection{A Partially Localized Constraint Versus a  Fully Localized Constraint For a Two-Site Hamiltonian With $U=0.1$ }
\label{subsec:pcfc}
% \begin{itemize}
%     \item A looser and more flexible constraint (see the Eq. \ref{eqn:constraint1}), which requires two active orbitals have some overlap with the impurity atomic orbitals. We denote it as partially localized constraint ( pcCASSCF(2,2) );
%     \begin{equation} \sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}=1
%     \end{equation}
%     \item A more strict constraint, which forces one active orbital to be fully localized on the molecule and the other active orbital to be a pure bath orbital. We denote it as a fully localized constraint ( fcCASSCF(2,2) ): 
%     \begin{eqnarray}
%     \sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}=1 ;  \sum_{\mu\in\textbf{impurity}}\mel{u}{d_\mu^{\dagger}d_\mu}{u}=0
%     \end{eqnarray}
% \end{itemize}

Finally, in Figs. \ref{fig:pcfc_E}, \ref{fig:pcfc_n} and \ref{fig:pcfc_orb}, we plot results for two different constraints: partially localized constraint (denoted as ``pc"
, see Eqn. \ref{eqn:constraint1}) v.s. fully localized constraint (denoted as ``fc", see Eqn. \ref{eqn:constraint2}). 
As one can see in Fig. \ref{fig:pcfc_E}(a), ``fc" $S_1$ and $S_2$ energies are much larger than the corresponding ``pc" energies for $\epsilon_d\in[-0.05,0.19]$, and the former also have a large discontinuity around 
 $\epsilon_d=0.19$. At this discontinuity point, in Fig. \ref{fig:pcfc_E}(c), we can clearly see that the ``fc" ground state energy recovers the RHF result.
A similar anomaly is found in Fig. \ref{fig:pcfc_n}, where we plot the total number of electron on the impurity ($\expval{n_{tot}}$) against the exact numerical renormalization group (NRG). In Fig. \ref{fig:pcfc_n}(a), for ``pc", two excited state populations have a transition around $\epsilon_d=-0.05$: from 3 to 1 for $S_1$ and from 4 to 0 for $S_2$. However,  for ``fc", $S_1$ and $S_2$ do not capture this population transition. Moreover, in Fig. \ref{fig:pcfc_n}(c), the fc $S_0$ population is wrong (and equal to the RHF answer) when $\expval{n_{tot}}$ changes from 2 to 0 around $\epsilon_d\in[0.1,0.19]$; the fc results display a discontinuity at $\epsilon_d=0.19$. 
Altogether we may hypothesize that the fc  method fails to describe how the active orbital switches locality around $\epsilon_d=-0.05$.
 This hypothesis is confirmed
in Fig. \ref{fig:pcfc_orb}(a), where we plot the impurity population on the pc and fc active orbitals.  For the pc method, the HOMO is not always localized on the impurity (true for $\epsilon_d<-0.05$) and in fact becomes a bath orbital for $\epsilon_d>-0.05$; however, for fc, the HOMO is always on the impurity. Such a change in frontier orbital localization can also be identified by the small tip/dip in Fig. \ref{fig:pcfc_orb}(b), where we plot the eigenvalues of the impurity projection operator, $\hat{P}_{imp} = 2(d^{\dagger}_1d_1+d^{\dagger}_2d_2$).
All told, the pc approach appears to be a far more robust approach than does the fc approach. Note that, in the range $\epsilon_d \in [-0.3,-0.25]$ (in Fig. \ref{fig:pcfc_n}(b)) or $\epsilon_d \in [0.15,0.2]$ (in Fig. \ref{fig:pcfc_n}(c)), UHF results become non-smooth whereas pc results remain smooth; this attribute is encouraging as far as the potential to run dynamics.




\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.45\textwidth}
\centering
\vspace{-25mm}
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_legend.eps}
\end{subfigure}

\begin{subfigure}[t]{\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_new.pdf}
\end{subfigure}
\caption{The partially constrained (pc) and fully constrained (fc) energies relative to RHF as a function of the onsite energy $\epsilon_d$. (a) The full range of $\epsilon_d$; (b) Zoom in on the left red circle in (a); (c) Zoom in on the right red circle in (a). Note that the fc energies are not smooth in Fig. (c) and the fc $S_1$, $S_2$ energies are far too large compared to pc for $\epsilon_d\in[-0.05,0.19]$ in Fig. (a). The parameter set is= a two-site model with $\epsilon_d=\epsilon_{d_1}=\epsilon_{d_2}, \Gamma=0.01, t_d=0.2, U=0.1, \zeta=10$ and 31 metal states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $3\Gamma$).} 
\label{fig:pcfc_E}
\end{figure}

\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
\centering
\vspace{-25mm}
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_legend.eps}
\end{subfigure}
\begin{subfigure}[t]{1.1\textwidth}
\centering
\vspace{-5mm}
\hspace*{-15mm}\includegraphics[width=\linewidth]{images2/pcfc_n4to0.eps}
\end{subfigure}
\begin{subfigure}[t]{1.1\textwidth}
\centering
\vspace{-5mm}
\hspace*{-15mm}\includegraphics[width=\linewidth]{images2/pcfc_n4to2.eps}
\end{subfigure}
\begin{subfigure}[t]{1.1\textwidth}
\centering
\vspace{-5mm}
\hspace*{-15mm}\includegraphics[width=\linewidth]{images2/pcfc_n2to0.eps}
\end{subfigure}
\caption{The pc and fc total number of electrons on the impurity as a function of the onsite energy $\epsilon_d$. (a) The full range of $\epsilon_d$; (b) Zoom in on the red solid box in (a); (c) Zoom in on the red dashed box in (a).  The fc ground state is neither smooth nor accurate compared to the NRG ground state electron population in Fig. (c); the pc results are more accurate relatively and always smooth. The parameter set is the two-site model with $\epsilon_d=\epsilon_{d_1}=\epsilon_{d_2}, \Gamma=0.01, t_d=0.2, U=0.1, \zeta=10$ and 31 metal states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $3\Gamma$).} 
\label{fig:pcfc_n}
\end{figure}

\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_hhll_new.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_eval_new.pdf}
\end{subfigure}

\caption{An analysis of the pc and fc active (or frontier) orbitals. (a) Impurity population. (b) The eigenvalues of the impurity projector $\hat{P}_{imp}$. Note that the HOMO/LUMO impurity populations switch at $\epsilon_d=-0.05$ only for pc (but not for fc) in Fig. (a), leading to the tip/dip in the eigenvalue curve in Fig. (b). This switch enables smooth curves over the full range of $\epsilon_d$ as shown in Figs. \ref{fig:pcfc_E} and \ref{fig:pcfc_n}.
The parameter set is the two-site model with $\epsilon_d=\epsilon_{d_1}=\epsilon_{d_2}, \Gamma=0.01, t_d=0.2, U=0.1, \zeta=10$ and 31 metal states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $3\Gamma$).} 
\label{fig:pcfc_orb}
\end{figure}




 Lastly, in Fig. \ref{fig:pcfc_zeta}, we investigate how these different constraints behave as a function of the dynamical weighting parameter $\zeta$.   
In particular, we plot the ground and excited energy (relative to RHF) of fc and pc for a dynamical weighting parameter $\zeta=10,20,30,40$. One can see that the fc excited state energies $S_1$ and $S_2$ never recognize a curve crossing around $\epsilon_d=-0.05$ which eventually leads to a discontiuity; the pc excited states do recognize a curve crossing but only  when $\zeta=10,20$. Altogether, the fc constraint would appear inferior to the pc constraint.

%how the So far, at $\epsilon_d=-0.33$, ``fc" behaves similar to the ``pc". However, next we will show that ``fc" result is also sensitive to the dynamical weighting parameter $\zeta$ at $\epsilon_d=-0.33$. 

%And we further examine their sensitivity to the state-average weighting paramter $\zeta$.



\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_zeta10.eps}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_zeta20.eps}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_zeta30.eps}
\end{subfigure}
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=\linewidth]{images2/pcfc_E_zeta40.eps}
\end{subfigure}
\caption{Sensitivity of the pc and fc excited state energies  as a function of the dynamical weighting parameter $\zeta$. (a) $\zeta=10$; (b) $\zeta=20$; (c) $\zeta=30$; (3) $\zeta=40$. Note that the pc approach recognizes  a curve crossing around $\epsilon_d=-0.05$ for $\zeta=10,20$ (though $\zeta=30,40$ does not). 
This switch enables smooth curves over the full range of $\epsilon_d$ as shown in Figs. \ref{fig:pcfc_E} and \ref{fig:pcfc_n}.  
The parameter set is the two-site model $\epsilon_d=\epsilon_{d_1}=\epsilon_{d_2}, \Gamma=0.01, t_d=0.2, U=0.1$ with 31 evenly distributed metal states  with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $3\Gamma$).
}
\label{fig:pcfc_zeta} 
\end{figure}

\section{Discussion}
So far, we have demonstrated that cCASSCF potential energy surfaces should be useful for modeling electron transfer processes at surfaces. That being said, in order to apply them in practice, two more practical quantities must be extracted. First, if we seek to run fully nonadiabatic dynamics in the spirit of an FSSH-ER algorithm\cite{jin2021nonadiabatic}, we will require system-bath couplings that capture non-vibrational electronic relaxation.  Second, if we seek to extract Marcus-like rate expression, we will need diabatic curves and diabatic couplings. We will now show how these quantities can be obtained.


\subsection{System-Bath Couplings}
\label{subsec:sb coupling}
In order to describe the molecule-metal coupling in a charge transfer process using as few singly-excitation configurations as possible (for reasons of efficiency), we will consider only single excitations between core and active ($i \rightarrow t,u$) as well as single excitations between active and virtual ($t,u \rightarrow a$).

Let us denote our  three DW-SA-cCASSCF(2,2) system CI states as $\{\ket{\Psi_0}, \ket{\Psi_1}, \ket{\Psi_2}\}$: 
\begin{equation}
\label{eqn:system}
    \Omega_S \equiv \{\ket{\Psi_0}, \ket{\Psi_1}, \ket{\Psi_2}\}
\end{equation}
following the conventions of Eq. \ref{eqn:casscf} above.
%If we drop the core electron configuration in our labeling of the slater determinants $\ket{t\bar{t}}$, $\ket{u\bar{u}}$ and $\ket{t\bar{u}+u\bar{t}}$, we 
%where three DW-SA-cCASSCF(2,2) states are defined as (we ignore the
%:
%\begin{align}
 %   \ket{\Psi_0}&=\alpha_0\ket{t\bar{t}}+\beta_0\ket{u\bar{u}}+\gamma_0\ket{t\bar{u}+u\bar{t}}\\
 %   \ket{\Psi_1}&=\alpha_1\ket{t\bar{t}}+\beta_1\ket{u\bar{u}}+\gamma_1\ket{t\bar{u}+u\bar{t}}\\
%    \ket{\Psi_2}&=\alpha_2\ket{t\bar{t}}+\beta_2\ket{u\bar{u}}+\gamma_2\ket{t\bar{u}+u\bar{t}}
%\end{align},
%where $\alpha_I,\beta_I,\gamma_I$ are CI coefficients for $I$th DW-SA-cCASSCF(2,2) state.
For the three system CI states above, we focus on those bath states that arise from single excitations with reference to three configurations: $\ket{t\bar{t}}$, $\ket{u\bar{u}}$ and $\ket{t\bar{u}+u\bar{t}}$.
%\begin{equation}
%    \Omega_B \equiv \{ \ket{\Psi_i^t}, \ket{\Psi_i^u}, \ket{\Psi_t^a}, \ket{\Psi_u^a} \}
%\end{equation}
In general, identifying and indexing excitations from a multireference configuration can be very difficult and tedious. Howevever, for CASSCF(2,2) refrence, this task is not terrible. 
%Notice that the configuration inside $\Omega_B$ depends on which reference configuration being excited. However, if we write these configurations on top of one reference state configuration, which is $\ket{t\bar{t}}$ (like Hartree-Fock), then 
If we define the reference state configuration to be $\ket{t\bar{t}}$, then there are four relevant classes of excited state slater determinants composed of molecular orbitals $i,t,u,a$: 
\begin{equation}\label{eqn:single_excitation}
    \begin{aligned}
        \ket{\Psi_i^u}&=\ket{\cdots u\bar{i}\cdots t\bar{t}}\\
        \ket{\Psi_t^a}&=\ket{\cdots i\bar{i}\cdots a\bar{t}}\\
        \ket{\Psi_{i\bar{t}}^{u\bar{u}}}&=\ket{\cdots u\bar{i}\cdots t\bar{u}}\\
        \ket{\Psi_{t\bar{t}}^{a\bar{u}}}&=\ket{\cdots i\bar{i}\cdots a\bar{u}}
    \end{aligned}
\end{equation}
Therefore, let us denote our bath CI states as:
\begin{equation}
\label{eqn:bath}
   \Omega_B \equiv \{ \ket{\Psi_i^u}, \ket{\Psi_t^a}, \ket{\Psi_{i\bar{t}}^{u\bar{u}}}, \ket{\Psi_{t\bar{t}}^{a\bar{u}}} \} 
    % (\textbf{reference to} \ket{\cdots i\bar{i}\cdots t\bar{t}})
\end{equation}
% \begin{equation}
%     \Omega_B \equiv \Omega_B^{tt} \cup \Omega_B^{uu} \cup \Omega_B^{tu} 
% \end{equation},
% where $\Omega_B^{tt}$, $\Omega_B^{uu}$ and $\Omega_B^{tu}$ are the singly excitations with reference to the configuration $\ket{t\bar{t}}$, $\ket{u\bar{u}}$ and $\ket{t\bar{u}+u\bar{t}}$, respectively:
% \begin{equation}
%     \Omega_B^{tt} \equiv \{ \ket{\Psi_i^u}_{tt}=\ket{\cdots u\bar{i}\cdots t\bar{t}}, \ket{\Psi_t^a}_{tt}=\ket{\cdots i\bar{i}\cdots a\bar{t}} \}
% \end{equation}
% \begin{equation}
%     \Omega_B^{uu} \equiv \{ \ket{\Psi_i^t}_{uu}=\ket{\cdots t\bar{i}\cdots u\bar{u}}, \ket{\Psi_u^a}_{uu}=\ket{\cdots i\bar{i}\cdots a\bar{u}} \}
% \end{equation}
% \begin{equation}
%     \Omega_B^{tu} \equiv \{ \ket{\Psi_i^t}_{tu}=\ket{\cdots t\bar{i}\cdots u\bar{t}}, \{ \ket{\Psi_i^u}_{tu}=\ket{\cdots u\bar{i}\cdots t\bar{u}} , \ket{\Psi_t^a}_{tu}=\ket{\cdots i\bar{i}\cdots a\bar{u}}, \ket{\Psi_u^a}_{tu}=\ket{\cdots i\bar{i}\cdots a\bar{t}} \}
% \end{equation}
% Interestingly, we find that the $\Omega_B^{tu}$ subspace is completely the same as the $\Omega_B^{tt} \cup \Omega_B^{uu}$ subspace, because:
% \begin{equation}
% \begin{aligned}
%     \ket{\Psi_i^t}_{tu}&=-\ket{\Psi_i^u}_{tt}\\
%     \ket{\Psi_i^u}_{tu}&=-\ket{\Psi_i^t}_{uu}\\
%     \ket{\Psi_t^a}_{tu}&=\ket{\Psi_u^a}_{uu}\\
%     \ket{\Psi_u^a}_{tu}&=\ket{\Psi_t^a}_{tt}
%     \end{aligned}
% \end{equation}
Having defined the system and the bath states, the Hamiltonian for the whole universe can be schematically represented as:

\begin{equation}
\begin{aligned}
    H&=
\left[
\begin{array}{c|c}
\textbf{system} & \textbf{coupling} \\
\hline
\textbf{coupling} & \textbf{bath}  \\
\end{array}
\right]
\\
\textbf{system}&=
\left[
\begin{array}{ccc}
\mel{\Psi_0}{H}{\Psi_0} & 0 & 0 \\
0 & \mel{\Psi_1}{H}{\Psi_1} & 0 \\
0 & 0 & \mel{\Psi_2}{H}{\Psi_2}\\
\end{array}
\right]
\\
\textbf{coupling} &=
\left[
\begin{array}{cccc}
 \mel{\Psi_0}{H}{S_i^u} & \mel{\Psi_0}{H}{S_t^a} & \mel{\Psi_0}{H}{S_{i\bar{t}}^{u\bar{u}}} & \mel{\Psi_0}{H}{S_{t\bar{t}}^{a\bar{u}}}\\
  \mel{\Psi_1}{H}{S_i^u} & \mel{\Psi_1}{H}{S_t^a} & \mel{\Psi_1}{H}{S_{i\bar{t}}^{u\bar{u}}} & \mel{\Psi_1}{H}{S_{t\bar{t}}^{a\bar{u}}}\\
   \mel{\Psi_2}{H}{S_i^u} & \mel{\Psi_2}{H}{S_t^a} & \mel{\Psi_2}{H}{S_{i\bar{t}}^{u\bar{u}}} & \mel{\Psi_2}{H}{S_{t\bar{t}}^{a\bar{u}}}\\
\end{array}
\right]
\\
\textbf{bath} &=
\left[
\begin{array}{cccc}
\mel{S_i^u}{H}{S_i^u} & * & * & * \\
* & \mel{S_t^a}{H}{S_t^a} & * & * \\
* & * & \mel{S_{i\bar{t}}^{u\bar{u}}}{H}{S_{i\bar{t}}^{u\bar{u}}} & * \\
* & * & * & \mel{S_{t\bar{t}}^{a\bar{u}}}{H}{S_{t\bar{t}}^{a\bar{u}}}
\end{array}
\right]
\end{aligned}
\end{equation}

Here, we have employed spin-adapted singlet configurations:
\begin{equation}\label{eqn:spin_adapted_single_excitation}
\begin{aligned}
    \ket{S_i^u}&=\frac{\ket{\Psi_i^u}+\ket{\Psi_{\bar{i}}^{\bar{u}}}}{\sqrt{2}}\\
    \ket{S_t^a}&=\frac{\ket{\Psi_t^a}+\ket{\Psi_{\bar{t}}^{\bar{a}}}}{\sqrt{2}}\\
    \ket{S_{i\bar{t}}^{u\bar{u}}}&=\frac{\ket{\Psi_{i\bar{t}}^{u\bar{u}}}+\ket{\Psi_{t\bar{i}}^{u\bar{u}}}}{\sqrt{2}}\\
    \ket{S_{t\bar{t}}^{a\bar{u}}}&=\frac{\ket{\Psi_{t\bar{t}}^{a\bar{u}}}+\ket{\Psi_{t\bar{t}}^{u\bar{a}}}}{\sqrt{2}}
\end{aligned}
\end{equation}

% In this subsection, we refer ``system" as the three DW-SA-cCASSCF(2,2) states which carry the charge transfer characters between molecules and metal surfaces. Meanwhile, we construct the single excitation on top of these three ``system" states as described in Sec. \ref{subsec:sb coupling}, defining these single excitation states as ``bath". 
We may then construct   
%In this subsection, we continue with %the annotation in Sec. \ref{subsec:sb coupling} and write 
{\em many-body} hybridization function between the system excited states and  the bath (which is analogous to the single-orbital hybridization in Eq. \ref{eqn:Gamma}):
\begin{equation}
\label{eqn:coupling}
\begin{aligned}
    \tilde{\Gamma}_1&= 2\pi\sum_B|\mel{\Psi_B}{H}{\Psi_1}|^2\delta(E_B-E_1)\\
    \tilde{\Gamma}_2&= 2\pi\sum_B|\mel{\Psi_B}{H}{\Psi_2}|^2\delta(E_B-E_2),
    \end{aligned}
\end{equation}
where $\ket{\Psi_B}$ is the {\em bath} state defined in Eq. \ref{eqn:bath} and $E_B$ is the {\em bath} state energy. $\ket{\Psi_1},\ket{\Psi_2}$ are two excited {\em system} states defined in Eq. \ref{eqn:system} and $E_1,E_2$ are excited {\em system} state energies. 

Consider  the $U=0$ case. In Fig. \ref{fig:coupling}, we plot the first and the second excited state hybridizations, $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$, respectively.  The magnitudes of both $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$ are of the same order as the impurity-bath hybridization $\Gamma$ as found in Ref. \citenum{jin2021nonadiabatic}.  More interestingly, in both cases, there is a dip in the effective hybridization  around $\epsilon_d(x)=0$. For the $\tilde{\Gamma}_1$ case, this interesting behavior was reported previously in Ref. \citenum{jin2021nonadiabatic}. In Ref. \citenum{jin2021nonadiabatic}, it was argued that this dip arises from the fact that although electronic relaxation between molecule and metal is dictated by the hybridization far away from the crossing, near the crossing the relaxation is dictated by vibronic or electron-phonon interactions (which leads to the dip at $\epsilon_d(x)=0$). 
To better understand the origin of this effect, in Fig. \ref{fig:coupling_U0}(b), we plot the density of bath states for the case $\Gamma=0.01$. We find that the density of states is roughly constant for the $S_0-S_1$ crossing as a function of $\epsilon_d(x)$. Thus, at least in one case, this dip is indeed caused by the changing character of the electronic states around the crossing point.
As a practical matter, we  note size of this dip does depend on the extent of dynamical weighting (not shown); at the same time however, following the results in Ref.\citenum{jin2021nonadiabatic}, we do not expect this dip to have a major dynamical impact.


\begin{figure}[H]
\centering

\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/coupling_G1_new.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/coupling_G2_new.pdf}
\end{subfigure}
%
\caption{The hybridization between a DW-SA-pcCASSCF(2,2) ($\zeta=40$) excited state and the bath states. (a) The hybridization for state $S_1$ ($\tilde{\Gamma}_1$); (b) the hybridization for state $S_2$ ($\tilde{\Gamma}_2$).
We investigate four different $\Gamma$s: $10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}$. Note that both $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$ have a dip at the symmetric point, where the onsite energy $\epsilon_d(x)$ reaches the fermi level $\epsilon_f=0$. We calculate $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$ using a lorentzian function to approximate the delta function in Eq. \ref{eqn:coupling}: i.e. $\delta(x-x_0)\approx\frac{1}{\pi}\frac{\sigma/2}{(x-x_0)^2+(\sigma/2)^2}$ with the full width at half maximum (FWHM) $\sigma=\Gamma$. The parameter set is theone-site model with $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05, U=0$ with 101 evenly distributed metal states with  energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:coupling}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/coupling_G12_U0_gamma001_new.eps}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/simple_DOS_U0_gamma-2_new.eps}
\end{subfigure}
% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/coupling_G12_U01_gamma001.eps}
% \end{subfigure}
% %
% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/DOS_U01_gamma-2.eps}
% \end{subfigure}
%
\caption{(a) The many-body hybridizations $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$; (b) The density of states (DOS) around the $S_1$ and $S_2$ energy levels. Note that the DOS around $S_1$ is effectively constant so that the dip in $\tilde{\Gamma}_1$
at $\epsilon_d=0$ is caused exclusively
by the change in electronic wavefunctions at the crossing point. The case of $S_2$ is slightly more difficult to interpret, but the fact that the DOS seems to have two maxima whereas the hybridization $\tilde{\Gamma}_2$ has two minima would also suggest that the variations in $\tilde{\Gamma}_2$ are not due to DOS effects.
Here, the DOS($S_1$) is calculated by counting in those bath states whose energy is within the energy window $[E(S_1)-\Gamma/2,E(S_1)+\Gamma/2]$ (same for DOS($S_2$)). 
% Note that the coupling behavior at the symmetric point for $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$ are different due to different DOS for $U=0$ and $U=0.1$ cases. 
The parameter set is the one-site model with $m\omega^2=0.003, g=0.0075, e_{d_1}=0.0365,
% for $U=0.1$ case, one-site model with $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06$. 
\Gamma=0.01, U=0, \zeta=40$ with 101 evenly distributed metal states with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:coupling_U0}

\end{figure}

% \begin{figure}[H]
% \centering

% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/DOS_gamma-2.eps}
% \end{subfigure}
% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/DOS_gamma-3.eps}
% \end{subfigure}
% %
% \caption{Heat maps for density of states (DOS). (a) $\Gamma=0.01$; (b) $\Gamma=0.001$. Note that Fig. (a) has the highest DOS at the $S_1$-$S_2$ crossing, leading to the tip for G1 at the middle of Fig. \ref{fig:coupling_U01}(a) (the blue line). Also note that the highest DOS area in Fig. (b) doesn't match the $S_1$ energy, therefore, there is no tip for G1 right at the middle of Fig. \ref{fig:coupling_U01}(a) (the orange line). The parameter set is: $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06, U=0.1$ with 101 metal states evenly distributed with the energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
% \label{fig:DOS_U01}

% \end{figure}

% \begin{figure}[H]
% \centering

% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/gap.pdf}
% \end{subfigure}
% %
% \begin{subfigure}[t]{0.45\textwidth}
% \centering
% \hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/gap_U01.pdf}
% \end{subfigure}
% \end{figure}
% \begin{figure}\ContinuedFloat
% \begin{subfigure}[t]{\textwidth}
% \centering
% \vspace{-70pt}% set the real top as the top
% % \hspace*{-0mm}\includegraphics[width=1.0\linewidth]
% \end{subfigure}
% %
% \caption{The minimum excitation gap between the DW-SA-pcCASSCF(2,2) ($\zeta=40$) state $S_0$ and the DW-SA-pcCASSCF(2,2) ($\zeta=40$) state $S_1$ across the range $\epsilon_d(x) \in [3\Gamma-U, -3\Gamma-U]$, for (a) $U=0$; (b) $U=0.1$. Note that DW-SA(the ``zeta=40" line) makes the gap smaller than that without DW-SA. Also note that the gap is in linear relationship with $\Gamma$ when $\Gamma<10^{-3}$. The uphill behavior of the ``zeta=40" line is because of the fact that the mixing weight on the ground state $S_0$ is increasing. The parameter set is: For $U=0$, $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05$; For $U=0.1$, $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06$, with 101 metal states evenly distributed with the energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
% \label{fig:gap}

% \end{figure}

\subsection{Diabatization}
For the purposes of modeling electron transfer with Marcus theory\cite{marcus1956theory}, it can be very helpful to work with a set of diabatic states.  Luckily, for a CASSCF(2,2) calculation, generating such diabatic states is often straightforward. Here, we will generate an adiabatic-to-diabatic transformation by 
%Our last task is to diabatize the three DW-SA-cCASSCF(2,2) states, $S_0, S_1$ and $S_2$. For the present Hamiltonian, this task can be achieved
diagonalizing the impurity projector  $\hat{w}$ in the basis of the three DW-SA-cCASSCF(2,2) states ($S_0, S_1$ and $S_2$). For the one-impurity Hamiltonian in Eq. \ref{eqn:model}, we diagonalize $\hat{w}=d^{\dagger}d$:
\begin{equation}
    C_{diab}^{\dagger}\hat{w}C_{diab}=n_{diab}
\end{equation}
The transformed diabatic Hamiltonian is then:
\begin{equation}
    H_{diab}=C_{diab}^{\dagger}\hat{H}C_{diab}
\end{equation}
In Fig. \ref{fig:Ediab}, we plot the extracted diabatic energies for the one-site Hamiltonian in Eq. \ref{eqn:model}. From the data, it is clear that the resulting energies and couplings are smooth:  the diabatization is robust. 

\begin{figure}[H]
\centering

\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Ediab.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Ediab_U01.pdf}
\end{subfigure}

\caption{The adiabatic and diabatic energies as a function of $\epsilon_d(x)$, for (a) $U=0$; (b) $U=0.1$. The diabatization uses the three DW-SA-pcCASSCF(2,2) ($\zeta=40$) states as the adiabatic state basis.  The parameter set is the one-site model and for $U=0$, we set $m\omega^2=0.003, g=0.0075, e_{d_1}=0.0365,\Gamma=0.01$. For $U=0.1$, we set $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06, \Gamma=0.01$. There are  101 metal states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:Ediab}
\end{figure}

Next, in Fig. \ref{fig:Vdiab}, we plot the diabatic couplings between the diabat 0 and the diabat 1 ($V_{01}$)  as a function of $\epsilon_d$ and for a range of different $\Gamma$s: $10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}$.
We investigate both the $U=0$ and $U=0.1$ cases.
Note that these couplings are nearly identical across all values of $\epsilon_d$ and both values of $U$; the couplings depend more than anything on the value of $\Gamma$. Note that the values of 
$|V_{01}|$ are identical (up to $10^{-15}$ significant digits) with the values of $|V_{12}|$. The diabatic coupling between the diabat 0 and the diabat 2 ($V_{02}$) is effectively zero (not shown).

\begin{figure}[H]
\centering

\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Vdiab.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Vdiab_U01.pdf}
\end{subfigure}
%
\caption{The diabatic coupling $|V_{01}|$ (which is numerically found to be equal to $|V_{12}|$) as a function of $\epsilon_d(x)$, for (a) $U=0$; (b) $U=0.1$, for four different $\Gamma$s: $10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}$. Note that diabat 0 and diabat 2 are indirectly coupled with each other according to $V_{01}$ and $V_{12}$ but the direct coupling $V_{02}$ is 0. The diabatization uses the three DW-SA-pcCASSCF(2,2) ($\zeta=40$) states as the adiabatic state basis. The parameter set is $U=0$, $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05$ or $U=0.1$, $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06$. We include 101 metal states evenly distributed with energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:Vdiab}
\end{figure}

Lastly, in Fig. \ref{fig:Vdiab_gamma}, we plot the diabatic coupling $V_{01}$, as well as the adiabatic $S_0-S_1$ minimum excitation gap, as a function of the molecule-metal coupling $\Gamma$. 
We plot results with dynamically-weighted state-averaging (DW-SA, blue)  and without any state-averaging (red). Several conclusions are apparent. 
First, the relationship between   $V_{01}-\Gamma$ and gap$-\Gamma$ are almost linear; see the dashed line for linear fits.  Note that a linear relationship between the gap and $\Gamma$ was found previously in Ref. \citenum{jin2021nonadiabatic}),
where it was shown that a reduced model Hamiltonian can in fact recover Marcus's electrochemical rate expression for the case $U=0$.
Second, one finds that DW-SA reduces both the gap and the diabatic coupling (compared to no DW-SA); this finding is perhaps expected because, in the gas phase, without state averaging, one does not properly the ground state and the excited state (and the gap is often too large). Third, by comparing (a) with (b) or (c) with (d), we find that the results do not change a lot after adding electron-electron repulsion ($U=0.1$); it would seem that, within this model, the main impact of electron-electron repulsion is on the barriers present in the ground state. For instance, for the $U=0$ case in Fig. \ref{fig:Ediab}(a), the symmetric barrier is 0.013; for the $U=0.1$ case in Fig. \ref{fig:Ediab}(b), the symmetric barrier is 0.007 for the middle well and 0.009 for the left/right well. Fourth, if one looks carefully at the $\zeta=40$ lines, one can discern a slight uphill behavior for large (around $\Gamma=0.01$); this feature arises because the weight of the ground state $S_0$ increases as the gap grows; after all, $\zeta$ is  a constant. In the future, one may want to employ a $\zeta$ that depends on $\Gamma$; in practice, this would mean choosing weighting parameters depending on the distance from the molecule to the metal. 


\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Vdiab_gamma.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/Vdiab_gamma_U01.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/gap.pdf}
\end{subfigure}
%
\begin{subfigure}[t]{0.45\textwidth}
\centering
\hspace*{-0mm}\includegraphics[width=1.0\linewidth]{images2/gap_U01.pdf}
\end{subfigure}
\caption{The diabatic coupling $|V_{01}|$ (the same as $|V_{12}|$) at the minimum crossing, for (a) $U=0$; (b) $U=0.1$. The $S_0-S_1$ excitation gap at the minimum crossing, for (c) $U=0$; (d) $U=0.1$. Note that both quantities effectively depend linearly on the system-bath coupling $\Gamma$. Also note that the slight  uphill behavior for the $\zeta=40$ line arises because the weight on the ground state $S_0$ increases for large $\zeta$. The parameter set is the one-site model with $U=0$, $m\omega^2=0.003, g=0.0075, e_{d_1}=0.05$ or with $U=0.1$, $m\omega^2=0.001, g=0.0075, e_{d_1}=0.06$. We include 101 metal states evenly distributed with  energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $10\Gamma$).} 
\label{fig:Vdiab_gamma}
\end{figure}
\newpage

\section{Conclusions}
In this paper, we have investigated a novel dynamically-weighted state-averaged constrained CASSCF(2,2) (DW-SA-cCASSCF(2,2)) electronic structure approach for studying open quantum systems and in particular molecules on metal surfaces. We have focused on this approach after several aborted attempts with other methods. For several reasons, the present method seems to be an excellent candidate for future work navigating electron transfer at a metal surface:
(i) The adiabatic energies are smooth 
as a result of state-averaging and implementing a constraint that forces the active space to overlap with the impurity; (ii) Diabatization is possible and Marcus curves can be generated; (iii) The approach overlaps well with standard CASSCF theory and we can employ (with modification) many standard quantum chemistry tools to solve the necessary equations.
In the end, although DW-SA-cCASSCF(2,2) wavefunctions are slightly more involved than standard multireference approaches, the active space is small and convergence can be achieved. 

Looking forward, the present method  should be applicable to realistic, {\em ab initio} systems, which we will report in a future publication. We also anticipate running fewest switches surface hopping (FSSH) calculations in the future where we will studying molecules moving (adiabatically or nonadiabatically) along metal surfaces once a gradient\cite{glover2014communication}
has been constructed; obviously, studying electrochemical dynamics will be easier than studying photo-electrochemical dynamics.   Finally, in this paper,  by working with a model Hamiltonian, we have ignored the question of  electron-electron exchange that inevitably  complicates any description of a metal (where Hartree-Fock exchange is not physical). In the future, when working with realistic (fully ab initio) models of molecules on surfaces, it would be very helpful if we can merge the present CASSCF(2,2) wavefunction calculation with a DFT framework, either in the spirit of multiconfiguration pair-density functional theory (MC-PDFT) \cite{gagliardi2017multiconfiguration}, time-dependent density functional theory plus one double (TDDFT-1D)\cite{athavale2022analytical}, or hole–hole Tamm–Dancoff approximated (hh-TDA)\cite{bannwarth2020hole}.
Armed with such an algorithm, one anticipates many new calculations that one would like to tackle at a catalytic metal surface. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The "Acknowledgement" section can be given in all manuscript
%% classes.  This should be given within the "acknowledgement"
%% environment, which will make the correct section or running title.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{acknowledgement}

This work was supported by the U.S. Air Force Office of Scientific Research (USAFOSR) under Grant Nos. FA9550-18-1-0497 and FA9550-18-1-0420. We thank the DoD High Performance Computing Modernization Program for computer time. We also thank Xinchun Wu for making corrections to the original draft. 
\end{acknowledgement}

\section{Appendix}
\subsection{Single Excitation Matrix Elements}
In this subsection, for the sake of concreteness, we report the matrix element between the system states (defined in Eq. \ref{eqn:system}) and the bath states (defined in Eq. \ref{eqn:bath}).
\begin{equation}
\begin{aligned}
    \mel{t\bar{t}}{H}{S_i^u} &= (\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots u\bar{i} \cdots t\bar{t}}+\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{u} \cdots t\bar{t}})/\sqrt{2} \\
    % &= h_{iu} + 2\sum_j (iu|jj) - (iu|ii) + 2(iu|tt) - \sum_j (ij|ju) + (ii|iu) - (it|tu)\\
    &= \sqrt{2}*(F^I_{iu} + 2(iu|tt) - (it|tu))\\
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{t}}{H}{S_t^a} &= (\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{i} \cdots a\bar{t}}+\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{i} \cdots t\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(F^I_{ta} + (ta|\bar{t}\bar{t}))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{t}}{H}{S_{i\bar{t}}^{u\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots u\bar{i} \cdots t\bar{u}}+\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots u\bar{t} \cdots i\bar{u}})/\sqrt{2} \\
    &= \sqrt{2}*(iu|\bar{t}\bar{u})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{t}}{H}{S_{t\bar{t}}^{a\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{i} \cdots a\bar{u}}+\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{i} \cdots u\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(ta|\bar{t}\bar{u})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{u}}{H}{S_i^u} &= (\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots u\bar{i} \cdots t\bar{t}}+\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{u} \cdots t\bar{t}})/\sqrt{2}\\
    &= -\sqrt{2}*(it|\bar{u}\bar{t})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{u}}{H}{S_t^a} &= (\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{i} \cdots a\bar{t}}+\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{i} \cdots t\bar{a}})/\sqrt{2}\\
    &= \sqrt{2}*(ua|\bar{u}\bar{t})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{u}}{H}{S_{i\bar{t}}^{u\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots u\bar{i} \cdots t\bar{u}}+\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots u\bar{t} \cdots i\bar{u}})/\sqrt{2} \\
    &= -\sqrt{2}*(F^{I}_{it} + 2(it|uu)-(iu|ut))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{u}}{H}{S_{t\bar{t}}^{a\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{i} \cdots a\bar{u}}+\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{i} \cdots u\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(F^{I}_{ua} + (ua|\bar{u}\bar{u}))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{t}}{H}{S_i^u} &= (\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots u\bar{i} \cdots t\bar{t}}+\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots i\bar{u} \cdots t\bar{t}})/\sqrt{2} \\
    &= \sqrt{2}*(-F^{I}_{it} - (it|\bar{t}\bar{t}))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{t}}{H}{S_t^a} &= (\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots i\bar{i} \cdots a\bar{t}}+\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots i\bar{i} \cdots t\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(F^{I}_{ua} + (ua|\bar{t}\bar{t}))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{t}}{H}{S_{i\bar{t}}^{u\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots u\bar{i} \cdots t\bar{u}}+\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots u\bar{t} \cdots i\bar{u}})/\sqrt{2} \\
    &= -\sqrt{2}*(it|\bar{t}\bar{u})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{u\bar{t}}{H}{S_{t\bar{t}}^{a\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots i\bar{i} \cdots a\bar{u}}+\mel{\cdots i\bar{i} \cdots u\bar{t}}{H}{\cdots i\bar{i} \cdots u\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(ua|\bar{t}\bar{u})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{u}}{H}{S_i^u} &= (\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots u\bar{i} \cdots t\bar{t}}+\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots i\bar{u} \cdots t\bar{t}})/\sqrt{2} \\
    &= \sqrt{2}((iu|\bar{u}\bar{t})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{u}}{H}{S_t^a} &= (\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots i\bar{i} \cdots a\bar{t}}+\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots i\bar{i} \cdots t\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(ta|\bar{u}\bar{t})
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{u}}{H}{S_{i\bar{t}}^{u\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots u\bar{i} \cdots t\bar{u}}+\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots u\bar{t} \cdots i\bar{u}})/\sqrt{2} \\
    &= \sqrt{2}*(F^{I}_{iu} + (iu|\bar{u}\bar{u}))
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
    \mel{t\bar{u}}{H}{S_{t\bar{t}}^{a\bar{u}}} &= (\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots i\bar{i} \cdots a\bar{u}}+\mel{\cdots i\bar{i} \cdots t\bar{u}}{H}{\cdots i\bar{i} \cdots u\bar{a}})/\sqrt{2} \\
    &= \sqrt{2}*(F^{I}_{ta} + (ta|\bar{u}\bar{u}))
\end{aligned}
\end{equation}


Finally, again for completeness, let us now also report the diagonal matrix elements for the Hamiltonian in the basis of single excitation configurations:
\begin{align}
 \mel{S_i^u}{H}{S_i^u} &= \mel{\cdots u\bar{i} \cdots t\bar{t}}{H}{\cdots u\bar{i} \cdots t\bar{t}}+\mel{\cdots u\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{u} \cdots t\bar{t}} \nonumber \\
    % &= h_{iu} + 2\sum_j (iu|jj) - (iu|ii) + 2(iu|tt) - \sum_j (ij|ju) + (ii|iu) - (it|tu)\\
    &= E_{tt}+F^I_{uu}-F^{I}_{ii}+[2(uu|tt)-(ut|tu)]-[2(ii|tt)-(it|ti)]-(uu|ii)+2(ui|iu)\\
\mel{S_t^a}{H}{S_t^a} &= \mel{\cdots i\bar{i} \cdots a\bar{t}}{H}{\cdots i\bar{i} \cdots a\bar{t}}+\mel{\cdots i\bar{i} \cdots a\bar{t}}{H}{\cdots i\bar{i} \cdots t\bar{a}} \nonumber \\
    &= E_{tt}+F^I_{aa}-F^{I}_{tt}+[2(aa|tt)-(at|ta)]-[2(tt|tt)-(tt|tt)]-(aa|tt)+2(at|ta)\\
\mel{S_{i\bar{t}}^{u\bar{u}}}{H}{S_{i\bar{t}}^{u\bar{u}}} &= \mel{\cdots u\bar{i} \cdots t\bar{u}}{H}{\cdots u\bar{i} \cdots t\bar{u}}+\mel{\cdots u\bar{i} \cdots t\bar{u}}{H}{\cdots u\bar{t} \cdots i\bar{u}} \nonumber \\
    &= E_{uu}+F^I_{tt}-F^{I}_{ii}+[2(tt|uu)-(tu|ut)]-[2(ii|uu)-(iu|ui)]-(tt|ii)+2(ti|it)\\
    \mel{S_{t\bar{t}}^{a\bar{u}}}{H}{S_{t\bar{t}}^{a\bar{u}}} &= \mel{\cdots i\bar{i} \cdots a\bar{u}}{H}{\cdots i\bar{i} \cdots a\bar{u}}+\mel{\cdots i\bar{i} \cdots a\bar{u}}{H}{\cdots i\bar{i} \cdots u\bar{a}} \nonumber \\
    &= E_{uu}+F^I_{aa}-F^{I}_{uu}+[2(aa|uu)-(au|ua)]-[2(uu|uu)-(uu|uu)]-(aa|uu)+2(au|ua).
\end{align}
Here $E_{tt}$ and $E_{uu}$ are the energies of the reference states:
\begin{align}
    E_{tt}&=\mel{\cdots i\bar{i} \cdots t\bar{t}}{H}{\cdots i\bar{i} \cdots t\bar{t}}\\
    E_{uu}&=\mel{\cdots i\bar{i} \cdots u\bar{u}}{H}{\cdots i\bar{i} \cdots u\bar{u}}
\end{align}

% \subsection{Pseduocode for DW-SA-cCASSCF(2,2)}
% \begin{algorithm}[H]
%   \caption{Quasi-Newton Algorithm for DW-SA-cCASSCF(2,2)}
%   \begin{algorithmic}[1]\label{alg:minE}
%     \Procedure{minE}{}\Comment{Minimize energy}
%       % \State Initialize state-average weighting factor: $\omega_0\gets 1$, $\omega_1\gets 0$ and $\omega_2\gets 0$; 
%       \State Obtain guess orbitals ($\bm{C}$) from finite temperature Hartree-Fock (FT-HF); 
%       \State Initialize configuration interaction (CI) coefficients in Eq. \ref{eqn:casscf}): 
%       \begin{equation}
%         \bm{c}=
%           \begin{bmatrix}
%               \alpha_0 & \alpha_1 & \alpha_2\\
%               \beta_0 & \beta_1 & \beta_2\\
%               \gamma_0 & \gamma_1 & \gamma_2
%           \end{bmatrix}
%           =
%           \begin{bmatrix}
%               1 & 0 & 0\\
%               0 & 1 & 0\\
%               0 & 0 & \frac{1}{\sqrt{2}}
%           \end{bmatrix}
%       \end{equation}
%       \State Initialize lagrange multiplier: $\lambda\gets 0.1$;
%       \State Set state-average parameter: $\zeta\gets40$;
%       \While{$\norm{\grad{\mathcal{L}}}>$thresh}\Comment{Optimization converges if $\norm{\grad{\mathcal{L}}}<$thresh}

%         \State Compute state-average weighting factors: $\omega_0$, $\omega_1$ and $\omega_2$ by Eq. \ref{eqn:DW};
%         \State Compute 1PMD ($D^{SA}$) and 2PDM ($\tilde{D}^{SA}$) in SA fashion (using Eq. \ref{eqn:1PDM}, Eq. \ref{eqn:2PDM} and Eq. \ref{eqn:sa_pdm});
%         \State Perform constrained orbital optimization using procedure [$\bm{C},\lambda$]=cOPT-ORB($\bm{C},\bm{\omega},\bm{c},\lambda$);
%         \State Perform configuration interaction diagonalization using procedure [$\bm{c}$]=CASCI22($\bm{C},\bm{c}$); 
        
        
%       \EndWhile\label{lssqpwhile}
%       % \For{\texttt{<some condition>}}
%       %   \State \texttt{<do stuff>}
%       % \EndFor
%       % \State \textbf{return} $b$\Comment{The gcd is b}
%     \EndProcedure

%     \Procedure{[$\bm{C},\lambda$]=cOPT-ORB}{$\bm{C},\bm{\omega},\bm{c},\lambda$}\Comment{Constrained Orbital Optimization}
%         \While{}\Comment{Break when constraint satisfies}
%         \State Compute state-averaged constrained energy gradient by Eqs. \ref{eqn:Bit_pc},\ref{eqn:Bia_pc},\ref{eqn:Bta_pc}:
%         \begin{equation}
%             \bm{g}_1=
%             \begin{bmatrix}
%                 \tilde{B}_{it}\\
%                 \tilde{B}_{ia}\\
%                 \tilde{B}_{ta}
%             \end{bmatrix};
%         \end{equation}
%         \State Compute Hessian $\tilde{H}_1$ with finite difference;
%         \For{\texttt{$k = 1,2...$}}
%         \State If $\tilde{H}_k$ is not positive definite with smallest eigenvalue $e$ (e.g. $e<1\times 10^{-8}$),
%         \begin{equation}
%             \tilde{H}_k=\tilde{H}_k+(\abs{e}+1.0)I;
%         \end{equation}
%         \State Obtain Newton direction $\bm{p}_k$ by inversing approximate Hessian $\tilde{H}_k$:
%         \begin{equation}
%             \bm{p}_k = -\tilde{H}_k^{-1}\bm{g}_k;
%         \end{equation}
%         \algstore{myalg}
%         \end{algorithmic}
% \end{algorithm}
% \begin{algorithm}                     
% \begin{algorithmic} [1]                   % enter the algorithmic environment
% \algrestore{myalg}
%         \State Construct the anti-symmetric rotation matrix: 
%         \begin{equation}
%             \Theta =
%             \begin{bmatrix}
%                 0 & (\bm{p}_k)_{it} & (\bm{p}_k)_{ia}\\
%                 -(\bm{p}_k^T)_{ti} & 0 & (\bm{p}_k)_{ta}\\
%                 -(\bm{p}_k^T)_{ai} & -(\bm{p}_k^T)_{at} & 0
%             \end{bmatrix};
%         \end{equation}
        
%         \State Construct the energy function as a function of the step length in the direction $\bm{p}_k$: 
%         \begin{equation}
%             F_0(\alpha)=f_0(\bm{C}_k\exp{-\alpha\Theta}),
%         \end{equation}
%         as well as the directional derivative: 
%         \begin{equation}
%             F_1(\alpha)=\bm{f_1}^T(\bm{C}_k\exp{-\alpha\Theta}) * \bm{p}_k;
%         \end{equation}
        
%         \State Find an optimal step length $\alpha_k$ by line search procedure [$\alpha_k$]=LS($F_0$,$F_1$);
        
%         \State Update orbitals: 
%         \begin{equation}
%             \bm{C}_{k+1}=\bm{C}_k\exp{-\alpha_k\Theta}
%         \end{equation}
%         \State Compute $\bm{g}_{k+1}$;
%         \If{$\norm{\bm{g}_{k+1}}<\texttt{thresh}$}
%             \State break;
%         \EndIf
%         \State Compute $\bm{s}_k=\alpha_k\bm{p}_k$ and $\bm{y}_k=\bm{g}_{k+1}-\bm{g}_k$; 
%         \State Update a new approximate Hessian by damped BFGS procedure [$\tilde{H}_{k+1}$]=D-BFGS($s_k,y_k,\tilde{H}_k$);
%         \EndFor
%         \State Compute orbital constraint, i.e. $\pdv{\mathcal{L}}{\lambda}$ from Eq. \ref{eqn:L};
%         \If{$\pdv{\mathcal{L}}{\lambda}<10*\texttt{thresh}$}
%             \State break;
%         \EndIf
%         \State Update lagrange multiplier: $\lambda\gets2\lambda$;
%         \EndWhile
%     \EndProcedure
% \Procedure{[$\alpha$]=LS}{$F_0,F_1$}\Comment{Line Search}
%     \State See Ref. \citenum{wright1999numerical} (Algorithm 3.5 in Chapter 3).
% \EndProcedure
% \Procedure{[$\tilde{H}_{k+1}$]=D-BFGS}{$s_k,y_k,\tilde{H}_k$}\Comment{Damped BFGS updating}
%     \State See Ref. \citenum{wright1999numerical} (Procedure 18.2 in Chapter 18).
% %     \State $\epsilon\gets 1$;
    
% %     \State Define a scalar $\theta_k$:
% %     \begin{equation} 
% %     \theta_k=\begin{cases}
% %       1 & \text{if $s_k^Ty_k\geq0.2s_k^T\tilde{H}_ks_k$,}\\     (0.8s_k^T\tilde{H}_ks_k)/(s_k^T\tilde{H}_ks_k-s_k^Ty_k) & \text{if $s_k^Ty_k<0.2s_k^T\tilde{H}_ks_k$;}
% %     \end{cases}
% %     \end{equation}

% %     \State $r_k=\theta_ky_k+(1-\theta_k)\tilde{H}_ks_k$;

% %     \State Update $\tilde{H}_{k+1}$:
% %     \begin{equation}
% %     \label{eqn:bfgs}
% %         \tilde{H}_{k+1}=\tilde{H}_k-\frac{\tilde{H}_ks_ks_k^T\tilde{H}_k}{s_k^T\tilde{H}_ks_k}+\frac{r_kr_k^T}{s_k^Tr_k}.
% %     \end{equation}
%   \EndProcedure
%     \Procedure{[$\bm{c}$]=CASCI22}{$\bm{C},\bm{c}$}\Comment{CAS-CI}
%     \State Diagonalize the 3by3 configuration interaction matrix (using the same convention in Eqs. \ref{eqn:single_excitation},\ref{eqn:spin_adapted_single_excitation} to describe excitation):
%     \begin{equation}
%         E=\bm{c}^\dagger 
%         \begin{bmatrix}
%          \mel{t\bar{t}}{H}{t\bar{t}} & \mel{t\bar{t}}{H}{S_{t\bar{t}}^{u\bar{u}}} & \mel{t\bar{t}}{H}{S_t^u}\\
%          \mel{S_{t\bar{t}}^{u\bar{u}}}{H}{t\bar{t}} & \mel{S_{t\bar{t}}^{u\bar{u}}}{H}{S_{t\bar{t}}^{u\bar{u}}} & \mel{S_{t\bar{t}}^{u\bar{u}}}{H}{S_t^u}\\
%          \mel{S_t^u}{H}{t\bar{t}} & \mel{S_t^u}{H}{S_{t\bar{t}}^{u\bar{u}}} & \mel{S_t^u}{H}{S_t^u}
%         \end{bmatrix}
%         \bm{c}.
%     \end{equation}
%     The matrix elements expressions can be found in Appendix. \ref{subsec:sb coupling}. 
%     \EndProcedure
%     \end{algorithmic}
% \end{algorithm}

% \subsection{Solve Orbitals and \label{subsec:kkt}
% Lagrange Multiplier in One Shot: Newton-KKT Equation}

% Our algorithm is not robust for all geometries, i.e. a single Newton-KKT might not converge at some geometries. In Table \ref{tab:KKT}, we perform a two-step Newton-KKT calculation: 
% \begin{enumerate}
%     \item  Generate self-consistent guess with a penalty objective function:
% \begin{equation}
%     \mathcal{L}=E^{SA-CASSCF(2,2)}+\eta(\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}-1)^2;
% \end{equation}
% \item Solve Eq. \ref{eqn:kkt} (see full details in Appendix \ref{subsec:lssqp}).
% \end{enumerate}


% In Table \ref{tab:KKT}, we show the convergence dependence on the penalty parameter $\eta$. $C_0, E_0$ are the initial orbital constraint condition and the initial total energy calculated by a set of self-consistent guess orbitals with penalty; $C_{opt},E_{opt},\lambda_{opt}$ are the final orbital constraint condition, the final total energy and the final lagrange multiplier after Newton-KKT converges. 
% \begin{table}[H]
% \centering
% \caption{Two-Step$^{*}$ Newton-KKT Convergence Results}
% \begin{tabular}{cccccc}
% \hline
%  $\eta$&$C_0(x)$&$C_{opt}(x)$&$E_0$&$E_{opt}$&$\lambda_{opt}$\\
% \hline
% 1&$-1.2\times 10^{-7}$&$-6.7\times 10^{-16}$ &-1.3548746 &-1.3548746 & $7.4 \times 10^{-7}$\\
% 0.1&$1.3\times 10^{-7}$&$-2.3\times 10^{-14}$& -1.3536738& -1.3536738 & $1.4 \times 10^{-6}$\\
% 0.01&$-5.5\times 10^{-5}$&$-2.2\times 10^{-12}$& -1.3548599& -1.3548599&$7.1 \times 10^{-6}$\\
% $10^{-3}$ & 0.009 & NC$^{**}$ & -1.3548762 & NC & NC\\
% $10^{-4}$ & 0.009 & NC & -1.3548770 & NC & NC\\
% $10^{-5}$ & 0.009 & NC & -1.3548771 & NC & NC\\
% $10^{-6}$ & 1.0 & NC & -1.3548761 & NC & NC\\
% $10^{-7}$ & 1.0 & NC & -1.3548770 & NC & NC\\
% $10^{-8}$ & 1.0 & NC & -1.3548770 & NC & NC\\
% \hline
% \end{tabular}
% \begin{enumerate}\footnotesize
%     \item[*]For better convergence of Newton-KKT scheme, in order to make the starting guess close to the solution, we do one step of orbital optimization with a quadratic penalty with a certain penalty parameter $\eta$;
%     \item[**] NC: not converge
% \end{enumerate}

% \label{tab:KKT}
% \end{table}%

% For those penalty parameters based on which Newton-KKT converges, we plot the total electronic energy as a function of $\eta$ to illustrate $\eta=0.01$ is the best among all because it gives the lowest energy. 
% \begin{figure}[H]
% \centering
% \hspace*{-0mm}\includegraphics[width=\linewidth]{images2/E_vs_eta.eps}
% \caption{Electronic energy as a function of penalty parameter $\eta$. The calculations for different $\eta$s all start from the same finite-temperature Hartree-Fock guess with temperature $T$ set to be 0.01. The parameter set is: two-site model, weighting factor $w=(1,0,0)$ for three cCASSCF states, $\epsilon_d=\epsilon_{d_1}=\epsilon_{d_2}=-0.33, \Gamma=0.01, t_d=0.2, U=0.1$ with 31 metal states evenly distributed with the energy spacing $dE=\frac{\Gamma}{10}$ (i.e. the full band width is $3\Gamma$).} 
% \label{fig:pcfc_zeta}
% \end{figure}

% \subsection{Line Search for Sequential Quadratic Programming (SQP) Algorithm}\label{subsec:lssqp}
% In this subsection, we describe the line search using a linear merit function, following the Chapter 18 in Ref. \cite{wright1999numerical}. We start by defining a linear merit function: 
% \begin{equation}\label{eqn:phi1}
%     \phi_1(x;\mu)=f(x)+\mu\norm{C(x)}
% \end{equation}
% Let $p_k$ and $\lambda_{k+1}$ be generated by the SQP iteration \ref{eqn:kkt}. Then the directional derivative of $\phi_1$ in the direction $p_k$ satisfies:
% \begin{equation}\label{eqn:D1}
%     D_1(\phi_1(x_k;\mu);p_k)=\grad f_k^Tp_k-\mu\norm{C(x_k)}.
% \end{equation}
% We choose the penalty parameter $\mu$ to satisfy:
% \begin{equation}
% \label{eqn:mu}
%     \mu\geq\frac{\grad f_k^Tp_k+(\sigma/2)p_k^T\grad^2_{xx}\mathcal{L}_kp_k}{(1-\rho)\norm{C(x_k)}},
% \end{equation}
% where we set $\rho=0.9$ and define $\sigma$ as:
% \begin{equation}
%     \sigma=
%     \begin{cases}
%             1 & \text{if $p_k^T\grad^2_{xx}\mathcal{L}_kp_k>0$,}\\     0 & \text{otherwise.}
%     \end{cases}
% \end{equation}
% It is easy to verify that, if $\mu$ satisfies Eq. \ref{eqn:mu}, this choice of $\sigma$ ensures that $D_1(\phi_1(x_k;\mu);p_k) \leq -\rho\mu\norm{C(x_k)}$, so that $p_k$ is a descent direction for the merit function $\phi_1$
% \begin{algorithm}[H]
%   \caption{Line Search SQP (LSSQP) Algorithm}
%   \begin{algorithmic}[1]\label{alg:lssqp}
%     \Procedure{LSSQP}{$f,\grad{f},C,x,\mu,\alpha$}\Comment{Line search with constraints $C$}
%       \State $\xi\gets 0.4$ and $\tau\gets 0.5$; 
%       \While{$\norm{\grad{\mathcal{L}}}>$thresh}\Comment{Optimization converges if $\norm{\grad{\mathcal{L}}}<$thresh}
      
%         \State Compute $p_k$ by solving Eq. \ref{eqn:kkt};
%         \State $p_{\lambda}\gets \lambda_{k+1}-\lambda_k$;
        
%         \State Choose $\mu_k$ to satisfy Eq. \ref{eqn:mu};
%         \State $\alpha_k\gets 1$;

%         \State Define the merit function $\phi_1$ by Eq. \ref{eqn:phi1} and its directional derivative $D_1$ by Eq. \ref{eqn:D1}        \While{$\phi_1(x_k+\alpha_kp_k;\mu_k)>\phi_1(x_k;\mu_k)+\xi\alpha_kD_1(\phi(x_k;\mu_k)p_k)$}\Comment{line search}

%         \State $\alpha_k\gets \tau\alpha_k$;
        
%         \EndWhile\label{lswhile}
        
%         \State $x_{k+1}\gets x_k+\alpha_kp_k$ and $\lambda_{k+1}\gets \lambda_k+\alpha_kp_{\lambda}$;

%         \State $s_k\gets \alpha_kp_k$ and $y_k\gets \grad_x{\mathcal{L}}(x_{k+1},\lambda_{k+1})-\grad_x{\mathcal{L}}(x_{k},\lambda_{k+1})$,

%         \State and obtain $\grad^2_{xx}\mathcal{L}_{k+1}$ by damped BFGS procedure;
        
%       \EndWhile\label{lssqpwhile}
%       % \For{\texttt{<some condition>}}
%       %   \State \texttt{<do stuff>}
%       % \EndFor
%       % \State \textbf{return} $b$\Comment{The gcd is b}
%     \EndProcedure

%     \Procedure{D-BFGS}{$s_k,y_k,\tilde{H}_k$}\Comment{Damped BFGS updating}
%     \State $\epsilon\gets 1$;

%     \State If $\tilde{H}_k$ is not positive definite with smallest eigenvalue $e$ (e.g. $e<1\times 10^{-8}$),
%     \begin{equation}
%         \tilde{H}_k=\tilde{H}_k+(\abs{e}+\epsilon)I
%     \end{equation}
    
%     \State Define a scalar $\theta_k$:
%     \begin{equation} 
%     \theta_k=\begin{cases}
%       1 & \text{if $s_k^Ty_k\geq0.2s_k^T\tilde{H}_ks_k$,}\\     (0.8s_k^T\tilde{H}_ks_k)/(s_k^T\tilde{H}_ks_k-s_k^Ty_k) & \text{if $s_k^Ty_k<0.2s_k^T\tilde{H}_ks_k$;}
%     \end{cases}
%     \end{equation}

%     \State $r_k=\theta_ky_k+(1-\theta_k)\tilde{H}_ks_k$;

%     \State Update $\tilde{H}_{k+1}$:
%     \begin{equation}
%     \label{eqn:bfgs}
%         \tilde{H}_{k+1}=\tilde{H}_k-\frac{\tilde{H}_ks_ks_k^T\tilde{H}_k}{s_k^T\tilde{H}_ks_k}+\frac{r_kr_k^T}{s_k^Tr_k}.
%     \end{equation}
%   \EndProcedure
%   \end{algorithmic}
% \end{algorithm}

% The Eq. \ref{eqn:bfgs} is simply the standard BFGS update equation, with $y_k$ replaced by $r_k$. It guarantees that $\tilde{H}_{k+1}$ is positive definite, since it is easy to show that when $\theta_k\neq$ 1 we have
% \begin{equation}
%     s_k^Tr_k=0.2s_k^T\tilde{H}_ks_k>0.
% \end{equation}
% A value $\theta_k \in (0, 1)$ produces a matrix that interpolates the current approximation $\tilde{H}_k$ and the one produced by the unmodified BFGS formula. The choice of $\theta_k$ ensures that the new approximation stays close enough to the current approximation $\tilde{H}_k$ to ensure positive definiteness.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The same is true for Supporting Information, which should use the
%% suppinfo environment.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{suppinfo}

% This will usually read something like: ``Experimental procedures and
% characterization data for all new compounds. The class will
% automatically add a sentence pointing to the information on-line:

% \end{suppinfo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The appropriate \bibliography command should be placed here.
%% Notice that the class file automatically sets \bibliographystyle
%% and also names the section correctly.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{paper2}

\end{document}


%next paper (JCP) figures:

-intro:we talked about this briefly in a letter, now we want to fill in many of the details
-all theory inside (not in supplemental), both pc and fc
-results:
-convergence, exact algorithm, number of steps
-show what happens with different zeta
-pc vs fc for U \ne 0
-evals(molecule projector)
-couplings (form)
-comparison with UHF

discussion: towards an ab initio implementation... 



interfacial electronic structure is hard because of the two aspects:
\begin{enumerate}
    \item Accuracy and generality. 
    \begin{itemize}
        \item The GW approximation \cite{hedin1965new,onida2002electronic}. One can use many-body theory to extract accurate excitation energies for molecules on clusters, but it strongly depends on the initial guess. So it can get attachment/detachment energies but it's hard to assign to a molecule per se; 
        
        \item Embedding methods \cite{kluner2002periodic,lahav2007self}. It combines high-accuracy quantum chemistry methods with DFT and has been applied to estimate PESs of excited molecules on clusters \cite{mehdaoui2007understanding} and surfaces \cite{martirez2017prediction}. It usually looks at local excitation, not charge-transfer excited states. But it's still complicated and demands a lot of computational cost. 
    \end{itemize}

    \item Low computational cost and dynamics-friendly. 
        \begin{itemize}
            \item Constrained DFT. \cite{wu2006extracting,wu2005direct,behler2007nonadiabatic,kaduk2012constrained,meng2022pragmatic} It has been applied in many realistic calculations, e.g. the charge transport\cite{goldey2017charge,ma2020pycdft} and the energy-level alignment near metal surfaces\cite{souza2013constrained}, but it can fail in the case of strong molecule-metal coupling (i.e. strong hybridization) \cite{gavnholt2008delta} and fractional charge transfer \cite{mavros2015communication}.
            
            \item $\Delta$ SCF. It is a powerful tool for the specific case of charge transfer. One runs two calculations, each with different numbers of electrons. It has been implemented to study molecular resonance near metal surfaces\cite{gavnholt2008delta}, but it's not clear how to pick linear-expansion coefficients of Kohn-Sham (KS) orbitals for the charge transfer between a molecule and a metal surface. What's more, it's not clear how to do diabatization based on $\Delta$ SCF, thus one cannot obtain the diabatic coupling. 
    \end{itemize}
    
\end{enumerate}




% next paper: (JCTC) FSSH-ER dynamics of AH model with fitting gradients and derivative couplings (don't need)


%next paper: (JCP/PRB), SF6 molecule structure


%next paper: JCP gradient, derivative coupling for ab initio methods



%next paper, JACS: dynamics with SF6


% next paper: no TB metal, real metal, extract couplings


% review paper


To solve/update the lagrange multiplier $\lambda$, we need the first and the second derivatives of $\mathcal{L}$ with respect to $\lambda$:
\begin{equation}
\label{eqn:dL}
    \dv{\mathcal{L}}{\lambda}=-\{\sum_{\mu\in\textbf{impurity}}\mel{t}{d_\mu^{\dagger}d_\mu}{t}+\mel{u}{d_\mu^{\dagger}d_\mu}{u}-1\}
\end{equation}
\begin{equation}
\begin{aligned}
\label{eqn:d2L}
    \dv[2]{\mathcal{L}}{\lambda}&=-4\sum_{\mu\in\textbf{impurity}}\sum_{i}\frac{|\mel{i}{d_\mu^{\dagger}d_\mu}{t}|^2}{\epsilon_t-\epsilon_i}-\sum_{a}\frac{|\mel{a}{d_\mu^{\dagger}d_\mu}{t}|^2}{\epsilon_t-\epsilon_a}\\
    &-4\sum_{\mu\in\textbf{impurity}}\sum_{i}\frac{|\mel{i}{d_\mu^{\dagger}d_\mu}{u}|^2}{\epsilon_u-\epsilon_i}-\sum_{a}\frac{|\mel{a}{d_\mu^{\dagger}d_\mu}{u}|^2}{\epsilon_u-\epsilon_a},
\end{aligned}
\end{equation}
% where $\{\ket{k}\}$ and $\{\epsilon_k\}$ are eigenvectors and eigenvalues of the working equations \ref{eqn:F}.

Please see below for the detailed derivation for the second derivative based on the first-order perturbation.
According to first-order perturbation theory,
the first-order changes of the two active orbitals $p,q$ with respect to $\lambda$ are:
\begin{align}
    \dv{\ket{t}}{\lambda}&=\sum_{k\neq t}\frac{\mel{k}{V}{t}}{\epsilon_t-\epsilon_k}\ket{k}\\
    &=2\sum_{\mu\in\textbf{impurity}}\sum_i\frac{\mel{i}{d_\mu^{\dagger}d_\mu}{t}}{\epsilon_t-\epsilon_i}\ket{i}-\sum_a\frac{\mel{a}{d_\mu^{\dagger}d_\mu}{t}}{\epsilon_t-\epsilon_a}\ket{a}\\
    \dv{\ket{u}}{\lambda}&=\sum_{k\neq u}\frac{\mel{k}{V}{u}}{\epsilon_u-\epsilon_k}\ket{k}\\
    &=2\sum_{\mu\in\textbf{impurity}}\sum_i\frac{\mel{i}{d_\mu^{\dagger}d_\mu}{u}}{\epsilon_u-\epsilon_i}\ket{i}-\sum_a\frac{\mel{a}{d_\mu^{\dagger}d_\mu}{u}}{\epsilon_u-\epsilon_a}\ket{a}
\end{align}
Therefore, combining with the first derivative of $\mathcal{L}$ with respect to $\lambda$ in Eq. \ref{eqn:dL}, the second derivative of $\mathcal{L}$ with respect to $\lambda$ can be written as:
\begin{equation}
\begin{aligned}
    \dv[2]{\mathcal{L}}{\lambda}&=-\{\sum_{\mu\in\textbf{impurity}}2\mel{\dv{t}{\lambda}}{d_\mu^{\dagger}d_\mu}{t}+2\mel{\dv{u}{\lambda}}{d_\mu^{\dagger}d_\mu}{u}\}\\
    &=-4\sum_{\mu\in\textbf{impurity}}\sum_{i}\frac{|\mel{i}{d_\mu^{\dagger}d_\mu}{t}|^2}{\epsilon_t-\epsilon_i}-\sum_{a}\frac{|\mel{a}{d_\mu^{\dagger}d_\mu}{t}|^2}{\epsilon_t-\epsilon_a}\\
    &-4\sum_{\mu\in\textbf{impurity}}\sum_{i}\frac{|\mel{i}{d_\mu^{\dagger}d_\mu}{u}|^2}{\epsilon_u-\epsilon_i}-\sum_{a}\frac{|\mel{a}{d_\mu^{\dagger}d_\mu}{u}|^2}{\epsilon_u-\epsilon_a}
\end{aligned}
\end{equation}
Note that the first-order perturbation is legitimate only when the absolute magnitude of the matrix elements of the perturbation is small compared with the corresponding differences in the unperturbed energy levels, i.e. $|\mel{k}{\lambda V}{t}| \ll |\epsilon_t-\epsilon_k|$. Note that the second derivative is always nonpositive.



XXX discuss above? nervous? Second, we turn to the more realistic $U=0.1$ case. In Fig. \ref{fig:coupling_U01}(c), the symmetric point for $\tilde{\Gamma}_1$ and $\tilde{\Gamma}_2$ is shifted from $\epsilon_d(x)=0$ (in Fig. \ref{fig:coupling_U01}(a)) to $\epsilon_d(x)=-U/2$. In Fig. \ref{fig:coupling_U01}(c), the $\tilde{\Gamma}_1$ behavior at the symmetric point is more complicated: For $\Gamma=0.01$, $\tilde{\Gamma}_1$ shows a single tip at the symmetric point and has two minima near $\epsilon_d(x)=0$ and $\epsilon_d(x)=-U$ while $\tilde{\Gamma}_2$ has largest coupling at the symmetric point. To further understand the $\tilde{\Gamma}_1$/$\tilde{\Gamma}_2$ behavior, in Fig. \ref{fig:coupling_U01}(d), we plot the heat map for $\Gamma=0.01$, which combines the density of states (DOS) at different $\epsilon_d(x)$. In Fig. \ref{fig:coupling_U01}(d), we can see that DOS is highest at the $S_1$-$S_2$ crossing, leading to the tip for $\tilde{\Gamma}_1$ at the symmetric point (the blue line in Fig. \ref{fig:coupling_U01}(c)), which is the same reason for largest $\tilde{\Gamma}_2$ at the symmetric point (the orange line in Fig. \ref{fig:coupling_U01}(c)); we can also see that DOS is lowest at the $S_0$-$S_1$ crossing, leading to the minima for $\tilde{\Gamma}_1$ near $\epsilon_d(x)=0$ and $\epsilon_d(x)=-U$ (the blue line in Fig. \ref{fig:coupling_U01}(c)). Here, we only showed the $\Gamma=0.01$ case in Fig. \ref{fig:coupling_U01} because our simulation will not hold the wide-band approximation for smaller $\Gamma$ limit so that the shape of the coupling will be not reliable (but the magnitude is still fine as far as for calculating hopping probability when running surface hopping dynamics). 