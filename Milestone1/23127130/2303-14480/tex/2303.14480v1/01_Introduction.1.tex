Taxonomy is formulated as directed acyclic graphs or trees, which consist of \emph{hyponym-hypernym} relations between concepts.
One concept is a hypernym of another concept if the meaning of the former covers the latter\cite{sang2007extracting}.
A well-constructed taxonomy can assist various downstream tasks, including web content tagging \cite{liu2020giant,liu2019tencent_taxonomy,peng2019RCNN4taxonomy}, personalized recommendation \cite{karamanolakis2020txtract, huang2019taxonomy, zhang2014taxonomy}, query understanding  \cite{yang2020co, hua2016understand} and so on. 


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{introduction.png}
    \caption{An example of the new framework of taxonomy expansion task combined with the Taxonomy Entrance Evaluation task}
    \label{fig:introduction}
    \vspace{-5mm}
\end{figure}

Manually constructing and maintaining a taxonomy is labor-intensive, expensive, and time-consuming.
So the task of automated taxonomy expansion is hence proposed \cite{jurgens2016semeval},  which aims to automatically assign an existing concept (anchor concept) as a hypernym concept to the newly input concept (query concept).
The mainstream taxonomy expansion methods tend to use the self-supervised method to generate data from the existing taxonomy \cite{shen2020taxoexpan, yu2020steam, wang2021enquire, zhang2021taxonomy, mao2020octet, ma2021hyperexpan, wang2022qen}.
The accuracy of the automatic-annotated data is highly guaranteed, and the cost of both time and expense is much lower than previous methods.

\red{
However, these traditional taxonomy expansion methods only focus on calculate the similarity between each anchor concept to the query concept\cite{shen2020taxoexpan, yu2020steam, zhang2021taxonomy, wang2021enquire, wang2022qen}, and ignore the problem of whether the query concept should be added to the existing taxonomy at all.
These two tasks sound similar, but we consider they are different.
As we show in Figure \ref{fig:introduction}, when input ``The Eiffel Tower'' and ``Coconut Cake'' to the taxonomy of ``Computer Science'', previous methods will only calculate the similarity between the query concept to each of the anchor concept.
However, the similarity between anchor concept and unknown query concept are greatly determined by the initial representation of the query concept, and learning a good representation for all query concepts may be a huge expense since there are unlimited potential query concepts in real-scenrios.

without specific training, the similarity between unknown query concept and existing anchor concept are random, so even the input query concepts are noisy, the traditional taxonomy expansion model will probabily calculate a high similarity to it.
As in the real scenario, the query concepts are often noisy, as far as we know, none of the previous researches have studied such questions before, most of the researches just build self-supervised datasets which ignore it at all.
The consequence of ignoring such problem will cost another large labor-intensive expense to manually denoise the query concepts before the taxonomy expansion, since the taxonomy expansion model do not have the ability to distinguish the noisy. 

}

In this paper, we propose a new task, called taxonomy enterance evaluation, together with a corresponding method called Generative Adversarial Network for Taxonomy Enterance Evaluation (GANTEE).
Before the taxonomy expansion, we use GANTEE to evaluate whether a query concept should be added to the existing taxonomy.
And then the existing taxonomy evaluation methods are used to assign an anchor concept to the query concept.
The reasons why we introduce GANTEE are listed as follows:
\begin{itemize}
    \item GANTEE will make the model have a strong ability to distinguish the noisy query concepts.
    \item When the number of query concepts is large, the denoise method will best increase the efficiency of the whole process.
\end{itemize}

A pre-trained auto-regressive generative model is used in GANTEE to introduce the outside information to alleviate the above problems.
Beyond that, a pure auto-regressive is mainly used to generate sentence-level text, and the semantic of concept, which is word-level text, is hard to be captured.
So the extra supervised signal is needed to guarantee the generated text is a concept that has a hyponym relation to the given anchor query.

To this end, we use Generative Adversarial Network(GAN) \cite{goodfellow2014generative} to alleviate the above problem.
Specifically, in GAN a discriminative net $\mathcal{D}$ learns to tell the fake data apart from the real data, and the generative net $\mathcal{G}$ learns to confuse $\mathcal{D}$ by generating fake data which has similar distribution with the real data.
We take the generative model as a reinforcement learning agent; the state is the generated tokens combined with the prior information of anchor concepts, and the action is the next token to be generated.
The generated texts are expected to be a fake query concept which is a hyponym to the given anchor concept, but a question proposed by the previous research\cite{guo2018leakgan} that when the discriminator is too strict, the effective gradient won't be calculated, so we use a loose rollout discriminator and a strict hyper discriminator to provide supervised generative signal during the generating process.
Rollout process \cite{yu2017seqgan} is proposed to alleviate the problem of gradient passing back, which is used to guarantee that the generated text is a concept during the generating process.
A hyper discriminator is used to detect whether the generated query concept has a ``hyponym'' relation to the given anchor concept after the generating process.

In the experiments, we benchmark the taxonomy entrance evaluation task on three real-world taxonomies in two different languages, English and Chinese.
We make new State-Of-Art score in the experiments by improve the hit@1 from \red{xxx} to \red{xxx}, MR from \red{xxx} to \red{xxx} and MRR from \red{xxx} to \red{xxx}.
Then we test the efficiency of our method, and GANTEE still outperforms the baselines by a large margin on all three datasets.
Finally, extensive experiments have been conducted to study how the parameters affect the result of GANTEE, and provide an effective tuning scheme for the following researchers who will use our method in the future.

\subsubsection{Contribution.}
To summarize, our major contributions include: 
(1): a more realistic task called taxonomy entrance evaluation which judges whether a query concept should be added to an existing taxonomy or not;
(2): a novel, effective, and PnP method called GANTEE to generate graph-level negative samples which boosts the performance and the efficiency for both traditional taxonomy expansion tasks and taxonomy enterance evaluation tasks.
(3): extensive experiments that verify the effectiveness of GANTEE on three datasets in two languages, and an effective tuning method was proposed by the experiment.


