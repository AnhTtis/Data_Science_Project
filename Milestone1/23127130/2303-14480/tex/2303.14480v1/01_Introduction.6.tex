Taxonomy is formulated as directed acyclic graphs or trees, which consist of hyponym-hypernym relations between concepts.
One concept is a hypernym of another concept if the meaning of the former covers the latter~\cite{sang2007extracting}.
A well-constructed taxonomy assist various downstream tasks, including web content tagging~\cite{liu2020giant,liu2019tencent_taxonomy,peng2019RCNN4taxonomy}, personalized recommendation~\cite{karamanolakis2020txtract, huang2019taxonomy}, query understanding~\cite{yang2020co} and so on. 



Manually maintaining a taxonomy is labor-intensive and time-consuming.
For example, millions of new concepts are expected to be added to the taxonomy of one of the largest shopping platforms in the world each month~\cite{jiang2019towards}.
So the task of automated taxonomy expansion is proposed~\cite{jurgens2016semeval}, which aims to automatically assign an existing concept (anchor concept) as a hypernym concept to the newly input concept (query concept).
These models successfully save much time from labor annotation in taxonomy maintenance.
These methods predict the hypernym-hyponym relationships mainly based on the representation similarity, so they sample the training data based on the existing taxonomy to learn good representations for each concept. 

However, we argue that these methods~\cite{yu2020steam,wang2022qen,cheng2022learning,shen2020taxoexpan,mao2020octet,wang2021enquire,zhang2021taxonomy} have two drawbacks when being applied to real applications. 
\textbf{First}, these methods suffer from low effectiveness in real applications due to limited ability to represent the semantics of concepts. Only sampling from existing taxonomy provides limited data to train representations for zero-shot concepts, where thousands times queries of the number of concepts in existing taxonomy are all unseen to the models~\cite{cheng2022learning}.
\textbf{Second}, these methods suffer from low efficiency in real applications because most of the query concepts are noisy.
For instance, in a leading ordering take-outs online platform, only thousands of concepts out of billions of queries are finally added to their taxonomy~\cite{cheng2022learning}.
Previous methods ignore the noisy concepts and waste much time finding the anchor concept for noisy query concepts.



\begin{figure*}
    \centering
    \resizebox{1\textwidth}{!}{
    \includegraphics{introduction.png}}
    \caption{An example of the GANTEE framework. This framework is implemented as a plugin before taxonomy expansion. The demand for generating high-quality data and taxonomy entering evaluation is formulated as a generative adversarial network in GANTEE.}
    \label{fig:introduction}
    \vspace{-7mm}
\end{figure*}
In this paper, we propose a pluggable framework called \textbf{G}enerative \textbf{A}dversarial \textbf{N}etwork for \textbf{T}axonomy \textbf{E}nterance \textbf{E}valuation (GANTEE) to boost both the effectiveness and efficiency of the taxonomy expansion methods in real-scenarios as is shown in Figure \ref{fig:introduction}.
To improve the effectiveness, GANTEE proposes a generative model to generate more high-quality training data, which are required to train the high-quality representation for taxonomy expansion. 
To improve efficiency, GANTEE introduces a new task called taxonomy entering evaluation, which removes many noisy query concepts before finding the suitable anchor concept for them.
Intuitively, the generative model and the taxonomy entering evaluation model are two adversarial models which can improve each other. The generative model produces fake samples similar to real ones to confuse the discriminative model. 
The taxonomy entering evaluation model learns to generate high-quality samples. Therefore, these two tasks can be formulated as a generative adversarial task~\cite{goodfellow2014generative} to improve their performance further.

Specifically, to improve efficiency, the taxonomy entering evaluation model is expected to be more lightweight than the taxonomy expansion model. 
We introduce two mechanisms to ensure the efficiency of the taxonomy entering evaluation model. 
First, instead of determining where to extend the query concept, GANTEE introduces two more manageable tasks \emph{``isA Concept Access''} and \emph{``isA Query Access''} to determine whether the query concept is a concept and whether the query concept should be added to the taxonomy.
Second, instead of training a new representation for emerging query concepts, we use pre-trained language models (PLMs) to directly obtain a representation of each concept based on the textual features of the concept. 
Although PLMs have limited ability in representing the fine-grained semantics based on conceptual text~\cite{lauscher2019specializing}, the experimental results verify that PLMs are suitable to generate representation in \emph{``isA Concept Access''} and \emph{``isA Query Access''} task.


In the experiments, we benchmark the taxonomy entering evaluation task on three real-world taxonomies in two languages, English and Chinese.
We reached the new SOTA in the experiments by improving all the metrics in only a third of the time of other methods in the prediction stage.
Finally, extensive experiments have been conducted to study how the parameters affect the result of GANTEE, and provide an effective tuning scheme for the following researchers who will use our method in the future.

\subsubsection{Contribution.}
To summarize, our major contributions include: 
(1) We propose a more manageable task called taxonomy entering evaluation which judges whether a query concept should be added to an existing taxonomy efficiently;
(2) We propose a novel, effective method called GANTEE to generate confusing negative and fidelity positive data boosts the performance and efficiency for both traditional taxonomy expansion tasks and taxonomy entering evaluation tasks.
(3) Extensive experiments have been conducted to verify the superiority of GANTEE on three datasets in two languages. We also propose an effective tuning method based on the experiment results.