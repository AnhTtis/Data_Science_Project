% Taxonomy is a particular type of hierarchical knowledge graph that portrays the hypernym-hyponym relations or ``is-A'' relations of various concepts and entities. 
% They have been adopted as the underlying infrastructure of a wide range of online services in various domains, such as product catalogs for e-commerce \cite{luo2020alicoco}, scientific indices like MeSH \cite{lipscomb2000MeSH}, lexical databases like WordNet \cite{miller1995wordnet}, product taxonomies built by Amazon \cite{dong2020autoknow} and universal concept databases Probase \cite{wu2012probase,chen2019cnprobase}. 
% A well-constructed taxonomy can assist various downstream tasks, including web content tagging \cite{liu2020giant,liu2019tencent_taxonomy,peng2019RCNN4taxonomy}, personalized recommendation \cite{karamanolakis2020txtract, huang2019taxonomy, zhang2014taxonomy}, query understanding  \cite{yang2020co, hua2016understand} and so on. 
Taxonomy is formulated as directed acyclic graphs or trees, which consist of \emph{hyponym-hypernym} relations between concepts.
One concept is a hypernym of another concept if the meaning of the former covers the latter\cite{sang2007extracting}.
% Many taxonomies are adopted as the underlying infrastructure of a wide range of online services, such as product catalogs for e-commerce \cite{luo2020alicoco}, scientific indices like MeSH \cite{lipscomb2000MeSH}, lexical databases like WordNet \cite{miller1995wordnet}, product taxonomies built by Amazon \cite{dong2020autoknow} and universal concept databases Probase \cite{wu2012probase,chen2019cnprobase}. 
A well-constructed taxonomy can assist various downstream tasks, including web content tagging \cite{liu2020giant,liu2019tencent_taxonomy,peng2019RCNN4taxonomy}, personalized recommendation \cite{karamanolakis2020txtract, huang2019taxonomy, zhang2014taxonomy}, query understanding  \cite{yang2020co, hua2016understand} and so on. 

% 1. A是啥，很重要。
% 2. expansion是维护A不断增长一种重要方式。
% 3. 然而，他们并没有考虑Taxonomy Entrance Evaluation，会所带来以下三点的后果：1）效果不好。2）开销大。
% 4. 在本文。我们提出一个即插即用的评估组件，off-the-shelf，放在expansion任务之前。输入A和taxonomy，我们首先判断A是否能挂在到taxonomy上，然后执行现有的expansion模型将其挂在到某一节点中。我们之所以引入这个组件的原因有以下2点：1）2）
% 5. To this end, 我们设计了。。。模型来实现这一组件。1）有监督，需要注意两个点：一是否是一个概念，二概念是否合适，这部分设计为。。分类方法。2）由于是有监督方法，需要负样本，伪标签，confuing，因此需要。。生成模型。3）为了将1）和2）joint，我们利用gan。。
% 6. 看实验效果：第一句。将组件加到10个方法中，实现了新sota。分别在数据集A，B提升了多少。并且在效率上加快了多少。并且在哪上线。。API。。

% 1. task新
% 2. 新方法
% 3. 效果好，效率快

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{introduction.png}
    \caption{An example of the new framework of taxonomy expansion task combined with the Taxonomy Entrance Evaluation task}
    \label{fig:introduction}
    \vspace{-5mm}
\end{figure}

Manually constructing and maintaining a taxonomy is labor-intensive, expensive, and time-consuming.
So the task of automated taxonomy expansion is hence proposed \cite{jurgens2016semeval},  which aims to automatically assign an existing concept (anchor concept) as a hypernym concept to the newly input concept (query concept).
The mainstream taxonomy expansion methods tend to use the self-supervised method to generate data from the existing taxonomy \cite{shen2020taxoexpan, yu2020steam, wang2021enquire, zhang2021taxonomy, mao2020octet, ma2021hyperexpan, wang2022qen}.
The accuracy of the automatic-annotated data is highly guaranteed, and the cost of both time and expense is much lower than previous methods.

\red{
However, these traditional taxonomy expansion methods only focus on calculate the similarity between each anchor concept to the query concept\cite{shen2020taxoexpan, yu2020steam, zhang2021taxonomy, wang2021enquire, wang2022qen}, and ignore the problem of whether the query concept should be added to the existing taxonomy at all.
These two tasks sound similar, but we consider they are different.
As we show in Figure \ref{fig:introduction}, when input ``The Eiffel Tower'' and ``Coconut Cake'' to the taxonomy of ``Computer Science'', previous methods will only calculate the similarity between the query concept to each of the anchor concept.
However, the similarity between anchor concept and unknown query concept are greatly determined by the initial representation of the query concept, and learning a good representation for all query concepts may be a huge expense since there are unlimited potential query concepts in real-scenrios.

without specific training, the similarity between unknown query concept and existing anchor concept are random, so even the input query concepts are noisy, the traditional taxonomy expansion model will probabily calculate a high similarity to it.
As in the real scenario, the query concepts are often noisy, as far as we know, none of the previous researches have studied such questions before, most of the researches just build self-supervised datasets which ignore it at all.
The consequence of ignoring such problem will cost another large labor-intensive expense to manually denoise the query concepts before the taxonomy expansion, since the taxonomy expansion model do not have the ability to distinguish the noisy. 
% The consequence of ignoring such problem is listed as follows:
% \begin{itemize}
%     \item The model does a poor job in distinguishing the noisy query concept from the clean query concept since it does train on such task at all.
%     \item When inputting large-scale noisy query concepts, it is still consuming much time to denoising such query concepts on manual work.
% \end{itemize}
}


% In this paper, we propose a new task called taxonomy enterance evaluation, which aims at evaluating whether a query concept should be added to the existing taxonomy or not.
% To solve this question, \red{negative data are needed.}
% The traditional taxonomy expansion method do not 

In this paper, we propose a new task, called taxonomy enterance evaluation, together with a corresponding method called Generative Adversarial Network for Taxonomy Enterance Evaluation (GANTEE).
Before the taxonomy expansion, we use GANTEE to evaluate whether a query concept should be added to the existing taxonomy.
And then the existing taxonomy evaluation methods are used to assign an anchor concept to the query concept.
The reasons why we introduce GANTEE are listed as follows:
\begin{itemize}
    \item GANTEE will make the model have a strong ability to distinguish the noisy query concepts.
    \item When the number of query concepts is large, the denoise method will best increase the efficiency of the whole process.
\end{itemize}

A pre-trained auto-regressive generative model is used in GANTEE to introduce the outside information to alleviate the above problems.
Beyond that, a pure auto-regressive is mainly used to generate sentence-level text, and the semantic of concept, which is word-level text, is hard to be captured.
So the extra supervised signal is needed to guarantee the generated text is a concept that has a hyponym relation to the given anchor query.

To this end, we use Generative Adversarial Network(GAN) \cite{goodfellow2014generative} to alleviate the above problem.
Specifically, in GAN a discriminative net $\mathcal{D}$ learns to tell the fake data apart from the real data, and the generative net $\mathcal{G}$ learns to confuse $\mathcal{D}$ by generating fake data which has similar distribution with the real data.
We take the generative model as a reinforcement learning agent; the state is the generated tokens combined with the prior information of anchor concepts, and the action is the next token to be generated.
The generated texts are expected to be a fake query concept which is a hyponym to the given anchor concept, but a question proposed by the previous research\cite{guo2018leakgan} that when the discriminator is too strict, the effective gradient won't be calculated, so we use a loose rollout discriminator and a strict hyper discriminator to provide supervised generative signal during the generating process.
Rollout process \cite{yu2017seqgan} is proposed to alleviate the problem of gradient passing back, which is used to guarantee that the generated text is a concept during the generating process.
A hyper discriminator is used to detect whether the generated query concept has a ``hyponym'' relation to the given anchor concept after the generating process.

In the experiments, we benchmark the taxonomy entrance evaluation task on three real-world taxonomies in two different languages, English and Chinese.
We make new State-Of-Art score in the experiments by improve the hit@1 from \red{xxx} to \red{xxx}, MR from \red{xxx} to \red{xxx} and MRR from \red{xxx} to \red{xxx}.
Then we test the efficiency of our method, and GANTEE still outperforms the baselines by a large margin on all three datasets.
Finally, extensive experiments have been conducted to study how the parameters affect the result of GANTEE, and provide an effective tuning scheme for the following researchers who will use our method in the future.

\subsubsection{Contribution.}
To summarize, our major contributions include: 
(1): a more realistic task called taxonomy entrance evaluation which judges whether a query concept should be added to an existing taxonomy or not;
(2): a novel, effective, and PnP method called GANTEE to generate graph-level negative samples which boosts the performance and the efficiency for both traditional taxonomy expansion tasks and taxonomy enterance evaluation tasks.
(3): extensive experiments that verify the effectiveness of GANTEE on three datasets in two languages, and an effective tuning method was proposed by the experiment.

% Manually constructing and maintaining a taxonomy is laborious, expensive, and time-consuming. 
% It is also highly inefficient and detrimental for downstream tasks if we construct a taxonomy from scratch \cite{gupta2017taxonomy, velardi2013ontolearn} as long as the taxonomy has new terms to be added. A more realistic strategy is to insert new terms (“query”) into an existing taxonomy, i.e., the seed taxonomy, as a child of an existing node in the taxonomy (“anchor”) without modifying its original structure to best preserve its design. 
% This problem is called taxonomy expansion \cite{jurgens2016semeval}.  


% Early taxonomy expansion approaches use supervised methods that annotate the terms which do not exist in the existing taxonomy to the position it should be added \cite{jurgens2015reserating}.
% Such approaches suffer from the insufficiency of training data and also a huge expanse of human effort.
% Recent studies concentrate on self-supervised method to generate data from the existing taxonomy automatically \cite{shen2020taxoexpan, yu2020steam, wang2021enquire, zhang2021taxonomy, mao2020octet, ma2021hyperexpan, wang2022qen}.
% The accuracy of the automatic-annotated data is highly guaranteed, and the cost of both time and expanse are much lower than previous methods, the most of all, they achieve great success in the experiments.
% Nowadays, such self-supervised methods have thus become the mainstream of the taxonomy expansion task.

% \red{
% However, the existing methods of taxonomy expansion task are mainly focus on how to give the best anchor concept to the query concept,  regardless of whether the query concept should be added into the existing taxonomy.
% In the real-scenario, the query concepts are often noisy, while the previous studies in industry application use rule-based methods to denoise the input data\cite{cheng2022learning}, most of the studies just build self-supervised datasets which ignore such question at all\cite{shen2020taxoexpan, yu2020steam, zhang2021taxonomy, wang2021enquire, wang2022qen}.
% The mainstream methods are lack of the ability to distinguish whether a query concept should be added into the taxonomy because they generate training data from the existing taxonomy only, the noisy data are not included during the training process.
% These sampled data are all node-level samples, which only used to denote whether two nodes have an ``isA'' relation or not.
% More graph-level negative data are needed to train a model which can tell whether a node should be added to the taxonomy or not.
% }

% Generatie Adversarial Network(GAN) \cite{goodfellow2014generative} is a promising framework for alleviating the above problem.
% Specifically, in GAN a discriminative net $\mathcal{D}$ learns to tell the fake data apart from the real data, and the generative net $\mathcal{G}$ learns to confuse $\mathcal{D}$ by generating fake data which has similar distribution with the real data.
% This approach was successful in computer vision tasks, then was transformed into natural language process and also achieved great success \cite{yu2017seqgan, guo2018long, wang2018sentigan, nie2018relgan}.

% Unfortunately, the previous text GANs are better doing sentence generation, while the fake data for taxonomy entrance evaluation are all concepts with fewer words than sentences.
% Since the semantic of a word is harder to be handled by the generative net, so using the existing text GANs do not have a good effect on concept generating.
% So we propose GANTEE (Generative Adversarial Network for Taxonomy Entrance Evaluation).
% GANTEE treat the generative model as an reinforcement learning agent; the state is the generate tokens combine with the prior information of anchor concepts, and the action is the next token to be generated.
% Rollout process \cite{yu2017seqgan} is proposed to alleviate the problem of gradient passing back, we regard that reward of rollout only are not enough for ``isA'' relation generating.
% So we take the rollout process as an short-term reward of the generating process, and propose another discriminator, which we called hyper discriminator, to detect whether the generated texts have a hypernym relation with the input anchor concept as an long-term reward.

% In the experiments, we benchmark the taxonomy entrance evaluation task on three real-world taxonomies in two different langauge, English and Chinese.
% We compare our method with other State-Of-Art methods to prove its effectiveness and efficiency.
% We make new State-Of-Art score by improve the hit@1 from \red{xxx} to \red{xxx}, MR from \red{xxx} to \red{xxx} and MRR from \red{xxx} to \red{xxx}.
% Then we also conduct experiments on traditional taxonomy expansion task, and GANTEE is still outperforms the baselines by a large margin on all three datasets.
% Finally, entensive experiments have been conducted to study how the parameters effect the result of GANTEE, and provide an effective tuning schemes for the following researchers who use our method in the future.

% \subsubsection{Contribution.}
% To summarize, our major contributions include: 
% (1): a more realistic task called taxonomy entrance evaluation which judge whether an query concept should be added into an existing taxonomy or not;
% (2): an novel, effective and PnP method called GANTEE to generating graph-level negative samples which boost the performance and the efficient for both traditional taxonomy expansion task and taxonomy entrance evaluation task.
% (3): extensive experiments that verify the effectiveness of GANTEE on three datasets in two language, and an effective tuning method was propose by the experiment.


