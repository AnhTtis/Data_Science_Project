\begin{table*}[!t]
    \centering
    \resizebox{0.95\textwidth}{!}{
    \begin{tabular}{c|cccc|ccc|ccc}
        \toprule
        \multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c|}{\textbf{MAG-CS (10k-level)}} & \multicolumn{3}{c|}{\textbf{MAG-FoS (100k-level)}} & \multicolumn{3}{c}{\textbf{CN-Probase (1000k-level)}} \\
         & MR & MRR@10 & hit@5 & time & MR & MRR@100 & time & MR & MRR@1k & time \\
        \midrule
% 'MR': 2259.935, 'hit@1': 0.0278, 'hit@3': 0.0232, 'hit@5': 0.0124, 'MRR': 0.13688529366800115
% {'MR': 23193.77, 'hit@1': 0.02, 'hit@3': 0.02, 'hit@5': 0.012, 'MRR': 0.12806979592017617}
% {'MR': 2453.602, 'hit@1': 0.002, 'hit@3': 0.0, 'hit@5': 0.0, 'MRR': 0.0022523345576482764}
% MAG_FoS {'MR': 25765.254901960783, 'hit@1': 0.0, 'hit@3': 0.0, 'hit@5': 0.0, 'MRR': 0.0014624484910608182}
% MAG_FoS {'MR': 25645.110638297872, 'hit@1': 0.0, 'hit@3': 0.012, 'hit@5': 0.023, 'MRR': 0.0015337247888280332}
        Close-Position   & 2.3k & 0.137 & 0.023 & - & 23.2k & 0.128 & - & 157.5k & 0.159 & -  \\
        Close-Neighbor & 1.8k & 0.153 & 0.043  & - & 15.6k & 0.146 & -  & 95.5k & 0.188 & -  \\
        BERT+MLP  & 2.5k & 0.001 & 0.002 & 116.0 s & 25.6k & 0.023 & 5.4k s & 159.1k & 0.143 & 42.5k s  \\
        % Octet & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        % QEN & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        TaxoExpan  & 1.3k & 0.319 & 0.157 & 471.4 s & 3.7k & 0.305 & 25.2k s & - & - & (200k+) s  \\
        % TMN  & - & - & - & - & - & - & - & - & - & - & - & -  \\
        \midrule
        TaxoExpan & 
        \multirow{2}{*}{1.2k} & \multirow{2}{*}{0.360} & \multirow{2}{*}{0.193} & \multirow{2}{*}{152.8 s} &
        \multirow{2}{*}{2.5k} & \multirow{2}{*}{0.382} & \multirow{2}{*}{6.1k s} &
        \multirow{2}{*}{6.6k} & \multirow{2}{*}{0.319} & \multirow{2}{*}{67.4k s}\\ + GANTEE&&&&&&&&&\\
        
        % Octet & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1}\\
        %  + GANTEE&&&&&&&&&\\
        % QEN & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1} & \multirow{2}{*}{1}\\
        %  + GANTEE&&&&&&&&&\\
        
        \bottomrule
    \end{tabular}
    }
    \caption{Overall Performance on Taxonomy Expansion.}
    \vspace{-5mm}
    \label{tab:overall}
\end{table*}

There is an open question that whether the generated positive samples should be treated as positive training samples or negative training samples.
Since the purpose of GAN is to train a generator that output a distribution similar to the real data, if all the data generated by the generator are regarded as negative samples, it will beyond the discriminative ability of the classifier in downstream applications.
In this paper, we treat them as negative training samples in the first epoch of adversarial training and as positive training samples in the subsequent epochs of adversarial training.

\subsection{Experimental Setup}
\subsubsection{Dataset}
We study the performance of GANTEE on three large-scale real-world taxonomies:
\begin{itemize}
    \item \textbf{Microsoft Academic Graph on Field-of-Study (MAG-FoS):} This taxonomy~\cite{sinha2015mag} consists of public Field-of-Study Taxonomy(FoS).
    It contains over 0.6 million scientific concepts and more than 0.7 million taxonomic relations in English.
    \item \textbf{Microsoft Academic Graph on Computer-Science (MAG-CS):} Following the work of TaxoExpan~\cite{shen2020taxoexpan}, we construct MAG-CS based on the sub-graph of MAG-FoS related to the ``Computer Science'' domain.
    \item \textbf{CN-Probase:} This is an open chinese general concept taxonomy CN-Probase~\cite{chen2019cnprobase}.
    It contains over 300 thousand concepts and more than 30 million ``isA'' relations between concepts and entities in Chinese.
\end{itemize}
Notice that there are many outlier concepts in the taxonomy, so we remove all concepts that do not relate to the original taxonomy.
To ensure the validity and test data won't be trained, we randomly mask 20\% of leaf concepts (along with their relations) for validation and testing.
Furthermore, we add noisy query concepts as 60\% size of leaf concepts into the validation and test set to conduct the experiments as in the real-scenarios. 

\subsubsection{Evaluation Metric}
\begin{itemize}
    \item \textbf{Mean Rank (MR)}: measures the average rank position of a query concept’s true parent among all candidates. 
    % For queries with multiple parents, we first calculate the rank position of each parent and then take the average of all rank positions. 
    % A smaller MR value indicates better model performance.
    \item \textbf{Mean Reciprocal Rank@k (MRR@k)}: calculates the reciprocal rank of a query concept’s true parent. We use a scaled version of MRR in the below equation:
    $$MRR=\frac{1}{|C|}\sum_{c\in C}\frac{1}{|parent(c)|}\sum_{i\in parent(c)}\frac{1}{R_{i,c}/k}$$
    where $parent(c)$ represents the parent node set of the query concept $c$, and $R_{i,c}$ is the rank position of query concept c’s true parent $i$. 
    % We scale the original MRR by a factor from 10 to 1000 (1k) to amplify the performance gap between different methods.
    \item \textbf{hit@k}: is the number of query concepts whose parent is ranked in the top k positions, divided by the total number of queries.
    \item \textbf{time}: denotes the seconds used in the predicting stage of each model on each dataset.
\end{itemize}


\subsubsection{Baseline Methods}
We compared our proposed GANTEE model with the following baseline approaches:
\begin{itemize}
    \item \textbf{Closest-Position}: A rule-based method that chooses the anchor concept which have the most similar embedding with query concept as the query concept’s parent.
    % A rule-based method that first scores each candidate position in the existing taxonomy based on its cosine distance to the query concept between their initial embedding and then ranks all positions using this score. 
    \item \textbf{Closest-Neighbor}: Another rule-based method that scores each position based on its distance to the query concept plus the average distance between its children nodes and the query.
    \item \textbf{BERT+MLP}: This method utilizes BERT~\cite{devlin2018bert} to perform hypernym detection.
    This model's input is the term's surface name, and the representation of BERT's classification token $\langle CLS\rangle$ is fed into a feed-forward layer to score whether the first sequence is the ground-truth parent.
    \item \textbf{Random}: This method is used only in the taxonomy entering evaluation task, which is random to determine if the query concept should be added to the existing taxonomy or not.
    \item \textbf{TaxoExpan}~\cite{shen2020taxoexpan}: One state-of-the-art taxonomy expansion framework which leverages position enhanced graph neural network to capture local information and InfoNCE~\cite{oord2018representation} loss for robust training.
    % \item \textbf{GANTEE}: This is our proposed pluggable framework, which is used to exclude the noisy query concepts and generate more high-quality training data for the taxonomy expansion task.
\end{itemize}
Notably, except for the rule-based method Closest-Position and Closest-Neighbor, other baselines are learning-based methods and designed for one-to-one matching.   
There are other recently proposed taxonomy expansion methods, e.g., HiExpan~\cite{shen2018hiexpan} and STEAM~\cite{yu2020steam}. 
We do not include them as baselines because they leverage external sources, e.g., text corpus, to extract complicated features. 
In contrast, TaxoExpan and other baselines only take initial feature vectors as input.

\subsubsection{Parameter Setting}
For learning-based methods, we use SGD optimizer with initial learning rate 0.0001 and ReduceLROnPlateau\footnote{https://pytorch.org/docs/stable/optim.html/\#torch.optim.lr\\\_scheduler.ReduceLROnPlateau} scheduler with ten patience epochs. 
During model training, the batch size and negative sample size are set to 16 and 256 in the overall performance experiments, respectively. 
We set the epochs to be ten and use two layers of Graph Attention Layer with 8 and 1 attention head and 100 dimensions of the position dim.

\begin{figure*}[h]
	\centering
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{MR_pic.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{hit_1_pic.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{hit_3_pic.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{MRR_pic.png}
	\end{minipage}
	\caption{The changing of the results on different metrics with different negative size sampling during the taxonomy expansion model training stage and different number of generated high-quality samples by GANTEE.}
	\label{Fig.detail} 
	\vspace{-3mm}
\end{figure*}

\begin{table}[!t]
    \centering
    \resizebox{0.9\columnwidth}{!}{
    \begin{tabular}{c|cc|cc}
        \toprule
        \multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{MAG-CS}} & \multicolumn{2}{c}{\textbf{CN-Probase-Sampled}} \\
         & Acc & F1 & Acc & F1 \\
        \midrule
        Closest-Position  & 21.5 & 13.9 & 15.4 & 11.5 \\
        Closest-Neighbor  & 28.8 & 17.8 & 19.6 & 13.7 \\
        BERT+MLP  & 57.6 & 46.1 & 52.3 & 43.8 \\
        Random & 74.8 & - & 75.9 & - \\
        TaxoExpan  & 76.4 & 52.7 & 66.8 & 32.1 \\
        % TMN  & - & - & - & - \\
        \midrule
        GANTEE  & \textbf{89.2} & \textbf{79.3} & \textbf{77.5} & \textbf{65.4}\\
        \bottomrule
    \end{tabular}
    }
    \caption{Performance on Taxonomy Entering Evaluation.}
    \label{tab:tee}
\end{table}


\begin{figure*}[h]
	\centering
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.05\linewidth]{MR_line.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.05\linewidth]{hit_1_line.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.05\linewidth]{hit_3_line.png}
	\end{minipage}
	\begin{minipage}[h]{0.23\textwidth}
		\centering
		\includegraphics[width=1.05\linewidth]{MRR_line.png}
	\end{minipage}
	\caption{The changing of the losses and results on different metrics with the adversarial training goes on. In these figures, red lines denote ``loss'', and blue line denotes the metrics, label ``No'' means taxonomy expansion without GANTEE, label ``P'' means the stage of pretraining generative model, and label ``A'' means the adversarial training stage.}
	\label{Fig.stage} 
    \vspace{-5mm}
\end{figure*}

\begin{table}[!t]
    \centering
    
    \resizebox{0.9\columnwidth}{!}{
    \begin{tabular}{c|ccc|cc}
        \toprule
        \textbf{Taxonomy} & \multicolumn{3}{c|}{\textbf{MAG-CS TE}} & \multicolumn{2}{c}{\textbf{MAG-CS TEE}}\\
        \textbf{+ GANTEE} & MR & MRR & hit@5 & Acc & F1 \\
        \midrule
        w/o hd  & 1235 & 0.357 & 0.186 & 78.5 & 62.9\\
        w/o rd  & 1217 & 0.351 & 0.182 & 81.5 & 71.3\\
        w/o $D_\phi$  & 1250.1 & 0.348 & 0.180 & 71.4 & 51.9\\
        - & \textbf{1188.1} & \textbf{0.360}& \textbf{0.193} & \textbf{89.2} & \textbf{79.3} \\
        \bottomrule
    \end{tabular}
    }
    \caption{Ablation study on GANTEE.}
    \label{tab:ablation}
    \vspace{-6mm}
\end{table}
\subsection{Experimental Results}


\subsubsection{Overall Performance on Taxonomy Expansion}
As our proposal is a plugin framework for improving both the effectiveness and efficiency of the taxonomy expansion, we are curious how GANTEE will affect the performance of the previous methods on the taxonomy expansion task. 
Thus, we use GANTEE on the most prevailing State-Of-The-Art (SOTA) method TaxoExpan~\cite{shen2020taxoexpan} on the taxonomy expansion task. 
The results are presented in Table~\ref{tab:overall}. 


Notably, since the time expense of the rule-based method only depends on the computational complexity of the algorithms or matrix operations, it is not recorded, for it can be neglected most of the time in our experiments. 
And the time expense of TaxoExpan on CN-Probase is too large, and we do not finish this experiment in days, so the expected time expense is recorded in the table.

\textbf{Effectiveness Performance:}
From the results, we can see that all of the rule-based methods did a poor job in most metrics, which demonstrates that the semantics of concepts in real-scenarios are complicated, so simple rule-based methods have difficulty performing well in the taxonomy expansion task.
However, BERT+MLP has also done a poor job on most metrics, demonstrating that simply using the representation of PLM is not suitable for taxonomy expansion tasks.
With our GANTEE, TaxoExpan can reach a new SOTA in all three datasets.
Additionally, the larger scale of the taxonomy, the more improvement is made through GANTEE.  

\textbf{Efficiency Performance:}
BERT+MLP method is proven itself to be an efficient method, and we think it is because this method also uses PLMs to fetch the representation of each concept, which is a trade to the final effectiveness of the taxonomy expansion task.
Moreover, when TaxoExpan is implemented after our proposed method, a new SOTA is reached within one-third of the predicting time on three datasets on average.




\subsubsection{Performance on Taxonomy Entering Evaluation}
Table~\ref{tab:tee} presents the results of all compared methods on the three datasets. 
The rule-based methods and BERT+MLP did a poor job on taxonomy entering evaluation task, which is much worse than the Random. 
The TaxoExpan has limited ability to distinguish the noisy query concept, for it outperforms four of the other baseline methods.
GANTEE outperforms all the other methods by a large margin on all datasets in taxonomy entering evaluation task.
Furthermore, since the PLM representation of the English word is better than the Chinese word, it is easier for the discriminator to distinguish the noisy query concepts in English than in Chinese, which makes all the metrics in English higher than in Chinese.



\subsubsection{Ablation Study}



The detail of ablation studies is presented in this subsection. 
We remove three of the essential designs in the GANTEE. 
In ``w/o hd'', we remove the hyper discriminator during the adversarial generating process. 
In ``w/o rd'', we remove the rollout discriminator during the adversarial generating process. 
In ``w/o $D_\phi$'', we remove all the adversarial processes and only use the generator to generate samples. 
The results are shown in Table~\ref{tab:ablation}

We compare the removal of the hyper discriminative model $D_H$ and rollout discriminative model $D_R$ together.
We can see that without the rollout discriminative model, all metrics have a more significant decline than without the hyper discriminative model in the taxonomy expansion task.
However, when the hyper discriminative model is removed, there will be a more significant decline in the metrics in the taxonomy entering evaluation task than removing the rollout discriminative.
We conclude that the rollout discriminative model generates better conceptual texts, and the hyper discriminative is used to strictly denoise all the noisy query concepts.

And without all of the discriminative models, which means only using the generative model to learn from the query conceptual text, a significant decline is witnessed in all metrics. 
We conclude there are two main reasons.
The first reason for this significant decline is because there has no model trained for taxonomy entering evaluation specifically, so the metrics of taxonomy entering evaluation task is decreasing.
The second reason for this significant decline is because there have no supervised signals provided during the generating process, and the GPT-2 is hard to capture the semantic of the hypernym-hyponym relationship in the existing taxonomy, so the result of the taxonomy expansion task is decreasing.


\subsubsection{Analysis of GANTEE}

The Table~\ref{Fig.detail} denotes how different the negative size during training and a different number of the high-quality generated training sampled by GANTEE affect the final result of the taxonomy expansion task.
The upper right corner of the figure is significantly darker than the other areas. 
So we conclude that when generating more high-quality training samples by GANTEE, the taxonomy expansion task will improve performance by using a bigger negative size of the taxonomy expansion in its training stage.

The Table~\ref{Fig.stage} denotes how the final result of the taxonomy expansion task will be affected when the GANTEE stop training in a different training stage.
In these figures, we can intuitively conclude that with the stage of the training going deeper, the performance of the final result will not be better because the line in MRR, hit@1, and hit@3 are not consistently decreasing, and the line in MR is not continuously increasing.
We conclude that when the loss no longer drops dramatically, it is better to stop the training of the GANTEE to receive a better performance in the taxonomy expansion task.
We find out that the goal of the generative model in GANTEE is to confuse the discriminator, and when the distribution of the generated text is close to the distribution of the real conceptual text, the discriminator will not be able to identify the samples effectively. 
And the gradients are not effectively obtained, causing the discriminator to become less and less effective, affecting the quality of the generator and generated training data.


% \begin{table}[!t]
%     \centering
%     \begin{tabular}{c|cccc}
%         \toprule
%         \multirow{3}{*}{Error 1}   
%         & \multicolumn{4}{c}{\textbf{Label:} Positive }\\  
%         & \multicolumn{4}{c}{\textbf{Given Anchor:} mackerel sharks }\\ 
%         & \multicolumn{4}{c}{\textbf{Generated:} mackerel sharks }\\ 
%         Error 3 & N & 46.1 & 52.3 & 43.8 \\
%         \bottomrule
%     \end{tabular}
%     \caption{Performance on Taxonomy Entering Evaluation.}
%     \label{tab:tee}
%     \vspace{-2mm}
% \end{table}


\begin{table}[!t]
    \centering
    \small
    \begin{tabular}{|l|}
        \makecell[|c|]{}\\
        \hline
        \textbf{Samples Generated by GANTEE} \\
        \hline
        \textbf{Given Label} \\
        \textcolor{purple}{Positive} \\
        \textbf{Given Anchor Concept} \\
        \textcolor{brown}{Deep Learning Algorithm}	 \\
        \textbf{Generated Text} \\
        \textcolor{blue}{Deep Q-Learning} \cmark\\
        \hdashline
        \textbf{Given Label} \\
        \textcolor{purple}{Positive} \\
        \textbf{Given Anchor Concept} \\
        \textcolor{brown}{Computer Vision}	 \\
        \textbf{Generated Text} \\
        \textcolor{blue}{Computer Vision Algorithm} \cmark\\
        \hdashline
        \textbf{Given Label} \\
        \textcolor{purple}{Negative} \\
        \textbf{Given Anchor Concept} \\
        \textcolor{brown}{Deep Learning Algorithm}	 \\
        \textbf{Generated Text} \\
        \textcolor{blue}{Deep Graphics Processing Unit} \cmark\\
        \midrule
        \midrule
        \textbf{Given Label} \\
        \textcolor{purple}{Positive} \\
        \textbf{Given Anchor Concept} \\
        \textcolor{brown}{Deep Q-Learning}	 \\
        \textbf{Generated Text} \\
        \textcolor{red}{Deep Algorithm} \xmark\\
        \hdashline
        \textbf{Given Label} \\
        \textcolor{purple}{Positive} \\
        \textbf{Given Anchor Concept} \\
        \textcolor{brown}{Deep Learning}	 \\
        \textbf{Generated Text} \\
        \textcolor{red}{Deep Graphics Processing Unit} \xmark\\
    \hline
    \end{tabular}
    \caption{Case study of the samples generated by GANTEE. 
    Text in purple and brown represents given label and given anchor concept.
    Text in blue and red denotes good cases and bad cases.}
    \label{tab:case}
    \vspace{-7mm}
\end{table}

\subsubsection{Case Analysis}
We present three good cases and two typical bad cases of GANTEE in Tabel \ref{tab:case}

The result shows that GANTEE has the ability in generating a new concept in a domain-specific field.
For example, ``Deep Q-Learning'', ``Computer Vision Algorithm'' and ``Deep Graphics Processing Unit'' are all correct concepts and have true hypernym-hyponym relationships to the given anchor concepts based on the given label. 

However, we find GANTEE has limited ability in generating positive query concepts for too fine-grained or too coarse-grained anchor concepts.
We conclude that GANTEE has difficulty in capturing the semantics of too fine-grained anchor concepts which are seldom seen in the training process of GANTEE ``Deep Q-Learning Algorithm'' to ``Deep Algorithm''.
And GANTEE tends to assign any concept to the too coarse-grained anchor concepts like ``Deep Graphics Processing Unit'' to ``Deep Learning''.

