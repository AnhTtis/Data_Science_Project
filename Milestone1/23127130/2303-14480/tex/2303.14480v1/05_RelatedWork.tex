
\subsection{Taxonomy Construction and Expansion}
The previous methods for taxonomy expansion task can be divided into two categories.
The studies in the first category tend to construct a better model to predict the hypernym-hyponym relationships of the concepts.
Position embedding~\cite{shen2020taxoexpan}, concept sorting mechanism~\cite{song2021should} and multilevel position matching~\cite{wang2022qen} are proposed to better understand the semantics of the query concepts and anchor concepts.
The second category focus on learning good representations for all concepts.
Open source~\cite{yu2020steam}, user-clicked-logs~\cite{cheng2022learning} and parent-child information~\cite{wang2021enquire, wang2022qen} are all used by the previous methods to learn a better representation for concepts.
Besides, there exist many studies that use PLMs during the representation learning stage~\cite{cheng2022learning, wang2022qen, takeoka2021low}, however, these methods only use the PLMs as a external information provider to learn a better representation.

% \subsection{Text GAN}
% The GANs in discrete domains encounter a problem in propagating the gradient into the generator.
% SeqGAN~\cite{yu2017seqgan} has overcome this problem by using a REINFORCE-like~\cite{williams1992simple} algorithm in the training of the generator.
% It assumes the generator as an agent that receives more reward from the discriminator to generate more realistic sentences and uses the Monte Carlo tree search to estimate the expected reward.
% And more improvements have been made these years, in which LeakGAN alleviates the problem of long text generating, RelGAN alleviates the problem of training instability and mode collapse, and FM-GAN alleviates the tradeoff between easy samples or hard samples collecting.

% Furthermore, apart from the RL-based algorithms, very recent works, such as AutoGAN-distiller~\cite{fu2020autogan}, AdversarialNAS~\cite{gao2020adversarialnas}, DEGAS~\cite{doveh2021degas} and alphaGAN~\cite{tian2020alphagan}, employ the gradient-based algorithm to search the GAN architecture. 
% It is noteworthy that gradient-based frameworks could better search generator and discriminator by playing a two-player min-max game at the same time to achieve good results. 
% Kobayashi \emph{et al.}~\cite{shi2022multi} adopted the evolutionary algorithm to search GAN and also achieved better results than the manual design. 


% Aly \emph{et al.}~\cite{aly2019every} adopt hyperbolic embedding to capture hierarchical lexical-semantic relations.
% Fauceglia \emph{et al.}~\cite{fauceglia2019automatic} use a hybrid method to combine linguistic patterns, semantic web, and neural network for taxonomy expansion.
% Manzoor \emph{et al.}~\cite{manzoor2020expanding} model the implicit edge semantics to score the hyponymy relevance between node pairs. 
% However, the above methods fail to exploit the structural information of the existing taxonomy.
% To better maintain the structure of the existing taxonomy, Shen \emph{et al.}~\cite{shen2020taxoexpan} propose position-enhanced graph neural networks to encode the relative position of terms and improve the overall quality of taxonomy.
% Song \emph{et al.}~\cite{song2021should} design a concept sorting model to extract hyponymy relations and sort their insertion order by utilizing the relationship between the newly mined concepts.
% Wang \emph{et al.}~\cite{wang2021enquire} utilize the hierarchical information of the existing taxonomy by extracting tree-exclusive features in the taxonomy for better taxonomy coherence. 
% One limitation of these approaches is that they mainly focus on the general-purpose taxonomies or utilize the general text corpora. Thus, they cannot be easily generalized to specific taxonomies.
% Mao \emph{et al.}~\cite{mao2020octet} leverage heterogeneous sources of signals such as lexical semantics and structural information to train an end-to-end online catalog taxonomy enrichment model.
% The structural information is captured by modeling the structure of the core taxonomy and the query-item-taxonomy interaction in user behavior. However, it has to work with extra item-category information and cannot represent the semantics of new concepts.
% Compared with these methods, our proposed method designs relational and structural representations learned from user-generated content and user click logs to model the semantics of in-domain concepts.

% Study like~\cite{cheng2022learning} have done the candidate query filtering, but their filtering method is mainly based on user generated content.
% In our work, we formulate the task of taxonomy entering, and use generative model to self-supervised generate graph-level negative samples, which boost both the performance of traditional taxonomy expansion and the taxonomy entering.

% \subsection{Text GAN}
% The GANs in discrete domains encounter a problem in propagating the gradient into the generator.
% SeqGAN~\cite{yu2017seqgan} has overcome this problem by using a REINFORCE-like~\cite{williams1992simple} algorithm in the training of the generator.
% It assumes the generator as an agent that receives more reward from the discriminator to generate more realistic sentences and uses the Monte Carlo tree search to estimate the expected reward.
% RankGAN~\cite{juefei2018rankgan} proposes a ranking model to replace the original binary classifier as the discriminator.
% LeakGAN~\cite{guo2018leakgan} designs a mechanism to provide intermediate information about text generation for generator, where the discriminator can leak its features through a manager module.
% MaskGAN~\cite{lee2020maskgan} introduces an actor-critic conditional GAN that fills in missing text conditioned on the surrounding context by resorting to a seq2seq model.
% FM-GAN~\cite{amodio2021fmgan} proposes to match the latent feature distributions of real and synthetic sentences using the feature-movers distance.
% REL-GAN~\cite{nie2018relgan} incorporates a relational memory as a new component for modeling the long-distance dependency.
% Furthermore, its discriminator utilizes multiple representations to preapre a more informative signal for the generator.

% Furthermore, apart from the RL-based algorithms, very recent works, such as AutoGAN-distiller~\cite{fu2020autogan}, AdversarialNAS~\cite{gao2020adversarialnas}, DEGAS~\cite{doveh2021degas} and alphaGAN~\cite{tian2020alphagan}, employ the gradient-based algorithm to search the GAN architecture. 
% It is noteworthy that gradient-based frameworks could better search generator and discriminator by playing a two-player min-max game at the same time to achieve good results. 
% Kobayashi \emph{et al.}~\cite{shi2022multi} adopted the evolutionary algorithm to search GAN and also achieved better results than the manual design. 
% Zhou \emph{et al.}~\cite{zhou2020searching} successfully applied gradient-based GANAS algorithm to the conditional GAN search.

