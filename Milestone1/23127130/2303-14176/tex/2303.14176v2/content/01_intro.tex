\section{Introduction}\label{sec:intro}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imgs/intro_fig_new.pdf}
    \caption{Spiking Neural Networks (SNNs, top) are prone to long transient periods and state decay in the absence of input data, leading to lower accuracy and higher latency and power consumption. In this work (bottom), we solve this with an auxiliary artificial neural network (ANN) that initializes the SNN states at low rates. Our resulting hybrid architecture is simultaneously accurate and maintains the low-power and low-latency aspect of SNNs.  \vspace{-\baselineskip} }
    \label{fig:intro_fig}
\end{figure}

Recent breakthroughs in deep learning have led to accelerating progress on a wide range of computer vision tasks. As this progress speed-ups, practitioners are moving to deeper and deeper models in the pursuit of higher task performance. 
However, this trend comes at a cost: Today's large-scale models require increasing amounts of power, which limits their adoption in power-constrained scenarios. 

Low-power computation is a crucial requirement for applications running on edge devices and can make the difference between changing the battery of IoT devices once a day or once a year or greatly increasing the mission time of autonomous robots with power-constrained hardware. 

Spiking Neural Networks (SNNs) are a novel brain-inspired way to process visual signals, which are orders of magnitude more efficient than their Artificial Neural Network (ANN) counterparts. Instead of processing inputs as synchronous, analog-valued tensor maps, they are dynamical systems that process data as sparse spike trains. Moreover, when deployed on neuromorphic processors, SNNs function asynchronously in an activity-driven fashion, enabling fast inference and low power consumption. 

Although previous work has demonstrated SNN applications on a wide range of tasks, they are still limited in their performance due to two shortcomings: First, they are difficult to train due to the non-differentiability of spikes~\cite{surrogate_gradient} and the vanishing-gradient problem~\cite{spiking_vanishing, pascanu2013difficulty}. Second, they require long time windows to converge and match the accuracy of ANNs~\cite{li2021free, fang2021deep} and are prone to decay in the absence of input data.
This is because SNNs, being temporal models, depend on an expressive state to generate predictions on par with classical ANNs. 
However, this state takes time to converge: Membrane potentials (i.e., states) in the SNN layers need to charge over time, then cross the firing threshold, and finally emit spikes that charge the next layer. In deep SNNs, this charging time generates a long delay, which increases latency and energy consumption due to the need for more iterations.

In this work, we solve this issue by using an auxiliary ANN to initialize the SNN states periodically at low rates, thus eliminating the need for the SNN states to converge. 
We then use the SNN to generate predictions and propagate the state forward until the next initialization step. The resulting predictions (i) have a high rate, (ii) experience a boost in accuracy due to a well-initialized state, and (iii) maintain the low-power property of SNNs. Crucially, the auxiliary ANN only requires little power due to the low rate of state initialization. The resulting hybrid model thus combines the advantages of both ANNs and SNNs. 

We evaluate our method on the tasks of 2D and 3D human pose estimation (HPE) using events from an event camera, where we show consistently that our method reduces the power consumption of standard ANNs by 88\% while only achieving a 4\% error increase. Instead, when compared to SNNs, our method achieves 74\% lower error. 

In summary:
\begin{enumerate}
    \item We propose an energy-efficient, low-latency hybrid ANN-SNN architecture, where the ANN is tasked with initializing the SNN states at low frequency, thus overcoming the limitations of both ANNs and SNNs. 
    \item We show for the task of event-based HPE that this method achieves a balance between being accurate and power efficient. Compared to standard ANNs, it achieves significant improvements in terms of energy consumption and update rate while only experiencing a slight decrease in accuracy. 
    \item The proposed method naturally supports frame-based input, such as RGB images, which further improves the accuracy.
\end{enumerate}

