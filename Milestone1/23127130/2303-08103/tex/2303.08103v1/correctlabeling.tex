%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%


%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{October 10--13,
  2022}{XXX, XXX, XXX}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{diagbox}
\usepackage{float}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Meta contrastive label correction for financial time series}

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers
%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

%
% By default, the full list of authors will be used in the page
% headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows
% the author to define a more concise list
% of authors' names for this purpose.

\author{\bf\normalsize{
Luxuan Yang$^{1}$,
Ting Gao$^{1,}$\footnotemark[1],
Min Dai$^{3}$,
Yubin Lu$^{2}$,
Wei Wei$^{1}$,
Cheng Fang$^{1}$,
Yufu Lan$^{1}$\
and Jinqiao Duan$^{2}$
}\\[10pt]
\footnotesize{$^1$School of Mathematics and Statistics \& Center for Mathematical Sciences,Huazhong University of Science and Technology,} \\
\footnotesize{ Wuhan 430074, China.} \\[5pt]
\footnotesize{$^2$Department of Applied Mathematics, College of Computing, Illinois Institute of Technology, Chicago, IL 60616, USA} \\[5pt]
\footnotesize{$^3$ Wuhan University of Technology,}\\
\footnotesize{ Wuhan 430070, China.} \\[5pt]
}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Financial applications such as stock price forecasting, usually face an issue that under the predefined labeling rules, it is hard to accurately predict the directions of stock movement. This is because traditional ways of labeling, taking Triple Barrier Method, for example, usually gives us inaccurate or even corrupted labels. To address this issue, we focus on two main goals. One is that our proposed method can automatically generate correct labels for noisy time series patterns, while at the same time, the method is capable of boosting classification performance on this new labeled dataset. Based on the aforementioned goals, our approach has the following three novelties: First, we fuse a new contrastive learning algorithm into the meta learning framework to estimate correct labels iteratively when updating the classification model inside. Moreover, we utilize images generated from time series data through Gramian angular field and representative learning. Most important of all, we adopt the multi-task learning to forecast temporal-variant labels. In the experiments, we work on $6\%$ clean data and the rest unlabeled data. It is shown that our method is competitive and outperforms a lot compared with benchmarks.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010405</concept_id>
<concept_desc>Applied computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[500]{Applied computing}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{meta learning, contrastive learning, label corrector, financial time series}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.

\maketitle


\section{Introduction} 
Recent development in Deep learning has enabled promising performance in many different research fields, such as image recognition \cite{imagesurvey,minaee2021image}, natural language processing, bio-physical science and mathematical finance \cite{ozbayoglu2020deep}, etc. In financial engineering, researchers usually adopt supervised or unsupervised methods to extract feature information so as to make predictions about future movements. Thus, Labels, as a crucial indicator for determining the direction of stock movement, play an important guiding role in model optimization. There are a number of traditional methods for labeling, such as triple barrier method, meta labeling, ensemble method and so on \cite{bounid2022advanced}. However, these traditional labeling methods sometimes fail to work (Fig. 1). In this picture, we can see from triple-barrier method, we can sometimes get wrong labels for certain stock trends, like Fig.1(b) and (c). This is because the thresholds of triple barrier need to be specified manually, mainly from personal experience. Moreover, due to the complex uncertainty in financial time series, it is not always reliable to fix the same threshold value for non-stationary time series. To solve these problems, we consider to use meta learning framework for adaptive label corrections. On the one hand, it can dynamically generate labels to the unclean data as time goes on, and on the other hand, it can simultaneously enhance the performance of the basic model.


\begin{figure}
    \centering
    \subfigure[Creating manual labels using triple barrier method.]{\includegraphics[width=\linewidth]{TRIPLEBARRIERMETHOD.jpeg}\label{fig: TRIPLE BARRIER METHOD}}
    \subfigure[The stock goes down but the manual label was up.]{\includegraphics[width=0.45\linewidth]{wronglabel2.jpg}\label{fig: wrong label 2}}
    \subfigure[The stock trend is confused but the manual label is down.]{\includegraphics[width=0.45\linewidth]{wronglabel1.jpg}\label{fig: wrong label 1}}
    \caption{The triple barrier method and the wrong label examples obtained from it. }
    \label{fig:imageexample}
\end{figure}


The next consideration is how to extract as much information as possible from time series data. Due to the limited message flow out of the value of univariate time series, we consider to convert the time series to images for training. This could also help to add more information to the value of the time series so that labels can be generated directly based on the image morphology. By leveraging the information from image data, we can also utilize the intrinsic patterns of time series data more efficiently. One of the most powerful tools is transforming time series to pictures, which includes Gramian Angular Fields (GAFs) \cite{wang2015imaging} and Markov Transition Field (MTF) \cite{campanharo2011duality} (see Figure \ref{fig:imageexample}). GAFs include two method called Gramian Summation Angular Field (GASF) and Gramian Difference Angular Field (GDAF), which represent time series in a polar coordinate system with the cosine and sine functions, respectively. The MTF, on the other hand, is obtained by constructing a Markov variational field based on a 1st-order Markov chain. How to make image based labeling more accurate and the classifier's prediction capacity more precise after enhancing the features is still an open problem.


With the emergence of meta learning, it is possible to change the man-made threshold dynamically. Nowadays, meta learning is mainly classified into optimization-based methods, model-based methods and metric-based methods. For optimization-based methods, the meta learner can be regarded as initial parameters or weights. MAML\cite{finn2017model} and Reptile\cite{nichol2018reptile} are two representative methods for optimizing network initial parameters. They try to make the initial parameters of the model better suited for a variety of tasks. Learning to weight is often applied to label correction. Zheng et al. \cite{zheng2021meta} consider the meta learner as the parameter of a function in the label correction network. Wu et al.\cite{wu2021learning} also aim at label correcting under the framework of meta learning. For the meta learner, they choose the convex combination coefficients of three different labels, which can be treated as the parameters of a neural network. Therefore, this inspires us to correct the generation labels dynamically in a meta-learning framework and achieve joint training. For model-based methods, they adopt the meta learner to directly generate a model. Memory-Augmented neural networks \cite{santoro2016meta} satisfy this condition, which just applies the meta learner to learn proper representation with memory. For metric-based methods, they include various models, such as siamese networks, graph networks, relation networks, etc. Ding et al.\cite{ding2019multi} propose a multi-scale relation network based on meta learning, which can avoid overfitting. Zhu et al.\cite{zhu2022few} combine with meta learning and siamese networks to achieve better performance for classification issues.

In addition to optimization and joint training problems, automatic label generation by the network is also the goal we are pursuing. Inspired by meta learning and siamese networks \cite{zhu2022few}, we apply a contrastive learning framework for label generation. Contrastive learning focuses on learning common features between similar examples and distinguishing differences between non-similar examples. This algorithm usually requires the identification of positive and negative samples, followed by model optimization using a contrastive loss. InfoNCE loss\cite{oord2018representation} and Triplet Loss\cite{schroff2015facenet} are two of the most representative loss functions. InfoNCE loss takes the form of a fraction, where the numerator part represents the similarity between positive cases and the denominator represents the similarity between positive and negative cases. When the denominator is large and the numerator is small, it means that the positive and negative samples are separated. SimCLR \cite{chen2020simple} model just applies InfoNCE loss to optimize the distance of different classes of samples on the hypersphere. Triplet Loss can be divided into three categories: easy triplets, hard triplets, and semi-hard triplets. However, due to the fact that easy triplets naturally hold, there is no need to optimize them. Zeng et al.\cite{zeng2020hierarchical} conduct training with hard-batch triplet loss to realize  unsupervised person reidentification. In line with the goal of traditional clustering methods, the idea of contrastive learning is also to cluster similar samples and separate samples from different classes. Considering that contrastive learning does not prepare all the data in advance for iteration which is different from traditional cluster method, it still achieves better performance. However, the difference is that contrastive learning does not require all data to be prepared in advance for iterative optimization, which makes it easier to analyze actual data, especially financial data.

Considering the respective benefits of meta learning and contrastive learning, our model incorporates them and applies them to financial time series data for the first time. We expect that automatic label generation and classifier performance improvement will be achieved with our learning framework. Therefore, our innovations include the following main points:

$\bullet$ A meta learning framework to adopt both feature and prediction image pattern information for optimizing classification accuracy;

$\bullet$ A regularized contrastive learning controller to generate label automatically as well as enhancing the performance of the classifier;

$\bullet$ A multitask approach to facilitate dynamical labeling over flexible prediction period. 



\section{Related Work} 
The rapid development of deep learning has facilitated practical applications, however, it is very difficult to build predictive models on time series data. Generally, time series is considered to be transformed into image data, and traditional transformation methods include Recurrence Plot \cite{wang2015imaging}, Markov Transition Field \cite{wang2015encoding}, Gramian Angular Field \cite{liu2016encoding}. In recent years, for the processing of image data, researchers have proposed a new U-net method \cite{ronneberger2015u}. U-net draws on the FCN network and also uses feature fusion to obtain more accurate image information.

\subsection*{Meta Label Correction}

Deep learning methods often require data to have certain label information, but in practice, the data may not have labels or noisy labels. To address this problem, researchers have proposed many methods. Zheng et al. \cite{zheng2021meta} proposed the Meta-Label Correction method, which mainly focuses on using inaccurate labels as a form of weak supervision for the learning of noisy labels. Wu et al. \cite{wu2021learning} establish Meta Soft Label Corrector considering data with damaged labels. Algan et al \cite{algan2021meta} propose the Meta Soft Label Generator method by combining meta-learning and deep learning. Subsequently, the Meta-Co-Training net method is proposed for the learning of noise labels \cite{Xia2022MctNetAC}, part of which is used for the training set, and the other part is used as the cooperative training stage of meta, which effectively improved the stability of the results.

\subsection*{Contrastive learning}
In order to learn the common features among similar instances and distinguish the differences between non-similar instances, researchers propose a contrastive learning method \cite{Gutmann2012NoiseContrastiveEO,He2020MomentumCF,oord2018representation}. This method achieves the goal of distinguishing data by learning an encoder that enables similar encoding of the same type of data, and makes the encoding results of different types of data as different as possible. Chen et al. \cite{chen2020simple} propose a contrastive self-supervised learning algorithm, which effectively learned a linear classifier for representation training and obtained visual representations. Khosla et al. \cite{khosla2020supervised} extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing to effectively leverage of label information. Turpault et al. \cite{turpault2019semi} combine unsupervised and supervised triplet loss based learning into a semi-supervised representation learning approach. Hermans et al. \cite{hermans2017defense} show that for models trained from scratch as well as pretrained ones, using a variant of the triplet loss to perform end-to-end deep metric learning outperforms most other published methods by a large margin.




\section{Our Method}
How to automatically label the data based on itself is well worth considering. To address the issue, we propose a new framework combined with meta learning and contrastive learning with multi-task learning in the background, called MCLC(Meta Constrastive Label Correction) learning framework. On account of the aforementioned methods, our methodology can be coarsely categorized into four parts: data processing, label generator, meta learning for label corrector, multi-task learning by the type of stock. 
 
 \subsection{Data Processing}
 In this paper, our goal is to predict the label obtained from Y using data X (Fig. \ref{ts}). The data processing includes three parts: two ways from temporal perspective and one way from the spatio perspective.
 \subsection*{Data Manipulation from temporal Perspective}
By convention, stock price prediction always adopts time series data with straightforward training and manual labeling. However, univariate time series hardly reflect potential commonalities and characteristics among data. Owing to the different purposes of X and Y, we choose two ways to convert time series data to images depending on their usage. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{datasplit.JPG}
  \caption{Two methods for transforming time seires to images through GASF and relative ratio. }{\label{ts}}
\end{figure}

 %\subsection*{Feature $x$ to Image}
First, we transform feature $x$ into images through GASF. Considering that $x$ is used to predict future trends, the images of $x$ need to be more focused on containing more feature information. Therefore, we attempt to convert time series data to image data with a method called Gramian Angular Summation Fields. The whole process of this method consists of four main steps. First, we split the original time series into multiple segments by window sliding. Suppose the original time series is $X=\left\{x_1, \cdots, x_n\right\}$. So it is reconstructed as:

\begin{equation}
\begin{bmatrix}
  x_1&  x_2&  \dots&  x_d& \\
  x_2&  x_3&  \dots&  x_{d+1}& \\ 
  \vdots &  \vdots&  \cdots&  \vdots& \\
  x_{n-(d-1)}&  x_{n-d}&  \dots&  x_n&
\end{bmatrix}
=
\begin{bmatrix}
 z_1\\
 z_2\\
 \vdots \\
z_{n-(d-1)}
\end{bmatrix}.
\end{equation}

Then, we pre-process the subsequences from the original time series to clean up the noise in the data with piecewise aggregate approximation method and map the data to $[0,1]$ with the MinMaxScaler method. Next, the polar coordinates are generated by timestamps and the inverse cosine of the scaling values. We use $x'_i \ (i=k,\dots, k+d-1, k=1,\dots,n)$ to represent the scaling value after completing the above two steps. Therefore, the inverse cosine of it is  $\phi_i=\arccos \left(x'_i\right)$. Finally, according to the Gramian Angular Summation Field (GASF) matrix formula:
\begin{equation}
\begin{aligned}
    \text{GASF} &=\left[\cos \left(\phi_i+\phi_j\right)\right]_{1 \leq i, j \leq n}
    \\&=\left[\cos \left(\phi_i\right) \cdot \cos \left(\phi_j\right)-\sin \left(\phi_i\right) \cdot \sin \left(\phi_j\right)\right]_{n\times n}\\
    &=\tilde{Z} \cdot \tilde{Z}^T-\sqrt{I-\tilde{Z}^2} \cdot \sqrt{I-(\tilde{Z}^{T})^2},
\end{aligned}
\end{equation}
where $\tilde{Z}=\left(\cos \left(\phi_1\right), \cdots, \cos \left(\phi_n\right)\right)^T$, we can get the matrix required to generate the image. We give an example of GASF in Figure \ref{fig:GAFExample}. GASF has many advantages as a method for reconstructing time series. It contains not only the original value information, but also complements the angle information of the time series, which reinforces the time dependence of the data. Moreover, by this method, univariate time series can also have high-level features, thus bridging the gap between time series and more sophisticated computer vision techniques.

\begin{figure}
    \centering
    \subfigure[One of the subseries of CVX stock time series.]{\includegraphics[width=0.48\linewidth]{CVXsubstock.jpg}\label{fig: CVXsubstock}}
    \subfigure[The subseries after scaling.]{\includegraphics[width=0.48\linewidth]{CVXscalerstock.jpg}\label{fig: CVXscalerstock}}

    \subfigure[Polar coordinates]{\includegraphics[width=0.48\linewidth]{CVXPolarstock.jpg}\label{fig: CVXPolarstock}}
    \subfigure[Gramian Angular Summation Field]{\includegraphics[width=0.48\linewidth]{CVXGAFstock.jpg}\label{fig: CVXGAFstock}}
    \caption{An example of a Gramian Angular Summation Fields}
    \label{fig:GAFExample}
\end{figure}

%  \subsection*{Change the window size of $y$ to Image}
Second, we use relative ratio to create black-white pattern pictures of $Y$. Considering that $y$ is used to generate a label based on its own image during the training process, the image of $y$ needs to be more intuitive to grasp its trend. We use the regular method to generate black \&  white pixmaps. Considering each sample in the dataset contains 30+10 close prices $(X,Y)$, and the last 10 close prices ($Y=(y_{0},y_{1},…,y_{9})$) are used to construct profit sequence $\hat{Y}=(\hat{y}_{0},\hat{y}_{1},…,\hat{y}_{9})$.

\begin{equation}
     \hat{y}_i = \frac{y_i}{y_0}-1, (i=0,1,\dots,9),
\end{equation}

Draw a line graph consisting of points $(i,\hat{y}_{i})$ and color the part between the x-axis and the image. The upper/lower borders of the image correspond to +0.15/-0.15 , and the left/right borders correspond to 0/9. Correct the image to a $32 \times 32$ black \& white image, and each pixel takes 0 or 255.\\


\subsection*{Data Manipulation in Space Perspective}
Third, we consider representative learning with spatial features. Considering that U-net can allow the network to capture a lot of spatial information through its unique forward structure and we have converted the time series data into images, we try to use U-net as Encoder to extract spatial features based on temporal information again, so as to achieve the fusion of spatial and temporal information. Hence, the input of our model is derived from the embedding obtained by downsampling of U-net.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{UNET.pdf}
  \caption{The process of embedding the images formed by X and Y with U-net respectively}
\end{figure}

 \subsection{Label Generator}
In our model, we need two neural networks responsible for labeling based on the image information of Y and classifying based on the image information of X, respectively. Hence, in this part, we explain the label generator of our model which updates in the outer loop of meta learning. The label generator inevitably needs to perform clustering. Although traditional clustering methods, such as K-Means, are simple, it is necessary to prepare all the data. However, for financial data, there is a preference to keep the data flowing in real time. Therefore, if each clustering iteration requires all the data, the computation is expensive and time-consuming. Considering that contrastive learning maximizes the similarity of positive pairs and minimizes the similarity of negative pairs for clustering, we make use of it to construct the label generator.


The goal of contrastive learning is to learn a neural network, which encodes data from the same class as similar as possible and  conversely data from different classes as discrepant as possible. Compared with other contrastive learning losses, triplet loss is more detail oriented. At the same time, it can solve the problem that the distance between negative samples and benchmark samples is greater than the distance between positive samples and benchmark samples. Therefore, we adopt it as the composition of our loss. 

Anchor, positive sample, and negative sample are all indispensable elements of triplet loss. In our data, we have a small number of labeled data called clean data $\tilde{\mathscr{D}}_{clean}=\left\{\left(\boldsymbol{{\tilde{X}}}_l, \boldsymbol{\tilde{Y}}_l, \boldsymbol{y}_l\right)\right\}_{l=1}^n$ and a large number of unlabeled data called noisy data $\tilde{\mathscr{D}}_{noise}=\left\{\left(\boldsymbol{\tilde{X}}_u, \boldsymbol{\tilde{Y}}_u\right)\right\}_{u=1}^m$, where $\boldsymbol i \in\{u, l\}$ represents the time frequency. The selection method for clean data can be found in the appendix \ref{clean}$. \boldsymbol{\tilde{X}_i}$ and  $\boldsymbol{\tilde{Y}_i}$ represents $\boldsymbol{X}_i$ and $\boldsymbol{Y}_i$ after data processing respectively. $\boldsymbol{y}_l$ is the label of clean data. Considering the triplet loss needs to determine anchor, positive samples and negative samples, we offer the unsupervised strategy and supervised strategy for unlabeled data $\boldsymbol{\tilde{Y}_u}$ and labeled data $\boldsymbol{\tilde{Y}_l}$, respectively.

$\bullet$ For supervised strategy, due to the fact that $\boldsymbol{\tilde{Y}_l}$ is labelde by $\boldsymbol{y}_l$, we can randomly select one of the data in $\tilde{\mathscr{D}}_{clean}$ as the anchor, and a point with a different label from the anchor is used as a negative sample, and vice versa for positive samples.

$\bullet$ For unsupervised strategy, we take advantage of the labeled nature of clean data in $\tilde{\mathscr{D}}_{clean}$ to assist in the pseudo-labeling of unlabeled data in $\tilde{\mathscr{D}}_{noise}$. We randomly select one of the noisy data as an anchor in $\tilde{\mathscr{D}}_{noise}$ and calculate the distance between it and all the clean data in $\tilde{\mathscr{D}}_{clean}$, and then take the label of the clean data with the smallest distance as the positive label, and take the label of the clean data with the larger distance as the negative label. If the label of the clean data with the largest distance agrees with the label of the clean data with the smallest distance, the label with the second largest distance is chosen as the negative label, and so on. After determining the pseudo label, the construction of triplet can be performed according to the supervised strategy above.

\begin{figure*}[h]
  \centering
   \includegraphics[width=0.78\linewidth]{model.pdf}
  \caption{Our model.}
\end{figure*}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{tripletloss.jpg}
  \caption{The triplet loss effect. Based on this loss, we push the negative label point near the anchor point farther and the positive label point closer.}
\end{figure}

We make use of the triplet $\left(\tilde{\boldsymbol{X}}^a, \tilde{\boldsymbol{X}}^p, \tilde{\boldsymbol{X}}^n\right)$ to represent (anchor, positive, negative) samples and the loss function can be shown as:
$$
Loss^{triplet}=\sum_{X_i \in \tilde{\mathscr{D}}_k}\left[\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^p\right)\right\|_2^2-\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^n\right)\right\|_2^2+\delta\right]_{+}
$$
where []$_{+}$is the hinge loss, $\|\cdot\|_2$ is the $L_2$ norm and $\delta$ is the margin, $\boldsymbol i \in\{u, l\}$, $\boldsymbol k \in\{noise, clean\}$. The whole label generator model includes the Resnet18 neural network $h$ for encoding and MLP network $I$ for labeling. Since triplet loss is prone to overfitting, we add the cross entropy loss between the positive sample and the benchmark sample as the regular term on basis of it. Hence, we give a new triplet loss called triplet regulize loss (TRL) as followed: 
\begin{equation}
\begin{aligned}
    Loss^{TRL} &= Loss^{triplet} + Loss^{regulize}\\
    &= \sum_{X_i \in \tilde{\mathscr{D}}_k}\left[\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^p\right)\right\|_2^2-\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^n\right)\right\|_2^2+\delta\right]_{+}\\
    & -\sum_{\tilde{X}_i \in \tilde{\mathscr{D}}_k} y_i^plog(I(h(\tilde{X}_i^{a}))\\
    &= \sum_{X_i \in \tilde{\mathscr{D}}_k}\left[\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^p\right)\right\|_2^2-\left\|h\left(\tilde{X}_i^a\right)-h\left(\tilde{X}_i^n\right)\right\|_2^2+\delta\right]_{+}\\
    & -\sum_{\tilde{X}_i \in \tilde{\mathscr{D}}_k} y_i^plog(g(\tilde{X}_i^{a})),
\end{aligned}
\end{equation}
where $\hat{y}_i^p$ is the positive pseudo label from the unsupervised strategy and the label generator network is defined as $g = I \circ h$.

 \subsection{Meta Contrastive Label Corrector(MCLC)}
Meta learning, one of the hotter directions, is able to  optimize gradients, loss functions, network structures, etc. Currently, for the labeling problem, gradient optimization is mainly used to achieve labeling correction. Based on the meta-learning framework, Wu et al.\cite{wu2021learning} aimed to implement an automatic scheme for estimating soft labels by meta-gradient descent steps with a small amount of clean data. Moreover, Zheng et al.\cite{zheng2021meta} used noisy label transformation into a weakly supervised form to solve the label correction problem. They regard the meta model and the main model for meta learning as a two-layer optimization problem to  train jointly. In addition to meta learning, contrastive learning is also one of the prominent methods for label correction, which is mostly applied in a self-supervised framework. Li et al.\cite{li2022selective} proposed selective supervised contrast learning with noise labeling. They tried to  select confident pairs from noisy pairs to learn robust latent representations. As a result, inspired by the two main research areas mentioned above, we combine meta learning and contrastive learning. 

\subsection*{The proposed MCLC Method}



The aforementioned methods are based on image data such as CIFAR for supervised research. Considering that financial time series data also have a great demand for labels, we proposed a model for label generation and correction with the framework of meta learning and contrastive learning through a few labeled data, which is called MCLC method. We describe the framework as follows.

Given a set of noisy preprocessed data $\tilde{D}_{noise}=\left\{\left(\boldsymbol{\tilde{X}}_u, \boldsymbol{\tilde{Y}}_u\right)\right\}_{u=1}^{m'}$ with $m'$ smaller than $m$. First, we feed $\boldsymbol{\tilde{Y}}_u$ to meta model to generate the label under unsupervised strategy. With the triplet regulize loss, we can pretrain the label generator in the outer loop and gain the label. Here we define the label generator (meta model) as $g_{\omega}$, where the subscript $\omega$ represents the parameter of the generator and is trained by following formula: 
\begin{equation}
    \omega_{0}-\eta \* \frac{\partial Loss^{ TRL}}{\partial \omega} \rightarrow \omega.
\end{equation}
Then, we feed $\boldsymbol{\tilde{X}}_u$ to the classifier (main model) as $f_{\theta}$, where $\theta$ is the parameter of the classifier in the inner loop. The classifier used for prediction is updated with the help of the label generated by the generators with the cross entropy loss. The loss in the inner loop is shown as follows:
\begin{equation}
\begin{aligned}
    Loss^{main} &= Loss\left(g_\omega\left(\boldsymbol{\tilde{Y}}_u\right), f_\theta\left(\boldsymbol{\tilde{X}}_u\right)\right) \\
    &= \sum_u g_\omega\left(\boldsymbol{\tilde{Y}}_u\right) \log \left( f_\theta\left(\boldsymbol{\tilde{X}}_u\right) \right).
\end{aligned}
\end{equation}
With the $Loss^{main}$, we can update the classifier under the generated label, i.e., by the following formula: 
\begin{equation}
    \theta-\alpha \* \frac{\partial L^{\text {main}}}{\partial \theta} \rightarrow \theta^{*}.
\end{equation}

Note that the classifier uses a pre-trained Resnet18. Then, we regard $\tilde{D}_{clean}=\left\{\left(\boldsymbol{\tilde{X}}_l, \boldsymbol{\tilde{Y}}_l, \boldsymbol{y}_l\right)\right\}_{l=1}^{n}$ as query data to update the main net aiming at correcting the main model through feedback information in the outer loop. The loss of outer loop can be given by:
\begin{equation}
\begin{aligned}
     Loss^{meta} &= Loss\left(f_{\theta^*}\left(\tilde{X}_{l}\right), g_\omega\left(\tilde{Y}_{l}\right), y_{l}\right)\\   
     & =  Loss^{TRL}(g_\omega\left(\tilde{Y}_{l}\right), y_{l}) + Loss^{main}(f_{\theta^*}\left(\tilde{X}_{l}\right), y_{l}).
\end{aligned}
\end{equation}

Hence, in the inner loop, we optimize the main model parameters $\theta$ with given $\omega$. In the outer loop, we optimize the meta learner $\omega$ with given $\theta$. It can be written as:
\begin{equation}
\begin{aligned}
&\omega^*=\underset{\omega}{\operatorname{argmin}}\  L^{meta }\left(\theta^{*}(\omega), \tilde{D}_{clean}\right),\\
\text { s.t. }& \theta^{*}(\omega)=\underset{\theta}{\operatorname{argmin}}\  L^{main}\left(\theta, \omega, \tilde{D}_{noise}\right).
\end{aligned}
\end{equation}

Therefore, the model we proposed can not only automatically label based on the image information from time series, but also to achieve mutual gaming which means that the meta model helps to correct the classifier bias and the classifier feeds information to the meta model through clean data to help update meta learner.

\section{Experiments}

\subsection{Datasets}

% \begin{figure}[h]
%   \centering
%   \includegraphics[width= \linewidth]{selected stock.jpg}
%   \caption{Five selected stock in KDD17.}
% \end{figure}

We retrieve the stock prices from Yahoo! Finance. To be specific, we collect the daily prices of 5 stocks from 2007 to 2017 for the experiments, as shown in Table 1. The length of the historical prices is 2053 days. We take the feature($X$) sequence length as 30 and the prediction($Y$) sequence length as 10 to construct the samples, that is, there are 2014 samples for each stock. We then split the dataset into training set and test set with a ratio of 3:1 approximately (1511 $\times$ 5 train samples and 503$\times$5 test samples).


\begin{table}
  \caption{Dataset satistics}
  \label{tab:dataset}
  \begin{tabular}{cccccl}
    \toprule
    Stock Dataset & BHP  & CVX & PG & RDS-B & XOM \\
    \midrule
    Train & 1511 & 1511 & 1511 & 1511 & 1511\\
    Test & 503 & 503 & 503 & 503 & 503 \\
    \midrule
    Clean & 100  & 100 & 100 & 100 & 100 \\
    Noisy & 1411 & 1411 & 1411 & 1411 & 1411 \\
  \bottomrule
\end{tabular}
\end{table}

\subsection{Comparison with Baseline Method}
In all the experiments, we use Resnet18 as both our classification network and meta network, and we also choose it as the baseline model without meta learning. The difference is that the labels of baseline model are calculated by triple barrier method while in meta learning setting, we only have labels for clean data. 


We will compare the results of our proposed MCLC model with the baseline model in terms of both accuracy and F1-score. All the results are aggregated among all the five stocks. Table \ref{tab:Test sets accuracy on all the Data} shows the accuracy on all the test data including 503$\times$5 test samples, and  Table \ref{tab:Test sets F1-score on all the dataset} presents the results in F1-score. It is shown that our proposed model outperforms the baseline model with 20 percent increment on accuracy and almost around 100 percent increment on F1-score. 


% Considering that there is an imbalance in our model to get the labels, which is caused by the imbalance in the picture data of Y, We tries to perform another evaluation using the F1-score values. From,  the F1-score of our model is still higher than baseline model.

\begin{table}
  \caption{Test sets accuracy on all the Data}
  \label{tab:Test sets accuracy on all the Data}
  \begin{tabular}{c|ccc}
    \toprule
    \diagbox{Model}{Prediction Day} & 10 & 13 & 15\\
    \midrule
    Resnet18 + Manual label & 0.315 & 0.349 & 0.363\\
    Our model & 0.566 & 0.527 & 0.504\\
  \bottomrule
\end{tabular}
\end{table}

\begin{table}
  \caption{Test sets F1-score on all the dataset}
  \label{tab:Test sets F1-score on all the dataset}
  \begin{tabular}{c|ccc}
    \toprule
    \diagbox{Model}{Prediction Day} & 10 & 13 & 15\\
    \midrule
    Resnet18 + Manual label & 0.311 & 0.339 & 0.360\\
    Our model & 0.709 & 0.679 & 0.631\\
  \bottomrule
\end{tabular}
\end{table}

\subsection{Result with Multi-Task}
Since in real life, investors prefer to know the forecast results for multiple days at once and give the best number of days to forecast and take action. We apply a multi-task learning framework on the outside of the model. Based on the predicted days of 10, 13, and 15 days, we created three separate tasks for parallel computation. Table \ref{tab:Evaluation results on different task} shows that the best number of prediction day is ten, which the accuracy achieves $57\%$ and the F1-score reaches $70\%$. This means as prediction days goes longer, both the accuracy and F1-score drops gradually. And this also happens in the similar way when we do the our MCLC without multi-task learning. 

\begin{table}
  \caption{Evaluation results on different task}
  \label{tab:Evaluation results on different task}
  \begin{tabular}{c|ccc}
    \toprule
    \diagbox{Evaluation results}{Prediction Day} & 10 & 13 & 15\\
    \midrule
    accuracy & 0.566 & 0.527 & 0.504\\
    F1-score & 0.709 & 0.679 & 0.631\\
  \bottomrule
\end{tabular}
\end{table}

\subsection{Result on the Embedding of Label Cenerator}
In addition, in the penultimate layer of the label generator network, we verified that triplet regulize loss has the effect of pulling positive samples closer and negative samples further away with test data. Taking the predicted thirteen days as an example, we can see that the embedding vectors of the three categories are largely separated on the test set ( See Figure \ref{embed13}).

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{embedding13.jpg}
  \caption{Test data for predicting 13 days. Green represents up (label=2), blue represents stable (label=1) and red represents down (label=0).}
  \label{embed13}
\end{figure}

% \begin{table}[H]
%   \caption{Results of predicting 10 days}
%   \label{tab:pre10multstock}
 
%   \begin{tabular}{c|cc}
%     \toprule
%     Stock & ACC & F1 score\\
%     \midrule
%     BHP & 0.537 & 0.685\\
%     CVX & 0.542 & 0.695 \\
%     PG & 0.539 & 0.685 \\
%     RDS & 0.578 & 0.727 \\
%     XOM & 0.543 & 0.687 \\
%   \bottomrule
% \end{tabular}
% \end{table}



% \begin{table}[H]
%   \caption{Results of predicting 13 days}
%   \label{tab:pre13multstock}
 
%   \begin{tabular}{c|cc}
%     \toprule
%     Stock & ACC & F1 score\\
%     \midrule
%     BHP & 0.490 & 0.648\\
%     CVX & 0.525 & 0.674 \\
%     PG & 0.582 & 0.719 \\
%     RDS & 0.546 & 0.692 \\
%     XOM & 0.563 & 0.703 \\
%   \bottomrule
% \end{tabular}
% \end{table}




\section{Conclusion}

In this work, we improve the traditional manual labeling such as the triple barrier method and develop an automatic labeling framework based on meta learning and contrastive learning. In contrast to previous time series, we adopt the Gramian Angular Summation
Field and pixel maps to convert the univariate time series to image data, which enhances the feature information. Moreover, we propose the triplet regulize loss function and confirm its validity. Meanwhile, we also verify the accuracy and F1-score of the proposed model on five stocks under the multi-task. The high accuracy and F1-score show that our MCLC method has a much better performance compared with baseline model in financial stock trend prediction. However, some of the artificial hyperparameters in the algorithm need to be accurately selected and have a more scientific basis. The future work will be more theoretical analysis based on bi-level optimization and dive more deep into why this amazing results happens with respect to different weights distribution.





%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%below is template%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%







%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{unsrt}
% \bibliographystyle{ACM-Reference-Format}

\bibliography{samplebase}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Selection of clean data}
\label{clean}

It is a time-consuming task to select clean data from a lot of noisy financial data based on observation. We therefore resort to manual labeling methods to assist us in selecting a small amount of clean data. The manual labeling methods is chosen as triple barrier method. After we get the noisy label, we will obverse the mode of the image data from different classes, separately. Then we use the image obtained by mode to calculate the similarity with the same class. Finally, we select the first one hundred images with the highest similarity as clean data. The details are as follows:
% \textbf{Generate black \& white pixmaps}\\
% Each sample in the dataset contains 30+10 close prices $(X,Y)$, and the last 10 close prices ($Y=(y_{0},y_{1},…,y_{9})$) are used to construct profit sequence $\hat{Y}=(\hat{y}_{0},\hat{y}_{1},…,\hat{y}_{9})$.

% \begin{equation}
%      \hat{y}_i = \frac{y_i}{y_0}-1, (i=0,1,\dots,9),
% \end{equation}

% Draw a line graph consisting of points $(i,\hat{y}_{i})$ and color the part between the x-axis and the image. The upper/lower borders of the image correspond to +0.15/-0.15 , and the left/right borders correspond to 0/9. Correct the image to a $32 \times 32$ black \& white image, and each pixel takes 0 or 255.\\

\textbf{Create manual labels}\\
For all samples in the dataset, we construct the manual labels using the formula below to divide the dataset into three categories.

\begin{equation}
label= \begin{cases}
0,\quad \text{if exist}\quad \hat{y}_i \leq -\mathscr{v}, \\
1,\quad \text{if each}\quad |\hat{y}_i| < \mathscr{v}, \\
2,\quad \text{if exist}\quad \hat{y}_i \geq \mathscr{v},
\end{cases} 
\end{equation}
where $\mathscr{v}$ is the boundary dividing the category, which needs to be given in advance as a hyperparameter.\\
% TRIPLE BARRIER METHOD.jpeg
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{TRIPLE BARRIER METHOD.jpeg}
%   \caption{Creating manual labels using triple barrier method}
% \end{figure}

\textbf{Select clean samples}\\
the black \& white images are calculated pixel-by-pixel to obtain a representative image for each category.

\begin{equation}
pixel(i,j)= \begin{cases}
0,\quad \text{if}\quad f_b(i,j) \geq f_w(i,j), \\
255,\quad \text{if}\quad f_b(i,j) < f_w(i,j), \\
\end{cases} 
\end{equation}
where $pixel  (i,j)$ is value of pixel at $(i,j)$,  $f_b(i,j)$ is the frequency of Event which the $(i,j)$ pixel  of black \& white image is black and  $f_w(i,j)$ is the frequency of Event which the $(i,j)$ pixel  of black \& white image is white.

% 
\begin{figure}[h]
    % \centering
    \subfigure[Category  0]{\includegraphics[width=0.32\linewidth]{modeldown.jpg}\label{fig: representc0}}
    \subfigure[Category 1]{\includegraphics[width=0.32\linewidth]{model0.jpg}\label{fig: representc1}}
    \subfigure[Category   2]{\includegraphics[width=0.32\linewidth]{modelup.jpg}\label{fig: representc2}}
    \caption{The representative image for each category. }
    \label{fig:represent}
\end{figure}

In each category, computing the Euclidean distance between  black\&white image of the sample and the representative image , we select the 100 samples with the smallest distance as clean sample.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.


