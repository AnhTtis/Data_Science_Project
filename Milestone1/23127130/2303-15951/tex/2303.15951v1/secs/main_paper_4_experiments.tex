\section{Experiments}

\input{figures/experiment_trajectory_vis.tex}
\input{figures/compare_free.tex}
% 360
\subsection{Experimental Settings}
{\bf Datasets.} We use three datasets for our evaluation. (1) A new unbounded dataset with free trajectories that we collected (called the {\em Free dataset}). The Free dataset contains seven scenes. Each scene has a narrow and long input camera trajectory and multiple focused foreground objects, which is extremely challenging to build a neural representation for the NVS task. Two of these trajectories are shown in Fig.~\ref{fig:traj}; (2) LLFF dataset~\cite{MildenhallSCKRN19}, which contains eight real unbounded forward-facing scenes with complex geometries; and (3) NeRF-360-V2 dataset~\cite{BarronMVSH22}, which contains seven unbounded 360-degree inward-facing outdoor and indoor scenes. For all the datasets, we follow the commonly-adopted settings that set one of every eight images as testing images and the other as the training set. We use three metrics, PSNR, SSIM, and LPIPS$_{\rm VGG}$, for evaluation.

{\bf Baselines.} We compare \ourmethod with the state-of-the-art fast NeRF training methods, the voxel-based methods (1) DVGO~\cite{SunSC22}, (2) Plenoxels~\cite{YuFTCR22} and the hash-grid based method (3) Instant-NGP~\cite{mueller2022instant}. We also report the results of MLP-based NeRF methods including NeRF++~\cite{ZhangRSK20}, mip-NeRF~\cite{BarronMTHMS21}, and mip-NeRF-360~\cite{BarronMVSH22}.
Note that both \ourmethod and Instant-NGP~\cite{mueller2022instant} are trained for 20k steps with the same batch size but we adopt a LibTorch~\cite{paszke2019pytorch} implementation while Instant-NGP uses a CUDA implementation, which is faster (6min) than ours (13min). All training times are evaluated on a single 2080Ti GPU.
Implementation details of \ourmethod are included in the supplementary material.

{\bf Warping functions.} Different warping functions are adopted for baseline methods on different datasets. On the LLFF dataset, all baselines use the NDC warping function, and on both the Free dataset and the NeRF-360-V2 dataset, all baseline methods use the inverse sphere warping function, except Instant-NGP. In the Instant-NGP, we follow the official implementation to enlarge the ray marching bounding box to represent backgrounds and carefully tune the scale parameters on different scenes to achieve the best performance. In comparison, \ourmethod always uses the perspective warping for all datasets.


\input{tables/compare_free.tex}

\subsection{Comparative studies}
We report the quantitative comparisons on the Free dataset in Table~\ref{tab:compare_free}. \ourmethod achieves the best rendering quality among all the fast-training NeRFs. The results for qualitative comparison are shown in Fig.~\ref{fig:compare_free}. The synthesized images of DVGO~\cite{SunSC22} and Plenoxels~\cite{YuLTLNK2021} are blurred due to their limited resolutions to represent such a long trajectory.
The results of Instant-NGP look sharper but are not clear enough due to its unbalanced scene space organization. In comparison, \ourmethod takes advantage of the perspective warping and the adaptive space subdivision to fully exploit the representation capacity, which enables \ourmethod to produce better rendering quality. Meanwhile, we find that training a mip-NeRF-360 on the Free dataset for a long time is also able to render clear images. The reason is that during the training process, the large MLP networks used by mip-NeRF-360 are able to gradually concentrate on foreground objects and adaptively allocate more capacity to these foreground objects. However, these MLP networks have to spend a long training time for convergence on the Free Trajectory dataset. With a short training time (30 minutes), the results of mip-NeRF-360 contain many foggy artifacts.

We also evaluate our method on the widely-used unbounded forward-facing dataset (LLFF) and 360$^\circ$ object-centric dataset (NeRF-360-V2) to show the compatibility of the perspective warping with these two kinds of specialized camera trajectories. On both datasets, \ourmethod achieves comparable results to the other fast NeRF methods. Note these baseline fast NeRF methods adopt the specially-designed NDC warping or inverse sphere warping for the LLFF dataset or the NeRF-360-V2 dataset while \ourmethod always uses the same perspective warping for all datasets. This demonstrates the compatibility of the perspective warping with different trajectories.


\input{tables/compare_360.tex}
\input{tables/compare_llff.tex}

\subsection{Ablation studies}
We conduct ablation studies on the ``pillar" from the Free dataset. In the ablation studies, we use the multi-resolution hash grid~\cite{mueller2022instant} as the scene representation and change the warping functions and the sampling strategies. 
% implementations of baselines
The warping functions include the inverse sphere warping (Inv. warp), the perspective warping (Pers. warp), and no warping (w/o warp). In the implementation of inverse sphere warping on the Free dataset, we use the bounding sphere of all camera positions as the foreground inner sphere and treat the space outside the sphere as backgrounds. For the point sampling strategies, we consider sampling by disparity (inverse-depth) (Disp. Sampling) used in mip-NeRF-360~\cite{BarronMVSH22}, sampling by the exponential function (Exp. Sampling) used in Instant-NGP~\cite{mueller2022instant}, and our perspective sampling (Sec.~\ref{sec:method_sampling}). 
The quantitative results are shown in Table~\ref{tab:ablation} and some qualitative results are shown in Fig.~\ref{fig:ablation}.

As shown in Table~\ref{tab:ablation}, the basic model (A) without space warping and using disparity sampling performs worst. The model (B) with Inv. warping improves the performances, which shows better compatibility with unbounded scenes compared with no warping (A). The model (C) replaces the disparity sampling with the exponential sampling, which makes the results better. The model (D) uses the proposed perspective warping, whose performance increases drastically compared to the inverse sphere warping. This demonstrates the effectiveness of our perspective warping on free trajectories. The model (E) further applies perspective sampling, which produces the best performance.

\input{figures/experiment_ablation.tex}

\input{tables/ablation.tex}

