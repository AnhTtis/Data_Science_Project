\section{Introduction}
Bayesian Optimization (BO) is a popular technique for optimizing expensive-to-evaluate black-box functions. Such a function might correspond to the case where evaluating it can take up to hours or days, which for example, is the case in re-training massive deep learning models with new hyper-parameters~\cite{wu2019hyperparameter}. In some cases, functions can be financially costly to evaluate, such as drug testing ~\cite{pyzer2018bayesian} or revenue maximization~\cite{phillips2021pricing}. In such black-box optimization problems, one often has a fixed budget on the total number of function evaluations that can be performed. For example, one typically has a budget on the computational capacity spent in the hyper-parameter tuning of neural networks~\cite{pmlr-v28-bergstra13,https://doi.org/10.48550/arxiv.1206.2944}. In such cases, BO proves to be very effective in providing a resource-conserving iterative procedure to query the objective function and identify the global optima~\cite{Perrotolo2018ATF}.

The key idea in BO is to use a surrogate Gaussian Process (GP) model~\cite{Rasmussen2005} for the black-box function, which is updated as and when multiple function evaluations are performed. To identify the location (in the domain) of the following query point, an acquisition function (a function of the surrogate model) is designed and optimized. The design of the acquisition function depends not only on the application in mind but also on the trade-off between exploration and exploitation that comes naturally with such sequential optimization problems. Some popular acquisition functions used in the literature are the Expected Improvement(EI), Probability of Improvement(PI), Knowledge Gradient(KG) and Upper Confidence Bound(UCB) \cite{https://doi.org/10.48550/arxiv.1012.2599,https://doi.org/10.48550/arxiv.1807.02811,Candelieri2021}. 
%Work is also being done to find fast and accurate methods to optimize these functions~\cite{https://doi.org/10.48550/arxiv.2111.04930}.

In this work, we consider Bayesian optimization of composite functions of the form $g(x) = h(f_1(x), f_2(x), \ldots f_M(x))$ where functions $f_i$ are expensive black-box functions while $h$ is known and easy to compute. More specifically, we are interested in maximizing $g$ and identifying its optima. A vanilla BO approach can be applied to this problem, ignoring the composite structure of the function~\cite{Candelieri2021,https://doi.org/10.48550/arxiv.1807.02811}. In this approach, one would build a GP posterior model over the function $g$ based on previous evaluations of $g(x)$ and then select the next query point using a suitable acquisition function computed over the posterior. However, such a vanilla BO approach ignores the available information about the composite nature of the functions, which we show can easily be improved upon. In this work, we model each constituent function $f_i$ using an independent GP model and build an acquisition function that uses the known structure of the composition. Our algorithms easily outperform the vanilla BO method in all the test cases and practical applications we have considered. Our algorithms are also more practical and less computationally intensive than the curent state-of-art  BO algorithm for composite function as proposed in~\cite{https://doi.org/10.48550/arxiv.1906.01537}.

Note that function compositions arise naturally in the real world. One such example is the revenue maximization problem based on the composition of price and demand function. Another example could be the optimization of the F1 score in classification problems that can be seen as a composition of precision and recall metrics~\cite{8647714}. A key novelty of our work lies in the application of our BO algorithms to dynamic pricing problems in revenue management. To the best of our knowledge, ours is the first work to perform dynamic pricing for revenue optimization using Bayesian optimization methods.  
%In optimization functions where the final metric is evaluated using a known composite of it's output, leveraging the composite function is a powerful method to converge to the optimum faster. \textcolor{red}{elaborate}
\subsection{Related Work}
Optimization of function compositions has been studied under various constraints such as convexity, inexpensive evaluations and derivative information ~\cite{barber2016mocca,NIPS2016_645098b0,https://doi.org/10.48550/arxiv.1605.00125,shapiro2003}. The scope of these work are somewhat restrictive and differ from our key assumption that the constituent functions in the composition are black-box functions and are relatively expensive to evaluate. Our work is closely related to Astudillo and Frazier~\cite{https://doi.org/10.48550/arxiv.1906.01537} who optimize black-box function compositions of the form $g(x) = h(f(x))$ using Bayesian Optimization. In this work, the constituent function $f(x)$ is expensive to evaluate and is modelled as a Multi-Ouput Gaussian Process (MOGP). This work was further improved by Maddox et al.~\cite{maddox2021bayesian} using Higher Order Gaussian Process (HOGP). These work assume that the member functions in the composition are correlated and dedicates a significant amount of computational power to capturing these correlations. 
They propose an EI-based acquisition function for estimating the value of $g$ using a MOGP over the functions $f$. The calculation of this acquisition function requires them to compute the inverse of the lower Cholesky factor of the covariance matrix, which is a computationally expensive task (runtime increases with order $\mathcal{O}(N^3)$ where $N$ is the size of the covariance matrix), especially when optimizing high dimensional problems. 

Our work differs from them in that we consider a composition of multiple constituent functions with single output and assume an independent GP model for each such constituent. This results in significantly lesser computational requirements and faster iterations. Our work focuses on practical deployments of the technique, as showcased in Section~\ref{sec:experiments}.  We also propose a UCB-based algorithm where the problem of matrix inversion does not arise. The UCB-based algorithm allows the user to trade-off between exploration and exploitation during iterations, making it more practical for our use cases. Finally, our key contribution lies in applying the proposed methods to dynamic pricing problems, a brief background of which is discussed in the next subsection.

\subsection{Dynamic Pricing and Learning}
Dynamic pricing is a phenomenon where the price for any commodity or good is changed to optimize the revenue collected. Consider the scenario of a retailer with a finite inventory, finite time horizon and a known probabilistic model for the demand. On formulating this as a Markov decision problem, it is easy to see that a revenue optimal pricing policy would be non-stationary, resulting in different optimal prices for the same inventory level at different time horizons. In this case, the dynamic nature of pricing is a by-product of finite inventory and horizon effects. See \cite{phillips2021pricing} for more details.

Now consider a second scenario of a retailer with an infinite horizon and infinite inventory, trying to find the optimal price for his product. Assuming that the underlying probabilistic demand model is unknown to the retailer, this becomes a simultaneous demand learning and price optimization problem. To learn the underlying demand function, the retailer is required to probe or explore the demand for the product at various prices, and use the information gathered to converges to an optimal price over time. Clearly, in this setting, uncertainty in the demand process naturally leads to exploration in the price space, resulting in the dynamic nature of the pricing policy. See \cite{den2015dynamic} for more details. This second scenario (black-box demand function) is of particular interest to us, and we apply our BO algorithms in this setting, something that has not been done before.

Dynamic pricing with learning is a traditional research topic in Operations Research with a long history (see \cite{den2015dynamic2} for a historical perspective). Lobo and Boyd~\cite{e21070651} introduced an exploration-exploitation framework for the demand pricing problem, which balances the need for demand learning with revenue maximization. The problem has been studied under various conditions, such as limited~\cite{10.1145/2559152} and unlimited inventory~\cite{harrison2012bayesian}, customer negotiations~\cite{kuo2011dynamic}, monopoly~\cite{crapis2017monopoly,chen1992dynamic}, limited price queries~\cite{cheung2017dynamic} etc.
One recurrent theme in these work is to assume a parametric form for the demand function in terms of price and other exogenous variables. Reinforcement learning (RL) methods are then used to simultaneously learn the unknown parameters of the demand function and set prices that have low regret.  See, for example,  Broder and Rusmevichientong~\cite{10.2307/23260288} where linear, polynomial and logic demand function models have been assumed. To the best of our understanding, these assumptions on the demand function are rather over-simplified and are typically made for technical convenience. Further, an RL method suited for a particular demand model (say linear demand) may not work when the ground truth model for the demand is different (say, logit model). There have been recent models which try to avoid this issue by modelling the demand as a parameterized random variable (here price is a parameter) but end up making similar convenient  assumptions on the parametric form of the mean or variance of the demand, see \cite{den2014simultaneously} and references therein.

To keep the demand function free from any specific parametric form, in this work, we assume that it is a black-box expensive to evaluate function and instead model it using a Gaussian process. The revenue function can be expressed as a composition of the price and the demand and this allows us to apply our proposed methods (of Bayesian optimization for function composition) to the dynamic pricing and learning problem.

\subsection{Contributions and Organization}
The following are the key contributions of our work:
\begin{enumerate}
    \item We propose novel acquisition functions cEI and cUCB for Bayesian Optimization for function compositions. These acquisition functions are based on EI and UCB acquisition functions for vanilla BO and are less compute intensive and faster to run through each iteration as compared to other state of the art algorithms for function composition.
    \item We assume independent GPs to model the constituent functions and this allows for possible parallelization of the posterior update step.
    \item As a key contribution of this work, we propose to use BO based dynamic pricing algorithms to optimize the revenue. To the best of our knowledge, we are the first, to use BO for learning the optimal price when the demand functions are expensive to evaluate or are black-box in nature.
    \item We consider various revenue maximization scenarios, obtain the revenue function as a composition of price and demand and illustrate the utility of our algorithms in each of these setting.
\end{enumerate}

The following is the organization of the rest of the paper. Section~\ref{sec:problem_description} formally describes the problem statement and Section~\ref{sec:our_approach} describes our proposed algorithms; Section~\ref{sec:experiments} details our experimental results ; and finally, we conclude in Section~\ref{sec:future_works}.