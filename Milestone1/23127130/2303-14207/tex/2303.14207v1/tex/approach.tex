\section{DiffuScene}
\label{SecApp}
%
We introduce DiffuScene a scene graph denoising diffusion probabilistic model aiming at learning the distribution of 3D indoor scenes which includes semantic classes, surface geometries, and placements of multiple objects.
%In this work, we introduce a scene graph denoising diffusion probabilistic model aiming at learning the distribution of 3D indoor scenes which includes semantic classes, surface geometries, and placements of multiple objects.
%
%This section is organized as follows. Sec.~\ref{SubSecSceRepre} describes the scene graph representation. In Sec.~\ref{SubSecSceDiff} scene graph diffusion is explained, details of the architecture of our denoising network are provided and the training objective is defined. Finally, we describe possible modifications for downstream applications of scene completion, scene re-arrangement, and text-conditioned scene synthesis in Sec.~\ref{SubSecApp}.
%

%
%\subsection{3D Scene Graph Representation}
%\label{SubSecSceRepre}
%
Specifically, we assume indoor scenes which are located in a world coordinate system whose origin is at the floor center, and that each scene $\mathcal{S}$ is a composition of at most $N$ objects $\{ \Vec{o} \}_{i=1}^{N}$.
%
We represent such scenes by a fully-connected scene graph with $N$ graph nodes, where each node denotes an object.% and each object is densely connected with other objects.
%
%
%Let $C$ be the number of semantic categories and $F$ be the number of object feature channels.
%
Each graph node (\ie object) is defined by its class semantics $\Vec{c} \in \mathbb{R}^C$, axis-aligned 3D bounding box size $\Vec{s}\in \mathbb{R}^3$, location $\Vec{\ell}\in \mathbb{R}^3$, rotation angle around the vertical axis $\Vec{\theta}\in \mathbb{R}$, and shape code $\Vec{f}\in \mathbb{R}^F$ extracted from object surfaces in the canonicalization system through a pre-trained shape auto-encoder~\cite{yang2018foldingnet}.
%
Since the number of objects varies across different scenes, we define an additional `empty' object and pad it into scenes to have a fixed number of objects across scenes.
%
%Concretely, we denote the semantic label as an additional class category `empty', representing the existence of an object and we assign zero vectors to other properties of empty objects.
%
As proposed in~\cite{yin2021center}, we represent the object rotation angle by parametrizing a 2-d vector of cosine and sine values.
%
In summary, each object $\Vec{o}_i$ is characterized by the concatenation of all attributes,~\ie $\Vec{o}_i = [ \Vec{\ell}_i , \Vec{s}_i , \cos\Vec{\theta}_i  , \sin\Vec{\theta}_i , \Vec{c}_i , \Vec{f}_i ] \in \mathbb{R}^D$, where $D$ is the dimension of concatenated attributes.
%
%$\Vec{o}_i = \Vec{\ell}_i \oplus \Vec{s}_i  \oplus \cos\Vec{\theta}_i  \oplus \sin\Vec{\theta}_i \oplus \Vec{c}_i \oplus \Vec{f}_i \in \mathbb{R}^D$
%

Based on this graph representation, we define our denoising diffusion probabilistic model (Sec.~\ref{SubSecSceDiff}), and propose different downstream applications like scene completion, scene re-arrangement, and text-conditioned scene synthesis in Sec.~\ref{SubSecApp}.



\subsection{3D Scene Graph Diffusion}
\label{SubSecSceDiff}
In Fig.~\ref{fig:pipeline} we shown an overview of our approach.
%
%Following recent success in denoising diffusion-based generative models~\cite{ho2020denoising, meng2021sdedit}, 
We design a scene graph denoising probabilistic diffusion model where a series of Gaussian noise corruptions and removals on graph nodes perform the transitions between the noisy and the clean scene graph distributions.
%\cite{ho2020denoising, meng2021sdedit, avrahami2022blended, kim2022diffusionclip, avrahami2022blended, saharia2022image,ho2022cascaded, dhariwal2021diffusion, rombach2022high,lugmayr2022repaint}

\paragraph{Diffusion process.} 
The (forward) diffusion process is a pre-defined discrete-time Markov chain in the data space $\mathcal{X}$ spanning all possible scene graphs represented as 2D tensors of fixed size $\Vec{x} \in \mathbb{R}^{N \times D}$, which are the concatenations of $N$ object properties $\{ \Vec{o}_i \}_{i=1}^{N}$ within a scene $\mathcal{S}$.
%
Given a clean scene graph $\Vec{x}_0$ from the underlying distribution  $q(\Vec{x}_0)$, we gradually add Guassian noise to $\Vec{x}_0$, obtaining a series of intermediate scene graph variables $\Vec{x}_1, ..., \Vec{x}_T$ with the same dimensionality as $\Vec{x}_0$, according to a pre-defined, linearly increased noise variance schedule $\beta_1, ..., \beta_T$ (where $\beta_1 < ... < \beta_T$).
%
The joint distribution $q (\Vec{x}_{1:T} | \Vec{x}_{0} )$ of the diffusion process can be expressed as:
\begin{equation}
    \label{Equadiffusion}
    q (\Vec{x}_{1:T} | \Vec{x}_{0} ) :=  \prod_{t=1}^{T} q(\Vec{x}_{t} | \Vec{x}_{t-1}) ,
\end{equation}
where the diffusion step at time $t$ is defined as:
\begin{equation}
    \label{Equadiffusion_each}
    q (\Vec{x}_{t} | \Vec{x}_{t-1} ) :=  \mathcal{N}(\Vec{x}_{t}; \sqrt{ 1-\beta_{t} } \Vec{x}_{t-1}, \beta_{t} \Vec{I} ) .
\end{equation}
A helpful property of diffusion processes is that we can directly sample $\Vec{x}_t$ from $\Vec{x}_0$ via the conditional distribution:
\begin{equation}
    \label{Equadiffusion_02t}
    q( \Vec{x}_{t} | \Vec{x}_{0} ) :=  \mathcal{N}( \Vec{x}_{t}; \sqrt{\bar{\alpha_t}}\Vec{x}_{0}, (1-\bar{\alpha_{t}}) \Vec{I} ) ,
\end{equation}
where $\Vec{x}_t = \sqrt{\bar{\alpha}_t} \Vec{x}_0 + \sqrt{1-\bar{\alpha}_t} \Vec{\epsilon}$ where $\alpha_t := 1 - \beta_t$  , $\bar{\alpha}_t := \prod_{r=1}^{t} \alpha_s$, and $\Vec{\epsilon}$ is the noise used to corrupt $\Vec{x}_t$. 
%
%
\begin{figure}
    \centering
    \includegraphics[width=.5\textwidth]{./figs/denoising_network.pdf}
    \caption{The denoising network architecture takes the graph nodes attributes (bounding box, object class, geometry code) as input and denoises them based on MLPs with skip connections and attention blocks.}
    \label{fig:denoise_net}
\end{figure}




\paragraph{Generative process.}
%
The generative (\ie denoising) process is parameterized as a Markov chain of learnable reverse Gaussian transitions.
%
Given a noisy scene graph from a standard multivariate Gaussian distribution $\Vec{x}_T\sim\mathcal{N}(\mathbf{0}, \Vec{I})$ as the initial state, it corrects $\Vec{x}_{t}$ to obtain a cleaner version $\Vec{x}_{t-1}$ at each time step by using a learned Gaussian transition $p_\Vec{\phi} (\Vec{x}_{t-1} | \Vec{x}_{t} )$ which is parameterized by a learnable network $\Vec{\phi}$.
%
By repeating this reverse process until the maximum number of steps $T$, we can reach the final state $\Vec{x}_0$, the clean scene graph we aim to obtain.
%
Specifically, the joint distribution of the generative process $p_\Vec{\phi} (\Vec{x}_{0:T} )$ is formulated as:
\begin{equation}
    \label{Equadenoise}
    p_\Vec{\phi} (\Vec{x}_{0:T} ) :=  p(\Vec{X}_T) \prod_{t=1}^{T} p_\Vec{\phi}( \Vec{x}_{t-1} | \Vec{x}_{t} )
\end{equation}
% $p_\Vec{\phi} (\Vec{x}_{t-1} | \Vec{x}_{t} )$ 
%
\begin{equation}
    \label{Equadenoise_each}
    p_\Vec{\phi} (\Vec{x}_{t-1} | \Vec{x}_{t} ) :=  \mathcal{N}(\Vec{x}_{t-1}; \Vec{\mu}_{\Vec{\phi}}(\Vec{x}_{t}, t), \Vec{\Sigma}_{\Vec{\phi}}(\Vec{x}_{t}, t) , ) ,
\end{equation}
where $\Vec{\mu_{\phi}}(\Vec{x}_{t})$ and $\Vec{\Sigma}_\Vec{\phi}(\Vec{x}_{t})$ are the predicted mean and covariance, respectively, of the Gaussian $\Vec{x}_{t-1}$ by feeding $\Vec{x}_{t}$ into the denoising network $\Vec{\phi}$.
%
For simplicity, we take pre-defined constants for $\Sigma_{\Vec{\phi}}(\Vec{x}_{t}) := \sigma_t := \frac{1-\bar{\alpha}_{t-1}}{ 1-\bar{\alpha}_t } \beta_t$, although Song et al. has shown that learnable covariances can increase generation quality in DDIM~\cite{song2020improved}.
%
Ho et al. empirically found in DDPM~\cite{ho2020denoising} that rather than directly predicting $\Vec{\mu}_{\Vec{\phi}}(\Vec{x}_{t}, t)$, we can synthesize more high-frequent details by estimating the noise $\Vec{\epsilon}_{\Vec{\phi}}(\Vec{x}_{t}, t)$ applied to perturb $\Vec{x}_{t}$.
%
Then $\Vec{\mu}_{\Vec{\phi}}(\Vec{x}_{t})$ can be re-parametrized by subtracting the predicted noise according to Bayes's theorem:
%
\begin{equation}
    \label{Equareparam}
    \Vec{\mu}_{\Vec\phi}(\Vec{x}_{t}, t) :=  \frac{1}{\sqrt{\alpha_{t}}} (\Vec{x}_{t} - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \Vec{\epsilon}_{\Vec{\phi}}(\Vec{x}_{t}, t))
\end{equation}
%


\paragraph{Denoising network.}
%
As shown in Fig.~\ref{fig:denoise_net}, the denoiser in our method is based on MLPs with skip connections, where MLP blocks are interleaved with attention blocks~\cite{vaswani2017attention} to aggregate the features of different objects, capturing the global context of a scene.
%
As MLPs are shared with each object, it would be difficult for the denoising network to distinguish different objects without position information.
%
To this end, we also use the positional embeddings of instance IDs and inject them into the network to guide the denoising process.
%


\paragraph{Training objective.}
%
The goal of training the reverse diffusion process is to find optimal denoising network parameters $\Vec{\phi}$ that can generate natural and plausible scenes.
%
Our training objective is composed of two parts:
i) A loss $L_{\text{sce}}$ to constrain that the generated scene graphs can approximate the underlying data distribution, 
and ii) a regularization term $L_{\text{iou}}$ to penalize the object intersections.
%
The $L_{\text{sce}}$ is derived by maximizing the negative log-likelihood of the last denoised scene $\mathbb{E}[ -\log p_{\Vec{\phi}}(\Vec{x}_0) ]$, which is yet not intractable to optimize directly.
%
Thus, we can instead choose to maximize its variational upper bound:
%
\begin{equation}
    \label{equaNLL}
     L_{\text{sce}} :=  \mathbb{E}_q [ -\log \frac{p_{\phi}(\Vec{x}_{0:T})} {q(\Vec{x}_{1:T}|\Vec{x}_0)} ] \ge \mathbb{E}[ -\log p_{\Vec{\phi}}(\Vec{x}_0) ] .
\end{equation}
%Kullbackâ€“Leibler (KL)
%$L_{\text{sce}}^t$
By surrogating variables, we can further simplify $L_{\text{sce}}$ as the sum of KL divergence between posterior $p_{\Vec{\phi}} (\Vec{x}_{t-1}  | \Vec{x}_{t}, \Vec{x}_{0})$ and conditional distribution $q(\Vec{x}_{t} | \Vec{x}_{t-1})$ at each $t$ :
\begin{equation}
    \label{equaDecompose}
    \begin{aligned}
        L_{\text{sce}} 
        %:= \mathbb{E}_q [ -\log p(\Vec{x}_T) - \sum_{t=1}^{T} L_{\text{sce}}^t ]\quad \quad \quad \quad \quad \quad  \\ 
        :=  \mathbb{E}_q [ -\log p(\Vec{x}_T) - \sum_{t=1}^{T} \log \frac{ p_{\Vec{\phi}} (\Vec{x}_{t-1} | \Vec{x}_{t}, \Vec{x}_{0}) } {q(\Vec{x}_{t} | \Vec{x}_{t-1})} ] ,
    \end{aligned}
\end{equation}
where $-\log p(\Vec{x}_T)$ is a fixed constant since $\Vec{x}_T \sim \mathcal{N}(0, \Vec{I})$.
%
Here, we refer the reader to DDPM~\cite{ho2020denoising} for the details of the derivation process.
%
Moreover, we can re-write $L_{\text{sce}}$ into a simple and intuitive version that constrains the correct prediction of the corrupted noise on $\Vec{x}_t$:
%
\begin{equation}
    \label{equaNoisypred}
    \begin{aligned}
    L_{\text{sce}} := \mathbb{E}_{\Vec{x}_0, \Vec{\epsilon}, t} [ \| \Vec{\epsilon} - \Vec{\epsilon}_{\Vec{\phi}} (\Vec{x}_t, t) \|^2 ] \quad \quad \quad \quad \quad \quad \\
    := \mathbb{E}_{\Vec{\phi}} [\| \Vec{\epsilon} - \Vec{\epsilon}_{\Vec{\phi}} ( \sqrt{\bar{\alpha}_t} \Vec{x}_0 +  \sqrt{1-\bar{\alpha}_t} \Vec{\epsilon}, t) \|^2] .
    \end{aligned}
\end{equation}
%
Based on Eq.~\ref{Equareparam}, we can obtain the approximation of clean scene graph $\tilde{\Vec{x}}_0^t$.
%
Thus, we can compute $L_{\text{iou}}$ as the IoU summation of arbitrary two bounding boxes:
\begin{equation}
    \label{equaIoU}
    L_{\text{iou}} :=  \sum_{t=1}^{T} \omega_t * \sum_{\Vec{o}_i, \Vec{o}_j \in \tilde{\Vec{x}}_0^t} \IoU(\Vec{o}_i, \Vec{o}_j) ,
\end{equation}
where the hyperparamter $\omega_t$ is set to $\bar{\alpha}_t * 0.1$.
%
%\paragraph{Sampling.} In the inference phase, we adopt the ancestral sampling strategy to progressively decorrupt the 3D scene graph via $\Vec{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} (\Vec{x}_t-\frac{1-\alpha_t} {\sqrt{1-\bar{{\alpha}_t}}} \Vec{\epsilon}(\Vec{x}_t, t) ) + \sqrt{\beta_t} \Vec{z}$ where $\Vec{z} \sim \mathcal{N}(0, \Vec{I})$ until the final state $\Vec{x}_{0}$.
%

\subsection{Applications}
\label{SubSecApp}
Based on the formulation of scene graph denoising diffusion probabilistic models in Sec.~\ref{SubSecSceDiff}, we can further develop the model to support various downstream tasks with few modifications as shown in Fig.~\ref{fig:teaser}. 
%

\paragraph{Scene completion.}
%
Assuming a partial scene containing $M \le N$ objects as $\Vec{y}_0 \in \mathbb{R}^{M \times D}$, we can utilize the learned scene priors from diffusion models to complement novel graph nodes $\hat{\Vec{x}}_0)$ into $\Vec{y}_0$ to obtain a complete graph  $\Vec{x}_0 = (\Vec{y}_0, \hat{\Vec{x}}_0)$.
Similar to image in-painting~\cite{ lugmayr2022repaint, rombach2022high} and shape completion~\cite{luo2021diffusion,zhou20213d,zeng2022lion,hui2022neural,zhang20233dshape2vecset}, the completion denoising process is almost same as the unconditional scene generation, except that we keep the already known graph nodes in the forward Guassian transitions $q$, and only hallucinate the missing ones through learnable reverse Guassian transitions $q_\Vec{\phi}$.
%
Concretely, the intermediate scene graphs during the diffusion process can be revised as $\Vec{x}_t = (\Vec{y}_t, \hat{\Vec{x}}_t)$, where the partial scene graph $\Vec{y}_t$ at time step $t$ is obtained by the forward diffusions.
%
The completed scene graph $\hat{\Vec{x}}_t$ is generated by the denoising process:
\begin{equation}
    \begin{aligned}
    \label{EquanCompletion}
    q(\Vec{y}_t | \Vec{y}_{t-1}) := \mathcal{N}(\Vec{y}_t; \sqrt{\bar{\alpha}_t}\Vec{y_0}, (1-\bar{\alpha}_t\Vec{I})), \\ 
    p_{\Vec{\phi}}( \hat{\Vec{x}}_{t-1} | \hat{\Vec{x}}_t  ) := \mathcal{N}(\mu_{\Vec{\phi}}(\Vec{x}_t, t), \sigma_t^2\Vec{I}) . \quad \quad \quad 
    \end{aligned}
\end{equation}
%

\paragraph{Scene re-arrangement.}
Given a collection of objects with their surface geometries and semantics, we can leverage priors of the scene graph diffusion generative model to determine reasonable object placements by estimating their locations and orientations.
%
Let us denote the noisy scene graph initialization as $\hat{\Vec{x}}_0 = [\hat{\Vec{u}}_0, \Vec{v}]$, where $\hat{\Vec{u}}_0 = \{  [\Vec{l}_i, \cos\theta_i, \sin\theta_i] \}_{i=1}^N$ is the concatenation of $N$ objects' locations and orientations, and $\Vec{v} = \{ [\Vec{s}_i, \Vec{c}_i, \Vec{f}] \}_{i=1}^N$ is the concatenation of $N$ objects' sizes, category classes, and shape codes.
%
The intermediate scenes during the arrangement diffusion process can be expressed as:
\begin{equation}
    \begin{aligned}
    \label{EquanRearrange}
    %q(\Vec{v}_t | \Vec{v}_{t-1}) := \mathcal{N}(\Vec{v}_t; \sqrt{\bar{\alpha}_t}\Vec{v_0}, (1-\bar{\alpha}_t\Vec{I})), \\ 
    p_{\Vec{\phi}}( \hat{\Vec{u}}_{t-1} | \hat{\Vec{u}}_t ) := \mathcal{N}(\mu_{\Vec{\phi}}(\hat{\Vec{u}}_t , t, \Vec{v}), \sigma_t^2\Vec{I}) , \quad \quad \quad
    \end{aligned}
\end{equation}
where we iteratively update the object locations and orientations $\Vec{u}_t$ via $p_\Vec{\phi}$ conditioned on $\Vec{v}$.
%
\paragraph{Text-conditioned scene synthesis.}
Given a list of sentences describing the desired object classes and inter-object spatial relationship as conditional inputs, we can employ a pre-trained BERT encoder~\cite{devlin2018bert} to extract word embeddings $\Vec{z} \in \mathbb{R}^{48 \times 768}$, then we utilize cross attention layers to inject the language guidance into the denoising network that predicts out noise via $\Vec{\epsilon}_\Vec{\phi}(\Vec{x}_t, t, \Vec{z})$, as depicted in Fig.~\ref{fig:denoise_net}.
