\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{makecell}
\usepackage[table]{xcolor}  
\usepackage{animate}

\usepackage{enumitem}

\makeatletter
\@namedef{ver@everyshi.sty}{}
\makeatother
\usepackage{tikz}
%\usepackage{tkz-euclide}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\PAR}[1]{\vskip4pt \noindent{\bf #1~}}
\newcommand*{\TODO}[1]{\textcolor{red}{[#1]}}
\newcommand*{\TS}[1]{\textcolor{blue}{TS: [#1]}}


\newcommand{\C}{{\mathbb C}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\M}[1]{\mathtt{#1}}
\newcommand{\V}[1]{\mathbf{#1}}
\newcommand{\diag}{\textrm{diag}}
\newcommand{\vnorm}[1]{\left|\left|#1\right|\right|}


\def\sft{{\texttt{5pt+P3P}}\xspace}
\def\sftl{{\texttt{4p3v(L)}}\xspace}
\def\sftm{{\texttt{4p3v(M)}}\xspace}
\def\sfto{{\texttt{4p3v(O)}}\xspace}
\def\step{{\texttt{3pt+ep}}\xspace}
\def\sfhc{{\texttt{4p3v(HC)}}\xspace}
\def\sfep{{\texttt{4p3v(N)}}\xspace}
\def\sfepo{{\texttt{4p3v(NO)}}\xspace}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3516} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\newcommand{\ch}{\textcolor{orange}}

%teaser-tikz
\tikzstyle{bedge}=[line width=1pt,cyan]
\tikzstyle{bsvertex}=[circle, draw=black, fill=cyan, inner sep=0pt, minimum size=2.5pt]
\tikzstyle{rsvertex}=[circle, draw=black, fill=red, inner sep=0pt, minimum size=2.5pt]
\newcommand{\iccv}{
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.66\columnwidth]{figures/rotunda2.PNG}};
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
    
        \node[rsvertex] (10) at (0.205, 0.274) {};
        \node[rsvertex] (10) at (0.406, 0.194) {};
        
        \draw[bedge] (0.24, 0.71) -- (0.155, 0.235);
        \draw[bedge] (0.35, 0.56) -- (0.155, 0.235);
        \draw[bedge] (0.66, 0.55) -- (0.155, 0.235);
        \draw[bedge] (0.57, 0.31) -- (0.155, 0.235);
        \draw[bedge] (0.24, 0.71) -- (0.395, 0.155);
        \draw[bedge] (0.35, 0.56) -- (0.395, 0.155);
        \draw[bedge] (0.66, 0.55) -- (0.395, 0.155);
        \draw[bedge] (0.57, 0.31) -- (0.395, 0.155);
        \draw[bedge] (0.24, 0.71) -- (0.848, 0.14);
        \draw[bedge] (0.35, 0.56) -- (0.848, 0.14);
        \draw[bedge] (0.66, 0.55) -- (0.848, 0.14);
        \draw[bedge] (0.57, 0.31) -- (0.848, 0.14);

        \node[bsvertex] (0) at (0.168, 0.31) {};
        \node[bsvertex] (1) at (0.188, 0.29) {};
        \node[bsvertex] (2) at (0.225, 0.279) {};
        \node[bsvertex] (3) at (0.225, 0.247) {};

        \node[bsvertex] (4) at (0.374, 0.228) {};
        \node[bsvertex] (5) at (0.389, 0.207) {};
        \node[bsvertex] (5) at (0.423, 0.197) {};
        \node[bsvertex] (6) at (0.42, 0.176) {};

        \node[bsvertex] (7) at (0.792, 0.174) {};
        \node[bsvertex] (8) at (0.765, 0.21) {};
        \node[bsvertex] (9) at (0.758, 0.225) {};
        \node[bsvertex] (10) at (0.816, 0.21) {};

        

        \draw[->, red, thick, dashed] plot [smooth, tension=1] coordinates {(0.155, 0.21) (0.25, 0.09) (0.395, 0.11)};
        \node at (0.23, 0.05) {$\texttt{\scriptsize 5pt}$};

        \draw[->, orange, thick, dashed] plot [smooth, tension=1] coordinates {(0.87, 0.16) (0.92, 0.4) (0.68, 0.55)};
        \node at (0.97, 0.25) {$\texttt{\scriptsize P3P}$};
        %\clip (0.5,0.5) circle (1cm);
    \end{scope}
\end{tikzpicture}

}




\begin{document}

%%%%%%%%% TITLE
\title{
%Using virtual correspondences in minimal solvers with applications to the four-points-in-three-views problem / 
Efficient solutions to the relative pose of three calibrated cameras from four points using virtual correspondences}

\author{Charalambos Tzamos$^\textrm{1}$ \quad
Daniel Barath$^\textrm{2}$ \quad
Torsten Sattler$^\textrm{3}$ \quad
Zuzana Kukelova$^\textrm{1}$\vspace{10pt}\\
$^\textrm{1}$Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague\\
{\tt\small tzamos.charalampos@fel.cvut.cz, kukelova@cmp.felk.cvut.cz} \\
$^\textrm{2}$ETH ZÃ¼rich, Computer Vision and Geometry Group, Switzerland\\
{\tt\small danielbela.barath@inf.ethz.ch} \\
$^\textrm{3}$Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague\\
{\tt\small torsten.sattler@cvut.cz}
}


%\author{First Author\\
%Institution1\\
%Institution1 address\\
%{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
%}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
We study the challenging problem of estimating the relative pose of three calibrated cameras. We propose two novel solutions to the notoriously difficult configuration of four points in three views, known as the 4p3v problem. Our solutions are based on the simple idea of generating one additional virtual point correspondence in two views by using the information from the locations of the four input correspondences in the three views. For the first solver, we train a network to predict this point correspondence. The second solver uses a much simpler and more efficient strategy based on the mean points of three corresponding input points. The new solvers are efficient and easy to implement since they are based on the existing efficient minimal solvers, i.e., the well-known 5-point relative pose and the P3P solvers. The solvers achieve state-of-the-art results on real data. 
The idea of solving minimal problems using virtual correspondences is general and can be applied to other problems, e.g., the 5-point relative pose problem. In this way, minimal problems can be solved using  simpler non-minimal solvers or even using sub-minimal samples inside RANSAC.

In addition, we compare different variants of 4p3v solvers with the baseline solver for the minimal configuration consisting of three triplets of points and two points visible in two views. We discuss which configuration of points is potentially the most practical in real applications. 

\end{abstract}




%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}


%Estimating the camera geometry, \ie, the pose and calibration parameters, 
Camera geometry estimation 
is a crucial tasks in computer vision with many applications, \eg, in structure-from-motion (SfM)~\cite{Snavely-IJCV-2008}, visual navigation~\cite{DBLP:journals/ram/ScaramuzzaF11}, augmented and mixed reality~\cite{Castle08ISWC}, self-driving cars~\cite{hane20173d}, large-scale 3D reconstruction~\cite{DBLP:conf/cvpr/HeinlySDF15}, and 
%image based 
visual localization~\cite{Sattler16PAMI}.

% Due to the presence of noise and outliers in input data, \ie input correspondences, the predominant way in camera geometry estimation is to use a hypothesis-and-test framework, such as RANSAC~\cite{Fischler-Bolles-ACM-1981,Chum-2003, DBLP:journals/pami/RaguramCPMF13, GC-RANSAC}.
% In RANSAC-like methods, two different solvers are used:
% (1) one for fitting a model to a minimal sample and (2) one for fitting a model (in general, to a non-minimal sample)
% when doing model polishing on all inliers or in the local optimization step. 
% For (1), the
% main objective is to solve the problem using as few correspondences as possible since the %run-time
% number of RANSAC iterations (run-time)
% depends exponentially on the number of correspondences required for the model estimation. 

Due to
noise and outliers 
in the input correspondences, 
the predominant way in camera geometry estimation is to use a hypothesis-and-test framework, \eg,  RANSAC~\cite{Fischler-Bolles-ACM-1981,Chum-2003, DBLP:journals/pami/RaguramCPMF13, barath2017graph}.
 For RANSAC-like methods, it is crucial to solve the camera geometry problems using as few correspondences as possible since the
 number of RANSAC iterations (and, thus, its run-time)
 depends exponentially on the number of correspondences required for the model estimation.

 \begin{figure}[t]
     \centering
     %\includegraphics[width=0.9\columnwidth]{figures/teaser-4pt-3.png}
     \iccv
     \caption{Visualization of the studied 4p3v problem and our solution that is based on generating one new virtual correspondence (in red) between two views. This is done using coordinates of four triplets of point correspondences. Using the virtual correspondence, the 4p3v problem is solved by existing efficient minimal solvers, \ie, the 5pt relative pose solver~\cite{Nister-5pt-PAMI-2004} and the P3P solver~\cite{lambda-twist}.}
     \label{fig:teaser}
 \end{figure}

%Minimal solvers are usually applied in the model estimating step of RANSAC-like methods.
%
%For example, the  estimation of the relative pose of two calibrated cameras has five degrees-of-freedom (DoF); three for the unknown rotation and two for the translation that can be estimated only up to scale. Since each point correspondence provides one equation in the form of the epipolar constraint, the minimum number of point correspondences required to solve this problem is five. The minimal solver that solves this problem is known as the  5-pt relative pose solver, for which an efficient implementation was proposed by Nister~\cite{Nister-5pt-PAMI-2004}, and which is widely used in many applications, \eg \TODO{in the state-of-the-art SALM systems like ORB-SLAM~\cite{tod}, structure-from-motion systems like Colmap~\cite{TODO} and....TODO}.
%
%
%
%and automatic generators of such solvers~\cite{Kukelova-ECCV-2008,larsson2017efficient}, 
%Efficient minimal solvers exist to many different camera geometry problems, 
%camera geometry 
%known vertical direction~\cite{...}, 
%rolling shutter~\cite{albl2016rolling}, 
%
%For some problems, \eg, the problem of estimating the relative pose of two calibrated cameras~\cite{Nister-5pt-PAMI-2004},  a model that precisely describes the camera geometry can be efficiently estimated from the minimal number of correspondences.
%On the other hand, some problems, like the problem of estimating the geometry of rolling shutter  cameras
%or the problem of estimating the relative pose of three calibrated cameras, 
%result in equations, for which state-of-the-art methods fail to generate a solver that is efficient and/or numerically stable.
%, like the problem of estimating the geometry of rolling shutter  cameras, however,
%or the problem of estimating the relative pose of three calibrated cameras, 

Algorithms that solve camera geometry estimation problems
using all available constraints (equations) and the minimum number of correspondences, such that the resulting system of equations has a finite number of solutions, are called \emph{minimal solvers}, and the corresponding problems are called \emph{minimal problems}. 
Minimal problems often result in complex systems of polynomial equations in several variables. After introducing algebraic-based methods, \ie, Gr\"{o}bner basis~\cite{DBLP:phd/basesearch/Stewenius05,Kukelova-thesis,Kukelova-ECCV-2008,larsson2017efficient} and resultant-based~\cite{bhayani2019sparse} methods for generating efficient polynomial solvers into computer vision community, 
solutions to many previously unsolved minimal 
problems were proposed, 
\eg, the relative and absolute pose problems for cameras with unknown focal length~\cite{Stewenius-CVPR-2005,bujnak_cvpr2008,Bujnak-ICCV-2009,larsson2019revisiting}, unknown radial distortion~\cite{DBLP:conf/cvpr/KukelovaP07,kukelova2013real,larsson2019revisiting,Oskarsson_2021_CVPR}, 
generalized~\cite{Stewenius-ISPRS-2006} and semi-generalized cameras~\cite{Wu_iccv15,bhayani2021calibrated,bhayani2023partially}.
Still, some problems, such as estimating the geometry of rolling shutter cameras, 
result in equations for which state-of-the-art algebraic methods fail to generate a solver that is efficient and/or numerically stable.

One approach to solve such problems is to introduce approximations of the camera model, \eg, a linearization of the rotation, and describe the problem 
%as a feasible set of polynomial equations that can be robustly and efficiently solved using algebraic methods. 
using simpler equations.
For some problems~\cite{albl2016rolling} such approximations do not introduce a visible decrease in the precision of the estimated model inside RANSAC: 
%since inside RANSAC-like methods, 
the estimated approx.\ model is typically % estimated from a minimum number of correspondences is 
polished in RANSAC's local optimization step~\cite{Chum-2003} 
%, \ie step (2), 
using all inliers and, potentially, using the original (more complex) model, \eg, a model with the full rotation. 
%
%
Another approach is to solve complex camera geometry problems using a non-minimal number of correspondences.
New correspondences usually add linear (or low-degree polynomial) equations in the unknown parameters. This allows to replace complex constraints that describe complex camera models with %these 
simpler equations, and  solve the problem using a simple solver\footnote{Note that non-minimal solvers are also approximating the original model by not considering some constraints describing it, \eg, $det(F)=0$. With respect to this simplified model, they are minimal.}. 
A standard approach is to use minimal plus one~\cite{kukelova2013real,kukelova2015efficient} matches not to significantly increase the number of RANSAC iterations. % inside RANSAC. 


%non-minimal solvers - minimal + 1 or linear solvers with more correspondences (linear trifocal tensor, linear RS solver)

%new correspondences usually add linear equations and threfore to solve the problem we can drop some more complex equations describing the model.

In this paper, we study the challenging problem of estimating the relative pose of three calibrated cameras. This problem has attracted attention % of researcher 
for a long time. 
However, due to its complexity, it is still not considered fully solved. For most of the minimal configurations of point and line correspondences, an efficient and practical solution to this problem does not exist yet.
One such configuration that is particularly interesting, is the notoriously difficult configuration of four points in three views, known as the 4p3v problem.
%for which an fully efficient and practical solution still does not exist.
%It is known that this problem is not Adjustment methods typically fail to solve
%the 3v4p problem and no practical numerical solution is know
It is known that the state-of-the-art algebraic methods as well as numerical methods fail to generate efficient and numerically stable solutions to the 4p3v problem.  

In this paper, instead of introducing  model approximations or  simplifying the problem equations by sampling more points inside RANSAC and solving a non-minimal problem, % as a non-minimal one, 
we propose a novel approach for solving the 4p3v problem.  
 The proposed method is based on generating a new ``approximate" point correspondence between two of the three views. We do this by using %an information purely from 
 only the locations of the four triplets of input point correspondences. 
Since the generation of the new points does not require  information from the image itself (\eg, the information about appearance or features in the image), the correspondence,  in general, does not need to correspond to any physical 3D point in the scene. 
Therefore, we call it a \emph{virtual correspondence}. 
Using the virtual correspondence, we can efficiently solve the 4p3v problem by first estimating the relative pose of the two cameras from five correspondences using the efficient 5pt solver~\cite{Nister-5pt-PAMI-2004}, and then registering the third camera using the P3P solver~\cite{lambda-twist}. We call this combination of the 5pt relative pose and the P3P solver the \sft solver. 

Virtual matches are also used in the literature of affine correspondences (AC) %\cite{Perdoch-CVPR2009efficient}. 
\cite{perd2006epipolar,pritts_ivcnz13,pritts-cvpr2018,barath2022relative}. 
There, points are sampled based on the affine feature geometry to generate point correspondences from affine ones. 
% The resulting point correspondences are then used as input to point correspondence-based solvers. 
In our scenario, we are directly given point correspondences, without associated feature geometry, and predict additional point matches. %are 
% However, they are employed to convert ACs to point correspondences. 
% In our case, 
%instead of reducing the DoF of the estimation problem as in our paper. 

 Based on this idea, we propose two novel solvers to the 4p3v problem. (1) 
%In the first solver we use a network to predict the coordinates of the virtual correspondence from the coordinates of the input four point correspondences in three views. 
In the %first 
\sftl solver, given four triplets of 
corresponding points in three views and  given a 5$^\text{th}$ point in the first view, we use a network to predict a corresponding 5$^\text{th}$ point %to this point 
in the second view, \ie a virtual $5^\text{th}$ correspondence.
(2) 
%In the second solver, we use the mean points of three corresponding points in two cameras as this virtual $5^{th}$ point correspondence.
In the \sftm solver, instead of using a network to predict the $5^\text{th}$ point correspondence, the solver uses the mean points of three corresponding points detected in two views as a new  virtual $5^{\text{th}}$ point correspondence. 
%\TODO{TODO: 
The novel solvers reach the state-of-the-art results for the 4p3v problem on real data.
%solutions to the 4p3v problem~\cite{Hruby_cvpr2022}

The idea of solving camera geometry problems using virtual correspondences is general, and can be applied to other
problems, \ie, to the 5-point relative pose problem. 
This opens up new opportunities to solve %In this
% way 
minimal problems %can be solved 
using much simpler
non-minimal solvers or even using sub-minimal samples inside RANSAC.






%To study the problem of estimating the relative pose of three calibrated cameras from point correspondences from practical perspective, we compare the novel 4p3v solvers with the simple baseline solver, that is solving a different minimal configuration of points in three views, \ie the configuration with three points  visible in all three views and additional two  points visible in two from the three views. 
%Surprisingly, this minimal configuration is usually not discussed and used in comparisons for the tree-view relative pose problem, even though, 
%This minimal configuration can be efficiently solved using the \sft solver.

%--------------------------------------------


%In this paper, we  explore a different type of approximation in camera pose estimation problems. Instead of approximating a camera model, we propose methods that approximate input point correspondences that are used for the model estimation. 
%
% The proposed a method that solves the 4p3v problem by generating new "approximate" point correspondences by using an information purely from the locations of the existing point correspondences. Since the generation of new correspondences does not require  information from the image itself (\eg the information about appearance and features in the image), these correspondences,  in general, do not need to correspond to any 3D points in the scene. Therefore, we call such correspondences \emph{virtual correspondences}.

% The proposed approximation does not simplify the model that is estimated and therefore original minimal solvers are used for the estimation. 
% However, using virtual correspondences, minimal problems can be solved using sub-minimal samples of points. 
% This is extremely important for RANSAC-style estimation framework, since the number of tested samples inside RANSAC depends exponentially on the number of correspondences required for the model estimation.

% The proposed approximation methods are general and can be used with any camera geometry estimation algorithm that is based point correspondences. Such algorithm can estimate the model from a minimal sample, like the 5-pt relative pose solver~\cite{Nister-5pt-PAMI-2004}, or  from a non-minimal sample, like the well known 8-pt relative pose solver for uncalibrated cameras~\cite{HZ-2003}. In this paper, we test the proposed approach with the most frequently used minimal solver, \ie the 5-point relative pose solver for calibrated cameras. 
% \TODO{In the supplementary material (SM), we show results with other type of solvers}.

\noindent The contributions of the paper are as follows: 
\vspace{-1.3ex}
\begin{itemize}[leftmargin=0.3cm]
%\setlength{\itemindent}{-1.0em}
\item We propose two novel solutions to the challenging 4p3v problem, % of estimating the relative pose of three calibrated cameras from four point correspondences, 
the \sftl and \sftm solvers. They generate an additional virtual point correspondence in two views by leveraging the four input triplet correspondences. 
This relatively simple idea allows us to solve the 4p3v problem using efficient existing solvers, the 5pt solver~\cite{Nister-5pt-PAMI-2004} and the P3P solver~\cite{lambda-twist}. The new solvers achieve state-of-the-art results in terms of accuracy on real data, %\footnote{TODO{We were not able to compare our results with the state-of-the-art %solers~\cite{DBLP:journals/ijcv/NisterS06,Hruby_cvpr2022}, 
% solver~\cite{DBLP:journals/ijcv/NisterS06} since it has no publicly available code, it is not easy to re-implement, and the authors do not have the original code either. 
%and is not easy to re-implement and for~\cite{Hruby_cvpr2022}, we were not obtaining correct results for our noisy real data instances. Since both these papers do not report result on noisy real data inside RANSAC-like framework, we consider our results as the state-of-the-art results on real data.
% }} 
with the \sftm solver being (slightly) worse, but much faster than the \sftl solver. Compared to the two state-of-the-art solutions to the 4p3v problem~\cite{Hruby_cvpr2022,DBLP:journals/ijcv/NisterS06}, which are non-trivial and hard to re-implement such that they are numerically stable and fast, our solutions, especially the \sftm solver, can be easily executed using existing efficient implementations of the 5pt and the P3P solvers.



%\item First, we study the performance of a simple minimal solver for estimating the relative pose of three calibrated cameras. Instead of sampling four points visible in three views, this solver samples only three points visible in all three views and additionally two more points visible in two from the three views. The solver is based on two efficient existing solvers, \ie, the 5pt relative pose solver~\cite{Nister-5pt-PAMI-2004} and the P3P solver~\cite{lambdatwist}. We show that this \sft solver outperforms the existing 4p3v solvers.

%\item We propose new learning-based ``minimal'' 4p3v solver -  \sftl. Given four triplets of 
%corresponding points in three views and  given one point in the first view train a network to predict a corresponding point to this point in the second view. With the fifth point correspondence between views 1 and 2, we apply the \sft solver to solve the 4p3v problem. We show that this solver \TODO{TODO}

%\item Additionally, we propose a simple and efficient 4p3v solver - \sftm.
%Instead of using a network to predict the $5^{th}$ point correspondence between the view 1 and 2, the solver uses the mean points of three corresponding points detected in these two views as a new $5^{th}$ point correspondence. We support this choice by experiments on synthetic and real data and show that this very simple solver returns only a slightly worse results than the learning-based \sftl solver while being much faster. It also significantly outperforms the existing 4p3v solvers.


%\item  To study, which minimal configuration and
%which solver is the most practical for estimating the relative pose of three calibrated %cameras, we develop an "oracle" solver - \sfto
\vspace{-1.3ex}
\item We propose a novel framework for solving camera geometry problems by  generating new \emph{virtual correspondences} using  information purely from the locations of the input point correspondences. This framework is general and can be applied to other camera geometry problems. It can be used to solve minimal problems using simpler non-minimal solvers, or even solving minimal problems from sub-minimal samples.
\vspace{-1.3ex}
\item 
%We compare the proposed 4p3v solvers as well as two ``oracle"  4p3v solvers, \ie, solvers that use a ground truth information to remove approximations introduce by the novel as well as the stat-of-the-art 4p3v~\cite{DBLP:journals/ijcv/NisterS06} solver, with the baseline minimal \sft solver that samples three triplets of points and two additional points visible  in two views.
We compare the proposed 4p3v solvers, the state-of-the-art 4p3v solver~\cite{Hruby_cvpr2022}, as well as two ``oracle"  4p3v solvers, 
%\ie, solvers that use a ground truth information to remove approximations introduce by the novel as well as the stat-of-the-art 4p3v~\cite{DBLP:journals/ijcv/NisterS06} solver, 
with the baseline minimal \sft solver that samples three triplets of points and two additional points visible in two views.
By evaluating all solvers on a large amount of real data, we discuss which minimal point configuration is potentially the most relevant %best 
in practical applications.
%\TODO{add Hruby}



\end{itemize}



% \begin{itemize}
% \item We propose new framework for solving camera geometry problems from sub-minimal samples of point correspondences, \ie samples that contain less points than necessary to formulate and solve the problem as a system of equations with a finite number of solutions.
% The framework extends the original sub-minimal sample with a new virtual point(s) that are generated using information about the locations of the original points. 
% %in the sub-minimal sample. 
% The generation of new virtual point(s) is computationally extremely efficient, \eg it computes the mean of the  original points 
% in the sub-minimal sample. 
% \item We evaluate several different strategies for generating virtual points on synthetic as well as real data.
% \item We incorporation of the best performing strategies into the solver for estimating the relative pose of two calibrated cameras, resulting in several variants of the new 4-point solver (with different strategies of generating the virtual point). We extensively evaluate the new sub-minimal 4-pt relative pose solvers on different real dataset and compare them with the state-of-the art 5-pt relative pose solver~\cite{Nister-5pt-PAMI-2004}.
% We show that ...\TODO{TODO}

% \end{itemize}

\section{Related work}
Estimating the relative pose of three cameras from a minimal number of point and line  correspondences 
% or a combination of point and line correspondences 
is known as an extremely challenging problem. 

For three uncalibrated cameras, 6 point correspondences are necessary to estimate the trifocal tensor, with a solution known for a long time~\cite{Quan_pami95,Torr97a}. 
 Solutions to three minimal combinations of points and lines are presented in~\cite{Oskarsson_bmvc2004}. 
The minimal configuration using 9 lines is much more challenging and was solved only recently by Larsson et al.~\cite{larsson2017efficient}.  However, the final solver is far from practical as it performs elimination of a huge $16k\times 13k$ matrix and runs 17.8s.

For calibrated cameras, the configuration that attracts most of the attention is the configuration of four points in three views (the 4p3v problem). Note, that this is not a minimal configuration since it generates 12 constraints for 11 degrees-of-freedom (DoF), \ie, it is over-constrained %by one 
(see also Section~\ref{sec:solvers}).
% The four-points-in-tree-views problem (4p3v) 
The 4p3v problem is known as being extremely difficult to solve.
Several papers present mostly theoretical results~\cite{leonardos_cvpr2015,Martyushev16,Aholt2014}.
%Since the problem is over-constrained, four general point triplets can not be realized as the projections of four common world points into three calibrated cameras.
For four triplets of exact points without noise, it is shown that the 4p3v problem has, in general, a unique solution~\cite{holt1995,Quan2006}.

To the best of our knowledge, there are only two reasonably efficient solutions to the 4p3v problem reported in the literature.
The first solver~\cite{DBLP:journals/ijcv/NisterS06} is based on  one-dimensional exhaustive search.
In the paper, the authors derive several interesting theoretical results and show that the four point correspondences between two calibrated views constrain the epipole in each image to lie on a curve of degree ten.
The solver performs a one-dimensional sweep of the curve of possible epipoles. 
For each potential epipole, it computes the relative pose of two cameras, registers the third camera using three triangulated points, and finally extracts the solution minimizing the reprojection error of the fourth point in the third view. 
The evaluation of the solver on one potential epipole is fast.  
Yet, to obtain reasonable precise and stable results, usually, 1,000 candidates need to be evaluated and even then, %in such a case 
refinement at multiple local minima is required to improve the precision. The reported run-times of this solver were $1-12$ms depending on the number of search points\footnote{This is the runtime reported in the paper from 2006, however, implemented by highly skilled researcher (the author of the fastest version of the well-known 5pt relative pose solver). Therefore, we do not expect significant speedup on recent hardware. Our implementation, which simulates one evaluation for one search point, runs $42 \mu s$, which corresponds to even slower runtimes $1.7-42$ms (without refinement and pose filtering).}. 
There is no publicly available implementation for this solver and it is not easy to re-implement. 
As such, the literature does not compare against the solver in experiments. 
% To obtain a
As an upper bound of the performance of~\cite{DBLP:journals/ijcv/NisterS06}, we compare against an oracle version using  the true epipole. % is given. 

The second efficient solver to the 4p3v problem was published only recently~\cite{Hruby_cvpr2022}. In this paper, the authors first transform the 4p3v problem to a minimal problem by considering a line passing through the last correspondence in the third view.
%, \ie by dropping one constraint. 
The resulting system of equations is solved using an efficient Homotopy continuation (HC) method~\cite{Fabbri_CVPR2020,SommeseAndrewJ2005Tnso}. 
To avoid computing large numbers of spurious solutions, an MLP-based classifier is trained. For a given problem $p$, it selects one or several starting problem-solution pairs (so-called anchors), such that the geometrically meaningful/correct solution of $p$ can be obtained by HC starting from this anchor. This strategy is fast, running $16.3\mu s$ on average per solution. 
At the same time, it has a high failure rate. The success rate of the 4p3v solver reported in~\cite{Hruby_cvpr2022} %the paper 
on two test %ing 
datasets and data without noise is $26.3\%$.
%Unfortunately,
% The paper does
\cite{Hruby_cvpr2022} do not show results of their solver in a real scenario, \ie, a RANSAC-like framework with noisy data. 
We provide such an evaluation in this paper. 
%Only a solver for much simpler 5pt relative pose problem, that has only 10 solutions and very simple system, is tested in such a scenario. Already for this solver 1.6 drop in the success rate is reported compared to testing datasets when it is used with noisy data. \TODO{adjust based on whether we will be able to run it}


Simple solutions for the 4p3v problem for orthographic and scaled orthographic views were presented in~\cite{xu_ortho4p3v,Higgins-4p3v91}. In~\cite{Higgins-4p3v91}, the author suggested an iterative approach for updating to perspective views. 
However, he reported results only on a few synthetic instances. % of points. 
Even after spending a non-negligible amount of work %(adding different local optimizations) 
and time (months) to make this update work, we were not able to get reasonable results on real data with general perspective cameras. % that are further from the scaled orthographic case.


Minimal configurations of points and lines in three calibrated views were  studied 
%from the theoretical perspective 
in~\cite{Duff_PL1P,Kileel2017,duff2019plmp}, aiming to classify %ing 
and derive %ing 
the number of solutions for different configurations. Solutions to two minimal configurations of combinations of points and lines, the so-called Chicago and Cleveland problems, were proposed in~\cite{Fabbri_CVPR2020}. These problems result in 216, respectively, 312 solutions and are solved using homotopy continuation methods~\cite{SommeseAndrewJ2005Tnso}. Due to the complexity, the resulting solvers are not practical in real applications, with running times ranging from $0.66$s to $1.9$s.


\section{Solvers for estimating the relative pose of three calibrated cameras}
\label{sec:solvers}
Let us assume that we are given $N$ cameras observing 3D points $\V P_i$ and for each point $\V P_i$, let $C_{\V{P}_i}>1$ 
be the number of cameras that observe it.
A necessary condition for a $N$-camera pose problem to be minimal is~\cite{Fabbri_CVPR2020}
\begin{equation}
\label{minimal_con}
    \sum_{\V{P}_i} (2C_{\V{P}_i}-3) =6N - 7 \enspace .
\end{equation}
%
A configuration of points in $N=3$ views that satisfies the constraint~\eqref{minimal_con} of a minimal problem is three points visible in all three cameras and two additional points visible in two of the three cameras. We will call this configuration %[(2,3),(2,3),(0,3)] 
$(5_3,5_3,3_3)$, where the lower index on the position $i$ indicates how many from the image points sampled in the camera $i$ are visible in all three cameras.

The configuration of four points visible in all three cameras, \ie, the configuration $(4_4,4_4,4_4)$, generates an over-constrained problem. In this case, we have one more constraint than DoF, \ie, in Eq.~\eqref{minimal_con}, we have $12 > 11$. This means that,
in general, four point triplets cannot be realized as the projections of four common world points into three calibrated cameras. A minimal solution would %have needed 
need to drop one constraint, \eg, %e.g., 
by considering only a line passing through one of the points in the third view~\cite{Hruby_cvpr2022} or by considering a ``half" point correspondence.
 Since in practice we always have full correspondences and sampling one less point in one view leads to an under-constrained problem, the configuration $(4_4,4_4,4_4)$, is usually considered %a 
 ``minimal".
 %\footnote{Sampling one less point in one view would have led to an under-constrained problem}.


In the following, we describe one baseline solution to the minimal $(5_3,5_3,3_3)$ configuration and two novel solutions to the ``minimal" $(4_4,4_4,4_4)$ configuration.
%and one solution to the configuration $(4_4,4_4,4_4)$ that is proposed to show an upper bound on the precision of the proposed 4p3v solvers.

\subsection{5pt+P3P solver}
% \PAR{5pt+P3P solver.}
 %Motivated by "minimal+1" solvers~\cite{kukelova2013fast,kukelovaICCV}, 
 %First, we 
 %consider the minimal configuration $(5_3,5_3,3_3)$, \ie, the configuration, where three points are visible in all three cameras and two additional points are visible in two from the three cameras.
% 
% In this paper, we study the performance of a simple baseline minimal solver, \ie the \sft solver, for estimating the relative pose of three calibrated cameras w.r.t. this configuration. 
First, we review a simple baseline minimal solver for the configuration $(5_3,5_3,3_3)$, \ie, the configuration where three points are visible in all three cameras and two additional points are visible in two of the three cameras.
% 

The \sft  solver first estimates the relative pose of two cameras from 5 image point correspondences using the efficient 5pt solver~\cite{Nister-5pt-PAMI-2004}. 
Next, the three points that are visible in all three views are triangulated. Finally, the third camera is registered using the three 2D-3D point correspondences and the well-known efficient P3P solver~\cite{lambda-twist}. 
 %The fourth point is used to filter out geometrically incorrect solutions, \ie solutions that do not satisfy three-view consistency. This is done by selecting the solution, among all solutions returned by the 5pt solver and the P3P, that minimizes  the reprojection error of the fourth point in the third view.
 
 This solver is straightforward and it is based on efficient existing solvers~\cite{Nister-5pt-PAMI-2004,lambda-twist}.
 %\footnote{
 %Note that we do not consider this solver as novel and its description as a contribution. Our contribution is in comparison of this ``baseline'' solver with the existing  4p3v and the new proposed 4p3v solvers. Our goal is  to study, which minimal configuration and which solver is the most practical in real applications}. 
 The \sft solver is not novel.
 %\footnote{
%Our contribution is 
%not in describing this solver but 
%in comparing this baseline solver with the existing  and the newly proposed 4p3v solvers. Our goal is  to study, which minimal configuration and which solver is the most practical in real applications.}. 
 This solver and the $(5_3,5_3,3_3)$ configuration  was, \eg, mentioned in% the paper
 ~\cite{Duff_PL1P}, where the authors present a classification of minimal problems for points and lines (partially) observed  by three calibrated perspective cameras. However, %here 
 the $(5_3,5_3,3_3)$ configuration and the \sft solver were only discussed %only 
 from %the 
 a  theoretical point of view, aiming to report the number of solutions to this problem and not its practical performance.
 %
 The \sft solver is %even 
 used by some researchers~\cite{Nister-5pt-PAMI-2004} and practitioners in their applications~\cite{Rodehorst2017}. 
Nister et al.~\cite{DBLP:journals/ijcv/NisterS06} showed that the \sft solver performs better than their dedicated 4p3v solver. 
 %and this solver is not considered as a standard minimal solution or a baseline for the three view relative pose problem. 
 Still, the \sft solver is not even used as a baseline for a comparison in papers that are studying the relative pose problem for three calibrated cameras~\cite{Fabbri_CVPR2020,Hruby_cvpr2022}. 
 To the best of our knowledge, the performance of this solver on real data and within state-of-the-art RANSAC frameworks in the context of the 4p3v problem was not extensively 
 studied. % in the computer vision literature. 



 
\subsection{4p3v(L) solver}
In this section, we describe our new, learning-based ``minimal''  \sftl solver, which solves the $(4_4,4_4,4_4)$ configuration. This solver is motivated by the efficient \sft solver and the minimal $(5_3,5_3,3_3)$ configuration, which, compared to the $(4_4,4_4,4_4)$ configuration, leads to significantly simpler systems of polynomial equations that can be solved efficiently. 

We use the fact that four triplets of points, in general, define a unique relative pose of three calibrated cameras. 
We train a network that given such four 
%triplets of 
corresponding points in three views and a 5$^\text{th}$ point in the first view, predicts a corresponding 5$^\text{th}$ %its corresponding point 
in the second view\footnote{By fixing a point in one view, we are defining an epipolar line %(an epipolar line) 
in the second view. Any of the points on this line (corresponding to 3D points with different depths) is in  correspondence with the %given 
point in the first view.}. % These points correspond to the 3D points with different depths}.
% Having such a
This 5$^\text{th}$ point correspondence between two views % view 1 and 2, we can 
enables us to apply the \sft solver to %solve 
the $(4_4,4_4,4_4)$ configuration. 
In this way, the network transforms the extremely complex 4v3p problem  into a problem for which efficient solutions exists.

% The proposed network can be seen as a network that instead of regressing two relative rotations and translations between three cameras from four triplets of point correspondences, which is an extremely challenging task, regresses only two coordinates of a point in the second image that corresponds to a given point in the first image. 
% In this way, the network transforms the extremely complex 4v3p problem,  to a problem for which an efficient exist.

% The architecture of the proposed n
Our network %\ch{
is based on the \textit{Set Transformer}~\cite{set_transformer}, an attention-based neural network that is designed to process unordered sets of data and is thus invariant to permutations of the input point correspondences. 
% This architecture has a strong property of permutation-invariance, which is very important for our representation of the problem, because we do not want to introduce any prior on the order of either the cameras or the point correspondences. 
% We keep the network very shallow, since we want the inference to be as fast as possible. 
The input to the network is a $5 \times 6$ matrix, where each one of the five rows represents a point correspondence. 
Inside the \textit{Set Transformer}, it is treated % be thought of 
as an unordered set of the $x$ and $y$ point coordinates in all three views. 
The first %Only 
four %of the 
rows represent the given %detected 
point correspondences. 
% while t
The $5^\text{th}$ row serves as an initialization for the prediction. This initialization is the mean of the three corresponding points. %Note that, i
In the first image we fix the $5^\text{th}$ correspondence to be the mean of those three points, thus the network aims to find its correspondence in the other two images. 
% After shaping the input instance, and before feeding it to the network, w
We normalize the input points per view %instance 
by applying a rotation %to each one of the coordinate systems, so that in each one of the them, 
such that the first point is sent to the origin, and the second point is sent to $(0, y)$. %}

% \ch{
We train and validate our network using only synthetic data. 
The synthetic dataset is generated as follows: first, we generate a scene of 10K random points $\M{X}_i \in \R^3$. Then, to generate each instance/configuration, we randomly select four 3D points and three cameras with random rotations and translations that view the scene, and project those points into the cameras. % get the camera coordinates. 
In total, that is for training and validation, we use $1$M such instances. %/configurations. 
The network was implemented in PyTorch~\cite{paszke2017automatic} and trained for 1,500 epochs using the Adam optimizer~\cite{DBLP:journals/corr/KingmaB14}. 
Details on the architecture, training data, and training can be found in the supp. mat.
% }



% As mentioned in Introduction, the \sftl solver is an ``approximate" solver to the original 4p3v problem, \ie, to the configuration $(4_4,4_4,4_4)$. The fifth point correspondence returned by the network, in general, does not satisfy the epipolar constraint w.r.t. the ground truth relative pose of the first two cameras. Therefore, the relative poses returned by the \sftl solver will not, in general, satisfy all constraints imposed by the input four correspondences in three views.
% However, in experiments, we show that already for image points affected by $2 px$ noise, the results of this solver are comparable to the results of the exact \sft solver for the $(5_3,5_3,5_3)$ configuration.~\TODO{maybe remove the whole paragraph}


\subsection{4p3v(M) solver}

The second solver for the  $(4_4,4_4,4_4)$ configuration is based on a simple observation: 
if we fix the $5^{\text{th}}$ point in the first view to be a mean of three points in this view, then the mean point of the corresponding three points in the second view usually has a small epipolar error \wrt the ground truth relative pose. 
That is, the mean of three points is a good approximation of a correct correspondence.


This can be considered as a surprising fact, since 4 (or actually 3) points in two views define an infinite number of camera poses that can observe these points. However, it comes from three simple facts and observations. (1)  To generate a good correspondence, we only require that the point in the second image is reasonably close to the epipolar line defined by the mean point in the first image, \ie, the 2D point does not need to correspond to one particular 3D point with a given depth.
(2) The epipolar line defined by the mean point of three points in the first image passes through the triangle defined by the corresponding three points in the second image. Therefore, the maximum distance of the mean point in the second image from the epipolar line is bounded by the maximum distance of the mean point from one of the vertices of the triangle.
(3) Three points in 3D define a plane. If this plane is not observed under very oblique and different angles in two views then the point on the 3D plane that projects on the mean point in the first image usually projects close to the mean  point in the second image.
We support this observation by experiments on a large amount of synthetic and real data (\cf Sec.~\ref{sec:experiments}, mean-point strategy). %\ref{sec:mean-point}). 

Motivated by these observations, our \sftm solver uses the mean points of three corresponding points detected in two views as a new $5^\text{th}$ point correspondence. The 4p3v problem is then solved using the \sft solver.



% \subsection{4p3v(O) solver}
% To show what is the upper bound in the precision of the proposed 4p3v solvers, \ie, the  \sftl and \sftm , we consider one more solver. This ``oracle'' \sfto solver for the $(4_4,4_4,4_4)$ configuration uses a correct correspondence, \ie a correspondence that satisfies the epipolar constraint for the ground truth relative pose of the first two cameras, as a $5^{th}$ correspondence between these cameras. Then the \sft solver is applied to estimate the relative pose of three cameras. 

% The  \sfto shows the maximum precision that the   \sftl and \sftm can reach, if they would have been able to predict or infer the correct $5^{th}$ correspondence from coordinates of four correspondences in three views.


\section{Solving camera geometry problems using virtual correspondences }

The proposed methods generating \emph{virtual correspondences}, \ie, the learning-based and the mean-point method that were used in the \sftl and \sftm solvers, can be, in general, applied to other camera geometry estimation problems % algorithm that is 
based on point correspondences. 
%
Generating one or potentially more \emph{virtual correspondences} using only %an information purely from 
the locations of the input
correspondences allow for solving complex minimal problems using much simpler non-minimal solvers, while still sampling only a minimal number of points inside RANSAC.

The good performance of the proposed ``mean solver" \sftm, which uses information from three point correspondences in two views, shown in Sec.~\ref{sec:experiments}, suggests that this method can be used to solve minimal problems using sub-minimal samples inside RANSAC in some scenarios.
Fig.~\ref{fig:noise} and the supp.\ mat.\ % material, we 
show %some 
preliminary results for the well-known 5pt relative pose problem, where we sample only four point correspondences inside RANSAC and generate the $5^\text{th}$ correspondence as a mean point of three corresponding points in both images. 
%We show that even thought 4 (3) points in two views define infinite number of camera poses that can observe these points, we show that, in practice, such a correspondence is usually a quite good approximation of a correct correspondence and the solver that 
While this $5^\text{th}$ correspondence can be noisy, the resulting \texttt{4pt(M)} solver shows comparable performance to the %minimal 
%well-known 
5pt solver %relative pose problem 
inside RANSAC. 
This shows a potential for applying such a sub-minimal solver in scenarios with lots of outliers and noisy data, where sampling one less point may show some improvement.
%\TODO{maybe point to noise experiment}

\section{Experiments}
\label{sec:experiments}
We evaluated the proposed solvers on synthetic and real data to test their robustness to noise, and assess their performance inside a state-of-the-art RANSAC-framework~\cite{barath2017graph}. 
%
We compare our new \sftl and \sftm solvers with the following state-of-the-art algorithms:
\begin{itemize}
[leftmargin=0.3cm]
\vspace{-1.0ex}
       \item \texttt{consecutive 5pt}: RANSAC-based robust essential matrix estimation is applied independently for two pairs of views (1-2 and 1-3), without considering triplets. 
    \vspace{-1.6ex}
    \item \texttt{joint 5pt}: %model estimation simultaneously returns 
    inside a single RANSAC, from a sample of 5 points in 3 views, essential matrices are estimated independently for two pairs of views (1-2 and 1-3) from the view triplet %the two-view correspondence sets, each consisting of 
    using five matches each. %, formed between the 1st-2nd and 1st-3rd views from the triplet matches.
    The two matrices are jointly validated inside RANSAC.
    \vspace{-1.6ex}
     \item \sft: The baseline minimal solver for the $(5_3,5_3,3_3)$ configuration.
    \vspace{-1.6ex}
    \item \sfhc: The homotopy continuation solver~\cite{Hruby_cvpr2022}.
    %\item \sftl - The novel solver for the configuration $(5_3,5_3,3)$, which samples four points in three views, predict $5^{th}$ virtual correspondence using network described in Sec.~\cite{sec:4p3v(L)} and then calls \sft solver.
    %\vspace{-1.6ex}
    %\item \textbf{DPR} Differential Pose Resection \cite{koser2008differential}.
    %\vspace{-1.6ex}
    %\item \textbf{IPPE} Infinitesimal Plane Pose Estimation \cite{collins2014infinitesimal}.
\end{itemize}

\begin{figure}[t!]
    \centering
	%\includegraphics[width=0.593\columnwidth]{assets/tests_distance_5.pdf}\hfill
	%\includegraphics[width=0.593\columnwidth]{assets/tests_distance_10.pdf}\hfill
	%\includegraphics[width=0.593\columnwidth]{assets/tests_distance_20.pdf}\phantom{xxx}\\[0.3cm] 
	\includegraphics[width=0.45\columnwidth]{figures/synth_symmetric_error.pdf}
	\includegraphics[width=0.45\columnwidth]{figures/real_symmetric_error.pdf}
\caption{Distribution of the average symmetric epipolar error as a function of barycentric coordinates of the point in the second image \wrt the mean point of three points in the first image, for synthetic data (left) and real data (right).  }
\label{fig:mean_tests}
\end{figure}

% \subsection{Mean-point strategy}
% \label{sec:mean-point}
\PAR{Mean-point strategy}
The first experiment aims to support our strategy of selecting a virtual point correspondence as the mean points of three corresponding points in two images.
We validate this strategy on synthetic and real data.

For the synthetic experiment, we generated 10k scenes with known ground truth parameters. 
In each scene, the three 3D points were randomly distributed within a cube of size $10 \times 10 \times 10$. Each 3D point was projected into two cameras.
%with realistic focal lengths. 
The orientations and positions of the cameras were selected at random such that they looked towards the origin from a random distance, varying from $20$ to $50$, from the scene. 
In the first camera, we generated a new point as a mean point of the three projected points. In the second camera, we were sampling points inside the triangle defined by the three 2D points.  To make the sampling invariant of actual coordinates of 2D points, we represented sampling in barycentric coordinates. We uniformly sampled $19 \times 19$ barycentric coordinates $(a,b)\in [0,1]^2$, such that $a+b \leq 1$. The third barycentric coordinate was computed as $c = 1-a-b$. We use these barycentric coordinates to compute the coordinates of the corresponding point in the second image. We then evaluated the symmetric epipolar error of this point and the mean point in the first image.
Fig.~\ref{fig:mean_tests} (left) shows the average symmetric epipolar error as a function of the barycentric coordinates of the point in the second image. 
The 2D Gaussian distribution fitted to these results has mean $\mu = (0.333,0.332)$. In this point the minimum was reached. The point with barycentric coordinates $(0.\bar{3}, 0.\bar{3})$ corresponds to the mean point of the triangle.

We performed the same experiment on real data. In this  experiment we used the SfM model of the Shop Facade scene from the Cambridge Landmark dataset~\cite{Kendall2015ICCV} to obtain image pairs. 
We extracted 4,525 pairs and used exact projections of 3D points into these pairs to simulate noise-less data. 
In each pair, we sampled 100 different triplets of points and for each, we performed the same experiment as described above. Altogether, we evaluated 452,500 triplets (corresponding triangles). 
Fig.~\ref{fig:mean_tests} (right) again shows the average symmetric epipolar error as a function of barycentric coordinates of the point in the second image. The distribution of errors was very similar to the synthetic data with the minimum at $(0.333,0.333)$, \ie, the mean point. 


\begin{figure*}[t]
    \centering
	\begin{subfigure}[t]{0.32\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_avg_R_final.pdf}
		% \caption{}
    	\label{fig:ground_rot_error_ori}
	\end{subfigure}
	\begin{subfigure}[t]{0.32\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_avg_t_final.pdf}
		% \caption{}
    	\label{fig:ground_tra_error_ori}
	\end{subfigure}
	\begin{subfigure}[t]{0.32\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_avg_R12_final.pdf}
		% \caption{}
		\end{subfigure}
    \caption{ Noise experiment showing 
    (left) $\texttt{avg}(e(\M R_{12}),e(\M R_{13}))$,  (middle) $\texttt{avg}(e(\M t_{12}),e(\M t_{13}))$, and (right) $e(\M R_{12})$ as functions of noise scale in pixels, where $\M R_{ij}$ and $\M t_{ij}$ are the relative rotation and translation of the $i^{\text{th}}$ and $j^{\text{th}}$ views, respectively.}
    \label{fig:noise}
\end{figure*}



% \subsection{Noise experiments}
\PAR{Noise experiments.}
We tested the performance of our solvers and the state-of-the-art algorithms \wrt increasing image noise. 
We use the SfM model of the botanical garden scene (randomly picked from all scenes) from the ETH3D dataset~\cite{Schops_2017_CVPR} to obtain instances of 5 points in three views by identifying images in the scene that share 3D points. 
Perfect correspondences with no noise are generated by projecting the 3D points into the images. 
We then add increasing amounts of normally distributed noise to these correspondences. 
We generated more than 9k instances, but show only 1k results per plot to avoid clutter. 
Note that the \sfhc solver was trained on the ETH3D dataset while our \sftl was trained on purely synthetic data. 
% Our experimental setup is thus not biased towards our solvers. 
% Since the network used in our \sftl solver was trained on synthetic scenes, here we decided to use real dataset....\TODO{Torste finish}

The results for increasing noise in the image points are shown in Fig.~\ref{fig:noise}. 
Results are represented by a boxplot function which shows the 25\% to 75\% quantiles as a box with a horizontal line at median. The crosses show data beyond 1.5 times the interquartile range.
Let $e(\M R_{ij})$  be the error of the estimated relative rotation  between cameras $i$ and $j$, computed as the angle in the axis-angle representation of $\M R_{ij}^{-1}\M R_{ij}^{\M{GT}}$ and let $e(\M t_{ij})$ be the error of the estimated translation computed as the angle between the two unit vectors corresponding to the translations. 
Fig.~\ref{fig:noise} shows boxplots of %(a) 
$\texttt{avg}(e(\M R_{12}),e(\M R_{13}))$,  %(b) 
$\texttt{avg}(e(\M t_{12}),e(\M t_{13}))$, and %(c) 
$e(\M R_{12})$ (zoomed in to the interesting interval) as functions of varying noise from $0px$ to $4px$. Individual errors ($e(\M R_{13})$, $e(\M t_{12})$, $e(\M t_{13})$) are shown in the supp. material.

Due to the approximate nature of the virtual correspondence, our newly proposed solvers \sftl and \sftm return non-zero errors for zero noise. However, at noise levels $\geq 2px$ both proposed solvers return comparable or even better results than the \sft solver, which is based on the same strategy, but uses real point correspondences affected only by considered noise. This shows that our predicted virtual correspondences are good approximations to real correspondences. The \sftm solver is returning slightly worse rotation but slightly better translation errors than the \sftl solver.
The recent state-of-the-art solver~\cite{Hruby_cvpr2022} is failing in about 50\% of the instances for noiseless data, even though the solver was trained on the ETH3D dataset. Thus, the median errors are significantly larger than the median errors of the remaining solvers. 

The rotation error in the first two views in Fig.~\ref{fig:noise} (right)  shows an interesting potential of using the ``mean solver" for the two-view relative pose estimation problem. The mean \sftm solver %, which generates a $5^\text{th}$ correspondences from three points visible in images 1 and 2, %for image pair 1-2 uses only local information from input point coordinates in these two views 
% and samples a sub-minimal sample of four points, 
achieves comparable results to the minimal 5pt point solver~\cite{Nister-5pt-PAMI-2004}, here represented by the results of \sft, for noise $\geq 3px$. 
The \sftm solver only uses information from the two individual views.  
Thus, the results indicate that a potential for %This opens door for investigation of using this simple idea for 
solving minimal problems from sub-minimal samples.


% \subsection{Oracle 4v3p solvers}
\PAR{Oracle 4v3p solvers.}
To obtain upper bounds for the precision that can be achieved by our %of the 
proposed %4p3v solvers, \ie, the  
\sftl and \sftm solvers, as well as the state-of-the-art \sfep solver~\cite{DBLP:journals/ijcv/NisterS06}, we consider two additional ``oracle'' solvers for real experiments: 
1) 
The \sfto solver uses a correct correspondence, \ie, a correspondence that satisfies the epipolar constraint for the ground truth relative pose of the first two cameras, as the $5^\text{th}$ virtual correspondence between these cameras. Then the \sft solver is applied to estimate the relative pose of three cameras. 
The \sfto shows the maximum precision that the  \sftl and \sftm can reach, if they would have been able to predict or infer a precise %correct 
$5^\text{th}$ correspondence from the coordinates of four correspondences in three views.

% Similarly, 
2) We test an oracle version of the %Nister's 
\sfep solver. In this \sfepo solver, instead of performing an one-dimensional search over the $10^{\text{th}}$ degree curve of possible epipoles, we provide the solver with the ground truth epipole. 
To simulate the effect of sampling four points for this solver inside RANSAC, instead of using the second epipole and the epipolar line homography to get the essential matrix $\M{E}$, as suggested in the implementation details~\cite{DBLP:journals/ijcv/NisterS06}, we use the second suggested way on how to obtain $\M{E}$, \ie, using their \step solver. However, we feed the \step solver %, we however, feed 
with four points and use SVD instead of the null space. The rest of the solver performs the triangulation and registers the last camera using the P3P solver~\cite{lambda-twist}. This is identical to the original \sfep solver. 
However, in this case we do not need to use the fourth point correspondence to select the pose that minimizes the reprojection error. Similarly, we do not need to use refinement. 
Remember that the original %Nister's 
\sfep solver needs to call these evaluations for each search step on the $10^{\text{th}}$ degree curve of possible epipoles (usually $40{\times}-1000{\times}$~\cite{DBLP:journals/ijcv/NisterS06}). Moreover, this solver has several sources of errors, \eg, the $10^{\text{th}}$ degree curve is affected by noise; sparse sampling of the points on the curve introduces additional potentially large noise in the epipole; the reprojections of the fourth image point in the third view, traced out by sweeping through the curve of possible epipoles, generates complex curves in the third view, with the reprojection cost function having a lot of local minima. In the paper~\cite{DBLP:journals/ijcv/NisterS06} it was reported that %, \eg, 
even for exact data and 1000 search points followed by refinement at multiple local minima the failure rate of the solver is $\approx 3\%$. Therefore, we expect the original solver \sfep to perform much worse that the ``oracle" \sfepo solver used in the following experiments.





\begin{table*}[]
    \centering
    \setlength{\tabcolsep}{4.8pt}
    \resizebox{1.0\linewidth}{!}{\begin{tabular}{r | c c c c c c | c c c c c c }
        \toprule
        & \multicolumn{6}{c |}{Sacre Coeur (5000 image triplets)}  & \multicolumn{6}{c}{St.\ Peters' Square (5000 image triplets)} \\
        \midrule
        Estimator & AVG ($^\circ$) $\downarrow$ & MED ($^\circ$) $\downarrow$ & AUC@5$^\circ$ $\uparrow$ & @10$^\circ$ & @20$^\circ$ & Time (s) $\downarrow$ & AVG ($^\circ$) $\downarrow$ & MED ($^\circ$) $\downarrow$ & AUC@5$^\circ$ $\uparrow$ & @10$^\circ$ & @20$^\circ$ & Time (s) $\downarrow$ \\
        \midrule
        %consecutive 5PC 
        cons.\ 5pt & 14.24 & 5.06 & 35.20& 45.82 & 56.76 & \phantom{1}0.15 & 16.46 & \phantom{1}9.12 & 16.49 & 30.27 & 46.39 & \phantom{1}0.04 \\
        %joint 5PC 
        joint 5pt & 24.88 & 4.33 & 38.45& 47.32 & 55.25 & \phantom{1}0.29 & 26.36 & 10.47 & 15.31 & 28.15 & 43.38 & \phantom{1}0.36  \\
        4p3v(HC)~\cite{Hruby_cvpr2022} & 24.79 & 2.94 & 43.25 & 50.80 & 57.41 & \phantom{1}2.08 & 27.04 & \phantom{1}9.67 & 19.45 & 31.74 & 44.94 & \phantom{1}1.83 \\
        %5PC + P3P 
        5pt+P3P & 23.80 & 1.88 & 47.43& 54.94 & 61.02 & \phantom{1}2.59 & 25.84 & \phantom{1}8.47 & 21.25 & 34.17 & 47.54 & \phantom{1}2.46 \\
        %4PC (mass) + P3P 
        4p3v(M) & 25.11 & 3.04 & 42.71& 50.51 & 57.36 & \phantom{1}2.47 & 27.48 & \phantom{1}9.78 & 18.35 & 30.99 & 44.69 & \phantom{1}2.15 \\
        %4PC (pred) + P3P
        4p3v(L) & 24.76 & 1.93 & 47.14& 54.35 & 60.08 & 38.50 & 27.11 & \phantom{1}8.70 & 21.34 & 33.95 & 46.65 & 14.13 \\
       %\sfhc & 24.79 & 2.94 & 43.25 & 50.80 & 57.41 & \phantom{1}2.08 & 27.04 & \phantom{1}9.67 & 19.45 & 31.74 & 44.94 & \phantom{1}1.83 \\
        \midrule
        %4PC (oracle) + P3P 
        4p3v(O) & 22.81 & 1.82 & 47.83 & 55.39 & 61.64 & \phantom{1}2.54 & 24.14 & \phantom{1}8.00 & 21.94 & 35.10 & 48.94 & \phantom{1}2.55 \\
        %4PC (oracle) + P2P (oracle) & 22.41 & 1.74 & 48.93 &  56.48 & 62.59 & 2.49 \\
        %GT E + Nister-3PC  & 21.78 & 2.83 & 45.62 & 52.45 & 58.93 & 0.06\\
        %GT E + Nister-4PC  
        4p3v(NO) & 23.34 & 2.13 & 46.15 & 54.54 & 61.08 & \phantom{1}0.22 & 25.89 & \phantom{1}7.90 & 21.23 & 34.79 & 48.34 & \phantom{1}0.20 \\
        \hline
    \end{tabular}
    }
    \caption{The average and median pose errors in degrees, and Area Under the Recall curve (AUC) thresholded at 5$^\circ$, 10$^\circ$ and 20$^\circ$ and the average run-time (in seconds) on a total of 10k image triplets from two scenes of the PhotoTourism dataset~\cite{IMC2020}.}
    \label{tab:phototourism_real_Test}
\end{table*}

% \subsection{Timings}
\PAR{Timings.} 
%\paragraph{Timings}
We computed the average processing times of the solvers over 1,000 random problem instances.  
The solvers were implemented in C++ within the GC-RANSAC~\cite{barath2021graph} framework using the Eigen library for performing matrix operations.
We used the \texttt{5pt}~\cite{Nister-5pt-PAMI-2004} and \texttt{P3P}~\cite{lambda-twist} methods implemented in GC-RANSAC for composing the discussed solvers.
For \sfhc we used the implementation from the authors\footnote{https://github.com/petrhruby97/learning\_minimal} with default settings\cite{Hruby_cvpr2022}.
The experiments were performed on an Intel(R) Core(TM) i9-10900K CPU @ 3.70GHz.
The results are reported in Tab.~\ref{table:timings}.  

%\TODO{Daniel: I prepared some template draft, please adjust it. I think for Hruby's time we should maybe mention that it has to be multiplied at least with $\frac{1}{success ratio}$ as it was done in their paper. They called it i guess effective time}

%\vspace{-1.0ex}
\begin{table*}
%\footnotesize
\begin{center}
% \footnotesize{
\begin{tabular}{|l| c | c | c | c || c|}
\hline
 & \sft & \sfhc~\cite{Hruby_cvpr2022} & \sftl & \sftm & \sfepo\\
\hline
% Time ($\mu$s)  & 1.18 & 53.94 & 4.74 \\
Time ($\mu$s)  & 53.15 & $51.93^{*}$ & 419.59 & 57.59 & $42.61^{*}$ \\ % new timings from Apple M1 Pro 
\hline
\end{tabular}
% }%
\end{center}
\vspace{-1.8ex}
\caption{\label{table:timings}Average timing in $\mu$s over 1,000 trials. $^{*}$ The time for \sfhc does not account for its high failure rate, the effective time is usually more than $4 \times$ higher~\cite{Hruby_cvpr2022}. Note that our time for the \sfhc is higher than the average time reported in~\cite{Hruby_cvpr2022}. This can be due to longer run-time of HC on our instances, different hardware, and that time reported in~\cite{Hruby_cvpr2022} did not involve, \eg, pose extraction from estimated depths. The time for \sfepo is the time for evaluation of one search point. Usually 40 -- 1,000 search points have to be evaluated. }
\end{table*}

% \subsection{Real experiments}
\PAR{Real data experiments.} 
We tested the solvers on two scenes from the validation set of the IMC2020 benchmark~\cite{IMC2020}.
The scenes, Sacre Coeur and St.\ Peters' Square, come from the PhotoTourism dataset~\cite{snavely2006photo} and provide ground truth pose via a COLMAP~\cite{Schoenberger2016CVPR} reconstruction.
To form image triplets, we iterated through the point correspondences provided in~\cite{IMC2020} and selected pairs of image pairs that share one view.
Since the provided correspondences do not contain descriptors, we detected RootSIFT~\cite{lowe1999object,Arandjelovic2012CVPR} features in all three images of each triplet.
We then matched features between the view pairs 1-2 and %th and 
1-3 %th views 
by standard nearest neighbors matching. 
To enforce cycle-consistency, we kept only those correspondences that were matched to the same features in all view pair combinations. 
In total, we collected 5,000 image triplets from each scene.

To estimate the relative poses between the images of each triplet, we apply the Graph-Cut RANSAC~\cite{barath2021graph} robust estimator. 
The point-to-model residual function is chosen to be the Sampson error of a triplet correspondence average over image pairs 1-2 %th 
and 1-3. %th. 
%
We calculate the error of the triplet pose by, first, taking the average of the relative rotation and translation errors coming from essential matrices $\textbf{E}_{12}$ and $\textbf{E}_{13}$ given the ground truth relative pose. 
Finally, we take the maximum of the averaged rotation and translation errors (both measured in degrees) as the pose error~\cite{IMC2020}. 

Tab.~\ref{tab:phototourism_real_Test} reports the average and median pose error in degrees, the Area Under the recall Curve (AUC) thresholded at $5^\circ$, $10^\circ$, and $20^\circ$, and the average processing time in seconds.
The results of this experiment are discussed in Sec.~\ref{sec:discussion}. %the next section.


% \TODO{Daniel}

\section{Discussion and limitations}
\label{sec:discussion}
%\TODO{Which configuration is the best...\sft solver? Does it make sense to try to solve 4p3v - maybe for higher outlier ratios?}
Tab.~\ref{tab:phototourism_real_Test} shows % this paper, we proposed two solvers to the well-known challenging 4p3v problem. These 
that the proposed solver \sftm achieves a similar pose accuracy as the state-of-the-art \sfhc solver~\cite{Hruby_cvpr2022} while the \sftl solver generates more accurate poses. 
However, this increase in performance comes at the price of significantly longer running times. 
Still, the \sftm solver has comparable run-times as \sfhc. 
All 4p3v solvers % 
%
%However, in real experiments inside the state-of-the-art RANSAC framework~\cite{barath2017graph}, they 
return (slightly) worse poses than the \sft solver. 
The \sft solver is sampling three triplets and two pairs of points. 
In general, this can lead to  more samples inside RANSAC-style algorithms than sampling four triplets of points in the 4p3v solvers. However, since the proposed 4p3v solvers introduce approximation in the form of approximate virtual correspondences, and the \sfhc solver has a high failure rate, the \sft solver performs slightly better.
The results of the oracle \sfto solver suggest that 
being able to predict a precise $5^\text{th}$ virtual correspondence 
%from the coordinates of four correspondences in three views, 
can result in improvement over the results of the \sft solver. However, this improvement is only marginal. In~\cite{DBLP:journals/ijcv/NisterS06}, it was shown on different synthetic data that their dedicated \sfep solver performs worse than the \sft solver. This is observed also in our real experiments, where even the oracle version of this solver~\cite{DBLP:journals/ijcv/NisterS06}, \ie the \sfepo solver, returns for some datasets worse errors than the \sft solver.

% These results 
%on real data 
% send as several important messages:
\noindent
Important conclusions that can be drawn from the results: 
\vspace{-1.3ex}
\begin{itemize}[leftmargin=0.3cm, topsep=0.2cm]
\item The very simple \sftm solver, which just uses mean points as a virtual ``approximate" correspondence and runs existing efficient solvers, achieves comparable results to the very complex \sfhc solver.
%which in non-failure cases deliver exact solution to the input equations. 
The \sfhc solver requires significant tuning, %a lot of design choices, 
\eg, a selection of good sets of anchors that cover the space of solutions, tuning the number of anchors, and problem-specific tuning of computations in the HC method. Moreover, \sfhc solver is not easy to re-implement. As such, the underlying learned HC framework is much harder to apply to other problems than our novel framework based on virtual correspondences. % it is not easy to efficiently apply to other problems.
\vspace{-1.3ex} 
\item The novel \sftl solver outperforms the state-of-the-art \sfhc solver.  \sftl solver is easy to train and while it is slower than the \sfhc solver, there is a  space for speed up (\eg, using simpler architectures). % it on GPU).
\vspace{-1.3ex} 
\item  The state-of-the-art results of \sftl and \sftm solvers show the potential of our novel framework for solving camera geometry problems using  approximate virtual correspondences. 
%We see a large potential of the proposed framework for solving camera geometry problems using virtual correspondences. 
While this method can be theoretically applied to any camera geometry problem, we see larger promise in relative pose problems, where it is sufficient to find one 2D point that is sufficiently close to the epipolar line. For %the 
absolute pose solvers, a %good 
virtual correspondence will need to be close to a 2D point instead of an epipolar line.
\vspace{-1.3ex} 
\item  While we think that studying the 4p3v problem is important from a theoretical perspective, % is important, 
from a practical point of view, it looks like that in most scenarios using the \sft solver instead of a 4p3v one is sufficient. 
Still, slightly better performance of 4p3v solvers over the \sft solver can be expected on data with large outlier contamination due to smaller sample sizes.
\end{itemize}

% We see these results as an important message for researchers. While we think that studying the 4p3v problem from the theoretical perspective is important, from the practical point of view, it looks like that in most scenarios using the \sft solver instead of a 4p3v solver would be sufficient.
% Slightly better performance of 4p3v solvers over the \sft solver could be potentially seen on data with large ourlier contamination.

%Future work can include: speeding up the \sftl solver by implementing it on GPU or by using a simpler architecture; incorporating few stpdf of fast refinement on the solution; selecting the triangle with largest area to improve the stability.



%\TODO{Mention that Petr's method involves tuning of design choices.}

% \begin{itemize}
%     \item future work - fast refinement e.g. few stpdf of newton
%     \item selecting mean of the triangle with the larges area
%     \item speed up netwot - on GPU
%     \item apply to other problems
% \end{itemize}

\section{Conclusion}
In this paper, we have considered the highly challenging %4p3v 
problem of relative pose estimation of three views from four correspondences. 
We have proposed a novel framework that solves this problem using existing and efficient solvers by simply predicting a $5^\text{th}$ point correspondence. 
We have proposed two solvers based on this framework, one using a trained predictor and the other simply using mean coordinates of input points. 
Extensive synthetic and real experiments show that both solvers can achieve state-of-the-art performance. 
At the same time, our solver based on using mean points is trivial to implement, especially compared to the current state-of-the-art. 
Our results furthermore indicate that our framework based on virtual correspondences is more generally applicable.
Yet, our results also suggest that the 4p3v problem might be of limited practical relevance. 
% The results also suggest that our framework is more generally applicable. % to other problems. 

\PAR{Acknowledgements.}
Charalambos Tzamos was supported by the Czech Science Foundation (GAÄR) JUNIOR STAR Grant (No. 22-23183M) and by SGS project (No. SGS23/173/OHK3/3T/13). Daniel Barath was supported by the ETH postdoc fellowship. Torsten Sattler was supported by the EU Horizon 2020 project RICAIP (grant agreement No. 857306) and the European Regional Development Fund under project IMPACT (No. CZ.02.1.01/0.0/0.0/15\_003/0000468). Zuzana Kukelova was supported by the Czech Science Foundation (GAÄR) JUNIOR STAR Grant (No. 22-23183M).

{\small
\bibliographystyle{ieee_fullname}
\bibliography{arxiv}
}

\pagebreak

\section*{Supplementary Material}

This supplementary material provides more details on the architecture, training data, and training of the network used in the \sftl solver presented in Sec.~3.2 of the main paper, and more details on the experiments presented in Sec.~5 of the main paper. 

 

\section*{Details on the network}

Our network used for correspondence prediction in the \sftl solver is based on the \textit{Set Transformer}~\cite{set_transformer}. 
Its input is a matrix $X \in \R^{n \times d}$, which represents a set of $d$-dimensional vectors.
The building blocks of the Set Transformer are the \textit{Set Attention Block} (SAB), the \textit{Induced Set Attention Block} (ISAB), and a \textit{Pooling by Multihead
Attention} (PMA) mechanism. 
SAB is a permutation equivariant self attention block that contains information about the pairwise interactions of the elements in the input set. 
$\text{ISAB}_m$ is also a permutation equivariant self attention blocks that contains also a trainable set of $m$ $d$-dimensional vectors, which can be used to encode some global structure of the problem.
PMA is a parameterized permutation invariant aggregation scheme.
For more details we refer the reader to~\cite{set_transformer}.

We use an encoder-decoder architecture. 
The encoder is a single $\text{ISAB}_m$, with $m=64$. The output of it is a set of 1024-dimensional vectors. Then, the decoder is a PMA aggregation, followed by a single SAB, which leads to a row-wise feed-forward layer. The output is a $2v$-vector, that contains the $x$ and $y$ coordinates of $v$ views for the $5^{\text{th}}$ point correspondence.

The loss we use to train our network is the symmetric epipolar error. When solving the 4p3v problem, the input is a $5 \times 6$ matrix. The 5th row contains, for each image, the mean of the first 3 corresponding points. For the 1st image, this mean will be the coordinates of the virtual correspondence, while for the other two images, this will only serve as an initialization for the network. We have the essential matrix $E_{12}$, and $E_{13}$ pre-computed, and we use them to compute the epipolar lines in the 2nd and the 3rd image that correspond to the fixed virtual correspondence of the 1st image. We also compute the epipolar lines in the 1st image that correspond to the predicted virtual correspondences in the 2nd and 3rd image. The final loss is the sum of the symmetric epipolar errors. 
% \TODO{You measure the epipolar errors only in the first image?} we measure symm epipolar errors between 12 and 13. Please check if it is written well. 
% \TODO{project is probably the wrong word here as we are not doing any projection into 3D and back into 2D. Do you mean that you compute the epipolar lines using the ground truth essential matrices and use them to measure the error?} correct. I was using the wrong words. Changed. Please check.

For both training and validation, we use synthetic data. Our synthetic dataset contains 1M input instances. 70\% of the dataset is used for training while the rest 30\% is used for validating the performance of the network. We generate 10K 3D points inside a 100$\times$100$\times$100 cube, and to generate each instance, we pick 4 random points and project them to 3 cameras with random rotations and translations that view the cube from a random distance between 130 to 150 units. 
% \TODO{What is a reasonable distance? Can we be more specific?}
% \TODO{So, the training and validation datasets likely contain shared points, no? Do we think we would be better if we had completely separate sets? I don't think this is much of an issue though.}

% \TODO{We promised to explain the training data generation: we should explain that we only use synthetic data, how we generate the synthetic data, how much synthetic data we generate / use for training and validation} most of these things we mentioned in the paper. I will also add things here.

The network is implemented in PyTorch \cite{paszke2017automatic}, and we use the Adam optimizer \cite{DBLP:journals/corr/KingmaB14} for the training. We train it in batches of 2048 input instances, with a fixed learning rate of 1e-5. In our experiments, the network converges in about 1500 epochs.
% 
We will make the network, the training data, and our two solvers publicly available.
% \TODO{We should explain how we train the network: what is the optimizer? what is the learning rate? do we use a fixed learning rate or do we adjust it over time (and if so, how?)? for how long do we train? does the network converge in that time? \etc} added some details. Let me know if we need more  

\begin{figure*}[t]
    \centering
	\begin{subfigure}[t]{0.42\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_t12_final2.pdf}
	 \caption{}
    	\label{fig:ground_rot_error_ori1}
	\end{subfigure}
	\begin{subfigure}[t]{0.42\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_t13_final2.pdf}
		 \caption{}
    	\label{fig:ground_tra_error_ori1}
	\end{subfigure}\\
	\begin{subfigure}[t]{0.42\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_R13_final2.pdf}
		 \caption{}
		\end{subfigure}
  \begin{subfigure}[t]{0.42\textwidth}
	    \includegraphics[width=1.0\textwidth]{figures/err_max_avg2.pdf}
		 \caption{}
		\end{subfigure}
    \caption{ Results of the noise experiment showing from the main paper showing 
    (a) $e(\M t_{12})$,  (b) $e(\M t_{13})$, (c) $e(\M R_{13})$ and (d) $\texttt{max}(\texttt{avg}(e(\M R_{12}),e(\M R_{13})),\texttt{avg}(e(\M t_{12}),e(\M t_{13})))$ as functions of the noise scale in pixels, where $\M R_{ij}$ and $\M t_{ij}$ are the relative rotation and translation of the $i^{\text{th}}$ and $j^{\text{th}}$ views, respectively.}
    \label{fig:noise_supp}
\end{figure*}

\section*{Experiments}
 This section provides more details on the noise experiment presented in Sec.~5 of the main paper, as well as results showing the potential of the proposed method based on virtual correspondences to solve minimal problems using sub-minimal samples of points. 
 
\subsection*{Noise experiments}
In Sec.~5 of the main paper, we showed the performance of our solvers and the state-of-the-art algorithms \wrt increasing image noise. 
Figure~3 of the main paper showed results for a subset of all error measures.  
Here, in Figure~\ref{fig:noise_supp}, we show the individual errors (a) $e(\M t_{12})$, (b) $e(\M t_{13})$, (c) $e(\M R_{13})$, as well as (d) the $\texttt{max}(\texttt{avg}(e(\M R_{12}),e(\M R_{13})),\texttt{avg}(e(\M t_{12}),e(\M t_{13})))$ error, which corresponds to the pose error that is reported in the real data experiments in Table 1 of the main paper.
Here, $e(\M R_{ij})$ is the error of the estimated relative rotation  between cameras $i$ and $j$, computed as the angle in the axis-angle representation of $\M R_{ij}^{-1}\M R_{ij}^{\M{GT}}$ and $e(\M t_{ij})$ is the error of the estimated translation computed as the angle between the two unit vectors corresponding to the translations. 

The results in Figure~\ref{fig:noise_supp} are again represented by a boxplot function which shows the 25\% to 75\% quantiles as a box with a horizontal line at median. The crosses show data beyond 1.5 times the interquartile range.

As can be seen in the figure, and as already observed in the main paper, the \sftm solver produces slightly better translation estimates than the \sftl solver, but also produces slightly worse rotation estimates compared to the \sftl solver. 
For all solvers, the translation errors dominate the rotation errors. 
Thus, the combined error measure used in real experiments shown in the paper is dominated by the translation errors. 


\subsection*{Essential matrix estimation using a virtual correspondence}
While the ``mean-point'' \sftm solver, presented in Sec. 3.3 of the main paper, performs slightly worse than the ``learning-based'' \sftl solver, it returns results that are comparable  to the results of the state-of-the-art homotopy continuation \sfhc solver~\cite{Hruby_cvpr2022} (\cf Table 1 of the main paper).
% 
The ``mean-point" \sftm solver actually does not exploit information from all three views when generating a virtual correspondence. It uses only information from three point correspondences in two views and is thus not specific to the 3-view scenario considered in the paper. 
This suggests that the proposed method for generating virtual correspondences 
 can be used to solve other minimal problems using sub-minimal samples inside RANSAC. % in some scenarios.

Here, we
show preliminary results for the well-known 5-point relative pose problem, where we sample only four point correspondences inside RANSAC and generate the $5^\text{th}$ correspondence (a) as a mean point of three corresponding points in both images (the \texttt{4p(M)} solver), (b) using a network similar to the one presented in Sec. 3.2 of the main paper and in Sec. 1 of this supplementary material (the \texttt{4p(L)} solver). 
Note that the network was trained only on four points in two views instead of four points in three views. % \ie the \texttt{4pt(L)} solver.
% \TODO{@Daniel: are we using this network in your experiment?}  

%We tested the 5 point essential matrix estimation problem with virtual correspondences
In our experiments, we tested the solvers
on the same two scenes (\ie, Sacre Coeur and St.\ Peter's Square) from the PhotoTourism~\cite{snavely2006photo} dataset that we used in the main paper.
The 4,950 image pairs for each scene, were selected by the Image Matching Challenge 2020~\cite{IMC2020}. 
The challenge also provides point correspondences together with the intrinsic calibration matrices and ground truth camera poses obtained from a COLMAP reconstruction~\cite{Schoenberger2016CVPR}.

We run the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004}, and the proposed \texttt{4p(M)} and \texttt{4p(L)} solvers which, respectively, generate the fifth correspondence by taking the mean of the first three ones, or via the proposed transformer-based neural network. 
We also show the results of the oracle \texttt{4p(O)} solver with a 
% an oracle 
fifth correspondence that is selected ensuring that it is consistent with the ground truth epipolar geometry. 
All minimal solvers are used inside GC-RANSAC~\cite{barath2017graph}.
% \TODO{Daniel: Are you showing both datasets in one table? Are you showing avg and med over all images in both scenes? 4950 image pairs are all together or in each scene?}

The results, over all 9,900 image pairs from both scenes, are reported in Table~\ref{tab:phototourism_real_Test1}. %\TODO{...}
%
%We show that even thought 4 (3) points in two views define infinite number of camera poses that can observe these points, we show that, in practice, such a correspondence is usually a quite good approximation of a correct correspondence and the solver that 
While the virtual $5^\text{th}$ correspondences generated in the proposed \texttt{4p(M)} and \texttt{4p(L)} solvers can be noisy, both solvers show only slightly worse results than the %minimal 
%well-known 
\texttt{5pt} solver, which uses a more accurate $5^\text{th}$ correspondence,  
inside GC-RANSAC. 
This shows the potential for applying such a sub-minimal solver in scenarios with high outlier ratios and noisy data, where sampling one less point may lead to faster run-times and where the higher noise of the $5^\text{th}$ correspondence will only have a limited impact.

\begin{table}[]
    \centering
    \setlength{\tabcolsep}{4.8pt}
    \resizebox{1.0\columnwidth}{!}{\begin{tabular}{r | c c c c c c }
        \toprule
        \midrule
        & AVG ($^\circ$) $\downarrow$ & MED ($^\circ$) $\downarrow$ & AUC@5$^\circ$ $\uparrow$ & @10$^\circ$ & @20$^\circ$ & Time (s) $\downarrow$ \\
        \midrule
        %consecutive 5PC 
        5pt & 5.04 & 0.89 & 63.71 & 74.45 & 83.11 & 0.04 \\
        4p(M) & 5.53 & 0.93 & 61.48 & 72.19 & 81.30 & 0.03 \\
        4p(L) & 5.49 & 0.89 & 61.84 & 72.23 & 81.23 & 3.24 \\
        \midrule
        4p(O) & 4.40 & 0.81 & 65.30 & 75.88 & 84.43 & 0.03 \\
        \hline
    \end{tabular}}
    \caption{The average and median pose errors in degrees, and Area Under the recall Curve (AUC), thresholded at 5$^\circ$, 10$^\circ$, and 20$^\circ$, as well as the average run-time (in seconds) on 9,900 image pairs from two scenes of the PhotoTourism dataset~\cite{IMC2020}.}
    \label{tab:phototourism_real_Test1}
\end{table}

The results of the oracle \texttt{4p(O)} solver shows that there is still some space for improvement when ``learning'' the $5^{th}$ virtual correspondence. However, in this case, the situation is more ``challenging'' than for the 4p3v problem. For the two-view problem, four points define an infinite number of camera poses that can observe these points, \ie, we have an under-constrained problem. This means that while the proposed ``mean-point'' strategy and the proposed network can return quite good correspondences for some image pairs and scenes, there is no guarantee that it will not result in larger errors for some other image pairs. % they can result in larger errors. 
%This also partially explains larger average pose errors that are computed over all 9,900 image pairs in Table~\ref{tab:phototourism_real_Test}.


\end{document}