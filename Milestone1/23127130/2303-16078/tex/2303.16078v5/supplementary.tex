\section*{Supplementary Material}
%%%%%%%%% BODY TEXT
This supplementary material provides additional details and experimental results promised in the main paper: 
Sec.~\ref{sec:estimating} provides the proof on the bound of the epipolar error of the mean point correspondence mentioned in Sec.~3.1 of the main paper, additional synthetic and noise experiments that were discussed in Sec.~4 of the main paper, accuracy-speed trade-off results for two-view approximate geometry inside RANSAC (see Sec.~4 of the main paper), and additional details and plots on more scenes for the mean point correspondence accuracy (see Sec.~4 of the main paper). 
Sec.~\ref{sec:exp:ablations} contains ablation studies to validate our choices regarding the modifications discussed in Sec.~3.2 of the main paper.
Sec.~\ref{sec:exp} provides results for the accuracy-speed trade-off for individual scenes from the PhotoTourism~\cite{IMC2020} and Cambridge Landmarks~\cite{kendall2015cambridge} datasets, evaluations of the three-view solvers for different thresholds inside RANSAC (see Sec.~4 of the main paper), runtimes of the proposed and state-of-the-art solvers for the 4p3v problem, semi-synthetic experiments for increasing outliers ratios on a scene from PhotoTourism~\cite{IMC2020}, details and results on an alternative evaluation measure (see Sec.~4 of the main paper), and results with GC-RANSAC (see Sec.~4 of the main paper).
\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother
\blfootnote{$^\ast$ Equal contribution}

\section{ Approximate camera geometry}
In this section, in addition to the experiments presented in Sec. 4  of the main paper (paragraph ``Approximate camera geometry"), we present additional experiments and results to support our idea of estimating approximate geometry in the first two views. We start 
with the proof on the bound of the epipolar error of the mean-point correspondence used in the proposed \sftm-based solvers (see Sec 3.1 of the main paper). 
Next, Sec.~\ref{sec:independentc} discusses why the mean-point correspondence provides an additional constraint (compared to the original point correspondences) that can be used to estimate the essential matrix. 
Then, to further assess the accuracy of the two-view variants of our approximate solvers (outside of RANSAC), \ie, \texttt{4p(A)}, \texttt{4p(M)},  and \texttt{4p(M$\pm \delta$)}, we design two additional synthetic experiments (see Sec.~\ref{sec:exp:synth}). 
The goal of these synthetic experiments is to study how the accuracy of approximate solutions varies with varying properties of the scene and the cameras.
Moreover, Sec.~\ref{sec:exp:synth} provides a synthetic noise experiment on 
%ground-truth 
data extracted from a real scene from the ETH3D dataset~\cite{Schops_2017_CVPR}, outside of RANSAC for the three-view solvers. Lastly, Sec.~\ref{sec:twoview} contains a speed-accuracy evaluation of the two-view variants of the proposed solvers, inside Poselib RANSAC, and in Sec.~\ref{sec:bary} we study the accuracy of the mean point correspondence (as in Fig. 3 of the main paper).

\label{sec:estimating}

\begin{figure}[t]
     \centering
     \includegraphics[width=1\columnwidth]{figures/4p3v_illustration_3-crop.pdf}
          \caption{Illustration of the geometric configuration considered in the proof of Lemma~\ref{lemma:inter}.}
     \label{fig:illustration}
 \end{figure}

\subsection{Proof of the bounds on the epipolar error} 
\label{sec:proof}
While the mean point correspondence $\V m^1 \leftrightarrow \V m^2$  used in the \sftm-based solvers can provide a good approximation of a correct correspondence, such a correspondence can be noisy. %\footnote{
Note that all state-of-the-art 4p3v solvers (including 
\sfhc~\cite{Hruby_cvpr2022} and 
%\sfep~ 
the solver from~\cite{DBLP:journals/ijcv/NisterS06}) rely on certain approximations without establishing theoretical proofs to quantify their accuracy. 
In the \sfhc solver~\cite{Hruby_cvpr2022}, the failures that appear quite often are usually the results of tracking a geometrically incorrect solution inside the homotopy continuation method.\footnote{The solver is tracking only one from 272 solutions of the relaxed version of the 4p3v problem and this solution does not need to be a geometrically correct one.} Thus, this solution can be arbitrarily far from the correct solution. The solver from~\cite{DBLP:journals/ijcv/NisterS06}  requires sampling epipoles from a $10^{th}$-degree curve on which the true epipole must lie. For any selected  point on the curve of epipoles, the error of the sampled epipole is not bounded, since the true epipole can lie anywhere on the unbounded curve. The curve is unbounded since the epipole can be located arbitrarily far away from the image center based on the relative pose of the two cameras (up to infinity for sideways motion). 

\begin{figure*}[htbp]
    \centering

    % TikZ figure at the top (only once)
    \begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend columns =7, % comment for column display
        /tikz/every even column/.append style={column sep=0.05cm}
        },
        legend image post style={xscale=1}
        ]
        \addlegendimage{Seaborn2}
        \addlegendentry{\texttt{5p(E)}~\cite{Nister-5pt-PAMI-2004}};
        \addlegendimage{Seaborn4}
        \addlegendentry{\texttt{4p(M)}};
        \addlegendimage{Seaborn5}
        \addlegendentry{\texttt{4p(M$\pm \delta$)}};
        \addlegendimage{Seaborn3}
        \addlegendentry{\texttt{4p(A)}};
        \addlegendimage{}
        \addlegendentry{};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{w/ \texttt{ENM}};
        \end{axis}
    \end{tikzpicture}

    % Subfigure 1
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_2px_gau_new_p.png}
        \caption{}
        \label{fig:subfig102}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_4px_gau_new_p.png}
        \caption{}
        \label{fig:subfig202}
    \end{subfigure}
    
    % Subfigure 3
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_2px_uni_p.png}
        \caption{}
        \label{fig:subfig302}
    \end{subfigure}
    \hfill
    % Subfigure 4
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_4px_uni_p.png} 
        \caption{}
        \label{fig:subfig402}
    \end{subfigure}
    \caption{{Results from a synthetic experiment evaluating the accuracy of two-view variants of our solvers as a function of the angle between the principal axes of the cameras are presented. The top row, comprising Subfigures (a) and (b), shows results for Gaussian noise with standard deviations of 2px and 4px, respectively. The bottom row, consisting of Subfigures (c) and (d), presents results for uniform noise with 2px and 4px deviations, respectively. The outlier ratio is set to 20\% in all cases. From the solutions for each solver and sample we select the one with the lowest error.}}
    \label{fig:synth_angle_4px}
\end{figure*}

\begin{figure*}[htbp]
    \centering

    % TikZ figure at the top (only once)
    \begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend columns =7, % comment for column display
        /tikz/every even column/.append style={column sep=0.05cm}
        },
        legend image post style={xscale=1}
        ]
        \addlegendimage{Seaborn2}
        \addlegendentry{\texttt{5p(E)}~\cite{Nister-5pt-PAMI-2004}};
        \addlegendimage{Seaborn4}
        \addlegendentry{\texttt{4p(M)}};
        \addlegendimage{Seaborn5}
        \addlegendentry{\texttt{4p(M$\pm \delta$)}};
        \addlegendimage{Seaborn3}
        \addlegendentry{\texttt{4p(A)}};
        \addlegendimage{}
        \addlegendentry{};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{w/ \texttt{ENM}};
        \end{axis}
    \end{tikzpicture}

    % Subfigure 1
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_2px_gau_new_04out_p.png}
        \caption{}
        \label{fig:subfig104}
    \end{subfigure}
    \hfill
    % Subfigure 2
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=\textwidth]{figures/rebuttal/angle_cam_4px_gau_new_04out_p.png}
        \caption{}
        \label{fig:subfig204}
    \end{subfigure}

    \caption{{Results from a synthetic experiment evaluating the accuracy of two-view variants of our solvers as a function of the angle between the principal axes of the cameras are presented. %The Subfigures (a) and (b) 
    We present results for Gaussian noise with standard deviations of 2px and 4px, respectively. The outlier ratio is set to 40\% in all cases. From the solutions for each solver and sample we select the one with the lowest error.}}
    \label{fig:synth_angle_04out}
\end{figure*}

\begin{figure*}[t!]
    \centering

\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =7, % comment for column display
        /tikz/every even column/.append style={column sep=0.2cm},
        }
        ]
        
        \addlegendimage{Seaborn2}
        \addlegendentry{\texttt{5p(E)}~\cite{Nister-5pt-PAMI-2004}};
        \addlegendimage{Seaborn4}        \addlegendentry{\texttt{4p(M)}};
        \addlegendimage{Seaborn5}        \addlegendentry{\texttt{4p(M$\pm\delta$)}};
        \addlegendimage{Seaborn3}
        \addlegendentry{\texttt{4p(A)}};
        \addlegendimage{}
        \addlegendentry{};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{w/ \texttt{ENM}};
        \end{axis}
    \end{tikzpicture}
   
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[trim={2.5cm 0 2.5cm 0},clip, width=\textwidth]{figures/synthetic/distance_cam_p.png}
    \caption{}
    \label{fig:synth_dist}
    \end{subfigure}
    \hfill    
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[trim={2.5cm 0 2.5cm 0},clip, width=\textwidth]{figures/synthetic/depth_scene_p.png}
    \caption{}
    \label{fig:synth_depth}
    \end{subfigure}  
    
    \caption{Synthetic experiments for two-view solvers, measuring the pose error under varying camera distance from the scene and scene depths, with added 1px noise. In \textbf{(a)}, points are uniformly sampled within a 2000x2000x100 cube, and projected to cameras positioned at distances (in units) from the scene as indicated by the x-axis, looking towards the scene. In \textbf{(b)}, the depth of the scene is varied, with points sampled inside a 2000x2000x\textit{depth} cube as specified by the x-axis. Cameras are randomly placed at distances between 1000 and 1200 units from the scene, looking towards the scene. On the y-axis of both figures is the pose error measured as $\max\left(\M R_{err}, \M t_{err} \right)$. From the solutions for each solver and sample we select the one with the lowest error. The results are displayed by boxplots which shows the 25\% to 75\% quantiles as a box with a horizontal line at the median.}
    \label{fig:synth_depth_distance}
\end{figure*}

In contrast, 
the error of our mean point correspondence is bounded. %.}. 
The $\V m^1 \leftrightarrow \V m^2$ correspondence can be seen as a correspondence of points that are projections of the mean point of three 3D points. 
In this case, the error of both projections $\V m^1$ and $\V m^2$ can be computed as an error that is introduced by approximating the perspective projection using the para-perspective projection. The approximation error introduced by the para-perspective projection is studied in the literature and can be found \eg. in~\cite{Zhang2014, Horaud97}.

 However, we can also look at the $\V m^1 \leftrightarrow \V m^2$ correspondence from a different point of view. We can consider this correspondence as a correspondence in which we fix a point in one view, \eg, $\V m^1$, and generate a corresponding point in the second view.
 In this case, as mentioned in the main paper, it can be proven that the epipolar error of the mean point correspondence $\V m^1 \leftrightarrow\V m^2$ is bounded by the maximum distance of the mean point $\V m^2$ from the vertices of the triangle $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$.
Here we provide a simple proof.

\begin{lemma}
Let us assume two cameras with camera centers $\V C^1$ and $\V C^2$ that observe 3D points $X_i, X_j,$ and $X_k$ (see Figure~\ref{fig:illustration} for an illustration). Let $\left\{\V x_i^1,\V x_j^1,\V x_k^1\right\}$ and $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$ be the projections of these 3D points in camera 1 and camera 2, respectively. Let $\V m^1$ be the mean point of the points $\left\{\V x_i^1,\V x_j^1,\V x_k^1\right\}$ and let $\V E$  be the essential matrix between these two cameras, \ie, a matrix that satisfies $\V x_l^{2^\top} \V E \V x_l^1 = 0,\; l \in \left\{i,j,k\right\}$. Then the epipolar line $\V E \V m^1$ passes through the triangle $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$.
\label{lemma:inter}
\end{lemma}

\begin{proof}
The camera center $\V C^1$ and the 3D points $\V X_i, \V X_j,$ and $\V X_k$ form a tetrahedron $T^1$ (see Figure~\ref{fig:illustration}). The projections $\left\{\V x_i^1,\V x_j^1,\V x_k^1\right\}$ in the first camera lie at the edges of this tetrahedron $T^1$.
The ray from the camera center $\V C^1$ through the mean point $\V m^1$ thus lies inside the tetrahedron $T^1$ and intersects the plane defined by 3D points $\V X_i, \V X_j,$ and $\V X_k$ in a point $\V M$ that lies inside the triangle defined by $\left\{\V X_i,\V X_j,\V X_k\right\}$. 

The camera center $\V C^2$ and the 3D points $\V X_i, \V X_j,$ and $\V X_k$ form a tetrahedron $T^2$.
Again, the projections $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$ 
%in the second camera 
lie at the edges of the tetrahedron $T^2$.
The ray passing through the camera center $\V C^2$ and the 3D point $\V M$ lies inside the tetrahedron $T^2$ and thus intersects the image plane of the second camera at a point that lies inside the triangle defined by the points $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. 
By construction, the projection of $\V M$ into the second camera lies on the epipolar line $\V E \V m^1$. 
Therefore, the epipolar line $\V E \V m^1$ which is a line connecting this point and the epipole $\V e^2$, passes through the triangle $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. 
\end{proof}

It follows from Lemma~\ref{lemma:inter} that since the epipolar line $\V E \V m^1$ passes through the triangle $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$, the maximum distance of the mean point $\V m^2$ to the epipolar line $\V E \V m^1$ is equal to the maximum distance of $\V m^2$ to the vertices of the triangle.

\subsection{Mean-point constraint}
\label{sec:independentc}
As already mentioned in the main paper, under the assumption of a para-perspective projection, \ie, of affine geometry, the mean point of three 3D points is projected to the mean points of the 3D points' projections in both images~\cite{Zhang2014}.
Thus,
the mean point correspondence $\V m^1 \leftrightarrow \V m^2$ does not add a new constraint if used to estimate an affine camera.  This can be easily shown. In the case of affine cameras, the essential matrix $\M E_A$ has the form
\begin{equation}
 \M E_A  =  \begin{bmatrix}
0 & 0 & a\\
0 & 0 & b \\
c & d & f
\end{bmatrix} \enspace .
\end{equation}
Thus the epipolar constraint for the mean point correspondence $\V m^1 \leftrightarrow \V m^2$ with the homogeneous coordinates $\V m^1 = (\V x_i^1/3 + \V x_j^1/3 + \V x_k^1/3$), and $\V m^2 = (\V x_i^2/3 + \V x_j^2/3 + \V x_k^2/3$):
\begin{equation}
    (\V m^{2})^{\top}  \mathtt{E}_A \V m^{1} = 0 
\end{equation}
% \begin{equation}
%   [\frac{(\V x_i^1 + \V x_j^1 + \V x_k^1)^T}{3} 1] \cdot \mathtt{E}_A \cdot [[(x_i^2/3 + x_j^2/3 + x_k^2/3) 1] = 0,  
% \end{equation}
can be written as a linear combination of the epipolar constraint for the three input points, \ie  $\V (x_l^{2})^{\top}  \mathtt{E}_A \V x_l^{1} = 0,\, l \in \left\{i,j,k\right\}$.

This is not the case for perspective cameras. For perspective cameras, \ie, when estimating the full essential %(fundamental) 
matrix $\M E$, the mean point correspondence introduces an additional constraint. In this case the epipolar constraint  
\begin{equation}
    (\V m^{2})^{\top}  \mathtt{E} \V m^{1} = 0 \enspace, %,
    \label{eq:epipolarE}
\end{equation}
 after expansion, contains terms $x_a^1x_b^2,  a \neq b, \, a,b \in \left\{i,j,k\right\}$. 
Thus, the epipolar constraint~\eqref{eq:epipolarE} is not a linear combination of the individual epipolar constraints $ (\V x_l^{2})^{\top}  \mathtt{E} \V x_l^{1} = 0, \, l =i,j,k$.
Therefore, the mean point correspondence provides an independent constraint when used to estimate the epipolar geometry of perspective cameras.

\subsection{Synthetic Experiments}
\label{sec:exp:synth}
The
error of the relative poses estimated with the proposed approximate %correspondences %, however, 
\sftm-based and \sfaf-based solvers
depends on many aspects, \eg, the baseline and the view angles of the cameras \wrt the three points used to compute the mean point correspondence, the depth of these points, the size and shape of the triangles defined by the three points, the type of motion of the cameras, the depth of the scene and the distance of cameras from the scene, the level of noise in the correspondences, \etc 
Isolating the impact of the individual aspects, \eg, through experiments on synthetic data, is highly non-trivial (\eg, how to generate realistic synthetic scenarios that allow conclusions to generalize to real-world scenarios) and analysing the co-dependencies between different aspects on the overall performance seems to need a paper on its own. Moreover, the effect of approximation introduced by using para-perspective projection was already studied in the literature~\cite{Zhang2014,Horaud97}.

In the main paper, we thus presented mostly results on real-world scenes, without trying to isolate individual factors (see Figure~3 and Table~1 in the main paper).  However, we also tested interesting camera and scene setups using synthetically generated data.

We extend the synthetic experiment for increasing angles between the projection rays of the cameras in the main paper (Fig.~2 of the main paper), by investigating the impact of increased noise, alternative noise models, and higher outlier ratio. Similar to the experiment of increasing angles, we evaluate the two-view solvers (outside of RANSAC) in two additional interesting scenarios. 
The goal is to study the effect of the proposed approximations on the relative pose estimation under varying properties of the scene and the cameras. 

Additionally, we test the performance (outside of RANSAC) of our proposed approximate solvers and the state-of-the-art solvers for the 4p3v problem \wrt increasing image noise added to ground-truth correspondences extracted from a scene from the ETH3D dataset~\cite{Schops_2017_CVPR}.
As an evaluation metric for the two-view geometry, we use the pose error measured as $\max\left(\M R_{err}, \M t_{err} \right)$~\cite{IMC2020}.

\PAR{Increasing angle between principal axes of cameras.}
In Fig.~\ref{fig:synth_angle_4px}, we present results analogous to Fig.~2 of the main paper, but for $\sigma=2$px and $\sigma=4$px noise levels. We also include results for the uniform noise model (noise is evenly distributed in range $[-\sigma, \sigma]$). As in Fig.~2 of the main paper, the synthetic data contain 20\% outliers. As in the results presented in Fig.~2 of the main paper, the accuracy of both approximate solvers decreases as the angle increases, where $\texttt{4p(A)}$ demonstrates notably lower accuracy than $\texttt{4p(M)}$ and \texttt{4p(M$\pm \delta$)}. However, ENM singnificantly improves the accuracy, with $\texttt{4p(M$\pm \delta$)+ENM}$ achieving the same or slightly better accuracy than $\texttt{5pt+ENM}$ for angle $\leq 30^\circ$. In Fig.~\ref{fig:synth_angle_04out} we present results for Gaussian noise and higher outlier ratio, in particular 40\% outliers. The results are consistent with those of Fig.~\ref{fig:synth_angle_4px}, though the increased outlier ratio leads to a higher error when using ENM.

\begin{figure*}[t!]
    \centering
    \resizebox{1.0\linewidth}{!}{
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, % comment for column display
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftm}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmd};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfaf};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        
        % \addlegendimage{white}
        % \addlegendentry{~};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{\texttt{+R} w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{\texttt{+R} w/ \texttt{ENM}};
        
        \end{axis}
    \end{tikzpicture}}
    \includegraphics[width=0.85\textwidth]{figures/rebuttal/realtest_cr_p.png}
    \caption{{Noise experiment showing 
    the pose error measured as $\text{max}\left(0.5 (\M R_{err}^{12} + \M R_{err}^{13}), 0.5 (\V t_{err}^{12} + \V t_{err}^{13})\right)$, as a function of the noise scale in pixels. Here, $\M R_{ij}$ and $\M t_{ij}$ are the relative rotation and translation of the $i^{\text{th}}$ and $j^{\text{th}}$ views, respectively. From the solutions for each solver and sample we select the one with the lowest error. Note that the errors observed for the pure \texttt{4p(A)} solver (without \texttt{ENM} and without refinement) are outside of the error range shown in this plot.}}
    \label{fig:noise}
\end{figure*}

\PAR{Increasing distance of cameras to the 3D scene.}
It is known that the quality of the affine approximation, \ie, the approximation of the perspective projection using the para-perspective projection, depends on the distance of the points from the camera~\cite{Zhang2014}. 
Thus in the first experiment, we evaluate the performance of all solvers w.r.t. increasing distance of the cameras to the 3D scene.

We perform this experiment on 10k synthetically generated instances. 
% In this case, f
For each of the 10k instances, we uniformly sample 3D points inside a 2000x2000x100 unit cube, and the camera centers are placed at random points with the same distance from the scene. % indicated by the values on the x-axis. 
The distances tested (in units) are $\{ 500, 1000, 1500, 2000, 2500, 3000\}$. The cameras are generated such that they look towards the scene. We add 1px noise to the projected points. Note that the scene is generated such that the projections of the points cover a large portion of the image for cameras at all distances.


Fig.~\ref{fig:synth_dist} shows the results of this experiment represented
by the boxplot function, which shows values between the $25\%$ and $75\%$ quantiles as a box with a horizontal line at the median.
As expected, the errors of the \texttt{4p(A)} solver decrease as the distance of the cameras from the scene increases, since affine geometry can be better satisfied with larger distances from the scene. Without considering \texttt{ENM}, \texttt{5p(E)} is the best performing solver. 
The errors of the \texttt{5p(E)} solver are increasing with increasing distance of the cameras from the scene (due to the fact that fixed image noise is generating larger errors for points that are farther from cameras).  This effect is less visible for the proposed \texttt{4p(M)} and \texttt{4p(M$\pm \delta$)} solvers
since for these solvers the error is originally more dominated by the error in the mean point correspondence.
When considering \texttt{ENM}, \texttt{5p(E)}, \texttt{4p(M)}, and \texttt{4p(M$\pm \delta$)} solvers perform similarly, with \texttt{4p(M$\pm \delta$)} being the most accurate for distances $\geq 1500$. The \texttt{4p(A)} solver is also greatly improved when using \texttt{ENM}, reaching similar or even better accuracy than \texttt{5p(E)} (w/o \texttt{ENM}), for distances $\geq 1000$.

\PAR{Increasing depth of the 3D scene.}
In Fig.~\ref{fig:synth_depth}, instead of increasing the distance of the cameras to the 3D scene, we place the cameras randomly at distances between 1000 and 1200 units away from the scene, looking towards the scene, while changing the depth of the scene. In particular, the 3D points are generated uniformly at random inside a 2000x2000x\textit{depth} unit cube, where the depth of the scene is specified by the values on the x-axis. The tested depths are $\{ 10, 50, 100, 200, 500, 800, 1500, 2500\}$. We add 1px noise to the projected points. Without using \texttt{ENM}, the pose errors of \texttt{4p(A)} are visibly decreasing as the depth of the scenes increases. 
This is to be expected since increasing the scene depth increases the chance of sampling four points that are more consistent with the para-perspective / affine camera model (since the points are more likely to be farther away from the cameras). 
The remaining solvers, that is, \texttt{5p(E)}, \texttt{4p(M)}, and \texttt{4p(M$\pm \delta$)}, are not significantly affected by the changes in the depth of the scene. When using \texttt{ENM}, all tested solvers are improved significantly, with \texttt{4p(M$\pm \delta$)} being the most accurate in terms of pose error. 
When using \texttt{ENM}, the errors in the estimated poses increase with increasing scene depths, which is particularly visible for the \texttt{4p(A)} solver. 
This behavior is due to the fact that for points farther away from the camera, the same amount of image noise (1px) has a larger impact, thus leading to the non-minimal samples being more affected by noise. 
Still, using \texttt{ENM} clearly leads to significantly smaller errors for all solvers. 

\PAR{Noise experiments.}
\label{sec:exp:noise}
 %\TODO{Update - ZK}
%\PAR{Noise experiments.}
We test the performance of our solvers and the state-of-the-art solvers \wrt increasing image noise. 
We used the SfM model of the botanical garden scene (randomly selected from all scenes) from the ETH3D dataset~\cite{Schops_2017_CVPR} to obtain instances of 5 points in three views by identifying images in the scene that share 3D points. 
Perfect noise-free image correspondences are generated by projecting the 3D points into the images. 
We then add increasing amounts of normally distributed noise to these correspondences. 
We generated more than 1k instances. 
Note that the \sfhc solver was trained on the ETH3D dataset~\cite{Schops_2017_CVPR}.

The results for increasing noise in the image points are shown in Fig.~\ref{fig:noise}. % and~\ref{fig:noise_uncalibrated}. 
The figure shows boxplots of %
the pose errors measured in the same way as in our experiments in the main paper (\cf Sec.~4 in the main paper), \ie, as
$\text{max}\left(0.5 (\M R_{err}^{12} + \M R_{err}^{13}), 0.5 (\V t_{err}^{12} + \V t_{err}^{13})\right)$.\footnote{Here $\M R_{err}^{ij}$  is the error of the estimated relative rotation between cameras $i$ and $j$, computed as the angle in the axis-angle representation of $\M R_{ij}^{-1}\M R_{ij}^{\M{GT}}$, and $\V t_{err}^{ij}$ is the error of the estimated translation computed as the angle between the two unit vectors corresponding to the translations~\cite{IMC2020}.} 
{The errors are zoomed into an interesting interval and are shown as functions of varying Gaussian noise from $0$px to $16$px.}

Due to the
approximations used in our proposed 
\sftm-based and \sfaf-based solvers, 
%\sftl and \sftm 
these solvers exhibit non-zero errors for zero noise. However, at noise levels %\newtext
{$\geq 4$px},  
our 
%\sftmR and 
\sftmdR solvers return comparable or even better (w/ \texttt{ENM}) results than the \sft solver. 
For noise %\newtext
{$\geq 8$px},  
% \newtext
{also the \sftmR solver with \texttt{ENM} returns  slightly more accurate poses than the \sft solver with \texttt{ENM}.}
In general, the effect of increasing image noise is
%much 
less visible for approximate \sftm-based and \sfaf-based solvers. In this case, the error of the approximation is dominating the error introduced by the noise in the image correspondences. While for \sfaf-based solvers the approximation error is dominant at all noise levels, for \sftm-based solvers,  at noise %\newtext
{$\geq 4$px}, the error introduced by the approximate mean point correspondence (and points in their vicinity in $\delta$-based solvers) is suppressed by the error introduced by noise in the remaining point correspondences.\footnote{This can be seen from the comparable pose accuracy of the \texttt{5pt+P3P} and \texttt{4p3v(M)} solvers for 
%\newtext
{$\geq 8$px} noise, and the comparable accuracy of the \texttt{5pt+P3P} and \texttt{4p3v(M$\pm\delta$)} solvers for %\newtext
{$\geq 4$px} noise.} 
Note that, although the pose errors for 
%\sfafR with \texttt{ENM}
the \texttt{4p3V(A)+R+ENM} solver
are higher than those of the rest of the solvers,
%what matter inside RANSAC,
%are the $10^{\text{th}}$ and $20^{\text{th}}$ percentiles or the pose error, which are reasonably low, 
as shown in our real experiments, this solver still returns reasonably low errors 
%(see $25\%$ quantiles)
to provide local optimization (LO) within RANSAC with a good initialization in real-world settings.
Further, note that the \sft solver samples one more point (real correspondence) in the first two cameras, and these points are affected only by the considered noise.
This shows that the mean point correspondence used in the \sftm-based solver is a good approximation to a real correspondence. 
The recent state-of-the-art \sfhc solver~\cite{Hruby_cvpr2022} is failing in about 50\% of the instances for noiseless data, even though the solver was trained on the ETH3D dataset. Thus, the median errors are significantly larger than the median errors of the remaining solvers. 

\begin{figure}[!t]
    \centering
    \resizebox{0.8\linewidth}{!}{
\begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =4, % comment for column display
        /tikz/every even column/.append style={column sep=0.2cm},
        }
        ]
        
        \addlegendimage{Seaborn2}
        \addlegendentry{\texttt{5p(E)}~\cite{Nister-5pt-PAMI-2004}};
        \addlegendimage{Seaborn4}        \addlegendentry{\texttt{4p(M)}};
        \addlegendimage{Seaborn5}        \addlegendentry{\texttt{4p(M$\pm\delta$)}};
        \addlegendimage{Seaborn3}
        \addlegendentry{\texttt{4p(A)}};
        \addlegendimage{white}
        \addlegendentry{~}

        \addlegendimage{black!30}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/ \texttt{ENM}};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \end{axis}
    \end{tikzpicture}}
    
    \includegraphics[width=0.8\linewidth]{figures/poselib_graphs/twoview_pt_5.0t-graph-pairs-features_superpoint_noresize_2048-LG_pose.pdf}
    
    \includegraphics[width=0.8\linewidth]{figures/poselib_graphs/twoview_pt_5.0t-graph-pairs-features_superpoint_noresize_2048-LG_pose-affine.pdf}
    \caption{Speed-accuracy evaluation of various solvers for two view relative pose estimation, evaluated using PoseLib~\cite{PoseLib} on 12 scenes from the Phototourism dataset~\cite{IMC2020} (excluding \textit{St.~Peter's Square}). We report the AUC@10$^\circ$ of the pose error and vary the number of Poselib RANSAC iterations ($\{10, 20, 50, 100, 200, 500, 1000\}$) for a fixed 5 px epipolar threshold. The top plot is a zoomed-in version of the bottom plot. }
    \label{fig:twoview}
\end{figure}

\subsection{Two-view approximate solutions inside RANSAC}
\label{sec:twoview}
In the next experiment, we evaluate the discussed two-view solvers, \ie, the \texttt{5p(E)}, \texttt{4p(M)}, \texttt{4p(M$\pm \delta$)}, and \texttt{4p(A)} solvers,  inside RANSAC as well.
This experiment indicates how the proposed approximate solvers would have behaved if used as two-view solvers. Note that in the two-view case, the proposed filtering (\texttt{+F}) and refinement (\texttt{+R}) using the $4^{th}$ point correspondence in the third view are not applicable.


Fig.~\ref{fig:twoview} shows the speed-accuracy evaluation of the solvers for the problem of two view relative pose estimation evaluated using PoseLib RANSAC~\cite{PoseLib} on 12 scenes from the Phototourism dataset~\cite{IMC2020} (excluding \textit{St.~Peter's Square}) with pairwise point correspondences obtained using~\cite{detone2018superpoint, lindenberger2023lightglue}. The statistic reported is the AUC@10$^\circ$ of the pose error for a varied number of RANSAC iterations ($\{10, 20, 50, 100, 200, 500, 1000\}$) and a fixed epipolar threshold of 5px. The upper figure is a zoom-in of the lower figure to an interesting interval, where differences between the solvers are more visible. Although all proposed solvers (except the %\sfaf 
\texttt{4p(A)} solver without \texttt{ENM}) have a performance comparable to that of the state-of-the-art two view \texttt{5pt} solver, the \texttt{5pt} solver is the best performing one for the two-view scenario. This result is not surprising, given the well-known good performance (in terms of speed and accuracy) of the \texttt{5pt} solver and not very high outlier contamination of the data (for which sampling one point less would have potentially had a more visible effect). It also indicates that the proposed modifications, \ie,  the filtering \texttt{+F} the and refinement \texttt{+R}, for the three-view scenario are important and are making the proposed 4p3v approximate solvers practical and more precise than the \sft sovler. 

\begin{figure*}[t!]
    \centering
    \begin{tikzpicture}
    \node[anchor=south west, inner sep=0] (image) at (0,0) {\includegraphics[width=0.24\textwidth]{figures/bary_4p/st_peters_bary_sed.png}};
        \begin{scope}[shift={(image.south west)}, x={(image.south east)}, y={(image.north west)}]
            \fill[white] (0.85, 0.93) rectangle (1, 1); % Adjust coordinates as needed
            \node[anchor=center] at (0.93, .97) {\tiny $\times 10^{\scalebox{0.5}[1.0]{\( - \)}3}$};
        \end{scope}
    \end{tikzpicture}   
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/st_peters_bary_rotation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/st_peters_bary_translation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/st_peters_bary_inlier.png}

    \hfill
    
    \begin{tikzpicture}
    \node[anchor=south west, inner sep=0] (image) at (0,0) {\includegraphics[width=0.24\textwidth]{figures/bary_4p/sacre_coeur_bary_sed.png}};
        % Draw the white rectangle (adjust the coordinates)
        \begin{scope}[shift={(image.south west)}, x={(image.south east)}, y={(image.north west)}]
            \fill[white] (0.85, 0.93) rectangle (1, 1); % Adjust coordinates as needed
            \node[anchor=center] at (0.93, .97) {\tiny $\times 10^{\scalebox{0.5}[1.0]{\( - \)}3}$};
        \end{scope}
    \end{tikzpicture}   
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/sacre_coeur_bary_rotation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/sacre_coeur_bary_translation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/sacre_coeur_bary_inlier.png}

    \hfill

    \begin{tikzpicture}
    \node[anchor=south west, inner sep=0] (image) at (0,0) {\includegraphics[width=0.24\textwidth]{figures/bary_4p/temple_nara_japan_bary_sed.png}};
        % Draw the white rectangle (adjust the coordinates)
        \begin{scope}[shift={(image.south west)}, x={(image.south east)}, y={(image.north west)}]
            \fill[white] (0.85, 0.93) rectangle (1, 1); % Adjust coordinates as needed
            \node[anchor=center] at (0.93, .97) {\tiny $\times 10^{\scalebox{0.5}[1.0]{\( - \)}3}$};
        \end{scope}
    \end{tikzpicture}  
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/temple_nara_japan_bary_rotation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/temple_nara_japan_bary_translation.png}
    \includegraphics[width=0.24\textwidth]{figures/bary_4p/temple_nara_japan_bary_inlier.png}


\caption{Left to right: Distribution of the average symmetric epipolar error (top: 0.3337, 0.3327) (middle: 0.3319,    0.3308) (bottom: 0.3355, 0.3290); rotation error (top: 0.3373, 0.3349) (middle: 0.3373,    0.3347) (bottom: 0.3261, 0.3496); translation error (top: 0.3336, 0.3417) (middle: 0.3325,    0.3382) (bottom: 0.3213, 0.3515); and percentage of inliers gathered (top: 0.3266, 0.3434) (middle: 0.3377,    0.3354) (bottom: 0.3198, 0.3552), as a function of the barycentric coordinates of the triangle in the second image \wrt the mean point of the corresponding triangle in the first image %, for (a) Shop Facade from the Cambridge Landmark dataset and (b,c,d) 
on 485k four-tuples of correspondences from scenes (top) \textit{St.~Peter's Square}, (middle) \textit{Sacre Coeur}, and (bottom) \textit{Temple Nara Japan} from the PhotoTourism dataset~\cite{IMC2020}. For each metric, we fit a 2D Gaussian distribution and report the mean of the distribution in brackets.}
\label{fig:mean_stats_pt}
\end{figure*}

\subsection{ Accuracy of the mean point correspondence} 
\label{sec:bary}

Fig.~3 in the main paper showed results obtained by establishing correspondences between the mean of the triangle in one image and various points in the triangle in the second image. 
We expressed points in the second triangle via their barycentric coordinates and uniformly sample $19 \times 19$ barycentric coordinates $(a,b)\in [0,1]^2$, such that $a+b \leq 1$ (ensuring 
points inside the triangle). 
The %third barycentric 
3rd coordinate is given as $c = 1-a-b$. 
For each correspondence, we measured the symmetric epipolar error \wrt the ground truth %relative 
pose, %the 
translation and rotation errors, and the percentage of inliers.
%consistent with the pose obtained with the \texttt{5pt} solver applied on the approximate and the four real correspondences. 
Fig.~3 in the main paper showed the rotation error and percentage of inliers, as observed %gathered results 
for the \textit{St.~Peter's Square} scene from the PhotoTourism dataset~\cite{IMC2020}. 
Here,  Fig.~\ref{fig:mean_stats_pt} shows the same statistics, including translation and symmetric epipolar errors, for the \textit{St.~Peter's Square} scene already used in the main paper (Fig.~\ref{fig:mean_stats_pt} (top row)), and two more scenes from the PhotoTourism dataset: %\textit{St.~Peter's Square} (top row), 
\textit{Sacre Coeur} (Fig.~\ref{fig:mean_stats_pt} (middle row)), and \textit{Temple Nara Japan} (Fig.~\ref{fig:mean_stats_pt} (bottom row)). 


As with Fig.~3 in the main paper, 
to suppress the effect of discrete sampling, 
%of points, 
for each metric, we fit a 2D Gaussian distribution and report the mean value (in barycentric coordinates) as numbers in brackets in the caption of the figure. 
As can be seen, the same conclusion can be drawn from Fig.~\ref{fig:mean_stats_pt} as from Fig.~3 in the main paper: 
The optima of the studied metrics are reached very close to the mean point of the triangles, which has barycentric coordinates $(0.\bar{3}, 0.\bar{3})$. 
This validates our approach of using the mean point correspondence as an approximate correspondence in our \sftm-based solvers. 

\begin{table}[!t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{ l | l | c c | c c c}
\toprule
Estimator & \multicolumn{1}{|c|}{$\delta$} & AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ \\
\midrule

\multirow{10}{*}{\sftmd}
 & 0.2 & 4.03 & 2.09 & 57.81 & 73.48 & 84.67 \\
 & 0.1 & 3.99 & 2.03 & 58.29 & 73.71 & 84.78 \\
 & 0.09 & 3.99 & 2.02 & 58.52 & 73.95 & 84.93 \\
 & 0.08 & \textbf{3.95} & 2.04 & \underline{58.66} & \underline{74.11} & \textbf{85.04} \\
 & 0.07 & 4.02 & 2.03 & 58.63 & 74.01 & \underline{84.98} \\
 & 0.06 & 4.01 & \underline{2.01} & 58.62 & 73.92 & 84.90 \\
 & 0.05 & \underline{3.98} & \textbf{1.98} & \textbf{58.94} & \textbf{74.19} & \textbf{85.04} \\
 & 0.01 & 4.01 & 2.07 & 57.90 & 73.60 & 84.75 \\
 & 0.005 & 4.12 & 2.07 & 57.54 & 73.23 & 84.55 \\
 & 0.001 & 4.28 & 2.14 & 56.65 & 72.51 & 84.08 \\
\midrule
\multirow{10}{*}{\sftmdR}
 & 0.2 & 3.75 & \underline{1.87} & 61.36 & \underline{75.83} & \underline{86.07} \\
 & 0.1 & 3.75 & \underline{1.87} & 61.33 & 75.78 & 86.03 \\
 & 0.09 & 3.74 & \underline{1.87} & 61.39 & 75.81 & 86.02 \\
 & 0.08 & \textbf{3.71} & \underline{1.87} & \textbf{61.45} & \textbf{75.90} & \textbf{86.16} \\
 & 0.07 & 3.76 & \underline{1.87} & \underline{61.41} & 75.82 & 86.06 \\
 & 0.06 & 3.79 & \underline{1.87} & 61.40 & 75.81 & 86.04 \\
 & 0.05 & 3.75 & \textbf{1.86} & 61.38 & 75.79 & 86.03 \\
 & 0.01 & 3.75 & \underline{1.87} & 61.25 & 75.70 & 85.95 \\
 & 0.005 & \underline{3.73} & \underline{1.87} & 61.22 & 75.75 & 86.03 \\
 & 0.001 & 3.86 & 1.90 & 60.82 & 75.46 & 85.80 \\
\midrule
\multirow{10}{*}{\sftmdRC}
 & 0.2 & 3.78 & \underline{1.88} & 61.12 & 75.70 & 85.96 \\
 & 0.1 & 3.77 & \textbf{1.87} & 61.16 & 75.68 & 85.95 \\
 & 0.09 & 3.76 & \textbf{1.87} & 61.24 & 75.70 & 85.92 \\
 & 0.08 & \textbf{3.73} & \textbf{1.87} & \textbf{61.30} & \textbf{75.78} & \textbf{86.07} \\
 & 0.07 & 3.77 & \textbf{1.87} & \textbf{61.30} & 75.71 & \underline{85.99} \\
 & 0.06 & 3.80 & \textbf{1.87} & 61.27 & \underline{75.75} & \underline{85.99} \\
 & 0.05 & \underline{3.75} & \textbf{1.87} & \underline{61.28} & 75.73 & 85.98 \\
 & 0.01 & 3.78 & \underline{1.88} & 61.11 & 75.62 & 85.89 \\
 & 0.005 & 3.76 & 1.89 & 61.09 & 75.65 & 85.95 \\
 & 0.001 & 3.90 & 1.91 & 60.53 & 75.26 & 85.67 \\
\midrule
    \end{tabular}}
    \caption{Evaluation of the effects of the scale of the $\delta$ shift on the  \textit{St.~Peter's Square} scene from PhotoTourism~\cite{IMC2020}.}
    \label{tab:delta_ablation}
\end{table}


\section{Ablation studies}
%Making approximate solvers practical
%\subsubsection{Ablation studies}
\label{sec:exp:ablations}

This section contains ablation studies to validate our choices in modifications discussed in Sec. 3.2 of the main paper.


\PAR{Validation of $\delta$.} We tested our $\delta$-based solvers for different values of $\delta$ and measured their performance. In general, there is no common value of the $\delta$ shift that leads to the best results on all datasets. This is expected since the precision of the mean-point correspondence depends on many different factors, \eg, the viewing angles of the cameras, the type of the motion, the depth and spatial distributions of the 3D points, \etc 
We set the value for $\delta$ %and the total number of refinement iterations 
by evaluating their effects on the \textit{St.~Peter's Square} scene from the PhotoTourism dataset~\cite{IMC2020},  which we used for validation only and did not include it in the other results for PhotoTourism~\cite{IMC2020} in the paper.  
Tab.~\ref{tab:delta_ablation} shows how the different settings of the scale of the $\delta$ shift affect the accuracy of the $\delta$-based solvers. 
%Based on these experiments we use $\delta = 0.08$ as it provides the best results for \sftmd solver and is also close to the optimal value for its variants.
Based on these experiments, we use $\delta = 0.08$ as it typically provides the best or the second best %to the best 
results for all variants of the \sftmd-based solvers.
However, note that \sftmd-based solvers achieve a very similar accuracy even with different settings of $\delta$.
Thus, we can conclude that the choice of $\delta$ is not critical.
%, \ie, different values perform similarly.
In some scenarios, the choice of the optimal $\delta$ parameter may be  more scene-dependent and could potentially be set using learning-based approaches.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/poselib_graphs/st_peters_square_refinement_validation.pdf}
    \caption{Evaluation of the effects of the number of inner refinement (\texttt{+R}) iterations within the \sftmdRC solver on the \textit{St.~Peter's Square} scene from the PhotoTourism~\cite{IMC2020} dataset. Shown is the speed-accuracy evaluation, where the curves are obtained by varying the number of Poselib RANSAC iterations.}
    \label{fig:r_validation}
\end{figure}

\begin{figure}[!h]
    \centering
    \resizebox{0.95\linewidth}{!}{
    \begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =3, % comment for column display
        /tikz/every even column/.append style={column sep=0.2cm}
        }
        ]
        
        \addlegendimage{Seaborn4}        \addlegendentry{\sftm};
        \addlegendimage{Seaborn7}
        \addlegendentry{\sftmd};
        \addlegendimage{Seaborn9}
        \addlegendentry{\sftmdR};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC}; 
        \addlegendimage{Seaborn6}
        \addlegendentry{\sftmdRCENM}; 
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRCENM}; 

        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{$t = 3\text{px}$};
        \addlegendimage{black!30}
        \addlegendentry{$t = 5\text{px}$};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{$t = 10\text{px}$};      
        \end{axis}
    \end{tikzpicture}}

    % \begin{subfigure}{0.45\linewidth}
    % \centering
    \includegraphics[width=0.8\linewidth]{figures/poselib_graphs/ablation_pt_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    % \end{subfigure}
    % \hfill
    % \begin{subfigure}{0.45\linewidth}
    % \centering
    \includegraphics[width=0.8\linewidth]{figures/poselib_graphs/joint_graph_pt_pose.pdf}
    % \end{subfigure}
    \caption{%\newtext
    {Speed-accuracy trade-off on 12 scenes of Phototourism~\cite{IMC2020}. We show the impact of %Ablation study of 
    (\textbf{Top:}) 
    %We show how the different modifications presented in Sec.~\ref{sec:making_solvers_practical} affect the performance of the solvers. 
     different modifications presented in Sec.~3.2 in the main paper on the performance of the solvers
    and (\textbf{Bottom:}) the maximum epipolar threshold used in RANSAC  on the performance of the three best-performing methods.}
    %We show how performance changes when we change the maximum epipolar threshold used in RANSAC for the three best-performing methods.
    }
    \label{fig:poselib_ablation_threshold}
\end{figure}

\PAR{Refinement validation.} We also perform validation of the total number of LM steps in the refinement (\texttt{+R}). 
Again, we used the \textit{St.~Peter's Square} scene from the PhotoTourism dataset~\cite{IMC2020} for validation. 
The results of this experiment are shown in Fig.~\ref{fig:r_validation}. We chose the value of 2 for other experiments as it provides good speed-accuracy trade-off across a range of RANSAC iterations. However, we note that other settings provide very similar performance. 

\begin{figure*}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =5, % comment for column display
        /tikz/every even column/.append style={column sep=0.2cm},
        }
        ]
        
        \addlegendimage{Seaborn4}        \addlegendentry{\sftm};
        \addlegendimage{Seaborn7}
        \addlegendentry{\sftmd};
        \addlegendimage{Seaborn9}
        \addlegendentry{\sftmdR};
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC}; 
        \addlegendimage{Seaborn6}
        \addlegendentry{\sftmdRCENM}; 
        %\addlegendimage{Seaborn3}
        %\addlegendentry{\sfafRCENM};       
        \end{axis}
    \end{tikzpicture}}

    \centering

    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/ablation_cambridge_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}       \caption{Cambridge~\cite{kendall2015cambridge}}
    \end{subfigure}
    \begin{subfigure}{0.48\linewidth}   
    \includegraphics[width=\linewidth]{figures/poselib_graphs/ablation_aachen_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}  
    \caption{Aachen~\cite{zhang2021aachen}}
\end{subfigure}
    
    \caption{We show the impact of the different strategies (\texttt{+F/+R/+ENM}) introduced in Sec.~3.2 of the main paper on the performance of our \sftm-based solvers on Cambridge Landmarks~\cite{kendall2015cambridge} and Aachen Day-Night v1.1~\cite{zhang2021aachen}. We report the AUC@10$^\circ$. We vary the number of Poselib RANSAC iterations ($\{100, 200, 500, 1000, 2000, 5000, 10000\}$). We use an epipolar threshold of 5px in RANSAC. Runtimes are averaged over all image triplets. }
    \label{fig:ablation_crenm_cambridge_aachen}
\end{figure*}

\PAR{Validation of \texttt{+F}/\texttt{+R}/\texttt{+ENM}.} 
Fig.~\ref{fig:poselib_ablation_threshold} ablates the impact of individual modifications (\texttt{+R}/\texttt{+C}/\texttt{+ENM}) proposed in Sec.~3.2 in the main paper on the speed-accuracy trade-off.
It especially highlights the importance of the refinement using the 4th point in the third view (\texttt{+R}).
Fig.~\ref{fig:poselib_ablation_threshold} also shows the performance of the top-performing solvers when different maximum epipolar thresholds are used within RANSAC. Compared to \sfafRCENM, the proposed \sftmd-based solvers are not as sensitive to the selection of the epipolar threshold.
The results presented in Fig.~\ref{fig:poselib_ablation_threshold} were obtained on the PhotoTourism dataset.
Fig.~\ref{fig:ablation_crenm_cambridge_aachen} shows results of the same ablation study, focused on the \sftm-based solvers, on the Cambridge Landmarks and Aachen Day-Night v1.1 datasets. 

\section{Experiments on real data}
\label{sec:exp}
In this section, we aim to further study the performance of the proposed methods, supplementing Sec.~4 (paragraph ``Experiments on real data") of main paper with more detailed evaluations. Section~\ref{sec:exp:details} presents results on individual scenes, extending the analysis in Fig.~4 of the main paper. Section~\ref{sec:threshold} investigates the impact of varying the RANSAC epipolar threshold on solver performance. These experiments extend Fig.~\ref{fig:poselib_ablation_threshold} (bottom) by comparing additional solvers across all three datasets. Section~\ref{sec:exp:timing} evaluates and compares the run-times of each of the proposed and state-of-the-art solvers. Section~\ref{sec:exp:outlier} explores the robustness of the solvers under varying inlier ratios using semi-synthetic data. 
In Section~\ref{sec:exp:measure}, we provide results using Poselib RANSAC~\cite{PoseLib} for an alternative pose error metric that considers errors across all three camera pairs. Section~\ref{sec:exp:gc_ransac} evaluates the solvers within the GC-RANSAC~\cite{barath2017graph} framework
%, offering a comprehensive comparison 
%across all three datasets.
for all three datasets.

\begin{figure*}[!t]
    \centering

\resizebox{1.0\linewidth}{!}{
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, % comment for column display
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRC};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftmRC}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \addlegendimage{black!30}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/ \texttt{ENM}};
        
        \end{axis}
    \end{tikzpicture}}

    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_GreatCourt_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Great Court}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_KingsCollege_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{King's College}}        
    \end{subfigure}
    \hfill
    % \begin{subfigure}{0.24\linewidth}
    % \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_StMarysChurch_graph-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    % \caption{\textit{St. Mary's Church}}        
    % \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_OldHospital_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Old Hospital}}        
    \end{subfigure}
    \hfill        
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_ShopFacade_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Shop Facade}}        
    \end{subfigure}

    \vspace{0.5ex}    
    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_brandenburg_gate_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Brandenburg Gate}}        
    \end{subfigure}
    \hfill    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_buckingham_palace_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Buckingham Palace}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_colosseum_exterior_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Colosseum Exterior}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_grand_place_brussels_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Grand Place Brussels}}       
    \end{subfigure}

    \vspace{0.5ex}
    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_notre_dame_front_facade_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Notre Dame}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_palace_of_westminster_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Palace of Westminster}} 
    \end{subfigure}
    \hfill        
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_pantheon_exterior_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Pantheon Exterior}}        
    \end{subfigure}
    \hfill    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_sacre_coeur_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Sacre Coeur}}        
    \end{subfigure}

    \vspace{0.5ex}
    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_reichstag_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Reichstag}}        
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_taj_mahal_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Taj Mahal}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_temple_nara_japan_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Temple Nara}}        
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_trevi_fountain_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{Trevi Fountain}}        
    \end{subfigure}
    
    \caption{Results for individual scenes from the Cambridge Landmarks~\cite{kendall2015cambridge} (a-d) and Phototourism~\cite{IMC2020} (e-p) scenes which were not presented in the main paper. We report the AUC@10$^\circ$ of the pose error and vary the number of Poselib RANSAC iterations ($\{100, 200, 500, 1000, 2000, 5000, 10000\}$). We use an epipolar threshold of 5px inside RANSAC. Runtimes are averaged over all image triplets.}
    \label{fig:poselib_graph_scenes}
\end{figure*}



\subsection{Results on individual scenes}
\label{sec:exp:details}
Fig.~4 in the main paper showed results jointly on all PhotoTourism~\cite{IMC2020} scenes (except \textit{St.~Peter's Square}), jointly on the 5 Cambridge Landmarks~\cite{kendall2015cambridge} scenes (except the Street scene, which is commonly not used due to issues with its ground truth), and Aachen Day-Night v1.1~\cite{zhang2021aachen}. 
It also showed results on one individual scene from~\cite{kendall2015cambridge}, \ie, the \textit{St. Mary's Church} scene.
In Fig.~\ref{fig:poselib_graph_scenes}, we provide results for the accuracy-speed trade-off evaluation for all remaining individual scenes of PhotoTourism~\cite{IMC2020} and Cambridge Landmarks~\cite{kendall2015cambridge}. 
%\TODO{discuss}


As discussed in the main paper, 
the accuracy of the proposed approximate solvers is scene-dependent. 
This %weakness 
also applies to the state-of-the-art \sfhc solver~\cite{Hruby_cvpr2022}, since in this solver the scene needs to be similar enough to the training scenes for the MLP-based classifier to work well. 
The proposed \texttt{ENM} refitting suppresses to some extent the scene dependency of the proposed \sftm-based and \sfaf-based solvers. 
It can be seen that the proposed \sftmdRC solver consistently provides the best speed-accuracy trade-off both with and without \texttt{ENM} accross all scenes. \sfafRCENM provides a similar performance, 
typically beating \sfhc~\cite{Hruby_cvpr2022}. However,
it may perform worse for some specific scenes, \eg, \textit{Shop Facade} and  \textit{Palace of Westminster}.
In general, the results on individual scenes are consistent with the results from the main paper.

\begin{figure*}[!t]
    \centering
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, % comment for column display
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRC};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftmRC}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \end{axis}
    \end{tikzpicture}

   \begin{tabular}{cccc}
    \raisebox{0.4\height}{\rotatebox[origin=l]{90}{\small{Phototourism~\cite{IMC2020}}}} &    
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/pt_graph-3.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}  
    &        
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/pt_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose-Copy.pdf}
    &
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/pt_graph-10.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}     \\

    \raisebox{0.55\height}{\rotatebox[origin=l]{90}{\small{Cambridge~\cite{kendall2015cambridge}}}} &
        \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/cambridge_graph-3.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}    
    &        
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/cambridge_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose-Copy.pdf}
    &
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/cambridge_graph-10.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf} \\

    \raisebox{0.80\height}{\rotatebox[origin=l]{90}{\small{Aachen~\cite{zhang2021aachen}}}} &
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/aachen_graph-3.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}    
    &        
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/aachen_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose-Copy.pdf}
    &
    \includegraphics[width=0.3\textwidth]{figures/poselib_graphs/aachen_graph-10.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}  \\

    ~&$t = 3\text{px}$&$t = 5\text{px}$&$t = 10\text{px}$
     
    \end{tabular}
    
    \caption{Speed-accuracy trade-off on all scenes from Phototourism~\cite{IMC2020}, except \textit{St.~Peter's Square}, 5 scenes from  Cambridge Landmarks~\cite{kendall2015cambridge}, and the Aachen Day-Night v1.1 dataset~\cite{zhang2021aachen}. 
    We report the AUC@10$^\circ$ of the pose error and vary the number of Poselib RANSAC iterations ($\{100, 200, 500, 1000, 2000, 5000, 10000\}$) for different maximum epipolar thresholds ($t$). Runtimes are averaged over all image triplets. }
    \label{fig:threshold_sensitivity}
\end{figure*}

% It especially highlights the importance of the re- 618
% finement using the 4th point in the third view (+R). Fur- 619
% ther ablation studies are presented in the SM.

\subsection{RANSAC threshold sensitivity}
\label{sec:threshold}


In Fig.~\ref{fig:poselib_ablation_threshold} (bottom), we provided experiments showing how the performance of the selected methods changes when we vary the RANSAC epipolar threshold. 
In Fig.~\ref{fig:threshold_sensitivity} we provide more extensive results comparing the methods with different thresholds on all three datsets. % for more methods.

Similar to the results presented in the main paper, %Here we show that 
\sftmdRC in both variants (with and without \texttt{ENM}) shows consistently good performance even when using a different threshold in RANSAC. In contrast, \sfafRCENM performs worse than \sftmdRC when considering a higher epipolar threshold in RANSAC.

\subsection{Solver run-times}
\label{sec:exp:timing}
In this section, we present run-times of the proposed solvers as well as the state-of-the-art solvers for the relative pose problem of three calibrated cameras.
While the main paper reports run-time results for full RANSAC-based estimation, we now report the run-times of the individual solvers outside of RANSAC. 
To measure the run-times of the solvers\footnote{Note that for \sfhc solver, in Tab~\ref{tab:calib_time}, the time needed to load the weights of the network (or any other required data) is not added to the runtime of the solver. The data are loaded once per RANSAC, and the loading takes on average 45ms.}, we calculated the average run-time of each solver on more than 50k instances of the \textit{Sacre Coeur} scene of the PhotoTourism dataset~\cite{snavely2006photo}.
The run-times are reported in Table~\ref{tab:calib_time}. The experiments were performed on an Intel(R) Core(TM) i9-10900X CPU @ 3.70GHz.
In general, the implementations of all proposed solvers are not optimized for speed, and we still see room for speeding them up. 

\begin{table}[t!]
 \begin{center}
 \resizebox{1\columnwidth}{!}{
 \begin{tabular}{|l| c | c | c | c | c |}% c | c |}
    \hline
    & \sft & \sfhc & \sftm & \sftmd & \sfaf \\ % \sftl & \sftld & \sftlid \\
    \hline
    Time ($\mu$s) & 77.90 & 66.06 & 83.92 & 218.71 & 61.12 \\%450.26 & 511.28 & 1130.31 \\
    \hline
\end{tabular}
 }
\end{center}
\caption{The average run-time, averaged over more than 50k instances of the \textit{Sacre Coeur} scene of the PhotoTourism dataset~\cite{snavely2006photo}, of the solvers for the 4p3v problem.}
\label{tab:calib_time}
\end{table}

\subsection{Outlier experiments}
\label{sec:exp:outlier}

\begin{figure*}
    \centering

\resizebox{1.0\linewidth}{!}{
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, % comment for column display
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRC};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftmRC}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \addlegendimage{black!30}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/ \texttt{ENM}};
        
        \end{axis}
    \end{tikzpicture}}
   
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/pt_notre_dame_front_facade_graph-0.4inliers-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{40\% Inlier Ratio}
    \end{subfigure}
    \hfill    
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/pt_notre_dame_front_facade_graph-0.6inliers-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{60\% Inlier Ratio}
    \end{subfigure}  
    \hfill
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/pt_notre_dame_front_facade_graph-0.8inliers-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}    
    \caption{80\% Inlier Ratio}
    \end{subfigure}
    
    \caption{Speed-accuracy trade-off on the \textit{Notre Dame} scene from Phototourism~\cite{IMC2020}. We perform semi-synthetic experiments where we add random outlier correspondences to modify the inlier ratios.
    %We vary the number of Poselib RANSAC iterations (100, 200, 500, 1000, 2000, 5000, 10000). We use RANSAC epipolar threshold of 5 px. Runtimes are averaged over all image triplets.
    }
    \label{fig:outliers}
\end{figure*}

To show how the different solvers perform even under varying inlier ratios, we perform a semi-synthetic experiment. 
We use the \textit{Notre Dame} scene from PhotoTourism~\cite{IMC2020}. We keep all inlier triplets \wrt a 5px epipolar threshold using the ground truth poses. 
We add additional synthetic outlier correspondences by generating random points in all three views. 
This allows us to study how the different methods perform when the inlier ratio changes. 
The results are shown in Fig.~\ref{fig:outliers}. 
As expected, the performance of all solvers decreases with lower inlier ratios. 
We also observe that \sftmdRC performs well even with a low inlier ratio. 
In contrast, the relative performance of \sfafRCENM worsens with a decreased inlier ratio. However, we note that even with an inlier ratio of 40\%, it still results in performance comparable to the baseline \sft solver. This suggests that a high inlier ratio is not necessary for the \texttt{ENM} to work well in conjunction with the solver \sfaf.

\begin{table*}[t]
    \centering
    \resizebox{1.0\linewidth}{!}{
\begin{tabular}{ l | c c | c c c | c | c c | c c c | c| c c | c c c | c}
    \toprule
    \multicolumn{1}{c |}{~} & \multicolumn{6}{c |}{Phototourism~\cite{IMC2020}} & \multicolumn{6}{c |}{Cambridge Landmarks~\cite{kendall2015cambridge}} & \multicolumn{6}{c}{Aachen Day-Night v1.1~\cite{zhang2021aachen}} \\
    \toprule
    Estimator & AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime (ms) $\downarrow$& AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime (ms) $\downarrow$& AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime (ms) $\downarrow$\\
    \midrule

\sfhc~\cite{Hruby_cvpr2022} & 10.28 & \phantom{1}2.81 & 46.97 & 61.37 & 73.16 & \phantom{1}64.10 & 13.95 & \phantom{1}4.58 & 29.54 & 48.68 & 65.12 & 60.11 & 23.46 & \phantom{1}6.58 & 28.56 & 41.20 & 53.12 & \phantom{1}67.26 \\
\midrule\sft & \phantom{1}9.02 & \phantom{1}2.81 & 47.06 & 61.89 & 74.12 & \phantom{1}33.77 & 12.39 & \phantom{1}4.57 & 29.56 & 49.03 & 65.94 & 24.04 & 21.17 & \phantom{1}6.33 & 29.07 & 41.90 & 54.13 & \phantom{1}53.34 \\
\sftENM & \phantom{1}8.77 & \phantom{1}2.73 & 47.93 & 62.68 & 74.73 & \phantom{1}48.79 & 12.00 & \phantom{1}4.52 & 29.76 & 49.35 & 66.25 & 34.82 & 21.39 & \phantom{1}6.42 & 28.91 & 41.73 & 53.78 & \phantom{1}71.61 \\
\midrule \sfaf & 58.51 & 46.32 & 16.16 & 21.93 & 27.71 & \phantom{1}16.58 & 59.75 & 43.50 & 13.59 & 22.93 & 31.44 & 13.33 & 53.53 & 41.38 & 17.05 & 23.62 & 30.10 & \phantom{1}32.04 \\
\sfafENM & \phantom{1}8.44 & \phantom{1}2.60 & 49.46 & 64.10 & 75.85 & \phantom{1}40.45 & 11.86 & \phantom{1}4.46 & 30.17 & 49.89 & 66.74 & 28.35 & 21.00 & \phantom{1}6.23 & 29.08 & 42.05 & 54.32 & \phantom{1}62.44 \\
\sfafR & 53.59 & 38.24 & 18.31 & 24.91 & 31.34 & \phantom{1}\underline{16.32} & 54.17 & 24.26 & 16.60 & 27.32 & 36.63 & \underline{12.48} & 51.81 & 38.69 & 17.55 & 24.35 & 31.05 & \phantom{1}\underline{29.56} \\
\sfafRC & 56.31 & 43.55 & 16.89 & 23.07 & 29.15 & \phantom{1}\textbf{11.10} & 55.99 & 30.64 & 15.71 & 26.07 & 35.10 & \phantom{1}\textbf{9.35} & 54.12 & 42.69 & 16.64 & 23.04 & 29.50 & \phantom{1}\textbf{19.75} \\
\sfafRCENM & \phantom{1}8.45 & \phantom{1}2.59 & 49.59 & 64.22 & 75.92 & \phantom{1}32.37 & 11.78 & \phantom{1}4.41 & 30.41 & 50.12 & 66.93 & 23.43 & 21.11 & \phantom{1}6.29 & 29.02 & 41.97 & 54.18 & \phantom{1}42.36 \\
\midrule\sftm & \phantom{1}9.98 & \phantom{1}3.01 & 45.16 & 60.02 & 72.55 & \phantom{1}35.18 & 13.63 & \phantom{1}4.73 & 28.66 & 47.83 & 64.70 & 25.15 & 23.44 & \phantom{1}6.82 & 27.90 & 40.53 & 52.69 & \phantom{1}54.89 \\
\sftmENM & \phantom{1}8.86 & \phantom{1}2.75 & 47.68 & 62.54 & 74.67 & \phantom{1}48.83 & 12.10 & \phantom{1}4.52 & 29.80 & 49.31 & 66.17 & 34.93 & 21.51 & \phantom{1}6.40 & 28.91 & 41.73 & 53.83 & \phantom{1}70.87 \\
\sftmR & \phantom{1}9.24 & \phantom{1}2.74 & 47.74 & 62.44 & 74.47 & \phantom{1}41.52 & 12.76 & \phantom{1}4.53 & 29.77 & 49.27 & 66.12 & 30.76 & 22.06 & \phantom{1}6.39 & 28.92 & 41.69 & 53.70 & \phantom{1}60.40 \\
\sftmRC & \phantom{1}9.19 & \phantom{1}2.71 & 48.10 & 62.73 & 74.69 & \phantom{1}30.88 & 12.84 & \phantom{1}4.53 & 29.74 & 49.29 & 66.11 & 22.72 & 22.06 & \phantom{1}6.42 & 28.70 & 41.53 & 53.62 & \phantom{1}42.38 \\
\sftmRCENM & \phantom{1}8.52 & \phantom{1}2.62 & 49.16 & 63.82 & 75.60 & \phantom{1}44.51 & 11.79 & \phantom{1}4.44 & 30.27 & 49.91 & 66.72 & 32.48 & 20.93 & \phantom{1}6.21 & 29.16 & 42.16 & 54.46 & \phantom{1}58.08 \\
\midrule\sftmd & \phantom{1}9.28 & \phantom{1}2.94 & 45.92 & 61.05 & 73.66 & \phantom{1}83.70 & 12.68 & \phantom{1}4.59 & 29.35 & 48.88 & 65.89 & 59.23 & 22.09 & \phantom{1}6.42 & 28.60 & 41.55 & 53.76 & 125.02 \\
\sftmdENM & \phantom{1}8.44 & \phantom{1}2.73 & 48.01 & 63.02 & 75.20 & 125.66 & \underline{11.61} & \phantom{1}4.47 & 30.04 & 49.75 & 66.68 & 89.05 & \underline{20.80} & \phantom{1}6.22 & 29.26 & 42.16 & 54.32 & 175.54 \\
\sftmdR & \phantom{1}\underline{8.32} & \phantom{1}\underline{2.58} & \underline{49.79} & \underline{64.53} & \underline{76.30} & 100.61 & 11.93 & \phantom{1}\underline{4.40} & \underline{30.47} & \underline{50.35} & \underline{67.22} & 73.94 & 21.15 & \phantom{1}\underline{6.12} & \underline{29.35} & \underline{42.31} & \underline{54.53} & 138.53 \\
\sftmdRC & \phantom{1}8.39 & \phantom{1}2.58 & 49.69 & 64.41 & 76.18 & \phantom{1}71.73 & 12.06 & \phantom{1}4.41 & 30.42 & 50.25 & 67.08 & 52.84 & 21.38 & \phantom{1}6.15 & 29.24 & 42.22 & 54.43 & \phantom{1}92.89 \\
\sftmdRCENM & \phantom{1}\textbf{7.99} & \phantom{1}\textbf{2.56} & \textbf{49.93} & \textbf{64.67} & \textbf{76.45} & 112.60 & \textbf{11.36} & \phantom{1}\textbf{4.39} & \textbf{30.54} & \textbf{50.40} & \textbf{67.30} & 81.98 & \textbf{20.64} & \phantom{1}\textbf{6.08} & \textbf{29.40} & \textbf{42.48} & \textbf{54.67} & 139.19 \\
\midrule
    \end{tabular}}
    \caption{Experiments with the alternative evaluation measure described in Sec.~\ref{sec:exp:measure}. Results for different solvers implemented in the PoseLib framework~\cite{PoseLib} on all scenes from the PhotoTourism~\cite{IMC2020}, 5 scenes from the Cambridge Landmarks~\cite{kendall2015cambridge}, and the Aachen Day-Night v1.1~\cite{zhang2021aachen} datasets. 
    We mark the \textbf{best} and \underline{second best} results. Reported runtimes are for the whole RANSAC.}
    \label{tab:max_error}
\end{table*}

\subsection{Alternative evaluation measure}
\label{sec:exp:measure}
For the evaluation in the main paper, we defined the pose error as $\text{max}\left(0.5 (\M R_{err}^{12} + \M R_{err}^{13}), 0.5 (\V t_{err}^{12} + \V t_{err}^{13})\right)$, where $\M R_{err}^{ij}$ and $\V t_{err}^{ij}$ are the angular errors of rotation and translation (both in degrees) for camera pair $ij$. % in degrees. 
The 4p3v problem also includes the estimation of $\M R_{23}$ and $\V t_{23}$ since the relative scale of $\V t_{12}$ and $\V t_{13}$ is recovered. We therefore also present results for the pose error defined as 
\begin{equation}
P_{err} = \text{max} \left(\M R_{err}^{12}, \M R_{err}^{13}, \M R_{err}^{23}, \V t_{err}^{12}, \V t_{err}^{13}, \V t_{err}^{23}\right) \enspace.    
\label{eq:max_error}
\end{equation}
The results equivalent to Tab.~2 from the main paper using this pose error definition are presented in Tab.~\ref{tab:max_error}. 
A speed-accuracy comparison equivalent to Fig.~4 in the main paper is presented in Fig.~\ref{fig:max_error}. The overall ranking of the methods remains the same under both the metric used in the main paper and the alternative described in this section. %even when using the alternative error metric.

\subsection{Comparison with \cite{DBLP:journals/ijcv/NisterS06}}
% \newtext
{
The authors of
% We have contacted the authors of
~\cite{DBLP:journals/ijcv/NisterS06} kindly shared their source code with us.   
% Given an accurate epipole estimate, their approach performs comparable to our M-based solvers. 
Unfortunately, we were not able to run the part of the code that samples epipole candidates from a 10-degree polynomial curve (appropriately sampling the curve is hard as the epipole can be arbitrarily far from the image center). At the same time, the authors were also not able to run it. 

Based on the working parts of the code, we tested an oracle version of~\cite{DBLP:journals/ijcv/NisterS06}, where instead of sampling the 10-degree polynomial curve, the oracle gives us the correct epipole. Given a sample close to the correct epipole, \cite{DBLP:journals/ijcv/NisterS06} performs comparable to our M-based solvers. In practice it is hard to find good samples (the epipole can be arbitrarily far from the image center). \cite{DBLP:journals/ijcv/NisterS06} report using 40-1,000 samples with additional local optimization for robust estimation. 
Even then, \cite{DBLP:journals/ijcv/NisterS06} show that this approach performs worse than \texttt{5pt+P3P} on synthetic data. In contrast, %w
% We observe that 
two additional samples in our $\delta$-based %the 
solvers %based on $\delta$ 
already lead to better %improve performance compared to 
accuracy than \texttt{5pt+P3P}.}

\begin{figure*}
    \centering

\resizebox{1.0\linewidth}{!}{
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, % comment for column display
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRC};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftmRC}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \addlegendimage{black!30}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/ \texttt{ENM}};
        
        \end{axis}
    \end{tikzpicture}}
   
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/maxerr_pt_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{Phototourism~\cite{IMC2020}}
    \end{subfigure}
    \hfill    
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/maxerr_cambridge_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{Cambridge Landmarks~\cite{kendall2015cambridge}}
    \end{subfigure}  
    \hfill
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/poselib_graphs/maxerr_aachen_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}    
    \caption{\textit{Aachen Day-Night v1.1}~\cite{zhang2021aachen}}
    \end{subfigure}
    
    \caption{Experiments with the alternative evaluation measure described in Sec.~\ref{sec:exp:measure}: Speed-accuracy trade-off on (a) all scenes from PhotoTourism~\cite{IMC2020}, except \textit{St.~Peter's Square}, (b) 5  Cambridge Landmarks~\cite{kendall2015cambridge} scenes, and (c) the Aachen Day-Night v1.1~\cite{zhang2021aachen} dataset.
    We report the AUC@10$^\circ$ using the alternative definition of the pose error \eqref{eq:max_error}. We vary the number of Poselib RANSAC iterations ($\{100, 200, 500, 1000, 2000, 5000, 10000\}$). We use an epipolar threshold of 5px in RANSAC. Runtimes are averaged over all image triplets.}
    \label{fig:max_error}
\end{figure*}

\begin{table}[t]
    \centering
    \resizebox{1.0\linewidth}{!}{
\begin{tabular}{ l | c c | c c c | c}
    \toprule
    \multicolumn{7}{c}{Phototourism~\cite{IMC2020}} \\
    \midrule
    Estimator & AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime (s) $\downarrow$\\
    \midrule
\sfhc~\cite{Hruby_cvpr2022} & 5.34 & 1.89 & 59.19 & 72.25 & 82.10 & 2.95 \\ \hline
\sft & 5.18 & 1.86 & 59.48 & 72.35 & 82.16 & \bf{1.99} \\
\sftENM & 5.15 & 1.86 & 59.53 & 72.39 & 82.20 & 2.05 \\
% \hline
% \sfah & 5.27 & 1.95 & 42.94 & 63.12 & 77.35 & 2.10\\
% \sfah \texttt{ENM} & 5.30 & 1.94 & 43.10 & 63.24 & 77.39 & 2.14 \\
%\texttt{3pt$\texttt{H}_{\texttt{A}}$+P3P ENM} & 7.70 & 2.12 & 40.34 & 59.08 & 72.86 & 3.72 \\
\hline
\sfaf & 5.75 & 1.90 & 59.02 & 71.87 & 81.61 & 2.34 \\
\sfafR & 5.69 & \underline{1.72} & 61.59 & 73.83 & 82.88 & 2.98 \\
\sfafRC & 5.76 & 1.73 & 61.53 & 73.79 & 82.83 & 3.00 \\
\sfafRCENM & 5.34 & \underline{1.72} & 61.71 & 74.00 & 83.09 & 2.87 \\
% \hline
% \sfae & 6.93 & 1.97 & 42.56 & 62.51 & 76.43 & 2.46 \\
% \sfae \texttt{ENM} & 6.86 & 1.97 & 42.64 & 62.55 & 76.47 & 2.32\\
\hline
\sftm & 5.21 & 1.88 & 59.35 & 72.29 & 82.15 & \bf{1.99} \\
%\sftm \texttt{ENM} & 5.08 & 1.93 & 43.03 & 62.95 & 77.27 & 2.21 \\
\sftmR & 4.94 & \underline{1.72} & \underline{61.91} & 74.21 & 83.36 & 2.71 \\ 
\sftmRC & 4.94 & \underline{1.72} & 61.88 & 74.22 & 83.35 & 2.71\\ 
\sftmRCENM & 4.93 & \underline{1.72} & 61.84 & 74.21 & 83.38 & 2.73 \\
\hline
\sftmd & 5.09 & 1.89 & 59.41 & 72.50 & 82.38 & \underline{2.01}\\
\sftmdR & 4.90 & \bf{1.71} & 61.90 & 74.26 & 83.42 & 2.76\\
\sftmdRC & \underline{4.88} & \bf{1.71} & \bf{61.95} & \bf{74.31} & \underline{83.47} & 2.75\\ 
\sftmdRCENM & \bf{4.86} & \underline{1.72} & 61.90 & \underline{74.29} & \bf{83.48} & 2.84 \\ 
% \hline
% \sftl & 5.20 & 1.89 & 43.69 & 63.47 & 77.46 & 2.05\\
% \sftlR &  4.92 & \underline{1.72} & 45.83 & 65.29 & 78.69 & 2.77\\
% \sftlRC & 4.92 & \bf{1.71} & \underline{45.94} & \underline{65.35} & \underline{78.73} & 2.71\\
% \sftlRC \texttt{ENM} & 4.92 & \underline{1.72} & 45.89 & 65.32 & 78.70 & 2.76\\
% \sftlidR & \underline{5.97} & \underline{1.89} & \underline{58.65} & \underline{71.43} & \underline{81.35} & 189.24 \\
% \midrule
%\sfto & 4.87 & 1.82 & 44.44 & 63.96 & 77.91 & 2.77\\
% \sftoR & 4.87 & 1.70 & 45.95 & 65.36 & 78.76 & 2.71 \\
%\sfepo &  4.19 & 1.69 & 46.55 & 66.37 & 79.99 & 2.40\\
% \sfepoR & 4.24 & 1.74 & 46.01 & 65.97 & 79.74 & 2.39\\ 
%5.64 & 2.42 & 37.58 & 58.66 & 74.51 & 0.09\\

\midrule
\toprule
    \multicolumn{7}{c}{Cambridge Landmarks~\cite{kendall2015cambridge}} \\
    \midrule

\sfhc~\cite{Hruby_cvpr2022} & 8.13 & 3.05 & 43.75 & 60.73 & 73.93 & 2.37 \\ \hline
\sft & 8.01 & 3.09 & 43.17 & 60.17 & 73.67 & \bf{2.31} \\
\sftENM & 8.09 & 3.11 & 43.15 & 60.02 & 73.50 & 2.48\\
% \hline
% \sfah & 5.27 & 1.95 & 42.94 & 63.12 & 77.35 & 2.10\\
% \sfah \texttt{ENM} & 5.30 & 1.94 & 43.10 & 63.24 & 77.39 & 2.14 \\
%\texttt{3pt$\texttt{H}_{\texttt{A}}$+P3P ENM} & 7.70 & 2.12 & 40.34 & 59.08 & 72.86 & 3.72 \\
\hline
\sfaf & 8.59 & 3.11 & 43.16 & 59.98 & 73.15 & 2.62\\
\sfafR & 7.95 & \bf{2.80} & 46.27 & 63.20 & 75.86 & 2.96 \\
\sfafRC & 8.05 & \underline{2.81} & 46.28 & 63.17 & 75.75 & 2.98 \\
\sfafRCENM & 7.75 & \underline{2.81} & 46.38 & 63.20 & 75.86 & 2.98 \\
% \hline
% \sfae & 6.93 & 1.97 & 42.56 & 62.51 & 76.43 & 2.46 \\
% \sfae \texttt{ENM} & 6.86 & 1.97 & 42.64 & 62.55 & 76.47 & 2.32\\
\hline
\sftm & 7.95 & 3.08 & 43.32 & 60.37 & 73.75 & \underline{2.34}\\
%\sftm \texttt{ENM} & 5.08 & 1.93 & 43.03 & 62.95 & 77.27 & 2.21 \\
\sftmR & 7.22 & \bf{2.80} & \underline{46.48} & \bf{63.52} & \underline{76.30} & 2.86 \\ 
\sftmRC & 8.05 & \underline{2.81} & 46.28 & 63.17 & 75.75 & 2.98 \\ 
\sftmRCENM & 7.75 & \underline{2.81} & 46.38 & 63.20 & 75.86 & 2.98\\
\hline
\sftmd & 7.82 & 3.06 & 43.58 & 60.60 & 73.99 & 2.41 \\
\sftmdR & \underline{7.16} & \bf{2.80} & \bf{46.52} & \underline{63.51} & 76.25 & 3.01 \\
\sftmdRC & \bf{7.12} & \underline{2.81} & 46.33 & 63.47 & \bf{76.35} & 2.95 \\ 
\sftmdRCENM & 7.19 & 2.80 & 46.42 & 63.44 & 76.24 & 3.29 \\ 

\midrule
\toprule
    \multicolumn{7}{c}{Aachen Day-Night v1.1~\cite{zhang2021aachen}} \\
    \midrule

\sfhc~\cite{Hruby_cvpr2022} & 10.73 & 3.84 & 39.94 & 53.01 & 64.77 & 1.90 \\ \hline
\sft & 10.76 & 3.91 & 39.54 & 52.67 & 64.56 & \bf{1.77} \\
\sftENM & 10.78 & 3.79 & 39.86 & 53.06 & 64.79 & 1.89\\
\hline
\sfaf & 11.06 & 3.88 & 39.54 & 52.63 & 64.19 & 2.24\\
%\sfafENM & 11.04 & 3.89 & 39.43 & 52.48 & 64.12 & 2.68 \\
\sfafR & 10.09 & 3.50 & 42.64 & 55.75 & 67.01 & 3.32 \\
\sfafRC & 10.22 & 3.49 & 42.58 & 55.75 & 66.87 & 3.38 \\
\sfafRCENM & 10.23 & 3.48 & 42.58 & 55.75 & 66.88 & 3.32 \\
% \hline
% \sfae & 6.93 & 1.97 & 42.56 & 62.51 & 76.43 & 2.46 \\
% \sfae \texttt{ENM} & 6.86 & 1.97 & 42.64 & 62.55 & 76.47 & 2.32\\
\hline
\sftm & 10.62 & 3.83 & 39.62 & 52.92 & 64.74 & \underline{1.87}\\
%\sftm \texttt{ENM} & 5.08 & 1.93 & 43.03 & 62.95 & 77.27 & 2.21 \\
%\sftmENM & 10.52 & 3.84 & 39.88 & 53.21 & 64.98 & 2.57 \\
\sftmR & 10.11 & \underline{3.46} & \underline{42.69} & \underline{55.90} & \underline{67.11} & 3.17 \\ 
\sftmRC & 10.22 & 3.53 & 42.58 & 55.62 & 66.71 & 3.18 \\ 
\sftmRCENM & \underline{10.06} & 3.52 & 42.55 & 55.76 & 67.00 & 3.20\\
\hline
\sftmd & 10.55 & 3.84 & 39.86 & 53.30 & 65.15 & 1.89 \\
%\sftmdENM & 10.40 & 3.74 & 40.46 & 53.65 & 65.37 & 3.28 \\
\sftmdR & \bf{10.04} & \bf{3.45} & \bf{42.91} & \bf{56.02} & \bf{67.15} & 3.24 \\
\sftmdRC & 10.15 & 3.47 & 42.65 & 55.76 & 66.94 & 3.17 \\ 
\sftmdRCENM & \bf{10.04} & 3.50 & 42.67 & 55.82 & 66.95 & 3.33 \\ 

\bottomrule

    \end{tabular}}
    \caption{Results for different solvers and strategies implemented in the GC-RANSAC framework~\cite{barath2017graph} for all scenes from the PhotoTourism~\cite{IMC2020}, the Cambridge Landmarks~\cite{kendall2015cambridge} and Aachen Day-Night v1.1~\cite{zhang2021aachen} datasets. % are presented in Tab.~\ref{tab:gcr_phototourism}.
    %and the Aachen Day-Night V1.1 dataset~\cite{zhang2021aachen}. 
    We mark the \textbf{best} and \underline{second best} results. Runtimes are reported in seconds for the whole RANSAC with early termination (0.9999 confidence, minimum 100 iterations) and the epipolar threshold set to 5px.}%Best and second best results (exluding oracle solvers) are highlighted with bold and underline font.}
    \label{tab:gcr_phototourism}
\end{table}

\begin{figure*}[!t]
    \centering
    \resizebox{0.7\linewidth}{!}{
\begin{tikzpicture} 
        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =6, % comment for column display
        /tikz/every even column/.append style={column sep=0.2cm},
        }
        ]
        
        % \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        % \addlegendimage{Seaborn2}
        % \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfaf};
        % \addlegendimage{Seaborn4}
        % \addlegendentry{\sfah}; 
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftm}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmd};
        % \addlegendimage{white}
        % \addlegendentry{~};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{\texttt{+R}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 0.66pt off 1pt}
        \addlegendentry{\texttt{+R+F}};
        \addlegendimage{black!30,dash pattern=on 0.5pt off 1pt on 0.5pt off 1pt}
        \addlegendentry{\texttt{+R+F+ENM}};
        \end{axis}
    \end{tikzpicture}}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{figures/gcr_graphs/st_marys_church_psac_graph.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{figures/gcr_graphs/shop_facade_psac_graph.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{figures/gcr_graphs/kings_college_psac_graph.pdf}
    \end{subfigure}
    \caption{Speed-accuracy evaluation of various solvers for three view relative pose estimation, evaluated using GC-RANSAC~\cite{barath2017graph} on the (left) \textit{St. Mary's Church}, (middle) \textit{Shop Facade}, and (right) \textit{King's College} scenes from the Cambridge Landmarks dataset~\cite{kendall2015cambridge}. We report the AUC@10$^\circ$ of the pose error and vary the number of  RANSAC iterations ($\{5, 10, 20, 50, 100, 200, 500, 1000\}$) with fixed 5px epipolar threshold.}
    \label{fig:gcr_graphs}
\end{figure*}

\subsection{GC-RANSAC}
\label{sec:exp:gc_ransac}
% \PAR{Experiments on GC-RANSAC} 
Besides PoseLib's RANSAC implementation, we also evaluated and compared our proposed solvers with the state-of-the-art solvers inside the GC-RANSAC~\cite{barath2017graph} framework. 
% Results for all scenes of the PhotoTourism~\cite{IMC2020}, the Cambridge Landmarks~\cite{kendall2015cambridge} and Aachen Day-Night v1.1~\cite{zhang2021aachen} datasets are presented in Tab.~\ref{tab:gcr_phototourism}.

In GC-RANSAC, local optimization (LO) is performed using non-minimal solvers that fit models to larger-than-minimal samples. We use the non-minimal version\footnote{The non-minimal version of the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004}  uses the last four vectors from the SVD/QR decomposition of a $n \times 9$ matrix instead of the 4-dim null space of a $5\times 9$ matrix to parameterize the unknown essential matrix.} of the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004} and the non-minimal absolute pose \texttt{DLSPnP}~\cite{dlspnp} solver.\footnote{This may not be the most efficient way how to perform non-minimal refitting. However, since all methods use the same LO, it is sufficient for a fair comparison.}
In contrast to LO used in Poselib RANSAC, where the estimated model is used as an initialization of the LevenbergMarquardt algorithm, in GC-RANSAC, the estimated model is used only to score inliers. 
% Notice the similarity in terms of model refitting between LO in GC-RANSAC and the \texttt{ENM} strategy. 

Tab.~\ref{tab:gcr_phototourism} shows the results 
for GC-RANSAC with PROSAC sampling~\cite{prosac2005chum} and a 5px epipolar threshold for all scenes from the PhotoTourism~\cite{IMC2020} dataset, 5 scenes from the Cambridge Landmarks~\cite{kendall2015cambridge} dataset, and the Aachen Day-Night v1.1~\cite{zhang2021aachen} dataset. 
Similarly to what was observed for Poselib RANSAC (see Table 2 in the main paper), with the suggested modifications, all the proposed
solvers outperform the state-of-the-art %HC-based 
\sfhc solver~\cite{Hruby_cvpr2022} and the baseline \sft solver in terms of pose accuracy with comparable runtimes. 
Again, the $\delta$-based solvers provide, in general, the best speed-accuracy trade-off.

Due to a different LO, there are several differences compared to the results from Poselib RANSAC. Since in GC-RANSAC the estimated model is used only to score inliers, it does not need to be as precise as in Poselib RANSAC. Thus, even \sfaf solver without any modification provides reasonably precise results.\footnote{Note that the model of \sfaf is refitted in the LO step with the non-minimal \texttt{5pt} solver. This is similar to the refitting used in \texttt{ENM}, \ie, GC-RANSAC's local optimization includes some form of \texttt{ENM}, explaining why the \sfaf performs quite well.} 
In contrast to this, in Poselib RANSAC, the \sfaf solver without any modification results in large errors (see Table 2 in the main paper). 
Without refitting using \texttt{ENM}, the affine model estimated for the first two views in the \sfaf solver is 
%without refitting using \texttt{ENM} 
not sufficiently precise to provide a good initialization for LevenbergMarquardt-based optimization in Poselib's LO.
Still, even for GC-RANSAC, the pure \sfaf solver performs %much 
worse than the remaining variants of the proposed \sfaf-based and \sftm-based solvers.

Another difference is in refitting using \texttt{ENM}. For GC-RANSAC, the effect of \texttt{ENM} is not as significant as for Poselib RANSAC. 
When applied without refinement (\texttt{+R}), the early non-minimal refitting (\texttt{ENM}), in general, increases the precision of solvers. 
When combined with \texttt{+R}, the improvement is not very visible. 
The reason is that the model returned after refining the initial, approximate model estimated by the \sftm-based and \sfaf-based solvers on the $4^{th}$ correspondence % in \texttt{+R}, 
is usually sufficiently accurate to score inliers.
Moreover, in the LO of GC-RANSAC, this approximate model is refitted using the non-minimal \texttt{5pt} solver (which is similar to the refitting that is used in \texttt{ENM}), and the non-minimal \texttt{DLSPnP} solver~\cite{dlspnp}. Similarly to \texttt{ENM}, the filtering (\texttt{+F}) that uses the $4^{th}$ correspondence does not bring an improvement that is as visible as for Poselib RANSAC. This is because for GC-RANSAC, the speedup obtained using the filtering \texttt{+F} is not as significant, compared to the longer running times of the LO part of GC-RANSAC. 

On the other hand, the remaining two suggested modifications, \ie, the $\delta$-based solvers and the refinement (\texttt{+R}) using the $4^{th}$ correspondence bring visible improvements. 
This behavior is also visible in Figure~\ref{fig:gcr_graphs}. Here we present an ablation study on the effects of the various modifications ($\delta$ and \texttt{+F/+R/+ENM}, which were introduced in Sec. 3.2 of the main paper) on the \sftm-based and \sfaf-based solvers. 
The results are reported on the \textit{St.~Mary's Church}, \textit{Shop Facade}, and \textit{King's College} scenes from the Cambridge Landmarks dataset~\cite{kendall2015cambridge}. These results especially highlight the importance of the refinement using the $4^{th}$ point in the third view (\texttt{+R}).
On the other hand, the benefits of \sftmd-based solvers over the \sftm-based solvers that are also visible in Table~\ref{tab:gcr_phototourism} are not so significant as in Poselib RANSAC. 
Still, \sftmd-based solvers lead to improved pose accuracy. %improve the performance. %there is still some improvement. 
