\documentclass[10pt,twocolumn,letterpaper]{article}

%
\usepackage{cvpr}              %
%
%
\usepackage[accsupp]{axessibility}  %

%
\input{preamble}

%
%
%
%
%
%
%
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

%
\def\paperID{7411} %
\def\confName{CVPR}
\def\confYear{2025}

%
\title{
%
Practical solutions to the relative pose of three calibrated cameras}

%
\author{Charalambos Tzamos$^{\textrm{1,}\ast}$ \quad
Viktor Kocur$^{\textrm{2},\ast}$ \quad
Yaqing Ding$^\textrm{1}$ \quad
Daniel Barath$^\textrm{3}$ \quad
Zuzana Berger Haladová$^\textrm{2}$\\
Torsten Sattler$^\textrm{4}$ \quad
Zuzana Kukelova$^\textrm{1}$\vspace{10pt}\\
$^\textrm{1}$Visual Recognition Group, Faculty of Electrical Engineering, Czech Technical University in Prague\\
%{\tt\small \{tzamocha, yaqing.ding, kukelzuz\}@fel.cvut.cz} \\
$^\textrm{2}$Faculty of Mathematics, Physics and Informatics, Comenius University in Bratislava\\
%{\tt\small \{viktor.kocur, haladova\}@fmph.uniba.sk} \\
$^\textrm{3}$ETH Zürich (Zurich), HUN-REN SZTAKI (Budapest) \\
%{\tt\small danielbela.barath@inf.ethz.ch} \\
$^\textrm{4}$Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague\\
%{\tt\small torsten.sattler@cvut.cz}
}


\begin{document}

\maketitle
%
%
\begin{abstract}
 We study the challenging problem of estimating the relative pose of three calibrated cameras from four point correspondences.
 We propose novel efficient solutions to this problem that are based on the simple idea of using four correspondences to estimate an approximate geometry of the first two views. We model this geometry either as an affine or a fully perspective geometry estimated using one additional approximate correspondence.
We generate such an approximate correspondence using a very simple and efficient strategy, where the new point is the mean point of three corresponding input points. 
The new solvers are efficient and easy to implement, since they are based on existing efficient minimal solvers, i.e., the 4-point affine fundamental matrix, the well-known 5-point relative pose solver, and the \texttt{P3P} solver. Extensive experiments on real data show that the proposed solvers, when properly coupled with local optimization, achieve state-of-the-art results, with the novel solver based on approximate mean-point correspondences being more robust and accurate than the affine-based solver. 
\end{abstract}
\vspace{-5.8mm}%
\section{Introduction}
\label{sec:intro}
\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother
\blfootnote{$^\ast$ Equal contribution}
%
Camera geometry estimation is crucial in many computer vision applications, \eg, visual navigation~\cite{DBLP:journals/ram/ScaramuzzaF11}, Structure-from-Motion~\cite{Snavely-IJCV-2008},
augmented 
reality~\cite{Castle08ISWC}, self-driving cars~\cite{hane20173d}, 
and 
visual localization~\cite{Sattler16PAMI}.
%
Due to
noise and outliers in  input correspondences, 
the predominant way for camera geometry estimation is to use a hypothesis-and-test framework, \eg,  RANSAC~\cite{Fischler-Bolles-ACM-1981,Chum-2003, DBLP:journals/pami/RaguramCPMF13, barath2017graph}. 
For RANSAC-like methods, using as few (ideally the minimal number of) correspondences as possible for estimation 
is important since the number of RANSAC iterations (and  thus its run-time)
grows exponentially with the number of correspondences required for the model estimation.

\begin{figure}[t]
     \centering
     %
     \iccvnew
     \caption{
     %
     %
    %
   Visualization of the four-points-in-three-views (4p3v) problem and our solution %
   based on %
   using four correspondences to efficiently estimate an approximate geometry of the first two views and then register the third view using a \texttt{P3P} solver~\cite{lambda-twist}.
      }\vspace{-12pt}
     \label{fig:teaser}
\end{figure}

Minimal camera geometry problems often result in complex systems of 
polynomial
equations.
Efficient algebraic methods helped solve many previously unsolved 
problems
~\cite{Stewenius-CVPR-2005,bujnak_cvpr2008,larsson2019revisiting,DBLP:conf/cvpr/KukelovaP07,kukelova2013real,Stewenius-ISPRS-2006}.
Still,  
they fail to generate efficient and/or numerically stable solutions for some configurations.
In this paper, 
we study one such challenging problem: 
Estimating the relative pose of three calibrated cameras. 
This problem has received attention
for a long time~\cite{holt1995,Quan2006,leonardos_cvpr2015,Martyushev16,Aholt2014}. 
However, due to its complexity, it is still not considered fully solved. There are no efficient and practical solutions for most of the minimal configurations of point and/or line correspondences~\cite{Kileel2017}.
%
One such configuration that is particularly interesting is the notoriously difficult configuration of four points in three calibrated views~\cite{Quan2006, Nister-5pt-PAMI-2004}, known as the 4p3v problem.  
%
%
%

State-of-the-art algebraic and numerical methods are known to fail in generating efficient and numerically stable solutions to the 4p3v problem.  
%
%
%
The existing methods for solving this problem are only approximate~\cite{Hruby_cvpr2022,DBLP:journals/ijcv/NisterS06}.
By solving only for one (or a few) solutions from the 272 solutions 
%
of the 4p3v problem~\cite{Hruby_cvpr2022}, and by discretely sampling the space of potential solutions~\cite{DBLP:journals/ijcv/NisterS06}, the existing 4p3v methods can often fail, \ie, the returned solution can be, in general, arbitrarily far from the geometrically correct solution. 
To decrease the failure rate, both methods~\cite{Hruby_cvpr2022,DBLP:journals/ijcv/NisterS06} require a lot of tuning and are challenging to re-implement.\footnote{%
%
There is no publicly available implementation for~\cite{DBLP:journals/ijcv/NisterS06}. 
%
Implementation of~\cite{Hruby_cvpr2022} %
is quite complex and requires a non-negligible effort to run.}

%
%
In contrast to complex solutions to the configuration of four points in three views, there is a simple and efficient solution for the configuration where five correspondences are detected in the first two views and three of these points are also visible in the third view.  
%
%
%
%
In this case, the \sft solver first estimates the relative pose of two 
cameras from five correspondences using an efficient \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004}, and then registers the third camera using a \texttt{P3P} solver~\cite{lambda-twist}.

Following the idea of first estimating the relative pose of two cameras, 
%
%
%
we propose two novel approaches 
for solving
the 4p3v problem. 
Our solutions are based on the simple idea
of using four correspondences to estimate an approximate geometry of the first two views and then registering the third camera using a \texttt{P3P} solver~\cite{lambda-twist}.

%
In the first
approach, 
we approximate the geometry of the first two views using affine cameras. The approximation using affine cameras was shown to provide good accuracy for relative pose estimation if coupled with geometry refitting and local optimization inside RANSAC~\cite{pritts_ivcnz13}. We denote the proposed affine-based 4p3v solver as \sfaf.

In the second approach, we use a %
less restrictive approximation.
In this case,
%Here, 
we estimate the full perspective geometry, \ie, the full 5DoF essential matrix, using four %original
input
correspondences and one additional approximate 
%
correspondence in two views.
%
%
%
%
%
%
%
%
%
%
%
%
%
We generate the approximate correspondence using the locations of three of the 
%original 
four input 
correspondences. %
Under the assumption of a para-perspective projection, \ie, of affine geometry, the mean point of three 3D points is projected to the mean points in both images~\cite{Zhang2014}.
Thus,
the new correspondence is generated as the correspondence between the mean points of three corresponding points detected in two views. 
This approximate mean-point correspondence can also be seen as a correspondence under the $1^{st}$-order approximation of the homography defined by the plane passing through the three %
corresponding 3D points. We denote the proposed %
mean point-based 4p3v solver as \sftm.


%
%
%
%
%





%
%
%
%
%


While the proposed \sftm solver returns significantly more accurate poses than the \sfaf solver, both solvers may not be accurate enough if not properly treated inside RANSAC.
Thus, in this paper, we propose several ways to improve the accuracy of the proposed approximate solvers.
(i) To compensate for noise in the mean point correspondences, we introduce the \sftmd solver that generates two additional correspondences in the vicinity of the mean point, and in the first step calls the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004} three times. 
(ii) To improve the approximate geometry estimated between the first two views, we refit this geometry using a non-minimal relative pose solver and inliers obtained from the approximate geometry (ENM). 
(iii) We use the fourth correspondence in the third view to filter out geometrically infeasible solutions (+F) and to refine the solutions 
%
on four input correspondences in three views
using just a few iterations of Levenberg-Marquardt (LM) refinement (+R). 
While conceptually %very 
simple and efficient, the novel solvers achieve state-of-the-art results 
%
on real data.


\noindent The contributions of the paper are as follows: 
%
\begin{itemize}
\item We propose two groups of novel solutions for the well-known and challenging 4p3v problem: %
%
\sfa- and \sftm-based solvers. 
 These solutions are based on the simple idea of using four correspondences to estimate an approximate geometry in the first two views. 
 %
 %
 Compared to state-of-the-art 4p3v solvers~\cite{Hruby_cvpr2022,DBLP:journals/ijcv/NisterS06}, which are non-trivial and difficult to re-implement such that they are numerically stable and fast, our new solutions
%
can be easily implemented using existing efficient implementations of the linear \texttt{4pt} affine fundamental matrix solver~\cite{hartley2006multiple}, the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004} and the \texttt{P3P} solver~\cite{lambda-twist}. 
The source code is available at \href{https://github.com/kocurvik/threeview}{https://github.com/kocurvik/threeview}.
 \item We present several ways of improving the accuracy and the speed of the proposed solvers, as well as a strategy for efficiently using these approximate solvers inside a RANSAC-style paradigm. 
We show that the new solvers achieve state-of-the-art results in terms of accuracy on real data. While both \sfaf- and \sftm-based solvers achieve comparable results when coupled with the suggested non-minimal geometry refitting and local optimization, %
our \sftm-based solvers are more robust to the scene geometry and RANSAC inlier thresholds.
%
\item To 
%
our knowledge, we are the first to extensively evaluate solutions to the 4p3v problem on a large variety of real-world scenes and within state-of-the-art RANSAC frameworks, and to compare them to the baseline %
\sft solver.
We report results on 3 datasets, consisting of 18 different scenes and altogether 90,000 camera triplets.
%
\end{itemize}

\section{Related work}
Estimating the relative pose of three cameras from a minimal number of point and line  correspondences 
%
is known as an extremely challenging problem. 
%
For three uncalibrated cameras, 6 point correspondences are necessary to estimate the trifocal tensor, with a solution known for a long time~\cite{Quan_pami95,Torr97a}. 
 Solutions to three minimal combinations of points and lines are presented in~\cite{Oskarsson_bmvc2004}. 
The
%
configuration of 9 lines is
%
more challenging and was solved only recently 
%
~\cite{larsson2017efficient}.  
%
Yet,
the
%
solver is far from practical
%
%
and
runs 
%
17.8s.

For calibrated cameras, the configuration that attracts most of the attention is the configuration of four points in three views (the 4p3v problem). Note that this is not a minimal configuration since it generates 12 constraints for 11 degrees-of-freedom (DoF).
%
%
%
The 4p3v problem is known to be extremely difficult to solve.
Several papers present mostly theoretical results~\cite{leonardos_cvpr2015,Martyushev16,Aholt2014}.
%
For four triplets of exact points without noise, it is shown that the 4p3v problem has, in general, a unique solution~\cite{holt1995,Quan2006}.

To the best of our knowledge, there are only two reasonably efficient solutions to the 4p3v problem reported in the literature.
The first solver~\cite{DBLP:journals/ijcv/NisterS06} is based on a similar idea as our solvers, \ie, to first estimate the relative pose of two cameras and then register the third camera using a \texttt{P3P} solver~\cite{lambda-twist}. 
To compute the pose of the first two cameras using information only from four point correspondences, the solver needs  additional information about the position of one epipole.  
The paper shows that the four point correspondences between two calibrated views constrain the epipole in each image to lie on a curve of degree ten.
%
%
%
Thus, the solver performs one-dimensional exhaustive search and sweeps a $10^{th}$-degree curve of possible epipoles.
For each potential epipole, it computes the relative pose of two cameras, registers the third camera using three triangulated points, and finally extracts the solution minimizing the reprojection error of the fourth point in the third view. 
Evaluation of the solver on one potential epipole is fast.  
Yet, %However, 
in contrast to our proposed \sftm-based solvers, the error of the sampled epipole for one fixed point on the curve is not bounded since the true epipole can lie anywhere on the curve, and in many scenarios it is very far from the image center (\eg, outside the image).
Thus, to obtain reasonably accurate and stable results, usually 1,000 candidates need to be evaluated. 
Even then, %
refinement at multiple local minima is required to improve the accuracy. The runtimes reported for this solver were $1-12ms$ depending on the number of points searched. On a small number of synthetic experiments, the paper shows that the translation error returned by the proposed solver is usually $1-10\deg$ higher than the error returned by the \sft solver.
%
%
%
The literature does not compare against~\cite{DBLP:journals/ijcv/NisterS06} as there is no publicly available implementation %
and it is hard to re-implement. 
%
%
%
%

The second efficient solver to the 4p3v problem was published only recently~\cite{Hruby_cvpr2022}. In this paper, the authors first transform the 4p3v problem into a minimal problem by considering a line passing through the last correspondence in the third view.
%
The resulting system of equations is solved using an efficient Homotopy continuation (HC) method~\cite{Fabbri_CVPR2020,SommeseAndrewJ2005Tnso}. 
To avoid computing large numbers of spurious solutions, an MLP-based classifier is trained. For a given problem $p$, it selects one or several starting problem-solution pairs (so-called anchors), such that the geometrically meaningful/correct solution of $p$ can be obtained by HC starting from this anchor. This strategy is fast, running $16.3\mu s$ on average per solution. 
%
However, it has a high failure rate. The success rate of the 4p3v solver reported in~\cite{Hruby_cvpr2022} %
on two test %
datasets and data without noise is $26.3\%$.  
%
%
\cite{Hruby_cvpr2022} 
 do not show results %
for a real scenario, \ie, a RANSAC-like framework with noisy data. 
%
Providing such an evaluation, we show that our much simpler solvers outperform~\cite{Hruby_cvpr2022}. 
%

%
Solutions to the 4p3v problem for orthographic and 
%
para-perspective views were presented in~\cite{xu_ortho4p3v,Higgins-4p3v91}. In~\cite{Higgins-4p3v91}, the author suggested an iterative approach for updating to perspective views, but  
%
reported results only on a few synthetic instances. %
According to our 
%
extensive 
experiments, the update does not work on real data with general perspective cameras. This solver is returning large errors even after incorporating it into RANSAC with local optimization.  We see two main reasons: (i) The set of inliers that satisfy an approximate para-perspective camera model in all three images is usually quite small, and (ii) the %
estimated
model 
%
is often very far from the perspective optimum, and thus %
local optimization does not converge to a good solution.
%
%
%


%
%
%
%
In~\cite{Duff_PL1P,Kileel2017,duff2019plmp}, the authors aim to classify and derive 
the number of solutions for different minimal configurations of points and lines in three calibrated views.
Solutions to two minimal configurations
%
combining
points and lines 
%
were proposed in~\cite{Fabbri_CVPR2020} %
%
and solved using a HC %
%
method~\cite{SommeseAndrewJ2005Tnso}. 
Due to their complexity, 
%
the solvers are not practical. %
%
%
A GPU HC method
was also used to solve minimal problems of four points/six lines in three views %
for a generalized 
%
camera in~\cite{Ding_2023_ICCV} and of four points in three cameras with an unknown shared focal length (4p3vf) in~\cite{Chien_2022_CVPR,Cin_2024_CVPR}.
%
%
%
Efficient GPU implementations 
of the 4p3vf solvers
run $16.7ms$ to $154ms$. These times are still too slow for practical applications.
%
%
%
%
%

An approximation of perspective cameras using affine ones was used in several papers on camera geometry estimation~\cite{Collins2014InfinitesimalPP}. 
%In~\cite{oberkampf1996} and~\cite{Horaud97}, the authors propose iterative approaches to the absolute camera pose estimation problem, 
\cite{oberkampf1996} and~\cite{Horaud97} propose iterative approaches to the absolute camera pose estimation problem, 
%
\ie, the PnP problem.  
%
Both methods first compute the pose for an affine camera 
%(weak-perspective 
(weak-
or para-perspective). Then the error induced by the affine camera approximation is used to adjust the constraints on the pose and recompute it. 
%However, 
These methods do not guarantee convergence to the perspective model solution.
%
In~\cite{pritts_ivcnz13}, affine cameras are used to efficiently solve the relative pose problem of two uncalibrated cameras from two affine correspondences. 
%(AC). 
These affine correspondences are %either 
transformed to six point or two ellipse correspondences and %subsequently 
then
used to estimate the affine fundamental matrix. 
The paper also proposes a RANSAC framework that uses local optimization~\cite{lebedaLO} to estimate the full fundamental matrix using inliers from the approximate affine model.

%
%
%
Points that are sampled based on feature geometry to generate point correspondences from affine or scale- and orientation-invariant feature correspondences were also  used %
in~\cite{perd2006epipolar,BEEP,pritts-cvpr2018}.
%
In contrast,
%
our M-based solvers %
%
use 
only point correspondences, without associated feature geometry, to generate an additional point correspondence. %
%
%
%




\section{Estimating the relative pose of three cameras}
\label{sec:solvers}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%

%
%


%
%



%
%
In this section, we describe different solutions for estimating the relative pose of three calibrated cameras. 
We start with a baseline solution for the minimal configuration of three points visible in all three cameras and two additional points visible in two of the three cameras (the (5,5,3) configuration). 
Next, we present our novel solutions for the configuration of four points visible in all three cameras (the (4,4,4) configuration). 
This configuration generates an over-constrained problem. In this case, we have one more constraint than DoF. 
A minimal solution would need to drop one constraint, \eg, %
by considering only a line passing through one of the points in the third view~\cite{Hruby_cvpr2022} or by considering a ``half" point correspondence.
 Since, in practice, we always have full correspondences and sampling one less point in one view leads to an under-constrained problem, the (4,4,4) configuration, is usually considered  ``minimal".

\PAR{5pt+P3P solver:}
%
 %
 %
 %
%
%
%
%
%
%
%
%
The \sft  solver first estimates the relative pose of two cameras from 5 image point correspondences using the efficient \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004}. 
Next, the three points %
visible in all three views are triangulated. Finally, the third camera is registered using the three 2D-3D point correspondences and the well-known efficient \texttt{P3P} solver~\cite{lambda-twist}. 
 %
 
 %
 %
 %
%
%
%
%
%
%
%
%
%
%
 %
 This straightforward solver, which is based on existing efficient solvers~\cite{Nister-5pt-PAMI-2004,lambda-twist}, was discussed in several works~\cite{Duff_PL1P,Nister-5pt-PAMI-2004,Rodehorst2017,DBLP:journals/ijcv/NisterS06}. 
 % Nister \etal~
 \cite{DBLP:journals/ijcv/NisterS06} showed that the \sft solver performs better than their dedicated 4p3v solver on synthetic data.
%
Yet, %
the most recent works~\cite{Fabbri_CVPR2020,Hruby_cvpr2022} that study the three view relative pose problem %
%
%
do not discuss the \sft solver %
and do not use it as a baseline for comparison.  
 To the best of our knowledge, the performance of this solver on real data and within state-of-the-art RANSAC frameworks in the context of the 4p3v problem has not been extensively studied. %
 Our paper fills 
 % We fill 
 this gap in the literature.

\subsection{Approximate solutions to the 4p3v problem}
In contrast to the (5,5,3) configuration, the (4,4,4) configuration, \ie, the configuration of four points in three views, leads to significantly more complex equations. State-of-the-art algebraic and numerical methods are known to fail in generating efficient and numerically stable solutions to these equations. 
Thus, %
solutions to the 4p3v problem require some approximations to be practical in real-world applications. 
%
This section introduces several practical approximate solutions to the 4p3v problem. 
%
Similarly to the \sft solver, we decompose the problem into the problem of first estimating the relative pose of two cameras and then registering the third camera with an efficient \texttt{P3P} solver~\cite{lambda-twist}. The idea is to assume an approximate geometry only in the first two views and use four input point correspondences to efficiently estimate this geometry. Next we describe two groups of such solvers.

 \PAR{4p3v(A) solver:}
%
The first group of solvers %
approximates the geometry in the first two views using affine cameras. Although the approximation can be quite far from the correct geometry, %
\cite{pritts_ivcnz13} showed that an approximate  affine camera model provides %
good accuracy for relative pose estimation if coupled with geometry refitting (using the full 7DoF fundamental matrix) and local optimization inside RANSAC. 
%
The proposed \sfaf solver first uses four point correspondences in two views to efficiently estimate the affine fundamental matrix $\M F_\M{A}$~\cite{hartley2006multiple} and then registers the third camera using three triangulated points and a \texttt{P3P} solver~\cite{lambda-twist}.
%


 \PAR{4p3v(M) solver:}
The affine camera model used in the \sfa-based solvers can be quite imprecise. This motivates us to introduce solvers that are based on a less restrictive approximation. 
In this case, we approximate only one point correspondence in two views. 
Under the assumption of a para-perspective projection, \ie, of affine geometry, it is known that the mean point of three 3D points is projected to the mean points of their projections in both images~\cite{Zhang2014}.
Thus, we generate one new approximate correspondence in two views as the correspondence between the mean points of three corresponding points detected in these views. 
Let $\V m^l$ be the mean point 
of three points $\left\{\V x_i^l,\V x_j^l,\V x_k^l\right\}, \; i,j,k \in \left\{1,\dots, 4\right\}$, in  the view $l \in \left\{1,2\right\}$, then $\V m^1 \leftrightarrow \V m^2$ is our new approximate correspondence.
% With this additional fifth correspondence, t
The new \sftm solver solves the 4p3v problem by first estimating the full 5DoF essential matrix from four original correspondences $\V x_i^1 \leftrightarrow \V x_i^2,\;  i = 1,\dots, 4$  and the $5^{th}$ correspondence  $\V m^1 \leftrightarrow \V m^2$. This is done using the efficient \texttt{5pt} relative pose solver~\cite{Nister-5pt-PAMI-2004}. 
As with previous solvers, %
the third camera is registered using a  \texttt{P3P} solver~\cite{lambda-twist}. 
In short, %
the \sftm solver solves the 4p3v problem using the \sft solver and one approximate correspondence.

As we show on large amounts of synthetic and real data (see Sec.~\ref{sec:experiments} and Supp.~mat.~(SM)), the  \sftm solver provides much more accurate estimates than the \sfaf solver. %
Moreover, even in the basic form (without the modifications presented in the next section), on many scenes it performs comparably to the state-of-the-art HC solver~\cite{Hruby_cvpr2022}.
This can be attributed to several facts and observations:
%
%
%
%
%
%
%
%
 (1)  The $\V m^1 \leftrightarrow \V m^2$ correspondence does not need to be seen as a correspondence of points that are projections of the mean point of three 3D points  $\V X_i, \V X_j,$ and $\V X_k$ (in which case both $\V m^1$ and $\V m^2$ would have some error).  
 We can look at this correspondence as a correspondence in which we fix a point in one view, \eg, $\V m^1$, and generate a corresponding point in the second view. 
 In this case, to generate a good correspondence, we only require %that 
 the point in the second view to be reasonably close to the epipolar line defined by the mean point $\V m^1$ in the first view, \ie, the 2D point does not need to correspond to one particular 3D point with a given depth.
%
%
%
(2) 
% \newtext{
{
 The ray from the center of the first camera through the mean point $\V m^1$  intersects the plane of $\V X_i, \V X_j,$ and $\V X_k$ at  point $\V M$, which lies inside the triangle formed by these 3D points. The projection of $\V M$ into the second camera lies inside the triangle formed by $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. By construction, this projection lies on the epipolar line $\V E \V m^1$. 
 Thus the epipolar line defined by  $\V m^1$  passes through the triangle defined by $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. 
 Consequently, the maximum distance of $\V m^2$ in the second image from the epipolar line is bounded by the maximum distance of $\V m^2$ from $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$.  For a formal lemma and proof, 
 %and a visualization, 
 see SM.}
%
% The epipolar line defined by 
% $\V m^1$ 
% passes through the triangle defined by the corresponding three points $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$ in the second image. 
% Thus, the maximum distance of $\V m^2$ in the second image from the epipolar line is bounded by the maximum distance of $\V m^2$ from $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. 
%
% \newtext{The camera centers $\V C^1$ and $\V C^2$, along with the 3D points $\V X_i, \V X_j,$ and $\V X_k$, form tetrahedra $T^1$ and $T^2$, respectively. 
% The projections $\left\{\V x_i^1,\V x_j^1,\V x_k^1\right\}$ and $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$, lie at the edges of $T^1$ and $T^2$, respectively. 
% The ray from $\V C^1$ through the mean point $\V m^1$  intersects the plane of $\V X_i, \V X_j,$ and $\V X_k$ at point $\V M$, which lies inside the triangle formed by these 3D points. 
% Similarly, the ray from $\V C^2$ through $\V M$ intersects the image plane of the second camera inside the triangle formed by $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. 
% By construction, the projection of M lies on the epipolar line $\V E \V m^1$, which passes through the triangle defined by $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$. (for a formal lemma, proof and a visualization, see SM).}
%
%
(3) For practical applications, when used in RANSAC, it is not necessary that each triplet $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$ generates a good correspondence $\V m^1 \leftrightarrow \V m^2$. 
Samples with a high level of noise in the mean-point correspondence are filtered inside RANSAC.\footnote{%
This property was also used in the %
HC solver~\cite{Hruby_cvpr2022}, which completely fails for many samples. %
These samples are filtered within RANSAC.} 
On a large number of different scenes, we observed that even if some image pairs have triplets of points that generate very noisy mean-point correspondences, there are usually enough triplets for which the noise in $\V m^2$ is reasonably small to %provide 
lead to good estimates. 
(4) Four point correspondences in two views usually fix the space of possible poses such that the $5^{th}$ correspondence, even if noisy, 
%
often generates  a pose that is not very far from the ground truth pose. 
Such a pose is usually sufficient for filtering out outliers and %as well as 
a good initialization for non-linear optimization on the original four points in three views and subsequent local optimization on detected inliers.
We support our observations by experiments on a large amount of data. 
%
%
%

%

\subsection {Making approximate solvers practical}
\label{sec:making_solvers_practical}
The \sfa-based solvers, when used without any modifications, generally provide imprecise results even when used inside RANSAC with local optimization on three views. While the accuracy of the pure \sftm solver inside LO-RANSAC~\cite{lebedaLO} (RANSAC with Local Optimization) is much better, there is still room for improvement. Here we present several simple modifications of these solvers that significantly boost their performance.


 \PAR{4p3v(M$\pm \delta$) solver:}
%
The mean point correspondence used in the \sftm solver can provide a good approximation of a correct correspondence. %
Yet, as mentioned above, it can also be noisy.
In the \sftmd solver, we thus, in addition to the mean point $\V m^2 = \left[x,y\right]$ of 
%
three points $\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$
in the second image, generate two additional points. These points are (1) $\V {m}^2_{\pm\delta} = \left[x\pm\delta,y\right]$ if the longest dimension of the triangle  $\mathcal{T}^2 = \Delta\left\{\V x_i^2,\V x_j^2,\V x_k^2\right\}$ is in the x-direction or (2) $\V {m}^2_{\pm\delta} = \left[x,y \pm\delta\right]$ if it is in the y-direction.
All three points, \ie, $\V m^2$, $\V m^2_{-\delta}$, and $\V m^2_{+\delta}$ are placed in  correspondence with the mean point $\V m^1$.
%
The \sftmd solver in the first step calls the \sfc solver~\cite{Nister-5pt-PAMI-2004} three times, with the $5^{th}$ correspondence being either $\V m^1 \leftrightarrow \V m^2$, $\V m^1 \leftrightarrow \V m^2_{-\delta}$, or $\V m^1 \leftrightarrow \V m^2_{+\delta}$. The results of these three \sfc solvers are collected to create hypotheses for the relative pose of the first two cameras inside RANSAC. The shift $\delta$ is selected relative to the size of the triangle $\mathcal{T}^2$. %

%
%


 \PAR{Early non-minimal refitting (ENM):} The geometry estimated between the first two cameras using the proposed \sfa and \sftm- based solvers is only approximate. In %
 standard LO-RANSAC, such a geometry is optimized in local optimization (LO) after registering the third view. However, this can lead to propagation of errors into triangulated points and subsequently into errors in the pose of the third camera. Inliers in three views \wrt such cameras together with imprecise pose initializations may not be sufficient for LO to converge to a good solution. We observed this especially for \sfa-based solvers. Fortunately, the design of our solvers allows us to optimize the geometry already %
 after estimating the approximate geometry between the first two cameras. Here, even a very imprecise geometry returned by the \sfa solvers is usually sufficient to filter out outliers. Thus, after running the \texttt{4pt} $\M F_{\M{A}}$/\texttt{5pt} solver in the first step of the proposed solvers, we use the estimated approximate models to detect inliers in two views. %
 We then refit the estimated geometry using the non-minimal version of the \texttt{5pt} solver~\cite{Nister-5pt-PAMI-2004},
 which instead of a 4-dim null space of a $5\times 9$ matrix uses the last four vectors from the SVD/QR decomposition of a $n \times 9$ matrix.
    %

\PAR{$\mathbf{4^{th}}$ point in the third view:} 
%
%
%
\sfa and \sftm solvers 
actually solve the configuration %
(4,4,3), \ie, they do not use the information from the 
%
point $\V{x}^3_4$ in the third view.
%
%
The information from %
%
$\V{x}^3_4$
 can be used 
 %
 %
 in two different ways: 
 
  \noindent \textbf{Filtering (}\texttt{+F}\textbf{):} $\V{x}^3_4$ can be used to filter out geometrically infeasible solutions returned by
 the proposed solvers. Note that the P3P and \texttt{5pt} solvers used inside the proposed methods and the $\delta$-based strategy return multiple solutions that can be evaluated \wrt $\V{x}^3_4$ to filter out spurious solutions. 
 %
 %
 %
 Since the returned solutions can be affected by %
 the proposed approximation, 
 we do not simply select the solution with the smallest error on $\V{x}^3_4$, but we keep all solutions that have an  epipolar error on $\V{x}^3_4$ smaller than twice the threshold used inside RANSAC. 
 %
 Our experiments show that this filtering can improve the speed of the proposed solvers. 
 However, as a trade-off, there is sometimes a small drop in the accuracy of the solvers since, in some cases, geometrically correct solutions are filtered out. 
 
 \noindent \textbf{Refinement (}\texttt{+R}\textbf{):} 
 %
 %
 %
 $\V{x}^3_4$ can be used to refine the solutions returned by the proposed
 %
 solvers.
 %
 We want solutions that minimize the 
 epipolar error on the original 4 points in all 3 views, \ie, that solve the original (4,4,4) configuration. %Note that %
 (4,4,4)
 is an overconstrained configuration; thus, for noisy data, there is, in general, no solution with zero error on all 4 points in 3 views. 
 %
 We refine the poses by minimizing the epipolar error of %all 
 the original four points in three views using %
 LM optimization, initialized using the solutions from the \sfaf- and \sftm-based solvers. 
 %
 Experiments with different numbers of iterations %
 show that two iterations are usually sufficient to obtain an improvement %
 (see SM).
 



%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%







%
%


%

%
%
%


%
%
%
%

%



%
%

%

%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%






\section{Experiments}
\label{sec:experiments}
%
We extensively evaluated the proposed solvers on a large variety of synthetic and real data to test their robustness to noise, outliers, and scene properties, and to assess their performance inside state-of-the-art RANSAC-frameworks~\cite{barath2017graph, PoseLib}. 
%
We compare our novel solvers with the homotopy continuation \sfhc solver ~\cite{Hruby_cvpr2022} and the \sft baseline minimal solver for the (5,5,3) 
%
configuration.
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\begin{figure}
    \centering

\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =7, %
        /tikz/every even column/.append style={column sep=0.05cm},
        font=\scriptsize
        },
        legend image post style={xscale=1}
        ]
        
        \addlegendimage{Seaborn2}
        \addlegendentry{\texttt{5p(E)}};
        \addlegendimage{Seaborn4}
        \addlegendentry{\texttt{4p(M)}};
        %
        %
        \addlegendimage{Seaborn5}
        \addlegendentry{\texttt{4p(M$\pm \delta$)}};
        %
        %
        \addlegendimage{Seaborn3}
        \addlegendentry{\texttt{4p(A)}}; 
        %
        %
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 1pt off 0.5pt on 1pt off 0.5pt}
        \addlegendentry{w/ \texttt{ENM}};
        %
        %
        \end{axis}
    \end{tikzpicture}
    \includegraphics[trim={1.5cm 0 1.5cm 2cm},clip, width=0.85\columnwidth]{figures/synthetic/angle_cam_noise1_p.png}
    %
    \caption{Results of a synthetic experiment measuring the accuracy of two-view variants of our solvers depending on the  angle between the principal axes of the cameras.}
    \label{fig:synth_angle}
\end{figure}

\PAR{Experimental setup.} To obtain feature correspondences, we use SuperPoint~\cite{detone2018superpoint} features with the  LightGlue~\cite{lindenberger2023lightglue} matcher. 
%
We extract at most 2048 features per image. 
We perform matching for all three image pairs and keep only those matches that were consistently matched across all three views. 
%
We perform evaluation within two RANSAC frameworks: PoseLib~\cite{PoseLib} and GC-RANSAC~\cite{barath2017graph}. For the \texttt{5pt} solver, %
we use~\cite{Nister-5pt-PAMI-2004} and for the \sp solver, %
we use~\cite{lambda-twist}. 
In PoseLib, we perform LO~\cite{Chum-2003} using LM optimization. 
In GC-RANSAC, we perform LO using non-minimal solvers~\cite{Nister-5pt-PAMI-2004,dlspnp} for fitting models to larger-than-minimal samples. 
We evaluated different shifts for our~$\delta$-based solvers using a validation scene (for the ablation study, see SM) and selected $\delta = 0.08*\texttt{\small(longest triangle dim.)}$. 
The choice of $\delta$ is not critical, \ie, different values perform similarly. %
%

\PAR{Evaluation measures.} Inspired by~\cite{IMC2020}, we define the %
pose error %
as $\text{max}\left(0.5 (\M R_{err}^{12} + \M R_{err}^{13}), 0.5 (\V t_{err}^{12} + \V t_{err}^{13})\right)$, where $\M R_{err}^{ij}$ and $\V t_{err}^{ij}$ are the angular errors of rotation and translation for pair $ij$ in degrees~\cite{IMC2020}. We also report AUC values~\cite{IMC2020} at different thresholds for the pose error. 
%
We include 
results for an alternative pose error definition which includes $\M R_{err}^{23}$ and $\V t_{err}^{23}$ %
in SM.

%
%
%
%



 \begin{figure}[t!]
    \centering
	%
	%
	%
   %
    \includegraphics[width=0.41\columnwidth]{figures/bary_4p/st_peters_bary_rotation.png}
   %
    \includegraphics[width=0.41\columnwidth]{figures/bary_4p/st_peters_bary_inlier.png}

\caption{
%
%
Distribution of the (left) rotation error (0.3373, 0.3349); and (right) percentage of inliers gathered (0.3266, 0.3434), as a function of the barycentric coordinates of the triangle in the second image \wrt the mean point of the corresponding triangle in the first image
%
on 465k four-tuples of correspondences from \textit{St.~Peter's Square} scene from the PhotoTourism dataset~\cite{IMC2020}. 
%
We fit a 2D Gaussian distribution to the results and report the mean in brackets.
}
\label{fig:mean_tests}
\end{figure}

%
%
\PAR{Approximate camera geometry.} The first experiments aim to support our idea of 
estimating approximate geometry in the first two views.
%
%
%
The accuracy of the
%
used approximations depends on a large number of variables, including the depths of the points \wrt the cameras, the angle under which the points are observed, 
%
the type of motion,  \etc. 
A detailed analysis of all these factors, \eg, through synthetic experiments, is beyond the scope of this paper. 

An approximation error introduced by the para-perspective projection, \ie, the affine geometry, 
and its effect on absolute camera pose determination is 
studied in the literature~\cite{Zhang2014,Horaud97}. Here, we thus only study the effect of the proposed approximation on relative pose estimation for real-world data and interesting synthetic scenarios. In the following experiments, all solvers are tested on two views without RANSAC. The two-view variants of our solvers are denoted as $\texttt{4p(A)}$, $\texttt{4p(M)}$, and \texttt{4p(M$\pm \delta$)}. 


%
%
%

In the first set of experiments, we consider several interesting synthetic setups. 
Fig.~\ref{fig:synth_angle} presents the results for increasing the angle between the principal axes %projection rays 
of the two cameras. 
%
%
We generate  3D points in a 2000x2000x100 cube uniformly at random. 
The distances of the camera centers are random between 1000 and 1200. The cameras are looking towards the scene and their principal axes form a specified angle. To simulate realistic scenarios, we add 1px noise to the image correspondences and 20\% outliers.\footnote{Outliers are only used in the ENM part to simulate that for approximate geometry outliers might be contained in the non-minimal samples.}
It can be seen that the results for both approximate solvers deteriorate with increasing angle, with $\texttt{4p(A)}$ being significantly less accurate than $\texttt{4p(M)}$ and \texttt{4p(M$\pm \delta$)}. However, ENM can significantly decrease errors, with the $\texttt{4p(M$\pm \delta$)+ENM}$ solver returning almost identical results to $\texttt{5pt+ENM}$. 
Results for %
varying distances of the cameras from the scene, depth of the scene, and image noise are in SM. 

Similar observations as on synthetic data can be made on real-world data. Tab.~\ref{tab:4ptM_vs_5pt} shows results 
%
on 
different 
scenes from the PhotoTourism dataset~\cite{IMC2020}. 
 As can be seen, the approximate solvers are not as accurate as the \texttt{5pt} solver when used without ENM.
The gap between the  $\texttt{4p(M)}$/\texttt{4p(M$\pm \delta$)} solvers and the \texttt{5pt} solver is for some scenes larger %
%
(%
\textit{Sacre Coeur}, 
\textit{Trevi Fountain}), and for some noticeably smaller (\textit{Reichstag}, \textit{St. Peter's Square}), showing that the performance of our solvers is scene-dependent. The $\texttt{4p(A)}$ solver returns large errors. 
%
The accuracy of the $\texttt{4p(M)}$/\texttt{4p(M$\pm \delta$)}  solvers is not very far from the \texttt{5pt} solver, with the  \texttt{4p(M$\pm \delta$)} solver even slightly outperforming the \texttt{5pt} solver on some scenes (\textit{Reichstag}, \textit{Taj Mahal}). ENM helps to increase the precision of all solvers, especially $\texttt{4p(A)}$.
%
%
%
%
%
 Still, the $\texttt{4p(A)+ENM}$ solver %
 returns quite high errors.  
However, in practice, all solvers are used inside RANSAC, where the current best pose is locally optimized on inliers. LO compensates for less accurate pose estimates and, as we show on real experiments for three %
as well as two views (see SM), it can suppress the errors of the $\texttt{4p(A)}$/\sfaf-based solvers, making them comparable to the $\texttt{4p(M)}$/\sftm-based solvers.
%
For the three view scenario, the performance of all of our solvers can be further improved by %
pose refinement (+R) and filtering (+F). % about 5pt+p3p+R+F
%\newtext{Can say here about how to apply +F +R to 5pt+P3P.}
%
%
%

%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\begin{table}  \resizebox{0.95\columnwidth}{!}{\begin{tabular}{c | c c c c || c c c c}
    \multicolumn{1}{c}{~} & \multicolumn{4}{c}{MED ($^\circ$)} & \multicolumn{4}{c}{$20^{th}$ perc. ($^\circ$)} \\
    \cmidrule{2-9}
    \multicolumn{1}{c}{~} & \multicolumn{8}{c}{w/o \texttt{ENM}} \\
    \midrule
    Scene & \texttt{5p(E)} & \texttt{4p(M)} & \texttt{4p(M$\pm \delta$)} & \texttt{4p(A)} & \texttt{5p(E)} & \texttt{4p(M)} & \texttt{4p(M$\pm \delta$)} & \texttt{4p(A)}\\
    \midrule
    \textit{Brandenburg Gate} & 16.14 & 19.02 & 15.69 & 75.32 & \phantom{1}7.22 & \phantom{1}9.83 & \phantom{1}7.46 & 45.99 \\
\textit{Buckingham Palace} & 18.87 & 21.12 & 17.74 & 66.19 & \phantom{1}8.04 & 10.01 & \phantom{1}8.23 & 40.59 \\
\textit{Colosseum Exterior} & 17.40 & 23.50 & 18.93 & 66.67 & \phantom{1}6.44 & 11.36 & \phantom{1}8.34 & 40.82 \\
\textit{Grand Place Brussels} & 18.40 & 20.28 & 16.78 & 69.31 & \phantom{1}8.04 & 10.09 & \phantom{1}8.07 & 44.45 \\
\textit{Notre Dame Front Facade} & 15.82 & 23.97 & 19.61 & 71.60 & \phantom{1}6.40 & 12.27 & \phantom{1}9.01 & 48.39 \\
\textit{Palace of Westminster} & 16.04 & 17.62 & 14.72 & 69.38 & \phantom{1}4.99 & \phantom{1}7.98 & \phantom{1}6.40 & 46.49 \\
\textit{Pantheon Exterior} & 22.65 & 25.71 & 21.31 & 61.33 & 10.65 & 14.09 & 10.94 & 38.12 \\
\textit{Reichstag} & 12.15 & 12.99 & 10.27 & 82.85 & \phantom{1}5.15 & \phantom{1}6.16 & \phantom{1}4.57 & 60.12 \\
\textit{Sacre Coeur} & 11.81 & 17.61 & 14.31 & 74.21 & \phantom{1}3.69 & \phantom{1}7.95 & \phantom{1}5.87 & 43.72 \\
\textit{St. Peter's Square} & 17.85 & 18.75 & 15.48 & 72.75 & \phantom{1}8.51 & \phantom{1}9.71 & \phantom{1}7.66 & 44.60 \\
\textit{Taj Mahal} & \phantom{1}9.95 & 11.20 & \phantom{1}8.56 & 82.74 & \phantom{1}3.77 & \phantom{1}4.90 & \phantom{1}3.63 & 64.27 \\
\textit{Temple Nara Japan} & 18.57 & 21.53 & 17.01 & 64.97 & \phantom{1}7.60 & 10.63 & \phantom{1}8.16 & 32.21 \\
\textit{Trevi Fountain} & 20.93 & 27.77 & 22.89 & 50.12 & \phantom{1}8.10 & 13.89 & 10.78 & 31.32 \\
\midrule
    \multicolumn{1}{c}{~} & \multicolumn{8}{c}{w/ \texttt{ENM}} \\
    \midrule
    Scene & \texttt{5p(E)} & \texttt{4p(M)} & \texttt{4p(M$\pm \delta$)} & \texttt{4p(A)} & \texttt{5p(E)} & \texttt{4p(M)} & \texttt{4p(M$\pm \delta$)} & \texttt{4p(A)}\\
    \midrule
    \textit{Brandenburg Gate} & 14.53 & 17.05 & 14.38 & 28.40 & \phantom{1}6.74 & \phantom{1}8.86 & \phantom{1}6.93 & 16.96 \\
\textit{Buckingham Palace} & 16.71 & 18.76 & 16.07 & 35.07 & \phantom{1}7.35 & \phantom{1}8.96 & \phantom{1}7.46 & 19.72 \\
\textit{Colosseum Exterior} & 16.21 & 21.46 & 17.70 & 34.90 & \phantom{1}6.35 & 10.71 & \phantom{1}8.04 & 21.98 \\
\textit{Grand Place Brussels} & 16.21 & 17.96 & 15.23 & 31.53 & \phantom{1}7.27 & \phantom{1}8.85 & \phantom{1}7.24 & 18.40 \\
\textit{Notre Dame Front Facade} & 15.05 & 22.08 & 18.46 & 34.49 & \phantom{1}6.30 & 11.65 & \phantom{1}8.71 & 22.08 \\
\textit{Palace of Westminster} & 13.83 & 14.95 & 12.74 & 29.06 & \phantom{1}4.68 & \phantom{1}7.13 & \phantom{1}5.84 & 16.41 \\
\textit{Pantheon Exterior} & 21.19 & 24.03 & 20.30 & 37.21 & 10.32 & 13.28 & 10.55 & 24.42 \\
\textit{Reichstag} & \phantom{1}9.32 & 10.03 & \phantom{1}8.36 & 17.69 & \phantom{1}4.40 & \phantom{1}5.06 & \phantom{1}3.97 & \phantom{1}9.39 \\
\textit{Sacre Coeur} & 10.71 & 15.19 & 12.64 & 24.92 & \phantom{1}3.61 & \phantom{1}7.23 & \phantom{1}5.49 & 13.41 \\
\textit{St. Peter's Square} & 16.01 & 16.94 & 14.35 & 28.60 & \phantom{1}7.75 & \phantom{1}8.63 & \phantom{1}7.03 & 15.68 \\
\textit{Taj Mahal} & \phantom{1}8.32 & \phantom{1}9.32 & \phantom{1}7.43 & 15.85 & \phantom{1}3.34 & \phantom{1}4.10 & \phantom{1}3.18 & \phantom{1}7.72 \\
\textit{Temple Nara Japan} & 16.24 & 19.38 & 15.74 & 29.97 & \phantom{1}6.83 & \phantom{1}9.19 & \phantom{1}7.32 & 16.65 \\
\textit{Trevi Fountain} & 20.22 & 26.42 & 22.09 & 39.67 & \phantom{1}8.02 & 13.43 & 10.53 & 26.62 \\
\bottomrule
    \end{tabular}}
    \caption{Accuracy of two-view solvers on PhotoTourism scenes.}
    \label{tab:4ptM_vs_5pt}
\end{table}

In the last set of experiments, we study the accuracy of the mean point correspondence.
We sample 100 four-tuples of point correspondences
%
consistent with the ground truth relative pose, \ie, inliers, for each image pair in scenes from the PhotoTourism dataset~\cite{IMC2020}. 
We use the first three correspondences to define the triangles in both images. 
%
Then, we establish correspondences between the mean of the triangle in one image and various points in the triangle in the second image. 
We express points in the second triangle via their barycentric coordinates and uniformly sample $19 \times 19$ barycentric coordinates $(a,b)\in [0,1]^2$, such that $a+b \leq 1$. 
%
%
%
%
%
%
%
%
%

%
Fig.~\ref{fig:mean_tests} shows the results 
for the rotation error and the percentage of inliers consistent with the pose obtained with the $\texttt{4p(M)}$ solver on the \textit{St.~Peter's Square} scene.  
%
The optimum of the metrics is reached around the mean point of the triangles (the mean values of 2D Gaussians fitted to the results
are very close to the mean point $(0.\bar{3}, 0.\bar{3})$ of the triangles).
%
%
%
%
%
%
%
A detailed description, the translation and the symmetric epipolar errors, and the results for more scenes are in SM. For all 
 %
 tested
 scenes, we observed a similar behavior.


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
 



%
%
%



%


%

%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%


\begin{figure*}
    \centering
    \resizebox{1.0\linewidth}{!}{
\begin{tikzpicture} 

        \begin{axis}[%
        hide axis, xmin=0,xmax=0,ymin=0,ymax=0,
        legend style={draw=white!15!white, 
        line width = 1pt,
        legend  columns =9, %
        /tikz/every even column/.append style={column sep=0.5cm},
        }
        ]
        
        \addlegendimage{Seaborn1}        \addlegendentry{\sfhc~\cite{Hruby_cvpr2022}};
        \addlegendimage{Seaborn2}
        \addlegendentry{\sft};
        \addlegendimage{Seaborn3}
        \addlegendentry{\sfafRC};
        %
        %
        \addlegendimage{Seaborn4}
        \addlegendentry{\sftmRC}; 
        \addlegendimage{Seaborn5}
        \addlegendentry{\sftmdRC};
        %
        %
        \addlegendimage{black!30}
        \addlegendentry{w/o \texttt{ENM}};
        \addlegendimage{black!30,dash pattern=on 2pt off 1pt on 2pt off 1pt}
        \addlegendentry{w/ \texttt{ENM}};
        
        \end{axis}
    \end{tikzpicture}}

    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/pt_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{Phototourism~\cite{IMC2020}}
    \end{subfigure} \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{Cambridge Landmarks~\cite{kendall2015cambridge}}
    \end{subfigure} \hfill    
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/aachen_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{Aachen Day-Night v1.1~\cite{zhang2021aachen}}
    \end{subfigure} \hfill
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=\linewidth]{figures/poselib_graphs/cambridge_StMarysChurch_graph-5.0t-triplets-features_superpoint_noresize_2048-LG_pose.pdf}
    \caption{\textit{St. Mary's Church}~\cite{kendall2015cambridge}}
    \label{fig:poselib_graphs_st_mary}
    \end{subfigure}
       
    \caption{Speed-accuracy trade-off for (a) all scenes from PhotoTourism~\cite{IMC2020} except \textit{St.\ Peter's Square}, (b) 5 scenes from  Cambridge Landmarks~\cite{kendall2015cambridge}, (c) Aachen Day-Night v1.1~\cite{zhang2021aachen}, and (d) \textit{St.\ Mary's Church} scene from the Cambridge Landmarks dataset~\cite{kendall2015cambridge}. 
    We report the AUC@10$^\circ$ of the pose error and vary the number of PoseLib RANSAC iterations (100, 200, 500, 1000, 2000, 5000, 10,000) with a 5 px epipolar threshold. Runtimes are averaged over all image triplets.}%
    \label{fig:poselib_graphs}
\end{figure*}

%
%
%
%
%
%
%
%
%
%
%
%
        
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%


%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%








%
%
%
%
%
%
%
%
%



%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%


%
\PAR{Experiments on real data.} 
We test the solvers on all scenes from the PhotoTourism dataset~\cite{snavely2006photo, IMC2020} which provide ground truth poses and intrinsics via a COLMAP~\cite{Schoenberger2016CVPR} reconstruction. 
In the results, we do not include the \textit{St.~Peter's Square} scene that we used for the validation of $\delta$ and the number of refinement iterations (see SM). We also include results for the Cambridge Landmarks dataset~\cite{kendall2015cambridge} (except the Street scene, which is commonly not used due to issues with its ground truth) and Aachen Day-Night v1.1~\cite{zhang2021aachen}. 
For PhotoTourism and Aachen, we use the images in their original resolution. For Cambridge Landmarks, we resize
%
them
so that the larger side is 800~px. 
For each scene, we sample 5,000 random image triplets with at least 10 matches obtained with~\cite{detone2018superpoint,lindenberger2023lightglue}
%
with at least %
$10\%$ overlap~\cite{IMC2020}.

%

%

%

\begin{table*}[t]
    \centering
    \resizebox{1.0\linewidth}{!}{

\begin{tabular}{ l | c c c c c c | c c  c c c  c | c c c c c c}
    \multicolumn{1}{c}{~} & \multicolumn{6}{c}{PhotoTourism~\cite{IMC2020}} & \multicolumn{6}{c}{Cambridge Landmarks~\cite{kendall2015cambridge}} & \multicolumn{6}{c}{Aachen Day-Night v1.1~\cite{zhang2021aachen}} \\
    \toprule
    Estimator & AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime $\downarrow$& 
    AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime $\downarrow$& 
    AVG $(^\circ)$ $\downarrow$ & MED $(^\circ)$ $\downarrow$ & AUC@5 $\uparrow$ & @10 $\uparrow$ & @20 $\uparrow$ & Runtime $\downarrow$\\
    \midrule

\sfhc~\cite{Hruby_cvpr2022} & \phantom{1}6.37 & \phantom{1}1.62 & 62.41 & 73.53 & 81.94 & \phantom{1}64.10 & \phantom{1}8.73 & \phantom{1}2.67 & 47.99 & 64.58 & 76.65 & 60.11 & 12.43 & \phantom{1}3.55 & 42.28 & 55.20 & 66.55 & \phantom{1}67.26 \\
\midrule\sft & \phantom{1}5.40 & \phantom{1}1.60 & 62.93 & 74.30 & 83.00 & \phantom{1}33.77 & \phantom{1}7.46 & \phantom{1}2.65 & 48.36 & 65.33 & 77.75 & 24.04 & 10.52 & \phantom{1}3.38 & 43.43 & 56.73 & 68.28 & \phantom{1}53.34 \\
\sftENM & \phantom{1}5.23 & \phantom{1}1.56 & 63.77 & 75.03 & 83.50 & \phantom{1}48.79 & \phantom{1}7.20 & \phantom{1}2.63 & 48.74 & 65.68 & 78.04 & 34.82 & 10.59 & \phantom{1}3.41 & 43.32 & 56.64 & 68.06 & \phantom{1}71.61 \\
\sftRC & \phantom{1}5.10 & \phantom{1}1.50 & 64.90 & 75.90 & 84.11 & \phantom{1}38.12 & \phantom{1}7.15 & \phantom{1}2.58 & 49.42 & 66.35 & 78.55 & 31.82 & 10.37 & \phantom{1}3.36 & 43.73 & 57.15 & 68.71 & \phantom{1}54.34 \\
\sftRCENM & \phantom{1}4.99 & \phantom{1}1.50 & 65.18 & 76.20 & 84.30 & \phantom{1}56.52 & \phantom{1}6.98 & \phantom{1}2.58 & 49.38 & 66.31 & 78.57 & 47.07 & \underline{10.20} & \phantom{1}3.34 & 43.75 & 57.11 & 68.63 & \phantom{1}76.86 \\
\midrule \sfaf & 37.48 & 25.16 & 22.91 & 28.59 & 35.16 & \phantom{1}16.58 & 41.23 & 21.73 & 22.75 & 31.47 & 38.98 & 13.33 & 36.40 & 19.53 & 24.41 & 31.73 & 39.24 & \phantom{1}32.04 \\
\sfafENM & \phantom{1}4.97 & \phantom{1}1.48 & 65.49 & 76.47 & 84.53 & \phantom{1}40.45 & \phantom{1}7.02 & \phantom{1}2.59 & 49.35 & 66.32 & 78.53 & 28.35 & 10.35 & \phantom{1}3.38 & 43.62 & 56.99 & 68.55 & \phantom{1}62.44 \\
\sfafR & 33.45 & 19.95 & 25.86 & 32.22 & 39.16 & \phantom{1}\underline{16.32} & 36.98 & 11.59 & 27.03 & 36.70 & 44.48 & \underline{12.48} & 34.84 & 18.22 & 25.27 & 32.77 & 40.29 & \phantom{1}\underline{29.56} \\
\sfafRC & 35.65 & 23.47 & 23.99 & 29.97 & 36.64 & \phantom{1}\textbf{11.10} & 38.34 & 14.47 & 25.89 & 35.19 & 42.80 & \phantom{1}\textbf{9.35} & 36.77 & 20.76 & 23.94 & 31.23 & 38.58 & \phantom{1}\textbf{19.75} \\
\sfafRCENM & \phantom{1}4.98 & \phantom{1}1.48 & 65.62 & 76.56 & 84.55 & \phantom{1}32.37 & \phantom{1}6.99 & \phantom{1}2.57 & 49.62 & 66.55 & 78.72 & 23.43 & 10.43 & \phantom{1}3.38 & 43.57 & 56.95 & 68.56 & \phantom{1}42.36 \\
\midrule\sftm & \phantom{1}6.02 & \phantom{1}1.71 & 60.86 & 72.56 & 81.73 & \phantom{1}35.18 & \phantom{1}8.36 & \phantom{1}2.74 & 47.15 & 64.06 & 76.59 & 25.15 & 12.09 & \phantom{1}3.62 & 41.78 & 55.06 & 66.67 & \phantom{1}54.89 \\
\sftmENM & \phantom{1}5.28 & \phantom{1}1.58 & 63.61 & 74.96 & 83.46 & \phantom{1}48.83 & \phantom{1}7.21 & \phantom{1}2.63 & 48.69 & 65.57 & 77.95 & 34.93 & 10.67 & \phantom{1}3.43 & 43.31 & 56.61 & 68.08 & \phantom{1}70.87 \\
\sftmR & \phantom{1}5.49 & \phantom{1}1.56 & 63.66 & 74.88 & 83.37 & \phantom{1}41.52 & \phantom{1}7.69 & \phantom{1}2.63 & 48.69 & 65.67 & 77.99 & 30.76 & 11.17 & \phantom{1}3.46 & 43.28 & 56.39 & 67.88 & \phantom{1}60.40 \\
\sftmRC & \phantom{1}5.48 & \phantom{1}1.54 & 63.99 & 75.14 & 83.51 & \phantom{1}30.88 & \phantom{1}7.75 & \phantom{1}2.62 & 48.77 & 65.71 & 77.98 & 22.72 & 11.16 & \phantom{1}3.48 & 43.04 & 56.28 & 67.73 & \phantom{1}42.38 \\
\sftmRCENM & \phantom{1}5.01 & \phantom{1}1.50 & 65.18 & 76.16 & 84.28 & \phantom{1}44.51 & \phantom{1}6.99 & \phantom{1}2.58 & 49.43 & 66.31 & 78.56 & 32.48 & \underline{10.25} & \phantom{1}3.39 & 43.74 & 57.21 & 68.80 & \phantom{1}58.08 \\
\midrule\sftmd & \phantom{1}5.55 & \phantom{1}1.68 & 61.86 & 73.73 & 82.78 & \phantom{1}83.70 & \phantom{1}7.65 & \phantom{1}2.67 & 48.16 & 65.25 & 77.76 & 59.23 & 11.13 & \phantom{1}3.47 & 42.74 & 56.11 & 67.74 & 125.02 \\
\sftmdENM & \phantom{1}4.99 & \phantom{1}1.56 & 64.02 & 75.51 & 84.01 & 125.66 & \phantom{1}\underline{6.88} & \phantom{1}2.60 & 49.11 & 66.13 & 78.51 & 89.05 & 10.26 & \phantom{1}3.35 & 43.66 & 56.99 & 68.55 & 175.54 \\
\sftmdR & \phantom{1}\underline{4.86} & \phantom{1}\underline{1.47} & \underline{65.97} & \underline{77.00} & \underline{85.01} & 100.61 & \phantom{1}7.10 & \phantom{1}\underline{2.56} & \underline{49.79} & \underline{66.89} & \underline{79.08} & 73.94 & 10.37 & \phantom{1}\underline{3.34} & \underline{43.93} & \underline{57.26} & \underline{68.82} & 138.53 \\
\sftmdRC & \phantom{1}4.92 & \phantom{1}1.47 & 65.85 & 76.87 & 84.90 & \phantom{1}71.73 & \phantom{1}7.19 & \phantom{1}2.56 & 49.71 & 66.75 & 78.95 & 52.84 & 10.52 & \phantom{1}3.36 & 43.79 & 57.17 & 68.73 & \phantom{1}92.89 \\
\sftmdRCENM & \phantom{1}\textbf{4.66} & \phantom{1}\textbf{1.46} & \textbf{66.12} & \textbf{77.14} & \textbf{85.15} & 112.60 & \phantom{1}\textbf{6.65} & \phantom{1}\textbf{2.55} & \textbf{49.87} & \textbf{66.95} & \textbf{79.20} & 81.98 & \phantom{1}\textbf{9.96} & \phantom{1}\textbf{3.32} & \textbf{44.02} & \textbf{57.42} & \textbf{68.97} & 139.19 \\
\midrule
\end{tabular}}

%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
    \caption{Results for different solvers implemented in the PoseLib framework~\cite{PoseLib} on 12 scenes from PhotoTourism~\cite{IMC2020}, 5 scenes from Cambridge Landmarks~\cite{kendall2015cambridge} and Aachen Day-Night v1.1~\cite{zhang2021aachen}. We mark the \textbf{best} and \underline{second best} results. Runtimes are reported in ms for the whole RANSAC with early termination (0.9999 confidence, minimum 100 iterations) and epipolar threshold set to 5 px.
    }
    \label{tab:poselib_both}
\end{table*}

%
%
%
%

%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

Tab.~\ref{tab:poselib_both} shows the results 
%
for PoseLib RANSAC with early termination and 5px epipolar threshold. %
Results for GC-RANSAC are in SM. 
With the suggested modifications (see Sec.~\ref{sec:making_solvers_practical}) all 
%
proposed 
solvers outperform the state-of-the-art %
\sfhc solver~\cite{Hruby_cvpr2022} in terms of pose accuracy with many 
%
of the variants also achieving faster runtimes. 

Using filtering (\texttt{+F}) improves the run-time of RANSAC at the cost of a decrease in pose accuracy. 
Still, our \sftmRC solver outperforms \sfhc in terms of both accuracy and run-time. 
The \sftmd and \sftmdR solvers clearly improve upon the \sftm solvers, albeit at an increased run-time.
%
%
%
Still the \sftmdRC solver provides, in general, the best speed-accuracy trade-off.
The results also show that early non-minimal refinement (\texttt{+ENM}) is necessary for the \sfaf solver to perform well. 
For the other approximate solvers, this form of refinement also leads to improved accuracy at some cost to the runtime. 
% \newtext
{Assuming that the \sft solver samples five points from which at least four have projections in all three cameras, the suggested 
pose refinement (+R) and filtering (+F) can also be applied to the baseline \sft by using the fourth (potentially the fifth) point in the third view.
%In this case, the fourth (potentially the fifth) point in the third view is used in the same way as in proposed solvers. 
The suggested modifications improve the performance of the \sft solver, with the \sftRCENM solver having an accuracy similar to that of the \sftmRCENM solver, however at slower run-times, 
Moreover, it is less %and worse accuracy 
accurate than the proposed \sftmdRCENM solver.
}

We also investigate the speed-accuracy trade-off of the solvers by running PoseLib RANSAC~\cite{PoseLib} for a set of fixed numbers of iterations. 
Runtimes are reported for 1 core of a 2 GHz Intel Xeon Gold 6338 CPU. 
As shown in Fig.~\ref{fig:poselib_graphs}, %
%
the proposed \sftmdRC solver consistently provides the best speed-accuracy trade-off both with and without \texttt{ENM}. \sfafRCENM provides a similar performance, %
typically beating \sfhc~\cite{Hruby_cvpr2022}. However, as shown in Fig.~\ref{fig:poselib_graphs_st_mary} for the \textit{St.~Mary's Church} scene~\cite{kendall2015cambridge}, %
it may perform worse for some specific scenes.
%
%
%
%

%
% \newtext
{
The SM provides detailed ablation studies on the significance of each individual modification (\texttt{+R}/\texttt{+C}/\texttt{+ENM}).} % as well as the various improvements achieved, 
% are presented in the SM.}
%
%
%
%

%
%
%

%
%
%
%
%




%
%
%
%
%
%
%



%
%
%
%

%
\PAR{Limitations.} 
%
As discussed, 
%
the accuracy of the proposed approximate solvers is scene dependent.\footnote{This weakness also applies to~\cite{Hruby_cvpr2022}, since the scene needs to be similar enough to the training scenes for the MLP-based classifier to work well.} However, after using the propsed ENM refitting, the scene-dependency is negligible. 
Especially for the \sftmdENM solver, we have not noticed performance drops for some specific scene geometries or camera configurations. 
While the two-view variants of our solvers $\texttt{4p(M)}$/\texttt{4p(M$\pm \delta$)} provide very similar results to the $\texttt{5pt}$ solver in two views, in this case they do not outperform the $\texttt{5pt}$ solver. In the three-view scenario, the better performance is achieved thanks to the proposed pose refinement (+R) and filtering (+F).

The proposed ENM refitting cannot be applied to the \sfhc solver~\cite{Hruby_cvpr2022}, since this solver estimates the pose of all three cameras together. It is theoretically applicable to the solver proposed in~\cite{DBLP:journals/ijcv/NisterS06}. However, here ENM would have needed to be run on hundreds of candidate poses corresponding to tens-to-hundreds of sampled epipoles. This is because for one fixed point on the curve of epipoles,
the error of the sampled epipole is not bounded since the true epipole can lie anywhere on the curve, even outside the image. Thus, ENM might avoid local minima present in the second step of the original solver, but would significantly slow down the solver in the first step, making it much slower than our \sftmENM / \sftmdENM solvers.




%
%
%
%
%
%
%

\section{Conclusion}
We consider the highly challenging %
problem of relative pose estimation of three calibrated %
cameras from four correspondences. 
We propose  novel 
%
approaches that solve the problem by utilizing solvers based on approximate geometry. The best performing solver uses a simple, yet novel strategy by using mean coordinates of three input points and points in their vicinity as an  approximate $5^{th}$ correspondences.
Extensive experiments show that our solvers achieve state-of-the-art performance on a large variety of real scenes. 
%
At the same time, our solvers %
%
are simple to implement, especially compared to the current state-of-the-art~\cite{Hruby_cvpr2022}. 

%
%
\PAR{Acknowledgements.}
This work was funded by 
the Czech Science Foundation (GAČR) JUNIOR STAR Grant No.~22-23183M (supporting C.T., Y.D., and Z.K.), 
the Grant Agency of the Czech Technical University in Prague grant no.~SGS23/173/OHK3/3T/13 (supporting C.T.), 
the EU NextGenerationEU through the Recovery and Resilience Plan for Slovakia under the project ''InnovAIte Slovakia, Illuminating Pathways for AI-Driven Breakthroughs" No.~09I02-03-V01-00029, % (supporting V.K.), 
the TERAIS project -- a Horizon-Widera-2021 program of the European Union under the Grant agreement number 101079338 (supporting V.K. and Z.B.H.), 
and the EU Horizon 2020 project RICAIP grant agreement No.~857306 (supporting T.S.). 
Part of the research results was obtained using the computational resources procured in the national project National competence centre for high performance computing project code: 311070AKF2, funded by European Regional Development Fund, EU Structural Funds Informatization of society, Operational Program Integrated Infrastructure.

\input{supplementary}

{\small
\bibliographystyle{ieeenat_fullname}
\bibliography{bibliography}
}

\end{document}