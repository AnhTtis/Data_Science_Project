\subsection{Time series classification} \label{sec:supclass}

\begin{table}[!t]
  \centering
    \caption{\textbf{Performance comparison for classification on all datasets.} We report for our method and competing methods, the number of trainable parameters (\#param) when trained on PASTIS, the overall accuracy (OA) and the mean class accuracy (MA). We distinguish with a background color the DENETHOR dataset - where train and test splits are acquired during different periods - from the others. 1NN-DTW is tested on TimeSen2Crop dataset only, due to the expensive cost of the algorithm. We separate results in 3 parts: the image level method UTAE, MTSC methods and different ablations of DTI-TS. We put in bold the best method in each of the 3 parts and underline the absolute best for each dataset. We report the average inference time of each method to process a batch of 2,048 time series from TS2C on a single NVIDIA GeForce RTX 2080 Ti GPU.\\}
  \resizebox{\linewidth}{!}{
  \begin{tabular}{lrrccccccaa}
  \toprule
    & \#param & Inf. time &\multicolumn{2}{c}{PASTIS} & \multicolumn{2}{c}{TS2C} & \multicolumn{2}{c}{SA} & \multicolumn{2}{a}{DENETH.}\\
    \cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
    Method & (x1000) & (ms/batch) & {\color{ACC}OA$\uparrow$} & MA$\uparrow$ & {\color{ACC}OA$\uparrow$} & MA$\uparrow$ & {\color{ACC}OA$\uparrow$} & MA$\uparrow$ & {\color{ACC}OA$\uparrow$} & MA$\uparrow$\\
    \midrule
    UTAE~\citep{Garnot2021}                  & $1\ 087$ & --- & \underline{\color{ACC}$\mathbf{83.3}$} & \underline{$\mathbf{73.6}$} & {\color{ACC}---} & --- & {\color{ACC}---} & --- & {\color{ACC}---} & ---\\
    \midrule
    MLP + LTAE~\citep{garnot2020lightweight} & $320$    &  78 & {\color{ACC}$80.6$} & $65.9$ & \underline{\color{ACC}$\mathbf{88.7}$} & $80.9$ & \color{ACC}$67.4$ & \underline{$\mathbf{63.7}$} & {\color{ACC}$55.6$} & $43.6$\\
    OS-CNN~\citep{tang2020rethinking}        & $4\ 729$ & 119 & {\color{ACC}$\mathbf{81.3}$} & $\mathbf{68.1}$ & {\color{ACC}$87.9$} & \underline{$\mathbf{81.2}$} & {\color{ACC}$64.6$} & $60.3$ & {\color{ACC}$49.0$} & $39.2$\\
    TapNet~\citep{zhang2020tapnet}           & $1\ 882$ & 229 & {\color{ACC} 78.0} & 60.3 & {\color{ACC}$83.1$} & $77.3$ & {\color{ACC}$59.6$} & $56.7$ & {\color{ACC} 53.1} & 43.7\\
    MLSTM-FCN~\citep{karim2019multivariate}  & $490$    & 11 & {\color{ACC}$44.4$} & $10.9$ & {\color{ACC}$58.7$} & $44.0$ & {\color{ACC}$56.1$} & $47.9$ & {\color{ACC}$58.2$} & $48.3$\\
    SVM~\citep{cortes1995support}           & $77$     & 48 & {\color{ACC}$76.3$} & $48.7$ & {\color{ACC}$74.9$} & $56.1$ & {\color{ACC}$64.6$} & $52.8$ & {\color{ACC}$35.6$} & $28.6$\\
    Random Forest~\citep{ho1995random}       & $16$    & 140 & {\color{ACC}$76.6$} & $46.6$ & {\color{ACC}$66.9$} & $50.2$ & {\color{ACC}\underline{$\mathbf{69.9}$}} & $61.3$ & {\color{ACC}$59.9$} & $51.6$\\
    1NN-DTW~\citep{seto2015multivariate}     & $0$      & $>$10$^4$ &{\color{ACC}---}    & ---    & {\color{ACC}$32.2$} & $23.0$ & {\color{ACC}---}    & --- & {\color{ACC}---} & ---\\
    1NN~\citep{cover1967nearest}             & $0$      & 6 & {\color{ACC}$65.8$} & $40.1$ & {\color{ACC}$43.9$} & $35.0$ & {\color{ACC}$60.7$} & $54.9$ & {\color{ACC}$56.7$} & $48.2$\\
    NCC~\citep{duda1973pattern}              & $77$     & 24 & {\color{ACC}$56.5$} & $48.4$ & {\color{ACC}$57.1$} & $49.9$ & {\color{ACC}$51.3$} & $46.4$ & {\color{ACC}$\mathbf{61.3}$} & $\mathbf{55.5}$\\
    \midrule
    DTI-TS: NCC~$+$~time warping                      & $398$    & 97 & {\color{ACC}$56.2$} & $51.4$ & {\color{ACC}$59.9$} & $52.3$ & {\color{ACC}$54.5$} & $49.7$ & \underline{\color{ACC}$\mathbf{62.4}$} & $56.4$\\
    ~~~~~~~~~~~~~~~~~~~~~~~$+$~offset                          & $423$    & 97 & {\color{ACC}$53.5$} & $53.8$ & {\color{ACC}$57.3$} & $55.0$ & {\color{ACC}$60.6$} & $50.0$ & {\color{ACC}$59.8$} & \underline{$\mathbf{62.9}$}\\
	~~~~~~~~~~~~~~~~~~~~~~~~~~$+$~contrastive loss              & $423$    & 97 & {\color{ACC}$\mathbf{73.7}$} & $\mathbf{59.1}$ & {\color{ACC}$\mathbf{78.5}$} & $\mathbf{70.5}$ & {\color{ACC}$\mathbf{62.3}$} & $\mathbf{54.9}$ & {\color{ACC}$56.5$} & $54.2$\\ 
  \bottomrule
  \end{tabular}
  }
  \label{tab:super}
\end{table}
We report the performance of \modelname~and competing methods in Table~\ref{tab:super}. Results on the DENETHOR dataset are qualitatively very different from the results on the other datasets. We believe this is because DENETHOR has train and test splits corresponding to two distinct years. We thus analyze it separately.

\paragraph{Results on PASTIS, TimeSen2Crop and SA.} As expected, since UTAE can leverage knowledge on the spatial context of each pixel, it achieves the best score on PASTIS dataset by $+2.0\%$ in OA and $+5.5\%$ in MA.
Our improvements over the NCC method~\citep{duda1973pattern} - adding time warping deformation, offset deformations and contrastive loss~(\ref{eq:lce_sup}) - consistently boost the mean accuracy. The improvement obtained by adding transformation modeling comes from a better capability to model the data, as confirmed by the detailed results reported in the left part of Table~\ref{tab:super_ablation}, where one can see the reconstruction error (i.e. $\mathcal{L}_\text{rec}$) significantly decreases when adding these transformations. Note that on the contrary, adding the discriminative loss increase the accuracy at the cost of decreasing the quality of the reconstruction error. Our complete supervised approach outperforms the nearest neighbor based methods, the traditional learning approaches SVM and Random Forest and also MLSTM-FCN. However, it is still significantly outperformed by top MTSC methods. This is not surprising, since these methods are able to learn complex embeddings that capture subtle signal variations, e.g. thanks to a temporal attention mechanism~\citep{garnot2020lightweight} or to multiple-sized receptive fields~\citep{tang2020rethinking}. Note however that in doing so, they lose the interpretability of simpler approaches such as 1NN or NCC, which our method is designed to keep.

\paragraph{Results on DENETHOR.} Because the data we use is highly dependent on weather conditions, subsets acquired on distinct years follow significantly different distributions~\citep{Kondmann2021denethor}. Because of their complexity, other methods struggle to deal with this domain shift. In this setting, our extension of NCC to incorporate specific meaningful deformations achieves better performances than all the other MTSC methods we evaluated. However, adding the contrastive loss significantly degrades the results. We believe this is again due to the temporal domain shift between train and test data. This analysis is supported by results reported in Table~\ref{tab:super_ablation} which show that on the validation set of DENETHOR, which is sampled from the same year as the training data, adding the constrative loss significantly boost the results, similar to the other dataset. One can also see again on DENETHOR the benefits of modeling the deformations in terms of reconstruction error.
\begin{figure}[t]
    \includegraphics[trim={0 0 0 0}, clip, width=0.55\linewidth]{figures/pastis_percentage_img_training.pdf}
    \centering
    \caption{\textbf{Low data regime on PASTIS dataset.} Using Fold 2 of PASTIS dataset, we train on only 1, 2, 4 or 10\% of the image time series of the training set. For the 1\%, 2\% and 4\% samples, we show the average for 5 random different subsets.}
    \label{fig:percent_training_set}
\end{figure}
\paragraph{Low data regime.} Our method is also beneficial when only few annotated images are available at training time. In Figure~\ref{fig:percent_training_set}, we plot the MA obtained by NCC, MLP+LTAE, OS-CNN, TapNet and our method depending on the proportion of the SITS of PASTIS dataset. While all methods benefit from more training data, our prototype-based approach generalizes better from few annotated samples. When using 4\% of the dataset or less, \textit{i.e.} 60 annotated image time series or less, our method is the best of all MTSC methods benchmarked in this paper. Training on 1\% of the data it outperforms MLP+LTAE by +4.7\% in MA, TapNet by +8.8\% and OS-CNN by +10.9\% but is not able to clearly do better than the NCC baseline. Using 2\% or 4\% of the dataset, \modelname~clearly improves over NCC and still has better scores than MLP+LTAE, TapNet and OS-CNN.
