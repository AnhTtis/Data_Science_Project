\subsection{Datasets}

\begin{table*}[!t]
  \vspace{-.5em}
  \renewcommand{\arraystretch}{0.75}
  \addtolength{\tabcolsep}{0.2pt}
  \centering
  %\scriptsize
  \begin{tabular}{@{}lcllllcll@{}} \toprule
  
    Dataset & Country & $T$ & $C$ & $K$ & Train/Test shift & Satellite(s) & Daily & Split size (x $10^6$)\rule{0pt}{2.6ex}\rule[-1.2ex]{0pt}{0pt}\\
    \midrule
    \rule{0pt}{3ex}
    PASTIS~\cite{Garnot2021} & \raisebox{-0.1\height}{\includegraphics[width=11px]{images/flags/fr.pdf}} & 406 & 10 & 19 & Spat. & Sentinel 2 & \xmark & 7.3 $|$ 7.3 $|$ 7.3 $|$ 7.0 $|$ 7.1\\
    \rule{0pt}{3ex}
    TimeSen2Crop~\cite{Weikmann2021} &\raisebox{-0.1\height}{\includegraphics[width=11px]{images/flags/at.pdf}} & 363 & 9 & 16 & Spat. & Sentinel 2 & \xmark & 0.8 $|$ 0.1 $|$ 0.1\\
    \rule{0pt}{3ex}
    SA~\cite{kondmann2022early} & \raisebox{-0.1\height}{\includegraphics[width=11px]{images/flags/za.pdf}} & 244 & 4 & 5 & Spat. & PlanetScope & \cmark & 60.1 $|$  10.1 $|$ 32.0\\
    \rule{0pt}{3ex}
    DENETHOR~\cite{Kondmann2021denethor} &\raisebox{-0.1\height}{\includegraphics[width=11px]{images/flags/de.pdf}} & 365 & 4 & 9 & Spat. \& Temp. & PlanetScope & \cmark & 20.6 $|$ 3.2 $|$ 22.8 \rule[-1.2ex]{0pt}{0pt}\\
  \bottomrule
  \end{tabular}
  \vspace{-.8em}
  \caption{\textbf{Comparison of studied datasets.} The datasets we study cover different regions (France, Austria, South Africa and Germany). We distinguish between datasets where train and test splits differ only spatially (Spat.) and where they differ both spatially and temporally (Spat. \& Temp.). Time series can have daily data (\cmark) or missing data (\xmark). Additionally, we report the length of the time series $T$, the number of spectral bands $C$ and the number of classes $K$. The last column shows the split sizes as train $|$ val $|$ test, except for PASTIS where we follow the 5-fold procedure described in~\cite{Garnot2021} and we show the size of each of the folds.
}
  \label{tab:comp}
  \vspace{-1em}
\end{table*}

We consider four recent open-source datasets on which we evaluate our method and multiple baselines. Details about these datasets can be found in Table~\ref{tab:comp}. %We now detail their respective main characteristics.

\paragraph{PASTIS~\cite{Garnot2021}.}~This dataset contains Sentinel-2 satellite patches within the French metropolitan area, acquired from September 1, 2018 to October 31, 2019. Each image time series contains a variable number of images that can show clouds and/or shadows. We pre-process the dataset and remove most of the cloudy/shadowy pixels using a classical thresholding approach on the blue reflectance~\cite{breon:hal-03119834}. We consider each of the pixels of the 2433 $128\times128$ image time series as independent time series, except those corresponding to the 'void' class, leading to $36$M times series. Each is labeled with one of 19 classes (including a \textit{background}, i.e., non-agricultural class). We follow the same 5-fold evaluation procedure as described in~\cite{Garnot2021}, with at least 1km separating images from different folds to ensure distinct spatial coverage between them.

\paragraph{TimeSen2Crop~\cite{Weikmann2021}.}~This dataset is also built from Sentinel-2 satellite images, but covering Austrian agricultural parcels and acquired between September 3, 2017 and September 1, 2018. It does not provide images but directly $1$M pixel time series of variable lengths. We pre-process these time series by removing the time-stamps associated to the 'shadow' and 'clouds' annotations provided in the dataset. Each time series is labeled with one of 16 types of crops. We follow the same train/val/test splitting as in~\cite{Weikmann2021} where each split covers a different area in Austria.

\paragraph{SA~\cite{kondmann2022early}.}~This dataset is built from images from the PlanetScope constellation of Cubesats satellite covering agricultural areas in South Africa, and contains daily time series from April 1, 2017 to November 31, 2017. Acquisitions are fused using Planet Fusion\footnote{https://assets.planet.com/docs/Fusion-Tech-Spec\_v1.0.0.pdf} to compensate for possible missing dates, clouds or shadows so that the provided data consists in clean daily image time series. The dataset contains 4151 single-field images time series from which we extract $102$M pixel time series. Each time series is labeled with one of 5 types of crops. We keep the same train/test splitting of the data and reserve 15\% of the train set for validation purposes. We make sure that the obtained train and validation set do not have pixel time series extracted from the same field image. 
 
\paragraph{DENETHOR~\cite{Kondmann2021denethor}.}~This dataset is also built from Cubesats images but covers agricultural areas in Germany. The training set is built from daily time series acquired from January 1, 2018 to December 31, 2018, while the test set is built from time series acquired from January 1, 2019 to December 31, 2019. The time shift between train and test sets makes this dataset significantly more challenging than the three previous ones. Similar to SA, the dataset has been pre-processed to provide clean daily time series. It contains 4561 single-field images time series from which we extract $47$M independent pixel time series. Each time series is labeled with one of 9 types of crops. Again, we use the original splits of the data, with 15\% of the training set kept for validation. All splits cover distinct areas in Germany.

\paragraph{Missing data.} Our method, as presented in Section~\ref{sec:method}, is designed for uniformly sampled constant-sized time series. While DENETHOR and SA time series have been pre-processed to obtain such regular data, PASTIS and TimeSen2Crop have at most a data point every 5 days due to a lower revisit frequency, and additional missing dates because of clouds or shadows. To handle such non-regularly sampled time series, we propose a simple interpolation scheme to transform raw time series into complete time series and an associated adaptation of our losses. 

 
Let us consider a specific time series, acquired over a period of length $T$ but with missing data. We define the associated raw time series $\inputseq_\text{raw}\in \mathbb{R}^{T\times C}$ by setting zero values for missing time steps and the associated binary mask $\mask_\text{raw}\in \{0,1\}^{T}$, equal to $0$ for missing time stamps and $1$ otherwise. We define the interpolated time series $\inputseq$ extracted from $\inputseq_\text{raw}$ and $\mask_\text{raw}$ through Gaussian filtering for $t\in [1, T]$ by:

\begin{equation}
    \inputseq[t] = \frac{1}{\mask[t]}\sum_{t'=1}^T \mathcal{G}_{t, \sigma}[t'] \cdot \inputseq_\text{raw}[t'],
    \label{eq:gaussian_filtering}
\end{equation}
with
\begin{equation}
    \mathcal{G}_{t, \sigma}[t'] = \exp\Big(-\frac{(t'-t)^2}{2\sigma^2}\Big),
    \label{eq:gaussian_filter}
\end{equation}
where $\sigma$ is a hyperparameter set to 7 days in our experiments. We also define the associated interpolated mask $m$ for $t\in [1, T]$ by:
\begin{equation}
    \mask[t] = \sum_{t'=1}^T \mathcal{G}_{t, \sigma}[t'] \cdot \mask_\text{raw}[t'],
    \label{eq:gaussian_filtering_mask}
\end{equation}
for $t\in [1, T]$ and with the same hyperparameter $\sigma$.

Using directly this interpolated time series to compute our mean square errors would lead to large errors, because data might be missing for long time periods. Thus, we modify the losses $\mathcal{L}_\text{rec}$ and $\mathcal{L}_\text{rec\_sup}$ by replacing the reconstruction error between a time series $\inputseq$  and reconstruction $\recons$,
\begin{equation}
    \frac{1}{TC}\Big|\Big|\inputseq-\recons\Big|\Big|_2^2= \frac{1}{C}\sum_{t=1}^T\frac{1}{T}\Big|\Big|\inputseq[t]-\recons[t]\Big|\Big|_2^2,
\end{equation}
in Equations~(\ref{eq:lrec_unsup}) and~(\ref{eq:lrec_sup}) by a weighted mean squared error:
\begin{equation}
\frac{1}{C}\sum_{t=1}^T\frac{m[t]}{\sum_{t'=1}^T m[t']}\Big|\Big|\inputseq[t]-\recons[t]\Big|\Big|_2^2.
\label{eq:lrec_unsup_mask}
\end{equation}
This adapted loss gives more weight to time stamps $t$ corresponding to true data acquisitions.