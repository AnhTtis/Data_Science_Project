\section{Related Work}

We first review methods specifically designed for SITS classification which are typically supervised and may take as input complete images or individual pixel sequences. When each pixel sequence is considered independently, SITS classification can be seen as a specific case of MTSC, for which both supervised and unsupervised approaches exist, which we review next. Finally, we review transformation-invariant prototype-based classification approaches which we extend to SITS classification in this paper.

\paragraph{Supervised satellite image time series classification.}{Deep networks for SITS classification either take individual pixel sequences~\cite{garnot2020satellite, garnot2020lightweight, ienco2017land, BELGIU2018509} or series of images~\cite{russwurm2018convolutional, pelletier2019temporal, Garnot2021} as input. While treating images as a whole may undeniably improves pattern learning for classification as the model can access spatial context information, we focus our work on pixel sequences, which allows us to present a simpler and less restrictive framework that can generalize better to various forms of input data. We evaluate our approach on four recent datasets of agricultural geospatial data~\cite{Garnot2021, Kondmann2021denethor, kondmann2022early, Weikmann2021}.}

\paragraph{Supervised multivariate times series classification.}{Methods achieving MTSC can be divided in two sub-groups: whole series-based techniques and feature-based techniques. Whole series-based methods includes nearest-neighbor search - where the closest neighbor is computed either using Euclidian distance~\cite{cover1967nearest} or DTW~\cite{shokoohi2015non} - and prototype-based approaches that model a template for each class of the dataset~\cite{seto2015multivariate, shapira2019diffeomorphic} and classify an input at inference by assigning it to the nearest prototype. Feature-based classifiers include bag-of-patterns methods~\cite{schafer2015boss, schafer2017multivariate}, shapelet-based techniques~\cite{lines2012shapelet, bostrom2015binary} and deep encoders like 1D-CNNs~\cite{tang2020rethinking, ismail2020inceptiontime} or LSTMs~\cite{karim2019multivariate, zhang2020tapnet, ienco2017land}.}

\begin{figure*}[t]
  \center
  \includegraphics[trim={0.5cm 0.85cm 5.0cm 0.8cm}, clip, width=\linewidth]{figures/pipeline.pdf}
  \caption{\textbf{Overview of the method.} Our method reconstructs a pixel-wise multi-spectral input sequence, extracted from a SITS, thanks to a prototype to which are successively applied a time warping and an offset. The parameters of these transformations are input-dependent and prototype-specific. The functions $g_{1:K}$ predicting the parameters of the transformations and the prototypes $\proto_{1:K}$ can be learned with or without supervision.}
  \label{fig:method}
  \vspace{-1.3em}
\end{figure*}
\paragraph{Unsupervised multivariate time series classification.}{The classical approach to multivariate time series clustering is to apply K-means~\cite{macqueen1967classification} to the raw time series. DTW has been shown to improve upon K-means for time series clustering in the particular case of SITS~\cite{zhang2014modis, Petitjean2011}. DTW is used during both steps of K-means: the assignment is performed under DTW and the centroids are updated as the DTW-barycenter averages of the newly formed clusters. 

Approaches to multivariate time series clustering often work on improving the representation used by K-means. Methods either extract hand-crafted features~\cite{wang2005dimension, rajan1995unsupervised, Petitjean2012} or apply principal component analysis~\cite{li2019multivariate, singhal2005clustering}. In \cite{Petitjean2012}, mean-shift~\cite{comaniciu2002mean} is used to segment the image into potential individual crops and K-means features are the means of the spectral bands and the smoothness, area and elongation of the obtained segments. \cite{Kalinicheva2020} reproduces this multi-step scheme but instead (i) applies mean-shift segmentation to a feature map encoded by a 3D spatio-temporal deep convolutional autoencoder, (ii) takes the median of the spectral bands over a segment as a feature representation, and (iii) uses hierarchical clustering to classify each segment. Other deep approaches that perform unsupervised classification of time series either use pseudo-labels to train neural networks in a supervised fashion~\cite{guo2022deep,iounousse2015using} or focus on learning deep representations on which clustering can be performed with standards algorithms~\cite{franceschi2019unsupervised, tonekaboni2021unsupervised}. DTIC~\cite{guo2022deep} iteratively trains a TempCNN~\cite{pelletier2019temporal} with pseudo-labelling and performs K-means on the learned features to update the pseudo-labels. 

Methods that perform deep unsupervised representation learning and clustering simultaneously~\cite{caron2018deep, YM.2020Self-labelling} are promising for time series classification. Although some recent works~\cite{franceschi2019unsupervised, tonekaboni2021unsupervised} train supervised classifiers using these learned features on temporal data as input, to the best of our knowledge, no method designed for time series performs classification in a fully unsupervised manner.

\paragraph{Transformation-invariant prototype-based classification.}The DTI framework~\cite{monnier2020deep} jointly learns prototypes and prototype-specific transformations for each sample. Each prototype is associated with a transformation network, which predicts transformation parameters for every sample and thus enables the prototype to better reconstruct them. The resulting models can be used for downstream tasks such as classification~\cite{monnier2020deep, loiseau22amodelyoucanhear}, few-shot segmentation~\cite{loiseau2021representing} and multi-object instance discovery~\cite{monnier2021unsupervised} and be trained with or without supervision. To the best of our knowledge, the DTI framework has never been applied to the case of time series, for which classifiers need to be invariant to some temporal distortions. Previous works bypass this concern using DTW to compare the samples to classify~\cite{Petitjean2011, seto2015multivariate} or by applying a transformation field to a selection of control points to distort the time series. Specific to agricultural time series,~\cite{Nyborg_2022_CVPR} leverages the fact that temperature is the main factor of temporal variations and uses thermal positional encoding of the temporal dimension to account for temperature change from a year (or location) to another. We use the DTI framework to instead learn the alignment of samples to the prototypes. \cite{shapira2019diffeomorphic} explores a similar idea for generic univariate time series, but, to the best of our knowledge, our paper is the first to perform both supervised and unsupervised transformation-invariant classification for agricultural satellite time series.
