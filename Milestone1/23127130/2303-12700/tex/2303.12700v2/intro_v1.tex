

In this paper, we introduce ReorientDiff, a diffusion model based \emph{generative} method to restructure the reorientation pose generation pipeline as a conditional distribution learning problem. Such a method enables us to directly sample feasible reorientation poses without rejection sampling, thus improving \emph{scalability}. Our contributions can be summarized as follows:

\textbf{Learning a distribution of intermediate poses:} For a given pile of objects, a target object, and its target placement location, we formulate a conditional distribution of feasible intermediate poses. As compared to rejection sampling using random prior, our approach aims at providing a learned prior to efficiently sample high-quality reorientation poses. Leveraging the multi-modality of diffusion models, this distribution encompasses all poses reachable from both the current pose and the target pose. 
% Notably, this formulation implicitly accounts for the effects of gravity, as illustrated in~\autoref{fig:train_pitcher_drill}.

\textbf{Flexibly sampling based on possible grasp poses:} It is necessary to make sure that the grasp poses w.r.t. object is constant during one pick-place transition. To achieve this, we flexibly sample intermediate poses from the learned distribution based on feasible grasp poses using classifier guidance via pre-trained success classifiers~\cite{mousavian20196dof, wada2022reorientbot}. Such models implicitly refine sampled pose and operate individually for both transitions during reorientation. Hence, the learned distribution can be used for any possible grasp pose based on kino-dynamic feasibility directly at inference.

\textbf{Representing target placement location via natural language:} We leverage CLIP~\cite{radford2021learning} to generate information embeddings from visual input and task descriptions in natural language.  We further use these embeddings as conditions for learning the conditional distribution. While this has been explored in recent literature~\cite{shridhar2022cliport}, we see this as a substantial improvement over the baseline.

In the proposed approach, we combine a generic classifier-free conditional sampling~\cite{ho2022classifier} with classifier-guided sampling~\cite{dhariwal2021diffusion} to sample from diffusion models. To validate the performance of ReorientDiff, we consider reorientation of objects in the YCB dataset~\cite{calli2015ycb} that are feasible for suction grippers. For each selected object, we choose suitable locations on multiple shelf levels and target orientations.