\textbf{Object manipulation and reorientation.} Finding the grasp pose that is feasible for both the current and target location is a widely employed strategy for pick-and-place operations~\cite{mahler2017dex, mahler2018dex, mahler2019learning}. Such problems are usually solved in two steps: deciding an appropriate placement pose (within a region of interest) and searching for common grasps. In order to ensure feasible target placement, prior works have mostly relied on known object geometries~\cite{mahler2017dex, mahler2018dex}, vision-based object representation~\cite{zeng2021transporter, seita2021learning} or using segmentation and depth maps of the pre-specified target object~\cite{pinto2016supersizing, zeng2022robotic, wada2022reorientbot}. These strategies have led to several object rearrangement methods~\cite{shridhar2022cliport, shridhar2022perceiver, tang2022selective}. Unlike most prior works that consider the availability of common grasps by default, for complex manipulation scenarios where there are no common grasps, \emph{reorientation} becomes mandatory. The object needs to be reoriented to an intermediate pose and \emph{regrasped} to place it at the target location. Such a scenario has been traditionally tackled via rejection sampling strategies and recently improved via regression-based methods. We also aim to develop a learning-based method.  

\textbf{Learning for object manipulation.} While prior works have pre-dominantly incorporated trajectory planners~\cite{kuffner2000rrt}, they have employed learning strategies to decide the target object and its placement pose as discussed in the previous subsection. Additionally, task descriptions as natural language have been very effective for generalized pick-place tasks in planar tabletop~\cite{shridhar2022cliport} and 3D~\cite{shridhar2022perceiver} manipulation. Such language descriptions can be embedded into the learning pipeline via foundation models like CLIP~\cite{radford2021learning}, which encodes visual and language information into a common representation space. This has been further extended towards language-conditioned object rearrangement planning~\cite{liu2022structdiffusion, liu2022structformer} and supplying high-level instructions for long-horizon planning~\cite{ahn2022can}.

Recently, \emph{reorientation} problems have been solved by planning to reorient objects using extrinsic supports~\cite{cheng2021learning, xu2022planar}, which enables them to re-grasp the object in a desired way. The above methods are regression-based and limited to modeling only one solution pose. Such approaches cannot cater to the multiple possible solutions of the same problem. In such a case, rejection sampling is still beneficial and can be performed using learned feasibility prediction models~\cite{wada2022reorientbot}. We want to develop a pipeline that can still learn about all feasible poses without analyzing extensive random samples.

\textbf{Generative models for object manipulation.} For pick-and-place and reorientation tasks, there can be multiple feasible grasps and reorientation poses respectively. Hence, generative models offer an option to learn them as conditional distributions. Prior works have explored VAE for planning grasps~\cite{mousavian20196dof} using visible point-cloud of objects. In this direction, diffusion models have been shown to be advantageous for robotics~\cite{janner2022diffuser, ajay2022conditional, chi2023diffusion, mishra2023generative, xian2023unifying}. Recent works have demonstrated the multi-modal distribution learning using diffusion models for finding target poses~\cite{liu2022structdiffusion, simeonov2023shelving} and learning policies~\cite{janner2022diffuser, ajay2022conditional, chi2023diffusion}. In addition to such properties, we also plan to leverage the flexible sampling and conditioning strategies offered by diffusion models to incorporate additional conditions at inference without re-training.